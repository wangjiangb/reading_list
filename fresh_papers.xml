<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/"><channel><title>Arxivfresh papers</title><link></link><description>Arxiv paper</description><language>en-US</language><lastBuildDate>Fri, 24 Jan 2025 01:00:08 GMT</lastBuildDate><generator>rfeed v1.0.0</generator><docs>https://github.com/svpino/rfeed/blob/master/README.md</docs><item><title>Accelerate High-Quality Diffusion Models with Inner Loop Feedback</title><link>http://arxiv.org/abs/2501.13107v1</link><description>We propose Inner Loop Feedback (ILF), a novel approach to acceleratediffusion models' inference. ILF trains a lightweight module to predict futurefeatures in the denoising process by leveraging the outputs from a chosendiffusion backbone block at a given time step. This approach exploits two keyintuitions; (1) the outputs of a given block at adjacent time steps aresimilar, and (2) performing partial computations for a step imposes a lowerburden on the model than skipping the step entirely. Our method is highlyflexible, since we find that the feedback module itself can simply be a blockfrom the diffusion backbone, with all settings copied. Its influence on thediffusion forward can be tempered with a learnable scaling factor from zeroinitialization. We train this module using distillation losses; however, unlikesome prior work where a full diffusion backbone serves as the student, ourmodel freezes the backbone, training only the feedback module. While manyefforts to optimize diffusion models focus on achieving acceptable imagequality in extremely few steps (1-4 steps), our emphasis is on matching bestcase results (typically achieved in 20 steps) while significantly reducingruntime. ILF achieves this balance effectively, demonstrating strongperformance for both class-to-image generation with diffusion transformer (DiT)and text-to-image generation with DiT-based PixArt-alpha and PixArt-sigma. Thequality of ILF's 1.7x-1.8x speedups are confirmed by FID, CLIP score, CLIPImage Quality Assessment, ImageReward, and qualitative comparisons.</description><author>Matthew Gwilliam, Han Cai, Di Wu, Abhinav Shrivastava, Zhiyu Cheng</author><pubDate>Wed, 22 Jan 2025 18:59:58 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.13107v1</guid></item><item><title>VideoLLaMA 3: Frontier Multimodal Foundation Models for Image and Video Understanding</title><link>http://arxiv.org/abs/2501.13106v1</link><description>In this paper, we propose VideoLLaMA3, a more advanced multimodal foundationmodel for image and video understanding. The core design philosophy ofVideoLLaMA3 is vision-centric. The meaning of "vision-centric" is two-fold: thevision-centric training paradigm and vision-centric framework design. The keyinsight of our vision-centric training paradigm is that high-quality image-textdata is crucial for both image and video understanding. Instead of preparingmassive video-text datasets, we focus on constructing large-scale andhigh-quality image-text datasets. VideoLLaMA3 has four training stages: 1)vision-centric alignment stage, which warms up the vision encoder andprojector; 2) vision-language pretraining stage, which jointly tunes the visionencoder, projector, and LLM with large-scale image-text data covering multipletypes (including scene images, documents, charts) as well as text-only data. 3)multi-task fine-tuning stage, which incorporates image-text SFT data fordownstream tasks and video-text data to establish a foundation for videounderstanding. 4) video-centric fine-tuning, which further improves the model'scapability in video understanding. As for the framework design, to bettercapture fine-grained details in images, the pretrained vision encoder isadapted to encode images of varying sizes into vision tokens with correspondingnumbers, rather than a fixed number of tokens. For video inputs, we reduce thenumber of vision tokens according to their similarity so that therepresentation of videos will be more precise and compact. Benefit fromvision-centric designs, VideoLLaMA3 achieves compelling performances in bothimage and video understanding benchmarks.</description><author>Boqiang Zhang, Kehan Li, Zesen Cheng, Zhiqiang Hu, Yuqian Yuan, Guanzheng Chen, Sicong Leng, Yuming Jiang, Hang Zhang, Xin Li, Peng Jin, Wenqi Zhang, Fan Wang, Lidong Bing, Deli Zhao</author><pubDate>Wed, 22 Jan 2025 18:59:46 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.13106v1</guid></item><item><title>Neural Radiance Fields for the Real World: A Survey</title><link>http://arxiv.org/abs/2501.13104v1</link><description>Neural Radiance Fields (NeRFs) have remodeled 3D scene representation sincerelease. NeRFs can effectively reconstruct complex 3D scenes from 2D images,advancing different fields and applications such as scene understanding, 3Dcontent generation, and robotics. Despite significant research progress, athorough review of recent innovations, applications, and challenges is lacking.This survey compiles key theoretical advancements and alternativerepresentations and investigates emerging challenges. It further exploresapplications on reconstruction, highlights NeRFs' impact on computer vision androbotics, and reviews essential datasets and toolkits. By identifying gaps inthe literature, this survey discusses open challenges and offers directions forfuture research.</description><author>Wenhui Xiao, Remi Chierchia, Rodrigo Santa Cruz, Xuesong Li, David Ahmedt-Aristizabal, Olivier Salvado, Clinton Fookes, Leo Lebrat</author><pubDate>Wed, 22 Jan 2025 18:59:10 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.13104v1</guid></item><item><title>A Rate-Distortion Framework for Summarization</title><link>http://arxiv.org/abs/2501.13100v1</link><description>This paper introduces an information-theoretic framework for textsummarization. We define the summarizer rate-distortion function and show thatit provides a fundamental lower bound on summarizer performance. We describe aniterative procedure, similar to Blahut-Arimoto algorithm, for computing thisfunction. To handle real-world text datasets, we also propose a practicalmethod that can calculate the summarizer rate-distortion function with limiteddata. Finally, we empirically confirm our theoretical results by comparing thesummarizer rate-distortion function with the performances of differentsummarizers used in practice.</description><author>Enes Arda, Aylin Yener</author><pubDate>Wed, 22 Jan 2025 18:57:14 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.13100v1</guid></item><item><title>Robust Representation Consistency Model via Contrastive Denoising</title><link>http://arxiv.org/abs/2501.13094v1</link><description>Robustness is essential for deep neural networks, especially insecurity-sensitive applications. To this end, randomized smoothing providestheoretical guarantees for certifying robustness against adversarialperturbations. Recently, diffusion models have been successfully employed forrandomized smoothing to purify noise-perturbed samples before makingpredictions with a standard classifier. While these methods excel at smallperturbation radii, they struggle with larger perturbations and incur asignificant computational overhead during inference compared to classicalmethods. To address this, we reformulate the generative modeling task along thediffusion trajectories in pixel space as a discriminative task in the latentspace. Specifically, we use instance discrimination to achieve consistentrepresentations along the trajectories by aligning temporally adjacent points.After fine-tuning based on the learned representations, our model enablesimplicit denoising-then-classification via a single prediction, substantiallyreducing inference costs. We conduct extensive experiments on various datasetsand achieve state-of-the-art performance with minimal computation budget duringinference. For example, our method outperforms the certified accuracy ofdiffusion-based methods on ImageNet across all perturbation radii by 5.3% onaverage, with up to 11.6% at larger radii, while reducing inference costs by85$\times$ on average. Codes are available at:https://github.com/jiachenlei/rRCM.</description><author>Jiachen Lei, Julius Berner, Jiongxiao Wang, Zhongzhu Chen, Zhongjia Ba, Kui Ren, Jun Zhu, Anima Anandkumar</author><pubDate>Wed, 22 Jan 2025 18:52:06 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.13094v1</guid></item><item><title>Guaranteed Recovery of Unambiguous Clusters</title><link>http://arxiv.org/abs/2501.13093v1</link><description>Clustering is often a challenging problem because of the inherent ambiguityin what the "correct" clustering should be. Even when the number of clusters$K$ is known, this ambiguity often still exists, particularly when there isvariation in density among different clusters, and clusters have multiplerelatively separated regions of high density. In this paper we propose aninformation-theoretic characterization of when a $K$-clustering is ambiguous,and design an algorithm that recovers the clustering whenever it isunambiguous. This characterization formalizes the situation when two highdensity regions within a cluster are separable enough that they look more liketwo distinct clusters than two truly distinct clusters in the clustering. Thealgorithm first identifies $K$ partial clusters (or "seeds") using adensity-based approach, and then adds unclustered points to the initial $K$partial clusters in a greedy manner to form a complete clustering. We implementand test a version of the algorithm that is modified to effectively handleoverlapping clusters, and observe that it requires little parameter selectionand displays improved performance on many datasets compared to widely usedalgorithms for non-convex cluster recovery.</description><author>Kayvon Mazooji, Ilan Shomorony</author><pubDate>Wed, 22 Jan 2025 18:51:25 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.13093v1</guid></item><item><title>Orchid: Image Latent Diffusion for Joint Appearance and Geometry Generation</title><link>http://arxiv.org/abs/2501.13087v1</link><description>Diffusion models are state-of-the-art for image generation. Trained on largedatasets, they capture expressive image priors that have been used for taskslike inpainting, depth, and (surface) normal prediction. However, these modelsare typically trained for one specific task, e.g., a separate model for each ofcolor, depth, and normal prediction. Such models do not leverage the intrinsiccorrelation between appearance and geometry, often leading to inconsistentpredictions. In this paper, we propose using a novel image diffusion prior that jointlyencodes appearance and geometry. We introduce a diffusion model Orchid,comprising a Variational Autoencoder (VAE) to encode color, depth, and surfacenormals to a latent space, and a Latent Diffusion Model (LDM) for generatingthese joint latents. Orchid directly generates photo-realistic color images,relative depth, and surface normals from user-provided text, and can be used tocreate image-aligned partial 3D scenes seamlessly. It can also performimage-conditioned tasks like joint monocular depth and normal prediction and iscompetitive in accuracy to state-of-the-art methods designed for those tasksalone. Lastly, our model learns a joint prior that can be used zero-shot as aregularizer for many inverse problems that entangle appearance and geometry.For example, we demonstrate its effectiveness in color-depth-normal inpainting,showcasing its applicability to problems in 3D generation from sparse views.</description><author>Akshay Krishnan, Xinchen Yan, Vincent Casser, Abhijit Kundu</author><pubDate>Wed, 22 Jan 2025 18:46:47 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.13087v1</guid></item><item><title>Attention-Driven Hierarchical Reinforcement Learning with Particle Filtering for Source Localization in Dynamic Fields</title><link>http://arxiv.org/abs/2501.13084v1</link><description>In many real-world scenarios, such as gas leak detection or environmentalpollutant tracking, solving the Inverse Source Localization andCharacterization problem involves navigating complex, dynamic fields withsparse and noisy observations. Traditional methods face significant challenges,including partial observability, temporal and spatial dynamics,out-of-distribution generalization, and reward sparsity. To address theseissues, we propose a hierarchical framework that integrates Bayesian inferenceand reinforcement learning. The framework leverages an attention-enhancedparticle filtering mechanism for efficient and accurate belief updates, andincorporates two complementary execution strategies: Attention ParticleFiltering Planning and Attention Particle Filtering Reinforcement Learning.These approaches optimize exploration and adaptation under uncertainty.Theoretical analysis proves the convergence of the attention-enhanced particlefilter, while extensive experiments across diverse scenarios validate theframework's superior accuracy, adaptability, and computational efficiency. Ourresults highlight the framework's potential for broad applications in dynamicfield estimation tasks.</description><author>Yiwei Shi, Mengyue Yang, Qi Zhang, Weinan Zhang, Cunjia Liu, Weiru Liu</author><pubDate>Wed, 22 Jan 2025 18:45:29 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.13084v1</guid></item><item><title>Boosting MCTS with Free Energy Minimization</title><link>http://arxiv.org/abs/2501.13083v1</link><description>Active Inference, grounded in the Free Energy Principle, provides a powerfullens for understanding how agents balance exploration and goal-directedbehavior in uncertain environments. Here, we propose a new planning framework,that integrates Monte Carlo Tree Search (MCTS) with active inference objectivesto systematically reduce epistemic uncertainty while pursuing extrinsicrewards. Our key insight is that MCTS already renowned for its searchefficiency can be naturally extended to incorporate free energy minimization byblending expected rewards with information gain. Concretely, the Cross-EntropyMethod (CEM) is used to optimize action proposals at the root node, while treeexpansions leverage reward modeling alongside intrinsic exploration bonuses.This synergy allows our planner to maintain coherent estimates of value anduncertainty throughout planning, without sacrificing computationaltractability. Empirically, we benchmark our planner on a diverse set ofcontinuous control tasks, where it demonstrates performance gains over bothstandalone CEM and MCTS with random rollouts.</description><author>Mawaba Pascal Dao, Adrian Peter</author><pubDate>Wed, 22 Jan 2025 18:45:15 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.13083v1</guid></item><item><title>Refining Input Guardrails: Enhancing LLM-as-a-Judge Efficiency Through Chain-of-Thought Fine-Tuning and Alignment</title><link>http://arxiv.org/abs/2501.13080v1</link><description>Large Language Models (LLMs) have demonstrated powerful capabilities thatrender them valuable in different applications, including conversational AIproducts. It is paramount to ensure the security and reliability of theseproducts by mitigating their vulnerabilities towards malicious userinteractions, which can lead to the exposure of great risks and reputationalrepercussions. In this work, we present a comprehensive study on the efficacyof fine-tuning and aligning Chain-of-Thought (CoT) responses of different LLMsthat serve as input moderation guardrails. We systematically explore varioustuning methods by leveraging a small set of training data to adapt these modelsas proxy defense mechanisms to detect malicious inputs and provide a reasoningfor their verdicts, thereby preventing the exploitation of conversationalagents. We rigorously evaluate the efficacy and robustness of different tuningstrategies to generalize across diverse adversarial and malicious query types.Our experimental results outline the potential of alignment processes tailoredto a varied range of harmful input queries, even with constrained dataresources. These techniques significantly enhance the safety of conversationalAI systems and provide a feasible framework for deploying more secure andtrustworthy AI-driven interactions.</description><author>Melissa Kazemi Rad, Huy Nghiem, Andy Luo, Sahil Wadhwa, Mohammad Sorower, Stephen Rawls</author><pubDate>Wed, 22 Jan 2025 18:40:57 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.13080v1</guid></item><item><title>Evolution and The Knightian Blindspot of Machine Learning</title><link>http://arxiv.org/abs/2501.13075v1</link><description>This paper claims that machine learning (ML) largely overlooks an importantfacet of general intelligence: robustness to a qualitatively unknown future inan open world. Such robustness relates to Knightian uncertainty (KU) ineconomics, i.e. uncertainty that cannot be quantified, which is excluded fromconsideration in ML's key formalisms. This paper aims to identify this blindspot, argue its importance, and catalyze research into addressing it, which webelieve is necessary to create truly robust open-world AI. To help illuminatethe blind spot, we contrast one area of ML, reinforcement learning (RL), withthe process of biological evolution. Despite staggering ongoing progress, RLstill struggles in open-world situations, often failing under unforeseensituations. For example, the idea of zero-shot transferring a self-driving carpolicy trained only in the US to the UK currently seems exceedingly ambitious.In dramatic contrast, biological evolution routinely produces agents thatthrive within an open world, sometimes even to situations that are remarkablyout-of-distribution (e.g. invasive species; or humans, who do undertake suchzero-shot international driving). Interestingly, evolution achieves suchrobustness without explicit theory, formalisms, or mathematical gradients. Weexplore the assumptions underlying RL's typical formalisms, showing how theylimit RL's engagement with the unknown unknowns characteristic of anever-changing complex world. Further, we identify mechanisms through whichevolutionary processes foster robustness to novel and unpredictable challenges,and discuss potential pathways to algorithmically embody them. The conclusionis that the intriguing remaining fragility of ML may result from blind spots inits formalisms, and that significant gains may result from direct confrontationwith the challenge of KU.</description><author>Joel Lehman, Elliot Meyerson, Tarek El-Gaaly, Kenneth O. Stanley, Tarin Ziyaee</author><pubDate>Wed, 22 Jan 2025 18:38:41 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.13075v1</guid></item><item><title>Autonomy-of-Experts Models</title><link>http://arxiv.org/abs/2501.13074v1</link><description>Mixture-of-Experts (MoE) models mostly use a router to assign tokens tospecific expert modules, activating only partial parameters and oftenoutperforming dense models. We argue that the separation between the router'sdecision-making and the experts' execution is a critical yet overlooked issue,leading to suboptimal expert selection and ineffective learning. To addressthis, we propose Autonomy-of-Experts (AoE), a novel MoE paradigm in whichexperts autonomously select themselves to process inputs. AoE is based on theinsight that an expert is aware of its own capacity to effectively process atoken, an awareness reflected in the scale of its internal activations. In AoE,routers are removed; instead, experts pre-compute internal activations forinputs and are ranked based on their activation norms. Only the top-rankingexperts proceed with the forward pass, while the others abort. The overhead ofpre-computing activations is reduced through a low-rank weight factorization.This self-evaluating-then-partner-comparing approach ensures improved expertselection and effective learning. We pre-train language models having 700M upto 4B parameters, demonstrating that AoE outperforms traditional MoE modelswith comparable efficiency.</description><author>Ang Lv, Ruobing Xie, Yining Qian, Songhao Wu, Xingwu Sun, Zhanhui Kang, Di Wang, Rui Yan</author><pubDate>Wed, 22 Jan 2025 18:37:08 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.13074v1</guid></item><item><title>CHaRNet: Conditioned Heatmap Regression for Robust Dental Landmark Localization</title><link>http://arxiv.org/abs/2501.13073v1</link><description>Identifying anatomical landmarks in 3D dental models is crucial fororthodontic treatment. Manually placing these key points is complex,time-consuming, and requires expert knowledge. While some machine learningmethods have been proposed for automatic tooth landmark detection in 3DIntraoral Scans (IOS), research remains limited, with no fully end-to-endapproaches that avoid teeth segmentation. We propose CHaRNet (Conditioned Heatmap Regression Network), the firstend-to-end deep learning method for tooth landmark detection in 3D IOS. Unliketraditional two-stage methods that segment teeth before detecting landmarks,CHaRNet directly detects landmarks on the input point cloud. It consists offour key modules: (1) a point cloud encoder, (2) a point cloud decoder with aheatmap regression head, (3) a teeth presence classification head, and (4) theinnovative Conditioned Heatmap Regression (CHaR) module. The CHaR modulerefines landmark regression by leveraging teeth presence classification,enabling dynamic adaptation to cases with missing teeth and improving accuracyin complex dental models. We evaluate CHaRNet using five point cloud learning algorithms to validatethe effectiveness of the CHaR module and test it on a clinical dataset of$1,214$ annotated 3D dental models. Both the dataset and code will be publiclyreleased to address the lack of open datasets in orthodontics, promotebenchmarking, and inspire new research. CHaRNet achieves a Mean Euclidean Distance Error (MEDE) of 1.28 mm and a MeanSuccess Ratio (MSR) of 82.40\%, demonstrating robust performance. Notably, itexcels in handling irregular dental geometries, such as models with missingteeth. This end-to-end approach streamlines orthodontic workflows, improves 3DIOS analysis precision, and facilitates efficient computer-assisted treatmentplanning.</description><author>José Rodríguez-Ortega, Siham Tabik</author><pubDate>Wed, 22 Jan 2025 18:35:57 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.13073v1</guid></item><item><title>AdaWM: Adaptive World Model based Planning for Autonomous Driving</title><link>http://arxiv.org/abs/2501.13072v1</link><description>World model based reinforcement learning (RL) has emerged as a promisingapproach for autonomous driving, which learns a latent dynamics model and usesit to train a planning policy. To speed up the learning process, thepretrain-finetune paradigm is often used, where online RL is initialized by apretrained model and a policy learned offline. However, naively performing suchinitialization in RL may result in dramatic performance degradation during theonline interactions in the new task. To tackle this challenge, we first analyzethe performance degradation and identify two primary root causes therein: themismatch of the planning policy and the mismatch of the dynamics model, due todistribution shift. We further analyze the effects of these factors onperformance degradation during finetuning, and our findings reveal that thechoice of finetuning strategies plays a pivotal role in mitigating theseeffects. We then introduce AdaWM, an Adaptive World Model based planningmethod, featuring two key steps: (a) mismatch identification, which quantifiesthe mismatches and informs the finetuning strategy, and (b) alignment-drivenfinetuning, which selectively updates either the policy or the model as neededusing efficient low-rank updates. Extensive experiments on the challengingCARLA driving tasks demonstrate that AdaWM significantly improves thefinetuning process, resulting in more robust and efficient performance inautonomous driving systems.</description><author>Hang Wang, Xin Ye, Feng Tao, Abhirup Mallik, Burhaneddin Yaman, Liu Ren, Junshan Zhang</author><pubDate>Wed, 22 Jan 2025 18:34:51 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.13072v1</guid></item><item><title>Towards impactful challenges: post-challenge paper, benchmarks and other dissemination actions</title><link>http://arxiv.org/abs/2312.06036v4</link><description>The conclusion of an AI challenge is not the end of its lifecycle; ensuring along-lasting impact requires meticulous post-challenge activities. Thelong-lasting impact also needs to be organised. This chapter covers the variousactivities after the challenge is formally finished. This work identifiestarget audiences for post-challenge initiatives and outlines methods forcollecting and organizing challenge outputs. The multiple outputs of thechallenge are listed, along with the means to collect them. The central part ofthe chapter is a template for a typical post-challenge paper, includingpossible graphs and advice on how to turn the challenge into a long-lastingbenchmark.</description><author>Antoine Marot, David Rousseau, Zhen, Xu</author><pubDate>Wed, 22 Jan 2025 18:33:39 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.06036v4</guid></item><item><title>Robust Body Composition Analysis by Generating 3D CT Volumes from Limited 2D Slices</title><link>http://arxiv.org/abs/2501.13071v1</link><description>Body composition analysis provides valuable insights into aging, diseaseprogression, and overall health conditions. Due to concerns of radiationexposure, two-dimensional (2D) single-slice computed tomography (CT) imaginghas been used repeatedly for body composition analysis. However, this approachintroduces significant spatial variability that can impact the accuracy androbustness of the analysis. To mitigate this issue and facilitate bodycomposition analysis, this paper presents a novel method to generate 3D CTvolumes from limited number of 2D slices using a latent diffusion model (LDM).Our approach first maps 2D slices into a latent representation space using avariational autoencoder. An LDM is then trained to capture the 3D context of astack of these latent representations. To accurately interpolateintermediateslices and construct a full 3D volume, we utilize body partregression to determine the spatial location and distance between the acquiredslices. Experiments on both in-house and public 3D abdominal CT datasetsdemonstrate that the proposed method significantly enhances body compositionanalysis compared to traditional 2D-based analysis, with a reduced error ratefrom 23.3% to 15.2%.</description><author>Lianrui Zuo, Xin Yu, Dingjie Su, Kaiwen Xu, Aravind R. Krishnan, Yihao Liu, Shunxing Bao, Fabien Maldonado, Luigi Ferrucci, Bennett A. Landman</author><pubDate>Wed, 22 Jan 2025 18:32:23 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.13071v1</guid></item><item><title>Beyond the Lungs: Extending the Field of View in Chest CT with Latent Diffusion Models</title><link>http://arxiv.org/abs/2501.13068v1</link><description>The interconnection between the human lungs and other organs, such as theliver and kidneys, is crucial for understanding the underlying risks andeffects of lung diseases and improving patient care. However, most researchchest CT imaging is focused solely on the lungs due to considerations of costand radiation dose. This restricted field of view (FOV) in the acquired imagesposes challenges to comprehensive analysis and hinders the ability to gaininsights into the impact of lung diseases on other organs. To address this, wepropose SCOPE (Spatial Coverage Optimization with Prior Encoding), a novelapproach to capture the inter-organ relationships from CT images and extend theFOV of chest CT images. Our approach first trains a variational autoencoder(VAE) to encode 2D axial CT slices individually, then stacks the latentrepresentations of the VAE to form a 3D context for training a latent diffusionmodel. Once trained, our approach extends the FOV of CT images in thez-direction by generating new axial slices in a zero-shot manner. We evaluatedour approach on the National Lung Screening Trial (NLST) dataset, and resultssuggest that it effectively extends the FOV to include the liver and kidneys,which are not completely covered in the original NLST data acquisition.Quantitative results on a held-out whole-body dataset demonstrate that thegenerated slices exhibit high fidelity with acquired data, achieving an SSIM of0.81.</description><author>Lianrui Zuo, Kaiwen Xu, Dingjie Su, Xin Yu, Aravind R. Krishnan, Yihao Liu, Shunxing Bao, Thomas Li, Kim L. Sandler, Fabien Maldonado, Bennett A. Landman</author><pubDate>Wed, 22 Jan 2025 18:28:18 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.13068v1</guid></item><item><title>Cross-D Conv: Cross-Dimensional Transferable Knowledge Base via Fourier Shifting Operation</title><link>http://arxiv.org/abs/2411.02441v3</link><description>In biomedical imaging analysis, the dichotomy between 2D and 3D data presentsa significant challenge. While 3D volumes offer superior real-worldapplicability, they are less available for each modality and not easy to trainin large scale, whereas 2D samples are abundant but less comprehensive. Thispaper introduces \texttt{Cross-D Conv} operation, a novel approach that bridgesthe dimensional gap by learning the phase shifting in the Fourier domain. Ourmethod enables seamless weight transfer between 2D and 3D convolutionoperations, effectively facilitating cross-dimensional learning. The proposedarchitecture leverages the abundance of 2D training data to enhance 3D modelperformance, offering a practical solution to the multimodal data scarcitychallenge in 3D medical model pretraining. Experimental validation on theRadImagenet (2D) and multimodal volumetric sets demonstrates that our approachachieves comparable or superior performance in feature quality assessment. Theenhanced convolution operation presents new opportunities for developingefficient classification and segmentation models in medical imaging. This workrepresents an advancement in cross-dimensional and multimodal medical imageanalysis, offering a robust framework for utilizing 2D priors in 3D modelpretraining while maintaining computational efficiency of 2D training.</description><author>Mehmet Can Yavuz, Yang Yang</author><pubDate>Wed, 22 Jan 2025 18:23:26 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2411.02441v3</guid></item><item><title>SMART-Vision: Survey of Modern Action Recognition Techniques in Vision</title><link>http://arxiv.org/abs/2501.13066v1</link><description>Human Action Recognition (HAR) is a challenging domain in computer vision,involving recognizing complex patterns by analyzing the spatiotemporal dynamicsof individuals' movements in videos. These patterns arise in sequential data,such as video frames, which are often essential to accurately distinguishactions that would be ambiguous in a single image. HAR has garneredconsiderable interest due to its broad applicability, ranging from robotics andsurveillance systems to sports motion analysis, healthcare, and the burgeoningfield of autonomous vehicles. While several taxonomies have been proposed tocategorize HAR approaches in surveys, they often overlook hybrid methodologiesand fail to demonstrate how different models incorporate various architecturesand modalities. In this comprehensive survey, we present the novel SMART-Visiontaxonomy, which illustrates how innovations in deep learning for HAR complementone another, leading to hybrid approaches beyond traditional categories. Oursurvey provides a clear roadmap from foundational HAR works to currentstate-of-the-art systems, highlighting emerging research directions andaddressing unresolved challenges in discussion sections for architectureswithin the HAR domain. We provide details of the research datasets that variousapproaches used to measure and compare goodness HAR approaches. We also explorethe rapidly emerging field of Open-HAR systems, which challenges HAR systems bypresenting samples from unknown, novel classes during test time.</description><author>Ali K. AlShami, Ryan Rabinowitz, Khang Lam, Yousra Shleibik, Melkamu Mersha, Terrance Boult, Jugal Kalita</author><pubDate>Wed, 22 Jan 2025 18:21:55 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.13066v1</guid></item><item><title>An Efficient Framework for Crediting Data Contributors of Diffusion Models</title><link>http://arxiv.org/abs/2407.03153v2</link><description>As diffusion models are deployed in real-world settings, and theirperformance is driven by training data, appraising the contribution of datacontributors is crucial to creating incentives for sharing quality data and toimplementing policies for data compensation. Depending on the use case, modelperformance corresponds to various global properties of the distributionlearned by a diffusion model (e.g., overall aesthetic quality). Hence, here weaddress the problem of attributing global properties of diffusion models todata contributors. The Shapley value provides a principled approach tovaluation by uniquely satisfying game-theoretic axioms of fairness. However,estimating Shapley values for diffusion models is computationally impracticalbecause it requires retraining on many training data subsets corresponding todifferent contributors and rerunning inference. We introduce a method toefficiently retrain and rerun inference for Shapley value estimation, byleveraging model pruning and fine-tuning. We evaluate the utility of our methodwith three use cases: (i) image quality for a DDPM trained on a CIFAR dataset,(ii) demographic diversity for an LDM trained on CelebA-HQ, and (iii) aestheticquality for a Stable Diffusion model LoRA-finetuned on Post-Impressionistartworks. Our results empirically demonstrate that our framework can identifyimportant data contributors across models' global properties, outperformingexisting attribution methods for diffusion models.</description><author>Chris Lin, Mingyu Lu, Chanwoo Kim, Su-In Lee</author><pubDate>Wed, 22 Jan 2025 18:21:13 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.03153v2</guid></item><item><title>Developing Cryptocurrency Trading Strategy Based on Autoencoder-CNN-GANs Algorithms</title><link>http://arxiv.org/abs/2412.18202v3</link><description>This paper leverages machine learning algorithms to forecast and analyzefinancial time series. The process begins with a denoising autoencoder tofilter out random noise fluctuations from the main contract price data. Then,one-dimensional convolution reduces the dimensionality of the filtered data andextracts key information. The filtered and dimensionality-reduced price data isfed into a GANs network, and its output serve as input of a fully connectednetwork. Through cross-validation, a model is trained to capture features thatprecede large price fluctuations. The model predicts the likelihood anddirection of significant price changes in real-time price sequences, placingtrades at moments of high prediction accuracy. Empirical results demonstratethat using autoencoders and convolution to filter and denoise financial data,combined with GANs, achieves a certain level of predictive performance,validating the capabilities of machine learning algorithms to discoverunderlying patterns in financial sequences. Keywords - CNN;GANs;Cryptocurrency; Prediction.</description><author>Zhuohuan Hu, Richard Yu, Zizhou Zhang, Haoran Zheng, Qianying Liu, Yining Zhou</author><pubDate>Wed, 22 Jan 2025 18:21:07 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.18202v3</guid></item><item><title>Introducing Perturb-ability Score (PS) to Enhance Robustness Against Problem-Space Evasion Adversarial Attacks on Flow-based ML-NIDS</title><link>http://arxiv.org/abs/2409.07448v3</link><description>As network security threats continue to evolve, safeguarding Machine Learning(ML)-based Network Intrusion Detection Systems (NIDS) from adversarial attacksis crucial. This paper introduces the notion of feature perturb-ability andpresents a novel Perturb-ability Score (PS) metric that identifies NIDSfeatures susceptible to manipulation in the problem-space by an attacker. Byquantifying a feature's susceptibility to perturbations within theproblem-space, the PS facilitates the selection of features that are inherentlymore robust against evasion adversarial attacks on ML-NIDS during the featureselection phase. These features exhibit natural resilience to perturbations, asthey are heavily constrained by the problem-space limitations and correlationsof the NIDS domain. Furthermore, manipulating these features may either disruptthe malicious function of evasion adversarial attacks on NIDS or render thenetwork traffic invalid for processing (or both). This proposed novel approachemploys a fresh angle by leveraging network domain constraints as a defensemechanism against problem-space evasion adversarial attacks targeting ML-NIDS.We demonstrate the effectiveness of our PS-guided feature selection defense inenhancing NIDS robustness. Experimental results across various ML-based NIDSmodels and public datasets show that selecting only robust features (low-PSfeatures) can maintain solid detection performance while significantly reducingvulnerability to evasion adversarial attacks. Additionally, our findings verifythat the PS effectively identifies NIDS features highly vulnerable toproblem-space perturbations.</description><author>Mohamed elShehaby, Ashraf Matrawy</author><pubDate>Wed, 22 Jan 2025 18:10:50 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2409.07448v3</guid></item><item><title>A polynomial formula for the perspective four points problem</title><link>http://arxiv.org/abs/2501.13058v1</link><description>We present a fast and accurate solution to the perspective n-points problem,by way of a new approach to the n=4 case. Our solution hinges on a novelseparation of variables: given four 3D points and four corresponding 2D pointson the camera canvas, we start by finding another set of 3D points, sitting onthe rays connecting the camera to the 2D canvas points, so that the sixpair-wise distances between these 3D points are as close as possible to the sixdistances between the original 3D points. This step reduces the perspectiveproblem to an absolute orientation problem (which has a solution via explicitformula). To solve the first problem we set coordinates which are asorientation-free as possible: on the 3D points side our coordinates are thesquared distances between the points. On the 2D canvas-points side ourcoordinates are the dot products of the points after rotating one of them tosit on the optical axis. We then derive the solution with the help of acomputer algebra system.</description><author>David Lehavi, Brian Osserman</author><pubDate>Wed, 22 Jan 2025 18:10:20 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.13058v1</guid></item><item><title>STMDNet: A Lightweight Directional Framework for Motion Pattern Recognition of Tiny Targets</title><link>http://arxiv.org/abs/2501.13054v1</link><description>Recognizing motions of tiny targets - only few dozen pixels - in clutteredbackgrounds remains a fundamental challenge when standard feature-based or deeplearning methods fail under scarce visual cues. We propose STMDNet, amodel-based computational framework to Recognize motions of tiny targets atvariable velocities under low-sampling frequency scenarios. STMDNet designs anovel dual-dynamics-and-correlation mechanism, harnessing ipsilateralexcitation to integrate target cues and leakage-enhancing-type contralateralinhibition to suppress large-object and background motion interference.Moreover, we develop the first collaborative directional encoding-decodingstrategy that determines the motion direction from only one correlation perspatial location, cutting computational costs to one-eighth of prior methods.Further, simply substituting the backbone of a strong STMD model with STMDNetraises AUC by 24%, yielding an enhanced STMDNet-F. Evaluations on real-worldlow sampling frequency datasets show state-of-the-art results, surpassing thedeep learning baseline. Across diverse speeds, STMDNet-F improves mF1 by 19%,16%, and 8% at 240Hz, 120Hz, and 60Hz, respectively, while STMDNet achieves 87FPS on a single CPU thread. These advances highlight STMDNet as anext-generation backbone for tiny target motion pattern recognition andunderscore its broader potential to revitalize model-based visual approaches inmotion detection.</description><author>Mingshuo Xu, Hao Luan, Zhou Daniel Hao, Jigen Peng, Shigang Yue</author><pubDate>Wed, 22 Jan 2025 18:06:00 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.13054v1</guid></item><item><title>One-Class Domain Adaptation via Meta-Learning</title><link>http://arxiv.org/abs/2501.13052v1</link><description>The deployment of IoT (Internet of Things) sensor-based machine learningmodels in industrial systems for anomaly classification tasks poses significantchallenges due to distribution shifts, as the training data acquired incontrolled laboratory settings may significantly differ from real-time data inproduction environments. Furthermore, many real-world applications cannotprovide a substantial number of labeled examples for each anomalous class inevery new environment. It is therefore crucial to develop adaptable machinelearning models that can be effectively transferred from one environment toanother, enabling rapid adaptation using normal operational data. We extendedthis problem setting to an arbitrary classification task and formulated theone-class domain adaptation (OC-DA) problem setting. We took a meta-learningapproach to tackle the challenge of OC-DA, and proposed a task samplingstrategy to adapt any bi-level meta-learning algorithm to OC-DA. We modifiedthe well-established model-agnostic meta-learning (MAML) algorithm andintroduced the OC-DA MAML algorithm. We provided a theoretical analysis showingthat OC-DA MAML optimizes for meta-parameters that enable rapid one-classadaptation across domains. The OC-DA MAML algorithm is evaluated on theRainbow-MNIST meta-learning benchmark and on a real-world dataset ofvibration-based sensor readings. The results show that OC-DA MAML significantlyimproves the performance on the target domains and outperforms MAML using thestandard task sampling strategy.</description><author>Stephanie Holly, Thomas Bierweiler, Stefan von Dosky, Ahmed Frikha, Clemens Heitzinger, Jana Eder</author><pubDate>Wed, 22 Jan 2025 18:01:24 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.13052v1</guid></item><item><title>Sketch and Patch: Efficient 3D Gaussian Representation for Man-Made Scenes</title><link>http://arxiv.org/abs/2501.13045v1</link><description>3D Gaussian Splatting (3DGS) has emerged as a promising representation forphotorealistic rendering of 3D scenes. However, its high storage requirementspose significant challenges for practical applications. We observe thatGaussians exhibit distinct roles and characteristics that are analogous totraditional artistic techniques -- Like how artists first sketch outlinesbefore filling in broader areas with color, some Gaussians capturehigh-frequency features like edges and contours; While other Gaussiansrepresent broader, smoother regions, that are analogous to broader brushstrokes that add volume and depth to a painting. Based on this observation, wepropose a novel hybrid representation that categorizes Gaussians into (i)Sketch Gaussians, which define scene boundaries, and (ii) Patch Gaussians,which cover smooth regions. Sketch Gaussians are efficiently encoded usingparametric models, leveraging their geometric coherence, while Patch Gaussiansundergo optimized pruning, retraining, and vector quantization to maintainvolumetric consistency and storage efficiency. Our comprehensive evaluationacross diverse indoor and outdoor scenes demonstrates that this structure-awareapproach achieves up to 32.62% improvement in PSNR, 19.12% in SSIM, and 45.41%in LPIPS at equivalent model sizes, and correspondingly, for an indoor scene,our model maintains the visual quality with 2.3% of the original model size.</description><author>Yuang Shi, Simone Gasparini, Géraldine Morin, Chenggang Yang, Wei Tsang Ooi</author><pubDate>Wed, 22 Jan 2025 17:52:45 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.13045v1</guid></item><item><title>Reasoning Language Models: A Blueprint</title><link>http://arxiv.org/abs/2501.11223v2</link><description>Reasoning language models (RLMs), also known as Large Reasoning Models(LRMs), such as OpenAI's o1 and o3, DeepSeek-V3, and Alibaba's QwQ, haveredefined AI's problem-solving capabilities by extending LLMs with advancedreasoning mechanisms. Yet, their high costs, proprietary nature, and complexarchitectures - uniquely combining Reinforcement Learning (RL), searchheuristics, and LLMs - present accessibility and scalability challenges. Toaddress these, we propose a comprehensive blueprint that organizes RLMcomponents into a modular framework, based on a survey and analysis of all RLMworks. This blueprint incorporates diverse reasoning structures (chains, trees,graphs, and nested forms), reasoning strategies (e.g., Monte Carlo Tree Search,Beam Search), RL concepts (policy, value models and others), supervisionschemes (Outcome-Based and Process-Based Supervision), and other relatedconcepts (e.g., Test-Time Compute, Retrieval-Augmented Generation, agenttools). We provide detailed mathematical formulations and algorithmicspecifications to simplify RLM implementation. By showing how schemes likeLLaMA-Berry, QwQ, Journey Learning, and Graph of Thoughts fit as special cases,we demonstrate the blueprint's versatility and unifying potential. Toillustrate its utility, we introduce x1, a modular implementation for rapid RLMprototyping and experimentation. Using x1 and a literature review, we providekey insights, such as multi-phase training for policy and value models, and theimportance of familiar training distributions. Finally, we discuss scalable RLMcloud deployments and we outline how RLMs can integrate with a broader LLMecosystem. Our work demystifies RLM construction, democratizes advancedreasoning capabilities, and fosters innovation, aiming to mitigate the gapbetween "rich AI" and "poor AI" by lowering barriers to RLM development andexperimentation.</description><author>Maciej Besta, Julia Barth, Eric Schreiber, Ales Kubicek, Afonso Catarino, Robert Gerstenberger, Piotr Nyczyk, Patrick Iff, Yueling Li, Sam Houliston, Tomasz Sternal, Marcin Copik, Grzegorz Kwaśniewski, Jürgen Müller, Łukasz Flis, Hannes Eberhard, Hubert Niewiadomski, Torsten Hoefler</author><pubDate>Wed, 22 Jan 2025 17:49:37 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.11223v2</guid></item><item><title>Does Table Source Matter? Benchmarking and Improving Multimodal Scientific Table Understanding and Reasoning</title><link>http://arxiv.org/abs/2501.13042v1</link><description>Recent large language models (LLMs) have advanced table understandingcapabilities but rely on converting tables into text sequences. Whilemultimodal large language models (MLLMs) enable direct visual processing, theyface limitations in handling scientific tables due to fixed input imageresolutions and insufficient numerical reasoning capabilities. We present acomprehensive framework for multimodal scientific table understanding andreasoning with dynamic input image resolutions. Our framework consists of threekey components: (1) MMSci-Pre, a domain-specific table structure learningdataset of 52K scientific table structure recognition samples, (2) MMSci-Ins,an instruction tuning dataset with 12K samples across three table-based tasks,and (3) MMSci-Eval, a benchmark with 3,114 testing samples specificallydesigned to evaluate numerical reasoning capabilities. Extensive experimentsdemonstrate that our domain-specific approach with 52K scientific table imagesachieves superior performance compared to 150K general-domain tables,highlighting the importance of data quality over quantity. Our proposedtable-based MLLMs with dynamic input resolutions show significant improvementsin both general table understanding and numerical reasoning capabilities, withstrong generalisation to held-out datasets. Our code and data are publiclyavailable at https://github.com/Bernard-Yang/MMSci_Table.</description><author>Bohao Yang, Yingji Zhang, Dong Liu, André Freitas, Chenghua Lin</author><pubDate>Wed, 22 Jan 2025 17:44:01 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.13042v1</guid></item><item><title>VisMin: Visual Minimal-Change Understanding</title><link>http://arxiv.org/abs/2407.16772v2</link><description>Fine-grained understanding of objects, attributes, and relationships betweenobjects is crucial for visual-language models (VLMs). Existing benchmarksprimarily focus on evaluating VLMs' capability to distinguish between two verysimilar captions given an image. In this paper, we introduce a new, challengingbenchmark termed Visual Minimal-Change Understanding (VisMin), which requiresmodels to predict the correct image-caption match given two images and twocaptions. The image pair and caption pair contain minimal changes, i.e., onlyone aspect changes at a time from among the following: object, attribute,count, and spatial relation. These changes test the models' understanding ofobjects, attributes (such as color, material, shape), counts, and spatialrelationships between objects. We built an automatic framework using largelanguage models and diffusion models, followed by a rigorous 4-stepverification process by human annotators. Empirical experiments reveal thatcurrent VLMs exhibit notable deficiencies in understanding spatialrelationships and counting abilities. We also generate a large-scale trainingdataset to finetune CLIP and Idefics2, showing significant improvements infine-grained understanding across benchmarks and in CLIP's general image-textalignment. We release all resources, including the benchmark, training data,and finetuned model checkpoints, at https://vismin.net/.</description><author>Rabiul Awal, Saba Ahmadi, Le Zhang, Aishwarya Agrawal</author><pubDate>Wed, 22 Jan 2025 17:42:29 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.16772v2</guid></item><item><title>TimeFilter: Patch-Specific Spatial-Temporal Graph Filtration for Time Series Forecasting</title><link>http://arxiv.org/abs/2501.13041v1</link><description>Current time series forecasting methods can be broadly classified into twocategories: Channel Independent (CI) and Channel Dependent (CD) strategies,both aiming to capture the complex dependencies within time series data.However, the CI strategy fails to exploit highly correlated covariateinformation, while the CD strategy integrates all dependencies, includingirrelevant or noisy ones, thus compromising generalization. To mitigate theseissues, recent works have introduced the Channel Clustering (CC) strategy bygrouping channels with similar characteristics and applying different modelingtechniques to each cluster. However, coarse-grained clustering cannot flexiblycapture complex, time-varying interactions. Addressing the above challenges, wepropose TimeFilter, a graph-based framework for adaptive and fine-graineddependency modeling. Specifically, after constructing the graph with the inputsequence, TimeFilter filters out irrelevant correlations and preserves the mostcritical ones through patch-specific filtering. Extensive experiments on 13real-world datasets from various application domains demonstrate thestate-of-the-art performance of TimeFilter. The code is available athttps://github.com/TROUBADOUR000/TimeFilter.</description><author>Yifan Hu, Guibin Zhang, Peiyuan Liu, Disen Lan, Naiqi Li, Dawei Cheng, Tao Dai, Shu-Tao Xia, Shirui Pan</author><pubDate>Wed, 22 Jan 2025 17:40:17 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.13041v1</guid></item><item><title>A Probabilistic Model for Self-Supervised Learning</title><link>http://arxiv.org/abs/2501.13031v1</link><description>Self-supervised learning (SSL) aims to find meaningful representations fromunlabeled data by encoding semantic similarities through data augmentations.Despite its current popularity, theoretical insights about SSL are stillscarce. For example, it is not yet known whether commonly used SSL lossfunctions can be related to a statistical model, much in the same as OLS,generalized linear models or PCA naturally emerge as maximum likelihoodestimates of an underlying generative process. In this short paper, we considera latent variable statistical model for SSL that exhibits an interestingproperty: Depending on the informativeness of the data augmentations, the MLEof the model either reduces to PCA, or approaches a simple non-contrastiveloss. We analyze the model and also empirically illustrate our findings.</description><author>Maximilian Fleissner, Pascal Esser, Debarghya Ghoshdastidar</author><pubDate>Wed, 22 Jan 2025 17:25:47 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.13031v1</guid></item><item><title>GSVC: Efficient Video Representation and Compression Through 2D Gaussian Splatting</title><link>http://arxiv.org/abs/2501.12060v2</link><description>3D Gaussian splats have emerged as a revolutionary, effective, learnedrepresentation for static 3D scenes. In this work, we explore using 2D Gaussiansplats as a new primitive for representing videos. We propose GSVC, an approachto learning a set of 2D Gaussian splats that can effectively represent andcompress video frames. GSVC incorporates the following techniques: (i) Toexploit temporal redundancy among adjacent frames, which can speed up trainingand improve the compression efficiency, we predict the Gaussian splats of aframe based on its previous frame; (ii) To control the trade-offs between filesize and quality, we remove Gaussian splats with low contribution to the videoquality; (iii) To capture dynamics in videos, we randomly add Gaussian splatsto fit content with large motion or newly-appeared objects; (iv) To handlesignificant changes in the scene, we detect key frames based on lossdifferences during the learning process. Experiment results show that GSVCachieves good rate-distortion trade-offs, comparable to state-of-the-art videocodecs such as AV1 and VVC, and a rendering speed of 1500 fps for a 1920x1080video.</description><author>Longan Wang, Yuang Shi, Wei Tsang Ooi</author><pubDate>Wed, 22 Jan 2025 17:24:38 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.12060v2</guid></item><item><title>Optimizing Return Distributions with Distributional Dynamic Programming</title><link>http://arxiv.org/abs/2501.13028v1</link><description>We introduce distributional dynamic programming (DP) methods for optimizingstatistical functionals of the return distribution, with standard reinforcementlearning as a special case. Previous distributional DP methods could optimizethe same class of expected utilities as classic DP. To go beyond expectedutilities, we combine distributional DP with stock augmentation, a techniquepreviously introduced for classic DP in the context of risk-sensitive RL, wherethe MDP state is augmented with a statistic of the rewards obtained so far(since the first time step). We find that a number of recently studied problemscan be formulated as stock-augmented return distribution optimization, and weshow that we can use distributional DP to solve them. We analyze distributionalvalue and policy iteration, with bounds and a study of what objectives thesedistributional DP methods can or cannot optimize. We describe a number ofapplications outlining how to use distributional DP to solve differentstock-augmented return distribution optimization problems, for examplemaximizing conditional value-at-risk, and homeostatic regulation. To highlightthe practical potential of stock-augmented return distribution optimization anddistributional DP, we combine the core ideas of distributional value iterationwith the deep RL agent DQN, and empirically evaluate it for solving instancesof the applications discussed.</description><author>Bernardo Ávila Pires, Mark Rowland, Diana Borsa, Zhaohan Daniel Guo, Khimya Khetarpal, André Barreto, David Abel, Rémi Munos, Will Dabney</author><pubDate>Wed, 22 Jan 2025 17:20:43 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.13028v1</guid></item><item><title>Towards Interpretable Radiology Report Generation via Concept Bottlenecks using a Multi-Agentic RAG</title><link>http://arxiv.org/abs/2412.16086v2</link><description>Deep learning has advanced medical image classification, but interpretabilitychallenges hinder its clinical adoption. This study enhances interpretabilityin Chest X-ray (CXR) classification by using concept bottleneck models (CBMs)and a multi-agent Retrieval-Augmented Generation (RAG) system for reportgeneration. By modeling relationships between visual features and clinicalconcepts, we create interpretable concept vectors that guide a multi-agent RAGsystem to generate radiology reports, enhancing clinical relevance,explainability, and transparency. Evaluation of the generated reports using anLLM-as-a-judge confirmed the interpretability and clinical utility of ourmodel's outputs. On the COVID-QU dataset, our model achieved 81% classificationaccuracy and demonstrated robust report generation performance, with five keymetrics ranging between 84% and 90%. This interpretable multi-agent frameworkbridges the gap between high-performance AI and the explainability required forreliable AI-driven CXR analysis in clinical settings. Our code is available athttps://github.com/tifat58/IRR-with-CBM-RAG.git.</description><author>Hasan Md Tusfiqur Alam, Devansh Srivastav, Md Abdul Kadir, Daniel Sonntag</author><pubDate>Wed, 22 Jan 2025 17:18:15 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.16086v2</guid></item><item><title>Provably-Safe Neural Network Training Using Hybrid Zonotope Reachability Analysis</title><link>http://arxiv.org/abs/2501.13023v1</link><description>Even though neural networks are being increasingly deployed insafety-critical applications, it remains difficult to enforce constraints ontheir output, meaning that it is hard to guarantee safety in such settings.Towards addressing this, many existing methods seek to verify a neuralnetwork's satisfaction of safety constraints, but do not address how to correctan "unsafe" network. On the other hand, the few works that extract a trainingsignal from verification cannot handle non-convex sets, and are eitherconservative or slow. To address these challenges, this work proposes a neuralnetwork training method that can encourage the exact reachable set of anon-convex input set through a neural network with rectified linear unit (ReLU)nonlinearities to avoid a non-convex unsafe region, using recent results innon-convex set representation with hybrid zonotopes and extracting gradientinformation from mixed-integer linear programs (MILPs). The proposed method isfast, with the computational complexity of each training iteration comparableto that of solving a linear program (LP) with number of dimensions andconstraints linear to the number of neurons and complexity of input and unsafesets. For a neural network with three hidden layers of width 30, the method wasable to drive the reachable set of a non-convex input set with 55 generatorsand 26 constraints out of a non-convex unsafe region with 21 generators and 11constraints in 490 seconds.</description><author>Long Kiu Chung, Shreyas Kousik</author><pubDate>Wed, 22 Jan 2025 17:13:48 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.13023v1</guid></item><item><title>Fast Ergodic Search with Kernel Functions</title><link>http://arxiv.org/abs/2403.01536v2</link><description>Ergodic search enables optimal exploration of an information distributionwhile guaranteeing the asymptotic coverage of the search space. However,current methods typically have exponential computation complexity in the searchspace dimension and are restricted to Euclidean space. We introduce acomputationally efficient ergodic search method. Our contributions aretwo-fold. First, we develop a kernel-based ergodic metric and generalize itfrom Euclidean space to Lie groups. We formally prove the proposed metric isconsistent with the standard ergodic metric while guaranteeing linearcomplexity in the search space dimension. Secondly, we derive the first-orderoptimality condition of the kernel ergodic metric for nonlinear systems, whichenables efficient trajectory optimization. Comprehensive numerical benchmarksshow that the proposed method is at least two orders of magnitude faster thanthe state-of-the-art algorithm. Finally, we demonstrate the proposed algorithmwith a peg-in-hole insertion task. We formulate the problem as a coverage taskin the space of SE(3) and use a 30-second-long human demonstration as the priordistribution for ergodic coverage. Ergodicity guarantees the asymptoticsolution of the peg-in-hole problem so long as the solution resides within theprior information distribution, which is seen in the 100% success rate.</description><author>Max Muchen Sun, Ayush Gaggar, Peter Trautman, Todd Murphey</author><pubDate>Wed, 22 Jan 2025 17:06:19 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.01536v2</guid></item><item><title>CHG Shapley: Efficient Data Valuation and Selection towards Trustworthy Machine Learning</title><link>http://arxiv.org/abs/2406.11730v3</link><description>Understanding the decision-making process of machine learning models iscrucial for ensuring trustworthy machine learning. Data Shapley, a landmarkstudy on data valuation, advances this understanding by assessing thecontribution of each datum to model performance. However, theresource-intensive and time-consuming nature of multiple model retraining poseschallenges for applying Data Shapley to large datasets. To address this, wepropose the CHG (compound of Hardness and Gradient) utility function, whichapproximates the utility of each data subset on model performance in everytraining epoch. By deriving the closed-form Shapley value for each data pointusing the CHG utility function, we reduce the computational complexity to thatof a single model retraining, achieving a quadratic improvement over existingmarginal contribution-based methods. We further leverage CHG Shapley forreal-time data selection, conducting experiments across three settings:standard datasets, label noise datasets, and class imbalance datasets. Theseexperiments demonstrate its effectiveness in identifying high-value and noisydata. By enabling efficient data valuation, CHG Shapley promotes trustworthymodel training through a novel data-centric perspective. Our codes areavailable at https://github.com/caihuaiguang/CHG-Shapley-for-Data-Valuation andhttps://github.com/caihuaiguang/CHG-Shapley-for-Data-Selection.</description><author>Huaiguang Cai</author><pubDate>Wed, 22 Jan 2025 17:05:51 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.11730v3</guid></item><item><title>Multi-Objective Hyperparameter Selection via Hypothesis Testing on Reliability Graphs</title><link>http://arxiv.org/abs/2501.13018v1</link><description>In sensitive application domains, multi-objective hyperparameter selectioncan ensure the reliability of AI models prior to deployment, while optimizingauxiliary performance metrics. The state-of-the-art Pareto Testing (PT) methodguarantees statistical reliability constraints by adopting a multiplehypothesis testing framework. In PT, hyperparameters are validated one at atime, following a data-driven order determined by expected reliability levels.This paper introduces a novel framework for multi-objective hyperparameterselection that captures the interdependencies among the reliability levels ofdifferent hyperparameter configurations using a directed acyclic graph (DAG),which is termed the reliability graph (RG). The RG is constructed based onprior information and data by using the Bradley-Terry model. The proposedapproach, RG-based PT (RG-PT), leverages the RG to enable the efficient,parallel testing of multiple hyperparameters at the same reliability level. Byintegrating False Discovery Rate (FDR) control, RG-PT ensures robuststatistical reliability guarantees and is shown via experiments across diversedomains to consistently yield superior solutions for multi-objectivecalibration problems.</description><author>Amirmohammad Farzaneh, Osvaldo Simeone</author><pubDate>Wed, 22 Jan 2025 17:05:38 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.13018v1</guid></item><item><title>Paper Quality Assessment based on Individual Wisdom Metrics from Open Peer Review</title><link>http://arxiv.org/abs/2501.13014v1</link><description>This study proposes a data-driven framework for enhancing the accuracy andefficiency of scientific peer review through an open, bottom-up process thatestimates reviewer quality. Traditional closed peer review systems, whileessential for quality control, are often slow, costly, and subject to biasesthat can impede scientific progress. Here, we introduce a method that evaluatesindividual reviewer reliability by quantifying agreement with communityconsensus scores and applying Bayesian weighting to refine paper qualityassessments. We analyze open peer review data from two major scientificconferences, and demonstrate that reviewer-specific quality scoressignificantly improve the reliability of paper quality estimation. Perhapssurprisingly, we find that reviewer quality scores are unrelated to authorshipquality. Our model incorporates incentive structures to recognize high-qualityreviewers and encourage broader coverage of submitted papers, therebymitigating the common "rich-get-richer" pitfall of social media. These findingssuggest that open peer review, with mechanisms for estimating and incentivizingreviewer quality, offers a scalable and equitable alternative for scientificpublishing, with potential to enhance the speed, fairness, and transparency ofthe peer review process.</description><author>Andrii Zahorodnii, Jasper J. F. van den Bosch, Ian Charest, Christopher Summerfield, Ila R. Fiete</author><pubDate>Wed, 22 Jan 2025 17:00:27 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.13014v1</guid></item><item><title>AI-driven View Guidance System in Intra-cardiac Echocardiography Imaging</title><link>http://arxiv.org/abs/2409.16898v3</link><description>Intra-cardiac echocardiography (ICE) is a crucial imaging modality used inelectrophysiology (EP) and structural heart disease (SHD) interventions,providing realtime, high-resolution views from within the heart. Despite itsadvantages, effective manipulation of the ICE catheter requires significantexpertise, which can lead to inconsistent outcomes, especially among lessexperienced operators. To address this challenge, we propose an AIdriven viewguidance system that operates in a continuous closed-loop withhuman-in-the-loop feedback, designed to assist users in navigating ICE imagingwithout requiring specialized knowledge. Specifically, our method models therelative position and orientation vectors between arbitrary views andclinically defined ICE views in a spatial coordinate system. It guides users onhow to manipulate the ICE catheter to transition from the current view to thedesired view over time. By operating in a closedloop configuration, the systemcontinuously predicts and updates the necessary catheter manipulations,ensuring seamless integration into existing clinical workflows. Theeffectiveness of the proposed system is demonstrated through a simulation-basedperformance evaluation using real clinical data, achieving an 89% success ratewith 6,532 test cases. Additionally, a semi-simulation experiment withhuman-in-the-loop testing validated the feasibility of continuous yet discreteguidance. These results underscore the potential of the proposed method toenhance the accuracy and efficiency of ICE imaging procedures.</description><author>Jaeyoung Huh, Paul Klein, Gareth Funka-Lea, Puneet Sharma, Ankur Kapoor, Young-Ho Kim</author><pubDate>Wed, 22 Jan 2025 16:58:30 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2409.16898v3</guid></item><item><title>The regret lower bound for communicating Markov Decision Processes</title><link>http://arxiv.org/abs/2501.13013v1</link><description>This paper is devoted to the extension of the regret lower bound beyondergodic Markov decision processes (MDPs) in the problem dependent setting.While the regret lower bound for ergodic MDPs is well-known and reached bytractable algorithms, we prove that the regret lower bound becomessignificatively more complex in communicating MDPs. Our lower bound revisitsthe necessary explorative behavior of consistent learning agents and furtherexplains that all optimal regions of the environment must be overvisitedcompared to sub-optimal ones, a phenomenon that we refer to as co-exploration.In tandem, we show that these two explorative and co-explorative behaviors areintertwined with navigation constraints obtained by scrutinizing the navigationstructure at logarithmic scale. The resulting lower bound is expressed as thesolution of an optimization problem that, in many standard classes of MDPs, canbe specialized to recover existing results. From a computational perspective,it is provably $\Sigma_2^\textrm{P}$-hard in general and as a matter of fact,even testing the membership to the feasible region is coNP-hard. We furtherprovide an algorithm to approximate the lower bound in a constructive way.</description><author>Victor Boone, Odalric-Ambrym Maillard</author><pubDate>Wed, 22 Jan 2025 16:56:42 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.13013v1</guid></item><item><title>MONA: Myopic Optimization with Non-myopic Approval Can Mitigate Multi-step Reward Hacking</title><link>http://arxiv.org/abs/2501.13011v1</link><description>Future advanced AI systems may learn sophisticated strategies throughreinforcement learning (RL) that humans cannot understand well enough to safelyevaluate. We propose a training method which avoids agents learning undesiredmulti-step plans that receive high reward (multi-step "reward hacks") even ifhumans are not able to detect that the behaviour is undesired. The method,Myopic Optimization with Non-myopic Approval (MONA), works by combiningshort-sighted optimization with far-sighted reward. We demonstrate that MONAcan prevent multi-step reward hacking that ordinary RL causes, even withoutbeing able to detect the reward hacking and without any extra information thatordinary RL does not get access to. We study MONA empirically in three settingswhich model different misalignment failure modes including 2-step environmentswith LLMs representing delegated oversight and encoded reasoning andlonger-horizon gridworld environments representing sensor tampering.</description><author>Sebastian Farquhar, Vikrant Varma, David Lindner, David Elson, Caleb Biddulph, Ian Goodfellow, Rohin Shah</author><pubDate>Wed, 22 Jan 2025 16:53:08 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.13011v1</guid></item><item><title>Learning accurate rigid registration for longitudinal brain MRI from synthetic data</title><link>http://arxiv.org/abs/2501.13010v1</link><description>Rigid registration aims to determine the translations and rotations necessaryto align features in a pair of images. While recent machine learning methodshave become state-of-the-art for linear and deformable registration acrosssubjects, they have demonstrated limitations when applied to longitudinal(within-subject) registration, where achieving precise alignment is critical.Building on an existing framework for anatomy-aware, acquisition-agnosticaffine registration, we propose a model optimized for longitudinal, rigid brainregistration. By training the model with synthetic within-subject pairsaugmented with rigid and subtle nonlinear transforms, the model estimates moreaccurate rigid transforms than previous cross-subject networks and performsrobustly on longitudinal registration pairs within and across magneticresonance imaging (MRI) contrasts.</description><author>Jingru Fu, Adrian V. Dalca, Bruce Fischl, Rodrigo Moreno, Malte Hoffmann</author><pubDate>Wed, 22 Jan 2025 16:52:20 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.13010v1</guid></item><item><title>Deep Learning-Based Image Recovery and Pose Estimation for Resident Space Objects</title><link>http://arxiv.org/abs/2501.13009v1</link><description>As the density of spacecraft in Earth's orbit increases, their recognition,pose and trajectory identification becomes crucial for averting potentialcollisions and executing debris removal operations. However, training modelsable to identify a spacecraft and its pose presents a significant challenge dueto a lack of available image data for model training. This paper puts forth aninnovative framework for generating realistic synthetic datasets of ResidentSpace Object (RSO) imagery. Using the International Space Station (ISS) as atest case, it goes on to combine image regression with image restorationmethodologies to estimate pose from blurred images. An analysis of the proposedimage recovery and regression techniques was undertaken, providing insightsinto the performance, potential enhancements and limitations when applied toreal imagery of RSOs. The image recovery approach investigated involves firstapplying image deconvolution using an effective point spread function, followedby detail object extraction with a U-Net. Interestingly, using only U-Net forimage reconstruction the best pose performance was attained, reducing theaverage Mean Squared Error in image recovery by 97.28% and the average angularerror by 71.9%. The successful application of U-Net image restoration combinedwith the Resnet50 regression network for pose estimation of the InternationalSpace Station demonstrates the value of a diverse set of evaluation tools foreffective solutions to real-world problems such as the analysis of distantobjects in Earth's orbit.</description><author>Louis Aberdeen, Mark Hansen, Melvyn L. Smith, Lyndon Smith</author><pubDate>Wed, 22 Jan 2025 16:50:58 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.13009v1</guid></item><item><title>Pairwise RM: Perform Best-of-N Sampling with Knockout Tournament</title><link>http://arxiv.org/abs/2501.13007v1</link><description>Best-of-N (BoN) sampling, a common strategy for test-time scaling of LargeLanguage Models (LLMs), relies on reward models to select the best candidatesolution from multiple generations. However, traditional reward models oftenassign arbitrary and inconsistent scores, limiting their effectiveness. Toaddress this, we propose a Pairwise Reward Model (Pairwise RM) combined with aknockout tournament for BoN sampling. Instead of assigning absolute scores,given one math problem, Pairwise RM evaluates two candidate solutions'correctness simultaneously. This approach eliminates the need for arbitraryscoring and enables cross-validation of solutions through parallel comparison.In the knockout tournament, Pairwise RM conducts pairwise comparisons betweencandidate solutions and eliminates the incorrect ones iteratively. We construct\ourdataset, a large-scale dataset of 443K pairwise comparisons derived fromNumiaMath and annotated using \texttt{gemini-1.5-flash}, and train the PairwiseRM via supervised fine-tuning. Experiments on MATH-500 and the Olympiad Benchdemonstrate significant improvements over traditional discriminative rewardmodels. And a 40\% to 60\% relative improvement is achieved on the top 50\%challenging problems.</description><author>Yantao Liu, Zijun Yao, Rui Min, Yixin Cao, Lei Hou, Juanzi Li</author><pubDate>Wed, 22 Jan 2025 16:49:37 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.13007v1</guid></item><item><title>O(d/T) Convergence Theory for Diffusion Probabilistic Models under Minimal Assumptions</title><link>http://arxiv.org/abs/2409.18959v2</link><description>Score-based diffusion models, which generate new data by learning to reversea diffusion process that perturbs data from the target distribution into noise,have achieved remarkable success across various generative tasks. Despite theirsuperior empirical performance, existing theoretical guarantees are oftenconstrained by stringent assumptions or suboptimal convergence rates. In thispaper, we establish a fast convergence theory for the denoising diffusionprobabilistic model (DDPM), a widely used SDE-based sampler, under minimalassumptions. Our analysis shows that, provided $\ell_{2}$-accurate estimates ofthe score functions, the total variation distance between the target andgenerated distributions is upper bounded by $O(d/T)$ (ignoring logarithmicfactors), where $d$ is the data dimensionality and $T$ is the number of steps.This result holds for any target distribution with finite first-order moment.Moreover, we show that with careful coefficient design, the convergence rateimproves to $O(k/T)$, where $k$ is the intrinsic dimension of the target datadistribution. This highlights the ability of DDPM to automatically adapt tounknown low-dimensional structures, a common feature of natural imagedistributions. These results are achieved through a novel set of analyticaltools that provides a fine-grained characterization of how the error propagatesat each step of the reverse process.</description><author>Gen Li, Yuling Yan</author><pubDate>Wed, 22 Jan 2025 16:45:40 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2409.18959v2</guid></item><item><title>Evaluating multiple models using labeled and unlabeled data</title><link>http://arxiv.org/abs/2501.11866v2</link><description>It remains difficult to evaluate machine learning classifiers in the absenceof a large, labeled dataset. While labeled data can be prohibitively expensiveor impossible to obtain, unlabeled data is plentiful. Here, we introduceSemi-Supervised Model Evaluation (SSME), a method that uses both labeled andunlabeled data to evaluate machine learning classifiers. SSME is the firstevaluation method to take advantage of the fact that: (i) there are frequentlymultiple classifiers for the same task, (ii) continuous classifier scores areoften available for all classes, and (iii) unlabeled data is often far moreplentiful than labeled data. The key idea is to use a semi-supervised mixturemodel to estimate the joint distribution of ground truth labels and classifierpredictions. We can then use this model to estimate any metric that is afunction of classifier scores and ground truth labels (e.g., accuracy orexpected calibration error). We present experiments in four domains whereobtaining large labeled datasets is often impractical: (1) healthcare, (2)content moderation, (3) molecular property prediction, and (4) imageannotation. Our results demonstrate that SSME estimates performance moreaccurately than do competing methods, reducing error by 5.1x relative to usinglabeled data alone and 2.4x relative to the next best competing method. SSMEalso improves accuracy when evaluating performance across subsets of the testdistribution (e.g., specific demographic subgroups) and when evaluating theperformance of language models.</description><author>Divya Shanmugam, Shuvom Sadhuka, Manish Raghavan, John Guttag, Bonnie Berger, Emma Pierson</author><pubDate>Wed, 22 Jan 2025 16:44:43 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.11866v2</guid></item><item><title>Ehrenfeucht-Haussler Rank and Chain of Thought</title><link>http://arxiv.org/abs/2501.12997v1</link><description>The notion of rank of a Boolean function has been a cornerstone in the theoryof PAC learning, enabling quasipolynomial-time learning algorithms forpolynomial-size decision trees. We present a novel characterization of rank,grounded in the well-known Transformer architecture. We show that the rank of afunction $f$ corresponds to the minimum number of Chain of Thought (CoT) stepsrequired by a single-layer transformer decoder with hard attention to compute$f$. Based on this characterization we establish tight bounds on the number ofCoT steps required for specific problems, showing that $\ell$-fold functioncomposition necessitates exactly $\ell$ CoT steps. Furthermore, we analyze theproblem of identifying the position of the $k$-th occurrence of 1 in a Booleansequence, proving that it requires $k$ CoT steps.</description><author>Pablo Barceló, Alexander Kozachinskiy, Tomasz Steifer</author><pubDate>Wed, 22 Jan 2025 16:30:58 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.12997v1</guid></item><item><title>Personalized Federated Learning for Cellular VR: Online Learning and Dynamic Caching</title><link>http://arxiv.org/abs/2501.11745v2</link><description>Delivering an immersive experience to virtual reality (VR) users throughwireless connectivity offers the freedom to engage from anywhere at any time.Nevertheless, it is challenging to ensure seamless wireless connectivity thatdelivers real-time and high-quality videos to the VR users. This paper proposesa field of view (FoV) aware caching for mobile edge computing (MEC)-enabledwireless VR network. In particular, the FoV of each VR user iscached/prefetched at the base stations (BSs) based on the caching strategiestailored to each BS. Specifically, decentralized and personalized federatedlearning (DP-FL) based caching strategies with guarantees are presented.Considering VR systems composed of multiple VR devices and BSs, a DP-FL cachingalgorithm is implemented at each BS to personalize content delivery for VRusers. The utilized DP-FL algorithm guarantees a probably approximately correct(PAC) bound on the conditional average cache hit. Further, to reduce the costof communicating gradients, one-bit quantization of the stochastic gradientdescent (OBSGD) is proposed, and a convergence guarantee of$\mathcal{O}(1/\sqrt{T})$ is obtained for the proposed algorithm, where $T$ isthe number of iterations. Additionally, to better account for the wirelesschannel dynamics, the FoVs are grouped into multicast or unicast groups basedon the number of requesting VR users. The performance of the proposed DP-FLalgorithm is validated through realistic VR head-tracking dataset, and theproposed algorithm is shown to have better performance in terms of averagedelay and cache hit as compared to baseline algorithms.</description><author>Krishnendu S. Tharakan, Hayssam Dahrouj, Nour Kouzayha, Hesham ElSawy, Tareq Y. Al-Naffouri</author><pubDate>Wed, 22 Jan 2025 16:25:47 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.11745v2</guid></item><item><title>An Offline Multi-Agent Reinforcement Learning Framework for Radio Resource Management</title><link>http://arxiv.org/abs/2501.12991v1</link><description>Offline multi-agent reinforcement learning (MARL) addresses key limitationsof online MARL, such as safety concerns, expensive data collection, extendedtraining intervals, and high signaling overhead caused by online interactionswith the environment. In this work, we propose an offline MARL algorithm forradio resource management (RRM), focusing on optimizing scheduling policies formultiple access points (APs) to jointly maximize the sum and tail rates of userequipment (UEs). We evaluate three training paradigms: centralized,independent, and centralized training with decentralized execution (CTDE). Oursimulation results demonstrate that the proposed offline MARL frameworkoutperforms conventional baseline approaches, achieving over a 15\% improvementin a weighted combination of sum and tail rates. Additionally, the CTDEframework strikes an effective balance, reducing the computational complexityof centralized methods while addressing the inefficiencies of independenttraining. These results underscore the potential of offline MARL to deliverscalable, robust, and efficient solutions for resource management in dynamicwireless networks.</description><author>Eslam Eldeeb, Hirley Alves</author><pubDate>Wed, 22 Jan 2025 16:25:46 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.12991v1</guid></item><item><title>Low-dimensional adaptation of diffusion models: Convergence in total variation</title><link>http://arxiv.org/abs/2501.12982v1</link><description>This paper investigates how diffusion generative models leverage (unknown)low-dimensional structure to accelerate sampling. Focusing on two mainstreamsamplers -- the denoising diffusion implicit model (DDIM) and the denoisingdiffusion probabilistic model (DDPM) -- and assuming accurate score estimates,we prove that their iteration complexities are no greater than the order of$k/\varepsilon$ (up to some log factor), where $\varepsilon$ is the precisionin total variation distance and $k$ is some intrinsic dimension of the targetdistribution. Our results are applicable to a broad family of targetdistributions without requiring smoothness or log-concavity assumptions.Further, we develop a lower bound that suggests the (near) necessity of thecoefficients introduced by Ho et al.(2020) and Song et al.(2020) infacilitating low-dimensional adaptation. Our findings provide the firstrigorous evidence for the adaptivity of the DDIM-type samplers to unknownlow-dimensional structure, and improve over the state-of-the-art DDPM theoryregarding total variation convergence.</description><author>Jiadong Liang, Zhihan Huang, Yuxin Chen</author><pubDate>Wed, 22 Jan 2025 16:12:33 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.12982v1</guid></item><item><title>UniUIR: Considering Underwater Image Restoration as An All-in-One Learner</title><link>http://arxiv.org/abs/2501.12981v1</link><description>Existing underwater image restoration (UIR) methods generally only handlecolor distortion or jointly address color and haze issues, but they oftenoverlook the more complex degradations that can occur in underwater scenes. Toaddress this limitation, we propose a Universal Underwater Image Restorationmethod, termed as UniUIR, considering the complex scenario of real-worldunderwater mixed distortions as an all-in-one manner. To decoupledegradation-specific issues and explore the inter-correlations among variousdegradations in UIR task, we designed the Mamba Mixture-of-Experts module. Thismodule enables each expert to identify distinct types of degradation andcollaboratively extract task-specific priors while maintaining global featurerepresentation based on linear complexity. Building upon this foundation, toenhance degradation representation and address the task conflicts that arisewhen handling multiple types of degradation, we introduce the spatial-frequencyprior generator. This module extracts degradation prior information in bothspatial and frequency domains, and adaptively selects the most appropriatetask-specific prompts based on image content, thereby improving the accuracy ofimage restoration. Finally, to more effectively address complex,region-dependent distortions in UIR task, we incorporate depth informationderived from a large-scale pre-trained depth prediction model, thereby enablingthe network to perceive and leverage depth variations across different imageregions to handle localized degradation. Extensive experiments demonstrate thatUniUIR can produce more attractive results across qualitative and quantitativecomparisons, and shows strong generalization than state-of-the-art methods.</description><author>Xu Zhang, Huan Zhang, Guoli Wang, Qian Zhang, Lefei Zhang, Bo Du</author><pubDate>Wed, 22 Jan 2025 16:10:42 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.12981v1</guid></item><item><title>Coseparable Nonnegative Tensor Factorization With T-CUR Decomposition</title><link>http://arxiv.org/abs/2401.16836v3</link><description>Nonnegative Matrix Factorization (NMF) is an important unsupervised learningmethod to extract meaningful features from data. To address the NMF problemwithin a polynomial time framework, researchers have introduced a separabilityassumption, which has recently evolved into the concept of coseparability. Thisadvancement offers a more efficient core representation for the original data.However, in the real world, the data is more natural to be represented as amulti-dimensional array, such as images or videos. The NMF's application tohigh-dimensional data involves vectorization, which risks losing essentialmulti-dimensional correlations. To retain these inherent correlations in thedata, we turn to tensors (multidimensional arrays) and leverage the tensort-product. This approach extends the coseparable NMF to the tensor setting,creating what we term coseparable Nonnegative Tensor Factorization (NTF). Inthis work, we provide an alternating index selection method to select thecoseparable core. Furthermore, we validate the t-CUR sampling theory andintegrate it with the tensor Discrete Empirical Interpolation Method (t-DEIM)to introduce an alternative, randomized index selection process. These methodshave been tested on both synthetic and facial analysis datasets. The resultsdemonstrate the efficiency of coseparable NTF when compared to coseparable NMF.</description><author>Juefei Chen, Longxiu Huang, Yimin Wei</author><pubDate>Wed, 22 Jan 2025 16:09:50 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.16836v3</guid></item><item><title>Developer Perspectives on Licensing and Copyright Issues Arising from Generative AI for Coding</title><link>http://arxiv.org/abs/2411.10877v2</link><description>Generative AI (GenAI) tools have already started to transform softwaredevelopment practices. Despite their utility in tasks such as writing code, theuse of these tools raises important legal questions and potential risks,particularly those associated with copyright law. In the midst of thisuncertainty, this paper presents a study jointly conducted by softwareengineering and legal researchers that surveyed 574 GitHub developers who useGenAI tools for development activities. The survey and follow-up interviewsprobed the developers' opinions on emerging legal issues as well as theirperception of copyrightability, ownership of generated code, and relatedconsiderations. We also investigate potential developer misconceptions, theimpact of GenAI on developers' work, and developers' awareness oflicensing/copyright risks. Qualitative and quantitative analysis showed thatdevelopers' opinions on copyright issues vary broadly and that many developersare aware of the nuances these legal questions involve. We provide: (1) asurvey of 574 developers on the licensing and copyright aspects of GenAI forcoding, (2) a snapshot of practitioners' views at a time when GenAI andperceptions of it are rapidly evolving, and (3) an analysis of developers'views, yielding insights and recommendations that can inform future regulatorydecisions in this evolving field.</description><author>Trevor Stalnaker, Nathan Wintersgill, Oscar Chaparro, Laura A. Heymann, Massimiliano Di Penta, Daniel M German, Denys Poshyvanyk</author><pubDate>Wed, 22 Jan 2025 16:08:07 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2411.10877v2</guid></item><item><title>Implicit Causality-biases in humans and LLMs as a tool for benchmarking LLM discourse capabilities</title><link>http://arxiv.org/abs/2501.12980v1</link><description>In this paper, we compare data generated with mono- and multilingual LLMsspanning a range of model sizes with data provided by human participants in anexperimental setting investigating well-established discourse biases. Beyondthe comparison as such, we aim to develop a benchmark to assess thecapabilities of LLMs with discourse biases as a robust proxy for more generaldiscourse understanding capabilities. More specifically, we investigatedImplicit Causality verbs, for which psycholinguistic research has foundparticipants to display biases with regard to three phenomena:\ theestablishment of (i) coreference relations (Experiment 1), (ii) coherencerelations (Experiment 2), and (iii) the use of particular referring expressions(Experiments 3 and 4). With regard to coreference biases we found only thelargest monolingual LLM (German Bloom 6.4B) to display more human-like biases.For coherence relation, no LLM displayed the explanation bias usually found forhumans. For referring expressions, all LLMs displayed a preference forreferring to subject arguments with simpler forms than to objects. However, nobias effect on referring expression was found, as opposed to recent studiesinvestigating human biases.</description><author>Florian Kankowski, Torgrim Solstad, Sina Zarriess, Oliver Bott</author><pubDate>Wed, 22 Jan 2025 16:07:24 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.12980v1</guid></item><item><title>FlanEC: Exploring Flan-T5 for Post-ASR Error Correction</title><link>http://arxiv.org/abs/2501.12979v1</link><description>In this paper, we present an encoder-decoder model leveraging Flan-T5 forpost-Automatic Speech Recognition (ASR) Generative Speech Error Correction(GenSEC), and we refer to it as FlanEC. We explore its application within theGenSEC framework to enhance ASR outputs by mapping n-best hypotheses into asingle output sentence. By utilizing n-best lists from ASR models, we aim toimprove the linguistic correctness, accuracy, and grammaticality of final ASRtranscriptions. Specifically, we investigate whether scaling the training dataand incorporating diverse datasets can lead to significant improvements inpost-ASR error correction. We evaluate FlanEC using the HyPoradise dataset,providing a comprehensive analysis of the model's effectiveness in this domain.Furthermore, we assess the proposed approach under different settings toevaluate model scalability and efficiency, offering valuable insights into thepotential of instruction-tuned encoder-decoder models for this task.</description><author>Moreno La Quatra, Valerio Mario Salerno, Yu Tsao, Sabato Marco Siniscalchi</author><pubDate>Wed, 22 Jan 2025 16:06:04 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.12979v1</guid></item><item><title>Galois groups of polynomials and neurosymbolic networks</title><link>http://arxiv.org/abs/2501.12978v1</link><description>This paper introduces a novel approach to understanding Galois theory, one ofthe foundational areas of algebra, through the lens of machine learning. Byanalyzing polynomial equations with machine learning techniques, we aim tostreamline the process of determining solvability by radicals and explorebroader applications within Galois theory. This summary encapsulates thebackground, methodology, potential applications, and challenges of using datascience in Galois theory. More specifically, we design a neurosymbolic network to classify Galoisgroups and show how this is more efficient than usual neural networks. Wediscover some very interesting distribution of polynomials for groups notisomorphic to the symmetric groups and alternating groups.</description><author>Elira Shaska, Tony Shaska</author><pubDate>Wed, 22 Jan 2025 16:05:59 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.12978v1</guid></item><item><title>LiT: Delving into a Simplified Linear Diffusion Transformer for Image Generation</title><link>http://arxiv.org/abs/2501.12976v1</link><description>In commonly used sub-quadratic complexity modules, linear attention benefitsfrom simplicity and high parallelism, making it promising for image synthesistasks. However, the architectural design and learning strategy for linearattention remain underexplored in this field. In this paper, we offer a suiteof ready-to-use solutions for efficient linear diffusion Transformers. Our corecontributions include: (1) Simplified Linear Attention using few heads,observing the free-lunch effect of performance without latency increase. (2)Weight inheritance from a fully pre-trained diffusion Transformer: initializinglinear Transformer using pre-trained diffusion Transformer and loading allparameters except for those related to linear attention. (3) Hybrid knowledgedistillation objective: using a pre-trained diffusion Transformer to help thetraining of the student linear Transformer, supervising not only the predictednoise but also the variance of the reverse diffusion process. These guidelineslead to our proposed Linear Diffusion Transformer (LiT), an efficienttext-to-image Transformer that can be deployed offline on a laptop. Experimentsshow that in class-conditional 256*256 and 512*512 ImageNet benchmark LiTachieves highly competitive FID while reducing training steps by 80% and 77%compared to DiT. LiT also rivals methods based on Mamba or Gated LinearAttention. Besides, for text-to-image generation, LiT allows for the rapidsynthesis of up to 1K resolution photorealistic images. Project page:https://techmonsterwang.github.io/LiT/.</description><author>Jiahao Wang, Ning Kang, Lewei Yao, Mengzhao Chen, Chengyue Wu, Songyang Zhang, Shuchen Xue, Yong Liu, Taiqiang Wu, Xihui Liu, Kaipeng Zhang, Shifeng Zhang, Wenqi Shao, Zhenguo Li, Ping Luo</author><pubDate>Wed, 22 Jan 2025 16:02:06 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.12976v1</guid></item><item><title>Condition-Invariant Semantic Segmentation</title><link>http://arxiv.org/abs/2305.17349v4</link><description>Adaptation of semantic segmentation networks to different visual conditionsis vital for robust perception in autonomous cars and robots. However, previouswork has shown that most feature-level adaptation methods, which employadversarial training and are validated on synthetic-to-real adaptation, providemarginal gains in condition-level adaptation, being outperformed by simplepixel-level adaptation via stylization. Motivated by these findings, we proposeto leverage stylization in performing feature-level adaptation by aligning theinternal network features extracted by the encoder of the network from theoriginal and the stylized view of each input image with a novel featureinvariance loss. In this way, we encourage the encoder to extract features thatare already invariant to the style of the input, allowing the decoder to focuson parsing these features and not on further abstracting from the specificstyle of the input. We implement our method, named Condition-Invariant SemanticSegmentation (CISS), on the current state-of-the-art domain adaptationarchitecture and achieve outstanding results on condition-level adaptation. Inparticular, CISS sets the new state of the art in the populardaytime-to-nighttime Cityscapes$\to$Dark Zurich benchmark. Furthermore, ourmethod achieves the second-best performance on the normal-to-adverseCityscapes$\to$ACDC benchmark. CISS is shown to generalize well to domainsunseen during training, such as BDD100K-night and ACDC-night. Code is publiclyavailable at https://github.com/SysCV/CISS .</description><author>Christos Sakaridis, David Bruggemann, Fisher Yu, Luc Van Gool</author><pubDate>Wed, 22 Jan 2025 16:01:04 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.17349v4</guid></item><item><title>OnionEval: An Unified Evaluation of Fact-conflicting Hallucination for Small-Large Language Models</title><link>http://arxiv.org/abs/2501.12975v1</link><description>Large Language Models (LLMs) are highly capable but require significantcomputational resources for both training and inference. Within the LLM family,smaller models (those with fewer than 10 billion parameters) also perform wellacross various tasks. However, these smaller models share similar limitationsto their larger counterparts, including the tendency to hallucinate. Despitethe existence of many benchmarks to evaluate hallucination in LLMs, few havespecifically focused on small LLMs (SLLMs). Additionally, SLLMs show widelyvarying performance across different benchmarks. In this paper, we introduceOnionEval, a multi-layer structured framework with a specific metric called thecontext-influence score (CI), designed to effectively assess thefact-conflicting hallucination tendencies of small LLMs across differentcontextual levels. Our experimental results reveal a key feature of SLLMs: theyexcel in factual analysis but face challenges with context reasoning. Furtherinvestigation shows that a simple Chain-of-Thought strategy can significantlyreduce these limitations, improving the practical usefulness of SLLMs inreal-world applications.</description><author>Chongren Sun, Yuran Li, Di Wu, Benoit Boulet</author><pubDate>Wed, 22 Jan 2025 15:59:44 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.12975v1</guid></item><item><title>MorphoSkel3D: Morphological Skeletonization of 3D Point Clouds for Informed Sampling in Object Classification and Retrieval</title><link>http://arxiv.org/abs/2501.12974v1</link><description>Point clouds are a set of data points in space to represent the 3D geometryof objects. A fundamental step in the processing is to identify a subset ofpoints to represent the shape. While traditional sampling methods often ignoreto incorporate geometrical information, recent developments in learning-basedsampling models have achieved significant levels of performance. With theintegration of geometrical priors, the ability to learn and preserve theunderlying structure can be enhanced when sampling. To shed light into theshape, a qualitative skeleton serves as an effective descriptor to guidesampling for both local and global geometries. In this paper, we introduceMorphoSkel3D as a new technique based on morphology to facilitate an efficientskeletonization of shapes. With its low computational cost, MorphoSkel3D is aunique, rule-based algorithm to benchmark its quality and performance on twolarge datasets, ModelNet and ShapeNet, under different sampling ratios. Theresults show that training with MorphoSkel3D leads to an informed and moreaccurate sampling in the practical application of object classification andpoint cloud retrieval.</description><author>Pierre Onghena, Santiago Velasco-Forero, Beatriz Marcotegui</author><pubDate>Wed, 22 Jan 2025 15:58:11 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.12974v1</guid></item><item><title>Distributional Counterfactual Explanations With Optimal Transport</title><link>http://arxiv.org/abs/2401.13112v5</link><description>Counterfactual explanations (CE) are the de facto method for providinginsights into black-box decision-making models by identifying alternativeinputs that lead to different outcomes. However, existing CE approaches,including group and global methods, focus predominantly on specific inputmodifications, lacking the ability to capture nuanced distributionalcharacteristics that influence model outcomes across the entire input-outputspectrum. This paper proposes distributional counterfactual explanation (DCE),shifting focus to the distributional properties of observed and counterfactualdata, thus providing broader insights. DCE is particularly beneficial forstakeholders making strategic decisions based on statistical data analysis, asit makes the statistical distribution of the counterfactual resembles the oneof the factual when aligning model outputs with a targetdistribution\textemdash something that the existing CE methods cannot fullyachieve. We leverage optimal transport (OT) to formulate a chance-constrainedoptimization problem, deriving a counterfactual distribution aligned with itsfactual counterpart, supported by statistical confidence. The efficacy of thisapproach is demonstrated through experiments, highlighting its potential toprovide deeper insights into decision-making models.</description><author>Lei You, Lele Cao, Mattias Nilsson, Bo Zhao, Lei Lei</author><pubDate>Wed, 22 Jan 2025 15:57:58 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.13112v5</guid></item><item><title>Accessible Smart Contracts Verification: Synthesizing Formal Models with Tamed LLMs</title><link>http://arxiv.org/abs/2501.12972v1</link><description>When blockchain systems are said to be trustless, what this really means isthat all the trust is put into software. Thus, there are strong incentives toensure blockchain software is correct -- vulnerabilities here cost millions andbreak businesses. One of the most powerful ways of establishing softwarecorrectness is by using formal methods. Approaches based on formal methods,however, induce a significant overhead in terms of time and expertise requiredto successfully employ them. Our work addresses this critical disadvantage byautomating the creation of a formal model -- a mathematical abstraction of thesoftware system -- which is often a core task when employing formal methods. Weperform model synthesis in three phases: we first transpile the code into modelstubs; then we "fill in the blanks" using a large language model (LLM);finally, we iteratively repair the generated model, on both syntactical andsemantical level. In this way, we significantly reduce the amount of timenecessary to create formal models and increase accessibility of valuablesoftware verification methods that rely on them. The practical context of ourwork was reducing the time-to-value of using formal models for correctnessaudits of smart contracts.</description><author>Jan Corazza, Ivan Gavran, Gabriela Moreira, Daniel Neider</author><pubDate>Wed, 22 Jan 2025 15:57:29 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.12972v1</guid></item><item><title>It's complicated. The relationship of algorithmic fairness and non-discrimination regulations in the EU AI Act</title><link>http://arxiv.org/abs/2501.12962v1</link><description>What constitutes a fair decision? This question is not only difficult forhumans but becomes more challenging when Artificial Intelligence (AI) modelsare used. In light of discriminatory algorithmic behaviors, the EU has recentlypassed the AI Act, which mandates specific rules for AI models, incorporatingboth traditional legal non-discrimination regulations and machine learningbased algorithmic fairness concepts. This paper aims to bridge these twodifferent concepts in the AI Act through: First a high-level introduction ofboth concepts targeting legal and computer science-oriented scholars, andsecond an in-depth analysis of the AI Act's relationship between legalnon-discrimination regulations and algorithmic fairness. Our analysis revealsthree key findings: (1.), most non-discrimination regulations target onlyhigh-risk AI systems. (2.), the regulation of high-risk systems encompassesboth data input requirements and output monitoring, though these regulationsare often inconsistent and raise questions of computational feasibility. (3.)Regulations for General Purpose AI Models, such as Large Language Models thatare not simultaneously classified as high-risk systems, currently lackspecificity compared to other regulations. Based on these findings, werecommend developing more specific auditing and testing methodologies for AIsystems. This paper aims to serve as a foundation for future interdisciplinarycollaboration between legal scholars and computer science-oriented machinelearning researchers studying discrimination in AI systems.</description><author>Kristof Meding</author><pubDate>Wed, 22 Jan 2025 15:38:09 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.12962v1</guid></item><item><title>Locate, Assign, Refine: Taming Customized Promptable Image Inpainting</title><link>http://arxiv.org/abs/2403.19534v2</link><description>Prior studies have made significant progress in image inpainting guided byeither text description or subject image. However, the research on inpaintingwith flexible guidance or control, i.e., text-only, image-only, and theircombination, is still in the early stage. Therefore, in this paper, weintroduce the multimodal promptable image inpainting project: a new task model,and data for taming customized image inpainting. We propose LAR-Gen, a novelapproach for image inpainting that enables seamless inpainting of specificregion in images corresponding to the mask prompt, incorporating both the textprompt and image prompt. Our LAR-Gen adopts a coarse-to-fine manner to ensurethe context consistency of source image, subject identity consistency, localsemantic consistency to the text description, and smoothness consistency. Itconsists of three mechanisms: (i) Locate mechanism: concatenating the noisewith masked scene image to achieve precise regional editing, (ii) Assignmechanism: employing decoupled cross-attention mechanism to accommodatemulti-modal guidance, and (iii) Refine mechanism: using a novel RefineNet tosupplement subject details. Additionally, to address the issue of scarcetraining data, we introduce a novel data engine to automatically extractsubstantial pairs of data consisting of local text prompts and correspondingvisual instances from a vast image data, leveraging publicly availablepre-trained large models. Extensive experiments and various applicationscenarios demonstrate the superiority of LAR-Gen in terms of both identitypreservation and text semantic consistency.</description><author>Yulin Pan, Chaojie Mao, Zeyinzi Jiang, Zhen Han, Jingfeng Zhang, Xiangteng He</author><pubDate>Wed, 22 Jan 2025 15:37:39 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.19534v2</guid></item><item><title>Boosting Diffusion Guidance via Learning Degradation-Aware Models for Blind Super Resolution</title><link>http://arxiv.org/abs/2501.08819v2</link><description>Recently, diffusion-based blind super-resolution (SR) methods have showngreat ability to generate high-resolution images with abundant high-frequencydetail, but the detail is often achieved at the expense of fidelity. Meanwhile,another line of research focusing on rectifying the reverse process ofdiffusion models (i.e., diffusion guidance), has demonstrated the power togenerate high-fidelity results for non-blind SR. However, these methods rely onknown degradation kernels, making them difficult to apply to blind SR. Toaddress these issues, we present DADiff in this paper. DADiff incorporatesdegradation-aware models into the diffusion guidance framework, eliminating theneed to know degradation kernels. Additionally, we propose two novel techniques-- input perturbation and guidance scalar -- to further improve ourperformance. Extensive experimental results show that our proposed method hassuperior performance over state-of-the-art methods on blind SR benchmarks.</description><author>Shao-Hao Lu, Ren Wang, Ching-Chun Huang, Wei-Chen Chiu</author><pubDate>Wed, 22 Jan 2025 15:34:51 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.08819v2</guid></item><item><title>Efficient Prompt Compression with Evaluator Heads for Long-Context Transformer Inference</title><link>http://arxiv.org/abs/2501.12959v1</link><description>Although applications involving long-context inputs are crucial for theeffective utilization of large language models (LLMs), they also result inincreased computational costs and reduced performance. To address thischallenge, we propose an efficient, training-free prompt compression methodthat retains key information within compressed prompts. We identify specificattention heads in transformer-based LLMs, which we designate as evaluatorheads, that are capable of selecting tokens in long inputs that are mostsignificant for inference. Building on this discovery, we develop EHPC, anEvaluator Head-based Prompt Compression method, which enables LLMs to rapidly"skim through" input prompts by leveraging only the first few layers withevaluator heads during the pre-filling stage, subsequently passing only theimportant tokens to the model for inference. EHPC achieves state-of-the-artresults across two mainstream benchmarks: prompt compression and long-contextinference acceleration. Consequently, it effectively reduces the complexity andcosts associated with commercial API calls. We further demonstrate that EHPCattains competitive results compared to key-value cache-based accelerationmethods, thereby highlighting its potential to enhance the efficiency of LLMsfor long-context tasks.</description><author>Weizhi Fei, Xueyan Niu, Guoqing Xie, Yingqing Liu, Bo Bai, Wei Han</author><pubDate>Wed, 22 Jan 2025 15:33:17 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.12959v1</guid></item><item><title>Structural adaptation via directional regularity: rate accelerated estimation in multivariate functional data</title><link>http://arxiv.org/abs/2409.00817v3</link><description>We introduce directional regularity, a new definition of anisotropy formultivariate functional data. Instead of taking the conventional view whichdetermines anisotropy as a notion of smoothness along a dimension, directionalregularity additionally views anisotropy through the lens of directions. Weshow that faster rates of convergence can be obtained through a change-of-basisby adapting to the directional regularity of a multivariate process. Analgorithm for the estimation and identification of the change-of-basis matrixis constructed, made possible due to the replication structure of functionaldata. Non-asymptotic bounds are provided for our algorithm, supplemented bynumerical evidence from an extensive simulation study. Possible applications ofthe directional regularity approach are discussed, and we advocate itsconsideration as a standard pre-processing step in multivariate functional dataanalysis.</description><author>Omar Kassi, Sunny G. W. Wang</author><pubDate>Wed, 22 Jan 2025 15:32:59 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2409.00817v3</guid></item><item><title>Pay Attention and Move Better: Harnessing Attention for Interactive Motion Generation and Training-free Editing</title><link>http://arxiv.org/abs/2410.18977v2</link><description>This research delves into the problem of interactive editing of human motiongeneration. Previous motion diffusion models lack explicit modeling of theword-level text-motion correspondence and good explainability, hencerestricting their fine-grained editing ability. To address this issue, wepropose an attention-based motion diffusion model, namely MotionCLR, with CLeaRmodeling of attention mechanisms. Technically, MotionCLR models the in-modalityand cross-modality interactions with self-attention and cross-attention,respectively. More specifically, the self-attention mechanism aims to measurethe sequential similarity between frames and impacts the order of motionfeatures. By contrast, the cross-attention mechanism works to find thefine-grained word-sequence correspondence and activate the correspondingtimesteps in the motion sequence. Based on these key properties, we develop aversatile set of simple yet effective motion editing methods via manipulatingattention maps, such as motion (de-)emphasizing, in-place motion replacement,and example-based motion generation, etc. For further verification of theexplainability of the attention mechanism, we additionally explore thepotential of action-counting and grounded motion generation ability viaattention maps. Our experimental results show that our method enjoys goodgeneration and editing ability with good explainability.</description><author>Ling-Hao Chen, Shunlin Lu, Wenxun Dai, Zhiyang Dou, Xuan Ju, Jingbo Wang, Taku Komura, Lei Zhang</author><pubDate>Wed, 22 Jan 2025 15:32:45 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.18977v2</guid></item><item><title>A Novel Tracking Framework for Devices in X-ray Leveraging Supplementary Cue-Driven Self-Supervised Features</title><link>http://arxiv.org/abs/2501.12958v1</link><description>To restore proper blood flow in blocked coronary arteries via angioplastyprocedure, accurate placement of devices such as catheters, balloons, andstents under live fluoroscopy or diagnostic angiography is crucial. Identifiedballoon markers help in enhancing stent visibility in X-ray sequences, whilethe catheter tip aids in precise navigation and co-registering vesselstructures, reducing the need for contrast in angiography. However, accuratedetection of these devices in interventional X-ray sequences faces significantchallenges, particularly due to occlusions from contrasted vessels and otherdevices and distractions from surrounding, resulting in the failure to tracksuch small objects. While most tracking methods rely on spatial correlation ofpast and current appearance, they often lack strong motion comprehensionessential for navigating through these challenging conditions, and fail toeffectively detect multiple instances in the scene. To overcome theselimitations, we propose a self-supervised learning approach that enhances itsspatio-temporal understanding by incorporating supplementary cues and learningacross multiple representation spaces on a large dataset. Followed by that, weintroduce a generic real-time tracking framework that effectively leverages thepretrained spatio-temporal network and also takes the historical appearance andtrajectory data into account. This results in enhanced localization of multipleinstances of device landmarks. Our method outperforms state-of-the-art methodsin interventional X-ray device tracking, especially stability and robustness,achieving an 87% reduction in max error for balloon marker detection and a 61%reduction in max error for catheter tip detection.</description><author>Saahil Islam, Venkatesh N. Murthy, Dominik Neumann, Serkan Cimen, Puneet Sharma, Andreas Maier, Dorin Comaniciu, Florin C. Ghesu</author><pubDate>Wed, 22 Jan 2025 15:32:07 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.12958v1</guid></item><item><title>Fixed-Budget Change Point Identification in Piecewise Constant Bandits</title><link>http://arxiv.org/abs/2501.12957v1</link><description>We study the piecewise constant bandit problem where the expected reward is apiecewise constant function with one change point (discontinuity) across theaction space $[0,1]$ and the learner's aim is to locate the change point. Underthe assumption of a fixed exploration budget, we provide the firstnon-asymptotic analysis of policies designed to locate abrupt changes in themean reward function under bandit feedback. We study the problem under a largeand small budget regime, and for both settings establish lower bounds on theerror probability and provide algorithms with near matching upper bounds.Interestingly, our results show a separation in the complexity of the tworegimes. We then propose a regime adaptive algorithm which is near optimal forboth small and large budgets simultaneously. We complement our theoreticalanalysis with experimental results in simulated environments to support ourfindings.</description><author>Joseph Lazzaro, Ciara Pike-Burke</author><pubDate>Wed, 22 Jan 2025 15:30:44 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.12957v1</guid></item><item><title>GANQ: GPU-Adaptive Non-Uniform Quantization for Large Language Models</title><link>http://arxiv.org/abs/2501.12956v1</link><description>Large Language Models (LLMs) face significant deployment challenges due totheir substantial resource requirements. While low-bit quantized weights canreduce memory usage and improve inference efficiency, current hardware lacksnative support for mixed-precision General Matrix Multiplication (mpGEMM),resulting in inefficient dequantization-based implementations. Moreover,uniform quantization methods often fail to capture weight distributionsadequately, leading to performance degradation. We propose GANQ (GPU-AdaptiveNon-Uniform Quantization), a layer-wise post-training non-uniform quantizationframework optimized for hardware-efficient lookup table-based mpGEMM. GANQachieves superior quantization performance by utilizing a training-free,GPU-adaptive optimization algorithm to efficiently reduce layer-wisequantization errors. Extensive experiments demonstrate GANQ's ability to reducethe perplexity gap from the FP16 baseline compared to state-of-the-art methodsfor both 3-bit and 4-bit quantization. Furthermore, when deployed on a singleNVIDIA RTX 4090 GPU, GANQ's quantized models achieve up to 2.57$\times$ speedupover the baseline, advancing memory and inference efficiency in LLM deployment.</description><author>Pengxiang Zhao, Xiaoming Yuan</author><pubDate>Wed, 22 Jan 2025 15:29:09 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.12956v1</guid></item><item><title>Multifractal hopscotch in "Hopscotch" by Julio Cortazar</title><link>http://arxiv.org/abs/2501.12955v1</link><description>Punctuation is the main factor introducing correlations in natural languagewritten texts and it crucially impacts their overall effectiveness,expressiveness, and readability. Punctuation marks at the end of sentences areof particular importance as their distribution can determine various complexityfeatures of written natural language. Here, the sentence length variability(SLV) time series representing "Hopscotch" by Julio Cortazar are subjected toquantitative analysis with an attempt to identify their distribution type,long-memory effects, and potential multiscale patterns. The analyzed novel isan important and innovative piece of literature whose essential property isfreedom of movement between its building blocks given to a reader by theauthor. The statistical consequences of this freedom are closely investigatedin both the original, Spanish version of the novel, and its translations intoEnglish and Polish. Clear evidence of rich multifractality in the SLV dynamics,with a left-sided asymmetry, however, is observed in all three languageversions as well as in the versions with differently ordered chapters.</description><author>Jakub Dec, Michał Dolina, Stanisław Drożdż, Jarosław Kwapień, Tomasz Stanisz</author><pubDate>Wed, 22 Jan 2025 15:28:24 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.12955v1</guid></item><item><title>Punctuation patterns in "Finnegans Wake" by James Joyce are largely translation-invariant</title><link>http://arxiv.org/abs/2501.12954v1</link><description>The complexity characteristics of texts written in natural languages aresignificantly related to the rules of punctuation. In particular, the distancesbetween punctuation marks measured by the number of words quite universallyfollow the family of Weibull distributions known from survival analyses.However, the values of two parameters marking specific forms of thesedistributions distinguish specific languages. This is such a strong constraintthat the punctuation distributions of texts translated from the originallanguage into another adopt quantitative characteristics of the targetlanguage. All these changes take place within Weibull distributions such thatthe corresponding hazard functions are always increasing. Recent previousresearch shows that James Joyce's famous "Finnegans Wake" is subject to suchextreme distribution from the Weibull family that the corresponding hazardfunction is clearly decreasing. At the same time, the distances of sentenceending punctuation marks, determining the variability of sentence length, havean almost perfect multifractal organization, so far to such an extent foundnowhere else in the literature. In the present contribution based on severalavailable translations (Dutch, French, German, Polish, Russian) of "FinnegansWake", it is shown that the punctuation characteristics of this work remainlargely translation invariant, contrary to the common cases. These observationsmay constitute further evidence that "Finnegans Wake" is a translinguistic workin this respect as well, in line with Joyce's original intention.</description><author>Krzysztof Bartnicki, Stanisław Drożdż, Jarosław Kwapień, Tomasz Stanisz</author><pubDate>Wed, 22 Jan 2025 15:27:43 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.12954v1</guid></item><item><title>Decision Mamba: A Multi-Grained State Space Model with Self-Evolution Regularization for Offline RL</title><link>http://arxiv.org/abs/2406.05427v3</link><description>While the conditional sequence modeling with the transformer architecture hasdemonstrated its effectiveness in dealing with offline reinforcement learning(RL) tasks, it is struggle to handle out-of-distribution states and actions.Existing work attempts to address this issue by data augmentation with thelearned policy or adding extra constraints with the value-based RL algorithm.However, these studies still fail to overcome the following challenges: (1)insufficiently utilizing the historical temporal information among inter-steps,(2) overlooking the local intrastep relationships among return-to-gos (RTGs),states, and actions, (3) overfitting suboptimal trajectories with noisy labels.To address these challenges, we propose Decision Mamba (DM), a novelmulti-grained state space model (SSM) with a self-evolving policy learningstrategy. DM explicitly models the historical hidden state to extract thetemporal information by using the mamba architecture. To capture therelationship among RTG-state-action triplets, a fine-grained SSM module isdesigned and integrated into the original coarse-grained SSM in mamba,resulting in a novel mamba architecture tailored for offline RL. Finally, tomitigate the overfitting issue on noisy trajectories, a self-evolving policy isproposed by using progressive regularization. The policy evolves by using itsown past knowledge to refine the suboptimal actions, thus enhancing itsrobustness on noisy demonstrations. Extensive experiments on various tasks showthat DM outperforms other baselines substantially.</description><author>Qi Lv, Xiang Deng, Gongwei Chen, Michael Yu Wang, Liqiang Nie</author><pubDate>Wed, 22 Jan 2025 15:21:24 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.05427v3</guid></item><item><title>DeepSeek-R1: Incentivizing Reasoning Capability in LLMs via Reinforcement Learning</title><link>http://arxiv.org/abs/2501.12948v1</link><description>We introduce our first-generation reasoning models, DeepSeek-R1-Zero andDeepSeek-R1. DeepSeek-R1-Zero, a model trained via large-scale reinforcementlearning (RL) without supervised fine-tuning (SFT) as a preliminary step,demonstrates remarkable reasoning capabilities. Through RL, DeepSeek-R1-Zeronaturally emerges with numerous powerful and intriguing reasoning behaviors.However, it encounters challenges such as poor readability, and languagemixing. To address these issues and further enhance reasoning performance, weintroduce DeepSeek-R1, which incorporates multi-stage training and cold-startdata before RL. DeepSeek-R1 achieves performance comparable to OpenAI-o1-1217on reasoning tasks. To support the research community, we open-sourceDeepSeek-R1-Zero, DeepSeek-R1, and six dense models (1.5B, 7B, 8B, 14B, 32B,70B) distilled from DeepSeek-R1 based on Qwen and Llama.</description><author>DeepSeek-AI, Daya Guo, Dejian Yang, Haowei Zhang, Junxiao Song, Ruoyu Zhang, Runxin Xu, Qihao Zhu, Shirong Ma, Peiyi Wang, Xiao Bi, Xiaokang Zhang, Xingkai Yu, Yu Wu, Z. F. Wu, Zhibin Gou, Zhihong Shao, Zhuoshu Li, Ziyi Gao, Aixin Liu, Bing Xue, Bingxuan Wang, Bochao Wu, Bei Feng, Chengda Lu, Chenggang Zhao, Chengqi Deng, Chenyu Zhang, Chong Ruan, Damai Dai, Deli Chen, Dongjie Ji, Erhang Li, Fangyun Lin, Fucong Dai, Fuli Luo, Guangbo Hao, Guanting Chen, Guowei Li, H. Zhang, Han Bao, Hanwei Xu, Haocheng Wang, Honghui Ding, Huajian Xin, Huazuo Gao, Hui Qu, Hui Li, Jianzhong Guo, Jiashi Li, Jiawei Wang, Jingchang Chen, Jingyang Yuan, Junjie Qiu, Junlong Li, J. L. Cai, Jiaqi Ni, Jian Liang, Jin Chen, Kai Dong, Kai Hu, Kaige Gao, Kang Guan, Kexin Huang, Kuai Yu, Lean Wang, Lecong Zhang, Liang Z</author><pubDate>Wed, 22 Jan 2025 15:19:35 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.12948v1</guid></item><item><title>Ontology-Enhanced Educational Annotation Activities</title><link>http://arxiv.org/abs/2501.12943v1</link><description>Information and communications technology and technology-enhanced learninghave unquestionably transformed traditional teaching-learning processes and arepositioned as key factors to promote quality education, one of the basicsustainable development goals of the 2030 agenda. Document annotation, whichwas traditionally carried out with pencil and paper and currently benefits fromdigital document annotation tools, is a representative example of thistransformation. Using document annotation tools, students can enrich thedocuments with annotations that highlight the most relevant aspects of thesedocuments. As the conceptual complexity of the learning domain increases, theannotation of the documents may require comprehensive domain knowledge and anexpert analysis capability that students usually lack. Consequently, aproliferation of irrelevant, incorrect, and/or poorly decontextualizedannotations may appear, while other relevant aspects are completely ignored bythe students. The main hypothesis proposed by this paper is that the use of aguiding annotation ontology in the annotation activities is a keystone aspectto alleviate these shortcomings. Consequently, comprehension is improved,exhaustive content analysis is promoted, and meta-reflective thinking isdeveloped. To test this hypothesis, we describe our own annotation tool,\@note, which fully implements this ontology-enhanced annotation paradigm, andwe provide experimental evidence about how \@note can improve academicperformance via a pilot study concerning critical literary annotation.</description><author>Joaquí Gayoso-Cabada, María Goicoechea-de-Jorge, Mercedes Gómez-Albarrán, Amelia Sanz-Cabrerizo, Antonio Sarasa-Cabezuelo, José-Luis Sierra</author><pubDate>Wed, 22 Jan 2025 15:15:59 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.12943v1</guid></item><item><title>Offline Critic-Guided Diffusion Policy for Multi-User Delay-Constrained Scheduling</title><link>http://arxiv.org/abs/2501.12942v1</link><description>Effective multi-user delay-constrained scheduling is crucial in variousreal-world applications, such as instant messaging, live streaming, and datacenter management. In these scenarios, schedulers must make real-time decisionsto satisfy both delay and resource constraints without prior knowledge ofsystem dynamics, which are often time-varying and challenging to estimate.Current learning-based methods typically require interactions with actualsystems during the training stage, which can be difficult or impractical, as itis capable of significantly degrading system performance and incurringsubstantial service costs. To address these challenges, we propose a noveloffline reinforcement learning-based algorithm, named \underline{S}cheduling By\underline{O}ffline Learning with \underline{C}ritic Guidance and\underline{D}iffusion Generation (SOCD), to learn efficient scheduling policiespurely from pre-collected \emph{offline data}. SOCD innovatively employs adiffusion-based policy network, complemented by a sampling-free critic networkfor policy guidance. By integrating the Lagrangian multiplier optimization intothe offline reinforcement learning, SOCD effectively trains high-qualityconstraint-aware policies exclusively from available datasets, eliminating theneed for online interactions with the system. Experimental results demonstratethat SOCD is resilient to various system dynamics, including partiallyobservable and large-scale environments, and delivers superior performancecompared to existing methods.</description><author>Zhuoran Li, Ruishuo Chen, Hai Zhong, Longbo Huang</author><pubDate>Wed, 22 Jan 2025 15:13:21 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.12942v1</guid></item><item><title>Des-q: a quantum algorithm to provably speedup retraining of decision trees</title><link>http://arxiv.org/abs/2309.09976v6</link><description>Decision trees are widely adopted machine learning models due to theirsimplicity and explainability. However, as training data size grows, standardmethods become increasingly slow, scaling polynomially with the number oftraining examples. In this work, we introduce Des-q, a novel quantum algorithmto construct and retrain decision trees for regression and binaryclassification tasks. Assuming the data stream produces small, periodicincrements of new training examples, Des-q significantly reduces the treeretraining time. Des-q achieves a logarithmic complexity in the combined totalnumber of old and new examples, even accounting for the time needed to load thenew samples into quantum-accessible memory. Our approach to grow the tree fromany given node involves performing piecewise linear splits to generate multiplehyperplanes, thus partitioning the input feature space into distinct regions.To determine the suitable anchor points for these splits, we develop anefficient quantum-supervised clustering method, building upon the q-meansalgorithm introduced by Kerenidis et al. We benchmark the simulated version ofDes-q against the state-of-the-art classical methods on multiple data sets andobserve that our algorithm exhibits similar performance to the state-of-the-artdecision trees while significantly speeding up the periodic tree retraining.</description><author>Niraj Kumar, Romina Yalovetzky, Changhao Li, Pierre Minssen, Marco Pistoia</author><pubDate>Wed, 22 Jan 2025 15:10:35 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2309.09976v6</guid></item><item><title>Yi-Lightning Technical Report</title><link>http://arxiv.org/abs/2412.01253v5</link><description>This technical report presents Yi-Lightning, our latest flagship largelanguage model (LLM). It achieves exceptional performance, ranking 6th overallon Chatbot Arena, with particularly strong results (2nd to 4th place) inspecialized categories including Chinese, Math, Coding, and Hard Prompts.Yi-Lightning leverages an enhanced Mixture-of-Experts (MoE) architecture,featuring advanced expert segmentation and routing mechanisms coupled withoptimized KV-caching techniques. Our development process encompassescomprehensive pre-training, supervised fine-tuning (SFT), and reinforcementlearning from human feedback (RLHF), where we devise deliberate strategies formulti-stage training, synthetic data construction, and reward modeling.Furthermore, we implement RAISE (Responsible AI Safety Engine), afour-component framework to address safety issues across pre-training,post-training, and serving phases. Empowered by our scalable super-computinginfrastructure, all these innovations substantially reduce training, deploymentand inference costs while maintaining high-performance standards. With furtherevaluations on public academic benchmarks, Yi-Lightning demonstratescompetitive performance against top-tier LLMs, while we observe a notabledisparity between traditional, static benchmark results and real-world, dynamichuman preferences. This observation prompts a critical reassessment ofconventional benchmarks' utility in guiding the development of more intelligentand powerful AI systems for practical applications. Yi-Lightning is nowavailable through our developer platform at https://platform.lingyiwanwu.com.</description><author>Alan Wake, Bei Chen, C. X. Lv, Chao Li, Chengen Huang, Chenglin Cai, Chujie Zheng, Daniel Cooper, Fan Zhou, Feng Hu, Ge Zhang, Guoyin Wang, Heng Ji, Howard Qiu, Jiangcheng Zhu, Jun Tian, Katherine Su, Lihuan Zhang, Liying Li, Ming Song, Mou Li, Peng Liu, Qicheng Hu, Shawn Wang, Shijun Zhou, Shiming Yang, Shiyong Li, Tianhang Zhu, Wen Xie, Wenhao Huang, Xiang He, Xiaobo Chen, Xiaohui Hu, Xiaoyi Ren, Xinyao Niu, Yanpeng Li, Yongke Zhao, Yongzhen Luo, Yuchi Xu, Yuxuan Sha, Zhaodong Yan, Zhiyuan Liu, Zirui Zhang, Zonghong Dai</author><pubDate>Wed, 22 Jan 2025 15:09:58 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.01253v5</guid></item><item><title>Episodic memory in AI agents poses risks that should be studied and mitigated</title><link>http://arxiv.org/abs/2501.11739v2</link><description>Most current AI models have little ability to store and later retrieve arecord or representation of what they do. In human cognition, episodic memoriesplay an important role in both recall of the past as well as planning for thefuture. The ability to form and use episodic memories would similarly enable abroad range of improved capabilities in an AI agent that interacts with andtakes actions in the world. Researchers have begun directing more attention todeveloping memory abilities in AI models. It is therefore likely that modelswith such capability will be become widespread in the near future. This couldin some ways contribute to making such AI agents safer by enabling users tobetter monitor, understand, and control their actions. However, as a newcapability with wide applications, we argue that it will also introducesignificant new risks that researchers should begin to study and address. Weoutline these risks and benefits and propose four principles to guide thedevelopment of episodic memory capabilities so that these will enhance, ratherthan undermine, the effort to keep AI safe and trustworthy.</description><author>Chad DeChant</author><pubDate>Wed, 22 Jan 2025 15:09:02 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.11739v2</guid></item><item><title>Search3D: Hierarchical Open-Vocabulary 3D Segmentation</title><link>http://arxiv.org/abs/2409.18431v2</link><description>Open-vocabulary 3D segmentation enables exploration of 3D spaces usingfree-form text descriptions. Existing methods for open-vocabulary 3D instancesegmentation primarily focus on identifying object-level instances but strugglewith finer-grained scene entities such as object parts, or regions described bygeneric attributes. In this work, we introduce Search3D, an approach toconstruct hierarchical open-vocabulary 3D scene representations, enabling 3Dsearch at multiple levels of granularity: fine-grained object parts, entireobjects, or regions described by attributes like materials. Unlike priormethods, Search3D shifts towards a more flexible open-vocabulary 3D searchparadigm, moving beyond explicit object-centric queries. For systematicevaluation, we further contribute a scene-scale open-vocabulary 3D partsegmentation benchmark based on MultiScan, along with a set of open-vocabularyfine-grained part annotations on ScanNet++. Search3D outperforms baselines inscene-scale open-vocabulary 3D part segmentation, while maintaining strongperformance in segmenting 3D objects and materials. Our project page ishttp://search3d-segmentation.github.io.</description><author>Ayca Takmaz, Alexandros Delitzas, Robert W. Sumner, Francis Engelmann, Johanna Wald, Federico Tombari</author><pubDate>Wed, 22 Jan 2025 15:09:00 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2409.18431v2</guid></item><item><title>3D Object Manipulation in a Single Image using Generative Models</title><link>http://arxiv.org/abs/2501.12935v1</link><description>Object manipulation in images aims to not only edit the object's presentationbut also gift objects with motion. Previous methods encountered challenges inconcurrently handling static editing and dynamic generation, while alsostruggling to achieve fidelity in object appearance and scene lighting. In thiswork, we introduce \textbf{OMG3D}, a novel framework that integrates theprecise geometric control with the generative power of diffusion models, thusachieving significant enhancements in visual performance. Our framework firstconverts 2D objects into 3D, enabling user-directed modifications and lifelikemotions at the geometric level. To address texture realism, we proposeCustomRefiner, a texture refinement module that pre-train a customizeddiffusion model, aligning the details and style of coarse renderings of 3Drough model with the original image, further refine the texture. Additionally,we introduce IllumiCombiner, a lighting processing module that estimates andcorrects background lighting to match human visual perception, resulting inmore realistic shadow effects. Extensive experiments demonstrate theoutstanding visual performance of our approach in both static and dynamicscenarios. Remarkably, all these steps can be done using one NVIDIA 3090.Project page is at https://whalesong-zrs.github.io/OMG3D-projectpage/</description><author>Ruisi Zhao, Zechuan Zhang, Zongxin Yang, Yi Yang</author><pubDate>Wed, 22 Jan 2025 15:06:30 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.12935v1</guid></item><item><title>Correctness Assessment of Code Generated by Large Language Models Using Internal Representations</title><link>http://arxiv.org/abs/2501.12934v1</link><description>Ensuring the correctness of code generated by Large Language Models (LLMs)presents a significant challenge in AI-driven software development. Existingapproaches predominantly rely on black-box (closed-box) approaches thatevaluate correctness post-generation, failing to utilize the rich insightsembedded in the LLMs' internal states during code generation. In this paper, weintroduce OPENIA, a novel white-box (open-box) framework that leverages theseinternal representations to assess the correctness of LLM-generated code.OPENIA systematically analyzes the intermediate states of representativeopen-source LLMs specialized for code, including DeepSeek-Coder, CodeLlama, andMagicCoder, across diverse code generation benchmarks. Our empirical analysisreveals that these internal representations encode latent information, whichstrongly correlates with the correctness of the generated code. Building onthese insights, OPENIA uses a white-box/open-box approach to make informedpredictions about code correctness, offering significant advantages inadaptability and robustness over traditional classification-based methods andzero-shot approaches. Experimental results demonstrate that OPENIA consistentlyoutperforms baseline models, achieving higher accuracy, precision, recall, andF1-Scores with up to a 2X improvement in standalone code generation and a 46%enhancement in repository-specific scenarios. By unlocking the potential ofin-process signals, OPENIA paves the way for more proactive and efficientquality assurance mechanisms in LLM-assisted code generation.</description><author>Tuan-Dung Bui, Thanh Trong Vu, Thu-Trang Nguyen, Son Nguyen, Hieu Dinh Vo</author><pubDate>Wed, 22 Jan 2025 15:04:13 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.12934v1</guid></item><item><title>DynamicEarth: How Far are We from Open-Vocabulary Change Detection?</title><link>http://arxiv.org/abs/2501.12931v1</link><description>Monitoring Earth's evolving land covers requires methods capable of detectingchanges across a wide range of categories and contexts. Existing changedetection methods are hindered by their dependency on predefined classes,reducing their effectiveness in open-world applications. To address this issue,we introduce open-vocabulary change detection (OVCD), a novel task that bridgesvision and language to detect changes across any category. Considering the lackof high-quality data and annotation, we propose two training-free frameworks,M-C-I and I-M-C, which leverage and integrate off-the-shelf foundation modelsfor the OVCD task. The insight behind the M-C-I framework is to discover allpotential changes and then classify these changes, while the insight of I-M-Cframework is to identify all targets of interest and then determine whethertheir states have changed. Based on these two frameworks, we instantiate toobtain several methods, e.g., SAM-DINOv2-SegEarth-OV, Grounding-DINO-SAM2-DINO,etc. Extensive evaluations on 5 benchmark datasets demonstrate the superiorgeneralization and robustness of our OVCD methods over existing supervised andunsupervised methods. To support continued exploration, we releaseDynamicEarth, a dedicated codebase designed to advance research and applicationof OVCD. https://likyoo.github.io/DynamicEarth</description><author>Kaiyu Li, Xiangyong Cao, Yupeng Deng, Chao Pang, Zepeng Xin, Deyu Meng, Zhi Wang</author><pubDate>Wed, 22 Jan 2025 15:02:43 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.12931v1</guid></item><item><title>Longitudinal Missing Data Imputation for Predicting Disability Stage of Patients with Multiple Sclerosis</title><link>http://arxiv.org/abs/2501.12927v1</link><description>Multiple Sclerosis (MS) is a chronic disease characterized by progressive oralternate impairment of neurological functions (motor, sensory, visual, andcognitive). Predicting disease progression with a probabilistic andtime-dependent approach might help in suggesting interventions that can delaythe progression of the disease. However, extracting informative knowledge fromirregularly collected longitudinal data is difficult, and missing data posesignificant challenges. MS progression is measured through the ExpandedDisability Status Scale (EDSS), which quantifies and monitors disability in MSover time. EDSS assesses impairment in eight functional systems (FS).Frequently, only the EDSS score assigned by clinicians is reported, while FSsub-scores are missing. Imputing these scores might be useful, especially tostratify patients according to their phenotype assessed over the diseaseprogression. This study aimed at i) exploring different methodologies forimputing missing FS sub-scores, and ii) predicting the EDSS score usingcomplete clinical data. Results show that Exponential Weighted Moving Averageachieved the lowest error rate in the missing data imputation task;furthermore, the combination of Classification and Regression Trees for theimputation and SVM for the prediction task obtained the best accuracy.</description><author>Mahin Vazifehdan, Pietro Bosoni, Daniele Pala, Eleonora Tavazzi, Roberto Bergamaschi, Riccardo Bellazzi, Arianna Dagliati</author><pubDate>Wed, 22 Jan 2025 14:56:19 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.12927v1</guid></item><item><title>RAG with Differential Privacy</title><link>http://arxiv.org/abs/2412.19291v2</link><description>Retrieval-Augmented Generation (RAG) has emerged as the dominant technique toprovide \emph{Large Language Models} (LLM) with fresh and relevant context,mitigating the risk of hallucinations and improving the overall quality ofresponses in environments with large and fast moving knowledge bases. However,the integration of external documents into the generation process raisessignificant privacy concerns. Indeed, when added to a prompt, it is notpossible to guarantee a response will not inadvertently expose confidentialdata, leading to potential breaches of privacy and ethical dilemmas. This paperexplores a practical solution to this problem suitable to general knowledgeextraction from personal data. It shows \emph{differentially private tokengeneration} is a viable approach to private RAG.</description><author>Nicolas Grislain</author><pubDate>Wed, 22 Jan 2025 14:50:33 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.19291v2</guid></item><item><title>Contrastive Language-Structure Pre-training Driven by Materials Science Literature</title><link>http://arxiv.org/abs/2501.12919v1</link><description>Understanding structure-property relationships is an essential yetchallenging aspect of materials discovery and development. To facilitate thisprocess, recent studies in materials informatics have sought latent embeddingspaces of crystal structures to capture their similarities based on propertiesand functionalities. However, abstract feature-based embedding spaces arehuman-unfriendly and prevent intuitive and efficient exploration of the vastmaterials space. Here we introduce Contrastive Language--Structure Pre-training(CLaSP), a learning paradigm for constructing crossmodal embedding spacesbetween crystal structures and texts. CLaSP aims to achieve material embeddingsthat 1) capture property- and functionality-related similarities betweencrystal structures and 2) allow intuitive retrieval of materials viauser-provided description texts as queries. To compensate for the lack ofsufficient datasets linking crystal structures with textual descriptions, CLaSPleverages a dataset of over 400,000 published crystal structures andcorresponding publication records, including paper titles and abstracts, fortraining. We demonstrate the effectiveness of CLaSP through text-based crystalstructure screening and embedding space visualization.</description><author>Yuta Suzuki, Tatsunori Taniai, Ryo Igarashi, Kotaro Saito, Naoya Chiba, Yoshitaka Ushiku, Kanta Ono</author><pubDate>Wed, 22 Jan 2025 14:47:59 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.12919v1</guid></item><item><title>Capsule Vision 2024 Challenge: Multi-Class Abnormality Classification for Video Capsule Endoscopy</title><link>http://arxiv.org/abs/2408.04940v3</link><description>We present the Capsule Vision 2024 Challenge: Multi-Class AbnormalityClassification for Video Capsule Endoscopy. It was virtually organized by theResearch Center for Medical Image Analysis and Artificial Intelligence (MIAAI),Department of Medicine, Danube Private University, Krems, Austria incollaboration with the 9th International Conference on Computer Vision &amp; ImageProcessing (CVIP 2024) being organized by the Indian Institute of InformationTechnology, Design and Manufacturing (IIITDM) Kancheepuram, Chennai, India.This document provides an overview of the challenge, including the registrationprocess, rules, submission format, description of the datasets used, qualifiedteam rankings, all team descriptions, and the benchmarking results reported bythe organizers.</description><author>Palak Handa, Amirreza Mahbod, Florian Schwarzhans, Ramona Woitek, Nidhi Goel, Manas Dhir, Deepti Chhabra, Shreshtha Jha, Pallavi Sharma, Vijay Thakur, Simarpreet Singh Chawla, Deepak Gunjan, Jagadeesh Kakarla, Balasubramanian Raman</author><pubDate>Wed, 22 Jan 2025 14:45:33 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.04940v3</guid></item><item><title>A Selective Homomorphic Encryption Approach for Faster Privacy-Preserving Federated Learning</title><link>http://arxiv.org/abs/2501.12911v1</link><description>Federated learning is a machine learning method that supports training modelson decentralized devices or servers, where each holds its local data, removingthe need for data exchange. This approach is especially useful in healthcare,as it enables training on sensitive data without needing to share them. Thenature of federated learning necessitates robust security precautions due todata leakage concerns during communication. To address this issue, we propose anew approach that employs selective encryption, homomorphic encryption,differential privacy, and bit-wise scrambling to minimize data leakage whileachieving good execution performance. Our technique , FAS (fast and securefederated learning) is used to train deep learning models on medical imagingdata. We implemented our technique using the Flower framework and compared witha state-of-the-art federated learning approach that also uses selectivehomomorphic encryption. Our experiments were run in a cluster of elevenphysical machines to create a real-world federated learning scenario ondifferent datasets. We observed that our approach is up to 90\% faster thanapplying fully homomorphic encryption on the model weights. In addition, we canavoid the pretraining step that is required by our competitor and can save upto 20\% in terms of total execution time. While our approach was faster, itobtained similar security results as the competitor.</description><author>Abdulkadir Korkmaz, Praveen Rao</author><pubDate>Wed, 22 Jan 2025 14:37:44 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.12911v1</guid></item><item><title>TriG-NER: Triplet-Grid Framework for Discontinuous Named Entity Recognition</title><link>http://arxiv.org/abs/2411.01839v2</link><description>Discontinuous Named Entity Recognition (DNER) presents a challenging problemwhere entities may be scattered across multiple non-adjacent tokens, makingtraditional sequence labelling approaches inadequate. Existing methodspredominantly rely on custom tagging schemes to handle these discontinuousentities, resulting in models tightly coupled to specific tagging strategiesand lacking generalisability across diverse datasets. To address thesechallenges, we propose TriG-NER, a novel Triplet-Grid Framework that introducesa generalisable approach to learning robust token-level representations fordiscontinuous entity extraction. Our framework applies triplet loss at thetoken level, where similarity is defined by word pairs existing within the sameentity, effectively pulling together similar and pushing apart dissimilar ones.This approach enhances entity boundary detection and reduces the dependency onspecific tagging schemes by focusing on word-pair relationships within aflexible grid structure. We evaluate TriG-NER on three benchmark DNER datasetsand demonstrate significant improvements over existing grid-basedarchitectures. These results underscore our framework's effectiveness incapturing complex entity structures and its adaptability to various taggingschemes, setting a new benchmark for discontinuous entity extraction.</description><author>Rina Carines Cabral, Soyeon Caren Han, Areej Alhassan, Riza Batista-Navarro, Goran Nenadic, Josiah Poon</author><pubDate>Wed, 22 Jan 2025 14:37:03 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2411.01839v2</guid></item><item><title>PreciseCam: Precise Camera Control for Text-to-Image Generation</title><link>http://arxiv.org/abs/2501.12910v1</link><description>Images as an artistic medium often rely on specific camera angles and lensdistortions to convey ideas or emotions; however, such precise control ismissing in current text-to-image models. We propose an efficient and generalsolution that allows precise control over the camera when generating bothphotographic and artistic images. Unlike prior methods that rely on predefinedshots, we rely solely on four simple extrinsic and intrinsic camera parameters,removing the need for pre-existing geometry, reference 3D objects, andmulti-view data. We also present a novel dataset with more than 57,000 images,along with their text prompts and ground-truth camera parameters. Ourevaluation shows precise camera control in text-to-image generation, surpassingtraditional prompt engineering approaches. Our data, model, and code arepublicly available at https://graphics.unizar.es/projects/PreciseCam2024.</description><author>Edurne Bernal-Berdun, Ana Serrano, Belen Masia, Matheus Gadelha, Yannick Hold-Geoffroy, Xin Sun, Diego Gutierrez</author><pubDate>Wed, 22 Jan 2025 14:37:01 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.12910v1</guid></item><item><title>FilmAgent: A Multi-Agent Framework for End-to-End Film Automation in Virtual 3D Spaces</title><link>http://arxiv.org/abs/2501.12909v1</link><description>Virtual film production requires intricate decision-making processes,including scriptwriting, virtual cinematography, and precise actor positioningand actions. Motivated by recent advances in automated decision-making withlanguage agent-based societies, this paper introduces FilmAgent, a novelLLM-based multi-agent collaborative framework for end-to-end film automation inour constructed 3D virtual spaces. FilmAgent simulates various crew roles,including directors, screenwriters, actors, and cinematographers, and coverskey stages of a film production workflow: (1) idea development transformsbrainstormed ideas into structured story outlines; (2) scriptwriting elaborateson dialogue and character actions for each scene; (3) cinematography determinesthe camera setups for each shot. A team of agents collaborates throughiterative feedback and revisions, thereby verifying intermediate scripts andreducing hallucinations. We evaluate the generated videos on 15 ideas and 4 keyaspects. Human evaluation shows that FilmAgent outperforms all baselines acrossall aspects and scores 3.98 out of 5 on average, showing the feasibility ofmulti-agent collaboration in filmmaking. Further analysis reveals thatFilmAgent, despite using the less advanced GPT-4o model, surpasses thesingle-agent o1, showing the advantage of a well-coordinated multi-agentsystem. Lastly, we discuss the complementary strengths and weaknesses ofOpenAI's text-to-video model Sora and our FilmAgent in filmmaking.</description><author>Zhenran Xu, Longyue Wang, Jifang Wang, Zhouyi Li, Senbao Shi, Xue Yang, Yiyu Wang, Baotian Hu, Jun Yu, Min Zhang</author><pubDate>Wed, 22 Jan 2025 14:36:30 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.12909v1</guid></item><item><title>Omnipredicting Single-Index Models with Multi-Index Models</title><link>http://arxiv.org/abs/2411.13083v2</link><description>Recent work on supervised learning [GKR+22] defined the notion ofomnipredictors, i.e., predictor functions $p$ over features that aresimultaneously competitive for minimizing a family of loss functions$\mathcal{L}$ against a comparator class $\mathcal{C}$. Omniprediction requiresapproximating the Bayes-optimal predictor beyond the loss minimizationparadigm, and has generated significant interest in the learning theorycommunity. However, even for basic settings such as agnostically learningsingle-index models (SIMs), existing omnipredictor constructions requireimpractically-large sample complexities and runtimes, and output complex,highly-improper hypotheses. Our main contribution is a new, simple construction of omnipredictors forSIMs. We give a learner outputting an omnipredictor that is$\varepsilon$-competitive on any matching loss induced by a monotone, Lipschitzlink function, when the comparator class is bounded linear predictors. Ouralgorithm requires $\approx \varepsilon^{-4}$ samples and runs in nearly-lineartime, and its sample complexity improves to $\approx \varepsilon^{-2}$ if linkfunctions are bi-Lipschitz. This significantly improves upon the only priorknown construction, due to [HJKRR18, GHK+23], which used $\gtrsim\varepsilon^{-10}$ samples. We achieve our construction via a new, sharp analysis of the classicalIsotron algorithm [KS09, KKKS11] in the challenging agnostic learning setting,of potential independent interest. Previously, Isotron was known to properlylearn SIMs in the realizable setting, as well as constant-factor competitivehypotheses under the squared loss [ZWDD24]. As they are based on Isotron, ouromnipredictors are multi-index models with $\approx \varepsilon^{-2}$prediction heads, bringing us closer to the tantalizing goal of properomniprediction for general loss families and comparators.</description><author>Lunjia Hu, Kevin Tian, Chutong Yang</author><pubDate>Wed, 22 Jan 2025 14:34:14 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2411.13083v2</guid></item><item><title>Panza: Design and Analysis of a Fully-Local Personalized Text Writing Assistant</title><link>http://arxiv.org/abs/2407.10994v2</link><description>The availability of powerful open-source large language models (LLMs) opensexciting use cases, such as automated personal assistants that adapt to theuser's unique data and demands. Two key requirements for such assistants arepersonalization - in the sense that the assistant should reflect the user's ownwriting style - and privacy - users may prefer to always store their personaldata locally, on their own computing device. In this application paper, wepresent a new design and evaluation for such an automated assistant, for thespecific use case of email generation, which we call Panza. Specifically, Panzacan be trained and deployed locally on commodity hardware, and is personalizedto the user's writing style. Panza's personalization features are based on acombination of fine-tuning using a variant of the Reverse Instructionstechnique together with Retrieval-Augmented Generation (RAG). We demonstratethat this combination allows us to fine-tune an LLM to better reflect a user'swriting style using limited data, while executing on extremely limitedresources, e.g. on a free Google Colab instance. Our key methodologicalcontribution is what we believe to be the first detailed study of evaluationmetrics for this personalized writing task, and of how different choices ofsystem components - e.g. the use of RAG and of different fine-tuning approaches- impact the system's performance. We are releasing the full Panza code as wellas a new "David" personalized email dataset licensed for research use, bothavailable on https://github.com/IST-DASLab/PanzaMail.</description><author>Armand Nicolicioiu, Eugenia Iofinova, Eldar Kurtic, Mahdi Nikdan, Andrei Panferov, Ilia Markov, Nir Shavit, Dan Alistarh</author><pubDate>Wed, 22 Jan 2025 14:33:23 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.10994v2</guid></item><item><title>Web vs. LLMs: An Empirical Study of Learning Behaviors of CS2 Students</title><link>http://arxiv.org/abs/2501.11935v2</link><description>LLMs such as ChatGPT have been widely adopted by students in higher educationas tools for learning programming and related concepts. However, it remainsunclear how effective students are and what strategies students use whilelearning with LLMs. Since the majority of students' experiences in onlineself-learning have come through using search engines such as Google, evaluatingAI tools in this context can help us address these gaps. In this mixed methodsresearch, we conducted an exploratory within-subjects study to understand howCS2 students learn programming concepts using both LLMs as well as traditionalonline methods such as educational websites and videos to examine how studentsapproach learning within and across both scenarios. We discovered that studentsfound it easier to learn a more difficult concept using traditional methodsthan using ChatGPT. We also found that students ask fewer follow-ups and usemore keyword-based queries for search engines while their prompts to LLMs tendto explicitly ask for information.</description><author>Aayush Kumar, Daniel Prol, Amin Alipour, Sruti Srinivasa Ragavan</author><pubDate>Wed, 22 Jan 2025 14:31:48 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.11935v2</guid></item><item><title>Architectural Fusion Through Contextual Partitioning in Large Language Models: A Novel Approach to Parameterized Knowledge Integration</title><link>http://arxiv.org/abs/2501.12901v1</link><description>Contextual Partitioning introduces an innovative approach to enhancing thearchitectural design of large-scale computational models through the dynamicsegmentation of parameters into context-aware regions. This methodologyemphasizes the importance of task-specific specialization, achieved throughadaptive parameter allocation mechanisms that align with the linguisticfeatures of input data. Experimental evaluations demonstrated substantialimprovements in accuracy, perplexity, and contextual coherence across a varietyof linguistic tasks, highlighting the adaptability and scalability of theproposed framework. By reducing redundancy and enhancing computationalefficiency, Contextual Partitioning not only streamlines model operations butalso expands the scope of applications for advanced language processingsystems. The approach operates autonomously, requiring no external fine-tuning,thereby addressing a significant limitation in conventional parameteroptimization techniques. Empirical results demonstrate the effectiveness ofgradient-driven segmentation, enabling models to dynamically recalibrate andspecialize in response to task-specific demands. Furthermore, resourceutilization metrics reveal notable reductions in memory usage and trainingtimes, confirming the efficiency of the approach. Observations from qualitativeanalyses illustrate improved contextual coherence and logical flow in generatedoutputs, reinforcing the practical value of this technique. The findingscollectively demonstrate the potential for Contextual Partitioning to redefinethe scalability and adaptability of computational language architectures indiverse and complex domains.</description><author>Offa Kingsleigh, Alfred Abercrombie, David Woolstencroft, Beorhtric Meadowcroft, Marcus Irvin</author><pubDate>Wed, 22 Jan 2025 14:21:04 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.12901v1</guid></item><item><title>Unified CNNs and transformers underlying learning mechanism reveals multi-head attention modus vivendi</title><link>http://arxiv.org/abs/2501.12900v1</link><description>Convolutional neural networks (CNNs) evaluate short-range correlations ininput images which progress along the layers, whereas vision transformer (ViT)architectures evaluate long-range correlations, using repeated transformerencoders composed of fully connected layers. Both are designed to solve complexclassification tasks but from different perspectives. This study demonstratesthat CNNs and ViT architectures stem from a unified underlying learningmechanism, which quantitatively measures the single-nodal performance (SNP) ofeach node in feedforward (FF) and multi-head attention (MHA) subblocks. Eachnode identifies small clusters of possible output labels, with additional noiserepresented as labels outside these clusters. These features are progressivelysharpened along the transformer encoders, enhancing the signal-to-noise ratio.This unified underlying learning mechanism leads to two main findings. First,it enables an efficient applied nodal diagonal connection (ANDC) pruningtechnique without affecting the accuracy. Second, based on the SNP, spontaneoussymmetry breaking occurs among the MHA heads, such that each head focuses itsattention on a subset of labels through cooperation among its SNPs.Consequently, each head becomes an expert in recognizing its designated labels,representing a quantitative MHA modus vivendi mechanism. These results arebased on a compact convolutional transformer architecture trained on theCIFAR-100 and Flowers-102 datasets and call for their extension to otherarchitectures and applications, such as natural language processing.</description><author>Ella Koresh, Ronit D. Gross, Yuval Meir, Yarden Tzach, Tal Halevi, Ido Kanter</author><pubDate>Wed, 22 Jan 2025 14:19:48 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.12900v1</guid></item><item><title>DocTTT: Test-Time Training for Handwritten Document Recognition Using Meta-Auxiliary Learning</title><link>http://arxiv.org/abs/2501.12898v1</link><description>Despite recent significant advancements in Handwritten Document Recognition(HDR), the efficient and accurate recognition of text against complexbackgrounds, diverse handwriting styles, and varying document layouts remains apractical challenge. Moreover, this issue is seldom addressed in academicresearch, particularly in scenarios with minimal annotated data available. Inthis paper, we introduce the DocTTT framework to address these challenges. Thekey innovation of our approach is that it uses test-time training to adapt themodel to each specific input during testing. We propose a novel Meta-Auxiliarylearning approach that combines Meta-learning and self-supervised MaskedAutoencoder~(MAE). During testing, we adapt the visual representationparameters using a self-supervised MAE loss. During training, we learn themodel parameters using a meta-learning framework, so that the model parametersare learned to adapt to a new input effectively. Experimental results show thatour proposed method significantly outperforms existing state-of-the-artapproaches on benchmark datasets.</description><author>Wenhao Gu, Li Gu, Ziqiang Wang, Ching Yee Suen, Yang Wang</author><pubDate>Wed, 22 Jan 2025 14:18:47 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.12898v1</guid></item><item><title>Irrational Complex Rotations Empower Low-bit Optimizers</title><link>http://arxiv.org/abs/2501.12896v1</link><description>In this paper, we propose a novel optimizer state compression algorithm,namely $\pi$-Quant, which leverages the properties of irrational numbers (e.g.,$\pi$) for memory-efficient training. The core idea is based on ourmathematical findings, which show that a pair of parameters can be representedby a single rotation angle using the complex rotation scheme. Building on thisinsight, we map the parameters into a complex space and perform quantizationusing the corresponding rotation angles. To efficiently integrate it intooptimization process, we develop an efficient system of geometric equationsthat computes the precise rotation angles with linear complexity. We evaluate$\pi$-Quant on a wide range of tasks. Our experiments show that it can reducethe bit-width of parameters to 3.32-bit, achieving a 75% reduction in parameterscale and a 40% decrease in GPU memory usage, all while maintaining fullaccuracy.</description><author>Zhen Tian, Wayne Xin Zhao, Ji-Rong Wen</author><pubDate>Wed, 22 Jan 2025 14:17:57 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.12896v1</guid></item></channel></rss>