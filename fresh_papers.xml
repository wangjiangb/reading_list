<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/"><channel><title>Arxivfresh papers</title><link></link><description>Arxiv paper</description><language>en-US</language><lastBuildDate>Mon, 11 Sep 2023 14:00:04 GMT</lastBuildDate><generator>rfeed v1.0.0</generator><docs>https://github.com/svpino/rfeed/blob/master/README.md</docs><item><title>On the Actionability of Outcome Prediction</title><link>http://arxiv.org/abs/2309.04470v1</link><description>Predicting future outcomes is a prevalent application of machine learning insocial impact domains. Examples range from predicting student success ineducation to predicting disease risk in healthcare. Practitioners recognizethat the ultimate goal is not just to predict but to act effectively.Increasing evidence suggests that relying on outcome predictions for downstreaminterventions may not have desired results. In most domains there exists a multitude of possible interventions for eachindividual, making the challenge of taking effective action more acute. Evenwhen causal mechanisms connecting the individual's latent states to outcomes iswell understood, in any given instance (a specific student or patient),practitioners still need to infer -- from budgeted measurements of latentstates -- which of many possible interventions will be most effective for thisindividual. With this in mind, we ask: when are accurate predictors of outcomeshelpful for identifying the most suitable intervention? Through a simple model encompassing actions, latent states, and measurements,we demonstrate that pure outcome prediction rarely results in the mosteffective policy for taking actions, even when combined with othermeasurements. We find that except in cases where there is a single decisiveaction for improving the outcome, outcome prediction never maximizes "actionvalue", the utility of taking actions. Making measurements of actionable latentstates, where specific actions lead to desired outcomes, considerably enhancesthe action value compared to outcome prediction, and the degree of improvementdepends on action costs and the outcome model. This analysis emphasizes theneed to go beyond generic outcome prediction in interventional settings byincorporating knowledge of plausible actions and latent states.</description><author>Lydia T. Liu, Solon Barocas, Jon Kleinberg, Karen Levy</author><pubDate>Fri, 08 Sep 2023 18:57:31 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2309.04470v1</guid></item><item><title>Entity Tracking in Language Models</title><link>http://arxiv.org/abs/2305.02363v2</link><description>Keeping track of how states of entities change as a text or dialog unfolds isa key prerequisite to discourse understanding. Yet, there have been fewsystematic investigations into the ability of large language models (LLMs) totrack discourse entities. In this work, we present a task probing to whatextent a language model can infer the final state of an entity given an Englishdescription of the initial state and a series of state-changing operations. Weuse this task to first investigate whether Flan-T5, GPT-3 and GPT-3.5 can trackthe state of entities, and find that only GPT-3.5 models, which have beenpretrained on large amounts of code, exhibit this ability. We then investigatewhether smaller models pretrained primarily on text can learn to trackentities, through finetuning T5 on several training/evaluation splits. Whileperformance degrades for more complex splits, we find that even when evaluatedon a different set of entities from training or longer operation sequences, afinetuned model can perform non-trivial entity tracking. Taken together, theseresults suggest that language models can learn to track entities butpretraining on text corpora alone does not make this capacity surface.</description><author>Najoung Kim, Sebastian Schuster</author><pubDate>Fri, 08 Sep 2023 18:51:51 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.02363v2</guid></item><item><title>Generalized Cross-domain Multi-label Few-shot Learning for Chest X-rays</title><link>http://arxiv.org/abs/2309.04462v1</link><description>Real-world application of chest X-ray abnormality classification requiresdealing with several challenges: (i) limited training data; (ii) training andevaluation sets that are derived from different domains; and (iii) classes thatappear during training may have partial overlap with classes of interest duringevaluation. To address these challenges, we present an integrated frameworkcalled Generalized Cross-Domain Multi-Label Few-Shot Learning (GenCDML-FSL).The framework supports overlap in classes during training and evaluation,cross-domain transfer, adopts meta-learning to learn using few trainingsamples, and assumes each chest X-ray image is either normal or associated withone or more abnormalities. Furthermore, we propose Generalized EpisodicTraining (GenET), a training strategy that equips models to operate withmultiple challenges observed in the GenCDML-FSL scenario. Comparisons withwell-established methods such as transfer learning, hybrid transfer learning,and multi-label meta-learning on multiple datasets show the superiority of ourapproach.</description><author>Aroof Aimen, Arsh Verma, Makarand Tapaswi, Narayanan C. Krishnan</author><pubDate>Fri, 08 Sep 2023 18:50:55 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2309.04462v1</guid></item><item><title>Measuring and Improving Chain-of-Thought Reasoning in Vision-Language Models</title><link>http://arxiv.org/abs/2309.04461v1</link><description>Vision-language models (VLMs) have recently demonstrated strong efficacy asvisual assistants that can parse natural queries about the visual content andgenerate human-like outputs. In this work, we explore the ability of thesemodels to demonstrate human-like reasoning based on the perceived information.To address a crucial concern regarding the extent to which their reasoningcapabilities are fully consistent and grounded, we also measure the reasoningconsistency of these models. We achieve this by proposing a chain-of-thought(CoT) based consistency measure. However, such an evaluation requires abenchmark that encompasses both high-level inference and detailed reasoningchains, which is costly. We tackle this challenge by proposing aLLM-Human-in-the-Loop pipeline, which notably reduces cost while simultaneouslyensuring the generation of a high-quality dataset. Based on this pipeline andthe existing coarse-grained annotated dataset, we build the CURE benchmark tomeasure both the zero-shot reasoning performance and consistency of VLMs. Weevaluate existing state-of-the-art VLMs, and find that even the best-performingmodel is unable to demonstrate strong visual reasoning capabilities andconsistency, indicating that substantial efforts are required to enable VLMs toperform visual reasoning as systematically and consistently as humans. As anearly step, we propose a two-stage training framework aimed at improving boththe reasoning performance and consistency of VLMs. The first stage involvesemploying supervised fine-tuning of VLMs using step-by-step reasoning samplesautomatically generated by LLMs. In the second stage, we further augment thetraining process by incorporating feedback provided by LLMs to producereasoning chains that are highly consistent and grounded. We empiricallyhighlight the effectiveness of our framework in both reasoning performance andconsistency.</description><author>Yangyi Chen, Karan Sikka, Michael Cogswell, Heng Ji, Ajay Divakaran</author><pubDate>Fri, 08 Sep 2023 18:49:44 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2309.04461v1</guid></item><item><title>Subwords as Skills: Tokenization for Sparse-Reward Reinforcement Learning</title><link>http://arxiv.org/abs/2309.04459v1</link><description>Exploration in sparse-reward reinforcement learning is difficult due to therequirement of long, coordinated sequences of actions in order to achieve anyreward. Moreover, in continuous action spaces there are an infinite number ofpossible actions, which only increases the difficulty of exploration. One classof methods designed to address these issues forms temporally extended actions,often called skills, from interaction data collected in the same domain, andoptimizes a policy on top of this new action space. Typically such methodsrequire a lengthy pretraining phase, especially in continuous action spaces, inorder to form the skills before reinforcement learning can begin. Given priorevidence that the full range of the continuous action space is not required insuch tasks, we propose a novel approach to skill-generation with twocomponents. First we discretize the action space through clustering, and secondwe leverage a tokenization technique borrowed from natural language processingto generate temporally extended actions. Such a method outperforms baselinesfor skill-generation in several challenging sparse-reward domains, and requiresorders-of-magnitude less computation in skill-generation and online rollouts.</description><author>David Yunis, Justin Jung, Falcon Dai, Matthew Walter</author><pubDate>Fri, 08 Sep 2023 18:37:05 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2309.04459v1</guid></item><item><title>Soft-Bellman Equilibrium in Affine Markov Games: Forward Solutions and Inverse Learning</title><link>http://arxiv.org/abs/2304.00163v2</link><description>Markov games model interactions among multiple players in a stochastic,dynamic environment. Each player in a Markov game maximizes its expected totaldiscounted reward, which depends upon the policies of the other players. Weformulate a class of Markov games, termed affine Markov games, where an affinereward function couples the players' actions. We introduce a novel solutionconcept, the soft-Bellman equilibrium, where each player is boundedly rationaland chooses a soft-Bellman policy rather than a purely rational policy as inthe well-known Nash equilibrium concept. We provide conditions for theexistence and uniqueness of the soft-Bellman equilibrium and propose anonlinear least-squares algorithm to compute such an equilibrium in the forwardproblem. We then solve the inverse game problem of inferring the players'reward parameters from observed state-action trajectories via aprojected-gradient algorithm. Experiments in a predator-prey OpenAI Gymenvironment show that the reward parameters inferred by the proposed algorithmoutperform those inferred by a baseline algorithm: they reduce theKullback-Leibler divergence between the equilibrium policies and observedpolicies by at least two orders of magnitude.</description><author>Shenghui Chen, Yue Yu, David Fridovich-Keil, Ufuk Topcu</author><pubDate>Fri, 08 Sep 2023 18:33:12 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2304.00163v2</guid></item><item><title>WiSARD: A Labeled Visual and Thermal Image Dataset for Wilderness Search and Rescue</title><link>http://arxiv.org/abs/2309.04453v1</link><description>Sensor-equipped unoccupied aerial vehicles (UAVs) have the potential to helpreduce search times and alleviate safety risks for first responders carryingout Wilderness Search and Rescue (WiSAR) operations, the process of finding andrescuing person(s) lost in wilderness areas. Unfortunately, visual sensorsalone do not address the need for robustness across all the possible terrains,weather, and lighting conditions that WiSAR operations can be conducted in. Theuse of multi-modal sensors, specifically visual-thermal cameras, is critical inenabling WiSAR UAVs to perform in diverse operating conditions. However, due tothe unique challenges posed by the wilderness context, existing datasetbenchmarks are inadequate for developing vision-based algorithms for autonomousWiSAR UAVs. To this end, we present WiSARD, a dataset with roughly 56,000labeled visual and thermal images collected from UAV flights in variousterrains, seasons, weather, and lighting conditions. To the best of ourknowledge, WiSARD is the first large-scale dataset collected with multi-modalsensors for autonomous WiSAR operations. We envision that our dataset willprovide researchers with a diverse and challenging benchmark that can test therobustness of their algorithms when applied to real-world (life-saving)applications.</description><author>Daniel Broyles, Christopher R. Hayner, Karen Leung</author><pubDate>Fri, 08 Sep 2023 18:22:26 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2309.04453v1</guid></item><item><title>Postprocessing of Ensemble Weather Forecasts Using Permutation-invariant Neural Networks</title><link>http://arxiv.org/abs/2309.04452v1</link><description>Statistical postprocessing is used to translate ensembles of raw numericalweather forecasts into reliable probabilistic forecast distributions. In thisstudy, we examine the use of permutation-invariant neural networks for thistask. In contrast to previous approaches, which often operate on ensemblesummary statistics and dismiss details of the ensemble distribution, we proposenetworks which treat forecast ensembles as a set of unordered member forecastsand learn link functions that are by design invariant to permutations of themember ordering. We evaluate the quality of the obtained forecast distributionsin terms of calibration and sharpness, and compare the models against classicaland neural network-based benchmark methods. In case studies addressing thepostprocessing of surface temperature and wind gust forecasts, we demonstratestate-of-the-art prediction quality. To deepen the understanding of the learnedinference process, we further propose a permutation-based importance analysisfor ensemble-valued predictors, which highlights specific aspects of theensemble forecast that are considered important by the trained postprocessingmodels. Our results suggest that most of the relevant information is containedin few ensemble-internal degrees of freedom, which may impact the design offuture ensemble forecasting and postprocessing systems.</description><author>Kevin Höhlein, Benedikt Schulz, Rüdiger Westermann, Sebastian Lerch</author><pubDate>Fri, 08 Sep 2023 18:20:51 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2309.04452v1</guid></item><item><title>A Conditional Generative Chatbot using Transformer Model</title><link>http://arxiv.org/abs/2306.02074v2</link><description>A Chatbot serves as a communication tool between a human user and a machineto achieve an appropriate answer based on the human input. In more recentapproaches, a combination of Natural Language Processing and sequential modelsare used to build a generative Chatbot. The main challenge of these models istheir sequential nature, which leads to less accurate results. To tackle thischallenge, in this paper, a novel architecture is proposed using conditionalWasserstein Generative Adversarial Networks and a transformer model for answergeneration in Chatbots. While the generator of the proposed model consists of afull transformer model to generate an answer, the discriminator includes onlythe encoder part of a transformer model followed by a classifier. To the bestof our knowledge, this is the first time that a generative Chatbot is proposedusing the embedded transformer in both generator and discriminator models.Relying on the parallel computing of the transformer model, the results of theproposed model on the Cornell Movie-Dialog corpus and the Chit-Chat datasetsconfirm the superiority of the proposed model compared to state-of-the-artalternatives using different evaluation metrics.</description><author>Nura Esfandiari, Kourosh Kiani, Razieh Rastgoo</author><pubDate>Fri, 08 Sep 2023 18:15:37 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.02074v2</guid></item><item><title>Demographic Disparities in 1-to-Many Facial Identification</title><link>http://arxiv.org/abs/2309.04447v1</link><description>Most studies to date that have examined demographic variations in facerecognition accuracy have analyzed 1-to-1 matching accuracy, using images thatcould be described as "government ID quality". This paper analyzes the accuracyof 1-to-many facial identification across demographic groups, and in thepresence of blur and reduced resolution in the probe image as might occur in"surveillance camera quality" images. Cumulative match characteristiccurves(CMC) are not appropriate for comparing propensity for rank-onerecognition errors across demographics, and so we introduce three metrics forthis: (1) d' metric between mated and non-mated score distributions, (2)absolute score difference between thresholds in the high-similarity tail of thenon-mated and the low-similarity tail of the mated distribution, and (3)distribution of (mated - non-mated rank one scores) across the set of probeimages. We find that demographic variation in 1-to-many accuracy does notentirely follow what has been observed in 1-to-1 matching accuracy. Also,different from 1-to-1 accuracy, demographic comparison of 1-to-many accuracycan be affected by different numbers of identities and images acrossdemographics. Finally, we show that increased blur in the probe image, orreduced resolution of the face in the probe image, can significantly increasethe false positive identification rate. And we show that the demographicvariation in these high blur or low resolution conditions is much larger formale/ female than for African-American / Caucasian. The point that 1-to-manyaccuracy can potentially collapse in the context of processing "surveillancecamera quality" probe images against a "government ID quality" gallery is animportant one.</description><author>Aman Bhatta, Gabriella Pangelinan, Micheal C. King, Kevin W. Bowyer</author><pubDate>Fri, 08 Sep 2023 18:13:22 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2309.04447v1</guid></item><item><title>LoopTune: Optimizing Tensor Computations with Reinforcement Learning</title><link>http://arxiv.org/abs/2309.01825v2</link><description>Advanced compiler technology is crucial for enabling machine learningapplications to run on novel hardware, but traditional compilers fail todeliver performance, popular auto-tuners have long search times andexpert-optimized libraries introduce unsustainable costs. To address this, wedeveloped LoopTune, a deep reinforcement learning compiler that optimizestensor computations in deep learning models for the CPU. LoopTune optimizestensor traversal order while using the ultra-fast lightweight code generatorLoopNest to perform hardware-specific optimizations. With a novel graph-basedrepresentation and action space, LoopTune speeds up LoopNest by 3.2x,generating an order of magnitude faster code than TVM, 2.8x faster thanMetaSchedule, and 1.08x faster than AutoTVM, consistently performing at thelevel of the hand-tuned library Numpy. Moreover, LoopTune tunes code in orderof seconds.</description><author>Dejan Grubisic, Bram Wasti, Chris Cummins, John Mellor-Crummey, Aleksandar Zlateski</author><pubDate>Fri, 08 Sep 2023 18:06:36 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2309.01825v2</guid></item><item><title>Comparative Study of Visual SLAM-Based Mobile Robot Localization Using Fiducial Markers</title><link>http://arxiv.org/abs/2309.04441v1</link><description>This paper presents a comparative study of three modes for mobile robotlocalization based on visual SLAM using fiducial markers (i.e., square-shapedartificial landmarks with a black-and-white grid pattern): SLAM, SLAM with aprior map, and localization with a prior map. The reason for comparing theSLAM-based approaches leveraging fiducial markers is because previous work hasshown their superior performance over feature-only methods, with lesscomputational burden compared to methods that use both feature and markerdetection without compromising the localization performance. The evaluation isconducted using indoor image sequences captured with a hand-held cameracontaining multiple fiducial markers in the environment. The performancemetrics include absolute trajectory error and runtime for the optimizationprocess per frame. In particular, for the last two modes (SLAM and localizationwith a prior map), we evaluate their performances by perturbing the quality ofprior map to study the extent to which each mode is tolerant to suchperturbations. Hardware experiments show consistent trajectory error levelsacross the three modes, with the localization mode exhibiting the shortestruntime among them. Yet, with map perturbations, SLAM with a prior mapmaintains performance, while localization mode degrades in both aspects.</description><author>Jongwon Lee, Su Yeon Choi, David Hanley, Timothy Bretl</author><pubDate>Fri, 08 Sep 2023 18:05:24 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2309.04441v1</guid></item><item><title>Single View Refractive Index Tomography with Neural Fields</title><link>http://arxiv.org/abs/2309.04437v1</link><description>Refractive Index Tomography is an inverse problem in which we seek toreconstruct a scene's 3D refractive field from 2D projected image measurements.The refractive field is not visible itself, but instead affects how the path ofa light ray is continuously curved as it travels through space. Refractivefields appear across a wide variety of scientific applications, fromtranslucent cell samples in microscopy to fields of dark matter bending lightfrom faraway galaxies. This problem poses a unique challenge because therefractive field directly affects the path that light takes, making itsrecovery a non-linear problem. In addition, in contrast with traditionaltomography, we seek to recover the refractive field using a projected imagefrom only a single viewpoint by leveraging knowledge of light sources scatteredthroughout the medium. In this work, we introduce a method that uses acoordinate-based neural network to model the underlying continuous refractivefield in a scene. We then use explicit modeling of rays' 3D spatial curvatureto optimize the parameters of this network, reconstructing refractive fieldswith an analysis-by-synthesis approach. The efficacy of our approach isdemonstrated by recovering refractive fields in simulation, and analyzing howrecovery is affected by the light source distribution. We then test our methodon a simulated dark matter mapping problem, where we recover the refractivefield underlying a realistic simulated dark matter distribution.</description><author>Brandon Zhao, Aviad Levis, Liam Connor, Pratul P. Srinivasan, Katherine L. Bouman</author><pubDate>Fri, 08 Sep 2023 18:01:34 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2309.04437v1</guid></item><item><title>Variations and Relaxations of Normalizing Flows</title><link>http://arxiv.org/abs/2309.04433v1</link><description>Normalizing Flows (NFs) describe a class of models that express a complextarget distribution as the composition of a series of bijective transformationsover a simpler base distribution. By limiting the space of candidatetransformations to diffeomorphisms, NFs enjoy efficient, exact sampling anddensity evaluation, enabling NFs to flexibly behave as both discriminative andgenerative models. Their restriction to diffeomorphisms, however, enforces thatinput, output and all intermediary spaces share the same dimension, limitingtheir ability to effectively represent target distributions with complextopologies. Additionally, in cases where the prior and target distributions arenot homeomorphic, Normalizing Flows can leak mass outside of the support of thetarget. This survey covers a selection of recent works that combine aspects ofother generative model classes, such as VAEs and score-based diffusion, and indoing so loosen the strict bijectivity constraints of NFs to achieve a balanceof expressivity, training speed, sample efficiency and likelihood tractability.</description><author>Keegan Kelly, Lorena Piedras, Sukrit Rao, David Roth</author><pubDate>Fri, 08 Sep 2023 17:55:23 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2309.04433v1</guid></item><item><title>Fairguard: Harness Logic-based Fairness Rules in Smart Cities</title><link>http://arxiv.org/abs/2302.11137v7</link><description>Smart cities operate on computational predictive frameworks that collect,aggregate, and utilize data from large-scale sensor networks. However, theseframeworks are prone to multiple sources of data and algorithmic bias, whichoften lead to unfair prediction results. In this work, we first demonstratethat bias persists at a micro-level both temporally and spatially by studyingreal city data from Chattanooga, TN. To alleviate the issue of such bias, weintroduce Fairguard, a micro-level temporal logic-based approach for fair smartcity policy adjustment and generation in complex temporal-spatial domains. TheFairguard framework consists of two phases: first, we develop a staticgenerator that is able to reduce data bias based on temporal logic conditionsby minimizing correlations between selected attributes. Then, to ensurefairness in predictive algorithms, we design a dynamic component to regulateprediction results and generate future fair predictions by harnessing logicrules. Evaluations show that logic-enabled static Fairguard can effectivelyreduce the biased correlations while dynamic Fairguard can guarantee fairnesson protected groups at run-time with minimal impact on overall performance.</description><author>Yiqi Zhao, Ziyan An, Xuqing Gao, Ayan Mukhopadhyay, Meiyi Ma</author><pubDate>Fri, 08 Sep 2023 17:46:02 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2302.11137v7</guid></item><item><title>Create Your World: Lifelong Text-to-Image Diffusion</title><link>http://arxiv.org/abs/2309.04430v1</link><description>Text-to-image generative models can produce diverse high-quality images ofconcepts with a text prompt, which have demonstrated excellent ability in imagegeneration, image translation, etc. We in this work study the problem ofsynthesizing instantiations of a use's own concepts in a never-ending manner,i.e., create your world, where the new concepts from user are quickly learnedwith a few examples. To achieve this goal, we propose a Lifelong text-to-imageDiffusion Model (L2DM), which intends to overcome knowledge "catastrophicforgetting" for the past encountered concepts, and semantic "catastrophicneglecting" for one or more concepts in the text prompt. In respect ofknowledge "catastrophic forgetting", our L2DM framework devises a task-awarememory enhancement module and a elastic-concept distillation module, whichcould respectively safeguard the knowledge of both prior concepts and each pastpersonalized concept. When generating images with a user text prompt, thesolution to semantic "catastrophic neglecting" is that a concept attentionartist module can alleviate the semantic neglecting from concept aspect, and anorthogonal attention module can reduce the semantic binding from attributeaspect. To the end, our model can generate more faithful image across a rangeof continual text prompts in terms of both qualitative and quantitativemetrics, when comparing with the related state-of-the-art models. The code willbe released at https://wenqiliang.github.io/.</description><author>Gan Sun, Wenqi Liang, Jiahua Dong, Jun Li, Zhengming Ding, Yang Cong</author><pubDate>Fri, 08 Sep 2023 17:45:56 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2309.04430v1</guid></item><item><title>Soft Quantization using Entropic Regularization</title><link>http://arxiv.org/abs/2309.04428v1</link><description>The quantization problem aims to find the best possible approximation ofprobability measures on ${\mathbb{R}}^d$ using finite, discrete measures. TheWasserstein distance is a typical choice to measure the quality of theapproximation. This contribution investigates the properties and robustness ofthe entropy-regularized quantization problem, which relaxes the standardquantization problem. The proposed approximation technique naturally adopts thesoftmin function, which is well known for its robustness in terms oftheoretical and practicability standpoints. Moreover, we use theentropy-regularized Wasserstein distance to evaluate the quality of the softquantization problem's approximation, and we implement a stochastic gradientapproach to achieve the optimal solutions. The control parameter in ourproposed method allows for the adjustment of the optimization problem'sdifficulty level, providing significant advantages when dealing withexceptionally challenging problems of interest. As well, this contributionempirically illustrates the performance of the method in various expositions.</description><author>Rajmadan Lakshmanan, Alois Pichler</author><pubDate>Fri, 08 Sep 2023 17:41:26 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2309.04428v1</guid></item><item><title>Robust Representation Learning for Privacy-Preserving Machine Learning: A Multi-Objective Autoencoder Approach</title><link>http://arxiv.org/abs/2309.04427v1</link><description>Several domains increasingly rely on machine learning in their applications.The resulting heavy dependence on data has led to the emergence of various lawsand regulations around data ethics and privacy and growing awareness of theneed for privacy-preserving machine learning (ppML). Current ppML techniquesutilize methods that are either purely based on cryptography, such ashomomorphic encryption, or that introduce noise into the input, such asdifferential privacy. The main criticism given to those techniques is the factthat they either are too slow or they trade off a model s performance forimproved confidentiality. To address this performance reduction, we aim toleverage robust representation learning as a way of encoding our data whileoptimizing the privacy-utility trade-off. Our method centers on trainingautoencoders in a multi-objective manner and then concatenating the latent andlearned features from the encoding part as the encoded form of our data. Such adeep learning-powered encoding can then safely be sent to a third party forintensive training and hyperparameter tuning. With our proposed framework, wecan share our data and use third party tools without being under the threat ofrevealing its original form. We empirically validate our results on unimodaland multimodal settings, the latter following a vertical splitting system andshow improved performance over state-of-the-art.</description><author>Sofiane Ouaari, Ali Burak Ünal, Mete Akgün, Nico Pfeifer</author><pubDate>Fri, 08 Sep 2023 17:41:25 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2309.04427v1</guid></item><item><title>Advanced Computing and Related Applications Leveraging Brain-inspired Spiking Neural Networks</title><link>http://arxiv.org/abs/2309.04426v1</link><description>In the rapid evolution of next-generation brain-inspired artificialintelligence and increasingly sophisticated electromagnetic environment, themost bionic characteristics and anti-interference performance of spiking neuralnetworks show great potential in terms of computational speed, real-timeinformation processing, and spatio-temporal information processing. Dataprocessing. Spiking neural network is one of the cores of brain-like artificialintelligence, which realizes brain-like computing by simulating the structureand information transfer mode of biological neural networks. This papersummarizes the strengths, weaknesses and applicability of five neuronal modelsand analyzes the characteristics of five network topologies; then reviews thespiking neural network algorithms and summarizes the unsupervised learningalgorithms based on synaptic plasticity rules and four types of supervisedlearning algorithms from the perspectives of unsupervised learning andsupervised learning; finally focuses on the review of brain-like neuromorphicchips under research at home and abroad. This paper is intended to providelearning concepts and research orientations for the peers who are new to theresearch field of spiking neural networks through systematic summaries.</description><author>Lyuyang Sima, Joseph Bucukovski, Erwan Carlson, Nicole L. Yien</author><pubDate>Fri, 08 Sep 2023 17:41:08 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2309.04426v1</guid></item><item><title>Frequentist Regret Bounds for Randomized Least-Squares Value Iteration</title><link>http://arxiv.org/abs/1911.00567v7</link><description>We consider the exploration-exploitation dilemma in finite-horizonreinforcement learning (RL). When the state space is large or continuous,traditional tabular approaches are unfeasible and some form of functionapproximation is mandatory. In this paper, we introduce anoptimistically-initialized variant of the popular randomized least-squaresvalue iteration (RLSVI), a model-free algorithm where exploration is induced byperturbing the least-squares approximation of the action-value function. Underthe assumption that the Markov decision process has low-rank transitiondynamics, we prove that the frequentist regret of RLSVI is upper-bounded by$\widetilde O(d^2 H^2 \sqrt{T})$ where $ d $ are the feature dimension, $ H $is the horizon, and $ T $ is the total number of steps. To the best of ourknowledge, this is the first frequentist regret analysis for randomizedexploration with function approximation.</description><author>Andrea Zanette, David Brandfonbrener, Emma Brunskill, Matteo Pirotta, Alessandro Lazaric</author><pubDate>Fri, 08 Sep 2023 17:34:55 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/1911.00567v7</guid></item><item><title>Video Task Decathlon: Unifying Image and Video Tasks in Autonomous Driving</title><link>http://arxiv.org/abs/2309.04422v1</link><description>Performing multiple heterogeneous visual tasks in dynamic scenes is ahallmark of human perception capability. Despite remarkable progress in imageand video recognition via representation learning, current research stillfocuses on designing specialized networks for singular, homogeneous, or simplecombination of tasks. We instead explore the construction of a unified modelfor major image and video recognition tasks in autonomous driving with diverseinput and output structures. To enable such an investigation, we design a newchallenge, Video Task Decathlon (VTD), which includes ten representative imageand video tasks spanning classification, segmentation, localization, andassociation of objects and pixels. On VTD, we develop our unified network,VTDNet, that uses a single structure and a single set of weights for all tentasks. VTDNet groups similar tasks and employs task interaction stages toexchange information within and between task groups. Given the impracticalityof labeling all tasks on all frames, and the performance degradation associatedwith joint training of many tasks, we design a Curriculum training,Pseudo-labeling, and Fine-tuning (CPF) scheme to successfully train VTDNet onall tasks and mitigate performance loss. Armed with CPF, VTDNet significantlyoutperforms its single-task counterparts on most tasks with only 20% overallcomputations. VTD is a promising new direction for exploring the unification ofperception tasks in autonomous driving.</description><author>Thomas E. Huang, Yifan Liu, Luc Van Gool, Fisher Yu</author><pubDate>Fri, 08 Sep 2023 17:33:27 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2309.04422v1</guid></item><item><title>SynthoGestures: A Novel Framework for Synthetic Dynamic Hand Gesture Generation for Driving Scenarios</title><link>http://arxiv.org/abs/2309.04421v1</link><description>Creating a diverse and comprehensive dataset of hand gestures for dynamichuman-machine interfaces in the automotive domain can be challenging andtime-consuming. To overcome this challenge, we propose using synthetic gesturedatasets generated by virtual 3D models. Our framework utilizes Unreal Engineto synthesize realistic hand gestures, offering customization options andreducing the risk of overfitting. Multiple variants, including gesture speed,performance, and hand shape, are generated to improve generalizability. Inaddition, we simulate different camera locations and types, such as RGB,infrared, and depth cameras, without incurring additional time and cost toobtain these cameras. Experimental results demonstrate that our proposedframework,SynthoGestures\footnote{\url{https://github.com/amrgomaaelhady/SynthoGestures}},improves gesture recognition accuracy and can replace or augment real-handdatasets. By saving time and effort in the creation of the data set, our toolaccelerates the development of gesture recognition systems for automotiveapplications.</description><author>Amr Gomaa, Robin Zitt, Guillermo Reyes, Antonio Krüger</author><pubDate>Fri, 08 Sep 2023 17:32:56 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2309.04421v1</guid></item><item><title>Parallel and Limited Data Voice Conversion Using Stochastic Variational Deep Kernel Learning</title><link>http://arxiv.org/abs/2309.04420v1</link><description>Typically, voice conversion is regarded as an engineering problem withlimited training data. The reliance on massive amounts of data hinders thepractical applicability of deep learning approaches, which have beenextensively researched in recent years. On the other hand, statistical methodsare effective with limited data but have difficulties in modelling complexmapping functions. This paper proposes a voice conversion method that workswith limited data and is based on stochastic variational deep kernel learning(SVDKL). At the same time, SVDKL enables the use of deep neural networks'expressive capability as well as the high flexibility of the Gaussian processas a Bayesian and non-parametric method. When the conventional kernel iscombined with the deep neural network, it is possible to estimate non-smoothand more complex functions. Furthermore, the model's sparse variationalGaussian process solves the scalability problem and, unlike the exact Gaussianprocess, allows for the learning of a global mapping function for the entireacoustic space. One of the most important aspects of the proposed scheme isthat the model parameters are trained using marginal likelihood optimization,which considers both data fitting and model complexity. Considering thecomplexity of the model reduces the amount of training data by increasing theresistance to overfitting. To evaluate the proposed scheme, we examined themodel's performance with approximately 80 seconds of training data. The resultsindicated that our method obtained a higher mean opinion score, smallerspectral distortion, and better preference tests than the compared methods.</description><author>Mohamadreza Jafaryani, Hamid Sheikhzadeh, Vahid Pourahmadi</author><pubDate>Fri, 08 Sep 2023 17:32:47 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2309.04420v1</guid></item><item><title>Adaptive Reordering Sampler with Neurally Guided MAGSAC</title><link>http://arxiv.org/abs/2111.14093v3</link><description>We propose a new sampler for robust estimators that always selects the samplewith the highest probability of consisting only of inliers. After everyunsuccessful iteration, the inlier probabilities are updated in a principledway via a Bayesian approach. The probabilities obtained by the deep network areused as prior (so-called neural guidance) inside the sampler. Moreover, weintroduce a new loss that exploits, in a geometrically justifiable manner, theorientation and scale that can be estimated for any type of feature, e.g., SIFTor SuperPoint, to estimate two-view geometry. The new loss helps to learnhigher-order information about the underlying scene geometry. Benefiting fromthe new sampler and the proposed loss, we combine the neural guidance with thestate-of-the-art MAGSAC++. Adaptive Reordering Sampler with Neurally GuidedMAGSAC (ARS-MAGSAC) is superior to the state-of-the-art in terms of accuracyand run-time on the PhotoTourism and KITTI datasets for essential andfundamental matrix estimation. The code and trained models are available athttps://github.com/weitong8591/ars_magsac.</description><author>Tong Wei, Jiri Matas, Daniel Barath</author><pubDate>Fri, 08 Sep 2023 17:23:49 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2111.14093v3</guid></item><item><title>Large Content And Behavior Models To Understand, Simulate, And Optimize Content And Behavior</title><link>http://arxiv.org/abs/2309.00359v2</link><description>Shannon, in his seminal paper introducing information theory, divided thecommunication into three levels: technical, semantic, and effectivenss. Whilethe technical level is concerned with accurate reconstruction of transmittedsymbols, the semantic and effectiveness levels deal with the inferred meaningand its effect on the receiver. Thanks to telecommunications, the first levelproblem has produced great advances like the internet. Large Language Models(LLMs) make some progress towards the second goal, but the third level stillremains largely untouched. The third problem deals with predicting andoptimizing communication for desired receiver behavior. LLMs, while showingwide generalization capabilities across a wide range of tasks, are unable tosolve for this. One reason for the underperformance could be a lack of"behavior tokens" in LLMs' training corpora. Behavior tokens define receiverbehavior over a communication, such as shares, likes, clicks, purchases,retweets, etc. While preprocessing data for LLM training, behavior tokens areoften removed from the corpora as noise. Therefore, in this paper, we make someinitial progress towards reintroducing behavior tokens in LLM training. Thetrained models, other than showing similar performance to LLMs on contentunderstanding tasks, show generalization capabilities on behavior simulation,content simulation, behavior understanding, and behavior domain adaptation.Using a wide range of tasks on two corpora, we show results on all thesecapabilities. We call these models Large Content and Behavior Models (LCBMs).Further, to spur more research on LCBMs, we release our new Content BehaviorCorpus (CBC), a repository containing communicator, message, and correspondingreceiver behavior.</description><author>Ashmit Khandelwal, Aditya Agrawal, Aanisha Bhattacharyya, Yaman K Singla, Somesh Singh, Uttaran Bhattacharya, Ishita Dasgupta, Stefano Petrangeli, Rajiv Ratn Shah, Changyou Chen, Balaji Krishnamurthy</author><pubDate>Fri, 08 Sep 2023 17:18:53 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2309.00359v2</guid></item><item><title>DeformToon3D: Deformable 3D Toonification from Neural Radiance Fields</title><link>http://arxiv.org/abs/2309.04410v1</link><description>In this paper, we address the challenging problem of 3D toonification, whichinvolves transferring the style of an artistic domain onto a target 3D facewith stylized geometry and texture. Although fine-tuning a pre-trained 3D GANon the artistic domain can produce reasonable performance, this strategy haslimitations in the 3D domain. In particular, fine-tuning can deteriorate theoriginal GAN latent space, which affects subsequent semantic editing, andrequires independent optimization and storage for each new style, limitingflexibility and efficient deployment. To overcome these challenges, we proposeDeformToon3D, an effective toonification framework tailored for hierarchical 3DGAN. Our approach decomposes 3D toonification into subproblems of geometry andtexture stylization to better preserve the original latent space. Specifically,we devise a novel StyleField that predicts conditional 3D deformation to aligna real-space NeRF to the style space for geometry stylization. Thanks to theStyleField formulation, which already handles geometry stylization well,texture stylization can be achieved conveniently via adaptive style mixing thatinjects information of the artistic domain into the decoder of the pre-trained3D GAN. Due to the unique design, our method enables flexible style degreecontrol and shape-texture-specific style swap. Furthermore, we achieveefficient training without any real-world 2D-3D training pairs but proxysamples synthesized from off-the-shelf 2D toonification models.</description><author>Junzhe Zhang, Yushi Lan, Shuai Yang, Fangzhou Hong, Quan Wang, Chai Kiat Yeo, Ziwei Liu, Chen Change Loy</author><pubDate>Fri, 08 Sep 2023 17:17:45 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2309.04410v1</guid></item><item><title>On Large Language Models' Selection Bias in Multi-Choice Questions</title><link>http://arxiv.org/abs/2309.03882v2</link><description>Multi-choice questions (MCQs) serve as a common yet important task format inthe research of large language models (LLMs). Our work shows that LLMs exhibitan inherent "selection bias" in MCQs, which refers to LLMs' preferences toselect options located at specific positions (like "Option C"). This bias isprevalent across various LLMs, making their performance vulnerable to optionposition changes in MCQs. We identify that one primary cause resulting inselection bias is option numbering, i.e., the ID symbols A/B/C/D associatedwith the options. To mitigate selection bias, we propose a new method calledPriDe. PriDe first decomposes the observed model prediction distribution intoan intrinsic prediction over option contents and a prior distribution overoption IDs. It then estimates the prior by permutating option contents on asmall number of test samples, which is used to debias the subsequent testsamples. We demonstrate that, as a label-free, inference-time method, PriDeachieves a more effective and computation-efficient debiasing than strongbaselines. We further show that the priors estimated by PriDe generalize wellacross different domains, highlighting its practical potential in broaderscenarios.</description><author>Chujie Zheng, Hao Zhou, Fandong Meng, Jie Zhou, Minlie Huang</author><pubDate>Fri, 08 Sep 2023 16:54:56 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2309.03882v2</guid></item><item><title>MaskDiffusion: Boosting Text-to-Image Consistency with Conditional Mask</title><link>http://arxiv.org/abs/2309.04399v1</link><description>Recent advancements in diffusion models have showcased their impressivecapacity to generate visually striking images. Nevertheless, ensuring a closematch between the generated image and the given prompt remains a persistentchallenge. In this work, we identify that a crucial factor leading to thetext-image mismatch issue is the inadequate cross-modality relation learningbetween the prompt and the output image. To better align the prompt and imagecontent, we advance the cross-attention with an adaptive mask, which isconditioned on the attention maps and the prompt embeddings, to dynamicallyadjust the contribution of each text token to the image features. Thismechanism explicitly diminishes the ambiguity in semantic information embeddingfrom the text encoder, leading to a boost of text-to-image consistency in thesynthesized images. Our method, termed MaskDiffusion, is training-free andhot-pluggable for popular pre-trained diffusion models. When applied to thelatent diffusion models, our MaskDiffusion can significantly improve thetext-to-image consistency with negligible computation overhead compared to theoriginal diffusion models.</description><author>Yupeng Zhou, Daquan Zhou, Zuo-Liang Zhu, Yaxing Wang, Qibin Hou, Jiashi Feng</author><pubDate>Fri, 08 Sep 2023 16:53:37 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2309.04399v1</guid></item><item><title>Binary classification based Monte Carlo simulation</title><link>http://arxiv.org/abs/2307.16035v2</link><description>Acceptance-rejection (AR), Independent Metropolis Hastings (IMH) orimportance sampling (IS) Monte Carlo (MC) simulation algorithms all involvecomputing ratios of probability density functions (pdfs). On the other hand,classifiers discriminate labeled samples produced by a mixture of twodistributions and can be used for approximating the ratio of the twocorresponding pdfs.This bridge between simulation and classification enables usto propose pdf-free versions of pdf-ratio-based simulation algorithms, wherethe ratio is replaced by a surrogate function computed via a classifier. From aprobabilistic modeling perspective, our procedure involves a structured energybased model which can easily be trained and is compatible with the classicalsamplers.</description><author>Elouan Argouarc'h, François Desbouvries</author><pubDate>Fri, 08 Sep 2023 16:47:49 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.16035v2</guid></item><item><title>CSPRD: A Financial Policy Retrieval Dataset for Chinese Stock Market</title><link>http://arxiv.org/abs/2309.04389v1</link><description>In recent years, great advances in pre-trained language models (PLMs) havesparked considerable research focus and achieved promising performance on theapproach of dense passage retrieval, which aims at retrieving relative passagesfrom massive corpus with given questions. However, most of existing datasetsmainly benchmark the models with factoid queries of general commonsense, whilespecialised fields such as finance and economics remain unexplored due to thedeficiency of large-scale and high-quality datasets with expert annotations. Inthis work, we propose a new task, policy retrieval, by introducing the ChineseStock Policy Retrieval Dataset (CSPRD), which provides 700+ prospectus passageslabeled by experienced experts with relevant articles from 10k+ entries in ourcollected Chinese policy corpus. Experiments on lexical, embedding andfine-tuned bi-encoder models show the effectiveness of our proposed CSPRD yetalso suggests ample potential for improvement. Our best performing baselineachieves 56.1% MRR@10, 28.5% NDCG@10, 37.5% Recall@10 and 80.6% Precision@10 ondev set.</description><author>Jinyuan Wang, Hai Zhao, Zhong Wang, Zeyang Zhu, Jinhao Xie, Yong Yu, Yongjian Fei, Yue Huang, Dawei Cheng</author><pubDate>Fri, 08 Sep 2023 16:40:54 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2309.04389v1</guid></item><item><title>Evaluating Deep Learning-based Melanoma Classification using Immunohistochemistry and Routine Histology: A Three Center Study</title><link>http://arxiv.org/abs/2309.03494v2</link><description>Pathologists routinely use immunohistochemical (IHC)-stained tissue slidesagainst MelanA in addition to hematoxylin and eosin (H&amp;E)-stained slides toimprove their accuracy in diagnosing melanomas. The use of diagnostic DeepLearning (DL)-based support systems for automated examination of tissuemorphology and cellular composition has been well studied in standardH&amp;E-stained tissue slides. In contrast, there are few studies that analyze IHCslides using DL. Therefore, we investigated the separate and joint performanceof ResNets trained on MelanA and corresponding H&amp;E-stained slides. The MelanAclassifier achieved an area under receiver operating characteristics curve(AUROC) of 0.82 and 0.74 on out of distribution (OOD)-datasets, similar to theH&amp;E-based benchmark classification of 0.81 and 0.75, respectively. A combinedclassifier using MelanA and H&amp;E achieved AUROCs of 0.85 and 0.81 on the OODdatasets. DL MelanA-based assistance systems show the same performance as thebenchmark H&amp;E classification and may be improved by multi stain classificationto assist pathologists in their clinical routine.</description><author>Christoph Wies, Lucas Schneider, Sarah Haggenmueller, Tabea-Clara Bucher, Sarah Hobelsberger, Markus V. Heppt, Gerardo Ferrara, Eva I. Krieghoff-Henning, Titus J. Brinker</author><pubDate>Fri, 08 Sep 2023 16:38:47 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2309.03494v2</guid></item><item><title>Generalized Differentiable RANSAC</title><link>http://arxiv.org/abs/2212.13185v3</link><description>We propose $\nabla$-RANSAC, a generalized differentiable RANSAC that allowslearning the entire randomized robust estimation pipeline. The proposedapproach enables the use of relaxation techniques for estimating the gradientsin the sampling distribution, which are then propagated through adifferentiable solver. The trainable quality function marginalizes over thescores from all the models estimated within $\nabla$-RANSAC to guide thenetwork learning accurate and useful inlier probabilities or to train featuredetection and matching networks. Our method directly maximizes the probabilityof drawing a good hypothesis, allowing us to learn better samplingdistributions. We test $\nabla$-RANSAC on various real-world scenarios onfundamental and essential matrix estimation, and 3D point cloud registration,outdoors and indoors, with handcrafted and learning-based features. It issuperior to the state-of-the-art in terms of accuracy while running at asimilar speed to its less accurate alternatives. The code and trained modelsare available at https://github.com/weitong8591/differentiable_ransac.</description><author>Tong Wei, Yash Patel, Alexander Shekhovtsov, Jiri Matas, Daniel Barath</author><pubDate>Fri, 08 Sep 2023 16:35:47 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2212.13185v3</guid></item><item><title>Emergent learning in physical systems as feedback-based aging in a glassy landscape</title><link>http://arxiv.org/abs/2309.04382v1</link><description>By training linear physical networks to learn linear transformations, wediscern how their physical properties evolve due to weight update rules. Ourfindings highlight a striking similarity between the learning behaviors of suchnetworks and the processes of aging and memory formation in disordered andglassy systems. We show that the learning dynamics resembles an aging process,where the system relaxes in response to repeated application of the feedbackboundary forces in presence of an input force, thus encoding a memory of theinput-output relationship. With this relaxation comes an increase in thecorrelation length, which is indicated by the two-point correlation functionfor the components of the network. We also observe that the square root of themean-squared error as a function of epoch takes on a non-exponential form,which is a typical feature of glassy systems. This physical interpretationsuggests that by encoding more detailed information into input and feedbackboundary forces, the process of emergent learning can be rather ubiquitous and,thus, serve as a very early physical mechanism, from an evolutionarystandpoint, for learning in biological systems.</description><author>Vidyesh Rao Anisetti, Ananth Kandala, J. M. Schwarz</author><pubDate>Fri, 08 Sep 2023 16:24:55 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2309.04382v1</guid></item><item><title>Generalization Bounds: Perspectives from Information Theory and PAC-Bayes</title><link>http://arxiv.org/abs/2309.04381v1</link><description>A fundamental question in theoretical machine learning is generalization.Over the past decades, the PAC-Bayesian approach has been established as aflexible framework to address the generalization capabilities of machinelearning algorithms, and design new ones. Recently, it has garnered increasedinterest due to its potential applicability for a variety of learningalgorithms, including deep neural networks. In parallel, aninformation-theoretic view of generalization has developed, wherein therelation between generalization and various information measures has beenestablished. This framework is intimately connected to the PAC-Bayesianapproach, and a number of results have been independently discovered in bothstrands. In this monograph, we highlight this strong connection and present aunified treatment of generalization. We present techniques and results that thetwo perspectives have in common, and discuss the approaches and interpretationsthat differ. In particular, we demonstrate how many proofs in the area share amodular structure, through which the underlying ideas can be intuited. We payspecial attention to the conditional mutual information (CMI) framework;analytical studies of the information complexity of learning algorithms; andthe application of the proposed methods to deep learning. This monograph isintended to provide a comprehensive introduction to information-theoreticgeneralization bounds and their connection to PAC-Bayes, serving as afoundation from which the most recent developments are accessible. It is aimedbroadly towards researchers with an interest in generalization and theoreticalmachine learning.</description><author>Fredrik Hellström, Giuseppe Durisi, Benjamin Guedj, Maxim Raginsky</author><pubDate>Fri, 08 Sep 2023 16:23:40 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2309.04381v1</guid></item><item><title>Language Prompt for Autonomous Driving</title><link>http://arxiv.org/abs/2309.04379v1</link><description>A new trend in the computer vision community is to capture objects ofinterest following flexible human command represented by a natural languageprompt. However, the progress of using language prompts in driving scenarios isstuck in a bottleneck due to the scarcity of paired prompt-instance data. Toaddress this challenge, we propose the first object-centric language prompt setfor driving scenes within 3D, multi-view, and multi-frame space, namedNuPrompt. It expands Nuscenes dataset by constructing a total of 35,367language descriptions, each referring to an average of 5.3 object tracks. Basedon the object-text pairs from the new benchmark, we formulate a newprompt-based driving task, \ie, employing a language prompt to predict thedescribed object trajectory across views and frames. Furthermore, we provide asimple end-to-end baseline model based on Transformer, named PromptTrack.Experiments show that our PromptTrack achieves impressive performance onNuPrompt. We hope this work can provide more new insights for the autonomousdriving community. Dataset and Code will be made public at\href{https://github.com/wudongming97/Prompt4Driving}{https://github.com/wudongming97/Prompt4Driving}.</description><author>Dongming Wu, Wencheng Han, Tiancai Wang, Yingfei Liu, Xiangyu Zhang, Jianbing Shen</author><pubDate>Fri, 08 Sep 2023 16:21:07 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2309.04379v1</guid></item><item><title>MI-SegNet: Mutual Information-Based US Segmentation for Unseen Domain Generalization</title><link>http://arxiv.org/abs/2303.12649v2</link><description>Generalization capabilities of learning-based medical image segmentationacross domains are currently limited by the performance degradation caused bythe domain shift, particularly for ultrasound (US) imaging. The quality of USimages heavily relies on carefully tuned acoustic parameters, which vary acrosssonographers, machines, and settings. To improve the generalizability on USimages across domains, we propose MI-SegNet, a novel mutual information (MI)based framework to explicitly disentangle the anatomical and domain featurerepresentations; therefore, robust domain-independent segmentation can beexpected. Two encoders are employed to extract the relevant features for thedisentanglement. The segmentation only uses the anatomical feature map for itsprediction. In order to force the encoders to learn meaningful featurerepresentations a cross-reconstruction method is used during training.Transformations, specific to either domain or anatomy are applied to guide theencoders in their respective feature extraction task. Additionally, any MIpresent in both feature maps is punished to further promote separate featurespaces. We validate the generalizability of the proposed domain-independentsegmentation approach on several datasets with varying parameters and machines.Furthermore, we demonstrate the effectiveness of the proposed MI-SegNet servingas a pre-trained model by comparing it with state-of-the-art networks.</description><author>Yuan Bi, Zhongliang Jiang, Ricarda Clarenbach, Reza Ghotbi, Angelos Karlas, Nassir Navab</author><pubDate>Fri, 08 Sep 2023 16:17:05 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2303.12649v2</guid></item><item><title>MoEController: Instruction-based Arbitrary Image Manipulation with Mixture-of-Expert Controllers</title><link>http://arxiv.org/abs/2309.04372v1</link><description>Diffusion-model-based text-guided image generation has recently madeastounding progress, producing fascinating results in open-domain imagemanipulation tasks. Few models, however, currently have complete zero-shotcapabilities for both global and local image editing due to the complexity anddiversity of image manipulation tasks. In this work, we propose a method with amixture-of-expert (MOE) controllers to align the text-guided capacity ofdiffusion models with different kinds of human instructions, enabling our modelto handle various open-domain image manipulation tasks with natural languageinstructions. First, we use large language models (ChatGPT) and conditionalimage synthesis models (ControlNet) to generate a large number of global imagetransfer dataset in addition to the instruction-based local image editingdataset. Then, using an MOE technique and task-specific adaptation training ona large-scale dataset, our conditional diffusion model can edit images globallyand locally. Extensive experiments demonstrate that our approach performssurprisingly well on various image manipulation tasks when dealing withopen-domain images and arbitrary human instructions. Please refer to ourproject page: [https://oppo-mente-lab.github.io/moe_controller/]</description><author>Sijia Li, Chen Chen, Haonan Lu</author><pubDate>Fri, 08 Sep 2023 16:06:05 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2309.04372v1</guid></item><item><title>Seeing-Eye Quadruped Navigation with Force Responsive Locomotion Control</title><link>http://arxiv.org/abs/2309.04370v1</link><description>Seeing-eye robots are very useful tools for guiding visually impaired people,potentially producing a huge societal impact given the low availability andhigh cost of real guide dogs. Although a few seeing-eye robot systems havealready been demonstrated, none considered external tugs from humans, whichfrequently occur in a real guide dog setting. In this paper, we simultaneouslytrain a locomotion controller that is robust to external tugging forces viaReinforcement Learning (RL), and an external force estimator via supervisedlearning. The controller ensures stable walking, and the force estimatorenables the robot to respond to the external forces from the human. Theseforces are used to guide the robot to the global goal, which is unknown to therobot, while the robot guides the human around nearby obstacles via a localplanner. Experimental results in simulation and on hardware show that ourcontroller is robust to external forces, and our seeing-eye system canaccurately detect force direction. We demonstrate our full seeing-eye robotsystem on a real quadruped robot with a blindfolded human. The video can beseen at our project page: https://bu-air-lab.github.io/guide_dog/</description><author>David DeFazio, Eisuke Hirota, Shiqi Zhang</author><pubDate>Fri, 08 Sep 2023 16:02:46 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2309.04370v1</guid></item><item><title>Beyond Static Datasets: A Deep Interaction Approach to LLM Evaluation</title><link>http://arxiv.org/abs/2309.04369v1</link><description>Large Language Models (LLMs) have made progress in various real-world tasks,which stimulates requirements for the evaluation of LLMs. Existing LLMevaluation methods are mainly supervised signal-based which depends on staticdatasets and cannot evaluate the ability of LLMs in dynamic real-worldscenarios where deep interaction widely exists. Other LLM evaluation methodsare human-based which are costly and time-consuming and are incapable oflarge-scale evaluation of LLMs. To address the issues above, we propose a novelDeep Interaction-based LLM-evaluation framework. In our proposed framework,LLMs' performances in real-world domains can be evaluated from their deepinteraction with other LLMs in elaborately designed evaluation tasks.Furthermore, our proposed framework is a general evaluation method that can beapplied to a host of real-world tasks such as machine translation and codegeneration. We demonstrate the effectiveness of our proposed method throughextensive experiments on four elaborately designed evaluation tasks.</description><author>Jiatong Li, Rui Li, Qi Liu</author><pubDate>Fri, 08 Sep 2023 16:00:41 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2309.04369v1</guid></item><item><title>Streaming algorithms for evaluating noisy judges on unlabeled data -- binary classification</title><link>http://arxiv.org/abs/2306.01726v3</link><description>The evaluation of noisy binary classifiers on unlabeled data is treated as astreaming task: given a data sketch of the decisions by an ensemble, estimatethe true prevalence of the labels as well as each classifier's accuracy onthem. Two fully algebraic evaluators are constructed to do this. Both are basedon the assumption that the classifiers make independent errors. The first isbased on majority voting. The second, the main contribution of the paper, isguaranteed to be correct. But how do we know the classifiers are independent onany given test? This principal/agent monitoring paradox is ameliorated byexploiting the failures of the independent evaluator to return sensibleestimates. A search for nearly error independent trios is empirically carriedout on the \texttt{adult}, \texttt{mushroom}, and \texttt{two-norm} datasets byusing the algebraic failure modes to reject evaluation ensembles as toocorrelated. The searches are refined by constructing a surface in evaluationspace that contains the true value point. The algebra of arbitrarily correlatedclassifiers permits the selection of a polynomial subset free of anycorrelation variables. Candidate evaluation ensembles are rejected if theirdata sketches produce independent estimates too far from the constructedsurface. The results produced by the surviving ensembles can sometimes be asgood as 1\%. But handling even small amounts of correlation remains achallenge. A Taylor expansion of the estimates produced when independence isassumed but the classifiers are, in fact, slightly correlated helps clarify howthe independent evaluator has algebraic `blind spots'.</description><author>Andrés Corrada-Emmanuel</author><pubDate>Fri, 08 Sep 2023 15:56:36 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.01726v3</guid></item><item><title>Emergent communication enhances foraging behaviour in evolved swarms controlled by Spiking Neural Networks</title><link>http://arxiv.org/abs/2212.08484v2</link><description>Social insects such as ants communicate via pheromones which allows them tocoordinate their activity and solve complex tasks as a swarm, e.g. foraging forfood. This behavior was shaped through evolutionary processes. In computationalmodels, self-coordination in swarms has been implemented using probabilistic orsimple action rules to shape the decision of each agent and the collectivebehavior. However, manual tuned decision rules may limit the behavior of theswarm. In this work we investigate the emergence of self-coordination andcommunication in evolved swarms without defining any explicit rule. We evolve aswarm of agents representing an ant colony. We use an evolutionary algorithm tooptimize a spiking neural network (SNN) which serves as an artificial brain tocontrol the behavior of each agent. The goal of the evolved colony is to findoptimal ways to forage for food and return it to the nest in the shortestamount of time. In the evolutionary phase, the ants are able to learn tocollaborate by depositing pheromone near food piles and near the nest to guideother ants. The pheromone usage is not manually encoded into the network;instead, this behavior is established through the optimization procedure. Weobserve that pheromone-based communication enables the ants to perform betterin comparison to colonies where communication via pheromone did not emerge. Weassess the foraging performance by comparing the SNN based model to a rulebased system. Our results show that the SNN based model can efficientlycomplete the foraging task in a short amount of time. Our approach illustratesself coordination via pheromone emerges as a result of the networkoptimization. This work serves as a proof of concept for the possibility ofcreating complex applications utilizing SNNs as underlying architectures formulti-agent interactions where communication and self-coordination is desired.</description><author>Cristian Jimenez Romero, Alper Yegenoglu, Aarón Pérez Martín, Sandra Diaz-Pier, Abigail Morrison</author><pubDate>Fri, 08 Sep 2023 15:56:33 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2212.08484v2</guid></item><item><title>Active Learning for Classifying 2D Grid-Based Level Completability</title><link>http://arxiv.org/abs/2309.04367v1</link><description>Determining the completability of levels generated by procedural generatorssuch as machine learning models can be challenging, as it can involve the useof solver agents that often require a significant amount of time to analyze andsolve levels. Active learning is not yet widely adopted in game evaluations,although it has been used successfully in natural language processing, imageand speech recognition, and computer vision, where the availability of labeleddata is limited or expensive. In this paper, we propose the use of activelearning for learning level completability classification. Through an activelearning approach, we train deep-learning models to classify the completabilityof generated levels for Super Mario Bros., Kid Icarus, and a Zelda-like game.We compare active learning for querying levels to label with completabilityagainst random queries. Our results show using an active learning approach tolabel levels results in better classifier performance with the same amount oflabeled data.</description><author>Mahsa Bazzaz, Seth Cooper</author><pubDate>Fri, 08 Sep 2023 15:56:22 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2309.04367v1</guid></item><item><title>CNN Injected Transformer for Image Exposure Correction</title><link>http://arxiv.org/abs/2309.04366v1</link><description>Capturing images with incorrect exposure settings fails to deliver asatisfactory visual experience. Only when the exposure is properly set, can thecolor and details of the images be appropriately preserved. Previous exposurecorrection methods based on convolutions often produce exposure deviation inimages as a consequence of the restricted receptive field of convolutionalkernels. This issue arises because convolutions are not capable of capturinglong-range dependencies in images accurately. To overcome this challenge, wecan apply the Transformer to address the exposure correction problem,leveraging its capability in modeling long-range dependencies to capture globalrepresentation. However, solely relying on the window-based Transformer leadsto visually disturbing blocking artifacts due to the application ofself-attention in small patches. In this paper, we propose a CNN InjectedTransformer (CIT) to harness the individual strengths of CNN and Transformersimultaneously. Specifically, we construct the CIT by utilizing a window-basedTransformer to exploit the long-range interactions among different regions inthe entire image. Within each CIT block, we incorporate a channel attentionblock (CAB) and a half-instance normalization block (HINB) to assist thewindow-based self-attention to acquire the global statistics and refine localfeatures. In addition to the hybrid architecture design for exposurecorrection, we apply a set of carefully formulated loss functions to improvethe spatial coherence and rectify potential color deviations. Extensiveexperiments demonstrate that our image exposure correction method outperformsstate-of-the-art approaches in terms of both quantitative and qualitativemetrics.</description><author>Shuning Xu, Xiangyu Chen, Binbin Song, Jiantao Zhou</author><pubDate>Fri, 08 Sep 2023 15:53:00 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2309.04366v1</guid></item><item><title>Accurate Neural Network Pruning Requires Rethinking Sparse Optimization</title><link>http://arxiv.org/abs/2308.02060v2</link><description>Obtaining versions of deep neural networks that are both highly-accurate andhighly-sparse is one of the main challenges in the area of model compression,and several high-performance pruning techniques have been investigated by thecommunity. Yet, much less is known about the interaction between sparsity andthe standard stochastic optimization techniques used for training sparsenetworks, and most existing work uses standard dense schedules andhyperparameters for training sparse networks. In this work, we examine theimpact of high sparsity on model training using the standard computer visionand natural language processing sparsity benchmarks. We begin by showing thatusing standard dense training recipes for sparse training is suboptimal, andresults in under-training. We provide new approaches for mitigating this issuefor both sparse pre-training of vision models (e.g. ResNet50/ImageNet) andsparse fine-tuning of language models (e.g. BERT/GLUE), achievingstate-of-the-art results in both settings in the high-sparsity regime, andproviding detailed analyses for the difficulty of sparse training in bothscenarios. Our work sets a new threshold in terms of the accuracies that can beachieved under high sparsity, and should inspire further research intoimproving sparse model training, to reach higher accuracies under highsparsity, but also to do so efficiently.</description><author>Denis Kuznedelev, Eldar Kurtic, Eugenia Iofinova, Elias Frantar, Alexandra Peste, Dan Alistarh</author><pubDate>Fri, 08 Sep 2023 15:45:48 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2308.02060v2</guid></item><item><title>Learning from Power Signals: An Automated Approach to Electrical Disturbance Identification Within a Power Transmission System</title><link>http://arxiv.org/abs/2309.04361v1</link><description>As power quality becomes a higher priority in the electric utility industry,the amount of disturbance event data continues to grow. Utilities do not havethe required personnel to analyze each event by hand. This work presents anautomated approach for analyzing power quality events recorded by digital faultrecorders and power quality monitors operating within a power transmissionsystem. The automated approach leverages rule-based analytics to examine thetime and frequency domain characteristics of the voltage and current signals.Customizable thresholds are set to categorize each disturbance event. Theevents analyzed within this work include various faults, motor starting, andincipient instrument transformer failure. Analytics for fourteen differentevent types have been developed. The analytics were tested on 160 signal filesand yielded an accuracy of ninety-nine percent. Continuous, nominal signal dataanalysis is performed using an approach coined as the cyclic histogram. Thecyclic histogram process will be integrated into the digital fault recordersthemselves to facilitate the detection of subtle signal variations that are toosmall to trigger a disturbance event and that can occur over hours or days. Inaddition to reducing memory requirements by a factor of 320, it is anticipatedthat cyclic histogram processing will aid in identifying incipient events andidentifiers. This project is expected to save engineers time by automating theclassification of disturbance events and increase the reliability of thetransmission system by providing near real time detection and identification ofdisturbances as well as prevention of problems before they occur.</description><author>Jonathan D. Boyd, Joshua H. Tyler, Anthony M. Murphy, Donald R. Reising</author><pubDate>Fri, 08 Sep 2023 15:41:21 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2309.04361v1</guid></item><item><title>SSIG: A Visually-Guided Graph Edit Distance for Floor Plan Similarity</title><link>http://arxiv.org/abs/2309.04357v1</link><description>We propose a simple yet effective metric that measures structural similaritybetween visual instances of architectural floor plans, without the need forlearning. Qualitatively, our experiments show that the retrieval results aresimilar to deeply learned methods. Effectively comparing instances of floorplan data is paramount to the success of machine understanding of floor plandata, including the assessment of floor plan generative models and floor planrecommendation systems. Comparing visual floor plan images goes beyond a solepixel-wise visual examination and is crucially about similarities anddifferences in the shapes and relations between subdivisions that compose thelayout. Currently, deep metric learning approaches are used to learn apair-wise vector representation space that closely mimics the structuralsimilarity, in which the models are trained on similarity labels that areobtained by Intersection-over-Union (IoU). To compensate for the lack ofstructural awareness in IoU, graph-based approaches such as Graph MatchingNetworks (GMNs) are used, which require pairwise inference for comparing datainstances, making GMNs less practical for retrieval applications. In thispaper, an effective evaluation metric for judging the structural similarity offloor plans, coined SSIG (Structural Similarity by IoU and GED), is proposedbased on both image and graph distances. In addition, an efficient algorithm isdeveloped that uses SSIG to rank a large-scale floor plan database. Code willbe openly available.</description><author>Casper van Engelenburg, Seyran Khademi, Jan van Gemert</author><pubDate>Fri, 08 Sep 2023 15:28:28 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2309.04357v1</guid></item><item><title>Graph Neural Network-enabled Terahertz-based Flow-guided Nanoscale Localization</title><link>http://arxiv.org/abs/2307.05551v2</link><description>Scientific advancements in nanotechnology and advanced materials are pavingthe way toward nanoscale devices for in-body precision medicine; comprisingintegrated sensing, computing, communication, data and energy storagecapabilities. In the human cardiovascular system, such devices are envisionedto be passively flowing and continuously sensing for detecting events ofdiagnostic interest. The diagnostic value of detecting such events can beenhanced by assigning to them their physical locations (e.g., body region),which is the main proposition of flow-guided localization. Current flow-guidedlocalization approaches suffer from low localization accuracy and they areby-design unable to localize events within the entire cardiovascular system.Toward addressing this issue, we propose the utilization of Graph NeuralNetworks (GNNs) for this purpose, and demonstrate localization accuracy andcoverage enhancements of our proposal over the existing State of the Art (SotA)approaches. Based on our evaluation, we provide several design guidelines forGNN-enabled flow-guided localization.</description><author>Gerard Calvo Bartra, Filip Lemic, Jakob Struye, Sergi Abadal, Xavier Costa Perez</author><pubDate>Fri, 08 Sep 2023 15:25:40 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.05551v2</guid></item><item><title>Value-Compressed Sparse Column (VCSC): Sparse Matrix Storage for Redundant Data</title><link>http://arxiv.org/abs/2309.04355v1</link><description>Compressed Sparse Column (CSC) and Coordinate (COO) are popular compressionformats for sparse matrices. However, both CSC and COO are general purpose andcannot take advantage of any of the properties of the data other than sparsity,such as data redundancy. Highly redundant sparse data is common in many machinelearning applications, such as genomics, and is often too large for in-corecomputation using conventional sparse storage formats. In this paper, wepresent two extensions to CSC: (1) Value-Compressed Sparse Column (VCSC) and(2) Index- and Value-Compressed Sparse Column (IVCSC). VCSC takes advantage ofhigh redundancy within a column to further compress data up to 3-fold over COOand 2.25-fold over CSC, without significant negative impact to performancecharacteristics. IVCSC extends VCSC by compressing index arrays through deltaencoding and byte-packing, achieving a 10-fold decrease in memory usage overCOO and 7.5-fold decrease over CSC. Our benchmarks on simulated and real datashow that VCSC and IVCSC can be read in compressed form with little addedcomputational cost. These two novel compression formats offer a broadly usefulsolution to encoding and reading redundant sparse data.</description><author>Skyler Ruiter, Seth Wolfgang, Marc Tunnell, Timothy Triche Jr., Erin Carrier, Zachary DeBruine</author><pubDate>Fri, 08 Sep 2023 15:24:40 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2309.04355v1</guid></item><item><title>Mobile V-MoEs: Scaling Down Vision Transformers via Sparse Mixture-of-Experts</title><link>http://arxiv.org/abs/2309.04354v1</link><description>Sparse Mixture-of-Experts models (MoEs) have recently gained popularity dueto their ability to decouple model size from inference efficiency by onlyactivating a small subset of the model parameters for any given input token. Assuch, sparse MoEs have enabled unprecedented scalability, resulting intremendous successes across domains such as natural language processing andcomputer vision. In this work, we instead explore the use of sparse MoEs toscale-down Vision Transformers (ViTs) to make them more attractive forresource-constrained vision applications. To this end, we propose a simplifiedand mobile-friendly MoE design where entire images rather than individualpatches are routed to the experts. We also propose a stable MoE trainingprocedure that uses super-class information to guide the router. We empiricallyshow that our sparse Mobile Vision MoEs (V-MoEs) can achieve a better trade-offbetween performance and efficiency than the corresponding dense ViTs. Forexample, for the ViT-Tiny model, our Mobile V-MoE outperforms its densecounterpart by 3.39% on ImageNet-1k. For an even smaller ViT variant with only54M FLOPs inference cost, our MoE achieves an improvement of 4.66%.</description><author>Erik Daxberger, Floris Weers, Bowen Zhang, Tom Gunter, Ruoming Pang, Marcin Eichner, Michael Emmersberger, Yinfei Yang, Alexander Toshev, Xianzhi Du</author><pubDate>Fri, 08 Sep 2023 15:24:10 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2309.04354v1</guid></item><item><title>SoDaCam: Software-defined Cameras via Single-Photon Imaging</title><link>http://arxiv.org/abs/2309.00066v2</link><description>Reinterpretable cameras are defined by their post-processing capabilitiesthat exceed traditional imaging. We present "SoDaCam" that providesreinterpretable cameras at the granularity of photons, from photon-cubesacquired by single-photon devices. Photon-cubes represent the spatio-temporaldetections of photons as a sequence of binary frames, at frame-rates as high as100 kHz. We show that simple transformations of the photon-cube, or photon-cubeprojections, provide the functionality of numerous imaging systems including:exposure bracketing, flutter shutter cameras, video compressive systems, eventcameras, and even cameras that move during exposure. Our photon-cubeprojections offer the flexibility of being software-defined constructs that areonly limited by what is computable, and shot-noise. We exploit this flexibilityto provide new capabilities for the emulated cameras. As an added benefit, ourprojections provide camera-dependent compression of photon-cubes, which wedemonstrate using an implementation of our projections on a novel computearchitecture that is designed for single-photon imaging.</description><author>Varun Sundar, Andrei Ardelean, Tristan Swedish, Claudio Bruschini, Edoardo Charbon, Mohit Gupta</author><pubDate>Fri, 08 Sep 2023 15:15:50 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2309.00066v2</guid></item><item><title>Zero-Shot Robustification of Zero-Shot Models With Foundation Models</title><link>http://arxiv.org/abs/2309.04344v1</link><description>Zero-shot inference is a powerful paradigm that enables the use of largepretrained models for downstream classification tasks without further training.However, these models are vulnerable to inherited biases that can impact theirperformance. The traditional solution is fine-tuning, but this undermines thekey advantage of pretrained models, which is their ability to be usedout-of-the-box. We propose RoboShot, a method that improves the robustness ofpretrained model embeddings in a fully zero-shot fashion. First, we usezero-shot language models (LMs) to obtain useful insights from taskdescriptions. These insights are embedded and used to remove harmful and boostuseful components in embeddings -- without any supervision. Theoretically, weprovide a simple and tractable model for biases in zero-shot embeddings andgive a result characterizing under what conditions our approach can boostperformance. Empirically, we evaluate RoboShot on nine image and NLPclassification tasks and show an average improvement of 15.98% over severalzero-shot baselines. Additionally, we demonstrate that RoboShot is compatiblewith a variety of pretrained and language models.</description><author>Dyah Adila, Changho Shin, Linrong Cai, Frederic Sala</author><pubDate>Fri, 08 Sep 2023 15:15:47 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2309.04344v1</guid></item><item><title>Revealing the preference for correcting separated aberrations in joint optic-image design</title><link>http://arxiv.org/abs/2309.04342v1</link><description>The joint design of the optical system and the downstream algorithm is achallenging and promising task. Due to the demand for balancing the globaloptimal of imaging systems and the computational cost of physical simulation,existing methods cannot achieve efficient joint design of complex systems suchas smartphones and drones. In this work, starting from the perspective of theoptical design, we characterize the optics with separated aberrations.Additionally, to bridge the hardware and software without gradients, an imagesimulation system is presented to reproduce the genuine imaging procedure oflenses with large field-of-views. As for aberration correction, we propose anetwork to perceive and correct the spatially varying aberrations and validateits superiority over state-of-the-art methods. Comprehensive experiments revealthat the preference for correcting separated aberrations in joint design is asfollows: longitudinal chromatic aberration, lateral chromatic aberration,spherical aberration, field curvature, and coma, with astigmatism coming last.Drawing from the preference, a 10% reduction in the total track length of theconsumer-level mobile phone lens module is accomplished. Moreover, thisprocedure spares more space for manufacturing deviations, realizingextreme-quality enhancement of computational photography. The optimizationparadigm provides innovative insight into the practical joint design ofsophisticated optical systems and post-processing algorithms.</description><author>Jingwen Zhou, Shiqi Chen, Zheng Ren, Wenguan Zhang, Jiapu Yan, Huajun Feng, Qi Li, Yueting Chen</author><pubDate>Fri, 08 Sep 2023 15:12:03 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2309.04342v1</guid></item><item><title>Online Submodular Maximization via Online Convex Optimization</title><link>http://arxiv.org/abs/2309.04339v1</link><description>We study monotone submodular maximization under general matroid constraintsin the online setting. We prove that online optimization of a large class ofsubmodular functions, namely, weighted threshold potential functions, reducesto online convex optimization (OCO). This is precisely because functions inthis class admit a concave relaxation; as a result, OCO policies, coupled withan appropriate rounding scheme, can be used to achieve sublinear regret in thecombinatorial setting. We show that our reduction extends to many differentversions of the online learning problem, including the dynamic regret, bandit,and optimistic-learning settings.</description><author>T. Si-Salem, G. Özcan, I. Nikolaou, E. Terzi, S. Ioannidis</author><pubDate>Fri, 08 Sep 2023 15:08:19 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2309.04339v1</guid></item><item><title>Encoding Multi-Domain Scientific Papers by Ensembling Multiple CLS Tokens</title><link>http://arxiv.org/abs/2309.04333v1</link><description>Many useful tasks on scientific documents, such as topic classification andcitation prediction, involve corpora that span multiple scientific domains.Typically, such tasks are accomplished by representing the text with a vectorembedding obtained from a Transformer's single CLS token. In this paper, weargue that using multiple CLS tokens could make a Transformer better specializeto multiple scientific domains. We present Multi2SPE: it encourages each ofmultiple CLS tokens to learn diverse ways of aggregating token embeddings, thensums them up together to create a single vector representation. We also proposeour new multi-domain benchmark, Multi-SciDocs, to test scientific paper vectorencoders under multi-domain settings. We show that Multi2SPE reduces error byup to 25 percent in multi-domain citation prediction, while requiring only anegligible amount of computation in addition to one BERT forward pass.</description><author>Ronald Seoh, Haw-Shiuan Chang, Andrew McCallum</author><pubDate>Fri, 08 Sep 2023 15:00:29 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2309.04333v1</guid></item><item><title>Graph Neural Networks Use Graphs When They Shouldn't</title><link>http://arxiv.org/abs/2309.04332v1</link><description>Predictions over graphs play a crucial role in various domains, includingsocial networks, molecular biology, medicine, and more. Graph Neural Networks(GNNs) have emerged as the dominant approach for learning on graph data.Instances of graph labeling problems consist of the graph-structure (i.e., theadjacency matrix), along with node-specific feature vectors. In some cases,this graph-structure is non-informative for the predictive task. For instance,molecular properties such as molar mass depend solely on the constituent atoms(node features), and not on the molecular structure. While GNNs have theability to ignore the graph-structure in such cases, it is not clear that theywill. In this work, we show that GNNs actually tend to overfit thegraph-structure in the sense that they use it even when a better solution canbe obtained by ignoring it. We examine this phenomenon with respect todifferent graph distributions and find that regular graphs are more robust tothis overfitting. We then provide a theoretical explanation for thisphenomenon, via analyzing the implicit bias of gradient-descent-based learningof GNNs in this setting. Finally, based on our empirical and theoreticalfindings, we propose a graph-editing method to mitigate the tendency of GNNs tooverfit graph-structures that should be ignored. We show that this methodindeed improves the accuracy of GNNs across multiple benchmarks.</description><author>Maya Bechler-Speicher, Ido Amos, Ran Gilad-Bachrach, Amir Globerson</author><pubDate>Fri, 08 Sep 2023 14:59:18 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2309.04332v1</guid></item><item><title>TREE-G: Decision Trees Contesting Graph Neural Networks</title><link>http://arxiv.org/abs/2207.02760v4</link><description>When dealing with tabular data, models based on decision trees are a popularchoice due to their high accuracy on these data types, their ease ofapplication, and explainability properties. However, when it comes tograph-structured data, it is not clear how to apply them effectively, in a waythat incorporates the topological information with the tabular data availableon the vertices of the graph. To address this challenge, we introduce TREE-G.TREE-G modifies standard decision trees, by introducing a novel split functionthat is specialized for graph data. Not only does this split functionincorporate the node features and the topological information, but it also usesa novel pointer mechanism that allows split nodes to use information computedin previous splits. Therefore, the split function adapts to the predictive taskand the graph at hand. We analyze the theoretical properties of TREE-G anddemonstrate its benefits empirically on multiple graph and vertex predictionbenchmarks. In these experiments, TREE-G consistently outperforms othertree-based models and often outperforms other graph-learning algorithms such asGraph Neural Networks (GNNs) and Graph Kernels, sometimes by large margins.Moreover, TREE-Gs models and their predictions can be explained and visualized</description><author>Maya Bechler-Speicher, Amir Globerson, Ran Gilad-Bachrach</author><pubDate>Fri, 08 Sep 2023 14:59:01 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2207.02760v4</guid></item><item><title>ValiTex -- a unified validation framework for computational text-based measures of social science constructs</title><link>http://arxiv.org/abs/2307.02863v3</link><description>Guidance on how to validate computational text-based measures of socialscience constructs is fragmented. Although scholars generally acknowledge theimportance of validating their text-based measures, they often lack commonterminology and a unified framework to do so. This paper introduces ValiTex, anew validation framework designed to assist scholars in validly measuringsocial science constructs based on textual data. The framework draws on along-established validity concept in psychometrics but extends these conceptsto cover the specific needs of computational text analysis. ValiTex consists oftwo components, a conceptual framework and a dynamic checklist. Whereas theconceptual framework provides a general structure along distinct phases on howto approach validation, the dynamic checklist defines specific validation stepsand provides guidance on which steps might be considered recommendable (i.e.,providing relevant and necessary validation evidence) or optional (i.e., usefulfor providing additional supporting validation evidence). We demonstrate theutility of the framework by applying it to a use case of detecting sexism fromsocial media data</description><author>Lukas Birkenmaier, Claudia Wagner, Clemens Lechner</author><pubDate>Fri, 08 Sep 2023 14:58:45 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.02863v3</guid></item><item><title>Leveraging Model Fusion for Improved License Plate Recognition</title><link>http://arxiv.org/abs/2309.04331v1</link><description>License Plate Recognition (LPR) plays a critical role in variousapplications, such as toll collection, parking management, and traffic lawenforcement. Although LPR has witnessed significant advancements through thedevelopment of deep learning, there has been a noticeable lack of studiesexploring the potential improvements in results by fusing the outputs frommultiple recognition models. This research aims to fill this gap byinvestigating the combination of up to 12 different models usingstraightforward approaches, such as selecting the most confident prediction oremploying majority vote-based strategies. Our experiments encompass a widerange of datasets, revealing substantial benefits of fusion approaches in bothintra- and cross-dataset setups. Essentially, fusing multiple models reducesconsiderably the likelihood of obtaining subpar performance on a particulardataset/scenario. We also found that combining models based on their speed isan appealing approach. Specifically, for applications where the recognitiontask can tolerate some additional time, though not excessively, an effectivestrategy is to combine 4-6 models. These models may not be the most accurateindividually, but their fusion strikes an optimal balance between accuracy andspeed.</description><author>Rayson Laroca, Luiz A. Zanlorensi, Valter Estevam, Rodrigo Minetto, David Menotti</author><pubDate>Fri, 08 Sep 2023 14:55:16 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2309.04331v1</guid></item><item><title>Leveraging the Potential of Novel Data in Power Line Communication of Electricity Grids</title><link>http://arxiv.org/abs/2209.12693v3</link><description>Electricity grids have become an essential part of daily life, even if theyare often not noticed in everyday life. We usually only become particularlyaware of this dependence by the time the electricity grid is no longeravailable. However, significant changes, such as the transition to renewableenergy (photovoltaic, wind turbines, etc.) and an increasing number of energyconsumers with complex load profiles (electric vehicles, home battery systems,etc.), pose new challenges for the electricity grid. To address thesechallenges, we propose two first-of-its-kind datasets based on measurements ina broadband powerline communications (PLC) infrastructure. Both datasets FiN-1and FiN-2, were collected during real practical use in a part of the Germanlow-voltage grid that supplies around 4.4 million people and show more than 13billion datapoints collected by more than 5100 sensors. In addition, we presentdifferent use cases in asset management, grid state visualization, forecasting,predictive maintenance, and novelty detection to highlight the benefits ofthese types of data. For these applications, we particularly highlight the useof novel machine learning architectures to extract rich information fromreal-world data that cannot be captured using traditional approaches. Bypublishing the first large-scale real-world dataset, we aim to shed light onthe previously largely unrecognized potential of PLC data and emphasizemachine-learning-based research in low-voltage distribution networks bypresenting a variety of different use cases.</description><author>Christoph Balada, Max Bondorf, Sheraz Ahmed, Andreas Dengela, Markus Zdrallek</author><pubDate>Fri, 08 Sep 2023 14:38:27 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2209.12693v3</guid></item><item><title>Generating the Ground Truth: Synthetic Data for Label Noise Research</title><link>http://arxiv.org/abs/2309.04318v1</link><description>Most real-world classification tasks suffer from label noise to some extent.Such noise in the data adversely affects the generalization error of learnedmodels and complicates the evaluation of noise-handling methods, as theirperformance cannot be accurately measured without clean labels. In label noiseresearch, typically either noisy or incomplex simulated data are accepted as abaseline, into which additional noise with known properties is injected. Inthis paper, we propose SYNLABEL, a framework that aims to improve upon theaforementioned methodologies. It allows for creating a noiseless datasetinformed by real data, by either pre-specifying or learning a function anddefining it as the ground truth function from which labels are generated.Furthermore, by resampling a number of values for selected features in thefunction domain, evaluating the function and aggregating the resulting labels,each data point can be assigned a soft label or label distribution. Suchdistributions allow for direct injection and quantification of label noise. Thegenerated datasets serve as a clean baseline of adjustable complexity intowhich different types of noise may be introduced. We illustrate how theframework can be applied, how it enables quantification of label noise and howit improves over existing methodologies.</description><author>Sjoerd de Vries, Dirk Thierens</author><pubDate>Fri, 08 Sep 2023 14:31:06 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2309.04318v1</guid></item><item><title>Actor critic learning algorithms for mean-field control with moment neural networks</title><link>http://arxiv.org/abs/2309.04317v1</link><description>We develop a new policy gradient and actor-critic algorithm for solvingmean-field control problems within a continuous time reinforcement learningsetting. Our approach leverages a gradient-based representation of the valuefunction, employing parametrized randomized policies. The learning for both theactor (policy) and critic (value function) is facilitated by a class of momentneural network functions on the Wasserstein space of probability measures, andthe key feature is to sample directly trajectories of distributions. A centralchallenge addressed in this study pertains to the computational treatment of anoperator specific to the mean-field framework. To illustrate the effectivenessof our methods, we provide a comprehensive set of numerical results. Theseencompass diverse examples, including multi-dimensional settings and nonlinearquadratic mean-field control problems with controlled volatility.</description><author>Huyên Pham, Xavier Warin</author><pubDate>Fri, 08 Sep 2023 14:29:57 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2309.04317v1</guid></item><item><title>Incremental Learning of Humanoid Robot Behavior from Natural Interaction and Large Language Models</title><link>http://arxiv.org/abs/2309.04316v1</link><description>Natural-language dialog is key for intuitive human-robot interaction. It canbe used not only to express humans' intents, but also to communicateinstructions for improvement if a robot does not understand a commandcorrectly. Of great importance is to endow robots with the ability to learnfrom such interaction experience in an incremental way to allow them to improvetheir behaviors or avoid mistakes in the future. In this paper, we propose asystem to achieve incremental learning of complex behavior from naturalinteraction, and demonstrate its implementation on a humanoid robot. Buildingon recent advances, we present a system that deploys Large Language Models(LLMs) for high-level orchestration of the robot's behavior, based on the ideaof enabling the LLM to generate Python statements in an interactive console toinvoke both robot perception and action. The interaction loop is closed byfeeding back human instructions, environment observations, and executionresults to the LLM, thus informing the generation of the next statement.Specifically, we introduce incremental prompt learning, which enables thesystem to interactively learn from its mistakes. For that purpose, the LLM cancall another LLM responsible for code-level improvements of the currentinteraction based on human feedback. The improved interaction is then saved inthe robot's memory, and thus retrieved on similar requests. We integrate thesystem in the robot cognitive architecture of the humanoid robot ARMAR-6 andevaluate our methods both quantitatively (in simulation) and qualitatively (insimulation and real-world) by demonstrating generalized incrementally-learnedknowledge.</description><author>Leonard Bärmann, Rainer Kartmann, Fabian Peller-Konrad, Alex Waibel, Tamim Asfour</author><pubDate>Fri, 08 Sep 2023 14:29:05 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2309.04316v1</guid></item><item><title>AMLP:Adaptive Masking Lesion Patches for Self-supervised Medical Image Segmentation</title><link>http://arxiv.org/abs/2309.04312v1</link><description>Self-supervised masked image modeling has shown promising results on naturalimages. However, directly applying such methods to medical images remainschallenging. This difficulty stems from the complexity and distinctcharacteristics of lesions compared to natural images, which impedes effectiverepresentation learning. Additionally, conventional high fixed masking ratiosrestrict reconstructing fine lesion details, limiting the scope of learnableinformation. To tackle these limitations, we propose a novel self-supervisedmedical image segmentation framework, Adaptive Masking Lesion Patches (AMLP).Specifically, we design a Masked Patch Selection (MPS) strategy to identify andfocus learning on patches containing lesions. Lesion regions are scarce yetcritical, making their precise reconstruction vital. To reducemisclassification of lesion and background patches caused by unsupervisedclustering in MPS, we introduce an Attention Reconstruction Loss (ARL) to focuson hard-to-reconstruct patches likely depicting lesions. We further propose aCategory Consistency Loss (CCL) to refine patch categorization based onreconstruction difficulty, strengthening distinction between lesions andbackground. Moreover, we develop an Adaptive Masking Ratio (AMR) strategy thatgradually increases the masking ratio to expand reconstructible information andimprove learning. Extensive experiments on two medical segmentation datasetsdemonstrate AMLP's superior performance compared to existing self-supervisedapproaches. The proposed strategies effectively address limitations in applyingmasked modeling to medical images, tailored to capturing fine lesion detailsvital for segmentation tasks.</description><author>Xiangtao Wang, Ruizhi Wang, Jie Zhou, Thomas Lukasiewicz, Zhenghua Xu</author><pubDate>Fri, 08 Sep 2023 14:18:10 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2309.04312v1</guid></item><item><title>Federated Learning for Early Dropout Prediction on Healthy Ageing Applications</title><link>http://arxiv.org/abs/2309.04311v1</link><description>The provision of social care applications is crucial for elderly people toimprove their quality of life and enables operators to provide earlyinterventions. Accurate predictions of user dropouts in healthy ageingapplications are essential since they are directly related to individual healthstatuses. Machine Learning (ML) algorithms have enabled highly accuratepredictions, outperforming traditional statistical methods that struggle tocope with individual patterns. However, ML requires a substantial amount ofdata for training, which is challenging due to the presence of personalidentifiable information (PII) and the fragmentation posed by regulations. Inthis paper, we present a federated machine learning (FML) approach thatminimizes privacy concerns and enables distributed training, withouttransferring individual data. We employ collaborative training by consideringindividuals and organizations under FML, which models both cross-device andcross-silo learning scenarios. Our approach is evaluated on a real-worlddataset with non-independent and identically distributed (non-iid) data amongclients, class imbalance and label ambiguity. Our results show that dataselection and class imbalance handling techniques significantly improve thepredictive accuracy of models trained under FML, demonstrating comparable orsuperior predictive performance than traditional ML models.</description><author>Christos Chrysanthos Nikolaidis, Vasileios Perifanis, Nikolaos Pavlidis, Pavlos S. Efraimidis</author><pubDate>Fri, 08 Sep 2023 14:17:06 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2309.04311v1</guid></item><item><title>Knowledge-Driven Multi-Agent Reinforcement Learning for Computation Offloading in Cybertwin-Enabled Internet of Vehicles</title><link>http://arxiv.org/abs/2308.02603v2</link><description>By offloading computation-intensive tasks of vehicles to roadside units(RSUs), mobile edge computing (MEC) in the Internet of Vehicles (IoV) canrelieve the onboard computation burden. However, existing model-based taskoffloading methods suffer from heavy computational complexity with the increaseof vehicles and data-driven methods lack interpretability. To address thesechallenges, in this paper, we propose a knowledge-driven multi-agentreinforcement learning (KMARL) approach to reduce the latency of taskoffloading in cybertwin-enabled IoV. Specifically, in the considered scenario,the cybertwin serves as a communication agent for each vehicle to exchangeinformation and make offloading decisions in the virtual space. To reduce thelatency of task offloading, a KMARL approach is proposed to select the optimaloffloading option for each vehicle, where graph neural networks are employed byleveraging domain knowledge concerning graph-structure communication topologyand permutation invariance into neural networks. Numerical results show thatour proposed KMARL yields higher rewards and demonstrates improved scalabilitycompared with other methods, benefitting from the integration of domainknowledge.</description><author>Ruijin Sun, Xiao Yang, Nan Cheng, Xiucheng Wang, Changle Li</author><pubDate>Fri, 08 Sep 2023 14:14:16 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2308.02603v2</guid></item><item><title>LadleNet: Translating Thermal Infrared Images to Visible Light Images Using A Scalable Two-stage U-Net</title><link>http://arxiv.org/abs/2308.06603v2</link><description>The translation of thermal infrared (TIR) images to visible light (VI) imagespresents a challenging task with potential applications spanning variousdomains such as TIR-VI image registration and fusion. Leveraging supplementaryinformation derived from TIR image conversions can significantly enhance modelperformance and generalization across these applications. However, prevailingissues within this field include suboptimal image fidelity and limited modelscalability. In this paper, we introduce an algorithm, LadleNet, based on theU-Net architecture. LadleNet employs a two-stage U-Net concatenation structure,augmented with skip connections and refined feature aggregation techniques,resulting in a substantial enhancement in model performance. Comprising'Handle' and 'Bowl' modules, LadleNet's Handle module facilitates theconstruction of an abstract semantic space, while the Bowl module decodes thissemantic space to yield mapped VI images. The Handle module exhibitsextensibility by allowing the substitution of its network architecture withsemantic segmentation networks, thereby establishing more abstract semanticspaces to bolster model performance. Consequently, we propose LadleNet+, whichreplaces LadleNet's Handle module with the pre-trained DeepLabv3+ network,thereby endowing the model with enhanced semantic space constructioncapabilities. The proposed method is evaluated and tested on the KAIST dataset,accompanied by quantitative and qualitative analyses. Compared to existingmethodologies, our approach achieves state-of-the-art performance in terms ofimage clarity and perceptual quality. The source code will be made available athttps://github.com/Ach-1914/LadleNet/tree/main/.</description><author>Tonghui Zou, Lei Chen</author><pubDate>Fri, 08 Sep 2023 14:03:24 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2308.06603v2</guid></item><item><title>Have We Ever Encountered This Before? Retrieving Out-of-Distribution Road Obstacles from Driving Scenes</title><link>http://arxiv.org/abs/2309.04302v1</link><description>In the life cycle of highly automated systems operating in an open anddynamic environment, the ability to adjust to emerging challenges is crucial.For systems integrating data-driven AI-based components, rapid responses todeployment issues require fast access to related data for testing andreconfiguration. In the context of automated driving, this especially appliesto road obstacles that were not included in the training data, commonlyreferred to as out-of-distribution (OoD) road obstacles. Given the availabilityof large uncurated recordings of driving scenes, a pragmatic approach is toquery a database to retrieve similar scenarios featuring the same safetyconcerns due to OoD road obstacles. In this work, we extend beyond identifyingOoD road obstacles in video streams and offer a comprehensive approach toextract sequences of OoD road obstacles using text queries, thereby proposing away of curating a collection of OoD data for subsequent analysis. Our proposedmethod leverages the recent advances in OoD segmentation and multi-modalfoundation models to identify and efficiently extract safety-relevant scenesfrom unlabeled videos. We present a first approach for the novel task oftext-based OoD object retrieval, which addresses the question ''Have we everencountered this before?''.</description><author>Youssef Shoeb, Robin Chan, Gesina Schwalbe, Azarm Nowzard, Fatma Güney, Hanno Gottschalk</author><pubDate>Fri, 08 Sep 2023 14:02:36 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2309.04302v1</guid></item><item><title>Improving Expressivity of Graph Neural Networks using Localization</title><link>http://arxiv.org/abs/2305.19659v2</link><description>In this paper, we propose localized versions of Weisfeiler-Leman (WL)algorithms in an effort to both increase the expressivity, as well as decreasethe computational overhead. We focus on the specific problem of subgraphcounting and give localized versions of $k-$WL for any $k$. We analyze thepower of Local $k-$WL and prove that it is more expressive than $k-$WL and atmost as expressive as $(k+1)-$WL. We give a characterization of patterns whosecount as a subgraph and induced subgraph are invariant if two graphs are Local$k-$WL equivalent. We also introduce two variants of $k-$WL: Layer $k-$WL andrecursive $k-$WL. These methods are more time and space efficient than applying$k-$WL on the whole graph. We also propose a fragmentation technique thatguarantees the exact count of all induced subgraphs of size at most 4 usingjust $1-$WL. The same idea can be extended further for larger patterns using$k&gt;1$. We also compare the expressive power of Local $k-$WL with other GNNhierarchies and show that given a bound on the time-complexity, our methods aremore expressive than the ones mentioned in Papp and Wattenhofer[2022a].</description><author>Anant Kumar, Shrutimoy Das, Shubhajit Roy, Binita Maity, Anirban Dasgupta</author><pubDate>Fri, 08 Sep 2023 14:02:31 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.19659v2</guid></item><item><title>Locomotion-Action-Manipulation: Synthesizing Human-Scene Interactions in Complex 3D Environments</title><link>http://arxiv.org/abs/2301.02667v2</link><description>Synthesizing interaction-involved human motions has been challenging due tothe high complexity of 3D environments and the diversity of possible humanbehaviors within. We present LAMA, Locomotion-Action-MAnipulation, tosynthesize natural and plausible long-term human movements in complex indoorenvironments. The key motivation of LAMA is to build a unified framework toencompass a series of everyday motions including locomotion, scene interaction,and object manipulation. Unlike existing methods that require motion data"paired" with scanned 3D scenes for supervision, we formulate the problem as atest-time optimization by using human motion capture data only for synthesis.LAMA leverages a reinforcement learning framework coupled with a motionmatching algorithm for optimization, and further exploits a motion editingframework via manifold learning to cover possible variations in interaction andmanipulation. Throughout extensive experiments, we demonstrate that LAMAoutperforms previous approaches in synthesizing realistic motions in variouschallenging scenarios. Project page: https://jiyewise.github.io/projects/LAMA/ .</description><author>Jiye Lee, Hanbyul Joo</author><pubDate>Fri, 08 Sep 2023 13:52:09 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2301.02667v2</guid></item><item><title>Navigating Out-of-Distribution Electricity Load Forecasting during COVID-19: A Continual Learning Approach Leveraging Human Mobility</title><link>http://arxiv.org/abs/2309.04296v1</link><description>In traditional deep learning algorithms, one of the key assumptions is thatthe data distribution remains constant during both training and deployment.However, this assumption becomes problematic when faced withOut-of-Distribution periods, such as the COVID-19 lockdowns, where the datadistribution significantly deviates from what the model has seen duringtraining. This paper employs a two-fold strategy: utilizing continual learningtechniques to update models with new data and harnessing human mobility datacollected from privacy-preserving pedestrian counters located outsidebuildings. In contrast to online learning, which suffers from 'catastrophicforgetting' as newly acquired knowledge often erases prior information,continual learning offers a holistic approach by preserving past insights whileintegrating new data. This research applies FSNet, a powerful continuallearning algorithm, to real-world data from 13 building complexes in Melbourne,Australia, a city which had the second longest total lockdown duration globallyduring the pandemic. Results underscore the crucial role of continual learningin accurate energy forecasting, particularly during Out-of-Distributionperiods. Secondary data such as mobility and temperature provided ancillarysupport to the primary forecasting model. More importantly, while traditionalmethods struggled to adapt during lockdowns, models featuring at least onlinelearning demonstrated resilience, with lockdown periods posing fewer challengesonce armed with adaptive learning techniques. This study contributes valuablemethodologies and insights to the ongoing effort to improve energy loadforecasting during future Out-of-Distribution periods.</description><author>Arian Prabowo, Kaixuan Chen, Hao Xue, Subbu Sethuvenkatraman, Flora D. Salim</author><pubDate>Fri, 08 Sep 2023 13:36:49 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2309.04296v1</guid></item><item><title>Learning a Consensus Sub-Network with Polarization Regularization and One Pass Training</title><link>http://arxiv.org/abs/2302.10798v3</link><description>The subject of green AI has been gaining attention within the deep learningcommunity given the recent trend of ever larger and more complex neural networkmodels. Existing solutions for reducing the computational load of training atinference time usually involve pruning the network parameters. Pruning schemesoften create extra overhead either by iterative training and fine-tuning forstatic pruning or repeated computation of a dynamic pruning graph. We propose anew parameter pruning strategy for learning a lighter-weight sub-network thatminimizes the energy cost while maintaining comparable performance to the fullyparameterised network on given downstream tasks. Our proposed pruning scheme isgreen-oriented, as it only requires a one-off training to discover the optimalstatic sub-networks by dynamic pruning methods. The pruning scheme consists ofa binary gating module and a novel loss function to uncover sub-networks withuser-defined sparsity. Our method enables pruning and training simultaneously,which saves energy in both the training and inference phases and avoids extracomputational overhead from gating modules at inference time. Our results onCIFAR-10 and CIFAR-100 suggest that our scheme can remove 50% of connections indeep networks with less than 1% reduction in classification accuracy. Comparedto other related pruning methods, our method demonstrates a lower drop inaccuracy for equivalent reductions in computational cost.</description><author>Xiaoying Zhi, Varun Babbar, Pheobe Sun, Fran Silavong, Ruibo Shi, Sean Moran</author><pubDate>Fri, 08 Sep 2023 13:36:08 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2302.10798v3</guid></item><item><title>FIMO: A Challenge Formal Dataset for Automated Theorem Proving</title><link>http://arxiv.org/abs/2309.04295v1</link><description>We present FIMO, an innovative dataset comprising formal mathematical problemstatements sourced from the International Mathematical Olympiad (IMO)Shortlisted Problems. Designed to facilitate advanced automated theorem provingat the IMO level, FIMO is currently tailored for the Lean formal language. Itcomprises 149 formal problem statements, accompanied by both informal problemdescriptions and their corresponding LaTeX-based informal proofs. Throughinitial experiments involving GPT-4, our findings underscore the existinglimitations in current methodologies, indicating a substantial journey aheadbefore achieving satisfactory IMO-level automated theorem proving outcomes.</description><author>Chengwu Liu, Jianhao Shen, Huajian Xin, Zhengying Liu, Ye Yuan, Haiming Wang, Wei Ju, Chuanyang Zheng, Yichun Yin, Lin Li, Ming Zhang, Qun Liu</author><pubDate>Fri, 08 Sep 2023 13:34:28 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2309.04295v1</guid></item><item><title>How Can We Tame the Long-Tail of Chest X-ray Datasets?</title><link>http://arxiv.org/abs/2309.04293v1</link><description>Chest X-rays (CXRs) are a medical imaging modality that is used to infer alarge number of abnormalities. While it is hard to define an exhaustive list ofthese abnormalities, which may co-occur on a chest X-ray, few of them are quitecommonly observed and are abundantly represented in CXR datasets used to traindeep learning models for automated inference. However, it is challenging forcurrent models to learn independent discriminatory features for labels that arerare but may be of high significance. Prior works focus on the combination ofmulti-label and long tail problems by introducing novel loss functions or somemechanism of re-sampling or re-weighting the data. Instead, we propose that itis possible to achieve significant performance gains merely by choosing aninitialization for a model that is closer to the domain of the target dataset.This method can complement the techniques proposed in existing literature, andcan easily be scaled to new labels. Finally, we also examine the veracity ofsynthetically generated data to augment the tail labels and analyse itscontribution to improving model performance.</description><author>Arsh Verma</author><pubDate>Fri, 08 Sep 2023 13:28:40 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2309.04293v1</guid></item><item><title>Fuzzy Fingerprinting Transformer Language-Models for Emotion Recognition in Conversations</title><link>http://arxiv.org/abs/2309.04292v1</link><description>Fuzzy Fingerprints have been successfully used as an interpretable textclassification technique, but, like most other techniques, have been largelysurpassed in performance by Large Pre-trained Language Models, such as BERT orRoBERTa. These models deliver state-of-the-art results in several NaturalLanguage Processing tasks, namely Emotion Recognition in Conversations (ERC),but suffer from the lack of interpretability and explainability. In this paper,we propose to combine the two approaches to perform ERC, as a means to obtainsimpler and more interpretable Large Language Models-based classifiers. Wepropose to feed the utterances and their previous conversational turns to apre-trained RoBERTa, obtaining contextual embedding utterance representations,that are then supplied to an adapted Fuzzy Fingerprint classification module.We validate our approach on the widely used DailyDialog ERC benchmark dataset,in which we obtain state-of-the-art level results using a much lighter model.</description><author>Patrícia Pereira, Rui Ribeiro, Helena Moniz, Luisa Coheur, Joao Paulo Carvalho</author><pubDate>Fri, 08 Sep 2023 13:26:01 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2309.04292v1</guid></item><item><title>Driver Profiling and Bayesian Workload Estimation Using Naturalistic Peripheral Detection Study Data</title><link>http://arxiv.org/abs/2303.14720v2</link><description>Monitoring drivers' mental workload facilitates initiating and maintainingsafe interactions with in-vehicle information systems, and thus deliversadaptive human machine interaction with reduced impact on the primary task ofdriving. In this paper, we tackle the problem of workload estimation fromdriving performance data. First, we present a novel on-road study forcollecting subjective workload data via a modified peripheral detection task innaturalistic settings. Key environmental factors that induce a high mentalworkload are identified via video analysis, e.g. junctions and behaviour ofvehicle in front. Second, a supervised learning framework usingstate-of-the-art time series classifiers (e.g. convolutional neural network andtransform techniques) is introduced to profile drivers based on the averageworkload they experience during a journey. A Bayesian filtering approach isthen proposed for sequentially estimating, in (near) real-time, the driver'sinstantaneous workload. This computationally efficient and flexible method canbe easily personalised to a driver (e.g. incorporate their inferred averageworkload profile), adapted to driving/environmental contexts (e.g. road type)and extended with data streams from new sources. The efficacy of the presentedprofiling and instantaneous workload estimation approaches are demonstratedusing the on-road study data, showing $F_{1}$ scores of up to 92% and 81%,respectively.</description><author>Nermin Caber, Bashar I. Ahmad, Jiaming Liang, Simon Godsill, Alexandra Bremers, Philip Thomas, David Oxtoby, Lee Skrypchuk</author><pubDate>Fri, 08 Sep 2023 13:20:23 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2303.14720v2</guid></item><item><title>Sequential Semantic Generative Communication for Progressive Text-to-Image Generation</title><link>http://arxiv.org/abs/2309.04287v1</link><description>This paper proposes new framework of communication system leveragingpromising generation capabilities of multi-modal generative models. Regardingnowadays smart applications, successful communication can be made by conveyingthe perceptual meaning, which we set as text prompt. Text serves as a suitablesemantic representation of image data as it has evolved to instruct an image orgenerate image through multi-modal techniques, by being interpreted in a mannersimilar to human cognition. Utilizing text can also reduce the overloadcompared to transmitting the intact data itself. The transmitter convertsobjective image to text through multi-model generation process and the receiverreconstructs the image using reverse process. Each word in the text sentencehas each syntactic role, responsible for particular piece of information thetext contains. For further efficiency in communication load, the transmittersequentially sends words in priority of carrying the most information untilreaches successful communication. Therefore, our primary focus is on thepromising design of a communication system based on image-to-texttransformation and the proposed schemes for sequentially transmitting wordtokens. Our work is expected to pave a new road of utilizing state-of-the-artgenerative models to real communication systems</description><author>Hyelin Nam, Jihong Park, Jinho Choi, Seong-Lyun Kim</author><pubDate>Fri, 08 Sep 2023 13:17:49 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2309.04287v1</guid></item><item><title>Viewing the process of generating counterfactuals as a source of knowledge -- Application to the Naive Bayes classifier</title><link>http://arxiv.org/abs/2309.04284v1</link><description>There are now many comprehension algorithms for understanding the decisionsof a machine learning algorithm. Among these are those based on the generationof counterfactual examples. This article proposes to view this generationprocess as a source of creating a certain amount of knowledge that can bestored to be used, later, in different ways. This process is illustrated in theadditive model and, more specifically, in the case of the naive Bayesclassifier, whose interesting properties for this purpose are shown.</description><author>Vincent Lemaire, Nathan Le Boudec, Françoise Fessant, Victor Guyomard</author><pubDate>Fri, 08 Sep 2023 13:06:48 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2309.04284v1</guid></item><item><title>Revisiting the Encoding of Satellite Image Time Series</title><link>http://arxiv.org/abs/2305.02086v2</link><description>Satellite Image Time Series (SITS) representation learning is complex due tohigh spatiotemporal resolutions, irregular acquisition times, and intricatespatiotemporal interactions. These challenges result in specialized neuralnetwork architectures tailored for SITS analysis. The field has witnessedpromising results achieved by pioneering researchers, but transferring thelatest advances or established paradigms from Computer Vision (CV) to SITS isstill highly challenging due to the existing suboptimal representation learningframework. In this paper, we develop a novel perspective of SITS processing asa direct set prediction problem, inspired by the recent trend in adoptingquery-based transformer decoders to streamline the object detection or imagesegmentation pipeline. We further propose to decompose the representationlearning process of SITS into three explicit steps: collect-update-distribute,which is computationally efficient and suits for irregularly-sampled andasynchronous temporal satellite observations. Facilitated by the uniquereformulation, our proposed temporal learning backbone of SITS, initiallypre-trained on the resource efficient pixel-set format and then fine-tuned onthe downstream dense prediction tasks, has attained new state-of-the-art (SOTA)results on the PASTIS benchmark dataset. Specifically, the clear separationbetween temporal and spatial components in the semantic/panoptic segmentationpipeline of SITS makes us leverage the latest advances in CV, such as theuniversal image segmentation architecture, resulting in a noticeable 2.5 pointsincrease in mIoU and 8.8 points increase in PQ, respectively, compared to thebest scores reported so far.</description><author>Xin Cai, Yaxin Bi, Peter Nicholl, Roy Sterritt</author><pubDate>Fri, 08 Sep 2023 12:58:41 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.02086v2</guid></item><item><title>Automotive Object Detection via Learning Sparse Events by Spiking Neurons</title><link>http://arxiv.org/abs/2307.12900v3</link><description>Event-based sensors, distinguished by their high temporal resolution of1$\mathrm{\mu s}$ and a dynamic range of 120$\mathrm{dB}$, stand out as idealtools for deployment in fast-paced settings like vehicles and drones.Traditional object detection techniques that utilize Artificial Neural Networks(ANNs) face challenges due to the sparse and asynchronous nature of the eventsthese sensors capture. In contrast, Spiking Neural Networks (SNNs) offer apromising alternative, providing a temporal representation that is inherentlyaligned with event-based data. This paper explores the unique membranepotential dynamics of SNNs and their ability to modulate sparse events. Weintroduce an innovative spike-triggered adaptive threshold mechanism designedfor stable training. Building on these insights, we present a specializedspiking feature pyramid network (SpikeFPN) optimized for automotive event-basedobject detection. Comprehensive evaluations demonstrate that SpikeFPN surpassesboth traditional SNNs and advanced ANNs enhanced with attention mechanisms.Evidently, SpikeFPN achieves a mean Average Precision (mAP) of 0.477 on the{GEN1 Automotive Detection (GAD)} benchmark dataset, marking a significantincrease of 9.7\% over the previous best SNN. Moreover, the efficient design ofSpikeFPN ensures robust performance while optimizing computational resources,attributed to its innate sparse computation capabilities.</description><author>Hu Zhang, Yanchen Li, Luziwei Leng, Kaiwei Che, Qian Liu, Qinghai Guo, Jianxing Liao, Ran Cheng</author><pubDate>Fri, 08 Sep 2023 12:55:57 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.12900v3</guid></item><item><title>Information Geometry of Wasserstein Statistics on Shapes and Affine Deformations</title><link>http://arxiv.org/abs/2307.12508v2</link><description>Information geometry and Wasserstein geometry are two main structuresintroduced in a manifold of probability distributions, and they capture itsdifferent characteristics. We study characteristics of Wasserstein geometry inthe framework of Li and Zhao (2023) for the affine deformation statisticalmodel, which is a multi-dimensional generalization of the location-scale model.We compare merits and demerits of estimators based on information geometry andWasserstein geometry. The shape of a probability distribution and its affinedeformation are separated in the Wasserstein geometry, showing its robustnessagainst the waveform perturbation in exchange for the loss in Fisherefficiency. We show that the Wasserstein estimator is the moment estimator inthe case of the elliptically symmetric affine deformation model. It coincideswith the information-geometrical estimator (maximum-likelihood estimator) whenand only when the waveform is Gaussian. The role of the Wasserstein efficiencyis elucidated in terms of robustness against waveform change.</description><author>Shun-ichi Amari, Takeru Matsuda</author><pubDate>Fri, 08 Sep 2023 12:54:52 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.12508v2</guid></item><item><title>Information Processing Equalities and the Information-Risk Bridge</title><link>http://arxiv.org/abs/2207.11987v2</link><description>We introduce two new classes of measures of information for statisticalexperiments which generalise and subsume $\phi$-divergences, integralprobability metrics, $\mathfrak{N}$-distances (MMD), and $(f,\Gamma)$divergences between two or more distributions. This enables us to derive asimple geometrical relationship between measures of information and the Bayesrisk of a statistical decision problem, thus extending the variational$\phi$-divergence representation to multiple distributions in an entirelysymmetric manner. The new families of divergence are closed under the action ofMarkov operators which yields an information processing equality which is arefinement and generalisation of the classical data processing inequality. Thisequality gives insight into the significance of the choice of the hypothesisclass in classical risk minimization.</description><author>Robert C. Williamson, Zac Cranko</author><pubDate>Fri, 08 Sep 2023 12:48:47 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2207.11987v2</guid></item><item><title>Learning Zero-Sum Linear Quadratic Games with Improved Sample Complexity</title><link>http://arxiv.org/abs/2309.04272v1</link><description>Zero-sum Linear Quadratic (LQ) games are fundamental in optimal control andcan be used (i) as a dynamic game formulation for risk-sensitive or robustcontrol, or (ii) as a benchmark setting for multi-agent reinforcement learningwith two competing agents in continuous state-control spaces. In contrast tothe well-studied single-agent linear quadratic regulator problem, zero-sum LQgames entail solving a challenging nonconvex-nonconcave min-max problem with anobjective function that lacks coercivity. Recently, Zhang et al. discovered animplicit regularization property of natural policy gradient methods which iscrucial for safety-critical control systems since it preserves the robustnessof the controller during learning. Moreover, in the model-free setting wherethe knowledge of model parameters is not available, Zhang et al. proposed thefirst polynomial sample complexity algorithm to reach an$\epsilon$-neighborhood of the Nash equilibrium while maintaining the desirableimplicit regularization property. In this work, we propose a simpler nestedZeroth-Order (ZO) algorithm improving sample complexity by several orders ofmagnitude. Our main result guarantees a$\widetilde{\mathcal{O}}(\epsilon^{-3})$ sample complexity under the sameassumptions using a single-point ZO estimator. Furthermore, when the estimatoris replaced by a two-point estimator, our method enjoys a better$\widetilde{\mathcal{O}}(\epsilon^{-2})$ sample complexity. Our keyimprovements rely on a more sample-efficient nested algorithm design and finercontrol of the ZO natural gradient estimation error.</description><author>Jiduan Wu, Anas Barakat, Ilyas Fatkhullin, Niao He</author><pubDate>Fri, 08 Sep 2023 12:47:31 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2309.04272v1</guid></item><item><title>Avoid Adversarial Adaption in Federated Learning by Multi-Metric Investigations</title><link>http://arxiv.org/abs/2306.03600v2</link><description>Federated Learning (FL) facilitates decentralized machine learning modeltraining, preserving data privacy, lowering communication costs, and boostingmodel performance through diversified data sources. Yet, FL facesvulnerabilities such as poisoning attacks, undermining model integrity withboth untargeted performance degradation and targeted backdoor attacks.Preventing backdoors proves especially challenging due to their stealthynature. Prominent mitigation techniques against poisoning attacks rely on monitoringcertain metrics and filtering malicious model updates. While shown effective inevaluations, we argue that previous works didn't consider realistic real-worldadversaries and data distributions. We define a new notion of strong adaptiveadversaries, capable of adapting to multiple objectives simultaneously. Throughextensive empirical tests, we show that existing defense methods can be easilycircumvented in this adversary model. We also demonstrate, that existingdefenses have limited effectiveness when no assumptions are made aboutunderlying data distributions. We introduce Metric-Cascades (MESAS), a novel defense method for morerealistic scenarios and adversary models. MESAS employs multiple detectionmetrics simultaneously to identify poisoned model updates, creating a complexmulti-objective optimization problem for adaptive attackers. In our extensiveevaluation featuring nine backdoors and three datasets, MESAS consistentlydetects even strong adaptive attackers. Furthermore, MESAS outperforms existingdefenses in distinguishing backdoors from data distribution-related distortionswithin and across clients. MESAS is the first defense robust against strongadaptive adversaries, effective in real-world data scenarios, with an averageoverhead of just 24.37 seconds.</description><author>Torsten Krauß, Alexandra Dmitrienko</author><pubDate>Fri, 08 Sep 2023 12:42:32 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.03600v2</guid></item><item><title>From Sparse to Dense: GPT-4 Summarization with Chain of Density Prompting</title><link>http://arxiv.org/abs/2309.04269v1</link><description>Selecting the ``right'' amount of information to include in a summary is adifficult task. A good summary should be detailed and entity-centric withoutbeing overly dense and hard to follow. To better understand this tradeoff, wesolicit increasingly dense GPT-4 summaries with what we refer to as a ``Chainof Density'' (CoD) prompt. Specifically, GPT-4 generates an initialentity-sparse summary before iteratively incorporating missing salient entitieswithout increasing the length. Summaries generated by CoD are more abstractive,exhibit more fusion, and have less of a lead bias than GPT-4 summariesgenerated by a vanilla prompt. We conduct a human preference study on 100 CNNDailyMail articles and find that that humans prefer GPT-4 summaries that aremore dense than those generated by a vanilla prompt and almost as dense ashuman written summaries. Qualitative analysis supports the notion that thereexists a tradeoff between informativeness and readability. 500 annotated CoDsummaries, as well as an extra 5,000 unannotated summaries, are freelyavailable on HuggingFace(https://huggingface.co/datasets/griffin/chain_of_density).</description><author>Griffin Adams, Alexander Fabbri, Faisal Ladhak, Eric Lehman, Noémie Elhadad</author><pubDate>Fri, 08 Sep 2023 12:31:08 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2309.04269v1</guid></item><item><title>Optimal Rate of Kernel Regression in Large Dimensions</title><link>http://arxiv.org/abs/2309.04268v1</link><description>We perform a study on kernel regression for large-dimensional data (where thesample size $n$ is polynomially depending on the dimension $d$ of the samples,i.e., $n\asymp d^{\gamma}$ for some $\gamma &gt;0$ ). We first build a generaltool to characterize the upper bound and the minimax lower bound of kernelregression for large dimensional data through the Mendelson complexity$\varepsilon_{n}^{2}$ and the metric entropy $\bar{\varepsilon}_{n}^{2}$respectively. When the target function falls into the RKHS associated with a(general) inner product model defined on $\mathbb{S}^{d}$, we utilize the newtool to show that the minimax rate of the excess risk of kernel regression is$n^{-1/2}$ when $n\asymp d^{\gamma}$ for $\gamma =2, 4, 6, 8, \cdots$. We thenfurther determine the optimal rate of the excess risk of kernel regression forall the $\gamma&gt;0$ and find that the curve of optimal rate varying along$\gamma$ exhibits several new phenomena including the {\it multiple descentbehavior} and the {\it periodic plateau behavior}. As an application, For theneural tangent kernel (NTK), we also provide a similar explicit description ofthe curve of optimal rate. As a direct corollary, we know these claims hold forwide neural networks as well.</description><author>Weihao Lu, Haobo Zhang, Yicheng Li, Manyun Xu, Qian Lin</author><pubDate>Fri, 08 Sep 2023 12:29:05 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2309.04268v1</guid></item><item><title>Simple LLM Prompting is State-of-the-Art for Robust and Multilingual Dialogue Evaluation</title><link>http://arxiv.org/abs/2308.16797v2</link><description>Despite significant research effort in the development of automatic dialogueevaluation metrics, little thought is given to evaluating dialogues other thanin English. At the same time, ensuring metrics are invariant to semanticallysimilar responses is also an overlooked topic. In order to achieve the desiredproperties of robustness and multilinguality for dialogue evaluation metrics,we propose a novel framework that takes advantage of the strengths of currentevaluation models with the newly-established paradigm of prompting LargeLanguage Models (LLMs). Empirical results show our framework achieves state ofthe art results in terms of mean Spearman correlation scores across severalbenchmarks and ranks first place on both the Robust and Multilingual tasks ofthe DSTC11 Track 4 "Automatic Evaluation Metrics for Open-Domain DialogueSystems", proving the evaluation capabilities of prompted LLMs.</description><author>John Mendonça, Patrícia Pereira, Helena Moniz, João Paulo Carvalho, Alon Lavie, Isabel Trancoso</author><pubDate>Fri, 08 Sep 2023 12:24:06 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2308.16797v2</guid></item><item><title>Kernelized Normalizing Flows</title><link>http://arxiv.org/abs/2307.14839v2</link><description>Normalising Flows are generative models characterised by their invertiblearchitecture. However, the requirement of invertibility imposes constraints ontheir expressiveness, necessitating a large number of parameters and innovativearchitectural designs to achieve satisfactory outcomes. Whilst flow-basedmodels predominantly rely on neural-network-based transformations forexpressive designs, alternative transformation methods have received limitedattention. In this work, we present Ferumal flow, a novel kernelisednormalising flow paradigm that integrates kernels into the framework. Ourresults demonstrate that a kernelised flow can yield competitive or superiorresults compared to neural network-based flows whilst maintaining parameterefficiency. Kernelised flows excel especially in the low-data regime, enablingflexible non-parametric density estimation in applications with sparse dataavailability.</description><author>Eshant English, Matthias Kirchler, Christoph Lippert</author><pubDate>Fri, 08 Sep 2023 12:22:30 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.14839v2</guid></item><item><title>Constrained Reinforcement Learning using Distributional Representation for Trustworthy Quadrotor UAV Tracking Control</title><link>http://arxiv.org/abs/2302.11694v2</link><description>Simultaneously accurate and reliable tracking control for quadrotors incomplex dynamic environments is challenging. As aerodynamics derived from dragforces and moment variations are chaotic and difficult to precisely identify,most current quadrotor tracking systems treat them as simple `disturbances' inconventional control approaches. We propose a novel, interpretable trajectorytracker integrating a Distributional Reinforcement Learning disturbanceestimator for unknown aerodynamic effects with a Stochastic Model PredictiveController (SMPC). The proposed estimator `Constrained DistributionalReinforced disturbance estimator' (ConsDRED) accurately identifiesuncertainties between true and estimated values of aerodynamic effects.Simplified Affine Disturbance Feedback is used for control parameterization toguarantee convexity, which we then integrate with a SMPC. We theoreticallyguarantee that ConsDRED achieves at least an optimal global convergence rateand a certain sublinear rate if constraints are violated with an errordecreases as the width and the layer of neural network increase. To demonstratepracticality, we show convergent training in simulation and real-worldexperiments, and empirically verify that ConsDRED is less sensitive tohyperparameter settings compared with canonical constrained RL approaches. Wedemonstrate our system improves accumulative tracking errors by at least 70%compared with the recent art. Importantly, the proposed framework,ConsDRED-SMPC, balances the tradeoff between pursuing high performance andobeying conservative constraints for practical implementations</description><author>Yanran Wang, David Boyle</author><pubDate>Fri, 08 Sep 2023 12:17:59 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2302.11694v2</guid></item><item><title>LLMCad: Fast and Scalable On-device Large Language Model Inference</title><link>http://arxiv.org/abs/2309.04255v1</link><description>Generative tasks, such as text generation and question answering, hold acrucial position in the realm of mobile applications. Due to their sensitivityto privacy concerns, there is a growing demand for their execution directly onmobile devices. Currently, the execution of these generative tasks heavilydepends on Large Language Models (LLMs). Nevertheless, the limited memorycapacity of these devices presents a formidable challenge to the scalability ofsuch models. In our research, we introduce LLMCad, an innovative on-device inferenceengine specifically designed for efficient generative Natural LanguageProcessing (NLP) tasks. The core idea behind LLMCad revolves around modelcollaboration: a compact LLM, residing in memory, takes charge of generatingthe most straightforward tokens, while a high-precision LLM steps in tovalidate these tokens and rectify any identified errors. LLMCad incorporatesthree novel techniques: (1) Instead of generating candidate tokens in asequential manner, LLMCad employs the smaller LLM to construct a token tree,encompassing a wider range of plausible token pathways. Subsequently, thelarger LLM can efficiently validate all of these pathways simultaneously. (2)It employs a self-adjusting fallback strategy, swiftly initiating theverification process whenever the smaller LLM generates an erroneous token. (3)To ensure a continuous flow of token generation, LLMCad speculatively generatestokens during the verification process by implementing a compute-IO pipeline.Through an extensive series of experiments, LLMCad showcases an impressivetoken generation speed, achieving rates up to 9.3x faster than existinginference engines.</description><author>Daliang Xu, Wangsong Yin, Xin Jin, Ying Zhang, Shiyun Wei, Mengwei Xu, Xuanzhe Liu</author><pubDate>Fri, 08 Sep 2023 11:44:19 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2309.04255v1</guid></item><item><title>Towards Practical Capture of High-Fidelity Relightable Avatars</title><link>http://arxiv.org/abs/2309.04247v1</link><description>In this paper, we propose a novel framework, Tracking-free Relightable Avatar(TRAvatar), for capturing and reconstructing high-fidelity 3D avatars. Comparedto previous methods, TRAvatar works in a more practical and efficient setting.Specifically, TRAvatar is trained with dynamic image sequences captured in aLight Stage under varying lighting conditions, enabling realistic relightingand real-time animation for avatars in diverse scenes. Additionally, TRAvatarallows for tracking-free avatar capture and obviates the need for accuratesurface tracking under varying illumination conditions. Our contributions aretwo-fold: First, we propose a novel network architecture that explicitly buildson and ensures the satisfaction of the linear nature of lighting. Trained onsimple group light captures, TRAvatar can predict the appearance in real-timewith a single forward pass, achieving high-quality relighting effects underilluminations of arbitrary environment maps. Second, we jointly optimize thefacial geometry and relightable appearance from scratch based on imagesequences, where the tracking is implicitly learned. This tracking-freeapproach brings robustness for establishing temporal correspondences betweenframes under different lighting conditions. Extensive qualitative andquantitative experiments demonstrate that our framework achieves superiorperformance for photorealistic avatar animation and relighting.</description><author>Haotian Yang, Mingwu Zheng, Wanquan Feng, Haibin Huang, Yu-Kun Lai, Pengfei Wan, Zhongyuan Wang, Chongyang Ma</author><pubDate>Fri, 08 Sep 2023 11:26:29 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2309.04247v1</guid></item><item><title>Verifiable Learning for Robust Tree Ensembles</title><link>http://arxiv.org/abs/2305.03626v2</link><description>Verifying the robustness of machine learning models against evasion attacksat test time is an important research problem. Unfortunately, prior workestablished that this problem is NP-hard for decision tree ensembles, hencebound to be intractable for specific inputs. In this paper, we identify arestricted class of decision tree ensembles, called large-spread ensembles,which admit a security verification algorithm running in polynomial time. Wethen propose a new approach called verifiable learning, which advocates thetraining of such restricted model classes which are amenable for efficientverification. We show the benefits of this idea by designing a new trainingalgorithm that automatically learns a large-spread decision tree ensemble fromlabelled data, thus enabling its security verification in polynomial time.Experimental results on public datasets confirm that large-spread ensemblestrained using our algorithm can be verified in a matter of seconds, usingstandard commercial hardware. Moreover, large-spread ensembles are more robustthan traditional ensembles against evasion attacks, at the cost of anacceptable loss of accuracy in the non-adversarial setting.</description><author>Stefano Calzavara, Lorenzo Cazzaro, Giulio Ermanno Pibiri, Nicola Prezza</author><pubDate>Fri, 08 Sep 2023 11:13:25 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.03626v2</guid></item><item><title>Text-to-SQL Empowered by Large Language Models: A Benchmark Evaluation</title><link>http://arxiv.org/abs/2308.15363v2</link><description>Large language models (LLMs) have emerged as a new paradigm for Text-to-SQLtask. However, the absence of a systematical benchmark inhibits the developmentof designing effective, efficient and economic LLM-based Text-to-SQL solutions.To address this challenge, in this paper, we first conduct a systematical andextensive comparison over existing prompt engineering methods, includingquestion representation, example selection and example organization, and withthese experimental results, we elaborate their pros and cons. Based on thesefindings, we propose a new integrated solution, named DAIL-SQL, which refreshesthe Spider leaderboard with 86.6% execution accuracy and sets a new bar. Toexplore the potential of open-source LLM, we investigate them in variousscenarios, and further enhance their performance with supervised fine-tuning.Our explorations highlight open-source LLMs' potential in Text-to-SQL, as wellas the advantages and disadvantages of the supervised fine-tuning.Additionally, towards an efficient and economic LLM-based Text-to-SQL solution,we emphasize the token efficiency in prompt engineering and compare the priorstudies under this metric. We hope that our work provides a deeperunderstanding of Text-to-SQL with LLMs, and inspires further investigations andbroad applications.</description><author>Dawei Gao, Haibin Wang, Yaliang Li, Xiuyu Sun, Yichen Qian, Bolin Ding, Jingren Zhou</author><pubDate>Fri, 08 Sep 2023 11:13:16 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2308.15363v2</guid></item><item><title>The Role of Communication and Reference Songs in the Mixing Process: Insights from Professional Mix Engineers</title><link>http://arxiv.org/abs/2309.03404v2</link><description>Effective music mixing requires technical and creative finesse, but clearcommunication with the client is crucial. The mixing engineer must grasp theclient's expectations, and preferences, and collaborate to achieve the desiredsound. The tacit agreement for the desired sound of the mix is oftenestablished using guides like reference songs and demo mixes exchanged betweenthe artist and the engineer and sometimes verbalised using semantic terms. Thispaper presents the findings of a two-phased exploratory study aimed atunderstanding how professional mixing engineers interact with clients and usetheir feedback to guide the mixing process. For phase one, semi-structuredinterviews were conducted with five mixing engineers with the aim of gatheringinsights about their communication strategies, creative processes, anddecision-making criteria. Based on the inferences from these interviews, anonline questionnaire was designed and administered to a larger group of 22mixing engineers during the second phase. The results of this study shed lighton the importance of collaboration, empathy, and intention in the mixingprocess, and can inform the development of smart multi-track mixing systemsthat better support these practices. By highlighting the significance of thesefindings, this paper contributes to the growing body of research on thecollaborative nature of music production and provides actionablerecommendations for the design and implementation of innovative mixing tools.</description><author>Soumya Sai Vanka, Maryam Safi, Jean-Baptiste Rolland, György Fazekas</author><pubDate>Fri, 08 Sep 2023 11:10:39 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2309.03404v2</guid></item><item><title>MAELi: Masked Autoencoder for Large-Scale LiDAR Point Clouds</title><link>http://arxiv.org/abs/2212.07207v4</link><description>The sensing process of large-scale LiDAR point clouds inevitably causes largeblind spots, i.e. regions not visible to the sensor. We demonstrate how theseinherent sampling properties can be effectively utilized for self-supervisedrepresentation learning by designing a highly effective pre-training frameworkthat considerably reduces the need for tedious 3D annotations to trainstate-of-the-art object detectors. Our Masked AutoEncoder for LiDAR pointclouds (MAELi) intuitively leverages the sparsity of LiDAR point clouds in boththe encoder and decoder during reconstruction. This results in more expressiveand useful initialization, which can be directly applied to downstreamperception tasks, such as 3D object detection or semantic segmentation forautonomous driving. In a novel reconstruction approach, MAELi distinguishesbetween empty and occluded space and employs a new masking strategy thattargets the LiDAR's inherent spherical projection. Thereby, without any groundtruth whatsoever and trained on single frames only, MAELi obtains anunderstanding of the underlying 3D scene geometry and semantics. To demonstratethe potential of MAELi, we pre-train backbones in an end-to-end manner and showthe effectiveness of our unsupervised pre-trained weights on the tasks of 3Dobject detection and semantic segmentation.</description><author>Georg Krispel, David Schinagl, Christian Fruhwirth-Reisinger, Horst Possegger, Horst Bischof</author><pubDate>Fri, 08 Sep 2023 11:10:23 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2212.07207v4</guid></item><item><title>TikTalk: A Video-Based Dialogue Dataset for Multi-Modal Chitchat in Real World</title><link>http://arxiv.org/abs/2301.05880v3</link><description>To facilitate the research on intelligent and human-like chatbots withmulti-modal context, we introduce a new video-based multi-modal dialoguedataset, called TikTalk. We collect 38K videos from a popular video-sharingplatform, along with 367K conversations posted by users beneath them. Usersengage in spontaneous conversations based on their multi-modal experiences fromwatching videos, which helps recreate real-world chitchat context. Compared toprevious multi-modal dialogue datasets, the richer context types in TikTalklead to more diverse conversations, but also increase the difficulty incapturing human interests from intricate multi-modal information to generatepersonalized responses. Moreover, external knowledge is more frequently evokedin our dataset. These facts reveal new challenges for multi-modal dialoguemodels. We quantitatively demonstrate the characteristics of TikTalk, propose avideo-based multi-modal chitchat task, and evaluate several dialogue baselines.Experimental results indicate that the models incorporating large languagemodels (LLM) can generate more diverse responses, while the model utilizingknowledge graphs to introduce external knowledge performs the best overall.Furthermore, no existing model can solve all the above challenges well. Thereis still a large room for future improvements, even for LLM with visualextensions. Our dataset is available at\url{https://ruc-aimind.github.io/projects/TikTalk/}.</description><author>Hongpeng Lin, Ludan Ruan, Wenke Xia, Peiyu Liu, Jingyuan Wen, Yixin Xu, Di Hu, Ruihua Song, Wayne Xin Zhao, Qin Jin, Zhiwu Lu</author><pubDate>Fri, 08 Sep 2023 11:03:16 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2301.05880v3</guid></item><item><title>CyberForce: A Federated Reinforcement Learning Framework for Malware Mitigation</title><link>http://arxiv.org/abs/2308.05978v2</link><description>Recent research has shown that the integration of Reinforcement Learning (RL)with Moving Target Defense (MTD) can enhance cybersecurity inInternet-of-Things (IoT) devices. Nevertheless, the practicality of existingwork is hindered by data privacy concerns associated with centralized dataprocessing in RL, and the unsatisfactory time needed to learn right MTDtechniques that are effective against a rising number of heterogeneous zero-dayattacks. Thus, this work presents CyberForce, a framework that combinesFederated and Reinforcement Learning (FRL) to collaboratively and privatelylearn suitable MTD techniques for mitigating zero-day attacks. CyberForceintegrates device fingerprinting and anomaly detection to reward or penalizeMTD mechanisms chosen by an FRL-based agent. The framework has been deployedand evaluated in a scenario consisting of ten physical devices of a real IoTplatform affected by heterogeneous malware samples. A pool of experiments hasdemonstrated that CyberForce learns the MTD technique mitigating each attackfaster than existing RL-based centralized approaches. In addition, when variousdevices are exposed to different attacks, CyberForce benefits from knowledgetransfer, leading to enhanced performance and reduced learning time incomparison to recent works. Finally, different aggregation algorithms usedduring the agent learning process provide CyberForce with notable robustness tomalicious attacks.</description><author>Chao Feng, Alberto Huertas Celdran, Pedro Miguel Sanchez Sanchez, Jan Kreischer, Jan von der Assen, Gerome Bovet, Gregorio Martinez Perez, Burkhard Stiller</author><pubDate>Fri, 08 Sep 2023 10:57:04 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2308.05978v2</guid></item><item><title>On the Robustness of Post-hoc GNN Explainers to Label Noise</title><link>http://arxiv.org/abs/2309.01706v2</link><description>Proposed as a solution to the inherent black-box limitations of graph neuralnetworks (GNNs), post-hoc GNN explainers aim to provide precise and insightfulexplanations of the behaviours exhibited by trained GNNs. Despite their recentnotable advancements in academic and industrial contexts, the robustness ofpost-hoc GNN explainers remains unexplored when confronted with label noise. Tobridge this gap, we conduct a systematic empirical investigation to evaluatethe efficacy of diverse post-hoc GNN explainers under varying degrees of labelnoise. Our results reveal several key insights: Firstly, post-hoc GNNexplainers are susceptible to label perturbations. Secondly, even minor levelsof label noise, inconsequential to GNN performance, harm the quality ofgenerated explanations substantially. Lastly, we engage in a discourseregarding the progressive recovery of explanation effectiveness with escalatingnoise levels.</description><author>Zhiqiang Zhong, Yangqianzi Jiang, Davide Mottin</author><pubDate>Fri, 08 Sep 2023 10:56:20 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2309.01706v2</guid></item><item><title>Adaptive Distributed Kernel Ridge Regression: A Feasible Distributed Learning Scheme for Data Silos</title><link>http://arxiv.org/abs/2309.04236v1</link><description>Data silos, mainly caused by privacy and interoperability, significantlyconstrain collaborations among different organizations with similar data forthe same purpose. Distributed learning based on divide-and-conquer provides apromising way to settle the data silos, but it suffers from several challenges,including autonomy, privacy guarantees, and the necessity of collaborations.This paper focuses on developing an adaptive distributed kernel ridgeregression (AdaDKRR) by taking autonomy in parameter selection, privacy incommunicating non-sensitive information, and the necessity of collaborations inperformance improvement into account. We provide both solid theoreticalverification and comprehensive experiments for AdaDKRR to demonstrate itsfeasibility and effectiveness. Theoretically, we prove that under some mildconditions, AdaDKRR performs similarly to running the optimal learningalgorithms on the whole data, verifying the necessity of collaborations andshowing that no other distributed learning scheme can essentially beat AdaDKRRunder the same conditions. Numerically, we test AdaDKRR on both toy simulationsand two real-world applications to show that AdaDKRR is superior to otherexisting distributed learning schemes. All these results show that AdaDKRR is afeasible scheme to defend against data silos, which are highly desired innumerous application regions such as intelligent decision-making, pricingforecasting, and performance prediction for products.</description><author>Di Wang, Xiaotong Liu, Shao-Bo Lin, Ding-Xuan Zhou</author><pubDate>Fri, 08 Sep 2023 10:54:36 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2309.04236v1</guid></item><item><title>FIVA: Facial Image and Video Anonymization and Anonymization Defense</title><link>http://arxiv.org/abs/2309.04228v1</link><description>In this paper, we present a new approach for facial anonymization in imagesand videos, abbreviated as FIVA. Our proposed method is able to maintain thesame face anonymization consistently over frames with our suggestedidentity-tracking and guarantees a strong difference from the original face.FIVA allows for 0 true positives for a false acceptance rate of 0.001. Our workconsiders the important security issue of reconstruction attacks andinvestigates adversarial noise, uniform noise, and parameter noise to disruptreconstruction attacks. In this regard, we apply different defense andprotection methods against these privacy threats to demonstrate the scalabilityof FIVA. On top of this, we also show that reconstruction attack models can beused for detection of deep fakes. Last but not least, we provide experimentalresults showing how FIVA can even enable face swapping, which is purely trainedon a single target image.</description><author>Felix Rosberg, Eren Erdal Aksoy, Cristofer Englund, Fernando Alonso-Fernandez</author><pubDate>Fri, 08 Sep 2023 10:34:48 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2309.04228v1</guid></item><item><title>Neuroevolution is a Competitive Alternative to Reinforcement Learning for Skill Discovery</title><link>http://arxiv.org/abs/2210.03516v4</link><description>Deep Reinforcement Learning (RL) has emerged as a powerful paradigm fortraining neural policies to solve complex control tasks. However, thesepolicies tend to be overfit to the exact specifications of the task andenvironment they were trained on, and thus do not perform well when conditionsdeviate slightly or when composed hierarchically to solve even more complextasks. Recent work has shown that training a mixture of policies, as opposed toa single one, that are driven to explore different regions of the state-actionspace can address this shortcoming by generating a diverse set of behaviors,referred to as skills, that can be collectively used to great effect inadaptation tasks or for hierarchical planning. This is typically realized byincluding a diversity term - often derived from information theory - in theobjective function optimized by RL. However these approaches often requirecareful hyperparameter tuning to be effective. In this work, we demonstratethat less widely-used neuroevolution methods, specifically Quality Diversity(QD), are a competitive alternative to information-theory-augmented RL forskill discovery. Through an extensive empirical evaluation comparing eightstate-of-the-art algorithms (four flagship algorithms from each line of work)on the basis of (i) metrics directly evaluating the skills' diversity, (ii) theskills' performance on adaptation tasks, and (iii) the skills' performance whenused as primitives for hierarchical planning; QD methods are found to provideequal, and sometimes improved, performance whilst being less sensitive tohyperparameters and more scalable. As no single method is found to providenear-optimal performance across all environments, there is a rich scope forfurther research which we support by proposing future directions and providingoptimized open-source implementations.</description><author>Felix Chalumeau, Raphael Boige, Bryan Lim, Valentin Macé, Maxime Allard, Arthur Flajolet, Antoine Cully, Thomas Pierrot</author><pubDate>Fri, 08 Sep 2023 10:33:41 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2210.03516v4</guid></item></channel></rss>