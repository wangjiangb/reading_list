<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/"><channel><title>Arxivfresh papers</title><link></link><description>Arxiv paper</description><language>en-US</language><lastBuildDate>Wed, 25 Dec 2024 01:00:29 GMT</lastBuildDate><generator>rfeed v1.0.0</generator><docs>https://github.com/svpino/rfeed/blob/master/README.md</docs><item><title>FaceLift: Single Image to 3D Head with View Generation and GS-LRM</title><link>http://arxiv.org/abs/2412.17812v1</link><description>We present FaceLift, a feed-forward approach for rapid, high-quality,360-degree head reconstruction from a single image. Our pipeline begins byemploying a multi-view latent diffusion model that generates consistent sideand back views of the head from a single facial input. These generated viewsthen serve as input to a GS-LRM reconstructor, which produces a comprehensive3D representation using Gaussian splats. To train our system, we develop adataset of multi-view renderings using synthetic 3D human head as-sets. Thediffusion-based multi-view generator is trained exclusively on synthetic headimages, while the GS-LRM reconstructor undergoes initial training on Objaversefollowed by fine-tuning on synthetic head data. FaceLift excels at preservingidentity and maintaining view consistency across views. Despite being trainedsolely on synthetic data, FaceLift demonstrates remarkable generalization toreal-world images. Through extensive qualitative and quantitative evaluations,we show that FaceLift outperforms state-of-the-art methods in 3D headreconstruction, highlighting its practical applicability and robust performanceon real-world images. In addition to single image reconstruction, FaceLiftsupports video inputs for 4D novel view synthesis and seamlessly integrateswith 2D reanimation techniques to enable 3D facial animation. Project page:https://weijielyu.github.io/FaceLift.</description><author>Weijie Lyu, Yi Zhou, Ming-Hsuan Yang, Zhixin Shu</author><pubDate>Mon, 23 Dec 2024 18:59:49 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.17812v1</guid></item><item><title>ChatGarment: Garment Estimation, Generation and Editing via Large Language Models</title><link>http://arxiv.org/abs/2412.17811v1</link><description>We introduce ChatGarment, a novel approach that leverages largevision-language models (VLMs) to automate the estimation, generation, andediting of 3D garments from images or text descriptions. Unlike previousmethods that struggle in real-world scenarios or lack interactive editingcapabilities, ChatGarment can estimate sewing patterns from in-the-wild imagesor sketches, generate them from text descriptions, and edit garments based onuser instructions, all within an interactive dialogue. These sewing patternscan then be draped into 3D garments, which are easily animatable andsimulatable. This is achieved by finetuning a VLM to directly generate a JSONfile that includes both textual descriptions of garment types and styles, aswell as continuous numerical attributes. This JSON file is then used to createsewing patterns through a programming parametric model. To support this, werefine the existing programming model, GarmentCode, by expanding its garmenttype coverage and simplifying its structure for efficient VLM fine-tuning.Additionally, we construct a large-scale dataset of image-to-sewing-pattern andtext-to-sewing-pattern pairs through an automated data pipeline. Extensiveevaluations demonstrate ChatGarment's ability to accurately reconstruct,generate, and edit garments from multimodal inputs, highlighting its potentialto revolutionize workflows in fashion and gaming applications. Code and datawill be available at https://chatgarment.github.io/.</description><author>Siyuan Bian, Chenghao Xu, Yuliang Xiu, Artur Grigorev, Zhen Liu, Cewu Lu, Michael J. Black, Yao Feng</author><pubDate>Mon, 23 Dec 2024 18:59:28 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.17811v1</guid></item><item><title>Token Statistics Transformer: Linear-Time Attention via Variational Rate Reduction</title><link>http://arxiv.org/abs/2412.17810v1</link><description>The attention operator is arguably the key distinguishing factor oftransformer architectures, which have demonstrated state-of-the-art performanceon a variety of tasks. However, transformer attention operators often impose asignificant computational burden, with the computational complexity scalingquadratically with the number of tokens. In this work, we propose a noveltransformer attention operator whose computational complexity scales linearlywith the number of tokens. We derive our network architecture by extendingprior work which has shown that a transformer style architecture naturallyarises by "white-box" architecture design, where each layer of the network isdesigned to implement an incremental optimization step of a maximal coding ratereduction objective (MCR$^2$). Specifically, we derive a novel variational formof the MCR$^2$ objective and show that the architecture that results fromunrolled gradient descent of this variational objective leads to a newattention module called Token Statistics Self-Attention (TSSA). TSSA has linearcomputational and memory complexity and radically departs from the typicalattention architecture that computes pairwise similarities between tokens.Experiments on vision, language, and long sequence tasks show that simplyswapping TSSA for standard self-attention, which we refer to as the TokenStatistics Transformer (ToST), achieves competitive performance withconventional transformers while being significantly more computationallyefficient and interpretable. Our results also somewhat call into question theconventional wisdom that pairwise similarity style attention mechanisms arecritical to the success of transformer architectures. Code will be available athttps://github.com/RobinWu218/ToST.</description><author>Ziyang Wu, Tianjiao Ding, Yifu Lu, Druv Pai, Jingyuan Zhang, Weida Wang, Yaodong Yu, Yi Ma, Benjamin D. Haeffele</author><pubDate>Mon, 23 Dec 2024 18:59:21 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.17810v1</guid></item><item><title>Learning on Large Graphs using Intersecting Communities</title><link>http://arxiv.org/abs/2405.20724v2</link><description>Message Passing Neural Networks (MPNNs) are a staple of graph machinelearning. MPNNs iteratively update each node's representation in an input graphby aggregating messages from the node's neighbors, which necessitates a memorycomplexity of the order of the number of graph edges. This complexity mightquickly become prohibitive for large graphs provided they are not very sparse.In this paper, we propose a novel approach to alleviate this problem byapproximating the input graph as an intersecting community graph (ICG) -- acombination of intersecting cliques. The key insight is that the number ofcommunities required to approximate a graph does not depend on the graph size.We develop a new constructive version of the Weak Graph Regularity Lemma toefficiently construct an approximating ICG for any input graph. We then devisean efficient graph learning algorithm operating directly on ICG in linearmemory and time with respect to the number of nodes (rather than edges). Thisoffers a new and fundamentally different pipeline for learning on very largenon-sparse graphs, whose applicability is demonstrated empirically on nodeclassification tasks and spatio-temporal data processing.</description><author>Ben Finkelshtein, İsmail İlkan Ceylan, Michael Bronstein, Ron Levie</author><pubDate>Mon, 23 Dec 2024 18:59:16 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.20724v2</guid></item><item><title>Dora: Sampling and Benchmarking for 3D Shape Variational Auto-Encoders</title><link>http://arxiv.org/abs/2412.17808v1</link><description>Recent 3D content generation pipelines commonly employ VariationalAutoencoders (VAEs) to encode shapes into compact latent representations fordiffusion-based generation. However, the widely adopted uniform point samplingstrategy in Shape VAE training often leads to a significant loss of geometricdetails, limiting the quality of shape reconstruction and downstream generationtasks. We present Dora-VAE, a novel approach that enhances VAE reconstructionthrough our proposed sharp edge sampling strategy and a dual cross-attentionmechanism. By identifying and prioritizing regions with high geometriccomplexity during training, our method significantly improves the preservationof fine-grained shape features. Such sampling strategy and the dual attentionmechanism enable the VAE to focus on crucial geometric details that aretypically missed by uniform sampling approaches. To systematically evaluate VAEreconstruction quality, we additionally propose Dora-bench, a benchmark thatquantifies shape complexity through the density of sharp edges, introducing anew metric focused on reconstruction accuracy at these salient geometricfeatures. Extensive experiments on the Dora-bench demonstrate that Dora-VAEachieves comparable reconstruction quality to the state-of-the-art denseXCube-VAE while requiring a latent space at least 8$\times$ smaller (1,280 vs.&gt; 10,000 codes). We will release our code and benchmark dataset to facilitatefuture research in 3D shape modeling.</description><author>Rui Chen, Jianfeng Zhang, Yixun Liang, Guan Luo, Weiyu Li, Jiarui Liu, Xiu Li, Xiaoxiao Long, Jiashi Feng, Ping Tan</author><pubDate>Mon, 23 Dec 2024 18:59:06 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.17808v1</guid></item><item><title>Cross-View Referring Multi-Object Tracking</title><link>http://arxiv.org/abs/2412.17807v1</link><description>Referring Multi-Object Tracking (RMOT) is an important topic in the currenttracking field. Its task form is to guide the tracker to track objects thatmatch the language description. Current research mainly focuses on referringmulti-object tracking under single-view, which refers to a view sequence ormultiple unrelated view sequences. However, in the single-view, someappearances of objects are easily invisible, resulting in incorrect matching ofobjects with the language description. In this work, we propose a new task,called Cross-view Referring Multi-Object Tracking (CRMOT). It introduces thecross-view to obtain the appearances of objects from multiple views, avoidingthe problem of the invisible appearances of objects in RMOT task. CRMOT is amore challenging task of accurately tracking the objects that match thelanguage description and maintaining the identity consistency of objects ineach cross-view. To advance CRMOT task, we construct a cross-view referringmulti-object tracking benchmark based on CAMPUS and DIVOTrack datasets, namedCRTrack. Specifically, it provides 13 different scenes and 221 languagedescriptions. Furthermore, we propose an end-to-end cross-view referringmulti-object tracking method, named CRTracker. Extensive experiments on theCRTrack benchmark verify the effectiveness of our method. The dataset and codeare available at https://github.com/chen-si-jia/CRMOT.</description><author>Sijia Chen, En Yu, Wenbing Tao</author><pubDate>Mon, 23 Dec 2024 18:58:39 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.17807v1</guid></item><item><title>Reconstructing People, Places, and Cameras</title><link>http://arxiv.org/abs/2412.17806v1</link><description>We present "Humans and Structure from Motion" (HSfM), a method for jointlyreconstructing multiple human meshes, scene point clouds, and camera parametersin a metric world coordinate system from a sparse set of uncalibratedmulti-view images featuring people. Our approach combines data-driven scenereconstruction with the traditional Structure-from-Motion (SfM) framework toachieve more accurate scene reconstruction and camera estimation, whilesimultaneously recovering human meshes. In contrast to existing scenereconstruction and SfM methods that lack metric scale information, our methodestimates approximate metric scale by leveraging a human statistical model.Furthermore, it reconstructs multiple human meshes within the same worldcoordinate system alongside the scene point cloud, effectively capturingspatial relationships among individuals and their positions in the environment.We initialize the reconstruction of humans, scenes, and cameras using robustfoundational models and jointly optimize these elements. This jointoptimization synergistically improves the accuracy of each component. Wecompare our method to existing approaches on two challenging benchmarks,EgoHumans and EgoExo4D, demonstrating significant improvements in humanlocalization accuracy within the world coordinate frame (reducing error from3.51m to 1.04m in EgoHumans and from 2.9m to 0.56m in EgoExo4D). Notably, ourresults show that incorporating human data into the SfM pipeline improvescamera pose estimation (e.g., increasing RRA@15 by 20.3% on EgoHumans).Additionally, qualitative results show that our approach improves overall scenereconstruction quality. Our code is available at: muelea.github.io/hsfm.</description><author>Lea Müller, Hongsuk Choi, Anthony Zhang, Brent Yi, Jitendra Malik, Angjoo Kanazawa</author><pubDate>Mon, 23 Dec 2024 18:58:34 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.17806v1</guid></item><item><title>Large Motion Video Autoencoding with Cross-modal Video VAE</title><link>http://arxiv.org/abs/2412.17805v1</link><description>Learning a robust video Variational Autoencoder (VAE) is essential forreducing video redundancy and facilitating efficient video generation. Directlyapplying image VAEs to individual frames in isolation can result in temporalinconsistencies and suboptimal compression rates due to a lack of temporalcompression. Existing Video VAEs have begun to address temporal compression;however, they often suffer from inadequate reconstruction performance. In thispaper, we present a novel and powerful video autoencoder capable ofhigh-fidelity video encoding. First, we observe that entangling spatial andtemporal compression by merely extending the image VAE to a 3D VAE canintroduce motion blur and detail distortion artifacts. Thus, we proposetemporal-aware spatial compression to better encode and decode the spatialinformation. Additionally, we integrate a lightweight motion compression modelfor further temporal compression. Second, we propose to leverage the textualinformation inherent in text-to-video datasets and incorporate text guidanceinto our model. This significantly enhances reconstruction quality,particularly in terms of detail preservation and temporal stability. Third, wefurther improve the versatility of our model through joint training on bothimages and videos, which not only enhances reconstruction quality but alsoenables the model to perform both image and video autoencoding. Extensiveevaluations against strong recent baselines demonstrate the superiorperformance of our method. The project website can be foundat~\href{https://yzxing87.github.io/vae/}{https://yzxing87.github.io/vae/}.</description><author>Yazhou Xing, Yang Fei, Yingqing He, Jingye Chen, Jiaxin Xie, Xiaowei Chi, Qifeng Chen</author><pubDate>Mon, 23 Dec 2024 18:58:24 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.17805v1</guid></item><item><title>GauSim: Registering Elastic Objects into Digital World by Gaussian Simulator</title><link>http://arxiv.org/abs/2412.17804v1</link><description>In this work, we introduce GauSim, a novel neural network-based simulatordesigned to capture the dynamic behaviors of real-world elastic objectsrepresented through Gaussian kernels. Unlike traditional methods that treatkernels as particles within particle-based simulations, we leverage continuummechanics, modeling each kernel as a continuous piece of matter to account forrealistic deformations without idealized assumptions. To improve computationalefficiency and fidelity, we employ a hierarchical structure that organizeskernels into Center of Mass Systems (CMS) with explicit formulations, enablinga coarse-to-fine simulation approach. This structure significantly reducescomputational overhead while preserving detailed dynamics. In addition, GauSimincorporates explicit physics constraints, such as mass and momentumconservation, ensuring interpretable results and robust, physically plausiblesimulations. To validate our approach, we present a new dataset, READY,containing multi-view videos of real-world elastic deformations. Experimentalresults demonstrate that GauSim achieves superior performance compared toexisting physics-driven baselines, offering a practical and accurate solutionfor simulating complex dynamic behaviors. Code and model will be released.Project page: https://www.mmlab-ntu.com/project/gausim/index.html .</description><author>Yidi Shao, Mu Huang, Chen Change Loy, Bo Dai</author><pubDate>Mon, 23 Dec 2024 18:58:17 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.17804v1</guid></item><item><title>Examining Imbalance Effects on Performance and Demographic Fairness of Clinical Language Models</title><link>http://arxiv.org/abs/2412.17803v1</link><description>Data imbalance is a fundamental challenge in applying language models tobiomedical applications, particularly in ICD code prediction tasks where labeland demographic distributions are uneven. While state-of-the-art languagemodels have been increasingly adopted in biomedical tasks, few studies havesystematically examined how data imbalance affects model performance andfairness across demographic groups. This study fills the gap by statisticallyprobing the relationship between data imbalance and model performance in ICDcode prediction. We analyze imbalances in a standard benchmark data acrossgender, age, ethnicity, and social determinants of health by state-of-the-artbiomedical language models. By deploying diverse performance metrics andstatistical analyses, we explore the influence of data imbalance on performancevariations and demographic fairness. Our study shows that data imbalancesignificantly impacts model performance and fairness, but feature similarity tothe majority class may be a more critical factor. We believe this studyprovides valuable insights for developing more equitable and robust languagemodels in healthcare applications.</description><author>Precious Jones, Weisi Liu, I-Chan Huang, Xiaolei Huang</author><pubDate>Mon, 23 Dec 2024 18:58:11 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.17803v1</guid></item><item><title>Comprehensive Multi-Modal Prototypes are Simple and Effective Classifiers for Vast-Vocabulary Object Detection</title><link>http://arxiv.org/abs/2412.17800v1</link><description>Enabling models to recognize vast open-world categories has been alongstanding pursuit in object detection. By leveraging the generalizationcapabilities of vision-language models, current open-world detectors canrecognize a broader range of vocabularies, despite being trained on limitedcategories. However, when the scale of the category vocabularies duringtraining expands to a real-world level, previous classifiers aligned withcoarse class names significantly reduce the recognition performance of thesedetectors. In this paper, we introduce Prova, a multi-modal prototypeclassifier for vast-vocabulary object detection. Prova extracts comprehensivemulti-modal prototypes as initialization of alignment classifiers to tackle thevast-vocabulary object recognition failure problem. On V3Det, this simplemethod greatly enhances the performance among one-stage, two-stage, andDETR-based detectors with only additional projection layers in both supervisedand open-vocabulary settings. In particular, Prova improves Faster R-CNN, FCOS,and DINO by 3.3, 6.2, and 2.9 AP respectively in the supervised setting ofV3Det. For the open-vocabulary setting, Prova achieves a new state-of-the-artperformance with 32.8 base AP and 11.0 novel AP, which is of 2.6 and 4.3 gainover the previous methods.</description><author>Yitong Chen, Wenhao Yao, Lingchen Meng, Sihong Wu, Zuxuan Wu, Yu-Gang Jiang</author><pubDate>Mon, 23 Dec 2024 18:57:43 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.17800v1</guid></item><item><title>Automating the Search for Artificial Life with Foundation Models</title><link>http://arxiv.org/abs/2412.17799v1</link><description>With the recent Nobel Prize awarded for radical advances in proteindiscovery, foundation models (FMs) for exploring large combinatorial spacespromise to revolutionize many scientific fields. Artificial Life (ALife) hasnot yet integrated FMs, thus presenting a major opportunity for the field toalleviate the historical burden of relying chiefly on manual design andtrial-and-error to discover the configurations of lifelike simulations. Thispaper presents, for the first time, a successful realization of thisopportunity using vision-language FMs. The proposed approach, called AutomatedSearch for Artificial Life (ASAL), (1) finds simulations that produce targetphenomena, (2) discovers simulations that generate temporally open-endednovelty, and (3) illuminates an entire space of interestingly diversesimulations. Because of the generality of FMs, ASAL works effectively across adiverse range of ALife substrates including Boids, Particle Life, Game of Life,Lenia, and Neural Cellular Automata. A major result highlighting the potentialof this technique is the discovery of previously unseen Lenia and Boidslifeforms, as well as cellular automata that are open-ended like Conway's Gameof Life. Additionally, the use of FMs allows for the quantification ofpreviously qualitative phenomena in a human-aligned way. This new paradigmpromises to accelerate ALife research beyond what is possible through humaningenuity alone.</description><author>Akarsh Kumar, Chris Lu, Louis Kirsch, Yujin Tang, Kenneth O. Stanley, Phillip Isola, David Ha</author><pubDate>Mon, 23 Dec 2024 18:57:00 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.17799v1</guid></item><item><title>MOCK: an Algorithm for Learning Nonparametric Differential Equations via Multivariate Occupation Kernel Functions</title><link>http://arxiv.org/abs/2306.10189v2</link><description>Learning a nonparametric system of ordinary differential equations fromtrajectories in a $d$-dimensional state space requires learning $d$ functionsof $d$ variables. Explicit formulations often scale quadratically in $d$ unlessadditional knowledge about system properties, such as sparsity and symmetries,is available. In this work, we propose a linear approach, the multivariateoccupation kernel method (MOCK), using the implicit formulation provided byvector-valued reproducing kernel Hilbert spaces. The solution for the vectorfield relies on multivariate occupation kernel functions associated with thetrajectories and scales linearly with the dimension of the state space. Wevalidate through experiments on a variety of simulated and real datasetsranging from 2 to 1024 dimensions. MOCK outperforms all other comparators on 3of the 9 datasets on full trajectory prediction and 4 out of the 9 datasets onnext-point prediction.</description><author>Victor Rielly, Kamel Lahouel, Ethan Lew, Michael Wells, Vicky Haney, Bruno Jedynak</author><pubDate>Mon, 23 Dec 2024 18:54:29 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.10189v2</guid></item><item><title>Observation Interference in Partially Observable Assistance Games</title><link>http://arxiv.org/abs/2412.17797v1</link><description>We study partially observable assistance games (POAGs), a model of thehuman-AI value alignment problem which allows the human and the AI assistant tohave partial observations. Motivated by concerns of AI deception, we study aqualitatively new phenomenon made possible by partial observability: would anAI assistant ever have an incentive to interfere with the human's observations?First, we prove that sometimes an optimal assistant must takeobservation-interfering actions, even when the human is playing optimally, andeven when there are otherwise-equivalent actions available that do notinterfere with observations. Though this result seems to contradict the classictheorem from single-agent decision making that the value of perfect informationis nonnegative, we resolve this seeming contradiction by developing a notion ofinterference defined on entire policies. This can be viewed as an extension ofthe classic result that the value of perfect information is nonnegative intothe cooperative multiagent setting. Second, we prove that if the human issimply making decisions based on their immediate outcomes, the assistant mightneed to interfere with observations as a way to query the human's preferences.We show that this incentive for interference goes away if the human is playingoptimally, or if we introduce a communication channel for the human tocommunicate their preferences to the assistant. Third, we show that if thehuman acts according to the Boltzmann model of irrationality, this can createan incentive for the assistant to interfere with observations. Finally, we usean experimental model to analyze tradeoffs faced by the AI assistant inpractice when considering whether or not to take observation-interferingactions.</description><author>Scott Emmons, Caspar Oesterheld, Vincent Conitzer, Stuart Russell</author><pubDate>Mon, 23 Dec 2024 18:53:33 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.17797v1</guid></item><item><title>Memory makes computation universal, remember?</title><link>http://arxiv.org/abs/2412.17794v1</link><description>Recent breakthroughs in AI capability have been attributed to increasinglysophisticated architectures and alignment techniques, but a simpler principlemay explain these advances: memory makes computation universal. Memory enablesuniversal computation through two fundamental capabilities: recursive statemaintenance and reliable history access. We formally prove these requirementsare both necessary and sufficient for universal computation. This principlemanifests across scales, from cellular computation to neural networks tolanguage models. Complex behavior emerges not from sophisticated processingunits but from maintaining and accessing state across time. We demonstrate howparallel systems like neural networks achieve universal computation despitelimitations in their basic units by maintaining state across iterations. Thistheoretical framework reveals a universal pattern: computational advancesconsistently emerge from enhanced abilities to maintain and access state ratherthan from more complex basic operations. Our analysis unifies understanding ofcomputation across biological systems, artificial intelligence, and humancognition, reminding us that humanity's own computational capabilities haveevolved in step with our technical ability to remember through oral traditions,writing, and now computing.</description><author>Erik Garrison</author><pubDate>Mon, 23 Dec 2024 18:51:46 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.17794v1</guid></item><item><title>Cross-Lingual Text-Rich Visual Comprehension: An Information Theory Perspective</title><link>http://arxiv.org/abs/2412.17787v1</link><description>Recent Large Vision-Language Models (LVLMs) have shown promising reasoningcapabilities on text-rich images from charts, tables, and documents. However,the abundant text within such images may increase the model's sensitivity tolanguage. This raises the need to evaluate LVLM performance on cross-lingualtext-rich visual inputs, where the language in the image differs from thelanguage of the instructions. To address this, we introduce XT-VQA(Cross-Lingual Text-Rich Visual Question Answering), a benchmark designed toassess how LVLMs handle language inconsistency between image text andquestions. XT-VQA integrates five existing text-rich VQA datasets and a newlycollected dataset, XPaperQA, covering diverse scenarios that require faithfulrecognition and comprehension of visual information despite languageinconsistency. Our evaluation of prominent LVLMs on XT-VQA reveals asignificant drop in performance for cross-lingual scenarios, even for modelswith multilingual capabilities. A mutual information analysis suggests thatthis performance gap stems from cross-lingual questions failing to adequatelyactivate relevant visual information. To mitigate this issue, we proposeMVCL-MI (Maximization of Vision-Language Cross-Lingual Mutual Information),where a visual-text cross-lingual alignment is built by maximizing mutualinformation between the model's outputs and visual information. This isachieved by distilling knowledge from monolingual to cross-lingual settingsthrough KL divergence minimization, where monolingual output logits serve as ateacher. Experimental results on the XT-VQA demonstrate that MVCL-MIeffectively reduces the visual-text cross-lingual performance disparity whilepreserving the inherent capabilities of LVLMs, shedding new light on thepotential practice for improving LVLMs. Codes are available at:https://github.com/Stardust-y/XTVQA.git</description><author>Xinmiao Yu, Xiaocheng Feng, Yun Li, Minghui Liao, Ya-Qi Yu, Xiachong Feng, Weihong Zhong, Ruihan Chen, Mengkang Hu, Jihao Wu, Dandan Tu, Duyu Tang, Bing Qin</author><pubDate>Mon, 23 Dec 2024 18:48:04 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.17787v1</guid></item><item><title>A partial likelihood approach to tree-based density modeling and its application in Bayesian inference</title><link>http://arxiv.org/abs/2412.11692v2</link><description>Tree-based models for probability distributions are usually specified using apredetermined, data-independent collection of candidate recursive partitions ofthe sample space. To characterize an unknown target density in detail over theentire sample space, candidate partitions must have the capacity to expanddeeply into all areas of the sample space with potential non-zero samplingprobability. Such an expansive system of partitions often incurs prohibitivecomputational costs and makes inference prone to overfitting, especially inregions with little probability mass. Existing models typically make acompromise and rely on relatively shallow trees. This hampers one of the mostdesirable features of trees, their ability to characterize local features, andresults in reduced statistical efficiency. Traditional wisdom suggests thatthis compromise is inevitable to ensure coherent likelihood-based reasoning, asa data-dependent partition system that allows deeper expansion only in regionswith more observations would induce double dipping of the data and thus lead toinconsistent inference. We propose a simple strategy to restore coherency whileallowing the candidate partitions to be data-dependent, using Cox's partiallikelihood. This strategy parametrizes the tree-based sampling model accordingto the allocation of probability mass based on the observed data, and yet underappropriate specification, the resulting inference remains valid. Our partiallikelihood approach is broadly applicable to existing likelihood-based methodsand in particular to Bayesian inference on tree-based models. We give examplesin density estimation in which the partial likelihood is endowed with existingpriors on tree-based models and compare with the standard, full-likelihoodapproach. The results show substantial gains in estimation accuracy andcomputational efficiency from using the partial likelihood.</description><author>Li Ma, Benedetta Bruni</author><pubDate>Mon, 23 Dec 2024 18:46:34 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.11692v2</guid></item><item><title>PepTune: De Novo Generation of Therapeutic Peptides with Multi-Objective-Guided Discrete Diffusion</title><link>http://arxiv.org/abs/2412.17780v1</link><description>Peptide therapeutics, a major class of medicines, have achieved remarkablesuccess across diseases such as diabetes and cancer, with landmark examplessuch as GLP-1 receptor agonists revolutionizing the treatment of type-2diabetes and obesity. Despite their success, designing peptides that satisfymultiple conflicting objectives, such as target binding affinity, solubility,and membrane permeability, remains a major challenge. Classical drugdevelopment and structure-based design are ineffective for such tasks, as theyfail to optimize global functional properties critical for therapeuticefficacy. Existing generative frameworks are largely limited to continuousspaces, unconditioned outputs, or single-objective guidance, making themunsuitable for discrete sequence optimization across multiple properties. Toaddress this, we present PepTune, a multi-objective discrete diffusion modelfor the simultaneous generation and optimization of therapeutic peptide SMILES.Built on the Masked Discrete Language Model (MDLM) framework, PepTune ensuresvalid peptide structures with state-dependent masking schedules andpenalty-based objectives. To guide the diffusion process, we propose a MonteCarlo Tree Search (MCTS)-based strategy that balances exploration andexploitation to iteratively refine Pareto-optimal sequences. MCTS integratesclassifier-based rewards with search-tree expansion, overcoming gradientestimation challenges and data sparsity inherent to discrete spaces. UsingPepTune, we generate diverse, chemically-modified peptides optimized formultiple therapeutic properties, including target binding affinity, membranepermeability, solubility, hemolysis, and non-fouling characteristics on variousdisease-relevant targets. In total, our results demonstrate that MCTS-guideddiscrete diffusion is a powerful and modular approach for multi-objectivesequence design in discrete state spaces.</description><author>Sophia Tang, Yinuo Zhang, Pranam Chatterjee</author><pubDate>Mon, 23 Dec 2024 18:38:49 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.17780v1</guid></item><item><title>The Prompt Report: A Systematic Survey of Prompting Techniques</title><link>http://arxiv.org/abs/2406.06608v4</link><description>Generative Artificial Intelligence (GenAI) systems are increasingly beingdeployed across diverse industries and research domains. Developers andend-users interact with these systems through the use of prompting and promptengineering. Although prompt engineering is a widely adopted and extensivelyresearched area, it suffers from conflicting terminology and a fragmentedontological understanding of what constitutes an effective prompt due to itsrelatively recent emergence. We establish a structured understanding of promptengineering by assembling a taxonomy of prompting techniques and analyzingtheir applications. We present a detailed vocabulary of 33 vocabulary terms, ataxonomy of 58 LLM prompting techniques, and 40 techniques for othermodalities. Additionally, we provide best practices and guidelines for promptengineering, including advice for prompting state-of-the-art (SOTA) LLMs suchas ChatGPT. We further present a meta-analysis of the entire literature onnatural language prefix-prompting. As a culmination of these efforts, thispaper presents the most comprehensive survey on prompt engineering to date.</description><author>Sander Schulhoff, Michael Ilie, Nishant Balepur, Konstantine Kahadze, Amanda Liu, Chenglei Si, Yinheng Li, Aayush Gupta, HyoJung Han, Sevien Schulhoff, Pranav Sandeep Dulepet, Saurav Vidyadhara, Dayeon Ki, Sweta Agrawal, Chau Pham, Gerson Kroiz, Feileen Li, Hudson Tao, Ashay Srivastava, Hevander Da Costa, Saloni Gupta, Megan L. Rogers, Inna Goncearenco, Giuseppe Sarli, Igor Galynker, Denis Peskoff, Marine Carpuat, Jules White, Shyamal Anadkat, Alexander Hoyle, Philip Resnik</author><pubDate>Mon, 23 Dec 2024 18:38:36 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.06608v4</guid></item><item><title>An Investigation on the Potential of KAN in Speech Enhancement</title><link>http://arxiv.org/abs/2412.17778v1</link><description>High-fidelity speech enhancement often requires sophisticated modeling tocapture intricate, multiscale patterns. Standard activation functions, whileintroducing nonlinearity, lack the flexibility to fully address thiscomplexity. Kolmogorov-Arnold Networks (KAN), an emerging methodology thatemploys learnable activation functions on graph edges, present a promisingalternative. This work investigates two novel KAN variants based on rationaland radial basis functions for speech enhancement. We integrate the rationalvariant into the 1D CNN blocks of Demucs and the GRU-Transformer blocks ofMP-SENet, while the radial variant is adapted to the 2D CNN-based decoders ofMP-SENet. Experiments on the VoiceBank-DEMAND dataset show that replacingstandard activations with KAN-based activations improves speech quality acrossboth the time-domain and time-frequency domain methods with minimal impact onmodel size and FLOP, underscoring KAN's potential to improve speech enhancementmodels.</description><author>Haoyang Li, Yuchen Hu, Chen Chen, Eng Siong Chng</author><pubDate>Mon, 23 Dec 2024 18:38:32 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.17778v1</guid></item><item><title>Towards structure-preserving quantum encodings</title><link>http://arxiv.org/abs/2412.17772v1</link><description>Harnessing the potential computational advantage of quantum computers formachine learning tasks relies on the uploading of classical data onto quantumcomputers through what are commonly referred to as quantum encodings. Thechoice of such encodings may vary substantially from one task to another, andthere exist only a few cases where structure has provided insight into theirdesign and implementation, such as symmetry in geometric quantum learning.Here, we propose the perspective that category theory offers a naturalmathematical framework for analyzing encodings that respect structure inherentin datasets and learning tasks. We illustrate this with pedagogical examples,which include geometric quantum machine learning, quantum metric learning,topological data analysis, and more. Moreover, our perspective provides alanguage in which to ask meaningful and mathematically precise questions forthe design of quantum encodings and circuits for quantum machine learningtasks.</description><author>Arthur J. Parzygnat, Tai-Danae Bradley, Andrew Vlasic, Anh Pham</author><pubDate>Mon, 23 Dec 2024 18:32:08 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.17772v1</guid></item><item><title>ActiveGS: Active Scene Reconstruction using Gaussian Splatting</title><link>http://arxiv.org/abs/2412.17769v1</link><description>Robotics applications often rely on scene reconstructions to enabledownstream tasks. In this work, we tackle the challenge of actively building anaccurate map of an unknown scene using an on-board RGB-D camera. We propose ahybrid map representation that combines a Gaussian splatting map with a coarsevoxel map, leveraging the strengths of both representations: the high-fidelityscene reconstruction capabilities of Gaussian splatting and the spatialmodelling strengths of the voxel map. The core of our framework is an effectiveconfidence modelling technique for the Gaussian splatting map to identifyunder-reconstructed areas, while utilising spatial information from the voxelmap to target unexplored areas and assist in collision-free path planning. Byactively collecting scene information in under-reconstructed and unexploredareas for map updates, our approach achieves superior Gaussian splattingreconstruction results compared to state-of-the-art approaches. Additionally,we demonstrate the applicability of our active scene reconstruction frameworkin the real world using an unmanned aerial vehicle.</description><author>Liren Jin, Xingguang Zhong, Yue Pan, Jens Behley, Cyrill Stachniss, Marija Popović</author><pubDate>Mon, 23 Dec 2024 18:29:03 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.17769v1</guid></item><item><title>ResearchTown: Simulator of Human Research Community</title><link>http://arxiv.org/abs/2412.17767v1</link><description>Large Language Models (LLMs) have demonstrated remarkable potential inscientific domains, yet a fundamental question remains unanswered: Can wesimulate human research communities with LLMs? Addressing this question candeepen our understanding of the processes behind idea brainstorming and inspirethe automatic discovery of novel scientific insights. In this work, we proposeResearchTown, a multi-agent framework for research community simulation. Withinthis framework, the human research community is simplified and modeled as anagent-data graph, where researchers and papers are represented as agent-typeand data-type nodes, respectively, and connected based on their collaborationrelationships. We also introduce TextGNN, a text-based inference framework thatmodels various research activities (e.g., paper reading, paper writing, andreview writing) as special forms of a unified message-passing process on theagent-data graph. To evaluate the quality of the research simulation, wepresent ResearchBench, a benchmark that uses a node-masking prediction task forscalable and objective assessment based on similarity. Our experiments revealthree key findings: (1) ResearchTown can provide a realistic simulation ofcollaborative research activities, including paper writing and review writing;(2) ResearchTown can maintain robust simulation with multiple researchers anddiverse papers; (3) ResearchTown can generate interdisciplinary research ideasthat potentially inspire novel research directions.</description><author>Haofei Yu, Zhaochen Hong, Zirui Cheng, Kunlun Zhu, Keyang Xuan, Jinwei Yao, Tao Feng, Jiaxuan You</author><pubDate>Mon, 23 Dec 2024 18:26:53 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.17767v1</guid></item><item><title>HyperQ-Opt: Q-learning for Hyperparameter Optimization</title><link>http://arxiv.org/abs/2412.17765v1</link><description>Hyperparameter optimization (HPO) is critical for enhancing the performanceof machine learning models, yet it often involves a computationally intensivesearch across a large parameter space. Traditional approaches such as GridSearch and Random Search suffer from inefficiency and limited scalability,while surrogate models like Sequential Model-based Bayesian Optimization (SMBO)rely heavily on heuristic predictions that can lead to suboptimal results. Thispaper presents a novel perspective on HPO by formulating it as a sequentialdecision-making problem and leveraging Q-learning, a reinforcement learningtechnique, to optimize hyperparameters. The study explores the works of H.S.Jomaa et al. and Qi et al., which model HPO as a Markov Decision Process (MDP)and utilize Q-learning to iteratively refine hyperparameter settings. Theapproaches are evaluated for their ability to find optimal or near-optimalconfigurations within a limited number of trials, demonstrating the potentialof reinforcement learning to outperform conventional methods. Additionally,this paper identifies research gaps in existing formulations, including thelimitations of discrete search spaces and reliance on heuristic policies, andsuggests avenues for future exploration. By shifting the paradigm towardpolicy-based optimization, this work contributes to advancing HPO methods forscalable and efficient machine learning applications.</description><author>Md. Tarek Hasan</author><pubDate>Mon, 23 Dec 2024 18:22:34 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.17765v1</guid></item><item><title>The Superposition of Diffusion Models Using the Itô Density Estimator</title><link>http://arxiv.org/abs/2412.17762v1</link><description>The Cambrian explosion of easily accessible pre-trained diffusion modelssuggests a demand for methods that combine multiple different pre-traineddiffusion models without incurring the significant computational burden ofre-training a larger combined model. In this paper, we cast the problem ofcombining multiple pre-trained diffusion models at the generation stage under anovel proposed framework termed superposition. Theoretically, we derivesuperposition from rigorous first principles stemming from the celebratedcontinuity equation and design two novel algorithms tailor-made for combiningdiffusion models in SuperDiff. SuperDiff leverages a new scalable It\^o densityestimator for the log likelihood of the diffusion SDE which incurs noadditional overhead compared to the well-known Hutchinson's estimator neededfor divergence calculations. We demonstrate that SuperDiff is scalable to largepre-trained diffusion models as superposition is performed solely throughcomposition during inference, and also enjoys painless implementation as itcombines different pre-trained vector fields through an automated re-weightingscheme. Notably, we show that SuperDiff is efficient during inference time, andmimics traditional composition operators such as the logical OR and the logicalAND. We empirically demonstrate the utility of using SuperDiff for generatingmore diverse images on CIFAR-10, more faithful prompt conditioned image editingusing Stable Diffusion, and improved unconditional de novo structure design ofproteins. https://github.com/necludov/super-diffusion</description><author>Marta Skreta, Lazar Atanackovic, Avishek Joey Bose, Alexander Tong, Kirill Neklyudov</author><pubDate>Mon, 23 Dec 2024 18:18:07 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.17762v1</guid></item><item><title>Survey of Large Multimodal Model Datasets, Application Categories and Taxonomy</title><link>http://arxiv.org/abs/2412.17759v1</link><description>Multimodal learning, a rapidly evolving field in artificial intelligence,seeks to construct more versatile and robust systems by integrating andanalyzing diverse types of data, including text, images, audio, and video.Inspired by the human ability to assimilate information through many senses,this method enables applications such as text-to-video conversion, visualquestion answering, and image captioning. Recent developments in datasets thatsupport multimodal language models (MLLMs) are highlighted in this overview.Large-scale multimodal datasets are essential because they allow for thoroughtesting and training of these models. With an emphasis on their contributionsto the discipline, the study examines a variety of datasets, including thosefor training, domain-specific tasks, and real-world applications. It alsoemphasizes how crucial benchmark datasets are for assessing models' performancein a range of scenarios, scalability, and applicability. Since multimodallearning is always changing, overcoming these obstacles will help AI researchand applications reach new heights.</description><author>Priyaranjan Pattnayak, Hitesh Laxmichand Patel, Bhargava Kumar, Amit Agarwal, Ishan Banerjee, Srikant Panda, Tejaswini Kumar</author><pubDate>Mon, 23 Dec 2024 18:15:19 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.17759v1</guid></item><item><title>In Case You Missed It: ARC 'Challenge' Is Not That Challenging</title><link>http://arxiv.org/abs/2412.17758v1</link><description>ARC Challenge appears more difficult than ARC Easy for modern LLMs primarilydue to an evaluation setup that prevents direct comparison of answer choicesrather than inherent complexity. Although some researchers have quietly shiftedto a more appropriate scheme over the last year, the implications of thischange have yet to be widely acknowledged. We highlight this overlooked shift,show how similar evaluation practices falsely imply reasoning deficits in otherbenchmarks, and demonstrate that fairer methods dramatically reduce performancegaps (e.g. on SIQA) and even yield superhuman results (OpenBookQA). In doingso, we reveal how evaluation shapes perceived difficulty and offer guidelinesto ensure that multiple-choice evaluations accurately reflect actual modelcapabilities.</description><author>Łukasz Borchmann</author><pubDate>Mon, 23 Dec 2024 18:14:36 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.17758v1</guid></item><item><title>Hands-On Tutorial: Labeling with LLM and Human-in-the-Loop</title><link>http://arxiv.org/abs/2411.04637v2</link><description>Training and deploying machine learning models relies on a large amount ofhuman-annotated data. As human labeling becomes increasingly expensive andtime-consuming, recent research has developed multiple strategies to speed upannotation and reduce costs and human workload: generating synthetic trainingdata, active learning, and hybrid labeling. This tutorial is oriented towardpractical applications: we will present the basics of each strategy, highlighttheir benefits and limitations, and discuss in detail real-life case studies.Additionally, we will walk through best practices for managing human annotatorsand controlling the quality of the final dataset. The tutorial includes ahands-on workshop, where attendees will be guided in implementing a hybridannotation setup. This tutorial is designed for NLP practitioners from bothresearch and industry backgrounds who are involved in or interested inoptimizing data labeling projects.</description><author>Ekaterina Artemova, Akim Tsvigun, Dominik Schlechtweg, Natalia Fedorova, Sergei Tilga, Konstantin Chernyshev, Boris Obmoroshev</author><pubDate>Mon, 23 Dec 2024 18:09:34 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2411.04637v2</guid></item><item><title>Minimax Optimal Simple Regret in Two-Armed Best-Arm Identification</title><link>http://arxiv.org/abs/2412.17753v1</link><description>This study investigates an asymptotically minimax optimal algorithm in thetwo-armed fixed-budget best-arm identification (BAI) problem. Given twotreatment arms, the objective is to identify the arm with the highest expectedoutcome through an adaptive experiment. We focus on the Neyman allocation,where treatment arms are allocated following the ratio of their outcomestandard deviations. Our primary contribution is to prove the minimaxoptimality of the Neyman allocation for the simple regret, defined as thedifference between the expected outcomes of the true best arm and the estimatedbest arm. Specifically, we first derive a minimax lower bound for the expectedsimple regret, which characterizes the worst-case performance achievable underthe location-shift distributions, including Gaussian distributions. We thenshow that the simple regret of the Neyman allocation asymptotically matchesthis lower bound, including the constant term, not just the rate in terms ofthe sample size, under the worst-case distribution. Notably, our optimalityresult holds without imposing locality restrictions on the distribution, suchas the local asymptotic normality. Furthermore, we demonstrate that the Neymanallocation reduces to the uniform allocation, i.e., the standard randomizedcontrolled trial, under Bernoulli distributions.</description><author>Masahiro Kato</author><pubDate>Mon, 23 Dec 2024 18:06:20 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.17753v1</guid></item><item><title>Deep Backward and Galerkin Methods for the Finite State Master Equation</title><link>http://arxiv.org/abs/2403.04975v2</link><description>This paper proposes and analyzes two neural network methods to solve themaster equation for finite-state mean field games (MFGs). Solving MFGs providesapproximate Nash equilibria for stochastic, differential games with finite butlarge populations of agents. The master equation is a partial differentialequation (PDE) whose solution characterizes MFG equilibria for any possibleinitial distribution. The first method we propose relies on backward inductionin a time component while the second method directly tackles the PDE withoutdiscretizing time. For both approaches, we prove two types of results: thereexist neural networks that make the algorithms' loss functions arbitrarilysmall, and conversely, if the losses are small, then the neural networks aregood approximations of the master equation's solution. We conclude the paperwith numerical experiments on benchmark problems from the literature up todimension 15, and a comparison with solutions computed by a classical methodfor fixed initial distributions.</description><author>Asaf Cohen, Mathieu Laurière, Ethan Zell</author><pubDate>Mon, 23 Dec 2024 18:05:07 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.04975v2</guid></item><item><title>Bivariate Matrix-valued Linear Regression (BMLR): Finite-sample performance under Identifiability and Sparsity Assumptions</title><link>http://arxiv.org/abs/2412.17749v1</link><description>This study explores the estimation of parameters in a matrix-valued linearregression model, where the $T$ responses $(Y_t)_{t=1}^T \in \mathbb{R}^{n\times p}$ and predictors $(X_t)_{t=1}^T \in \mathbb{R}^{m \times q}$ satisfythe relationship $Y_t = A^* X_t B^* + E_t$ for all $t = 1, \ldots, T$. In thismodel, $A^* \in \mathbb{R}_+^{n \times m}$ has $L_1$-normalized rows, $B^* \in\mathbb{R}^{q \times p}$, and $(E_t)_{t=1}^T$ are independent noise matricesfollowing a matrix Gaussian distribution. The primary objective is to estimatethe unknown parameters $A^*$ and $B^*$ efficiently. We propose explicit optimization-free estimators and establish non-asymptoticconvergence rates to quantify their performance. Additionally, we extend ouranalysis to scenarios where $A^*$ and $B^*$ exhibit sparse structures. Tosupport our theoretical findings, we conduct numerical simulations that confirmthe behavior of the estimators, particularly with respect to the impact of thedimensions $n, m, p, q$, and the sample size $T$ on finite-sample performances.We complete the simulations by investigating the denoising performances of ourestimators on noisy real-world images.</description><author>Nayel Bettache</author><pubDate>Mon, 23 Dec 2024 18:03:34 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.17749v1</guid></item><item><title>Deliberation in Latent Space via Differentiable Cache Augmentation</title><link>http://arxiv.org/abs/2412.17747v1</link><description>Techniques enabling large language models (LLMs) to "think more" bygenerating and attending to intermediate reasoning steps have shown promise insolving complex problems. However, the standard approaches generate sequencesof discrete tokens immediately before responding, and so they can incursignificant latency costs and be challenging to optimize. In this work, wedemonstrate that a frozen LLM can be augmented with an offline coprocessor thatoperates on the model's key-value (kv) cache. This coprocessor augments thecache with a set of latent embeddings designed to improve the fidelity ofsubsequent decoding. We train this coprocessor using the language modeling lossfrom the decoder on standard pretraining data, while keeping the decoder itselffrozen. This approach enables the model to learn, in an end-to-enddifferentiable fashion, how to distill additional computation into itskv-cache. Because the decoder remains unchanged, the coprocessor can operateoffline and asynchronously, and the language model can function normally if thecoprocessor is unavailable or if a given cache is deemed not to require extracomputation. We show experimentally that when a cache is augmented, the decoderachieves lower perplexity on numerous subsequent tokens. Furthermore, evenwithout any task-specific training, our experiments demonstrate that cacheaugmentation consistently reduces perplexity and improves performance across arange of reasoning-intensive tasks.</description><author>Luyang Liu, Jonas Pfeiffer, Jiaxing Wu, Jun Xie, Arthur Szlam</author><pubDate>Mon, 23 Dec 2024 18:02:25 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.17747v1</guid></item><item><title>Quantifying Positional Biases in Text Embedding Models</title><link>http://arxiv.org/abs/2412.15241v2</link><description>Embedding models are crucial for tasks in Information Retrieval (IR) andsemantic similarity measurement, yet their handling of longer texts andassociated positional biases remains underexplored. In this study, weinvestigate the impact of content position and input size on text embeddings.Our experiments reveal that embedding models, irrespective of their positionalencoding mechanisms, disproportionately prioritize the beginning of an input.Ablation studies demonstrate that insertion of irrelevant text or removal atthe start of a document reduces cosine similarity between altered and originalembeddings by up to 12.3\% more than ablations at the end. Regression analysisfurther confirms this bias, with sentence importance declining as positionmoves further from the start, even with with content-agnosticity. Wehypothesize that this effect arises from pre-processing strategies and chosenpositional encoding techniques. These findings quantify the sensitivity ofretrieval systems and suggest a new lens towards embedding model robustness.</description><author>Reagan J. Lee, Samarth Goel, Kannan Ramchandran</author><pubDate>Mon, 23 Dec 2024 17:59:23 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.15241v2</guid></item><item><title>Attention Heads of Large Language Models: A Survey</title><link>http://arxiv.org/abs/2409.03752v3</link><description>Since the advent of ChatGPT, Large Language Models (LLMs) have excelled invarious tasks but remain as black-box systems. Understanding the reasoningbottlenecks of LLMs has become a critical challenge, as these limitations aredeeply tied to their internal architecture. Among these, attention heads haveemerged as a focal point for investigating the underlying mechanics of LLMs. Inthis survey, we aim to demystify the internal reasoning processes of LLMs bysystematically exploring the roles and mechanisms of attention heads. We firstintroduce a novel four-stage framework inspired by the human thought process:Knowledge Recalling, In-Context Identification, Latent Reasoning, andExpression Preparation. Using this framework, we comprehensively reviewexisting research to identify and categorize the functions of specificattention heads. Additionally, we analyze the experimental methodologies usedto discover these special heads, dividing them into two categories:Modeling-Free and Modeling-Required methods. We further summarize relevantevaluation methods and benchmarks. Finally, we discuss the limitations ofcurrent research and propose several potential future directions.</description><author>Zifan Zheng, Yezhaohui Wang, Yuxin Huang, Shichao Song, Mingchuan Yang, Bo Tang, Feiyu Xiong, Zhiyu Li</author><pubDate>Mon, 23 Dec 2024 17:57:29 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2409.03752v3</guid></item><item><title>Variational Sequential Optimal Experimental Design using Reinforcement Learning</title><link>http://arxiv.org/abs/2306.10430v2</link><description>We present variational sequential optimal experimental design (vsOED), anovel method for optimally designing a finite sequence of experiments within aBayesian framework with information-theoretic criteria. vsOED employs aone-point reward formulation with variational posterior approximations,providing a provable lower bound to the expected information gain. Numericalmethods are developed following an actor-critic reinforcement learningapproach, including derivation and estimation of variational and policygradients to optimize the design policy, and posterior approximation usingGaussian mixture models and normalizing flows. vsOED accommodates nuisanceparameters, implicit likelihoods, and multiple candidate models, whilesupporting flexible design criteria that can target designs for modeldiscrimination, parameter inference, goal-oriented prediction, and theirweighted combinations. We demonstrate vsOED across various engineering andscience applications, illustrating its superior sample efficiency compared toexisting sequential experimental design algorithms.</description><author>Wanggang Shen, Jiayuan Dong, Xun Huan</author><pubDate>Mon, 23 Dec 2024 17:56:29 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.10430v2</guid></item><item><title>Simplified derivations for high-dimensional convex learning problems</title><link>http://arxiv.org/abs/2412.01110v3</link><description>Statistical physics provides tools for analyzing high-dimensional problems inmachine learning and theoretical neuroscience. These calculations, particularlythose using the replica method, often involve lengthy derivations that canobscure physical interpretation. We give concise, non-replica derivations ofseveral key results and highlight their underlying similarities. Specifically,we introduce a cavity approach to analyzing high-dimensional learning problemsand apply it to three cases: perceptron classification of points, perceptronclassification of manifolds, and kernel ridge regression. These problems sharea common structure -- a bipartite system of interacting feature and datumvariables -- enabling a unified analysis. For perceptron-capacity problems, weidentify a symmetry that allows derivation of correct capacities through ana\"ive method. These results match those obtained through the replica method.</description><author>David G. Clark, Haim Sompolinsky</author><pubDate>Mon, 23 Dec 2024 17:52:40 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.01110v3</guid></item><item><title>RepoTransBench: A Real-World Benchmark for Repository-Level Code Translation</title><link>http://arxiv.org/abs/2412.17744v1</link><description>Repository-level code translation refers to translating an entire coderepository from one programming language to another while preserving thefunctionality of the source repository. Many benchmarks have been proposed toevaluate the performance of such code translators. However, previous benchmarksmostly provide fine-grained samples, focusing at either code snippet, function,or file-level code translation. Such benchmarks do not accurately reflectreal-world demands, where entire repositories often need to be translated,involving longer code length and more complex functionalities. To address thisgap, we propose a new benchmark, named RepoTransBench, which is a real-worldrepository-level code translation benchmark with an automatically executabletest suite. We conduct experiments on RepoTransBench to evaluate thetranslation performance of 11 advanced LLMs. We find that the Success@1 score(test success in one attempt) of the best-performing LLM is only 7.33%. Tofurther explore the potential of LLMs for repository-level code translation, weprovide LLMs with error-related feedback to perform iterative debugging andobserve an average 7.09% improvement on Success@1. However, even with thisimprovement, the Success@1 score of the best-performing LLM is only 21%, whichmay not meet the need for reliable automatic repository-level code translation.Finally, we conduct a detailed error analysis and highlight current LLMs'deficiencies in repository-level code translation, which could provide areference for further improvements.</description><author>Yanli Wang, Yanlin Wang, Suiquan Wang, Daya Guo, Jiachi Chen, John Grundy, Xilin Liu, Yuchi Ma, Mingzhi Mao, Hongyu Zhang, Zibin Zheng</author><pubDate>Mon, 23 Dec 2024 17:52:10 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.17744v1</guid></item><item><title>YuLan-Mini: An Open Data-efficient Language Model</title><link>http://arxiv.org/abs/2412.17743v1</link><description>Effective pre-training of large language models (LLMs) has been challengingdue to the immense resource demands and the complexity of the technicalprocesses involved. This paper presents a detailed technical report onYuLan-Mini, a highly capable base model with 2.42B parameters that achievestop-tier performance among models of similar parameter scale. Our pre-trainingapproach focuses on enhancing training efficacy through three key technicalcontributions: an elaborate data pipeline combines data cleaning with dataschedule strategies, a robust optimization method to mitigate traininginstability, and an effective annealing approach that incorporates targeteddata selection and long context training. Remarkably, YuLan-Mini, trained on1.08T tokens, achieves performance comparable to industry-leading models thatrequire significantly more data. To facilitate reproduction, we release thefull details of the data composition for each training phase. Project detailscan be accessed at the following link: https://github.com/RUC-GSAI/YuLan-Mini.</description><author>Yiwen Hu, Huatong Song, Jia Deng, Jiapeng Wang, Jie Chen, Kun Zhou, Yutao Zhu, Jinhao Jiang, Zican Dong, Wayne Xin Zhao, Ji-Rong Wen</author><pubDate>Mon, 23 Dec 2024 17:47:53 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.17743v1</guid></item><item><title>Reasoning to Attend: Try to Understand How &lt;SEG&gt; Token Works</title><link>http://arxiv.org/abs/2412.17741v1</link><description>Current Large Multimodal Models (LMMs) empowered visual grounding typicallyrely on $\texttt{&lt;SEG&gt;}$ token as a text prompt to jointly optimize thevision-language model (e.g., LLaVA) and the downstream task-specified model(\eg, SAM). However, we observe that little research has looked into how itworks.In this work, we first visualize the similarity maps, which are obtainedby computing the semantic similarity between the $\texttt{&lt;SEG&gt;}$ token and theimage token embeddings derived from the last hidden layer in both the LLaVAencoder and SAM decoder. Intriguingly, we have found that a strikingconsistency holds in terms of activation responses in the similarity map,whichreveals that what $\texttt{&lt;SEG&gt;}$ token contributes to is the semanticsimilarity within image-text pairs. Specifically, $\texttt{&lt;SEG&gt;}$ token, aplaceholder expanded in text vocabulary, extensively queries among individualtokenized image patches to match the semantics of an object from text to thepaired image while the Large Language Models (LLMs) are being fine-tuned. Uponthe above findings, we present READ, which facilitates LMMs' resilient$\textbf{REA}$soning capability of where to atten$\textbf{D}$ under theguidance of highly activated points borrowed from similarity maps. Remarkably,READ features an intuitive design, Similarity as Points module (SasP), whichcan be seamlessly applied to $\texttt{&lt;SEG&gt;}$-like paradigms in a plug-and-playfashion.Also, extensive experiments have been conducted on the ReasonSeg andRefCOCO(+/g) datasets. To validate whether READ suffers from catastrophicforgetting of previous skills after fine-tuning, we further assess itsgeneration ability on an augmented FP-RefCOCO(+/g) dataset. All codes andmodels are publicly available at https://github.com/rui-qian/READ.</description><author>Rui Qian, Xin Yin, Dejing Dou</author><pubDate>Mon, 23 Dec 2024 17:44:05 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.17741v1</guid></item><item><title>Sensitivity Curve Maximization: Attacking Robust Aggregators in Distributed Learning</title><link>http://arxiv.org/abs/2412.17740v1</link><description>In distributed learning agents aim at collaboratively solving a globallearning problem. It becomes more and more likely that individual agents aremalicious or faulty with an increasing size of the network. This leads to adegeneration or complete breakdown of the learning process. Classicalaggregation schemes are prone to breakdown at small contamination rates,therefore robust aggregation schemes are sought for. While robust aggregationschemes can generally tolerate larger contamination rates, many have been shownto be susceptible to carefully crafted malicious attacks. In this work, we showhow the sensitivity curve (SC), a classical tool from robust statistics, can beused to systematically derive optimal attack patterns against arbitrary robustaggregators, in most cases rendering them ineffective. We show theeffectiveness of the proposed attack in multiple simulations.</description><author>Christian A. Schroth, Stefan Vlaski, Abdelhak M. Zoubir</author><pubDate>Mon, 23 Dec 2024 17:44:03 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.17740v1</guid></item><item><title>Fourier Position Embedding: Enhancing Attention's Periodic Extension for Length Generalization</title><link>http://arxiv.org/abs/2412.17739v1</link><description>Extending the context length of Language Models (LMs) by improving RotaryPosition Embedding (RoPE) has become a trend. While existing works mainlyaddress RoPE's limitations within attention mechanism, this paper provides ananalysis across nearly all parts of LMs, uncovering their adverse effects onlength generalization for RoPE-based attention. Using Discrete SignalProcessing theory, we show that RoPE enables periodic attention by implicitlyachieving Non-Uniform Discrete Fourier Transform. However, this periodicity isundermined by the spectral damage caused by: 1) linear layers and activationfunctions outside of attention; 2) insufficiently trained frequency componentsbrought by time-domain truncation. Building on our observations, we proposeFourier Position Embedding (FoPE), which enhances attention's frequency-domainproperties to improve both its periodic extension and length generalization.FoPE constructs Fourier Series and zero-outs the destructive frequencycomponents, increasing model robustness against the spectrum damage.Experiments across various model scales show that, within varying contextwindows, FoPE can maintain a more stable perplexity and a more consistentaccuracy in a needle-in-haystack task compared to RoPE and ALiBi. Severalanalyses and ablations bring further support to our method and theoreticalmodeling.</description><author>Ermo Hua, Che Jiang, Xingtai Lv, Kaiyan Zhang, Ning Ding, Youbang Sun, Biqing Qi, Yuchen Fan, Xue Kai Zhu, Bowen Zhou</author><pubDate>Mon, 23 Dec 2024 17:44:01 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.17739v1</guid></item><item><title>Generalized Neyman Allocation for Locally Minimax Optimal Best-Arm Identification</title><link>http://arxiv.org/abs/2405.19317v2</link><description>This study investigates an asymptotically locally minimax optimal algorithmfor fixed-budget best-arm identification (BAI). We propose the GeneralizedNeyman Allocation (GNA) algorithm and demonstrate that its worst-case upperbound on the probability of misidentifying the best arm aligns with theworst-case lower bound under the small-gap regime, where the gap between theexpected outcomes of the best and suboptimal arms is small. Our lower and upperbounds are tight, matching exactly including constant terms within thesmall-gap regime. The GNA algorithm generalizes the Neyman allocation fortwo-armed bandits (Neyman, 1934; Kaufmann et al., 2016) and refines existingBAI algorithms, such as those proposed by Glynn &amp; Juneja (2004). By proposingan asymptotically minimax optimal algorithm, we address the longstanding openissue in BAI (Kaufmann, 2020) and treatment choice (Kasy &amp; Sautmann, 202) byrestricting a class of distributions to the small-gap regimes.</description><author>Masahiro Kato</author><pubDate>Mon, 23 Dec 2024 17:43:05 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.19317v2</guid></item><item><title>Incentivized Symbiosis: A Paradigm for Human-Agent Coevolution</title><link>http://arxiv.org/abs/2412.06855v2</link><description>Cooperation is vital to our survival and progress. Evolutionary game theoryoffers a lens to understand the structures and incentives that enablecooperation to be a successful strategy. As artificial intelligence agentsbecome integral to human systems, the dynamics of cooperation take onunprecedented significance. Decentralized frameworks like Web3, grounded intransparency, accountability, and trust, offer a foundation for fosteringcooperation by establishing enforceable rules and incentives for humans and AIagents. Guided by our Incentivized Symbiosis model, a paradigm aligning humanand AI agent goals through bidirectional incentives and mutual adaptation, weinvestigate mechanisms for embedding cooperation into human-agent coevolution.We conceptualize Incentivized Symbiosis as part of a contemporary moralframework inspired by Web3 principles, encoded in blockchain technology todefine and enforce rules, incentives, and consequences for both humans and AIagents. This study explores how these principles could be integrated into thearchitecture of human-agent interactions within Web3 ecosystems, creating apotential foundation for collaborative innovation. Our study examines potentialapplications of the Incentivized Symbiosis model, including decentralizedfinance, governance, and cultural adaptation, to explore how AI agents mightcoevolve with humans and contribute to shared, sustainable progress.</description><author>Tomer Jordi Chaffer, Justin Goldston, Gemach D. A. T. A. I</author><pubDate>Mon, 23 Dec 2024 17:41:34 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.06855v2</guid></item><item><title>Arbitrary Polynomial Separations in Trainable Quantum Machine Learning</title><link>http://arxiv.org/abs/2402.08606v3</link><description>Recent theoretical results in quantum machine learning have demonstrated ageneral trade-off between the expressive power of quantum neural networks(QNNs) and their trainability; as a corollary of these results, practicalexponential separations in expressive power over classical machine learningmodels are believed to be infeasible as such QNNs take a time to train that isexponential in the model size. We here circumvent these negative results byconstructing a hierarchy of efficiently trainable QNNs that exhibitunconditionally provable, polynomial memory separations of arbitrary constantdegree over classical neural networks -- including state-of-the-art models,such as Transformers -- in performing a classical sequence modeling task. Thisconstruction is also computationally efficient, as each unit cell of theintroduced class of QNNs only has constant gate complexity. We show thatcontextuality -- informally, a quantitative notion of semantic ambiguity -- isthe source of the expressivity separation, suggesting that other learning taskswith this property may be a natural setting for the use of quantum learningalgorithms.</description><author>Eric R. Anschuetz, Xun Gao</author><pubDate>Mon, 23 Dec 2024 17:38:51 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.08606v3</guid></item><item><title>Contextual Backpropagation Loops: Amplifying Deep Reasoning with Iterative Top-Down Feedback</title><link>http://arxiv.org/abs/2412.17737v1</link><description>Deep neural networks typically rely on a single forward pass for inference,which can limit their capacity to resolve ambiguous inputs. We introduceContextual Backpropagation Loops (CBLs) as an iterative mechanism thatincorporates top-down feedback to refine intermediate representations, therebyimproving accuracy and robustness. This repeated process mirrors how humanscontinuously re-interpret sensory information in daily life-by checking andre-checking our perceptions using contextual cues. Our results suggest thatCBLs can offer a straightforward yet powerful way to incorporate suchcontextual reasoning in modern deep learning architectures.</description><author>Jacob Fein-Ashley</author><pubDate>Mon, 23 Dec 2024 17:36:51 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.17737v1</guid></item><item><title>DiffH2O: Diffusion-Based Synthesis of Hand-Object Interactions from Textual Descriptions</title><link>http://arxiv.org/abs/2403.17827v2</link><description>Generating natural hand-object interactions in 3D is challenging as theresulting hand and object motions are expected to be physically plausible andsemantically meaningful. Furthermore, generalization to unseen objects ishindered by the limited scale of available hand-object interaction datasets. Inthis paper, we propose a novel method, dubbed DiffH2O, which can synthesizerealistic, one or two-handed object interactions from provided text prompts andgeometry of the object. The method introduces three techniques that enableeffective learning from limited data. First, we decompose the task into agrasping stage and an text-based manipulation stage and use separate diffusionmodels for each. In the grasping stage, the model only generates hand motions,whereas in the manipulation phase both hand and object poses are synthesized.Second, we propose a compact representation that tightly couples hand andobject poses and helps in generating realistic hand-object interactions. Third,we propose two different guidance schemes to allow more control of thegenerated motions: grasp guidance and detailed textual guidance. Grasp guidancetakes a single target grasping pose and guides the diffusion model to reachthis grasp at the end of the grasping stage, which provides control over thegrasping pose. Given a grasping motion from this stage, multiple differentactions can be prompted in the manipulation phase. For the textual guidance, wecontribute comprehensive text descriptions to the GRAB dataset and show thatthey enable our method to have more fine-grained control over hand-objectinteractions. Our quantitative and qualitative evaluation demonstrates that theproposed method outperforms baseline methods and leads to natural hand-objectmotions.</description><author>Sammy Christen, Shreyas Hampali, Fadime Sener, Edoardo Remelli, Tomas Hodan, Eric Sauser, Shugao Ma, Bugra Tekin</author><pubDate>Mon, 23 Dec 2024 17:36:22 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.17827v2</guid></item><item><title>LASE: Learned Adjacency Spectral Embeddings</title><link>http://arxiv.org/abs/2412.17734v1</link><description>We put forth a principled design of a neural architecture to learn nodalAdjacency Spectral Embeddings (ASE) from graph inputs. By bringing to bear thegradient descent (GD) method and leveraging the principle of algorithmunrolling, we truncate and re-interpret each GD iteration as a layer in a graphneural network (GNN) that is trained to approximate the ASE. Accordingly, wecall the resulting embeddings and our parametric model Learned ASE (LASE),which is interpretable, parameter efficient, robust to inputs with unobservededges, and offers controllable complexity during inference. LASE layers combineGraph Convolutional Network (GCN) and fully-connected Graph Attention Network(GAT) modules, which is intuitively pleasing since GCN-based local aggregationsalone are insufficient to express the sought graph eigenvectors. We proposeseveral refinements to the unrolled LASE architecture (such as sparse attentionin the GAT module and decoupled layerwise parameters) that offer favorableapproximation error versus computation tradeoffs; even outperformingheavily-optimized eigendecomposition routines from scientific computinglibraries. Because LASE is a differentiable function with respect to itsparameters as well as its graph input, we can seamlessly integrate it as atrainable module within a larger (semi-)supervised graph representationlearning pipeline. The resulting end-to-end system effectively learns``discriminative ASEs'' that exhibit competitive performance in supervised linkprediction and node classification tasks, outperforming a GNN even when thelatter is endowed with open loop, meaning task-agnostic, precomputed spectralpositional encodings.</description><author>Sofía Pérez Casulo, Marcelo Fiori, Federico Larroca, Gonzalo Mateos</author><pubDate>Mon, 23 Dec 2024 17:35:19 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.17734v1</guid></item><item><title>DART-Math: Difficulty-Aware Rejection Tuning for Mathematical Problem-Solving</title><link>http://arxiv.org/abs/2407.13690v2</link><description>Solving mathematical problems requires advanced reasoning abilities andpresents notable challenges for large language models. Previous works usuallysynthesize data from proprietary models to augment existing datasets, followedby instruction tuning to achieve top-tier results. However, our analysis ofthese datasets reveals severe biases towards easy queries, with frequentfailures to generate any correct response for the most challenging queries.Hypothesizing that difficult queries are crucial to learn complex reasoning, wepropose Difficulty-Aware Rejection Tuning (DART), a method that allocatesdifficult queries more trials during the synthesis phase, enabling moreextensive training on difficult samples. Utilizing DART, we have created newdatasets for mathematical problem-solving that focus more on difficult queriesand are substantially smaller than previous ones. Remarkably, our synthesisprocess solely relies on a 7B-sized open-weight model, without reliance on thecommonly used proprietary GPT-4. We fine-tune various base models on ourdatasets ranging from 7B to 70B in size, resulting in a series of strong modelscalled DART-MATH. In comprehensive in-domain and out-of-domain evaluation on 6mathematical benchmarks, DART-MATH outperforms vanilla rejection tuningsignificantly, being superior or comparable to previous arts, despite usingmuch smaller datasets and no proprietary models. Furthermore, our resultsposition our synthetic datasets as the most effective and cost-efficientpublicly available resources for advancing mathematical problem-solving.</description><author>Yuxuan Tong, Xiwen Zhang, Rui Wang, Ruidong Wu, Junxian He</author><pubDate>Mon, 23 Dec 2024 17:32:21 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.13690v2</guid></item><item><title>Mimicking-Bench: A Benchmark for Generalizable Humanoid-Scene Interaction Learning via Human Mimicking</title><link>http://arxiv.org/abs/2412.17730v1</link><description>Learning generic skills for humanoid robots interacting with 3D scenes bymimicking human data is a key research challenge with significant implicationsfor robotics and real-world applications. However, existing methodologies andbenchmarks are constrained by the use of small-scale, manually collecteddemonstrations, lacking the general dataset and benchmark support necessary toexplore scene geometry generalization effectively. To address this gap, weintroduce Mimicking-Bench, the first comprehensive benchmark designed forgeneralizable humanoid-scene interaction learning through mimicking large-scalehuman animation references. Mimicking-Bench includes six household full-bodyhumanoid-scene interaction tasks, covering 11K diverse object shapes, alongwith 20K synthetic and 3K real-world human interaction skill references. Weconstruct a complete humanoid skill learning pipeline and benchmark approachesfor motion retargeting, motion tracking, imitation learning, and their variouscombinations. Extensive experiments highlight the value of human mimicking forskill learning, revealing key challenges and research directions.</description><author>Yun Liu, Bowen Yang, Licheng Zhong, He Wang, Li Yi</author><pubDate>Mon, 23 Dec 2024 17:27:30 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.17730v1</guid></item><item><title>Chumor 2.0: Towards Benchmarking Chinese Humor Understanding</title><link>http://arxiv.org/abs/2412.17729v1</link><description>Existing humor datasets and evaluations predominantly focus on English,leaving limited resources for culturally nuanced humor in non-English languageslike Chinese. To address this gap, we construct Chumor, the first Chinese humorexplanation dataset that exceeds the size of existing humor datasets. Chumor issourced from Ruo Zhi Ba, a Chinese Reddit-like platform known for sharingintellectually challenging and culturally specific jokes. We test ten LLMsthrough direct and chain-of-thought prompting, revealing that Chumor posessignificant challenges to existing LLMs, with their accuracy slightly aboverandom and far below human. In addition, our analysis highlights thathuman-annotated humor explanations are significantly better than thosegenerated by GPT-4o and ERNIE-4-turbo. We release Chumor athttps://huggingface.co/datasets/dnaihao/Chumor, our project page is athttps://dnaihao.github.io/Chumor-dataset/, our leaderboard is athttps://huggingface.co/spaces/dnaihao/Chumor, and our codebase is athttps://github.com/dnaihao/Chumor-dataset.</description><author>Ruiqi He, Yushu He, Longju Bai, Jiarui Liu, Zhenjie Sun, Zenghao Tang, He Wang, Hanchen Xia, Rada Mihalcea, Naihao Deng</author><pubDate>Mon, 23 Dec 2024 17:19:58 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.17729v1</guid></item><item><title>Knowledge Editing through Chain-of-Thought</title><link>http://arxiv.org/abs/2412.17727v1</link><description>Large Language Models (LLMs) have demonstrated exceptional capabilitiesacross a wide range of natural language processing (NLP) tasks. However,keeping these models up-to-date with evolving world knowledge remains asignificant challenge due to the high costs of frequent retraining. To addressthis challenge, knowledge editing techniques have emerged to update LLMs withnew information without rebuilding the model from scratch. Among these, thein-context editing paradigm stands out for its effectiveness in integrating newknowledge while preserving the model's original capabilities. Despite itspotential, existing in-context knowledge editing methods are oftentask-specific, focusing primarily on multi-hop QA tasks using structuredknowledge triples. Moreover, their reliance on few-shot prompting for taskdecomposition makes them unstable and less effective in generalizing acrossdiverse tasks. In response to these limitations, we propose EditCoT, a novel knowledgeediting framework that flexibly and efficiently updates LLMs across varioustasks without retraining. EditCoT works by generating a chain-of-thought (CoT)for a given input and then iteratively refining this CoT process using a CoTeditor based on updated knowledge. We evaluate EditCoT across a diverse rangeof benchmarks, covering multiple languages and tasks. The results demonstratethat our approach achieves state-of-the-art performance while offering superiorgeneralization, effectiveness, and stability compared to existing methods,marking a significant advancement in the field of knowledge updating. Code anddata are available at: https://github.com/bebr2/EditCoT.</description><author>Changyue Wang, Weihang Su, Qingyao Ai, Yiqun Liu</author><pubDate>Mon, 23 Dec 2024 17:17:50 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.17727v1</guid></item><item><title>VidTwin: Video VAE with Decoupled Structure and Dynamics</title><link>http://arxiv.org/abs/2412.17726v1</link><description>Recent advancements in video autoencoders (Video AEs) have significantlyimproved the quality and efficiency of video generation. In this paper, wepropose a novel and compact video autoencoder, VidTwin, that decouples videointo two distinct latent spaces: Structure latent vectors, which captureoverall content and global movement, and Dynamics latent vectors, whichrepresent fine-grained details and rapid movements. Specifically, our approachleverages an Encoder-Decoder backbone, augmented with two submodules forextracting these latent spaces, respectively. The first submodule employs aQ-Former to extract low-frequency motion trends, followed by downsamplingblocks to remove redundant content details. The second averages the latentvectors along the spatial dimension to capture rapid motion. Extensiveexperiments show that VidTwin achieves a high compression rate of 0.20% withhigh reconstruction quality (PSNR of 28.14 on the MCL-JCV dataset), andperforms efficiently and effectively in downstream generative tasks. Moreover,our model demonstrates explainability and scalability, paving the way forfuture research in video latent representation and generation. Our code hasbeen released at https://github.com/microsoft/VidTok/tree/main/vidtwin.</description><author>Yuchi Wang, Junliang Guo, Xinyi Xie, Tianyu He, Xu Sun, Jiang Bian</author><pubDate>Mon, 23 Dec 2024 17:16:58 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.17726v1</guid></item><item><title>Asynchronous Federated Learning: A Scalable Approach for Decentralized Machine Learning</title><link>http://arxiv.org/abs/2412.17723v1</link><description>Federated Learning (FL) has emerged as a powerful paradigm for decentralizedmachine learning, enabling collaborative model training across diverse clientswithout sharing raw data. However, traditional FL approaches often facelimitations in scalability and efficiency due to their reliance on synchronousclient updates, which can result in significant delays and increasedcommunication overhead, particularly in heterogeneous and dynamic environments.To address these challenges in this paper, we propose an Asynchronous FederatedLearning (AFL) algorithm, which allows clients to update the global modelindependently and asynchronously. Our key contributions include a comprehensiveconvergence analysis of AFL in the presence of client delays and modelstaleness. By leveraging martingale difference sequence theory and variancebounds, we ensure robust convergence despite asynchronous updates. Assumingstrongly convex local objective functions, we establish bounds on gradientvariance under random client sampling and derive a recursion formulaquantifying the impact of client delays on convergence. Furthermore, wedemonstrate the practical applicability of AFL by training a decentralized LongShort-Term Memory (LSTM)-based deep learning model on the CMIP6 climatedataset, effectively handling non-IID and geographically distributed data. The proposed AFL algorithm addresses key limitations of traditional FLmethods, such as inefficiency due to global synchronization and susceptibilityto client drift. It enhances scalability, robustness, and efficiency inreal-world settings with heterogeneous client populations and dynamic networkconditions. Our results underscore the potential of AFL to drive advancementsin distributed learning systems, particularly for large-scale,privacy-preserving applications in resource-constrained environments.</description><author>Ali Forootani, Raffaele Iervolino</author><pubDate>Mon, 23 Dec 2024 17:11:02 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.17723v1</guid></item><item><title>Non-parametric Hypothesis Tests for Distributional Group Symmetry</title><link>http://arxiv.org/abs/2307.15834v2</link><description>Symmetry plays a central role in the sciences, machine learning, andstatistics. For situations in which data are known to obey a symmetry, amultitude of methods that exploit symmetry have been developed. Statisticaltests for the presence or absence of general group symmetry, however, arelargely non-existent. This work formulates non-parametric hypothesis tests,based on a single independent and identically distributed sample, fordistributional symmetry under a specified group. We provide a generalformulation of tests for symmetry that apply to two broad settings. The firstsetting tests for the invariance of a marginal or joint distribution under theaction of a compact group. Here, an asymptotically unbiased test only requiresa computable metric on the space of probability distributions and the abilityto sample uniformly random group elements. Building on this, we propose aneasy-to-implement conditional Monte Carlo test and prove that it achieves exact$p$-values with finitely many observations and Monte Carlo samples. The secondsetting tests for the invariance or equivariance of a conditional distributionunder the action of a locally compact group. We show that the test forconditional invariance or equivariance can be formulated as particular tests ofconditional independence. We implement these tests from both settings usingkernel methods and study them empirically on synthetic data. Finally, we applythem to testing for symmetry in geomagnetic satellite data and in two problemsfrom high-energy particle physics.</description><author>Kenny Chiu, Benjamin Bloem-Reddy</author><pubDate>Mon, 23 Dec 2024 17:07:50 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.15834v2</guid></item><item><title>What to Say and When to Say it: Live Fitness Coaching as a Testbed for Situated Interaction</title><link>http://arxiv.org/abs/2407.08101v3</link><description>Vision-language models have shown impressive progress in recent years.However, existing models are largely limited to turn-based interactions, whereeach turn must be stepped (i.e., prompted) by the user. Open-ended,asynchronous interactions, where an AI model may proactively deliver timelyresponses or feedback based on the unfolding situation in real-time, are anopen challenge. In this work, we present the QEVD benchmark and dataset, whichexplores human-AI interaction in the challenging, yet controlled, real-worlddomain of fitness coaching -- a task which intrinsically requires monitoringlive user activity and providing immediate feedback. The benchmark requiresvision-language models to recognize complex human actions, identify possiblemistakes, and provide appropriate feedback in real-time. Our experiments revealthe limitations of existing state-of-the-art vision-language models for suchasynchronous situated interactions. Motivated by this, we propose a simpleend-to-end streaming baseline that can respond asynchronously to human actionswith appropriate feedback at the appropriate time.</description><author>Sunny Panchal, Apratim Bhattacharyya, Guillaume Berger, Antoine Mercier, Cornelius Bohm, Florian Dietrichkeit, Reza Pourreza, Xuanlin Li, Pulkit Madan, Mingu Lee, Mark Todorovich, Ingo Bax, Roland Memisevic</author><pubDate>Mon, 23 Dec 2024 17:06:20 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.08101v3</guid></item><item><title>CLAPNQ: Cohesive Long-form Answers from Passages in Natural Questions for RAG systems</title><link>http://arxiv.org/abs/2404.02103v2</link><description>Retrieval Augmented Generation (RAG) has become a popular application forlarge language models. It is preferable that successful RAG systems provideaccurate answers that are supported by being grounded in a passage without anyhallucinations. While considerable work is required for building a full RAGpipeline, being able to benchmark performance is also necessary. We presentClapNQ, a benchmark Long-form Question Answering dataset for the full RAGpipeline. ClapNQ includes long answers with grounded gold passages from NaturalQuestions (NQ) and a corpus to perform either retrieval, generation, or thefull RAG pipeline. The ClapNQ answers are concise, 3x smaller than the fullpassage, and cohesive, meaning that the answer is composed fluently, often byintegrating multiple pieces of the passage that are not contiguous. RAG modelsmust adapt to these properties to be successful at ClapNQ. We present baselineexperiments and analysis for ClapNQ that highlight areas where there is stillsignificant room for improvement in grounded RAG. CLAPNQ is publicly availableat https://github.com/primeqa/clapnq</description><author>Sara Rosenthal, Avirup Sil, Radu Florian, Salim Roukos</author><pubDate>Mon, 23 Dec 2024 17:01:11 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.02103v2</guid></item><item><title>MR-GDINO: Efficient Open-World Continual Object Detection</title><link>http://arxiv.org/abs/2412.15979v2</link><description>Open-world (OW) recognition and detection models show strong zero- andfew-shot adaptation abilities, inspiring their use as initializations incontinual learning methods to improve performance. Despite promising results onseen classes, such OW abilities on unseen classes are largely degenerated dueto catastrophic forgetting. To tackle this challenge, we propose an open-worldcontinual object detection task, requiring detectors to generalize to old, new,and unseen categories in continual learning scenarios. Based on this task, wepresent a challenging yet practical OW-COD benchmark to assess detectionabilities. The goal is to motivate OW detectors to simultaneously preservelearned classes, adapt to new classes, and maintain open-world capabilitiesunder few-shot adaptations. To mitigate forgetting in unseen categories, wepropose MR-GDINO, a strong, efficient and scalable baseline via memory andretrieval mechanisms within a highly scalable memory pool. Experimental resultsshow that existing continual detectors suffer from severe forgetting for bothseen and unseen categories. In contrast, MR-GDINO largely mitigates forgettingwith only 0.1% activated extra parameters, achieving state-of-the-artperformance for old, new, and unseen categories.</description><author>Bowen Dong, Zitong Huang, Guanglei Yang, Lei Zhang, Wangmeng Zuo</author><pubDate>Mon, 23 Dec 2024 16:55:57 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.15979v2</guid></item><item><title>Fast Causal Discovery by Approximate Kernel-based Generalized Score Functions with Linear Computational Complexity</title><link>http://arxiv.org/abs/2412.17717v1</link><description>Score-based causal discovery methods can effectively identify causalrelationships by evaluating candidate graphs and selecting the one with thehighest score. One popular class of scores is kernel-based generalized scorefunctions, which can adapt to a wide range of scenarios and work well inpractice because they circumvent assumptions about causal mechanisms and datadistributions. Despite these advantages, kernel-based generalized scorefunctions pose serious computational challenges in time and space, with a timecomplexity of $\mathcal{O}(n^3)$ and a memory complexity of $\mathcal{O}(n^2)$,where $n$ is the sample size. In this paper, we propose an approximatekernel-based generalized score function with $\mathcal{O}(n)$ time and spacecomplexities by using low-rank technique and designing a set of rules to handlethe complex composite matrix operations required to calculate the score, aswell as developing sampling algorithms for different data types to benefit thehandling of diverse data types efficiently. Our extensive causal discoveryexperiments on both synthetic and real-world data demonstrate that compared tothe state-of-the-art method, our method can not only significantly reducecomputational costs, but also achieve comparable accuracy, especially for largedatasets.</description><author>Yixin Ren, Haocheng Zhang, Yewei Xia, Hao Zhang, Jihong Guan, Shuigeng Zhou</author><pubDate>Mon, 23 Dec 2024 16:51:45 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.17717v1</guid></item><item><title>A Tunable Despeckling Neural Network Stabilized via Diffusion Equation</title><link>http://arxiv.org/abs/2411.15921v2</link><description>The removal of multiplicative Gamma noise is a critical research area in theapplication of synthetic aperture radar (SAR) imaging, where neural networksserve as a potent tool. However, real-world data often diverges fromtheoretical models, exhibiting various disturbances, which makes the neuralnetwork less effective. Adversarial attacks can be used as a criterion forjudging the adaptability of neural networks to real data, since adversarialattacks can find the most extreme perturbations that make neural networksineffective. In this work, the diffusion equation is designed as aregularization block to provide sufficient regularity to the whole neuralnetwork, due to its spontaneous dissipative nature. We propose a tunable,regularized neural network framework that unrolls a shallow denoising neuralnetwork block and a diffusion regularity block into a single network forend-to-end training. The linear heat equation, known for its inherentsmoothness and low-pass filtering properties, is adopted as the diffusionregularization block. In our model, a single time step hyperparameter governsthe smoothness of the outputs and can be adjusted dynamically, significantlyenhancing flexibility. The stability and convergence of our model aretheoretically proven. Experimental results demonstrate that the proposed modeleffectively eliminates high-frequency oscillations induced by adversarialattacks. Finally, the proposed model is benchmarked against severalstate-of-the-art denoising methods on simulated images, adversarial samples,and real SAR images, achieving superior performance in both quantitative andvisual evaluations.</description><author>Yi Ran, Zhichang Guo, Jia Li, Yao Li, Martin Burger, Boying Wu</author><pubDate>Mon, 23 Dec 2024 16:50:54 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2411.15921v2</guid></item><item><title>Causal Deep Learning</title><link>http://arxiv.org/abs/2301.00314v2</link><description>We derive a set of causal deep neural networks whose architectures are aconsequence of tensor (multilinear) factor analysis, a framework thatfacilitates forward and inverse causal inference. Forward causal questions areaddressed with a neural architecture composed of causal capsules and a tensortransformer. Causal capsules compute a set of invariant causal factorrepresentations, whose interactions are governed by a tensor transformation.Inverse causal questions are addressed with a neural network that implementsthe multilinear projection algorithm. The architecture reverses the order ofthe operations of a forward neural network and estimates the causes of effects.As an alternative to aggressive bottleneck dimension reduction or regularizedregression that may camouflage an inherently underdetermined inverse problem,we prescribe modeling different aspects of the mechanism of data formation withpiecewise tensor models whose multilinear projections produce multiplecandidate solutions. Our forward and inverse questions may be addressed withshallow architectures, but for computationally scalable solutions, we derive aset of deep neural networks by taking advantage of block algebra. Aninterleaved kernel hierarchy results in a doubly non-linear tensor factormodels. The causal neural networks that are a consequence of tensor factoranalysis are data agnostic, but are illustrated with facial images. Sequential,parallel and asynchronous parallel computation strategies are described.</description><author>M. Alex O. Vasilescu</author><pubDate>Mon, 23 Dec 2024 16:48:28 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2301.00314v2</guid></item><item><title>GaussianPainter: Painting Point Cloud into 3D Gaussians with Normal Guidance</title><link>http://arxiv.org/abs/2412.17715v1</link><description>In this paper, we present GaussianPainter, the first method to paint a pointcloud into 3D Gaussians given a reference image. GaussianPainter introduces aninnovative feed-forward approach to overcome the limitations of time-consumingtest-time optimization in 3D Gaussian splatting. Our method addresses acritical challenge in the field: the non-uniqueness problem inherent in thelarge parameter space of 3D Gaussian splatting. This space, encompassingrotation, anisotropic scales, and spherical harmonic coefficients, introducesthe challenge of rendering similar images from substantially different Gaussianfields. As a result, feed-forward networks face instability when attempting todirectly predict high-quality Gaussian fields, struggling to converge onconsistent parameters for a given output. To address this issue, we propose toestimate a surface normal for each point to determine its Gaussian rotation.This strategy enables the network to effectively predict the remaining Gaussianparameters in the constrained space. We further enhance our approach with anappearance injection module, incorporating reference image appearance intoGaussian fields via a multiscale triplane representation. Our methodsuccessfully balances efficiency and fidelity in 3D Gaussian generation,achieving high-quality, diverse, and robust 3D content creation from pointclouds in a single forward pass.</description><author>Jingqiu Zhou, Lue Fan, Xuesong Chen, Linjiang Huang, Si Liu, Hongsheng Li</author><pubDate>Mon, 23 Dec 2024 16:45:37 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.17715v1</guid></item><item><title>Comparative Analysis of Resource-Efficient CNN Architectures for Brain Tumor Classification</title><link>http://arxiv.org/abs/2411.15596v3</link><description>Accurate brain tumor classification in MRI images is critical for timelydiagnosis and treatment planning. While deep learning models like ResNet-18,VGG-16 have shown high accuracy, they often come with increased complexity andcomputational demands. This study presents a comparative analysis of effectiveyet simple Convolutional Neural Network (CNN) architecture and pre-trainedResNet18, and VGG16 model for brain tumor classification using two publiclyavailable datasets: Br35H:: Brain Tumor Detection 2020 and Brain Tumor MRIDataset. The custom CNN architecture, despite its lower complexity,demonstrates competitive performance with the pre-trained ResNet18 and VGG16models. In binary classification tasks, the custom CNN achieved an accuracy of98.67% on the Br35H dataset and 99.62% on the Brain Tumor MRI Dataset. Formulti-class classification, the custom CNN, with a slight architecturalmodification, achieved an accuracy of 98.09%, on the Brain Tumor MRI Dataset.Comparatively, ResNet18 and VGG16 maintained high performance levels, but thecustom CNNs provided a more computationally efficient alternative.Additionally,the custom CNNs were evaluated using few-shot learning (0, 5, 10,15, 20, 40, and 80 shots) to assess their robustness, achieving notableaccuracy improvements with increased shots. This study highlights the potentialof well-designed, less complex CNN architectures as effective andcomputationally efficient alternatives to deeper, pre-trained models formedical imaging tasks, including brain tumor classification. This studyunderscores the potential of custom CNNs in medical imaging tasks andencourages further exploration in this direction.</description><author>Md Ashik Khan, Rafath Bin Zafar Auvee</author><pubDate>Mon, 23 Dec 2024 16:40:32 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2411.15596v3</guid></item><item><title>SMAC-Hard: Enabling Mixed Opponent Strategy Script and Self-play on SMAC</title><link>http://arxiv.org/abs/2412.17707v1</link><description>The availability of challenging simulation environments is pivotal foradvancing the field of Multi-Agent Reinforcement Learning (MARL). Incooperative MARL settings, the StarCraft Multi-Agent Challenge (SMAC) hasgained prominence as a benchmark for algorithms following centralized trainingwith decentralized execution paradigm. However, with continual advancements inSMAC, many algorithms now exhibit near-optimal performance, complicating theevaluation of their true effectiveness. To alleviate this problem, in thiswork, we highlight a critical issue: the default opponent policy in theseenvironments lacks sufficient diversity, leading MARL algorithms to overfit andexploit unintended vulnerabilities rather than learning robust strategies. Toovercome these limitations, we propose SMAC-HARD, a novel benchmark designed toenhance training robustness and evaluation comprehensiveness. SMAC-HARDsupports customizable opponent strategies, randomization of adversarialpolicies, and interfaces for MARL self-play, enabling agents to generalize tovarying opponent behaviors and improve model stability. Furthermore, weintroduce a black-box testing framework wherein agents are trained withoutexposure to the edited opponent scripts but are tested against these scripts toevaluate the policy coverage and adaptability of MARL algorithms. We conductextensive evaluations of widely used and state-of-the-art algorithms onSMAC-HARD, revealing the substantial challenges posed by edited and mixedstrategy opponents. Additionally, the black-box strategy tests illustrate thedifficulty of transferring learned policies to unseen adversaries. We envisionSMAC-HARD as a critical step toward benchmarking the next generation of MARLalgorithms, fostering progress in self-play methods for multi-agent systems.Our code is available at https://github.com/devindeng94/smac-hard.</description><author>Yue Deng, Yan Yu, Weiyu Ma, Zirui Wang, Wenhui Zhu, Jian Zhao, Yin Zhang</author><pubDate>Mon, 23 Dec 2024 16:36:21 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.17707v1</guid></item><item><title>From Models to Microtheories: Distilling a Model's Topical Knowledge for Grounded Question Answering</title><link>http://arxiv.org/abs/2412.17701v1</link><description>Recent reasoning methods (e.g., chain-of-thought, entailment reasoning) helpusers understand how language models (LMs) answer a single question, but theydo little to reveal the LM's overall understanding, or "theory," about thequestion's $\textit{topic}$, making it still hard to trust the model. Our goalis to materialize such theories - here called $\textit{microtheories}$ (alinguistic analog of logical microtheories) - as a set of sentencesencapsulating an LM's core knowledge about a topic. These statementssystematically work together to entail answers to a $\textit{set}$ of questionsto both engender trust and improve performance. Our approach is to firstpopulate a knowledge store with (model-generated) sentences that entail answersto training questions and then distill those down to a core microtheory that isconcise, general, and non-redundant. We show that, when added to a generalcorpus (e.g., Wikipedia), microtheories can supply critical, topicalinformation not necessarily present in the corpus, improving both a model'sability to ground its answers to verifiable knowledge (i.e., show how answersare systematically entailed by documents in the corpus, fully grounding up to+8% more answers), and the accuracy of those grounded answers (up to +8%absolute). We also show that, in a human evaluation in the medical domain, ourdistilled microtheories contain a significantly higher concentration oftopically critical facts than the non-distilled knowledge store. Finally, weshow we can quantify the coverage of a microtheory for a topic (characterizedby a dataset) using a notion of $p$-relevance. Together, these suggest thatmicrotheories are an efficient distillation of an LM's topic-relevantknowledge, that they can usefully augment existing corpora, and can provideboth performance gains and an interpretable, verifiable window into the model'sknowledge of a topic.</description><author>Nathaniel Weir, Bhavana Dalvi Mishra, Orion Weller, Oyvind Tafjord, Sam Hornstein, Alexander Sabol, Peter Jansen, Benjamin Van Durme, Peter Clark</author><pubDate>Mon, 23 Dec 2024 16:32:55 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.17701v1</guid></item><item><title>MRANet: A Modified Residual Attention Networks for Lung and Colon Cancer Classification</title><link>http://arxiv.org/abs/2412.17700v1</link><description>Lung and colon cancers are predominant contributors to cancer mortality.Early and accurate diagnosis is crucial for effective treatment. By utilizingimaging technology in different image detection, learning models have shownpromise in automating cancer classification from histopathological images. Thisincludes the histopathological diagnosis, an important factor in cancer typeidentification. This research focuses on creating a high-efficiencydeep-learning model for identifying lung and colon cancer fromhistopathological images. We proposed a novel approach based on a modifiedresidual attention network architecture. The model was trained on a dataset of25,000 high-resolution histopathological images across several classes. Ourproposed model achieved an exceptional accuracy of 99.30%, 96.63%, and 97.56%for two, three, and five classes, respectively; those are outperforming otherstate-of-the-art architectures. This study presents a highly accurate deeplearning model for lung and colon cancer classification. The superiorperformance of our proposed model addresses a critical need in medical AIapplications.</description><author>Diponkor Bala, S M Rakib Ul Karim, Rownak Ara Rasul</author><pubDate>Mon, 23 Dec 2024 16:31:45 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.17700v1</guid></item><item><title>Establishing Reality-Virtuality Interconnections in Urban Digital Twins for Superior Intelligent Road Inspection</title><link>http://arxiv.org/abs/2412.17699v1</link><description>Road inspection is essential for ensuring road maintenance and trafficsafety, as road defects gradually emerge and compromise road functionality.Traditional methods, which rely on manual evaluations, are labor-intensive,costly, and time-consuming. Although data-driven approaches are gainingtraction, the scarcity and spatial sparsity of road defects in the real worldpose significant challenges in acquiring high-quality datasets. Existingsimulators designed to generate detailed synthetic driving scenes, however,lack models for road defects. Furthermore, advanced driving tasks involvinginteractions with road surfaces, such as planning and control in defectiveareas, remain underexplored. To address these limitations, we propose a systembased on Urban Digital Twin (UDT) technology for intelligent road inspection.First, hierarchical road models are constructed from real-world driving data,creating highly detailed representations of road defect structures and surfaceelevations. Next, digital road twins are generated to create simulationenvironments for comprehensive analysis and evaluation. These scenarios aresubsequently imported into a simulator to enable both data acquisition andphysical simulation. Experimental results demonstrate that driving tasks,including perception and decision-making, can be significantly improved usingthe high-fidelity road defect scenes generated by our system.</description><author>Yikang Zhang, Chuang-Wei Liu, Jiahang Li, Yingbing Chen, Jie Cheng, Rui Fan</author><pubDate>Mon, 23 Dec 2024 16:31:29 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.17699v1</guid></item><item><title>Variational Graph Generator for Multi-View Graph Clustering</title><link>http://arxiv.org/abs/2210.07011v3</link><description>Multi-view graph clustering (MGC) methods are increasingly being studied dueto the explosion of multi-view data with graph structural information. Thecritical point of MGC is to better utilize view-specific and view-commoninformation in features and graphs of multiple views. However, existing workshave an inherent limitation that they are unable to concurrently utilize theconsensus graph information across multiple graphs and the view-specificfeature information. To address this issue, we propose Variational GraphGenerator for Multi-View Graph Clustering (VGMGC). Specifically, a novelvariational graph generator is proposed to extract common information amongmultiple graphs. This generator infers a reliable variational consensus graphbased on a priori assumption over multiple graphs. Then a simple yet effectivegraph encoder in conjunction with the multi-view clustering objective ispresented to learn the desired graph embeddings for clustering, which embedsthe inferred view-common graph and view-specific graphs together with features.Finally, theoretical results illustrate the rationality of the VGMGC byanalyzing the uncertainty of the inferred consensus graph with the informationbottleneck principle.Extensive experiments demonstrate the superior performanceof our VGMGC over SOTAs. The source code is publicly available athttps://github.com/cjpcool/VGMGC.</description><author>Jianpeng Chen, Yawen Ling, Jie Xu, Yazhou Ren, Shudong Huang, Xiaorong Pu, Zhifeng Hao, Philip S. Yu, Lifang He</author><pubDate>Mon, 23 Dec 2024 16:29:38 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2210.07011v3</guid></item><item><title>Understanding the Logic of Direct Preference Alignment through Logic</title><link>http://arxiv.org/abs/2412.17696v1</link><description>Recent direct preference alignment algorithms (DPA), such as DPO, have showngreat promise in aligning large language models to human preferences. Whilethis has motivated the development of many new variants of the original DPOloss, understanding the differences between these recent proposals, as well asdeveloping new DPA loss functions, remains difficult given the lack of atechnical and conceptual framework for reasoning about the underlying semanticsof these algorithms. In this paper, we attempt to remedy this by formalizingDPA losses in terms of discrete reasoning problems. Specifically, we ask: Givenan existing DPA loss, can we systematically derive a symbolic expression thatcharacterizes its semantics? How do the semantics of two losses relate to eachother? We propose a novel formalism for characterizing preference losses forsingle model and reference model based approaches, and identify symbolic formsfor a number of commonly used DPA variants. Further, we show how this formalview of preference learning sheds new light on both the size and structure ofthe DPA loss landscape, making it possible to not only rigorously characterizethe relationships between recent loss proposals but also to systematicallyexplore the landscape and derive new loss functions from first principles. Wehope our framework and findings will help provide useful guidance to thoseworking on human AI alignment.</description><author>Kyle Richardson, Vivek Srikumar, Ashish Sabharwal</author><pubDate>Mon, 23 Dec 2024 16:23:13 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.17696v1</guid></item><item><title>FedTLU: Federated Learning with Targeted Layer Updates</title><link>http://arxiv.org/abs/2412.17692v1</link><description>Federated learning (FL) addresses privacy concerns in language modeling byenabling multiple clients to contribute to training language models. However,non-IID (identically and independently distributed) data across clients oftenlimits FL's performance. This issue is especially challenging during modelfine-tuning, as noise due to variations in clients' data distributions can harmmodel convergence near the optimum. This paper proposes a targeted layer updatestrategy for fine-tuning in FL. Instead of randomly updating layers of thelanguage model, as often done in practice, we use a scoring mechanism toidentify and update the most critical layers, avoiding excessively noisy oreven poisoned updates by freezing the parameters in other layers. We show inextensive experiments that our method improves convergence and performance innon-IID settings, offering a more efficient approach to fine-tuning federatedlanguage models.</description><author>Jong-Ik Park, Carlee Joe-Wong</author><pubDate>Mon, 23 Dec 2024 16:17:46 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.17692v1</guid></item><item><title>RAGONITE: Iterative Retrieval on Induced Databases and Verbalized RDF for Conversational QA over KGs with RAG</title><link>http://arxiv.org/abs/2412.17690v1</link><description>Conversational question answering (ConvQA) is a convenient means of searchingover RDF knowledge graphs (KGs), where a prevalent approach is to translatenatural language questions to SPARQL queries. However, SPARQL has certainshortcomings: (i) it is brittle for complex intents and conversationalquestions, and (ii) it is not suitable for more abstract needs. Instead, wepropose a novel two-pronged system where we fuse: (i) SQL-query results over adatabase automatically derived from the KG, and (ii) text-search results oververbalizations of KG facts. Our pipeline supports iterative retrieval: when theresults of any branch are found to be unsatisfactory, the system canautomatically opt for further rounds. We put everything together in a retrievalaugmented generation (RAG) setup, where an LLM generates a coherent responsefrom accumulated search results. We demonstrate the superiority of our proposedsystem over several baselines on a knowledge graph of BMW automobiles.</description><author>Rishiraj Saha Roy, Chris Hinze, Joel Schlotthauer, Farzad Naderi, Viktor Hangya, Andreas Foltyn, Luzian Hahn, Fabian Kuech</author><pubDate>Mon, 23 Dec 2024 16:16:30 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.17690v1</guid></item><item><title>Global Optimization with A Power-Transformed Objective and Gaussian Smoothing</title><link>http://arxiv.org/abs/2412.05204v2</link><description>We propose a novel method that solves global optimization problems in twosteps: (1) perform a (exponential) power-$N$ transformation to thenot-necessarily differentiable objective function $f$ and get $f_N$, and (2)optimize the Gaussian-smoothed $f_N$ with stochastic approximations. Under mildconditions on $f$, for any $\delta&gt;0$, we prove that with a sufficiently largepower $N_\delta$, this method converges to a solution in the$\delta$-neighborhood of $f$'s global optimum point. The convergence rate is$O(d^2\sigma^4\varepsilon^{-2})$, which is faster than both the standard andsingle-loop homotopy methods if $\sigma$ is pre-selected to be in $(0,1)$. Inmost of the experiments performed, our method produces better solutions thanother algorithms that also apply smoothing techniques.</description><author>Chen Xu</author><pubDate>Mon, 23 Dec 2024 16:15:34 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.05204v2</guid></item><item><title>Evidence Contextualization and Counterfactual Attribution for Conversational QA over Heterogeneous Data with RAG Systems</title><link>http://arxiv.org/abs/2412.10571v3</link><description>Retrieval Augmented Generation (RAG) works as a backbone for interacting withan enterprise's own data via Conversational Question Answering (ConvQA). In aRAG system, a retriever fetches passages from a collection in response to aquestion, which are then included in the prompt of a large language model (LLM)for generating a natural language (NL) answer. However, several RAG systemstoday suffer from two shortcomings: (i) retrieved passages usually containtheir raw text and lack appropriate document context, negatively impacting bothretrieval and answering quality; and (ii) attribution strategies that explainanswer generation typically rely only on similarity between the answer and theretrieved passages, thereby only generating plausible but not causalexplanations. In this work, we demonstrate RAGONITE, a RAG system that remediesthe above concerns by: (i) contextualizing evidence with source metadata andsurrounding text; and (ii) computing counterfactual attribution, a causalexplanation approach where the contribution of an evidence to an answer isdetermined by the similarity of the original response to the answer obtained byremoving that evidence. To evaluate our proposals, we release a new benchmarkConfQuestions: it has 300 hand-created conversational questions, each inEnglish and German, coupled with ground truth URLs, completed questions, andanswers from 215 public Confluence pages. These documents are typical ofenterprise wiki spaces with heterogeneous elements. Experiments with RAGONITEon ConfQuestions show the viability of our ideas: contextualization improvesRAG performance, and counterfactual explanations outperform standardattribution.</description><author>Rishiraj Saha Roy, Joel Schlotthauer, Chris Hinze, Andreas Foltyn, Luzian Hahn, Fabian Kuech</author><pubDate>Mon, 23 Dec 2024 16:12:59 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.10571v3</guid></item><item><title>Large Language Model Safety: A Holistic Survey</title><link>http://arxiv.org/abs/2412.17686v1</link><description>The rapid development and deployment of large language models (LLMs) haveintroduced a new frontier in artificial intelligence, marked by unprecedentedcapabilities in natural language understanding and generation. However, theincreasing integration of these models into critical applications raisessubstantial safety concerns, necessitating a thorough examination of theirpotential risks and associated mitigation strategies. This survey provides a comprehensive overview of the current landscape of LLMsafety, covering four major categories: value misalignment, robustness toadversarial attacks, misuse, and autonomous AI risks. In addition to thecomprehensive review of the mitigation methodologies and evaluation resourceson these four aspects, we further explore four topics related to LLM safety:the safety implications of LLM agents, the role of interpretability inenhancing LLM safety, the technology roadmaps proposed and abided by a list ofAI companies and institutes for LLM safety, and AI governance aimed at LLMsafety with discussions on international cooperation, policy proposals, andprospective regulatory directions. Our findings underscore the necessity for a proactive, multifaceted approachto LLM safety, emphasizing the integration of technical solutions, ethicalconsiderations, and robust governance frameworks. This survey is intended toserve as a foundational resource for academy researchers, industrypractitioners, and policymakers, offering insights into the challenges andopportunities associated with the safe integration of LLMs into society.Ultimately, it seeks to contribute to the safe and beneficial development ofLLMs, aligning with the overarching goal of harnessing AI for societaladvancement and well-being. A curated list of related papers has been publiclyavailable at https://github.com/tjunlp-lab/Awesome-LLM-Safety-Papers.</description><author>Dan Shi, Tianhao Shen, Yufei Huang, Zhigen Li, Yongqi Leng, Renren Jin, Chuang Liu, Xinwei Wu, Zishan Guo, Linhao Yu, Ling Shi, Bojian Jiang, Deyi Xiong</author><pubDate>Mon, 23 Dec 2024 16:11:27 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.17686v1</guid></item><item><title>COBRA: COmBinatorial Retrieval Augmentation for Few-Shot Learning</title><link>http://arxiv.org/abs/2412.17684v1</link><description>Retrieval augmentation, the practice of retrieving additional data from largeauxiliary pools, has emerged as an effective technique for enhancing modelperformance in the low-data regime, e.g. few-shot learning. Prior approacheshave employed only nearest-neighbor based strategies for data selection, whichretrieve auxiliary samples with high similarity to instances in the targettask. However, these approaches are prone to selecting highly redundantsamples, since they fail to incorporate any notion of diversity. In our work,we first demonstrate that data selection strategies used in priorretrieval-augmented few-shot learning settings can be generalized using a classof functions known as Combinatorial Mutual Information (CMI) measures. We thenpropose COBRA (COmBinatorial Retrieval Augmentation), which employs analternative CMI measure that considers both diversity and similarity to atarget dataset. COBRA consistently outperforms previous retrieval approachesacross image classification tasks and few-shot learning techniques when used toretrieve samples from LAION-2B. COBRA introduces negligible computationaloverhead to the cost of retrieval while providing significant gains indownstream model performance.</description><author>Arnav M. Das, Gantavya Bhatt, Lilly Kumari, Sahil Verma, Jeff Bilmes</author><pubDate>Mon, 23 Dec 2024 16:10:07 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.17684v1</guid></item><item><title>EPE-P: Evidence-based Parameter-efficient Prompting for Multimodal Learning with Missing Modalities</title><link>http://arxiv.org/abs/2412.17677v1</link><description>Missing modalities are a common challenge in real-world multimodal learningscenarios, occurring during both training and testing. Existing methods formanaging missing modalities often require the design of separate prompts foreach modality or missing case, leading to complex designs and a substantialincrease in the number of parameters to be learned. As the number of modalitiesgrows, these methods become increasingly inefficient due to parameterredundancy. To address these issues, we propose Evidence-basedParameter-Efficient Prompting (EPE-P), a novel and parameter-efficient methodfor pretrained multimodal networks. Our approach introduces a streamlineddesign that integrates prompting information across different modalities,reducing complexity and mitigating redundant parameters. Furthermore, wepropose an Evidence-based Loss function to better handle the uncertaintyassociated with missing modalities, improving the model's decision-making. Ourexperiments demonstrate that EPE-P outperforms existing prompting-based methodsin terms of both effectiveness and efficiency. The code is released athttps://github.com/Boris-Jobs/EPE-P_MLLMs-Robustness.</description><author>Zhe Chen, Xun Lin, Yawen Cui, Zitong Yu</author><pubDate>Mon, 23 Dec 2024 16:01:12 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.17677v1</guid></item><item><title>A Bias-Free Training Paradigm for More General AI-generated Image Detection</title><link>http://arxiv.org/abs/2412.17671v1</link><description>Successful forensic detectors can produce excellent results in supervisedlearning benchmarks but struggle to transfer to real-world applications. Webelieve this limitation is largely due to inadequate training data quality.While most research focuses on developing new algorithms, less attention isgiven to training data selection, despite evidence that performance can bestrongly impacted by spurious correlations such as content, format, orresolution. A well-designed forensic detector should detect generator specificartifacts rather than reflect data biases. To this end, we propose B-Free, abias-free training paradigm, where fake images are generated from real onesusing the conditioning procedure of stable diffusion models. This ensuressemantic alignment between real and fake images, allowing any differences tostem solely from the subtle artifacts introduced by AI generation. Throughcontent-based augmentation, we show significant improvements in bothgeneralization and robustness over state-of-the-art detectors and morecalibrated results across 27 different generative models, including recentreleases, like FLUX and Stable Diffusion 3.5. Our findings emphasize theimportance of a careful dataset curation, highlighting the need for furtherresearch in dataset design. Code and data will be publicly available athttps://grip-unina.github.io/B-Free/</description><author>Fabrizio Guillaro, Giada Zingarini, Ben Usman, Avneesh Sud, Davide Cozzolino, Luisa Verdoliva</author><pubDate>Mon, 23 Dec 2024 15:54:32 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.17671v1</guid></item><item><title>Generating Completions for Fragmented Broca's Aphasic Sentences Using Large Language Models</title><link>http://arxiv.org/abs/2412.17669v1</link><description>Broca's aphasia is a type of aphasia characterized by non-fluent, effortfuland fragmented speech production with relatively good comprehension. Sincetraditional aphasia treatment methods are often time-consuming,labour-intensive, and do not reflect real-world conversations, applying naturallanguage processing based approaches such as Large Language Models (LLMs) couldpotentially contribute to improving existing treatment approaches. To addressthis issue, we explore the use of sequence-to-sequence LLMs for completingfragmented Broca's aphasic sentences. We first generate synthetic Broca'saphasic data using a rule-based system designed to mirror the linguisticcharacteristics of Broca's aphasic speech. Using this synthetic data, we thenfine-tune four pre-trained LLMs on the task of completing fragmented sentences.We evaluate our fine-tuned models on both synthetic and authentic Broca'saphasic data. We demonstrate LLMs' capability for reconstructing fragmentedsentences, with the models showing improved performance with longer inpututterances. Our result highlights the LLMs' potential in advancingcommunication aids for individuals with Broca's aphasia and possibly otherclinical populations.</description><author>Sijbren van Vaals, Yevgen Matusevych, Frank Tsiwah</author><pubDate>Mon, 23 Dec 2024 15:54:15 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.17669v1</guid></item><item><title>FocusLLM: Precise Understanding of Long Context by Dynamic Condensing</title><link>http://arxiv.org/abs/2408.11745v2</link><description>Empowering LLMs with the ability to precisely understand long contexts iscrucial for many downstream applications. However, handling long contexts withconventional transformer architecture requires substantial training andinference resources. Existing context condensing methods cannot accuratelyunderstand the full context, as there is a considerable amount of informationloss in the condensing process. To address these issues, we present FocusLLM, aframework designed to extend the fixed context length of any decoder-only LLM,allowing the model to focus on relevant information from very long sequences.FocusLLM first divides long text input into chunks based on the model'soriginal context length. It then employs the dynamic condensing process todistill crucial information from each chunk. Ultimately, through the novelparallel decoding mechanism, FocusLLM can integrate the extracted informationinto its local context. FocusLLM stands out for great training efficiency andversatility: trained with an 8K input length and with much less training costthan previous methods, FocusLLM exhibits superior performance across downstreamtasks and maintains strong language modeling ability when handling extensivelong texts, even up to 400K tokens. Our code is available athttps://github.com/leezythu/FocusLLM.</description><author>Zhenyu Li, Yike Zhang, Tengyu Pan, Yutao Sun, Zhichao Duan, Junjie Fang, Rong Han, Zixuan Wang, Jianyong Wang</author><pubDate>Mon, 23 Dec 2024 15:36:32 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.11745v2</guid></item><item><title>EDGE: Unknown-aware Multi-label Learning by Energy Distribution Gap Expansion</title><link>http://arxiv.org/abs/2412.07499v2</link><description>Multi-label Out-Of-Distribution (OOD) detection aims to discriminate the OODsamples from the multi-label In-Distribution (ID) ones. Compared with itsmulticlass counterpart, it is crucial to model the joint information amongclasses. To this end, JointEnergy, which is a representative multi-label OODinference criterion, summarizes the logits of all the classes. However, we findthat JointEnergy can produce an imbalance problem in OOD detection, especiallywhen the model lacks enough discrimination ability. Specifically, we find thatthe samples only related to minority classes tend to be classified as OODsamples due to the ambiguous energy decision boundary. Besides, imbalancedmulti-label learning methods, originally designed for ID ones, would not besuitable for OOD detection scenarios, even producing a serious negativetransfer effect. In this paper, we resort to auxiliary outlier exposure (OE)and propose an unknown-aware multi-label learning framework to reshape theuncertainty energy space layout. In this framework, the energy score isseparately optimized for tail ID samples and unknown samples, and the energydistribution gap between them is expanded, such that the tail ID samples canhave a significantly larger energy score than the OOD ones. What's more, asimple yet effective measure is designed to select more informative OEdatasets. Finally, comprehensive experimental results on multiple multi-labeland OOD datasets reveal the effectiveness of the proposed method.</description><author>Yuchen Sun, Qianqian Xu, Zitai Wang, Zhiyong Yang, Junwei He</author><pubDate>Mon, 23 Dec 2024 15:34:09 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.07499v2</guid></item><item><title>Enhanced Temporal Processing in Spiking Neural Networks for Static Object Detection Using 3D Convolutions</title><link>http://arxiv.org/abs/2412.17654v1</link><description>Spiking Neural Networks (SNNs) are a class of network models capable ofprocessing spatiotemporal information, with event-driven characteristics andenergy efficiency advantages. Recently, directly trained SNNs have shownpotential to match or surpass the performance of traditional Artificial NeuralNetworks (ANNs) in classification tasks. However, in object detection tasks,directly trained SNNs still exhibit a significant performance gap compared toANNs when tested on frame-based static object datasets (such as COCO2017).Therefore, bridging this performance gap and enabling directly trained SNNs toachieve performance comparable to ANNs on these static datasets has become oneof the key challenges in the development of SNNs.To address this challenge,this paper focuses on enhancing the SNN's unique ability to processspatiotemporal information. Spiking neurons, as the core components of SNNs,facilitate the exchange of information between different temporal channelsduring the process of converting input floating-point data into binary spikesignals. However, existing neuron models still have certain limitations in thecommunication of temporal information. Some studies have even suggested thatdisabling the backpropagation in the time dimension during SNN training canstill yield good training results. To improve the SNN handling of temporalinformation, this paper proposes replacing traditional 2D convolutions with 3Dconvolutions, thus directly incorporating temporal information into theconvolutional process. Additionally, temporal information recurrence mechanismis introduced within the neurons to further enhance the neurons' efficiency inutilizing temporal information.Experimental results show that the proposedmethod enables directly trained SNNs to achieve performance levels comparableto ANNs on the COCO2017 and VOC datasets.</description><author>Huaxu He</author><pubDate>Mon, 23 Dec 2024 15:32:26 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.17654v1</guid></item><item><title>Benchmarking Generative AI Models for Deep Learning Test Input Generation</title><link>http://arxiv.org/abs/2412.17652v1</link><description>Test Input Generators (TIGs) are crucial to assess the ability of DeepLearning (DL) image classifiers to provide correct predictions for inputsbeyond their training and test sets. Recent advancements in Generative AI(GenAI) models have made them a powerful tool for creating and manipulatingsynthetic images, although these advancements also imply increased complexityand resource demands for training. In this work, we benchmark and combine different GenAI models with TIGs,assessing their effectiveness, efficiency, and quality of the generated testimages, in terms of domain validity and label preservation. We conduct anempirical study involving three different GenAI architectures (VAEs, GANs,Diffusion Models), five classification tasks of increasing complexity, and 364human evaluations. Our results show that simpler architectures, such as VAEs,are sufficient for less complex datasets like MNIST. However, when dealing withfeature-rich datasets, such as ImageNet, more sophisticated architectures likeDiffusion Models achieve superior performance by generating a higher number ofvalid, misclassification-inducing inputs.</description><author>Maryam, Matteo Biagiola, Andrea Stocco, Vincenzo Riccio</author><pubDate>Mon, 23 Dec 2024 15:30:42 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.17652v1</guid></item><item><title>Detecting anxiety and depression in dialogues: a multi-label and explainable approach</title><link>http://arxiv.org/abs/2412.17651v1</link><description>Anxiety and depression are the most common mental health issues worldwide,affecting a non-negligible part of the population. Accordingly, stakeholders,including governments' health systems, are developing new strategies to promoteearly detection and prevention from a holistic perspective (i.e., addressingseveral disorders simultaneously). In this work, an entirely novel system forthe multi-label classification of anxiety and depression is proposed. The inputdata consists of dialogues from user interactions with an assistant chatbot.Another relevant contribution lies in using Large Language Models (LLMs) forfeature extraction, provided the complexity and variability of language. Thecombination of LLMs, given their high capability for language understanding,and Machine Learning (ML) models, provided their contextual knowledge about theclassification problem thanks to the labeled data, constitute a promisingapproach towards mental health assessment. To promote the solution'strustworthiness, reliability, and accountability, explainability descriptionsof the model's decision are provided in a graphical dashboard. Experimentalresults on a real dataset attain 90 % accuracy, improving those in the priorliterature. The ultimate objective is to contribute in an accessible andscalable way before formal treatment occurs in the healthcare systems.</description><author>Francisco de Arriba-Pérez, Silvia García-Méndez</author><pubDate>Mon, 23 Dec 2024 15:29:46 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.17651v1</guid></item><item><title>Sloth: scaling laws for LLM skills to predict multi-benchmark performance across families</title><link>http://arxiv.org/abs/2412.06540v2</link><description>Scaling laws for large language models (LLMs) predict model performance basedon parameters like size and training data. However, differences in trainingconfigurations and data processing across model families lead to significantvariations in benchmark performance, making it difficult for a single scalinglaw to generalize across all LLMs. On the other hand, training family-specificscaling laws requires training models of varying sizes for every family. Inthis work, we propose Skills Scaling Laws (SSLaws, pronounced as Sloth), anovel scaling law that leverages publicly available benchmark data and assumesLLM performance is driven by low-dimensional latent skills, such as reasoningand instruction following. These latent skills are influenced by computationalresources like model size and training tokens but with varying efficienciesacross model families. Sloth exploits correlations across benchmarks to providemore accurate and interpretable predictions while alleviating the need to trainmultiple LLMs per family. We present both theoretical results on parameteridentification and empirical evaluations on 12 prominent benchmarks, from OpenLLM Leaderboard v1/v2, demonstrating that Sloth predicts LLM performanceefficiently and offers insights into scaling behaviors for downstream taskssuch as coding and emotional intelligence applications.</description><author>Felipe Maia Polo, Seamus Somerstep, Leshem Choshen, Yuekai Sun, Mikhail Yurochkin</author><pubDate>Mon, 23 Dec 2024 15:29:22 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.06540v2</guid></item><item><title>Mirage: A Multi-Level Superoptimizer for Tensor Programs</title><link>http://arxiv.org/abs/2405.05751v2</link><description>We introduce Mirage, the first multi-level superoptimizer for tensorprograms. A key idea in Mirage is $\mu$Graphs, a uniform representation oftensor programs at the kernel, thread block, and thread levels of the GPUcompute hierarchy. $\mu$Graphs enable Mirage to discover novel optimizationsthat combine algebraic transformations, schedule transformations, andgeneration of new custom kernels. To navigate the large search space, Mirageintroduces a pruning technique based on abstraction that significantly reducesthe search space and provides a certain optimality guarantee. To ensure thatthe optimized $\mu$Graph is equivalent to the input program, Mirage introducesa probabilistic equivalence verification procedure with strong theoreticalguarantees. Our evaluation shows that Mirage outperforms existing approaches by1.1-2.9$\times$ even for DNNs that are widely used and heavily optimized.Mirage is publicly available at https://github.com/mirage-project/mirage.</description><author>Mengdi Wu, Xinhao Cheng, Shengyu Liu, Chunan Shi, Jianan Ji, Kit Ao, Praveen Velliengiri, Xupeng Miao, Oded Padon, Zhihao Jia</author><pubDate>Mon, 23 Dec 2024 15:28:18 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.05751v2</guid></item><item><title>Sharp bounds on aggregate expert error</title><link>http://arxiv.org/abs/2407.16642v4</link><description>We revisit the classic problem of aggregating binary advice fromconditionally independent experts, also known as the Naive Bayes setting. Ourquantity of interest is the error probability of the optimal decision rule. Inthe case of symmetric errors (sensitivity = specificity), reasonably tightbounds on the optimal error probability are known. In the general asymmetriccase, we are not aware of any nontrivial estimates on this quantity. Ourcontribution consists of sharp upper and lower bounds on the optimal errorprobability in the general case, which recover and sharpen the best knownresults in the symmetric special case. Since this turns out to be equivalent toestimating the total variation distance between two product distributions, ourresults also have bearing on this important and challenging problem.</description><author>Aryeh Kontorovich, Ariel Avital</author><pubDate>Mon, 23 Dec 2024 15:25:57 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.16642v4</guid></item><item><title>An Adaptive Framework for Multi-View Clustering Leveraging Conditional Entropy Optimization</title><link>http://arxiv.org/abs/2412.17647v1</link><description>Multi-view clustering (MVC) has emerged as a powerful technique forextracting valuable insights from data characterized by multiple perspectivesor modalities. Despite significant advancements, existing MVC methods strugglewith effectively quantifying the consistency and complementarity among views,and are particularly susceptible to the adverse effects of noisy views, knownas the Noisy-View Drawback (NVD). To address these challenges, we proposeCE-MVC, a novel framework that integrates an adaptive weighting algorithm witha parameter-decoupled deep model. Leveraging the concept of conditional entropyand normalized mutual information, CE-MVC quantitatively assesses and weightsthe informative contribution of each view, facilitating the construction ofrobust unified representations. The parameter-decoupled design enablesindependent processing of each view, effectively mitigating the influence ofnoise and enhancing overall clustering performance. Extensive experimentsdemonstrate that CE-MVC outperforms existing approaches, offering a moreresilient and accurate solution for multi-view clustering tasks.</description><author>Lijian Li</author><pubDate>Mon, 23 Dec 2024 15:21:55 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.17647v1</guid></item><item><title>Rate of Model Collapse in Recursive Training</title><link>http://arxiv.org/abs/2412.17646v1</link><description>Given the ease of creating synthetic data from machine learning models, newmodels can be potentially trained on synthetic data generated by previousmodels. This recursive training process raises concerns about the long-termimpact on model quality. As models are recursively trained on generated datafrom previous rounds, their ability to capture the nuances of the originalhuman-generated data may degrade. This is often referred to as \emph{modelcollapse}. In this work, we ask how fast model collapse occurs for somewell-studied distribution families under maximum likelihood (ML or near ML)estimation during recursive training. Surprisingly, even for fundamentaldistributions such as discrete and Gaussian distributions, the exact rate ofmodel collapse is unknown. In this work, we theoretically characterize the rateof collapse in these fundamental settings and complement it with experimentalevaluations. Our results show that for discrete distributions, the time toforget a word is approximately linearly dependent on the number of times itoccurred in the original corpus, and for Gaussian models, the standarddeviation reduces to zero roughly at $n$ iterations, where $n$ is the number ofsamples at each iteration. Both of these findings imply that model forgetting,at least in these simple distributions under near ML estimation with manysamples, takes a long time.</description><author>Ananda Theertha Suresh, Andrew Thangaraj, Aditya Nanda Kishore Khandavally</author><pubDate>Mon, 23 Dec 2024 15:21:50 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.17646v1</guid></item><item><title>DreamFit: Garment-Centric Human Generation via a Lightweight Anything-Dressing Encoder</title><link>http://arxiv.org/abs/2412.17644v1</link><description>Diffusion models for garment-centric human generation from text or imageprompts have garnered emerging attention for their great application potential.However, existing methods often face a dilemma: lightweight approaches, such asadapters, are prone to generate inconsistent textures; while finetune-basedmethods involve high training costs and struggle to maintain the generalizationcapabilities of pretrained diffusion models, limiting their performance acrossdiverse scenarios. To address these challenges, we propose DreamFit, whichincorporates a lightweight Anything-Dressing Encoder specifically tailored forthe garment-centric human generation. DreamFit has three key advantages: (1)\textbf{Lightweight training}: with the proposed adaptive attention and LoRAmodules, DreamFit significantly minimizes the model complexity to 83.4Mtrainable parameters. (2)\textbf{Anything-Dressing}: Our model generalizessurprisingly well to a wide range of (non-)garments, creative styles, andprompt instructions, consistently delivering high-quality results acrossdiverse scenarios. (3) \textbf{Plug-and-play}: DreamFit is engineered forsmooth integration with any community control plugins for diffusion models,ensuring easy compatibility and minimizing adoption barriers. To furtherenhance generation quality, DreamFit leverages pretrained large multi-modalmodels (LMMs) to enrich the prompt with fine-grained garment descriptions,thereby reducing the prompt gap between training and inference. We conductcomprehensive experiments on both $768 \times 512$ high-resolution benchmarksand in-the-wild images. DreamFit surpasses all existing methods, highlightingits state-of-the-art capabilities of garment-centric human generation.</description><author>Ente Lin, Xujie Zhang, Fuwei Zhao, Yuxuan Luo, Xin Dong, Long Zeng, Xiaodan Liang</author><pubDate>Mon, 23 Dec 2024 15:21:28 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.17644v1</guid></item><item><title>Advances in Machine Learning Research Using Knowledge Graphs</title><link>http://arxiv.org/abs/2412.17643v1</link><description>The study uses CSSCI-indexed literature from the China National KnowledgeInfrastructure (CNKI) database as the data source. It utilizes the CiteSpacevisualization software to draw knowledge graphs on aspects such asinstitutional collaboration and keyword co-occurrence. This analysis providesinsights into the current state of research and emerging trends in the field ofmachine learning in China. Additionally, it identifies the challenges faced inthe field of machine learning research and offers suggestions that could serveas valuable references for future research.</description><author>Jing Si, Jianfei Xu</author><pubDate>Mon, 23 Dec 2024 15:20:01 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.17643v1</guid></item><item><title>Hierarchical Vector Quantization for Unsupervised Action Segmentation</title><link>http://arxiv.org/abs/2412.17640v1</link><description>In this work, we address unsupervised temporal action segmentation, whichsegments a set of long, untrimmed videos into semantically meaningful segmentsthat are consistent across videos. While recent approaches combinerepresentation learning and clustering in a single step for this task, they donot cope with large variations within temporal segments of the same class. Toaddress this limitation, we propose a novel method, termed Hierarchical VectorQuantization (\ours), that consists of two subsequent vector quantizationmodules. This results in a hierarchical clustering where the additionalsubclusters cover the variations within a cluster. We demonstrate that ourapproach captures the distribution of segment lengths much better than thestate of the art. To this end, we introduce a new metric based on theJensen-Shannon Distance (JSD) for unsupervised temporal action segmentation. Weevaluate our approach on three public datasets, namely Breakfast, YouTubeInstructional and IKEA ASM. Our approach outperforms the state of the art interms of F1 score, recall and JSD.</description><author>Federico Spurio, Emad Bahrami, Gianpiero Francesca, Juergen Gall</author><pubDate>Mon, 23 Dec 2024 15:18:24 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.17640v1</guid></item><item><title>SCBench: A Sports Commentary Benchmark for Video LLMs</title><link>http://arxiv.org/abs/2412.17637v1</link><description>Recently, significant advances have been made in Video Large Language Models(Video LLMs) in both academia and industry. However, methods to evaluate andbenchmark the performance of different Video LLMs, especially theirfine-grained, temporal visual capabilities, remain very limited. On one hand,current benchmarks use relatively simple videos (e.g., subtitled movie clips)where the model can understand the entire video by processing just a fewframes. On the other hand, their datasets lack diversity in task format,comprising only QA or multi-choice QA, which overlooks the models' capacity forgenerating in-depth and precise texts. Sports videos, which feature intricatevisual information, sequential events, and emotionally charged commentary,present a critical challenge for Video LLMs, making sports commentary an idealbenchmarking task. Inspired by these challenges, we propose a novel task:sports video commentary generation, developed $\textbf{SCBench}$ for VideoLLMs. To construct such a benchmark, we introduce (1) $\textbf{SCORES}$, asix-dimensional metric specifically designed for our task, upon which wepropose a GPT-based evaluation method, and (2) $\textbf{CommentarySet}$, adataset consisting of 5,775 annotated video clips and ground-truth labelstailored to our metric. Based on SCBench, we conduct comprehensive evaluationson multiple Video LLMs (e.g. VILA, Video-LLaVA, etc.) and chain-of-thoughtbaseline methods. Our results found that InternVL-Chat-2 achieves the bestperformance with 5.44, surpassing the second-best by 1.04. Our work provides afresh perspective for future research, aiming to enhance models' overallcapabilities in complex visual understanding tasks. Our dataset will bereleased soon.</description><author>Kuangzhi Ge, Lingjun Chen, Kevin Zhang, Yulin Luo, Tianyu Shi, Liaoyuan Fan, Xiang Li, Guanqun Wang, Shanghang Zhang</author><pubDate>Mon, 23 Dec 2024 15:13:56 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.17637v1</guid></item><item><title>LangSurf: Language-Embedded Surface Gaussians for 3D Scene Understanding</title><link>http://arxiv.org/abs/2412.17635v1</link><description>Applying Gaussian Splatting to perception tasks for 3D scene understanding isbecoming increasingly popular. Most existing works primarily focus on rendering2D feature maps from novel viewpoints, which leads to an imprecise 3D languagefield with outlier languages, ultimately failing to align objects in 3D space.By utilizing masked images for feature extraction, these approaches also lackessential contextual information, leading to inaccurate feature representation.To this end, we propose a Language-Embedded Surface Field (LangSurf), whichaccurately aligns the 3D language fields with the surface of objects,facilitating precise 2D and 3D segmentation with text query, widely expandingthe downstream tasks such as removal and editing. The core of LangSurf is ajoint training strategy that flattens the language Gaussian on the objectsurfaces using geometry supervision and contrastive losses to assign accuratelanguage features to the Gaussians of objects. In addition, we also introducethe Hierarchical-Context Awareness Module to extract features at the imagelevel for contextual information then perform hierarchical mask pooling usingmasks segmented by SAM to obtain fine-grained language features in differenthierarchies. Extensive experiments on open-vocabulary 2D and 3D semanticsegmentation demonstrate that LangSurf outperforms the previousstate-of-the-art method LangSplat by a large margin. As shown inFig.~\ref{fig:teaser}, our method is capable of segmenting objects in 3D space,thus boosting the effectiveness of our approach in instance recognition,removal, and editing, which is also supported by comprehensive experiments.\url{https://langsurf.github.io}{Project Page}.</description><author>Hao Li, Roy Qin, Zhengyu Zou, Diqi He, Bohan Li, Bingquan Dai, Dingewn Zhang, Junwei Han</author><pubDate>Mon, 23 Dec 2024 15:12:20 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.17635v1</guid></item><item><title>Evaluating Image Hallucination in Text-to-Image Generation with Question-Answering</title><link>http://arxiv.org/abs/2409.12784v6</link><description>Despite the impressive success of text-to-image (TTI) generation models,existing studies overlook the issue of whether these models accurately conveyfactual information. In this paper, we focus on the problem of imagehallucination, where images created by generation models fail to faithfullydepict factual content. To address this, we introduce I-HallA (ImageHallucination evaluation with Question Answering), a novel automated evaluationmetric that measures the factuality of generated images through visual questionanswering (VQA). We also introduce I-HallA v1.0, a curated benchmark datasetfor this purpose. As part of this process, we develop a pipeline that generateshigh-quality question-answer pairs using multiple GPT-4 Omni-based agents, withhuman judgments to ensure accuracy. Our evaluation protocols measure imagehallucination by testing if images from existing TTI models can correctlyrespond to these questions. The I-HallA v1.0 dataset comprises 1.2K diverseimage-text pairs across nine categories with 1,000 rigorously curated questionscovering various compositional challenges. We evaluate five TTI models usingI-HallA and reveal that these state-of-the-art models often fail to accuratelyconvey factual information. Moreover, we validate the reliability of our metricby demonstrating a strong Spearman correlation ($\rho$=0.95) with humanjudgments. We believe our benchmark dataset and metric can serve as afoundation for developing factually accurate TTI generation models. Additionalresources can be found on our project page: https://sgt-lim.github.io/I-HallA/.</description><author>Youngsun Lim, Hojun Choi, Hyunjung Shim</author><pubDate>Mon, 23 Dec 2024 15:08:35 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2409.12784v6</guid></item><item><title>ANID: How Far Are We? Evaluating the Discrepancies Between AI-synthesized Images and Natural Images through Multimodal Guidance</title><link>http://arxiv.org/abs/2412.17632v1</link><description>In the rapidly evolving field of Artificial Intelligence Generated Content(AIGC), one of the key challenges is distinguishing AI-synthesized images fromnatural images. Despite the remarkable capabilities of advanced AI generativemodels in producing visually compelling images, significant discrepanciesremain when these images are compared to natural ones. To systematicallyinvestigate and quantify these discrepancies, we introduce an AI-Natural ImageDiscrepancy Evaluation benchmark aimed at addressing the critical question:\textit{how far are AI-generated images (AIGIs) from truly realistic images?}We have constructed a large-scale multimodal dataset, the DistinguishingNatural and AI-generated Images (DNAI) dataset, which includes over 440,000AIGI samples generated by 8 representative models using both unimodal andmultimodal prompts, such as Text-to-Image (T2I), Image-to-Image (I2I), and Text\textit{vs.} Image-to-Image (TI2I). Our fine-grained assessment frameworkprovides a comprehensive evaluation of the DNAI dataset across five keydimensions: naive visual feature quality, semantic alignment in multimodalgeneration, aesthetic appeal, downstream task applicability, and coordinatedhuman validation. Extensive evaluation results highlight significantdiscrepancies across these dimensions, underscoring the necessity of aligningquantitative metrics with human judgment to achieve a holistic understanding ofAI-generated image quality. Code is available at\href{https://github.com/ryliu68/ANID}{https://github.com/ryliu68/ANID}.</description><author>Renyang Liu, Ziyu Lyu, Wei Zhou, See-Kiong Ng</author><pubDate>Mon, 23 Dec 2024 15:08:08 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.17632v1</guid></item><item><title>Detail-Preserving Latent Diffusion for Stable Shadow Removal</title><link>http://arxiv.org/abs/2412.17630v1</link><description>Achieving high-quality shadow removal with strong generalizability ischallenging in scenes with complex global illumination. Due to the limiteddiversity in shadow removal datasets, current methods are prone to overfittingtraining data, often leading to reduced performance on unseen cases. To addressthis, we leverage the rich visual priors of a pre-trained Stable Diffusion (SD)model and propose a two-stage fine-tuning pipeline to adapt the SD model forstable and efficient shadow removal. In the first stage, we fix the VAE andfine-tune the denoiser in latent space, which yields substantial shadow removalbut may lose some high-frequency details. To resolve this, we introduce asecond stage, called the detail injection stage. This stage selectivelyextracts features from the VAE encoder to modulate the decoder, injecting finedetails into the final results. Experimental results show that our methodoutperforms state-of-the-art shadow removal techniques. The cross-datasetevaluation further demonstrates that our method generalizes effectively tounseen data, enhancing the applicability of shadow removal methods.</description><author>Jiamin Xu, Yuxin Zheng, Zelong Li, Chi Wang, Renshu Gu, Weiwei Xu, Gang Xu</author><pubDate>Mon, 23 Dec 2024 15:06:46 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.17630v1</guid></item><item><title>Graph Neural Networks Are Evolutionary Algorithms</title><link>http://arxiv.org/abs/2412.17629v1</link><description>In this paper, we reveal the intrinsic duality between graph neural networks(GNNs) and evolutionary algorithms (EAs), bridging two traditionally distinctfields. Building on this insight, we propose Graph Neural Evolution (GNE), anovel evolutionary algorithm that models individuals as nodes in a graph andleverages designed frequency-domain filters to balance global exploration andlocal exploitation. Through the use of these filters, GNE aggregateshigh-frequency (diversity-enhancing) and low-frequency (stability-promoting)information, transforming EAs into interpretable and tunable mechanisms in thefrequency domain. Extensive experiments on benchmark functions demonstrate thatGNE consistently outperforms state-of-the-art algorithms such as GA, DE,CMA-ES, SDAES, and RL-SHADE, excelling in complex landscapes, optimal solutionshifts, and noisy environments. Its robustness, adaptability, and superiorconvergence highlight its practical and theoretical value. Beyond optimization,GNE establishes a conceptual and mathematical foundation linking EAs and GNNs,offering new perspectives for both fields. Its framework encourages thedevelopment of task-adaptive filters and hybrid approaches for EAs, while itsinsights can inspire advances in GNNs, such as improved global informationpropagation and mitigation of oversmoothing. GNE's versatility extends tosolving challenges in machine learning, including hyperparameter tuning andneural architecture search, as well as real-world applications in engineeringand operations research. By uniting the dynamics of EAs with the structuralinsights of GNNs, this work provides a foundation for interdisciplinaryinnovation, paving the way for scalable and interpretable solutions to complexoptimization problems.</description><author>Kaichen Ouyang, Shengwei Fu</author><pubDate>Mon, 23 Dec 2024 15:06:37 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.17629v1</guid></item><item><title>Editing Implicit and Explicit Representations of Radiance Fields: A Survey</title><link>http://arxiv.org/abs/2412.17628v1</link><description>Neural Radiance Fields (NeRF) revolutionized novel view synthesis in recentyears by offering a new volumetric representation, which is compact andprovides high-quality image rendering. However, the methods to edit thoseradiance fields developed slower than the many improvements to other aspects ofNeRF. With the recent development of alternative radiance field-basedrepresentations inspired by NeRF as well as the worldwide rise in popularity oftext-to-image models, many new opportunities and strategies have emerged toprovide radiance field editing. In this paper, we deliver a comprehensivesurvey of the different editing methods present in the literature for NeRF andother similar radiance field representations. We propose a new taxonomy forclassifying existing works based on their editing methodologies, reviewpioneering models, reflect on current and potential new applications ofradiance field editing, and compare state-of-the-art approaches in terms ofediting options and performance.</description><author>Arthur Hubert, Gamal Elghazaly, Raphael Frank</author><pubDate>Mon, 23 Dec 2024 14:59:46 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.17628v1</guid></item><item><title>Tracking the Feature Dynamics in LLM Training: A Mechanistic Study</title><link>http://arxiv.org/abs/2412.17626v1</link><description>Understanding training dynamics and feature evolution is crucial for themechanistic interpretability of large language models (LLMs). Although sparseautoencoders (SAEs) have been used to identify features within LLMs, a clearpicture of how these features evolve during training remains elusive. In thisstudy, we: (1) introduce SAE-Track, a method to efficiently obtain a continualseries of SAEs; (2) formulate the process of feature formation and conduct amechanistic analysis; and (3) analyze and visualize feature drift duringtraining. Our work provides new insights into the dynamics of features in LLMs,enhancing our understanding of training mechanisms and feature evolution.</description><author>Yang Xu, Yi Wang, Hao Wang</author><pubDate>Mon, 23 Dec 2024 14:58:37 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.17626v1</guid></item><item><title>Towards An Unsupervised Learning Scheme for Efficiently Solving Parameterized Mixed-Integer Programs</title><link>http://arxiv.org/abs/2412.17623v1</link><description>In this paper, we describe a novel unsupervised learning scheme foraccelerating the solution of a family of mixed integer programming (MIP)problems. Distinct substantially from existing learning-to-optimize methods,our proposal seeks to train an autoencoder (AE) for binary variables in anunsupervised learning fashion, using data of optimal solutions to historicalinstances for a parametric family of MIPs.By a deliberate design of AEarchitecture and exploitation of its statistical implication, we present asimple and straightforward strategy to construct a class of cutting planeconstraints from the decoder parameters of an offline-trained AE. Theseconstraints reliably enclose the optimal binary solutions of new probleminstances thanks to the representation strength of the AE. More importantly,their integration into the primal MIP problem leads to a tightened MIP with thereduced feasible region, which can be resolved at decision time usingoff-the-shelf solvers with much higher efficiency. Our method is applied to abenchmark batch process scheduling problem formulated as a mixed integer linearprogramming (MILP) problem. Comprehensive results demonstrate that our approachsignificantly reduces the computational cost of off-the-shelf MILP solverswhile retaining a high solution quality. The codes of this work areopen-sourced at https://github.com/qushiyuan/AE4BV.</description><author>Shiyuan Qu, Fenglian Dong, Zhiwei Wei, Chao Shang</author><pubDate>Mon, 23 Dec 2024 14:48:32 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.17623v1</guid></item><item><title>Be More Diverse than the Most Diverse: Online Selection of Diverse Mixtures of Generative Models</title><link>http://arxiv.org/abs/2412.17622v1</link><description>The availability of multiple training algorithms and architectures forgenerative models requires a selection mechanism to form a single model over agroup of well-trained generation models. The selection task is commonlyaddressed by identifying the model that maximizes an evaluation score based onthe diversity and quality of the generated data. However, such a best-modelidentification approach overlooks the possibility that a mixture of availablemodels can outperform each individual model. In this work, we explore theselection of a mixture of multiple generative models and formulate a quadraticoptimization problem to find an optimal mixture model achieving the maximum ofkernel-based evaluation scores including kernel inception distance (KID) andR\'{e}nyi kernel entropy (RKE). To identify the optimal mixture of the modelsusing the fewest possible sample queries, we propose an online learningapproach called Mixture Upper Confidence Bound (Mixture-UCB). Specifically, ourproposed online learning method can be extended to every convex quadraticfunction of the mixture weights, for which we prove a concentration bound toenable the application of the UCB approach. We prove a regret bound for theproposed Mixture-UCB algorithm and perform several numerical experiments toshow the success of the proposed Mixture-UCB method in finding the optimalmixture of text-based and image-based generative models. The codebase isavailable at https://github.com/Rezaei-Parham/Mixture-UCB .</description><author>Parham Rezaei, Farzan Farnia, Cheuk Ting Li</author><pubDate>Mon, 23 Dec 2024 14:48:17 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.17622v1</guid></item></channel></rss>