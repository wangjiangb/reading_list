<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/"><channel><title>Arxivfresh papers</title><link></link><description>Arxiv paper</description><language>en-US</language><lastBuildDate>Thu, 06 Jun 2024 06:00:19 GMT</lastBuildDate><generator>rfeed v1.0.0</generator><docs>https://github.com/svpino/rfeed/blob/master/README.md</docs><item><title>Wings: Learning Multimodal LLMs without Text-only Forgetting</title><link>http://arxiv.org/abs/2406.03496v1</link><description>Multimodal large language models (MLLMs), initiated with a trained LLM, firstalign images with text and then fine-tune on multimodal mixed inputs. However,the MLLM catastrophically forgets the text-only instructions, which do notinclude images and can be addressed within the initial LLM. In this paper, wepresent Wings, a novel MLLM that excels in both text-only dialogues andmultimodal comprehension. Analyzing MLLM attention in multimodal instructionsreveals that text-only forgetting is related to the attention shifts frompre-image to post-image text. From that, we construct extra modules that act asthe boosted learner to compensate for the attention shift. The complementaryvisual and textual learners, like "wings" on either side, are connected inparallel within each layer's attention block. Initially, image and text inputsare aligned with visual learners operating alongside the main attention,balancing focus on visual elements. Textual learners are later collaborativelyintegrated with attention-based routing to blend the outputs of the visual andtextual learners. We design the Low-Rank Residual Attention (LoRRA) toguarantee high efficiency for learners. Our experimental results demonstratethat Wings outperforms equally-scaled MLLMs in both text-only and visualquestion-answering tasks. On a newly constructed Interleaved Image-Text (IIT)benchmark, Wings exhibits superior performance from text-only-rich tomultimodal-rich question-answering tasks.</description><author>Yi-Kai Zhang, Shiyin Lu, Yang Li, Yanqing Ma, Qing-Guo Chen, Zhao Xu, Weihua Luo, Kaifu Zhang, De-Chuan Zhan, Han-Jia Ye</author><pubDate>Wed, 05 Jun 2024 18:59:40 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.03496v1</guid></item><item><title>Grokking Modular Polynomials</title><link>http://arxiv.org/abs/2406.03495v1</link><description>Neural networks readily learn a subset of the modular arithmetic tasks, whilefailing to generalize on the rest. This limitation remains unmoved by thechoice of architecture and training strategies. On the other hand, ananalytical solution for the weights of Multi-layer Perceptron (MLP) networksthat generalize on the modular addition task is known in the literature. Inthis work, we (i) extend the class of analytical solutions to include modularmultiplication as well as modular addition with many terms. Additionally, weshow that real networks trained on these datasets learn similar solutions upongeneralization (grokking). (ii) We combine these "expert" solutions toconstruct networks that generalize on arbitrary modular polynomials. (iii) Wehypothesize a classification of modular polynomials into learnable andnon-learnable via neural networks training; and provide experimental evidencesupporting our claims.</description><author>Darshil Doshi, Tianyu He, Aritra Das, Andrey Gromov</author><pubDate>Wed, 05 Jun 2024 18:59:35 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.03495v1</guid></item><item><title>Solving Poisson Equations using Neural Walk-on-Spheres</title><link>http://arxiv.org/abs/2406.03494v1</link><description>We propose Neural Walk-on-Spheres (NWoS), a novel neural PDE solver for theefficient solution of high-dimensional Poisson equations. Leveraging stochasticrepresentations and Walk-on-Spheres methods, we develop novel losses for neuralnetworks based on the recursive solution of Poisson equations on spheres insidethe domain. The resulting method is highly parallelizable and does not requirespatial gradients for the loss. We provide a comprehensive comparison againstcompeting methods based on PINNs, the Deep Ritz method, and (backward)stochastic differential equations. In several challenging, high-dimensionalnumerical examples, we demonstrate the superiority of NWoS in accuracy, speed,and computational costs. Compared to commonly used PINNs, our approach canreduce memory usage and errors by orders of magnitude. Furthermore, we applyNWoS to problems in PDE-constrained optimization and molecular dynamics to showits efficiency in practical applications.</description><author>Hong Chul Nam, Julius Berner, Anima Anandkumar</author><pubDate>Wed, 05 Jun 2024 18:59:22 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.03494v1</guid></item><item><title>Push Past Green: Learning to Look Behind Plant Foliage by Moving It</title><link>http://arxiv.org/abs/2307.03175v2</link><description>Autonomous agriculture applications (e.g., inspection, phenotyping, pluckingfruits) require manipulating the plant foliage to look behind the leaves andthe branches. Partial visibility, extreme clutter, thin structures, and unknowngeometry and dynamics for plants make such manipulation challenging. We tacklethese challenges through data-driven methods. We use self-supervision to trainSRPNet, a neural network that predicts what space is revealed on execution of acandidate action on a given plant. We use SRPNet with the cross-entropy methodto predict actions that are effective at revealing space beneath plant foliage.Furthermore, as SRPNet does not just predict how much space is revealed butalso where it is revealed, we can execute a sequence of actions thatincrementally reveal more and more space beneath the plant foliage. Weexperiment with a synthetic (vines) and a real plant (Dracaena) on a physicaltest-bed across 5 settings including 2 settings that test generalization tonovel plant configurations. Our experiments reveal the effectiveness of ouroverall method, PPG, over a competitive hand-crafted exploration method, andthe effectiveness of SRPNet over a hand-crafted dynamics model and relevantablations.</description><author>Xiaoyu Zhang, Saurabh Gupta</author><pubDate>Wed, 05 Jun 2024 18:59:01 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.03175v2</guid></item><item><title>Future Directions in the Theory of Graph Machine Learning</title><link>http://arxiv.org/abs/2402.02287v3</link><description>Machine learning on graphs, especially using graph neural networks (GNNs),has seen a surge in interest due to the wide availability of graph data acrossa broad spectrum of disciplines, from life to social and engineering sciences.Despite their practical success, our theoretical understanding of theproperties of GNNs remains highly incomplete. Recent theoretical advancementsprimarily focus on elucidating the coarse-grained expressive power of GNNs,predominantly employing combinatorial techniques. However, these studies do notperfectly align with practice, particularly in understanding the generalizationbehavior of GNNs when trained with stochastic first-order optimizationtechniques. In this position paper, we argue that the graph machine learningcommunity needs to shift its attention to developing a balanced theory of graphmachine learning, focusing on a more thorough understanding of the interplay ofexpressive power, generalization, and optimization.</description><author>Christopher Morris, Fabrizio Frasca, Nadav Dym, Haggai Maron, İsmail İlkan Ceylan, Ron Levie, Derek Lim, Michael Bronstein, Martin Grohe, Stefanie Jegelka</author><pubDate>Wed, 05 Jun 2024 18:55:43 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.02287v3</guid></item><item><title>On the Universality of Coupling-based Normalizing Flows</title><link>http://arxiv.org/abs/2402.06578v2</link><description>We present a novel theoretical framework for understanding the expressivepower of normalizing flows. Despite their prevalence in scientificapplications, a comprehensive understanding of flows remains elusive due totheir restricted architectures. Existing theorems fall short as they requirethe use of arbitrarily ill-conditioned neural networks, limiting practicalapplicability. We propose a distributional universality theorem forwell-conditioned coupling-based normalizing flows such as RealNVP. In addition,we show that volume-preserving normalizing flows are not universal, whatdistribution they learn instead, and how to fix their expressivity. Our resultssupport the general wisdom that affine and related couplings are expressive andin general outperform volume-preserving flows, bridging a gap between empiricalresults and theoretical understanding.</description><author>Felix Draxler, Stefan Wahl, Christoph Schnörr, Ullrich Köthe</author><pubDate>Wed, 05 Jun 2024 18:52:14 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.06578v2</guid></item><item><title>Analyzing LLM Behavior in Dialogue Summarization: Unveiling Circumstantial Hallucination Trends</title><link>http://arxiv.org/abs/2406.03487v1</link><description>Recent advancements in large language models (LLMs) have considerablyadvanced the capabilities of summarization systems. However, they continue toface concerns about hallucinations. While prior work has evaluated LLMsextensively in news domains, most evaluation of dialogue summarization hasfocused on BART-based models, leaving a gap in our understanding of theirfaithfulness. Our work benchmarks the faithfulness of LLMs for dialoguesummarization, using human annotations and focusing on identifying andcategorizing span-level inconsistencies. Specifically, we focus on twoprominent LLMs: GPT-4 and Alpaca-13B. Our evaluation reveals subtleties as towhat constitutes a hallucination: LLMs often generate plausible inferences,supported by circumstantial evidence in the conversation, that lack directevidence, a pattern that is less prevalent in older models. We propose arefined taxonomy of errors, coining the category of "Circumstantial Inference"to bucket these LLM behaviors and release the dataset. Using our taxonomy, wecompare the behavioral differences between LLMs and older fine-tuned models.Additionally, we systematically assess the efficacy of automatic errordetection methods on LLM summaries and find that they struggle to detect thesenuanced errors. To address this, we introduce two prompt-based approaches forfine-grained error detection that outperform existing metrics, particularly foridentifying "Circumstantial Inference."</description><author>Sanjana Ramprasad, Elisa Ferracane, Zachary C. Lipton</author><pubDate>Wed, 05 Jun 2024 18:49:47 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.03487v1</guid></item><item><title>BIPED: Pedagogically Informed Tutoring System for ESL Education</title><link>http://arxiv.org/abs/2406.03486v1</link><description>Large Language Models (LLMs) have a great potential to serve as readilyavailable and cost-efficient Conversational Intelligent Tutoring Systems (CITS)for teaching L2 learners of English. Existing CITS, however, are designed toteach only simple concepts or lack the pedagogical depth necessary to addressdiverse learning strategies. To develop a more pedagogically informed CITScapable of teaching complex concepts, we construct a BIlingualPEDagogically-informed Tutoring Dataset (BIPED) of one-on-one, human-to-humanEnglish tutoring interactions. Through post-hoc analysis of the tutoringinteractions, we come up with a lexicon of dialogue acts (34 tutor acts and 9student acts), which we use to further annotate the collected dataset. Based ona two-step framework of first predicting the appropriate tutor act thengenerating the corresponding response, we implemented two CITS models usingGPT-4 and SOLAR-KO, respectively. We experimentally demonstrate that theimplemented models not only replicate the style of human teachers but alsoemploy diverse and contextually appropriate pedagogical strategies.</description><author>Soonwoo Kwon, Sojung Kim, Minju Park, Seunghyun Lee, Kyuseok Kim</author><pubDate>Wed, 05 Jun 2024 18:49:24 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.03486v1</guid></item><item><title>Highway Value Iteration Networks</title><link>http://arxiv.org/abs/2406.03485v1</link><description>Value iteration networks (VINs) enable end-to-end learning for planning tasksby employing a differentiable "planning module" that approximates the valueiteration algorithm. However, long-term planning remains a challenge becausetraining very deep VINs is difficult. To address this problem, we embed highwayvalue iteration -- a recent algorithm designed to facilitate long-term creditassignment -- into the structure of VINs. This improvement augments the"planning module" of the VIN with three additional components: 1) an "aggregategate," which constructs skip connections to improve information flow acrossmany layers; 2) an "exploration module," crafted to increase the diversity ofinformation and gradient flow in spatial dimensions; 3) a "filter gate"designed to ensure safe exploration. The resulting novel highway VIN can betrained effectively with hundreds of layers using standard backpropagation. Inlong-term planning tasks requiring hundreds of planning steps, deep highwayVINs outperform both traditional VINs and several advanced, very deep NNs.</description><author>Yuhui Wang, Weida Li, Francesco Faccio, Qingyuan Wu, Jürgen Schmidhuber</author><pubDate>Wed, 05 Jun 2024 18:46:26 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.03485v1</guid></item><item><title>Class-Level Code Generation from Natural Language Using Iterative, Tool-Enhanced Reasoning over Repository</title><link>http://arxiv.org/abs/2405.01573v2</link><description>LLMs have demonstrated significant potential in code generation tasks,achieving promising results at the function or statement level across variousbenchmarks. However, the complexities associated with creating code artifactslike classes, particularly within the context of real-world softwarerepositories, remain underexplored. Prior research treats class-levelgeneration as an isolated task, neglecting the intricate dependencies &amp;interactions that characterize real-world software environments. To addressthis gap, we introduce RepoClassBench, a comprehensive benchmark designed torigorously evaluate LLMs in generating complex, class-level code withinreal-world repositories. RepoClassBench includes "Natural Language to Classgeneration" tasks across Java, Python &amp; C# from a selection of repositories. Weensure that each class in our dataset not only has cross-file dependencieswithin the repository but also includes corresponding test cases to verify itsfunctionality. We find that current models struggle with the realisticchallenges posed by our benchmark, primarily due to their limited exposure torelevant repository contexts. To address this shortcoming, we introduceRetrieve-Repotools-Reflect (RRR), a novel approach that equips LLMs with staticanalysis tools to iteratively navigate &amp; reason about repository-level contextin an agent-based framework. Our experiments demonstrate that RRR significantlyoutperforms existing baselines on RepoClassBench, showcasing its effectivenessacross programming languages &amp; under various settings. Our findings emphasizethe critical need for code-generation benchmarks to incorporate repo-leveldependencies to more accurately reflect the complexities of softwaredevelopment. Our work shows the benefits of leveraging specialized tools toenhance LLMs' understanding of repository context. We plan to make our dataset&amp; evaluation harness public.</description><author>Ajinkya Deshpande, Anmol Agarwal, Shashank Shet, Arun Iyer, Aditya Kanade, Ramakrishna Bairi, Suresh Parthasarathy</author><pubDate>Wed, 05 Jun 2024 18:44:24 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.01573v2</guid></item><item><title>The Heuristic Core: Understanding Subnetwork Generalization in Pretrained Language Models</title><link>http://arxiv.org/abs/2403.03942v2</link><description>Prior work has found that pretrained language models (LMs) fine-tuned withdifferent random seeds can achieve similar in-domain performance but generalizedifferently on tests of syntactic generalization. In this work, we show that,even within a single model, we can find multiple subnetworks that performsimilarly in-domain, but generalize vastly differently. To better understandthese phenomena, we investigate if they can be understood in terms of"competing subnetworks": the model initially represents a variety of distinctalgorithms, corresponding to different subnetworks, and generalization occurswhen it ultimately converges to one. This explanation has been used to accountfor generalization in simple algorithmic tasks ("grokking"). Instead of findingcompeting subnetworks, we find that all subnetworks -- whether they generalizeor not -- share a set of attention heads, which we refer to as the heuristiccore. Further analysis suggests that these attention heads emerge early intraining and compute shallow, non-generalizing features. The model learns togeneralize by incorporating additional attention heads, which depend on theoutputs of the "heuristic" heads to compute higher-level features. Overall, ourresults offer a more detailed picture of the mechanisms for syntacticgeneralization in pretrained LMs.</description><author>Adithya Bhaskar, Dan Friedman, Danqi Chen</author><pubDate>Wed, 05 Jun 2024 18:44:03 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.03942v2</guid></item><item><title>QJL: 1-Bit Quantized JL Transform for KV Cache Quantization with Zero Overhead</title><link>http://arxiv.org/abs/2406.03482v1</link><description>Serving LLMs requires substantial memory due to the storage requirements ofKey-Value (KV) embeddings in the KV cache, which grows with sequence length. Aneffective approach to compress KV cache is quantization. However, traditionalquantization methods face significant memory overhead due to the need to storequantization constants (at least a zero point and a scale) in full precisionper data block. Depending on the block size, this overhead can add 1 or 2 bitsper quantized number. We introduce QJL, a new quantization approach thatconsists of a Johnson-Lindenstrauss (JL) transform followed by sign-bitquantization. In contrast to existing methods, QJL eliminates memory overheadsby removing the need for storing quantization constants. We propose anasymmetric estimator for the inner product of two vectors and demonstrate thatapplying QJL to one vector and a standard JL transform without quantization tothe other provides an unbiased estimator with minimal distortion. We havedeveloped an efficient implementation of the QJL sketch and its correspondinginner product estimator, incorporating a lightweight CUDA kernel for optimizedcomputation. When applied across various LLMs and NLP tasks to quantize the KVcache to only 3 bits, QJL demonstrates a more than fivefold reduction in KVcache memory usage without compromising accuracy, all while achieving fasterruntime. Codes are available at \url{https://github.com/amirzandieh/QJL}.</description><author>Amir Zandieh, Majid Daliri, Insu Han</author><pubDate>Wed, 05 Jun 2024 18:42:05 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.03482v1</guid></item><item><title>Confronting Reward Overoptimization for Diffusion Models: A Perspective of Inductive and Primacy Biases</title><link>http://arxiv.org/abs/2402.08552v2</link><description>Bridging the gap between diffusion models and human preferences is crucialfor their integration into practical generative workflows. While optimizingdownstream reward models has emerged as a promising alignment strategy,concerns arise regarding the risk of excessive optimization with learned rewardmodels, which potentially compromises ground-truth performance. In this work,we confront the reward overoptimization problem in diffusion model alignmentthrough the lenses of both inductive and primacy biases. We first identify amismatch between current methods and the temporal inductive bias inherent inthe multi-step denoising process of diffusion models, as a potential source ofreward overoptimization. Then, we surprisingly discover that dormant neurons inour critic model act as a regularization against reward overoptimization whileactive neurons reflect primacy bias. Motivated by these observations, wepropose Temporal Diffusion Policy Optimization with critic active neuron Reset(TDPO-R), a policy gradient algorithm that exploits the temporal inductive biasof diffusion models and mitigates the primacy bias stemming from activeneurons. Empirical results demonstrate the superior efficacy of our methods inmitigating reward overoptimization. Code is avaliable athttps://github.com/ZiyiZhang27/tdpo.</description><author>Ziyi Zhang, Sen Zhang, Yibing Zhan, Yong Luo, Yonggang Wen, Dacheng Tao</author><pubDate>Wed, 05 Jun 2024 18:36:47 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.08552v2</guid></item><item><title>Diffusion Meets DAgger: Supercharging Eye-in-hand Imitation Learning</title><link>http://arxiv.org/abs/2402.17768v2</link><description>A common failure mode for policies trained with imitation is compoundingexecution errors at test time. When the learned policy encounters states thatare not present in the expert demonstrations, the policy fails, leading todegenerate behavior. The Dataset Aggregation, or DAgger approach to thisproblem simply collects more data to cover these failure states. However, inpractice, this is often prohibitively expensive. In this work, we proposeDiffusion Meets DAgger (DMD), a method to reap the benefits of DAgger withoutthe cost for eye-in-hand imitation learning problems. Instead of collecting newsamples to cover out-of-distribution states, DMD uses recent advances indiffusion models to synthesize these samples. This leads to robust performancefrom few demonstrations. We compare DMD against behavior cloning baselineacross four tasks: pushing, stacking, pouring, and shirt hanging. In pushing,DMD achieves 80% success rate with as few as 8 expert demonstrations, wherenaive behavior cloning reaches only 20%. In stacking, DMD succeeds on average92% of the time across 5 cups, versus 40% for BC. When pouring coffee beans,DMD transfers to another cup successfully 80% of the time. Finally, DMD attains90% success rate for hanging shirt on a clothing rack.</description><author>Xiaoyu Zhang, Matthew Chang, Pranav Kumar, Saurabh Gupta</author><pubDate>Wed, 05 Jun 2024 18:33:56 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.17768v2</guid></item><item><title>MODABS: Multi-Objective Learning for Dynamic Aspect-Based Summarization</title><link>http://arxiv.org/abs/2406.03479v1</link><description>The rapid proliferation of online content necessitates effectivesummarization methods, among which dynamic aspect-based summarization standsout. Unlike its traditional counterpart, which assumes a fixed set of knownaspects, this approach adapts to the varied aspects of the input text. Weintroduce a novel multi-objective learning framework employing aLongformer-Encoder-Decoder for this task. The framework optimizes aspect numberprediction, minimizes disparity between generated and reference summaries foreach aspect, and maximizes dissimilarity across aspect-specific summaries.Extensive experiments show our method significantly outperforms baselines onthree diverse datasets, largely due to the effective alignment of generated andreference aspect counts without sacrificing single-aspect summarizationquality.</description><author>Xiaobo Guo, Soroush Vosoughi</author><pubDate>Wed, 05 Jun 2024 18:32:28 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.03479v1</guid></item><item><title>Convolutional Neural Networks and Vision Transformers for Fashion MNIST Classification: A Literature Review</title><link>http://arxiv.org/abs/2406.03478v1</link><description>Our review explores the comparative analysis between Convolutional NeuralNetworks (CNNs) and Vision Transformers (ViTs) in the domain of imageclassification, with a particular focus on clothing classification within thee-commerce sector. Utilizing the Fashion MNIST dataset, we delve into theunique attributes of CNNs and ViTs. While CNNs have long been the cornerstoneof image classification, ViTs introduce an innovative self-attention mechanismenabling nuanced weighting of different input data components. Historically,transformers have primarily been associated with Natural Language Processing(NLP) tasks. Through a comprehensive examination of existing literature, ouraim is to unveil the distinctions between ViTs and CNNs in the context of imageclassification. Our analysis meticulously scrutinizes state-of-the-artmethodologies employing both architectures, striving to identify the factorsinfluencing their performance. These factors encompass dataset characteristics,image dimensions, the number of target classes, hardware infrastructure, andthe specific architectures along with their respective top results. Our keygoal is to determine the most appropriate architecture between ViT and CNN forclassifying images in the Fashion MNIST dataset within the e-commerce industry,while taking into account specific conditions and needs. We highlight theimportance of combining these two architectures with different forms to enhanceoverall performance. By uniting these architectures, we can take advantage oftheir unique strengths, which may lead to more precise and reliable models fore-commerce applications. CNNs are skilled at recognizing local patterns, whileViTs are effective at grasping overall context, making their combination apromising strategy for boosting image classification performance.</description><author>Sonia Bbouzidi, Ghazala Hcini, Imen Jdey, Fadoua Drira</author><pubDate>Wed, 05 Jun 2024 18:32:22 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.03478v1</guid></item><item><title>Does your data spark joy? Performance gains from domain upsampling at the end of training</title><link>http://arxiv.org/abs/2406.03476v1</link><description>Pretraining datasets for large language models (LLMs) have grown to trillionsof tokens composed of large amounts of CommonCrawl (CC) web scrape along withsmaller, domain-specific datasets. It is expensive to understand the impact ofthese domain-specific datasets on model capabilities as training at large FLOPscales is required to reveal significant changes to difficult and emergentbenchmarks. Given the increasing cost of experimenting with pretraining data,how does one determine the optimal balance between the diversity in general webscrapes and the information density of domain specific data? In this work, weshow how to leverage the smaller domain specific datasets by upsampling themrelative to CC at the end of training to drive performance improvements ondifficult benchmarks. This simple technique allows us to improve up to 6.90 ppon MMLU, 8.26 pp on GSM8K, and 6.17 pp on HumanEval relative to the base datamix for a 7B model trained for 1 trillion (T) tokens, thus rivaling Llama-2(7B)$\unicode{x2014}$a model trained for twice as long. We experiment withablating the duration of domain upsampling from 5% to 30% of training and findthat 10% to 20% percent is optimal for navigating the tradeoff between generallanguage modeling capabilities and targeted benchmarks. We also use domainupsampling to characterize at scale the utility of individual datasets forimproving various benchmarks by removing them during this final phase oftraining. This tool opens up the ability to experiment with the impact ofdifferent pretraining datasets at scale, but at an order of magnitude lowercost compared to full pretraining runs.</description><author>Cody Blakeney, Mansheej Paul, Brett W. Larsen, Sean Owen, Jonathan Frankle</author><pubDate>Wed, 05 Jun 2024 18:29:15 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.03476v1</guid></item><item><title>RAFT: Adapting Language Model to Domain Specific RAG</title><link>http://arxiv.org/abs/2403.10131v2</link><description>Pretraining Large Language Models (LLMs) on large corpora of textual data isnow a standard paradigm. When using these LLMs for many downstreamapplications, it is common to additionally bake in new knowledge (e.g.,time-critical news, or private domain knowledge) into the pretrained modeleither through RAG-based-prompting, or fine-tuning. However, the optimalmethodology for the model to gain such new knowledge remains an open question.In this paper, we present Retrieval Augmented FineTuning (RAFT), a trainingrecipe that improves the model's ability to answer questions in a "open-book"in-domain settings. In RAFT, given a question, and a set of retrieveddocuments, we train the model to ignore those documents that don't help inanswering the question, which we call, distractor documents. RAFT accomplishesthis by citing verbatim the right sequence from the relevant document thatwould help answer the question. This coupled with RAFT's chain-of-thought-styleresponse helps improve the model's ability to reason. In domain-specific RAG,RAFT consistently improves the model's performance across PubMed, HotpotQA, andGorilla datasets, presenting a post-training recipe to improve pre-trained LLMsto in-domain RAG. RAFT's code and demo are open-sourced atgithub.com/ShishirPatil/gorilla.</description><author>Tianjun Zhang, Shishir G. Patil, Naman Jain, Sheng Shen, Matei Zaharia, Ion Stoica, Joseph E. Gonzalez</author><pubDate>Wed, 05 Jun 2024 18:27:51 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.10131v2</guid></item><item><title>AD-H: Autonomous Driving with Hierarchical Agents</title><link>http://arxiv.org/abs/2406.03474v1</link><description>Due to the impressive capabilities of multimodal large language models(MLLMs), recent works have focused on employing MLLM-based agents forautonomous driving in large-scale and dynamic environments. However, prevalentapproaches often directly translate high-level instructions into low-levelvehicle control signals, which deviates from the inherent language generationparadigm of MLLMs and fails to fully harness their emergent powers. As aresult, the generalizability of these methods is highly restricted byautonomous driving datasets used during fine-tuning. To tackle this challenge,we propose to connect high-level instructions and low-level control signalswith mid-level language-driven commands, which are more fine-grained thanhigh-level instructions but more universal and explainable than controlsignals, and thus can effectively bridge the gap in between. We implement thisidea through a hierarchical multi-agent driving system named AD-H, including aMLLM planner for high-level reasoning and a lightweight controller forlow-level execution. The hierarchical design liberates the MLLM from low-levelcontrol signal decoding and therefore fully releases their emergent capabilityin high-level perception, reasoning, and planning. We build a new dataset withaction hierarchy annotations. Comprehensive closed-loop evaluations demonstrateseveral key advantages of our proposed AD-H system. First, AD-H can notablyoutperform state-of-the-art methods in achieving exceptional drivingperformance, even exhibiting self-correction capabilities during vehicleoperation, a scenario not encountered in the training dataset. Second, AD-Hdemonstrates superior generalization under long-horizon instructions and novelenvironmental conditions, significantly surpassing current state-of-the-artmethods. We will make our data and code publicly accessible athttps://github.com/zhangzaibin/AD-H</description><author>Zaibin Zhang, Shiyu Tang, Yuanhang Zhang, Talas Fu, Yifan Wang, Yang Liu, Dong Wang, Jing Shao, Lijun Wang, Huchuan Lu</author><pubDate>Wed, 05 Jun 2024 18:25:46 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.03474v1</guid></item><item><title>Solving Differential Equations using Physics-Informed Deep Equilibrium Models</title><link>http://arxiv.org/abs/2406.03472v1</link><description>This paper introduces Physics-Informed Deep Equilibrium Models (PIDEQs) forsolving initial value problems (IVPs) of ordinary differential equations(ODEs). Leveraging recent advancements in deep equilibrium models (DEQs) andphysics-informed neural networks (PINNs), PIDEQs combine the implicit outputrepresentation of DEQs with physics-informed training techniques. We validatePIDEQs using the Van der Pol oscillator as a benchmark problem, demonstratingtheir efficiency and effectiveness in solving IVPs. Our analysis includes keyhyperparameter considerations for optimizing PIDEQ performance. By bridgingdeep learning and physics-based modeling, this work advances computationaltechniques for solving IVPs, with implications for scientific computing andengineering applications.</description><author>Bruno Machado Pacheco, Eduardo Camponogara</author><pubDate>Wed, 05 Jun 2024 18:25:29 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.03472v1</guid></item><item><title>SpikeZIP-TF: Conversion is All You Need for Transformer-based SNN</title><link>http://arxiv.org/abs/2406.03470v1</link><description>Spiking neural network (SNN) has attracted great attention due to itscharacteristic of high efficiency and accuracy. Currently, the ANN-to-SNNconversion methods can obtain ANN on-par accuracy SNN with ultra-low latency (8time-steps) in CNN structure on computer vision (CV) tasks. However, asTransformer-based networks have achieved prevailing precision on both CV andnatural language processing (NLP), the Transformer-based SNNs are stillencounting the lower accuracy w.r.t the ANN counterparts. In this work, weintroduce a novel ANN-to-SNN conversion method called SpikeZIP-TF, where ANNand SNN are exactly equivalent, thus incurring no accuracy degradation.SpikeZIP-TF achieves 83.82% accuracy on CV dataset (ImageNet) and 93.79%accuracy on NLP dataset (SST-2), which are higher than SOTA Transformer-basedSNNs. The code is available in GitHub:https://github.com/Intelligent-Computing-Research-Group/SpikeZIP_transformer</description><author>Kang You, Zekai Xu, Chen Nie, Zhijie Deng, Qinghai Guo, Xiang Wang, Zhezhi He</author><pubDate>Wed, 05 Jun 2024 18:24:07 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.03470v1</guid></item><item><title>SPIN: Sparsifying and Integrating Internal Neurons in Large Language Models for Text Classification</title><link>http://arxiv.org/abs/2311.15983v2</link><description>Among the many tasks that Large Language Models (LLMs) have revolutionized istext classification. Current text classification paradigms, however, relysolely on the output of the final layer in the LLM, with the rich informationcontained in internal neurons largely untapped. In this study, we present SPIN:a model-agnostic framework that sparsifies and integrates internal neurons ofintermediate layers of LLMs for text classification. Specifically, SPINsparsifies internal neurons by linear probing-based salient neuron selectionlayer by layer, avoiding noise from unrelated neurons and ensuring efficiency.The cross-layer salient neurons are then integrated to serve as multi-layeredfeatures for the classification head. Extensive experimental results show ourproposed SPIN significantly improves text classification accuracy, efficiency,and interpretability.</description><author>Difan Jiao, Yilun Liu, Zhenwei Tang, Daniel Matter, Jürgen Pfeffer, Ashton Anderson</author><pubDate>Wed, 05 Jun 2024 18:15:47 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.15983v2</guid></item><item><title>Node-wise Filtering in Graph Neural Networks: A Mixture of Experts Approach</title><link>http://arxiv.org/abs/2406.03464v1</link><description>Graph Neural Networks (GNNs) have proven to be highly effective for nodeclassification tasks across diverse graph structural patterns. Traditionally,GNNs employ a uniform global filter, typically a low-pass filter for homophilicgraphs and a high-pass filter for heterophilic graphs. However, real-worldgraphs often exhibit a complex mix of homophilic and heterophilic patterns,rendering a single global filter approach suboptimal. In this work, wetheoretically demonstrate that a global filter optimized for one pattern canadversely affect performance on nodes with differing patterns. To address this,we introduce a novel GNN framework Node-MoE that utilizes a mixture of expertsto adaptively select the appropriate filters for different nodes. Extensiveexperiments demonstrate the effectiveness of Node-MoE on both homophilic andheterophilic graphs.</description><author>Haoyu Han, Juanhui Li, Wei Huang, Xianfeng Tang, Hanqing Lu, Chen Luo, Hui Liu, Jiliang Tang</author><pubDate>Wed, 05 Jun 2024 18:12:38 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.03464v1</guid></item><item><title>Fiducial Tag Localization on a 3D LiDAR Prior Map</title><link>http://arxiv.org/abs/2209.01072v3</link><description>The LiDAR fiducial tag, akin to the well-known AprilTag used in cameraapplications, serves as a convenient resource to impart artificial features tothe LiDAR sensor, facilitating robotics applications. Unfortunately, theexisting LiDAR fiducial tag localization methods do not apply to 3D LiDAR mapswhile resolving this problem is beneficial to LiDAR-based relocalization andnavigation. In this paper, we develop a novel approach to directly localizefiducial tags on a 3D LiDAR prior map, returning the tag poses (labeled by IDnumber) and vertex locations (labeled by index) w.r.t. the global coordinatesystem of the map. In particular, considering that fiducial tags are thin sheetobjects indistinguishable from the attached planes, we design a new pipelinethat gradually analyzes the 3D point cloud of the map from the intensity andgeometry perspectives, extracting potential tag-containing point clusters.Then, we introduce an intermediate-plane-based method to further check if eachpotential cluster has a tag and compute the vertex locations and tag pose iffound. We conduct both qualitative and quantitative experiments to demonstratethat our approach is the first method applicable to localize tags on a 3D LiDARmap while achieving better accuracy compared to previous methods. Theopen-source implementation of this work is available at:https://github.com/York-SDCNLab/Marker-Detection-General.</description><author>Yibo Liu, Jinjun Shan, Hunter Schofield</author><pubDate>Wed, 05 Jun 2024 18:12:32 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2209.01072v3</guid></item><item><title>NEO-BENCH: Evaluating Robustness of Large Language Models with Neologisms</title><link>http://arxiv.org/abs/2402.12261v3</link><description>The performance of Large Language Models (LLMs) degrades from the temporaldrift between data used for model training and newer text seen duringinference. One understudied avenue of language change causing data drift is theemergence of neologisms -- new word forms -- over time. We create a diverseresource of recent English neologisms by using several popular collectionmethods. We analyze temporal drift using neologisms by comparing sentencescontaining new words with near-identical sentences that replace neologisms withexisting substitute words. Model performance is nearly halved in machinetranslation when a single neologism is introduced in a sentence. Motivated bythese results, we construct a benchmark to evaluate LLMs' ability to generalizeto neologisms with various natural language understanding tasks and modelperplexity. Models with later knowledge cutoff dates yield lower perplexitiesand perform better in downstream tasks. LLMs are also affected differentlybased on the linguistic origins of words, indicating that neologisms arecomplex for static LLMs to address. We will release our benchmark and code forreproducing our experiments.</description><author>Jonathan Zheng, Alan Ritter, Wei Xu</author><pubDate>Wed, 05 Jun 2024 18:12:23 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.12261v3</guid></item><item><title>PartialFormer: Modeling Part Instead of Whole for Machine Translation</title><link>http://arxiv.org/abs/2310.14921v2</link><description>The design choices in Transformer feed-forward neural networks have resultedin significant computational and parameter overhead. In this work, we emphasizethe importance of hidden dimensions in designing lightweight FFNs, a factoroften overlooked in previous architectures. Guided by this principle, weintroduce PartialFormer, a parameter-efficient Transformer architectureutilizing multiple smaller FFNs to reduce parameters and computation whilemaintaining essential hidden dimensions. These smaller FFNs are integrated intoa multi-head attention mechanism for effective collaboration. We also propose atailored head scaling strategy to enhance PartialFormer's capabilities.Furthermore, we present a residual-like attention calculation to improve depthscaling within PartialFormer. Extensive experiments on 9 translation tasks and1 abstractive summarization task validate the effectiveness of ourPartialFormer approach on machine translation and summarization tasks. Our codewould be available at: https://github.com/zhengkid/PartialFormer.</description><author>Tong Zheng, Bei Li, Huiwen Bao, Jiale Wang, Weiqiao Shan, Tong Xiao, Jingbo Zhu</author><pubDate>Wed, 05 Jun 2024 18:12:04 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.14921v2</guid></item><item><title>Gaussian Copula Models for Nonignorable Missing Data Using Auxiliary Marginal Quantiles</title><link>http://arxiv.org/abs/2406.03463v1</link><description>We present an approach for modeling and imputation of nonignorable missingdata under Gaussian copulas. The analyst posits a set of quantiles of themarginal distributions of the study variables, for example, reflectinginformation from external data sources or elicited expert opinion. When thesequantiles are accurately specified, we prove it is possible to consistentlyestimate the copula correlation and perform multiple imputation in the presenceof nonignorable missing data. We develop algorithms for estimation andimputation that are computationally efficient, which we evaluate in simulationstudies of multiple imputation inferences. We apply the model to analyzeassociations between lead exposure levels and end-of-grade test scores for170,000 students in North Carolina. These measurements are not missing atrandom, as children deemed at-risk for high lead exposure are more likely to bemeasured. We construct plausible marginal quantiles for lead exposure usingnational statistics provided by the Centers for Disease Control and Prevention.Complete cases and missing at random analyses appear to underestimate therelationships between certain variables and end-of-grade test scores, whilemultiple imputation inferences under our model support stronger adverseassociations between lead exposure and educational outcomes.</description><author>Joseph Feldman, Jerome P. Reiter, Daniel R. Kowal</author><pubDate>Wed, 05 Jun 2024 18:11:59 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.03463v1</guid></item><item><title>Polarization Wavefront Lidar: Learning Large Scene Reconstruction from Polarized Wavefronts</title><link>http://arxiv.org/abs/2406.03461v1</link><description>Lidar has become a cornerstone sensing modality for 3D vision, especially forlarge outdoor scenarios and autonomous driving. Conventional lidar sensors arecapable of providing centimeter-accurate distance information by emitting laserpulses into a scene and measuring the time-of-flight (ToF) of the reflection.However, the polarization of the received light that depends on the surfaceorientation and material properties is usually not considered. As such, thepolarization modality has the potential to improve scene reconstruction beyonddistance measurements. In this work, we introduce a novel long-rangepolarization wavefront lidar sensor (PolLidar) that modulates the polarizationof the emitted and received light. Departing from conventional lidar sensors,PolLidar allows access to the raw time-resolved polarimetric wavefronts. Weleverage polarimetric wavefronts to estimate normals, distance, and materialproperties in outdoor scenarios with a novel learned reconstruction method. Totrain and evaluate the method, we introduce a simulated and real-worldlong-range dataset with paired raw lidar data, ground truth distance, andnormal maps. We find that the proposed method improves normal and distancereconstruction by 53\% mean angular error and 41\% mean absolute error comparedto existing shape-from-polarization (SfP) and ToF methods. Code and data areopen-sourced at https://light.princeton.edu/pollidar.</description><author>Dominik Scheuble, Chenyang Lei, Seung-Hwan Baek, Mario Bijelic, Felix Heide</author><pubDate>Wed, 05 Jun 2024 18:09:51 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.03461v1</guid></item><item><title>The PESQetarian: On the Relevance of Goodhart's Law for Speech Enhancement</title><link>http://arxiv.org/abs/2406.03460v1</link><description>To obtain improved speech enhancement models, researchers often focus onincreasing performance according to specific instrumental metrics. However,when the same metric is used in a loss function to optimize models, it may bedetrimental to aspects that the given metric does not see. The goal of thispaper is to illustrate the risk of overfitting a speech enhancement model tothe metric used for evaluation. For this, we introduce enhancement models thatexploit the widely used PESQ measure. Our "PESQetarian" model achieves 3.82PESQ on VB-DMD while scoring very poorly in a listening experiment. While theobtained PESQ value of 3.82 would imply "state-of-the-art" PESQ-performance onthe VB-DMD benchmark, our examples show that when optimizing w.r.t. a metric,an isolated evaluation on the same metric may be misleading. Instead, othermetrics should be included in the evaluation and the resulting performancepredictions should be confirmed by listening.</description><author>Danilo de Oliveira, Simon Welker, Julius Richter, Timo Gerkmann</author><pubDate>Wed, 05 Jun 2024 18:07:39 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.03460v1</guid></item><item><title>LW-DETR: A Transformer Replacement to YOLO for Real-Time Detection</title><link>http://arxiv.org/abs/2406.03459v1</link><description>In this paper, we present a light-weight detection transformer, LW-DETR,which outperforms YOLOs for real-time object detection. The architecture is asimple stack of a ViT encoder, a projector, and a shallow DETR decoder. Ourapproach leverages recent advanced techniques, such as training-effectivetechniques, e.g., improved loss and pretraining, and interleaved window andglobal attentions for reducing the ViT encoder complexity. We improve the ViTencoder by aggregating multi-level feature maps, and the intermediate and finalfeature maps in the ViT encoder, forming richer feature maps, and introducewindow-major feature map organization for improving the efficiency ofinterleaved attention computation. Experimental results demonstrate that theproposed approach is superior over existing real-time detectors, e.g., YOLO andits variants, on COCO and other benchmark datasets. Code and models areavailable at (https://github.com/Atten4Vis/LW-DETR).</description><author>Qiang Chen, Xiangbo Su, Xinyu Zhang, Jian Wang, Jiahui Chen, Yunpeng Shen, Chuchu Han, Ziliang Chen, Weixiang Xu, Fanrong Li, Shan Zhang, Kun Yao, Errui Ding, Gang Zhang, Jingdong Wang</author><pubDate>Wed, 05 Jun 2024 18:07:24 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.03459v1</guid></item><item><title>Once-for-All: Controllable Generative Image Compression with Dynamic Granularity Adaption</title><link>http://arxiv.org/abs/2406.00758v2</link><description>Although recent generative image compression methods have demonstratedimpressive potential in optimizing the rate-distortion-perception trade-off,they still face the critical challenge of flexible rate adaption to diversecompression necessities and scenarios. To overcome this challenge, this paperproposes a Controllable Generative Image Compression framework, Control-GIC,the first capable of fine-grained bitrate adaption across a broad spectrumwhile ensuring high-fidelity and generality compression. We base Control-GIC ona VQGAN framework representing an image as a sequence of variable-length codes(i.e. VQ-indices), which can be losslessly compressed and exhibits a directpositive correlation with the bitrates. Therefore, drawing inspiration from theclassical coding principle, we naturally correlate the information density oflocal image patches with their granular representations, to achieve dynamicadjustment of the code quantity following different granularity decisions. Thisimplies we can flexibly determine a proper allocation of granularity for thepatches to acquire desirable compression rates. We further develop aprobabilistic conditional decoder that can trace back to historic encodedmulti-granularity representations according to transmitted codes, and thenreconstruct hierarchical granular features in the formalization of conditionalprobability, enabling more informative aggregation to improve reconstructionrealism. Our experiments show that Control-GIC allows highly flexible andcontrollable bitrate adaption and even once compression on an entire dataset tofulfill constrained bitrate conditions. Experimental results demonstrate itssuperior performance over recent state-of-the-art methods.</description><author>Anqi Li, Yuxi Liu, Huihui Bai, Feng Li, Runmin Cong, Meng Wang, Yao Zhao</author><pubDate>Wed, 05 Jun 2024 18:05:55 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.00758v2</guid></item><item><title>SaySelf: Teaching LLMs to Express Confidence with Self-Reflective Rationales</title><link>http://arxiv.org/abs/2405.20974v2</link><description>Large language models (LLMs) often generate inaccurate or fabricatedinformation and generally fail to indicate their confidence, which limits theirbroader applications. Previous work elicits confidence from LLMs by direct orself-consistency prompting, or constructing specific datasets for supervisedfinetuning. The prompting-based approaches have inferior performance, and thetraining-based approaches are limited to binary or inaccurate group-levelconfidence estimates. In this work, we present the advanced SaySelf, a trainingframework that teaches LLMs to express more accurate fine-grained confidenceestimates. In addition, beyond the confidence scores, SaySelf initiates theprocess of directing LLMs to produce self-reflective rationales that clearlyidentify gaps in their parametric knowledge and explain their uncertainty. Thisis achieved by using an LLM to automatically summarize the uncertainties inspecific knowledge via natural language. The summarization is based on theanalysis of the inconsistency in multiple sampled reasoning chains, and theresulting data is utilized for supervised fine-tuning. Moreover, we utilizereinforcement learning with a meticulously crafted reward function to calibratethe confidence estimates, motivating LLMs to deliver accurate, high-confidencepredictions and to penalize overconfidence in erroneous outputs. Experimentalresults in both in-distribution and out-of-distribution datasets demonstratethe effectiveness of SaySelf in reducing the confidence calibration error andmaintaining the task performance. We show that the generated self-reflectiverationales are reasonable and can further contribute to the calibration. Thecode is made public at https://github.com/xu1868/SaySelf.</description><author>Tianyang Xu, Shujin Wu, Shizhe Diao, Xiaoze Liu, Xingyao Wang, Yangyi Chen, Jing Gao</author><pubDate>Wed, 05 Jun 2024 18:04:01 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.20974v2</guid></item><item><title>Distributional Adversarial Loss</title><link>http://arxiv.org/abs/2406.03458v1</link><description>A major challenge in defending against adversarial attacks is the enormousspace of possible attacks that even a simple adversary might perform. Toaddress this, prior work has proposed a variety of defenses that effectivelyreduce the size of this space. These include randomized smoothing methods thatadd noise to the input to take away some of the adversary's impact. Anotherapproach is input discretization which limits the adversary's possible numberof actions. Motivated by these two approaches, we introduce a new notion of adversarialloss which we call distributional adversarial loss, to unify these two forms ofeffectively weakening an adversary. In this notion, we assume for each originalexample, the allowed adversarial perturbation set is a family of distributions(e.g., induced by a smoothing procedure), and the adversarial loss over eachexample is the maximum loss over all the associated distributions. The goal isto minimize the overall adversarial loss. We show generalization guarantees for our notion of adversarial loss in termsof the VC-dimension of the hypothesis class and the size of the set of allowedadversarial distributions associated with each input. We also investigate therole of randomness in achieving robustness against adversarial attacks in themethods described above. We show a general derandomization technique thatpreserves the extent of a randomized classifier's robustness againstadversarial attacks. We corroborate the procedure experimentally viaderandomizing the Random Projection Filters framework of\cite{dong2023adversarial}. Our procedure also improves the robustness of themodel against various adversarial attacks.</description><author>Saba Ahmadi, Siddharth Bhandari, Avrim Blum, Chen Dan, Prabhav Jain</author><pubDate>Wed, 05 Jun 2024 18:03:47 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.03458v1</guid></item><item><title>Mixture of Gaussian-distributed Prototypes with Generative Modelling for Interpretable and Trustworthy Image Recognition</title><link>http://arxiv.org/abs/2312.00092v2</link><description>Prototypical-part methods, e.g., ProtoPNet, enhance interpretability in imagerecognition by linking predictions to training prototypes, thereby offeringintuitive insights into their decision-making. Existing methods, which rely ona point-based learning of prototypes, typically face two critical issues: 1)the learned prototypes have limited representation power and are not suitableto detect Out-of-Distribution (OoD) inputs, reducing their decisiontrustworthiness; and 2) the necessary projection of the learned prototypes backinto the space of training images causes a drastic degradation in thepredictive performance. Furthermore, current prototype learning adopts anaggressive approach that considers only the most active object parts duringtraining, while overlooking sub-salient object regions which still hold crucialclassification information. In this paper, we present a new generative paradigmto learn prototype distributions, termed as Mixture of Gaussian-distributedPrototypes (MGProto). The distribution of prototypes from MGProto enables bothinterpretable image classification and trustworthy recognition of OoD inputs.The optimisation of MGProto naturally projects the learned prototypedistributions back into the training image space, thereby addressing theperformance degradation caused by prototype projection. Additionally, wedevelop a novel and effective prototype mining strategy that considers not onlythe most active but also sub-salient object parts. To promote modelcompactness, we further propose to prune MGProto by removing prototypes withlow importance priors. Experiments on CUB-200-2011, Stanford Cars, StanfordDogs, and Oxford-IIIT Pets datasets show that MGProto achieves state-of-the-artimage recognition and OoD detection performances, while providing encouraginginterpretability results.</description><author>Chong Wang, Yuanhong Chen, Fengbei Liu, Yuyuan Liu, Davis James McCarthy, Helen Frazer, Gustavo Carneiro</author><pubDate>Wed, 05 Jun 2024 18:03:02 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.00092v2</guid></item><item><title>Stealthy Attack on Large Language Model based Recommendation</title><link>http://arxiv.org/abs/2402.14836v2</link><description>Recently, the powerful large language models (LLMs) have been instrumental inpropelling the progress of recommender systems (RS). However, while thesesystems have flourished, their susceptibility to security threats has beenlargely overlooked. In this work, we reveal that the introduction of LLMs intorecommendation models presents new security vulnerabilities due to theiremphasis on the textual content of items. We demonstrate that attackers cansignificantly boost an item's exposure by merely altering its textual contentduring the testing phase, without requiring direct interference with themodel's training process. Additionally, the attack is notably stealthy, as itdoes not affect the overall recommendation performance and the modifications tothe text are subtle, making it difficult for users and platforms to detect. Ourcomprehensive experiments across four mainstream LLM-based recommendationmodels demonstrate the superior efficacy and stealthiness of our approach. Ourwork unveils a significant security gap in LLM-based recommendation systems andpaves the way for future research on protecting these systems.</description><author>Jinghao Zhang, Yuting Liu, Qiang Liu, Shu Wu, Guibing Guo, Liang Wang</author><pubDate>Wed, 05 Jun 2024 18:02:47 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.14836v2</guid></item><item><title>Locality-Sensitive Hashing-Based Efficient Point Transformer with Applications in High-Energy Physics</title><link>http://arxiv.org/abs/2402.12535v2</link><description>This study introduces a novel transformer model optimized for large-scalepoint cloud processing in scientific domains such as high-energy physics (HEP)and astrophysics. Addressing the limitations of graph neural networks andstandard transformers, our model integrates local inductive bias and achievesnear-linear complexity with hardware-friendly regular operations. Onecontribution of this work is the quantitative analysis of the error-complexitytradeoff of various sparsification techniques for building efficienttransformers. Our findings highlight the superiority of usinglocality-sensitive hashing (LSH), especially OR &amp; AND-construction LSH, inkernel approximation for large-scale point cloud data with local inductivebias. Based on this finding, we propose LSH-based Efficient Point Transformer(HEPT), which combines E$^2$LSH with OR &amp; AND constructions and is built uponregular computations. HEPT demonstrates remarkable performance on two criticalyet time-consuming HEP tasks, significantly outperforming existing GNNs andtransformers in accuracy and computational speed, marking a significantadvancement in geometric deep learning and large-scale scientific dataprocessing. Our code is available at https://github.com/Graph-COM/HEPT.</description><author>Siqi Miao, Zhiyuan Lu, Mia Liu, Javier Duarte, Pan Li</author><pubDate>Wed, 05 Jun 2024 17:57:00 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.12535v2</guid></item><item><title>Using Synchronic Definitions and Semantic Relations to Classify Semantic Change Types</title><link>http://arxiv.org/abs/2406.03452v1</link><description>There is abundant evidence of the fact that the way words change theirmeaning can be classified in different types of change, highlighting therelationship between the old and new meanings (among which generalization,specialization and co-hyponymy transfer). In this paper, we present a way ofdetecting these types of change by constructing a model that leveragesinformation both from synchronic lexical relations and definitions of wordmeanings. Specifically, we use synset definitions and hierarchy informationfrom WordNet and test it on a digitized version of Blank's (1997) dataset ofsemantic change types. Finally, we show how the sense relationships can improvemodels for both approximation of human judgments of semantic relatedness aswell as binary Lexical Semantic Change Detection.</description><author>Pierluigi Cassotti, Stefano De Pascale, Nina Tahmasebi</author><pubDate>Wed, 05 Jun 2024 17:52:21 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.03452v1</guid></item><item><title>What is the Best Way for ChatGPT to Translate Poetry?</title><link>http://arxiv.org/abs/2406.03450v1</link><description>Machine translation (MT) has historically faced significant challenges whenapplied to literary works, particularly in the domain of poetry translation.The advent of Large Language Models such as ChatGPT holds potential forinnovation in this field. This study examines ChatGPT's capabilities inEnglish-Chinese poetry translation tasks, utilizing targeted prompts and smallsample scenarios to ascertain optimal performance. Despite promising outcomes,our analysis reveals persistent issues in the translations generated by ChatGPTthat warrant attention. To address these shortcomings, we propose anExplanation-Assisted Poetry Machine Translation (EAPMT) method, which leveragesmonolingual poetry explanation as a guiding information for the translationprocess. Furthermore, we refine existing evaluation criteria to better suit thenuances of modern poetry translation. We engaged a panel of professional poetsfor assessments, complemented evaluations by using GPT-4. The results from bothhuman and machine evaluations demonstrate that our EAPMT method outperformstraditional translation methods of ChatGPT and the existing online systems.This paper validates the efficacy of our method and contributes a novelperspective to machine-assisted literary translation.</description><author>Shanshan Wang, Derek F. Wong, Jingming Yao, Lidia S. Chao</author><pubDate>Wed, 05 Jun 2024 17:48:26 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.03450v1</guid></item><item><title>TKAN: Temporal Kolmogorov-Arnold Networks</title><link>http://arxiv.org/abs/2405.07344v2</link><description>Recurrent Neural Networks (RNNs) have revolutionized many areas of machinelearning, particularly in natural language and data sequence processing. LongShort-Term Memory (LSTM) has demonstrated its ability to capture long-termdependencies in sequential data. Inspired by the Kolmogorov-Arnold Networks(KANs) a promising alternatives to Multi-Layer Perceptrons (MLPs), we proposeda new neural networks architecture inspired by KAN and the LSTM, the TemporalKolomogorov-Arnold Networks (TKANs). TKANs combined the strenght of bothnetworks, it is composed of Recurring Kolmogorov-Arnold Networks (RKANs) Layersembedding memory management. This innovation enables us to perform multi-steptime series forecasting with enhanced accuracy and efficiency. By addressingthe limitations of traditional models in handling complex sequential patterns,the TKAN architecture offers significant potential for advancements in fieldsrequiring more than one step ahead forecasting.</description><author>Remi Genet, Hugo Inzirillo</author><pubDate>Wed, 05 Jun 2024 17:46:11 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.07344v2</guid></item><item><title>FILS: Self-Supervised Video Feature Prediction In Semantic Language Space</title><link>http://arxiv.org/abs/2406.03447v1</link><description>This paper demonstrates a self-supervised approach for learning semanticvideo representations. Recent vision studies show that a masking strategy forvision and natural language supervision has contributed to developingtransferable visual pretraining. Our goal is to achieve a more semantic videorepresentation by leveraging the text related to the video content during thepretraining in a fully self-supervised manner. To this end, we present FILS, anovel self-supervised video Feature prediction In semantic Language Space(FILS). The vision model can capture valuable structured information bycorrectly predicting masked feature semantics in language space. It is learnedusing a patch-wise video-text contrastive strategy, in which the textrepresentations act as prototypes for transforming vision features into alanguage space, which are then used as targets for semantically meaningfulfeature prediction using our masked encoder-decoder structure. FILSdemonstrates remarkable transferability on downstream action recognition tasks,achieving state-of-the-art on challenging egocentric datasets, likeEpic-Kitchens, Something-SomethingV2, Charades-Ego, and EGTEA, using ViT-Base.Our efficient method requires less computation and smaller batches compared toprevious works.</description><author>Mona Ahmadian, Frank Guerin, Andrew Gilbert</author><pubDate>Wed, 05 Jun 2024 17:44:06 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.03447v1</guid></item><item><title>Context versus Prior Knowledge in Language Models</title><link>http://arxiv.org/abs/2404.04633v2</link><description>To answer a question, language models often need to integrate prior knowledgelearned during pretraining and new information presented in context. Wehypothesize that models perform this integration in a predictable way acrossdifferent questions and contexts: models will rely more on prior knowledge forquestions about entities (e.g., persons, places, etc.) that they are morefamiliar with due to higher exposure in the training corpus, and be more easilypersuaded by some contexts than others. To formalize this problem, we proposetwo mutual information-based metrics to measure a model's dependency on acontext and on its prior about an entity: first, the persuasion score of agiven context represents how much a model depends on the context in itsdecision, and second, the susceptibility score of a given entity represents howmuch the model can be swayed away from its original answer distribution aboutan entity. We empirically test our metrics for their validity and reliability.Finally, we explore and find a relationship between the scores and the model'sexpected familiarity with an entity, and provide two use cases to illustratetheir benefits.</description><author>Kevin Du, Vésteinn Snæbjarnarson, Niklas Stoehr, Jennifer C. White, Aaron Schein, Ryan Cotterell</author><pubDate>Wed, 05 Jun 2024 17:42:38 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.04633v2</guid></item><item><title>Pre-trained Large Language Models Use Fourier Features to Compute Addition</title><link>http://arxiv.org/abs/2406.03445v1</link><description>Pre-trained large language models (LLMs) exhibit impressive mathematicalreasoning capabilities, yet how they compute basic arithmetic, such asaddition, remains unclear. This paper shows that pre-trained LLMs add numbersusing Fourier features -- dimensions in the hidden state that represent numbersvia a set of features sparse in the frequency domain. Within the model, MLP andattention layers use Fourier features in complementary ways: MLP layersprimarily approximate the magnitude of the answer using low-frequency features,while attention layers primarily perform modular addition (e.g., computingwhether the answer is even or odd) using high-frequency features. Pre-trainingis crucial for this mechanism: models trained from scratch to add numbers onlyexploit low-frequency features, leading to lower accuracy. Introducingpre-trained token embeddings to a randomly initialized model rescues itsperformance. Overall, our analysis demonstrates that appropriate pre-trainedrepresentations (e.g., Fourier features) can unlock the ability of Transformersto learn precise mechanisms for algorithmic tasks.</description><author>Tianyi Zhou, Deqing Fu, Vatsal Sharan, Robin Jia</author><pubDate>Wed, 05 Jun 2024 17:40:53 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.03445v1</guid></item><item><title>Intersectional Unfairness Discovery</title><link>http://arxiv.org/abs/2405.20790v2</link><description>AI systems have been shown to produce unfair results for certain subgroups ofpopulation, highlighting the need to understand bias on certain sensitiveattributes. Current research often falls short, primarily focusing on thesubgroups characterized by a single sensitive attribute, while neglecting thenature of intersectional fairness of multiple sensitive attributes. This paperfocuses on its one fundamental aspect by discovering diverse high-biassubgroups under intersectional sensitive attributes. Specifically, we propose aBias-Guided Generative Network (BGGN). By treating each bias value as a reward,BGGN efficiently generates high-bias intersectional sensitive attributes.Experiments on real-world text and image datasets demonstrate a diverse andefficient discovery of BGGN. To further evaluate the generated unseen butpossible unfair intersectional sensitive attributes, we formulate them asprompts and use modern generative AI to produce new texts and images. Theresults of frequently generating biased data provides new insights ofdiscovering potential unfairness in popular modern generative AI systems.Warning: This paper contains generative examples that are offensive in nature.</description><author>Gezheng Xu, Qi Chen, Charles Ling, Boyu Wang, Changjian Shui</author><pubDate>Wed, 05 Jun 2024 17:37:50 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.20790v2</guid></item><item><title>Are language models rational? The case of coherence norms and belief revision</title><link>http://arxiv.org/abs/2406.03442v1</link><description>Do norms of rationality apply to machine learning models, in particularlanguage models? In this paper we investigate this question by focusing on aspecial subset of rational norms: coherence norms. We consider both logicalcoherence norms as well as coherence norms tied to the strength of belief. Tomake sense of the latter, we introduce the Minimal Assent Connection (MAC) andpropose a new account of credence, which captures the strength of belief inlanguage models. This proposal uniformly assigns strength of belief simply onthe basis of model internal next token probabilities. We argue that rationalnorms tied to coherence do apply to some language models, but not to others.This issue is significant since rationality is closely tied to predicting andexplaining behavior, and thus it is connected to considerations about AI safetyand alignment, as well as understanding model behavior more generally.</description><author>Thomas Hofweber, Peter Hase, Elias Stengel-Eskin, Mohit Bansal</author><pubDate>Wed, 05 Jun 2024 17:36:21 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.03442v1</guid></item><item><title>Trust Regions for Explanations via Black-Box Probabilistic Certification</title><link>http://arxiv.org/abs/2402.11168v3</link><description>Given the black box nature of machine learning models, a plethora ofexplainability methods have been developed to decipher the factors behindindividual decisions. In this paper, we introduce a novel problem of black box(probabilistic) explanation certification. We ask the question: Given a blackbox model with only query access, an explanation for an example and a qualitymetric (viz. fidelity, stability), can we find the largest hypercube (i.e.,$\ell_{\infty}$ ball) centered at the example such that when the explanation isapplied to all examples within the hypercube, (with high probability) a qualitycriterion is met (viz. fidelity greater than some value)? Being able toefficiently find such a \emph{trust region} has multiple benefits: i) insightinto model behavior in a \emph{region}, with a \emph{guarantee}; ii)ascertained \emph{stability} of the explanation; iii) \emph{explanation reuse},which can save time, energy and money by not having to find explanations forevery example; and iv) a possible \emph{meta-metric} to compare explanationmethods. Our contributions include formalizing this problem, proposingsolutions, providing theoretical guarantees for these solutions that arecomputable, and experimentally showing their efficacy on synthetic and realdata.</description><author>Amit Dhurandhar, Swagatam Haldar, Dennis Wei, Karthikeyan Natesan Ramamurthy</author><pubDate>Wed, 05 Jun 2024 17:36:21 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.11168v3</guid></item><item><title>Improved Techniques for Optimization-Based Jailbreaking on Large Language Models</title><link>http://arxiv.org/abs/2405.21018v2</link><description>Large language models (LLMs) are being rapidly developed, and a key componentof their widespread deployment is their safety-related alignment. Manyred-teaming efforts aim to jailbreak LLMs, where among these efforts, theGreedy Coordinate Gradient (GCG) attack's success has led to a growing interestin the study of optimization-based jailbreaking techniques. Although GCG is asignificant milestone, its attacking efficiency remains unsatisfactory. In thispaper, we present several improved (empirical) techniques foroptimization-based jailbreaks like GCG. We first observe that the single targettemplate of "Sure" largely limits the attacking performance of GCG; given this,we propose to apply diverse target templates containing harmful self-suggestionand/or guidance to mislead LLMs. Besides, from the optimization aspects, wepropose an automatic multi-coordinate updating strategy in GCG (i.e.,adaptively deciding how many tokens to replace in each step) to accelerateconvergence, as well as tricks like easy-to-hard initialisation. Then, wecombine these improved technologies to develop an efficient jailbreak method,dubbed I-GCG. In our experiments, we evaluate on a series of benchmarks (suchas NeurIPS 2023 Red Teaming Track). The results demonstrate that our improvedtechniques can help GCG outperform state-of-the-art jailbreaking attacks andachieve nearly 100% attack success rate. The code is released athttps://github.com/jiaxiaojunQAQ/I-GCG.</description><author>Xiaojun Jia, Tianyu Pang, Chao Du, Yihao Huang, Jindong Gu, Yang Liu, Xiaochun Cao, Min Lin</author><pubDate>Wed, 05 Jun 2024 17:35:49 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.21018v2</guid></item><item><title>Cycles of Thought: Measuring LLM Confidence through Stable Explanations</title><link>http://arxiv.org/abs/2406.03441v1</link><description>In many high-risk machine learning applications it is essential for a modelto indicate when it is uncertain about a prediction. While large languagemodels (LLMs) can reach and even surpass human-level accuracy on a variety ofbenchmarks, their overconfidence in incorrect responses is still awell-documented failure mode. Traditional methods for ML uncertaintyquantification can be difficult to directly adapt to LLMs due to thecomputational cost of implementation and closed-source nature of many models. Avariety of black-box methods have recently been proposed, but these often relyon heuristics such as self-verbalized confidence. We instead propose aframework for measuring an LLM's uncertainty with respect to the distributionof generated explanations for an answer. While utilizing explanations is not anew idea in and of itself, by interpreting each possible model+explanation pairas a test-time classifier we can calculate a posterior answer distribution overthe most likely of these classifiers. We demonstrate how a specific instance ofthis framework using explanation entailment as our classifier likelihoodimproves confidence score metrics (in particular AURC and AUROC) over baselinesacross five different datasets. We believe these results indicate that ourframework is both a well-principled and effective way of quantifyinguncertainty in LLMs.</description><author>Evan Becker, Stefano Soatto</author><pubDate>Wed, 05 Jun 2024 17:35:30 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.03441v1</guid></item><item><title>Text-to-Events: Synthetic Event Camera Streams from Conditional Text Input</title><link>http://arxiv.org/abs/2406.03439v1</link><description>Event cameras are advantageous for tasks that require vision sensors withlow-latency and sparse output responses. However, the development of deepnetwork algorithms using event cameras has been slow because of the lack oflarge labelled event camera datasets for network training. This paper reports amethod for creating new labelled event datasets by using a text-to-X model,where X is one or multiple output modalities, in the case of this work, events.Our proposed text-to-events model produces synthetic event frames directly fromtext prompts. It uses an autoencoder which is trained to produce sparse eventframes representing event camera outputs. By combining the pretrainedautoencoder with a diffusion model architecture, the new text-to-events modelis able to generate smooth synthetic event streams of moving objects. Theautoencoder was first trained on an event camera dataset of diverse scenes. Inthe combined training with the diffusion model, the DVS gesture dataset wasused. We demonstrate that the model can generate realistic event sequences ofhuman gestures prompted by different text statements. The classificationaccuracy of the generated sequences, using a classifier trained on the realdataset, ranges between 42% to 92%, depending on the gesture group. The resultsdemonstrate the capability of this method in synthesizing event datasets.</description><author>Joachim Ott, Zuowen Wang, Shih-Chii Liu</author><pubDate>Wed, 05 Jun 2024 17:34:12 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.03439v1</guid></item><item><title>Transfer Learning for Latent Variable Network Models</title><link>http://arxiv.org/abs/2406.03437v1</link><description>We study transfer learning for estimation in latent variable network models.In our setting, the conditional edge probability matrices given the latentvariables are represented by $P$ for the source and $Q$ for the target. We wishto estimate $Q$ given two kinds of data: (1) edge data from a subgraph inducedby an $o(1)$ fraction of the nodes of $Q$, and (2) edge data from all of $P$.If the source $P$ has no relation to the target $Q$, the estimation error mustbe $\Omega(1)$. However, we show that if the latent variables are shared, thenvanishing error is possible. We give an efficient algorithm that utilizes theordering of a suitably defined graph distance. Our algorithm achieves $o(1)$error and does not assume a parametric form on the source or target networks.Next, for the specific case of Stochastic Block Models we prove a minimax lowerbound and show that a simple algorithm achieves this rate. Finally, weempirically demonstrate our algorithm's use on real-world and simulated graphtransfer problems.</description><author>Akhil Jalan, Arya Mazumdar, Soumendu Sundar Mukherjee, Purnamrita Sarkar</author><pubDate>Wed, 05 Jun 2024 17:33:30 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.03437v1</guid></item><item><title>Fault Tolerant ML: Efficient Meta-Aggregation and Synchronous Training</title><link>http://arxiv.org/abs/2405.14759v2</link><description>In this paper, we investigate the challenging framework of Byzantine-robusttraining in distributed machine learning (ML) systems, focusing on enhancingboth efficiency and practicality. As distributed ML systems become integral forcomplex ML tasks, ensuring resilience against Byzantine failures-where workersmay contribute incorrect updates due to malice or error-gains paramountimportance. Our first contribution is the introduction of the Centered TrimmedMeta Aggregator (CTMA), an efficient meta-aggregator that upgrades baselineaggregators to optimal performance levels, while requiring low computationaldemands. Additionally, we propose harnessing a recently developed gradientestimation technique based on a double-momentum strategy within the Byzantinecontext. Our paper highlights its theoretical and practical advantages forByzantine-robust training, especially in simplifying the tuning process andreducing the reliance on numerous hyperparameters. The effectiveness of thistechnique is supported by theoretical insights within the stochastic convexoptimization (SCO) framework and corroborated by empirical evidence.</description><author>Tehila Dahan, Kfir Y. Levy</author><pubDate>Wed, 05 Jun 2024 17:32:31 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.14759v2</guid></item><item><title>A Temporal Kolmogorov-Arnold Transformer for Time Series Forecasting</title><link>http://arxiv.org/abs/2406.02486v2</link><description>Capturing complex temporal patterns and relationships within multivariatedata streams is a difficult task. We propose the Temporal Kolmogorov-ArnoldTransformer (TKAT), a novel attention-based architecture designed to addressthis task using Temporal Kolmogorov-Arnold Networks (TKANs). Inspired by theTemporal Fusion Transformer (TFT), TKAT emerges as a powerful encoder-decodermodel tailored to handle tasks in which the observed part of the features ismore important than the a priori known part. This new architecture combined thetheoretical foundation of the Kolmogorov-Arnold representation with the powerof transformers. TKAT aims to simplify the complex dependencies inherent intime series, making them more "interpretable". The use of transformerarchitecture in this framework allows us to capture long-range dependenciesthrough self-attention mechanisms.</description><author>Remi Genet, Hugo Inzirillo</author><pubDate>Wed, 05 Jun 2024 17:32:16 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.02486v2</guid></item><item><title>Unified PAC-Bayesian Study of Pessimism for Offline Policy Learning with Regularized Importance Sampling</title><link>http://arxiv.org/abs/2406.03434v1</link><description>Off-policy learning (OPL) often involves minimizing a risk estimator based onimportance weighting to correct bias from the logging policy used to collectdata. However, this method can produce an estimator with a high variance. Acommon solution is to regularize the importance weights and learn the policy byminimizing an estimator with penalties derived from generalization boundsspecific to the estimator. This approach, known as pessimism, has gained recentattention but lacks a unified framework for analysis. To address this gap, weintroduce a comprehensive PAC-Bayesian framework to examine pessimism withregularized importance weighting. We derive a tractable PAC-Bayesiangeneralization bound that universally applies to common importance weightregularizations, enabling their comparison within a single framework. Ourempirical results challenge common understanding, demonstrating theeffectiveness of standard IW regularization techniques.</description><author>Imad Aouali, Victor-Emmanuel Brunel, David Rohde, Anna Korba</author><pubDate>Wed, 05 Jun 2024 17:32:14 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.03434v1</guid></item><item><title>CattleFace-RGBT: RGB-T Cattle Facial Landmark Benchmark</title><link>http://arxiv.org/abs/2406.03431v1</link><description>To address this challenge, we introduce CattleFace-RGBT, a RGB-T CattleFacial Landmark dataset consisting of 2,300 RGB-T image pairs, a total of 4,600images. Creating a landmark dataset is time-consuming, but AI-assistedannotation can help. However, applying AI to thermal images is challenging dueto suboptimal results from direct thermal training and infeasible RGB-thermalalignment due to different camera views. Therefore, we opt to transfer modelstrained on RGB to thermal images and refine them using our AI-assistedannotation tool following a semi-automatic annotation approach. Accuratelylocalizing facial key points on both RGB and thermal images enables us to notonly discern the cattle's respiratory signs but also measure temperatures toassess the animal's thermal state. To the best of our knowledge, this is thefirst dataset for the cattle facial landmark on RGB-T images. We conductbenchmarking of the CattleFace-RGBT dataset across various backbonearchitectures, with the objective of establishing baselines for futureresearch, analysis, and comparison. The dataset and models are athttps://github.com/UARK-AICV/CattleFace-RGBT-benchmark</description><author>Ethan Coffman, Reagan Clark, Nhat-Tan Bui, Trong Thang Pham, Beth Kegley, Jeremy G. Powell, Jiangchao Zhao, Ngan Le</author><pubDate>Wed, 05 Jun 2024 17:29:13 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.03431v1</guid></item><item><title>Computation-Efficient Era: A Comprehensive Survey of State Space Models in Medical Image Analysis</title><link>http://arxiv.org/abs/2406.03430v1</link><description>Sequence modeling plays a vital role across various domains, with recurrentneural networks being historically the predominant method of performing thesetasks. However, the emergence of transformers has altered this paradigm due totheir superior performance. Built upon these advances, transformers haveconjoined CNNs as two leading foundational models for learning visualrepresentations. However, transformers are hindered by the $\mathcal{O}(N^2)$complexity of their attention mechanisms, while CNNs lack global receptivefields and dynamic weight allocation. State Space Models (SSMs), specificallythe \textit{\textbf{Mamba}} model with selection mechanisms and hardware-awarearchitecture, have garnered immense interest lately in sequential modeling andvisual representation learning, challenging the dominance of transformers byproviding infinite context lengths and offering substantial efficiencymaintaining linear complexity in the input sequence. Capitalizing on theadvances in computer vision, medical imaging has heralded a new epoch withMamba models. Intending to help researchers navigate the surge, this surveyseeks to offer an encyclopedic review of Mamba models in medical imaging.Specifically, we start with a comprehensive theoretical review forming thebasis of SSMs, including Mamba architecture and its alternatives for sequencemodeling paradigms in this context. Next, we offer a structured classificationof Mamba models in the medical field and introduce a diverse categorizationscheme based on their application, imaging modalities, and targeted organs.Finally, we summarize key challenges, discuss different future researchdirections of the SSMs in the medical domain, and propose several directions tofulfill the demands of this field. In addition, we have compiled the studiesdiscussed in this paper along with their open-source implementations on ourGitHub repository.</description><author>Moein Heidari, Sina Ghorbani Kolahi, Sanaz Karimijafarbigloo, Bobby Azad, Afshin Bozorgpour, Soheila Hatami, Reza Azad, Ali Diba, Ulas Bagci, Dorit Merhof, Ilker Hacihaliloglu</author><pubDate>Wed, 05 Jun 2024 17:29:03 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.03430v1</guid></item><item><title>HelloFresh: LLM Evaluations on Streams of Real-World Human Editorial Actions across X Community Notes and Wikipedia edits</title><link>http://arxiv.org/abs/2406.03428v1</link><description>Benchmarks have been essential for driving progress in machine learning. Abetter understanding of LLM capabilities on real world tasks is vital for safedevelopment. Designing adequate LLM benchmarks is challenging: Data fromreal-world tasks is hard to collect, public availability of static evaluationdata results in test data contamination and benchmark overfitting, andperiodically generating new evaluation data is tedious and may result intemporally inconsistent results. We introduce HelloFresh, based on continuousstreams of real-world data generated by intrinsically motivated human labelers.It covers recent events from X (formerly Twitter) community notes and edits ofWikipedia pages, mitigating the risk of test data contamination and benchmarkoverfitting. Any X user can propose an X note to add additional context to amisleading post (formerly tweet); if the community classifies it as helpful, itis shown with the post. Similarly, Wikipedia relies on community-basedconsensus, allowing users to edit articles or revert edits made by other users.Verifying whether an X note is helpful or whether a Wikipedia edit should beaccepted are hard tasks that require grounding by querying the web. We backteststate-of-the-art LLMs supplemented with simple web search access and find thatHelloFresh yields a temporally consistent ranking. To enable continuousevaluation on HelloFresh, we host a public leaderboard and periodically updatedevaluation data at https://tinyurl.com/hello-fresh-LLM.</description><author>Tim Franzmeyer, Aleksandar Shtedritski, Samuel Albanie, Philip Torr, João F. Henriques, Jakob N. Foerster</author><pubDate>Wed, 05 Jun 2024 17:25:57 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.03428v1</guid></item><item><title>HarmonyDream: Task Harmonization Inside World Models</title><link>http://arxiv.org/abs/2310.00344v3</link><description>Model-based reinforcement learning (MBRL) holds the promise ofsample-efficient learning by utilizing a world model, which models how theenvironment works and typically encompasses components for two tasks:observation modeling and reward modeling. In this paper, through a dedicatedempirical investigation, we gain a deeper understanding of the role each taskplays in world models and uncover the overlooked potential of sample-efficientMBRL by mitigating the domination of either observation or reward modeling. Ourkey insight is that while prevalent approaches of explicit MBRL attempt torestore abundant details of the environment via observation models, it isdifficult due to the environment's complexity and limited model capacity. Onthe other hand, reward models, while dominating implicit MBRL and adept atlearning compact task-centric dynamics, are inadequate for sample-efficientlearning without richer learning signals. Motivated by these insights anddiscoveries, we propose a simple yet effective approach, HarmonyDream, whichautomatically adjusts loss coefficients to maintain task harmonization, i.e. adynamic equilibrium between the two tasks in world model learning. Ourexperiments show that the base MBRL method equipped with HarmonyDream gains10%-69% absolute performance boosts on visual robotic tasks and sets a newstate-of-the-art result on the Atari 100K benchmark. Code is available athttps://github.com/thuml/HarmonyDream.</description><author>Haoyu Ma, Jialong Wu, Ningya Feng, Chenjun Xiao, Dong Li, Jianye Hao, Jianmin Wang, Mingsheng Long</author><pubDate>Wed, 05 Jun 2024 17:21:40 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.00344v3</guid></item><item><title>HAAQI-Net: A Non-intrusive Neural Music Audio Quality Assessment Model for Hearing Aids</title><link>http://arxiv.org/abs/2401.01145v4</link><description>This paper introduces HAAQI-Net, a non-intrusive deep learning model formusic audio quality assessment tailored for hearing aid users. Unliketraditional methods like the Hearing Aid Audio Quality Index (HAAQI), whichrely on intrusive comparisons to a reference signal, HAAQI-Net offers a moreaccessible and efficient alternative. Using a bidirectional Long Short-TermMemory (BLSTM) architecture with attention mechanisms and features from thepre-trained BEATs model, HAAQI-Net predicts HAAQI scores directly from musicaudio clips and hearing loss patterns. Results show HAAQI-Net's effectiveness,with predicted scores achieving a Linear Correlation Coefficient (LCC) of0.9368, a Spearman's Rank Correlation Coefficient (SRCC) of 0.9486, and a MeanSquared Error (MSE) of 0.0064, reducing inference time from 62.52 seconds to2.54 seconds. Although effective, feature extraction via the large BEATs modelincurs computational overhead. To address this, a knowledge distillationstrategy creates a student distillBEATs model, distilling information from theteacher BEATs model during HAAQI-Net training, reducing required parameters.The distilled HAAQI-Net maintains strong performance with an LCC of 0.9071, anSRCC of 0.9307, and an MSE of 0.0091, while reducing parameters by 75.85% andinference time by 96.46%. This reduction enhances HAAQI-Net's efficiency andscalability, making it viable for real-world music audio quality assessment inhearing aid settings. This work also opens avenues for further research intooptimizing deep learning models for specific applications, contributing toaudio signal processing and quality assessment by providing insights intodeveloping efficient and accurate models for practical applications in hearingaid technology.</description><author>Dyah A. M. G. Wisnu, Stefano Rini, Ryandhimas E. Zezario, Hsin-Min Wang, Yu Tsao</author><pubDate>Wed, 05 Jun 2024 17:17:40 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.01145v4</guid></item><item><title>Post-hoc Part-prototype Networks</title><link>http://arxiv.org/abs/2406.03421v1</link><description>Post-hoc explainability methods such as Grad-CAM are popular because they donot influence the performance of a trained model. However, they mainly reveal"where" a model looks at for a given input, fail to explain "what" the modellooks for (e.g., what is important to classify a bird image to a ScottOriole?). Existing part-prototype networks leverage part-prototypes (e.g.,characteristic Scott Oriole's wing and head) to answer both "where" and "what",but often under-perform their black box counterparts in the accuracy.Therefore, a natural question is: can one construct a network that answers both"where" and "what" in a post-hoc manner to guarantee the model's performance?To this end, we propose the first post-hoc part-prototype network viadecomposing the classification head of a trained model into a set ofinterpretable part-prototypes. Concretely, we propose an unsupervised prototypediscovery and refining strategy to obtain prototypes that can preciselyreconstruct the classification head, yet being interpretable. Besidesguaranteeing the performance, we show that our network offers more faithfulexplanations qualitatively and yields even better part-prototypesquantitatively than prior part-prototype networks.</description><author>Andong Tan, Fengtao Zhou, Hao Chen</author><pubDate>Wed, 05 Jun 2024 17:16:03 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.03421v1</guid></item><item><title>CoFie: Learning Compact Neural Surface Representations with Coordinate Fields</title><link>http://arxiv.org/abs/2406.03417v1</link><description>This paper introduces CoFie, a novel local geometry-aware neural surfacerepresentation. CoFie is motivated by the theoretical analysis of local SDFswith quadratic approximation. We find that local shapes are highly compressivein an aligned coordinate frame defined by the normal and tangent directions oflocal shapes. Accordingly, we introduce Coordinate Field, which is acomposition of coordinate frames of all local shapes. The Coordinate Field isoptimizable and is used to transform the local shapes from the world coordinateframe to the aligned shape coordinate frame. It largely reduces the complexityof local shapes and benefits the learning of MLP-based implicitrepresentations. Moreover, we introduce quadratic layers into the MLP toenhance expressiveness concerning local shape geometry. CoFie is ageneralizable surface representation. It is trained on a curated set of 3Dshapes and works on novel shape instances during testing. When using the sameamount of parameters with prior works, CoFie reduces the shape error by 48% and56% on novel instances of both training and unseen shape categories. Moreover,CoFie demonstrates comparable performance to prior works when using only 70%fewer parameters.</description><author>Hanwen Jiang, Haitao Yang, Georgios Pavlakos, Qixing Huang</author><pubDate>Wed, 05 Jun 2024 17:12:19 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.03417v1</guid></item><item><title>UnWave-Net: Unrolled Wavelet Network for Compton Tomography Image Reconstruction</title><link>http://arxiv.org/abs/2406.03413v1</link><description>Computed tomography (CT) is a widely used medical imaging technique to scaninternal structures of a body, typically involving collimation and mechanicalrotation. Compton scatter tomography (CST) presents an interesting alternativeto conventional CT by leveraging Compton physics instead of collimation togather information from multiple directions. While CST introduces new imagingopportunities with several advantages such as high sensitivity, compactness,and entirely fixed systems, image reconstruction remains an open problem due tothe mathematical challenges of CST modeling. In contrast, deep unrollingnetworks have demonstrated potential in CT image reconstruction, despite theircomputationally intensive nature. In this study, we investigate the efficiencyof unrolling networks for CST image reconstruction. To address the importantcomputational cost required for training, we propose UnWave-Net, a novelunrolled wavelet-based reconstruction network. This architecture includes anon-local regularization term based on wavelets, which captures long-rangedependencies within images and emphasizes the multi-scale components of thewavelet transform. We evaluate our approach using a CST of circular geometrywhich stays completely static during data acquisition, where UnWave-Netfacilitates image reconstruction in the absence of a specific reconstructionformula. Our method outperforms existing approaches and achievesstate-of-the-art performance in terms of SSIM and PSNR, and offers an improvedcomputational efficiency compared to traditional unrolling networks.</description><author>Ishak Ayad, Cécilia Tarpau, Javier Cebeiro, Maï K. Nguyen</author><pubDate>Wed, 05 Jun 2024 17:10:29 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.03413v1</guid></item><item><title>Minimally Modifying a Markov Game to Achieve Any Nash Equilibrium and Value</title><link>http://arxiv.org/abs/2311.00582v3</link><description>We study the game modification problem, where a benevolent game designer or amalevolent adversary modifies the reward function of a zero-sum Markov game sothat a target deterministic or stochastic policy profile becomes the uniqueMarkov perfect Nash equilibrium and has a value within a target range, in a waythat minimizes the modification cost. We characterize the set of policyprofiles that can be installed as the unique equilibrium of some game, andestablish sufficient and necessary conditions for successful installation. Wepropose an efficient algorithm, which solves a convex optimization problem withlinear constraints and then performs random perturbation, to obtain amodification plan with a near-optimal cost.</description><author>Young Wu, Jeremy McMahan, Yiding Chen, Yudong Chen, Xiaojin Zhu, Qiaomin Xie</author><pubDate>Wed, 05 Jun 2024 17:09:46 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.00582v3</guid></item><item><title>Interactive Text-to-Image Retrieval with Large Language Models: A Plug-and-Play Approach</title><link>http://arxiv.org/abs/2406.03411v1</link><description>In this paper, we primarily address the issue of dialogue-form context querywithin the interactive text-to-image retrieval task. Our methodology, PlugIR,actively utilizes the general instruction-following capability of LLMs in twoways. First, by reformulating the dialogue-form context, we eliminate thenecessity of fine-tuning a retrieval model on existing visual dialogue data,thereby enabling the use of any arbitrary black-box model. Second, we constructthe LLM questioner to generate non-redundant questions about the attributes ofthe target image, based on the information of retrieval candidate images in thecurrent context. This approach mitigates the issues of noisiness and redundancyin the generated questions. Beyond our methodology, we propose a novelevaluation metric, Best log Rank Integral (BRI), for a comprehensive assessmentof the interactive retrieval system. PlugIR demonstrates superior performancecompared to both zero-shot and fine-tuned baselines in various benchmarks.Additionally, the two methodologies comprising PlugIR can be flexibly appliedtogether or separately in various situations. Our codes are available athttps://github.com/Saehyung-Lee/PlugIR.</description><author>Saehyung Lee, Sangwon Yu, Junsung Park, Jihun Yi, Sungroh Yoon</author><pubDate>Wed, 05 Jun 2024 17:09:01 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.03411v1</guid></item><item><title>NeuroPrune: A Neuro-inspired Topological Sparse Training Algorithm for Large Language Models</title><link>http://arxiv.org/abs/2404.01306v3</link><description>Transformer-based Language Models have become ubiquitous in Natural LanguageProcessing (NLP) due to their impressive performance on various tasks. However,expensive training as well as inference remains a significant impediment totheir widespread applicability. While enforcing sparsity at various levels ofthe model architecture has found promise in addressing scaling and efficiencyissues, there remains a disconnect between how sparsity affects networktopology. Inspired by brain neuronal networks, we explore sparsity approachesthrough the lens of network topology. Specifically, we exploit mechanisms seenin biological networks, such as preferential attachment and redundant synapsepruning, and show that principled, model-agnostic sparsity approaches areperformant and efficient across diverse NLP tasks, spanning both classification(such as natural language inference) and generation (summarization, machinetranslation), despite our sole objective not being optimizing performance.NeuroPrune is competitive with (or sometimes superior to) baselines onperformance and can be up to $10$x faster in terms of training time for a givenlevel of sparsity, simultaneously exhibiting measurable improvements ininference time in many cases.</description><author>Amit Dhurandhar, Tejaswini Pedapati, Ronny Luss, Soham Dan, Aurelie Lozano, Payel Das, Georgios Kollias</author><pubDate>Wed, 05 Jun 2024 17:07:13 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.01306v3</guid></item><item><title>Distribution-Free Conformal Joint Prediction Regions for Neural Marked Temporal Point Processes</title><link>http://arxiv.org/abs/2401.04612v2</link><description>Sequences of labeled events observed at irregular intervals in continuoustime are ubiquitous across various fields. Temporal Point Processes (TPPs)provide a mathematical framework for modeling these sequences, enablinginferences such as predicting the arrival time of future events and theirassociated label, called mark. However, due to model misspecification or lackof training data, these probabilistic models may provide a poor approximationof the true, unknown underlying process, with prediction regions extracted fromthem being unreliable estimates of the underlying uncertainty. This paperdevelops more reliable methods for uncertainty quantification in neural TPPmodels via the framework of conformal prediction. A primary objective is togenerate a distribution-free joint prediction region for an event's arrivaltime and mark, with a finite-sample marginal coverage guarantee. A keychallenge is to handle both a strictly positive, continuous response and acategorical response, without distributional assumptions. We first consider asimple but conservative approach that combines individual prediction regionsfor the event's arrival time and mark. Then, we introduce a more effectivemethod based on bivariate highest density regions derived from the jointpredictive density of arrival times and marks. By leveraging the dependenciesbetween these two variables, this method excludes unlikely combinations of thetwo, resulting in sharper prediction regions while still attaining thepre-specified coverage level. We also explore the generation of individualunivariate prediction regions for events' arrival times and marks throughconformal regression and classification techniques. Moreover, we evaluate thestronger notion of conditional coverage. Finally, through extensiveexperimentation on both simulated and real-world datasets, we assess thevalidity and efficiency of these methods.</description><author>Victor Dheur, Tanguy Bosser, Rafael Izbicki, Souhaib Ben Taieb</author><pubDate>Wed, 05 Jun 2024 17:06:27 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.04612v2</guid></item><item><title>Compressed Federated Reinforcement Learning with a Generative Model</title><link>http://arxiv.org/abs/2404.10635v2</link><description>Reinforcement learning has recently gained unprecedented popularity, yet itstill grapples with sample inefficiency. Addressing this challenge, federatedreinforcement learning (FedRL) has emerged, wherein agents collaborativelylearn a single policy by aggregating local estimations. However, thisaggregation step incurs significant communication costs. In this paper, wepropose CompFedRL, a communication-efficient FedRL approach incorporating both\textit{periodic aggregation} and (direct/error-feedback) compressionmechanisms. Specifically, we consider compressed federated $Q$-learning with agenerative model setup, where a central server learns an optimal $Q$-functionby periodically aggregating compressed $Q$-estimates from local agents. For thefirst time, we characterize the impact of these two mechanisms (which haveremained elusive) by providing a finite-time analysis of our algorithm,demonstrating strong convergence behaviors when utilizing either direct orerror-feedback compression. Our bounds indicate improved solution accuracyconcerning the number of agents and other federated hyperparameters whilesimultaneously reducing communication costs. To corroborate our theory, we alsoconduct in-depth numerical experiments to verify our findings, consideringTop-$K$ and Sparsified-$K$ sparsification operators.</description><author>Ali Beikmohammadi, Sarit Khirirat, Sindri Magnússon</author><pubDate>Wed, 05 Jun 2024 17:04:47 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.10635v2</guid></item><item><title>A General Framework for Learning from Weak Supervision</title><link>http://arxiv.org/abs/2402.01922v3</link><description>Weakly supervised learning generally faces challenges in applicability tovarious scenarios with diverse weak supervision and in scalability due to thecomplexity of existing algorithms, thereby hindering the practical deployment.This paper introduces a general framework for learning from weak supervision(GLWS) with a novel algorithm. Central to GLWS is an Expectation-Maximization(EM) formulation, adeptly accommodating various weak supervision sources,including instance partial labels, aggregate statistics, pairwise observations,and unlabeled data. We further present an advanced algorithm that significantlysimplifies the EM computational demands using a Non-deterministic FiniteAutomaton (NFA) along with a forward-backward algorithm, which effectivelyreduces time complexity from quadratic or factorial often required in existingsolutions to linear scale. The problem of learning from arbitrary weaksupervision is therefore converted to the NFA modeling of them. GLWS not onlyenhances the scalability of machine learning models but also demonstratessuperior performance and versatility across 11 weak supervision scenarios. Wehope our work paves the way for further advancements and practical deploymentin this field.</description><author>Hao Chen, Jindong Wang, Lei Feng, Xiang Li, Yidong Wang, Xing Xie, Masashi Sugiyama, Rita Singh, Bhiksha Raj</author><pubDate>Wed, 05 Jun 2024 17:03:55 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.01922v3</guid></item><item><title>A Neuro-Symbolic Framework for Answering Graph Pattern Queries in Knowledge Graphs</title><link>http://arxiv.org/abs/2310.04598v2</link><description>The challenge of answering graph queries over incomplete knowledge graphs isgaining significant attention in the machine learning community. Neuro-symbolicmodels have emerged as a promising approach, combining good performance withhigh interpretability. These models utilize trained architectures to executeatomic queries and integrate modules that mimic symbolic query operators.However, most neuro-symbolic query processors are constrained to tree-likegraph pattern queries. These queries admit a bottom-up execution with constantvalues or anchors at the leaves and the target variable at the root. Whileexpressive, tree-like queries fail to capture critical properties in knowledgegraphs, such as the existence of multiple edges between entities or thepresence of triangles. We introduce a framework for answering arbitrary graphpattern queries over incomplete knowledge graphs, encompassing both cyclicqueries and tree-like queries with existentially quantified leaves. Theseclasses of queries are vital for practical applications but are beyond thescope of most current neuro-symbolic models. Our approach employs anapproximation scheme that facilitates acyclic traversals for cyclic patterns,thereby embedding additional symbolic bias into the query execution process.Our experimental evaluation demonstrates that our framework performscompetitively on three datasets, effectively handling cyclic queries throughour approximation strategy. Additionally, it maintains the performance ofexisting neuro-symbolic models on anchored tree-like queries and extends theircapabilities to queries with existentially quantified variables.</description><author>Tamara Cucumides, Daniel Daza, Pablo Barceló, Michael Cochez, Floris Geerts, Juan L Reutter, Miguel Romero</author><pubDate>Wed, 05 Jun 2024 16:56:54 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.04598v2</guid></item><item><title>Ranking Large Language Models without Ground Truth</title><link>http://arxiv.org/abs/2402.14860v3</link><description>Evaluation and ranking of large language models (LLMs) has become animportant problem with the proliferation of these models and their impact.Evaluation methods either require human responses which are expensive toacquire or use pairs of LLMs to evaluate each other which can be unreliable. Inthis paper, we provide a novel perspective where, given a dataset of prompts(viz. questions, instructions, etc.) and a set of LLMs, we rank them withoutaccess to any ground truth or reference responses. Inspired by real life whereboth an expert and a knowledgeable person can identify a novice our main ideais to consider triplets of models, where each one of them evaluates the othertwo, correctly identifying the worst model in the triplet with highprobability. We also analyze our idea and provide sufficient conditions for itto succeed. Applying this idea repeatedly, we propose two methods to rank LLMs.In experiments on different generative tasks (summarization, multiple-choice,and dialog), our methods reliably recover close to true rankings withoutreference data. This points to a viable low-resource mechanism for practicaluse.</description><author>Amit Dhurandhar, Rahul Nair, Moninder Singh, Elizabeth Daly, Karthikeyan Natesan Ramamurthy</author><pubDate>Wed, 05 Jun 2024 16:56:49 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.14860v3</guid></item><item><title>Computational Approaches for Integrating out Subjectivity in Cognate Synonym Selection</title><link>http://arxiv.org/abs/2404.19328v2</link><description>Working with cognate data involves handling synonyms, that is, multiple wordsthat describe the same concept in a language. In the early days of languagephylogenetics it was recommended to select one synonym only. However, as weshow here, binary character matrices, which are used as input for computationalmethods, do allow for representing the entire dataset including all synonyms.Here we address the question how one can and if one should include all synonymsor whether it is preferable to select synonyms a priori. To this end, weperform maximum likelihood tree inferences with the widely used RAxML-NG tooland show that it yields plausible trees when all synonyms are used as input.Furthermore, we show that a priori synonym selection can yield topologicallysubstantially different trees and we therefore advise against doing so. Torepresent cognate data including all synonyms, we introduce two types ofcharacter matrices beyond the standard binary ones: probabilistic binary andprobabilistic multi-valued character matrices. We further show that it isdataset-dependent for which character matrix type the inferred RAxML-NG tree istopologically closest to the gold standard. We also make available a Pythoninterface for generating all of the above character matrix types for cognatedata provided in CLDF format.</description><author>Luise Häuser, Gerhard Jäger, Alexandros Stamatakis</author><pubDate>Wed, 05 Jun 2024 16:56:26 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.19328v2</guid></item><item><title>Methods for Class-Imbalanced Learning with Support Vector Machines: A Review and an Empirical Evaluation</title><link>http://arxiv.org/abs/2406.03398v1</link><description>This paper presents a review on methods for class-imbalanced learning withthe Support Vector Machine (SVM) and its variants. We first explain thestructure of SVM and its variants and discuss their inefficiency in learningwith class-imbalanced data sets. We introduce a hierarchical categorization ofSVM-based models with respect to class-imbalanced learning. Specifically, wecategorize SVM-based models into re-sampling, algorithmic, and fusion methods,and discuss the principles of the representative models in each category. Inaddition, we conduct a series of empirical evaluations to compare theperformances of various representative SVM-based models in each category usingbenchmark imbalanced data sets, ranging from low to high imbalanced ratios. Ourfindings reveal that while algorithmic methods are less time-consuming owing tono data pre-processing requirements, fusion methods, which combine bothre-sampling and algorithmic approaches, generally perform the best, but with ahigher computational load. A discussion on research gaps and future researchdirections is provided.</description><author>Salim rezvani, Farhad Pourpanah, Chee Peng Lim, Q. M. Jonathan Wu</author><pubDate>Wed, 05 Jun 2024 16:55:08 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.03398v1</guid></item><item><title>Automating Turkish Educational Quiz Generation Using Large Language Models</title><link>http://arxiv.org/abs/2406.03397v1</link><description>Crafting quizzes from educational content is a pivotal activity that benefitsboth teachers and students by reinforcing learning and evaluatingunderstanding. In this study, we introduce a novel approach to generate quizzesfrom Turkish educational texts, marking a pioneering endeavor in educationaltechnology specifically tailored to the Turkish educational context. We presenta specialized dataset, named the Turkish-Quiz-Instruct, comprising an extensivecollection of Turkish educational texts accompanied by multiple-choice andshort-answer quizzes. This research leverages the capabilities of LargeLanguage Models (LLMs), including GPT-4-Turbo, GPT-3.5-Turbo,Llama-2-7b-chat-hf, and Llama-2-13b-chat-hf, to automatically generate quizquestions and answers from the Turkish educational content. Our work delineatesthe methodology for employing these LLMs in the context of Turkish educationalmaterial, thereby opening new avenues for automated Turkish quiz generation.The study not only demonstrates the efficacy of using such models forgenerating coherent and relevant quiz content but also sets a precedent forfuture research in the domain of automated educational content creation forlanguages other than English. The Turkish-Quiz-Instruct dataset is introducedas a valuable resource for researchers and practitioners aiming to explore theboundaries of educational technology and language-specific applications of LLMsin Turkish. By addressing the challenges of quiz generation in a non-Englishcontext specifically Turkish, this study contributes significantly to the fieldof Turkish educational technology, providing insights into the potential ofleveraging LLMs for educational purposes across diverse linguistic landscapes.</description><author>Kamyar Zeinalipour, Yusuf Gökberk Keptiğ, Marco Maggini, Marco Gori</author><pubDate>Wed, 05 Jun 2024 16:54:50 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.03397v1</guid></item><item><title>Noisy Data Visualization using Functional Data Analysis</title><link>http://arxiv.org/abs/2406.03396v1</link><description>Data visualization via dimensionality reduction is an important tool inexploratory data analysis. However, when the data are noisy, many existingmethods fail to capture the underlying structure of the data. The method calledEmpirical Intrinsic Geometry (EIG) was previously proposed for performingdimensionality reduction on high dimensional dynamical processes whiletheoretically eliminating all noise. However, implementing EIG in practicerequires the construction of high-dimensional histograms, which suffer from thecurse of dimensionality. Here we propose a new data visualization method calledFunctional Information Geometry (FIG) for dynamical processes that adapts theEIG framework while using approaches from functional data analysis to mitigatethe curse of dimensionality. We experimentally demonstrate that the resultingmethod outperforms a variant of EIG designed for visualization in terms ofcapturing the true structure, hyperparameter robustness, and computationalspeed. We then use our method to visualize EEG brain measurements of sleepactivity.</description><author>Haozhe Chen, Andres Felipe Duque Correa, Guy Wolf, Kevin R. Moon</author><pubDate>Wed, 05 Jun 2024 16:53:25 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.03396v1</guid></item><item><title>CR-UTP: Certified Robustness against Universal Text Perturbations on Large Language Models</title><link>http://arxiv.org/abs/2406.01873v2</link><description>It is imperative to ensure the stability of every prediction made by alanguage model; that is, a language's prediction should remain consistentdespite minor input variations, like word substitutions. In this paper, weinvestigate the problem of certifying a language model's robustness againstUniversal Text Perturbations (UTPs), which have been widely used in universaladversarial attacks and backdoor attacks. Existing certified robustness basedon random smoothing has shown considerable promise in certifying theinput-specific text perturbations (ISTPs), operating under the assumption thatany random alteration of a sample's clean or adversarial words would negate theimpact of sample-wise perturbations. However, with UTPs, masking only theadversarial words can eliminate the attack. A naive method is to simplyincrease the masking ratio and the likelihood of masking attack tokens, but itleads to a significant reduction in both certified accuracy and the certifiedradius due to input corruption by extensive masking. To solve this challenge,we introduce a novel approach, the superior prompt search method, designed toidentify a superior prompt that maintains higher certified accuracy underextensive masking. Additionally, we theoretically motivate why ensembles are aparticularly suitable choice as base prompts for random smoothing. The methodis denoted by superior prompt ensembling technique. We also empirically confirmthis technique, obtaining state-of-the-art results in multiple settings. Thesemethodologies, for the first time, enable high certified accuracy against bothUTPs and ISTPs. The source code of CR-UTP is available at \url{https://github.com/UCFML-Research/CR-UTP}.</description><author>Qian Lou, Xin Liang, Jiaqi Xue, Yancheng Zhang, Rui Xie, Mengxin Zheng</author><pubDate>Wed, 05 Jun 2024 16:53:01 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.01873v2</guid></item><item><title>How to Train Neural Field Representations: A Comprehensive Study and Benchmark</title><link>http://arxiv.org/abs/2312.10531v2</link><description>Neural fields (NeFs) have recently emerged as a versatile method for modelingsignals of various modalities, including images, shapes, and scenes.Subsequently, a number of works have explored the use of NeFs asrepresentations for downstream tasks, e.g. classifying an image based on theparameters of a NeF that has been fit to it. However, the impact of the NeFhyperparameters on their quality as downstream representation is scarcelyunderstood and remains largely unexplored. This is in part caused by the largeamount of time required to fit datasets of neural fields. In this work, we propose a JAX-based library that leverages parallelizationto enable fast optimization of large-scale NeF datasets, resulting in asignificant speed-up. With this library, we perform a comprehensive study thatinvestigates the effects of different hyperparameters on fitting NeFs fordownstream tasks. In particular, we explore the use of a shared initialization,the effects of overtraining, and the expressiveness of the networkarchitectures used. Our study provides valuable insights on how to train NeFsand offers guidance for optimizing their effectiveness in downstreamapplications. Finally, based on the proposed library and our analysis, wepropose Neural Field Arena, a benchmark consisting of neural field variants ofpopular vision datasets, including MNIST, CIFAR, variants of ImageNet, andShapeNetv2. Our library and the Neural Field Arena will be open-sourced tointroduce standardized benchmarking and promote further research on neuralfields.</description><author>Samuele Papa, Riccardo Valperga, David Knigge, Miltiadis Kofinas, Phillip Lippe, Jan-Jakob Sonke, Efstratios Gavves</author><pubDate>Wed, 05 Jun 2024 16:51:53 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.10531v2</guid></item><item><title>Conformal Validity Guarantees Exist for Any Data Distribution (and How to Find Them)</title><link>http://arxiv.org/abs/2405.06627v3</link><description>As artificial intelligence (AI) / machine learning (ML) gain widespreadadoption, practitioners are increasingly seeking means to quantify and controlthe risk these systems incur. This challenge is especially salient when suchsystems have autonomy to collect their own data, such as in black-boxoptimization and active learning, where their actions induce sequentialfeedback-loop shifts in the data distribution. Conformal prediction is apromising approach to uncertainty and risk quantification, but prior variants'validity guarantees have assumed some form of ``quasi-exchangeability'' on thedata distribution, thereby excluding many types of sequential shifts. In thispaper we prove that conformal prediction can theoretically be extended to\textit{any} joint data distribution, not just exchangeable orquasi-exchangeable ones. Although the most general case is exceedinglyimpractical to compute, for concrete practical applications we outline aprocedure for deriving specific conformal algorithms for any data distribution,and we use this procedure to derive tractable algorithms for a series ofAI/ML-agent-induced covariate shifts. We evaluate the proposed algorithmsempirically on synthetic black-box optimization and active learning tasks.</description><author>Drew Prinster, Samuel Stanton, Anqi Liu, Suchi Saria</author><pubDate>Wed, 05 Jun 2024 16:49:11 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.06627v3</guid></item><item><title>Demonstrating Mutual Reinforcement Effect through Information Flow</title><link>http://arxiv.org/abs/2403.02902v2</link><description>The Mutual Reinforcement Effect (MRE) investigates the synergisticrelationship between word-level and text-level classifications in textclassification tasks. It posits that the performance of both classificationlevels can be mutually enhanced. However, this mechanism has not beenadequately demonstrated or explained in prior research. To address this gap, weemploy information flow analysis to observe and substantiate the MRE theory.Our experiments on six MRE hybrid datasets revealed the presence of MRE in themodel and its impact. Additionally, we conducted fine-tuning experiments, whoseresults were consistent with those of the information flow experiments. Theconvergence of findings from both experiments corroborates the existence ofMRE. Furthermore, we extended the application of MRE to prompt learning,utilizing word-level information as a verbalizer to bolster the model'sprediction of text-level classification labels. In our final experiment, theF1-score significantly surpassed the baseline in five out of six datasets,further validating the notion that word-level information enhances the languagemodel's comprehension of the text as a whole.</description><author>Chengguang Gan, Xuzheng He, Qinghao Zhang, Tatsunori Mori</author><pubDate>Wed, 05 Jun 2024 16:47:38 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.02902v2</guid></item><item><title>Learning to Edit: Aligning LLMs with Knowledge Editing</title><link>http://arxiv.org/abs/2402.11905v2</link><description>Knowledge editing techniques, aiming to efficiently modify a minor proportionof knowledge in large language models (LLMs) without negatively impactingperformance across other inputs, have garnered widespread attention. However,existing methods predominantly rely on memorizing the updated knowledge,impeding LLMs from effectively combining the new knowledge with their inherentknowledge when answering questions. To this end, we propose a Learning to Edit(LTE) framework, focusing on teaching LLMs to apply updated knowledge intoinput questions, inspired by the philosophy of "Teach a man to fish." LTEfeatures a two-phase process: (i) the Alignment Phase, which fine-tunes LLMs ona meticulously curated parallel dataset to make reliable, in-scope edits whilepreserving out-of-scope information and linguistic proficiency; and (ii) theInference Phase, which employs a retrieval-based mechanism for real-time andmass knowledge editing. By comparing our approach with seven advanced baselinesacross four popular knowledge editing benchmarks and two LLM architectures, wedemonstrate LTE's superiority in knowledge editing performance, robustness inboth batch and sequential editing, minimal interference on general tasks, andrapid editing speeds. The data and code are available athttps://github.com/YJiangcm/LTE.</description><author>Yuxin Jiang, Yufei Wang, Chuhan Wu, Wanjun Zhong, Xingshan Zeng, Jiahui Gao, Liangyou Li, Xin Jiang, Lifeng Shang, Ruiming Tang, Qun Liu, Wei Wang</author><pubDate>Wed, 05 Jun 2024 16:46:03 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.11905v2</guid></item><item><title>Error Feedback Can Accurately Compress Preconditioners</title><link>http://arxiv.org/abs/2306.06098v5</link><description>Leveraging second-order information about the loss at the scale of deepnetworks is one of the main lines of approach for improving the performance ofcurrent optimizers for deep learning. Yet, existing approaches for accuratefull-matrix preconditioning, such as Full-Matrix Adagrad (GGT) or Matrix-FreeApproximate Curvature (M-FAC) suffer from massive storage costs when appliedeven to small-scale models, as they must store a sliding window of gradients,whose memory requirements are multiplicative in the model dimension. In thispaper, we address this issue via a novel and efficient error-feedback techniquethat can be applied to compress preconditioners by up to two orders ofmagnitude in practice, without loss of convergence. Specifically, our approachcompresses the gradient information via sparsification or low-rank compression\emph{before} it is fed into the preconditioner, feeding the compression errorback into future iterations. Experiments on deep neural networks show that thisapproach can compress full-matrix preconditioners to up to 99\% sparsitywithout accuracy loss, effectively removing the memory overhead of full-matrixpreconditioners such as GGT and M-FAC. Our code is available at\url{https://github.com/IST-DASLab/EFCP}.</description><author>Ionut-Vlad Modoranu, Aleksei Kalinov, Eldar Kurtic, Elias Frantar, Dan Alistarh</author><pubDate>Wed, 05 Jun 2024 16:45:58 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.06098v5</guid></item><item><title>Luna: An Evaluation Foundation Model to Catch Language Model Hallucinations with High Accuracy and Low Cost</title><link>http://arxiv.org/abs/2406.00975v2</link><description>Retriever Augmented Generation (RAG) systems have become pivotal in enhancingthe capabilities of language models by incorporating external knowledgeretrieval mechanisms. However, a significant challenge in deploying thesesystems in industry applications is the detection and mitigation ofhallucinations: instances where the model generates information that is notgrounded in the retrieved context. Addressing this issue is crucial forensuring the reliability and accuracy of responses generated by large languagemodels (LLMs) in diverse industry settings. Current hallucination detectiontechniques fail to deliver accuracy, low latency, and low cost simultaneously.We introduce Luna: a DeBERTA-large (440M) encoder, finetuned for hallucinationdetection in RAG settings. We demonstrate that Luna outperforms GPT-3.5 andcommercial evaluation frameworks on the hallucination detection task, with 97%and 91% reduction in cost and latency, respectively. Luna is lightweight andgeneralizes across multiple industry verticals and out-of-domain data, makingit an ideal candidate for industry LLM applications.</description><author>Masha Belyi, Robert Friel, Shuai Shao, Atindriyo Sanyal</author><pubDate>Wed, 05 Jun 2024 16:45:04 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.00975v2</guid></item><item><title>Gaussian Representation for Deformable Image Registration</title><link>http://arxiv.org/abs/2406.03394v1</link><description>Deformable image registration (DIR) is a fundamental task in radiotherapy,with existing methods often struggling to balance computational efficiency,registration accuracy, and speed effectively. We introduce a novel DIR approachemploying parametric 3D Gaussian control points achieving a better tradeoff. Itprovides an explicit and flexible representation for spatial deformation fieldsbetween 3D volumetric medical images, producing a displacement vector field(DVF) across all volumetric positions. The movement of individual voxels isderived using linear blend skinning (LBS) through localized interpolation oftransformations associated with neighboring Gaussians. This interpolationstrategy not only simplifies the determination of voxel motions but also actsas an effective regularization technique. Our approach incorporates a unifiedoptimization process through backpropagation, enabling iterative learning ofboth the parameters of the 3D Gaussians and their transformations.Additionally, the density of Gaussians is adjusted adaptively during thelearning phase to accommodate varying degrees of motion complexity. Wevalidated our approach on the 4D-CT lung DIR-Lab and cardiac ACDC datasets,achieving an average target registration error (TRE) of 1.06 mm within amuch-improved processing time of 2.43 seconds for the DIR-Lab dataset overexisting methods, demonstrating significant advancements in both accuracy andefficiency.</description><author>Jihe Li, Fabian Zhang, Xia Li, Tianhao Zhang, Ye Zhang, Joachim Buhmann</author><pubDate>Wed, 05 Jun 2024 16:44:54 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.03394v1</guid></item><item><title>Author, Content or Sharers? Estimating Spread Dynamics with Bayesian Mixture Hawkes</title><link>http://arxiv.org/abs/2406.03390v1</link><description>The spread of content on social media is shaped by intertwining factors onthree levels: the source, the content itself, and the pathways of contentspread. At the lowest level, the popularity of the sharing user determines itseventual reach. However, higher-level factors such as the nature of the onlineitem and the credibility of its source also play crucial roles in determininghow widely and rapidly the online item spreads. In this work, we propose theBayesian Mixture Hawkes (BMH) model to jointly learn the influence of source,content and spread. We formulate the BMH model as a hierarchical mixture modelof separable Hawkes processes, accommodating different classes of Hawkesdynamics and the influence of feature sets on these classes. We test the BMHmodel on two learning tasks, cold-start popularity prediction and temporalprofile generalization performance, applying to two real-world retweet cascadedatasets referencing articles from controversial and traditional mediapublishers. The BMH model outperforms the state-of-the-art models andpredictive baselines on both datasets and utilizes cascade- and item-levelinformation better than the alternatives. Lastly, we perform a counter-factualanalysis where we apply the trained publisher-level BMH models to a set ofarticle headlines and show that effectiveness of headline writing style(neutral, clickbait, inflammatory) varies across publishers. The BMH modelunveils differences in style effectiveness between controversial and reputablepublishers, where we find clickbait to be notably more effective for reputablepublishers as opposed to controversial ones, which links to the latter'soveruse of clickbait.</description><author>Pio Calderon, Marian-Andrei Rizoiu</author><pubDate>Wed, 05 Jun 2024 16:41:02 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.03390v1</guid></item><item><title>FollowBench: A Multi-level Fine-grained Constraints Following Benchmark for Large Language Models</title><link>http://arxiv.org/abs/2310.20410v3</link><description>The ability to follow instructions is crucial for Large Language Models(LLMs) to handle various real-world applications. Existing benchmarks primarilyfocus on evaluating pure response quality, rather than assessing whether theresponse follows constraints stated in the instruction. To fill this researchgap, in this paper, we propose FollowBench, a Multi-level Fine-grainedConstraints Following Benchmark for LLMs. FollowBench comprehensively includesfive different types (i.e., Content, Situation, Style, Format, and Example) offine-grained constraints. To enable a precise constraint following estimationon diverse difficulties, we introduce a Multi-level mechanism thatincrementally adds a single constraint to the initial instruction at eachincreased level. To assess whether LLMs' outputs have satisfied everyindividual constraint, we propose to prompt strong LLMs withconstraint-evolution paths to handle challenging open-ended instructions. Byevaluating 13 closed-source and open-source popular LLMs on FollowBench, wehighlight the weaknesses of LLMs in instruction following and point towardspotential avenues for future work. The data and code are publicly available athttps://github.com/YJiangcm/FollowBench.</description><author>Yuxin Jiang, Yufei Wang, Xingshan Zeng, Wanjun Zhong, Liangyou Li, Fei Mi, Lifeng Shang, Xin Jiang, Qun Liu, Wei Wang</author><pubDate>Wed, 05 Jun 2024 16:39:26 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.20410v3</guid></item><item><title>SelfReDepth: Self-Supervised Real-Time Depth Restoration for Consumer-Grade Sensors</title><link>http://arxiv.org/abs/2406.03388v1</link><description>Depth maps produced by consumer-grade sensors suffer from inaccuratemeasurements and missing data from either system or scene-specific sources.Data-driven denoising algorithms can mitigate such problems. However, theyrequire vast amounts of ground truth depth data. Recent research has tackledthis limitation using self-supervised learning techniques, but it requiresmultiple RGB-D sensors. Moreover, most existing approaches focus on denoisingsingle isolated depth maps or specific subjects of interest, highlighting aneed for methods to effectively denoise depth maps in real-time dynamicenvironments. This paper extends state-of-the-art approaches fordepth-denoising commodity depth devices, proposing SelfReDepth, aself-supervised deep learning technique for depth restoration, via denoisingand hole-filling by inpainting full-depth maps captured with RGB-D sensors. Thealgorithm targets depth data in video streams, utilizing multiple sequentialdepth frames coupled with color data to achieve high-quality depth videos withtemporal coherence. Finally, SelfReDepth is designed to be compatible withvarious RGB-D sensors and usable in real-time scenarios as a pre-processingstep before applying other depth-dependent algorithms. Our results demonstrateour approach's real-time performance on real-world datasets. They show that itoutperforms state-of-the-art denoising and restoration performance at over30fps on Commercial Depth Cameras, with potential benefits for augmented andmixed-reality applications.</description><author>Alexandre Duarte, Francisco Fernandes, João M. Pereira, Catarina Moreira, Jacinto C. Nascimento, Joaquim Jorge</author><pubDate>Wed, 05 Jun 2024 16:38:02 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.03388v1</guid></item><item><title>Learning Long Range Dependencies on Graphs via Random Walks</title><link>http://arxiv.org/abs/2406.03386v1</link><description>Message-passing graph neural networks (GNNs), while excelling at capturinglocal relationships, often struggle with long-range dependencies on graphs.Conversely, graph transformers (GTs) enable information exchange between allnodes but oversimplify the graph structure by treating them as a set offixed-length vectors. This work proposes a novel architecture, NeuralWalker,that overcomes the limitations of both methods by combining random walks withmessage passing. NeuralWalker achieves this by treating random walks assequences, allowing for the application of recent advances in sequence modelsin order to capture long-range dependencies within these walks. Based on thisconcept, we propose a framework that offers (1) more expressive graphrepresentations through random walk sequences, (2) the ability to utilize anysequence model for capturing long-range dependencies, and (3) the flexibilityby integrating various GNN and GT architectures. Our experimental evaluationsdemonstrate that NeuralWalker achieves significant performance improvements on19 graph and node benchmark datasets, notably outperforming existing methods byup to 13% on the PascalVoc-SP and COCO-SP datasets. Code is available athttps://github.com/BorgwardtLab/NeuralWalker.</description><author>Dexiong Chen, Till Hendrik Schulz, Karsten Borgwardt</author><pubDate>Wed, 05 Jun 2024 16:36:57 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.03386v1</guid></item><item><title>AFF-ttention! Affordances and Attention models for Short-Term Object Interaction Anticipation</title><link>http://arxiv.org/abs/2406.01194v2</link><description>Short-Term object-interaction Anticipation consists of detecting the locationof the next-active objects, the noun and verb categories of the interaction,and the time to contact from the observation of egocentric video. This abilityis fundamental for wearable assistants or human robot interaction to understandthe user goals, but there is still room for improvement to perform STA in aprecise and reliable way. In this work, we improve the performance of STApredictions with two contributions: 1. We propose STAformer, a novelattention-based architecture integrating frame guided temporal pooling, dualimage-video attention, and multiscale feature fusion to support STA predictionsfrom an image-input video pair. 2. We introduce two novel modules to ground STApredictions on human behavior by modeling affordances.First, we integrate anenvironment affordance model which acts as a persistent memory of interactionsthat can take place in a given physical scene. Second, we predict interactionhotspots from the observation of hands and object trajectories, increasingconfidence in STA predictions localized around the hotspot. Our results showsignificant relative Overall Top-5 mAP improvements of up to +45% on Ego4D and+42% on a novel set of curated EPIC-Kitchens STA labels. We will release thecode, annotations, and pre extracted affordances on Ego4D and EPIC- Kitchens toencourage future research in this area.</description><author>Lorenzo Mur-Labadia, Ruben Martinez-Cantin, Josechu Guerrero, Giovanni Maria Farinella, Antonino Furnari</author><pubDate>Wed, 05 Jun 2024 16:34:47 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.01194v2</guid></item><item><title>Entity Matching using Large Language Models</title><link>http://arxiv.org/abs/2310.11244v3</link><description>Entity Matching is the task of deciding whether two entity descriptions referto the same real-world entity and is a central step in most data integrationpipelines. Many state-of-the-art entity matching methods rely on pre-trainedlanguage models (PLMs) such as BERT or RoBERTa. Two major drawbacks of thesemodels for entity matching are that (i) the models require significant amountsof task-specific training data and (ii) the fine-tuned models are not robustconcerning out-of-distribution entities. This paper investigates usinggenerative large language models (LLMs) as a less task-specific trainingdata-dependent and more robust alternative to PLM-based matchers. Our studycovers hosted and open-source LLMs, which can be run locally. We evaluate thesemodels in a zero-shot scenario and a scenario where task-specific training datais available. We compare different prompt designs and the prompt sensitivity ofthe models and show that there is no single best prompt but needs to be tunedfor each model/dataset combination. We further investigate (i) the selection ofin-context demonstrations, (ii) the generation of matching rules, as well as(iii) fine-tuning a hosted LLM using the same pool of training data. Ourexperiments show that the best LLMs require no or only a few training examplesto perform similarly to PLMs that were fine-tuned using thousands of examples.LLM-based matchers further exhibit higher robustness to unseen entities. Weshow that GPT4 can generate structured explanations for matching decisions. Themodel can automatically identify potential causes of matching errors byanalyzing explanations of wrong decisions. We demonstrate that the model cangenerate meaningful textual descriptions of the identified error classes, whichcan help data engineers improve entity matching pipelines.</description><author>Ralph Peeters, Christian Bizer</author><pubDate>Wed, 05 Jun 2024 16:33:25 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.11244v3</guid></item><item><title>CoopHash: Cooperative Learning of Multipurpose Descriptor and Contrastive Pair Generator via Variational MCMC Teaching for Supervised Image Hashing</title><link>http://arxiv.org/abs/2210.04288v2</link><description>Leveraging supervised information can lead to superior retrieval performancein the image hashing domain but the performance degrades significantly withoutenough labeled data. One effective solution to boost performance is to employgenerative models, such as Generative Adversarial Networks (GANs), to generatesynthetic data in an image hashing model. However, GAN-based methods aredifficult to train, which prevents the hashing approaches from jointly trainingthe generative models and the hash functions. This limitation results insub-optimal retrieval performance. To overcome this limitation, we propose anovel framework, the generative cooperative hashing network, which is based onenergy-based cooperative learning. This framework jointly learns a powerfulgenerative representation of the data and a robust hash function via twocomponents: a top-down contrastive pair generator that synthesizes contrastiveimages and a bottom-up multipurpose descriptor that simultaneously representsthe images from multiple perspectives, including probability density, hashcode, latent code, and category. The two components are jointly learned via anovel likelihood-based cooperative learning scheme. We conduct experiments onseveral real-world datasets and show that the proposed method outperforms thecompeting hashing supervised methods, achieving up to 10\% relative improvementover the current state-of-the-art supervised hashing methods, and exhibits asignificantly better performance in out-of-distribution retrieval.</description><author>Khoa D. Doan, Jianwen Xie, Yaxuan Zhu, Yang Zhao, Ping Li</author><pubDate>Wed, 05 Jun 2024 16:33:23 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2210.04288v2</guid></item><item><title>Robust CLIP: Unsupervised Adversarial Fine-Tuning of Vision Embeddings for Robust Large Vision-Language Models</title><link>http://arxiv.org/abs/2402.12336v2</link><description>Multi-modal foundation models like OpenFlamingo, LLaVA, and GPT-4 areincreasingly used for various real-world tasks. Prior work has shown that thesemodels are highly vulnerable to adversarial attacks on the vision modality.These attacks can be leveraged to spread fake information or defraud users, andthus pose a significant risk, which makes the robustness of large multi-modalfoundation models a pressing problem. The CLIP model, or one of its variants,is used as a frozen vision encoder in many large vision-language models(LVLMs), e.g. LLaVA and OpenFlamingo. We propose an unsupervised adversarialfine-tuning scheme to obtain a robust CLIP vision encoder, which yieldsrobustness on all vision down-stream tasks (LVLMs, zero-shot classification)that rely on CLIP. In particular, we show that stealth-attacks on users ofLVLMs by a malicious third party providing manipulated images are no longerpossible once one replaces the original CLIP model with our robust one. Noretraining or fine-tuning of the down-stream LVLMs is required. The code androbust models are available at https://github.com/chs20/RobustVLM</description><author>Christian Schlarmann, Naman Deep Singh, Francesco Croce, Matthias Hein</author><pubDate>Wed, 05 Jun 2024 16:32:03 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.12336v2</guid></item><item><title>Sampling in Unit Time with Kernel Fisher-Rao Flow</title><link>http://arxiv.org/abs/2401.03892v3</link><description>We introduce a new mean-field ODE and corresponding interacting particlesystems (IPS) for sampling from an unnormalized target density. The IPS aregradient-free, available in closed form, and only require the ability to samplefrom a reference density and compute the (unnormalized) target-to-referencedensity ratio. The mean-field ODE is obtained by solving a Poisson equation fora velocity field that transports samples along the geometric mixture of the twodensities, which is the path of a particular Fisher-Rao gradient flow. Weemploy a RKHS ansatz for the velocity field, which makes the Poisson equationtractable and enables discretization of the resulting mean-field ODE overfinite samples. The mean-field ODE can be additionally be derived from adiscrete-time perspective as the limit of successive linearizations of theMonge-Amp\`ere equations within a framework known as sample-driven optimaltransport. We introduce a stochastic variant of our approach and demonstrateempirically that our IPS can produce high-quality samples from varied targetdistributions, outperforming comparable gradient-free particle systems andcompetitive with gradient-based alternatives.</description><author>Aimee Maurais, Youssef Marzouk</author><pubDate>Wed, 05 Jun 2024 16:30:09 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.03892v3</guid></item><item><title>The AI Community Building the Future? A Quantitative Analysis of Development Activity on Hugging Face Hub</title><link>http://arxiv.org/abs/2405.13058v2</link><description>Open model developers have emerged as key actors in the political economy ofartificial intelligence (AI), but we still have a limited understanding ofcollaborative practices in the open AI ecosystem. This paper responds to thisgap with a three-part quantitative analysis of development activity on theHugging Face (HF) Hub, a popular platform for building, sharing, anddemonstrating models. First, various types of activity across 348,181 model,65,761 dataset, and 156,642 space repositories exhibit right-skeweddistributions. Activity is extremely imbalanced between repositories; forexample, over 70% of models have 0 downloads, while 1% account for 99% ofdownloads. Furthermore, licenses matter: there are statistically significantdifferences in collaboration patterns in model repositories with permissive,restrictive, and no licenses. Second, we analyse a snapshot of the socialnetwork structure of collaboration in model repositories, finding that thecommunity has a core-periphery structure, with a core of prolific developersand a majority of isolate developers (89%). Upon removing the isolatedevelopers from the network, collaboration is characterised by high reciprocityregardless of developers' network positions. Third, we examine model adoptionthrough the lens of model usage in spaces, finding that a minority of models,developed by a handful of companies, are widely used on the HF Hub. Overall,activity on the HF Hub is characterised by Pareto distributions, congruent withOSS development patterns on platforms like GitHub. We conclude withrecommendations for researchers, companies, and policymakers to advance ourunderstanding of open AI development.</description><author>Cailean Osborne, Jennifer Ding, Hannah Rose Kirk</author><pubDate>Wed, 05 Jun 2024 16:28:43 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.13058v2</guid></item><item><title>Training of Physical Neural Networks</title><link>http://arxiv.org/abs/2406.03372v1</link><description>Physical neural networks (PNNs) are a class of neural-like networks thatleverage the properties of physical systems to perform computation. While PNNsare so far a niche research area with small-scale laboratory demonstrations,they are arguably one of the most underappreciated important opportunities inmodern AI. Could we train AI models 1000x larger than current ones? Could we dothis and also have them perform inference locally and privately on edgedevices, such as smartphones or sensors? Research over the past few years hasshown that the answer to all these questions is likely "yes, with enoughresearch": PNNs could one day radically change what is possible and practicalfor AI systems. To do this will however require rethinking both how AI modelswork, and how they are trained - primarily by considering the problems throughthe constraints of the underlying hardware physics. To train PNNs at largescale, many methods including backpropagation-based and backpropagation-freeapproaches are now being explored. These methods have various trade-offs, andso far no method has been shown to scale to the same scale and performance asthe backpropagation algorithm widely used in deep learning today. However, thisis rapidly changing, and a diverse ecosystem of training techniques providesclues for how PNNs may one day be utilized to create both more efficientrealizations of current-scale AI models, and to enable unprecedented-scalemodels.</description><author>Ali Momeni, Babak Rahmani, Benjamin Scellier, Logan G. Wright, Peter L. McMahon, Clara C. Wanjura, Yuhang Li, Anas Skalli, Natalia G. Berloff, Tatsuhiro Onodera, Ilker Oguz, Francesco Morichetti, Philipp del Hougne, Manuel Le Gallo, Abu Sebastian, Azalia Mirhoseini, Cheng Zhang, Danijela Marković, Daniel Brunner, Christophe Moser, Sylvain Gigan, Florian Marquardt, Aydogan Ozcan, Julie Grollier, Andrea J. Liu, Demetri Psaltis, Andrea Alù, Romain Fleury</author><pubDate>Wed, 05 Jun 2024 16:28:04 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.03372v1</guid></item><item><title>I-LLM: Efficient Integer-Only Inference for Fully-Quantized Low-Bit Large Language Models</title><link>http://arxiv.org/abs/2405.17849v2</link><description>Post-training quantization (PTQ) serves as a potent technique to acceleratethe inference of large language models (LLMs). Nonetheless, existing worksstill necessitate a considerable number of floating-point (FP) operationsduring inference, including additional quantization and de-quantization, aswell as non-linear operators such as RMSNorm and Softmax. This limitationhinders the deployment of LLMs on the edge and cloud devices. In this paper, weidentify the primary obstacle to integer-only quantization for LLMs lies in thelarge fluctuation of activations across channels and tokens in both linear andnon-linear operations. To address this issue, we propose I-LLM, a novelinteger-only fully-quantized PTQ framework tailored for LLMs. Specifically, (1)we develop Fully-Smooth Block-Reconstruction (FSBR) to aggressively smoothinter-channel variations of all activations and weights. (2) to alleviatedegradation caused by inter-token variations, we introduce a novel approachcalled Dynamic Integer-only MatMul (DI-MatMul). This method enables dynamicquantization in full-integer matrix multiplication by dynamically quantizingthe input and outputs with integer-only operations. (3) we designDI-ClippedSoftmax, DI-Exp, and DI-Normalization, which utilize bit shift toexecute non-linear operators efficiently while maintaining accuracy. Theexperiment shows that our I-LLM achieves comparable accuracy to the FP baselineand outperforms non-integer quantization methods. For example, I-LLM canoperate at W4A4 with negligible loss of accuracy. To our knowledge, we are thefirst to bridge the gap between integer-only quantization and LLMs. We'vepublished our code on anonymous.4open.science, aiming to contribute to theadvancement of this field.</description><author>Xing Hu, Yuan Cheng, Dawei Yang, Zhihang Yuan, Jiangyong Yu, Chen Xu, Sifan Zhou</author><pubDate>Wed, 05 Jun 2024 16:26:58 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.17849v2</guid></item><item><title>Large Language Models Can Infer Psychological Dispositions of Social Media Users</title><link>http://arxiv.org/abs/2309.08631v2</link><description>Large Language Models (LLMs) demonstrate increasingly human-like abilitiesacross a wide variety of tasks. In this paper, we investigate whether LLMs likeChatGPT can accurately infer the psychological dispositions of social mediausers and whether their ability to do so varies across socio-demographicgroups. Specifically, we test whether GPT-3.5 and GPT-4 can derive the Big Fivepersonality traits from users' Facebook status updates in a zero-shot learningscenario. Our results show an average correlation of r = .29 (range = [.22,.33]) between LLM-inferred and self-reported trait scores - a level of accuracythat is similar to that of supervised machine learning models specificallytrained to infer personality. Our findings also highlight heterogeneity in theaccuracy of personality inferences across different age groups and gendercategories: predictions were found to be more accurate for women and youngerindividuals on several traits, suggesting a potential bias stemming from theunderlying training data or differences in online self-expression. The abilityof LLMs to infer psychological dispositions from user-generated text has thepotential to democratize access to cheap and scalable psychometric assessmentsfor both researchers and practitioners. On the one hand, this democratizationmight facilitate large-scale research of high ecological validity and sparkinnovation in personalized services. On the other hand, it also raises ethicalconcerns regarding user privacy and self-determination, highlighting the needfor stringent ethical frameworks and regulation.</description><author>Heinrich Peters, Sandra Matz</author><pubDate>Wed, 05 Jun 2024 16:25:06 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2309.08631v2</guid></item><item><title>Posterior and variational inference for deep neural networks with heavy-tailed weights</title><link>http://arxiv.org/abs/2406.03369v1</link><description>We consider deep neural networks in a Bayesian framework with a priordistribution sampling the network weights at random. Following a recent idea ofAgapiou and Castillo (2023), who show that heavy-tailed prior distributionsachieve automatic adaptation to smoothness, we introduce a simple Bayesian deeplearning prior based on heavy-tailed weights and ReLU activation. We show thatthe corresponding posterior distribution achieves near-optimal minimaxcontraction rates, simultaneously adaptive to both intrinsic dimension andsmoothness of the underlying function, in a variety of contexts includingnonparametric regression, geometric data and Besov spaces. While most works sofar need a form of model selection built-in within the prior distribution, akey aspect of our approach is that it does not require to samplehyperparameters to learn the architecture of the network. We also providevariational Bayes counterparts of the results, that show that mean-fieldvariational approximations still benefit from near-optimal theoretical support.</description><author>Ismaël Castillo, Paul Egels</author><pubDate>Wed, 05 Jun 2024 16:24:20 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.03369v1</guid></item><item><title>IrokoBench: A New Benchmark for African Languages in the Age of Large Language Models</title><link>http://arxiv.org/abs/2406.03368v1</link><description>Despite the widespread adoption of Large language models (LLMs), theirremarkable capabilities remain limited to a few high-resource languages.Additionally, many low-resource languages (e.g. African languages) are oftenevaluated only on basic text classification tasks due to the lack ofappropriate or comprehensive benchmarks outside of high-resource languages. Inthis paper, we introduce IrokoBench -- a human-translated benchmark dataset for16 typologically-diverse low-resource African languages covering three tasks:natural language inference~(AfriXNLI), mathematical reasoning~(AfriMGSM), andmulti-choice knowledge-based QA~(AfriMMLU). We use IrokoBench to evaluatezero-shot, few-shot, and translate-test settings~(where test sets aretranslated into English) across 10 open and four proprietary LLMs. Ourevaluation reveals a significant performance gap between high-resourcelanguages~(such as English and French) and low-resource African languages. Weobserve a significant performance gap between open and proprietary models, withthe highest performing open model, Aya-101 only at 58\% of the best-performingproprietary model GPT-4o performance. Machine translating the test set toEnglish before evaluation helped to close the gap for larger models that areEnglish-centric, like LLaMa 3 70B. These findings suggest that more efforts areneeded to develop and adapt LLMs for African languages.</description><author>David Ifeoluwa Adelani, Jessica Ojo, Israel Abebe Azime, Jian Yun Zhuang, Jesujoba O. Alabi, Xuanli He, Millicent Ochieng, Sara Hooker, Andiswa Bukula, En-Shiun Annie Lee, Chiamaka Chukwuneke, Happy Buzaaba, Blessing Sibanda, Godson Kalipe, Jonathan Mukiibi, Salomon Kabongo, Foutse Yuehgoh, Mmasibidi Setaka, Lolwethu Ndolela, Nkiruka Odu, Rooweither Mabuya, Shamsuddeen Hassan Muhammad, Salomey Osei, Sokhar Samb, Tadesse Kebede Guge, Pontus Stenetorp</author><pubDate>Wed, 05 Jun 2024 16:23:08 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.03368v1</guid></item><item><title>CLMASP: Coupling Large Language Models with Answer Set Programming for Robotic Task Planning</title><link>http://arxiv.org/abs/2406.03367v1</link><description>Large Language Models (LLMs) possess extensive foundational knowledge andmoderate reasoning abilities, making them suitable for general task planning inopen-world scenarios. However, it is challenging to ground a LLM-generated planto be executable for the specified robot with certain restrictions. This paperintroduces CLMASP, an approach that couples LLMs with Answer Set Programming(ASP) to overcome the limitations, where ASP is a non-monotonic logicprogramming formalism renowned for its capacity to represent and reason about arobot's action knowledge. CLMASP initiates with a LLM generating a basicskeleton plan, which is subsequently tailored to the specific scenario using avector database. This plan is then refined by an ASP program with a robot'saction knowledge, which integrates implementation details into the skeleton,grounding the LLM's abstract outputs in practical robot contexts. Ourexperiments conducted on the VirtualHome platform demonstrate CLMASP'sefficacy. Compared to the baseline executable rate of under 2% with LLMapproaches, CLMASP significantly improves this to over 90%.</description><author>Xinrui Lin, Yangfan Wu, Huanyu Yang, Yu Zhang, Yanyong Zhang, Jianmin Ji</author><pubDate>Wed, 05 Jun 2024 16:21:44 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.03367v1</guid></item><item><title>LLM-based Rewriting of Inappropriate Argumentation using Reinforcement Learning from Machine Feedback</title><link>http://arxiv.org/abs/2406.03363v1</link><description>Ensuring that online discussions are civil and productive is a majorchallenge for social media platforms. Such platforms usually rely both on usersand on automated detection tools to flag inappropriate arguments of otherusers, which moderators then review. However, this kind of post-hoc moderationis expensive and time-consuming, and moderators are often overwhelmed by theamount and severity of flagged content. Instead, a promising alternative is toprevent negative behavior during content creation. This paper studies howinappropriate language in arguments can be computationally mitigated. Wepropose a reinforcement learning-based rewriting approach that balances contentpreservation and appropriateness based on existing classifiers, prompting aninstruction-finetuned large language model (LLM) as our initial policy. Unlikerelated style transfer tasks, rewriting inappropriate arguments allows deletingand adding content permanently. It is therefore tackled on document levelrather than sentence level. We evaluate different weighting schemes for thereward function in both absolute and relative human assessment studies.Systematic experiments on non-parallel data provide evidence that our approachcan mitigate the inappropriateness of arguments while largely preserving theircontent. It significantly outperforms competitive baselines, including few-shotlearning, prompting, and humans.</description><author>Timon Ziegenbein, Gabriella Skitalinskaya, Alireza Bayat Makou, Henning Wachsmuth</author><pubDate>Wed, 05 Jun 2024 16:18:08 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.03363v1</guid></item><item><title>What Matters in Hierarchical Search for Combinatorial Reasoning Problems?</title><link>http://arxiv.org/abs/2406.03361v1</link><description>Efficiently tackling combinatorial reasoning problems, particularly thenotorious NP-hard tasks, remains a significant challenge for AI research.Recent efforts have sought to enhance planning by incorporating hierarchicalhigh-level search strategies, known as subgoal methods. While promising, theirperformance against traditional low-level planners is inconsistent, raisingquestions about their application contexts. In this study, we conduct anin-depth exploration of subgoal-planning methods for combinatorial reasoning.We identify the attributes pivotal for leveraging the advantages of high-levelsearch: hard-to-learn value functions, complex action spaces, presence of deadends in the environment, or using data collected from diverse experts. Wepropose a consistent evaluation methodology to achieve meaningful comparisonsbetween methods and reevaluate the state-of-the-art algorithms.</description><author>Michał Zawalski, Gracjan Góral, Michał Tyrolski, Emilia Wiśnios, Franciszek Budrowski, Łukasz Kuciński, Piotr Miłoś</author><pubDate>Wed, 05 Jun 2024 16:14:58 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.03361v1</guid></item><item><title>SuperFormer: Volumetric Transformer Architectures for MRI Super-Resolution</title><link>http://arxiv.org/abs/2406.03359v1</link><description>This paper presents a novel framework for processing volumetric medicalinformation using Visual Transformers (ViTs). First, We extend thestate-of-the-art Swin Transformer model to the 3D medical domain. Second, wepropose a new approach for processing volumetric information and encodingposition in ViTs for 3D applications. We instantiate the proposed framework andpresent SuperFormer, a volumetric transformer-based approach for MagneticResonance Imaging (MRI) Super-Resolution. Our method leverages the 3Dinformation of the MRI domain and uses a local self-attention mechanism with a3D relative positional encoding to recover anatomical details. In addition, ourapproach takes advantage of multi-domain information from volume and featuredomains and fuses them to reconstruct the High-Resolution MRI. We perform anextensive validation on the Human Connectome Project dataset and demonstratethe superiority of volumetric transformers over 3D CNN-based methods. Our codeand pretrained models are available athttps://github.com/BCV-Uniandes/SuperFormer.</description><author>Cristhian Forigua, Maria Escobar, Pablo Arbelaez</author><pubDate>Wed, 05 Jun 2024 16:14:29 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.03359v1</guid></item><item><title>Remove that Square Root: A New Efficient Scale-Invariant Version of AdaGrad</title><link>http://arxiv.org/abs/2403.02648v2</link><description>Adaptive methods are extremely popular in machine learning as they makelearning rate tuning less expensive. This paper introduces a novel optimizationalgorithm named KATE, which presents a scale-invariant adaptation of thewell-known AdaGrad algorithm. We prove the scale-invariance of KATE for thecase of Generalized Linear Models. Moreover, for general smooth non-convexproblems, we establish a convergence rate of $O \left(\frac{\log T}{\sqrt{T}}\right)$ for KATE, matching the best-known ones for AdaGrad and Adam. We alsocompare KATE to other state-of-the-art adaptive algorithms Adam and AdaGrad innumerical experiments with different problems, including complex machinelearning tasks like image classification and text classification on real data.The results indicate that KATE consistently outperforms AdaGrad andmatches/surpasses the performance of Adam in all considered scenarios.</description><author>Sayantan Choudhury, Nazarii Tupitsa, Nicolas Loizou, Samuel Horvath, Martin Takac, Eduard Gorbunov</author><pubDate>Wed, 05 Jun 2024 16:13:02 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.02648v2</guid></item></channel></rss>