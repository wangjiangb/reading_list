<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/"><channel><title>Arxivfresh papers</title><link></link><description>Arxiv paper</description><language>en-US</language><lastBuildDate>Thu, 03 Aug 2023 06:00:48 GMT</lastBuildDate><generator>rfeed v1.0.0</generator><docs>https://github.com/svpino/rfeed/blob/master/README.md</docs><item><title>ELIXR: Towards a general purpose X-ray artificial intelligence system through alignment of large language models and radiology vision encoders</title><link>http://arxiv.org/abs/2308.01317v1</link><description>Our approach, which we call Embeddings for Language/Image-aligned X-Rays, orELIXR, leverages a language-aligned image encoder combined or grafted onto afixed LLM, PaLM 2, to perform a broad range of tasks. We train this lightweightadapter architecture using images paired with corresponding free-text radiologyreports from the MIMIC-CXR dataset. ELIXR achieved state-of-the-art performanceon zero-shot chest X-ray (CXR) classification (mean AUC of 0.850 across 13findings), data-efficient CXR classification (mean AUCs of 0.893 and 0.898across five findings (atelectasis, cardiomegaly, consolidation, pleuraleffusion, and pulmonary edema) for 1% (~2,200 images) and 10% (~22,000 images)training data), and semantic search (0.76 normalized discounted cumulative gain(NDCG) across nineteen queries, including perfect retrieval on twelve of them).Compared to existing data-efficient methods including supervised contrastivelearning (SupCon), ELIXR required two orders of magnitude less data to reachsimilar performance. ELIXR also showed promise on CXR vision-language tasks,demonstrating overall accuracies of 58.7% and 62.5% on visual questionanswering and report quality assurance tasks, respectively. These resultssuggest that ELIXR is a robust and versatile approach to CXR AI.</description><author>Shawn Xu, Lin Yang, Christopher Kelly, Marcin Sieniek, Timo Kohlberger, Martin Ma, Wei-Hung Weng, Attila Kiraly, Sahar Kazemzadeh, Zakkai Melamed, Jungyeon Park, Patricia Strachan, Yun Liu, Chuck Lau, Preeti Singh, Christina Chen, Mozziyar Etemadi, Sreenivasa Raju Kalidindi, Yossi Matias, Katherine Chou, Greg S. Corrado, Shravya Shetty, Daniel Tse, Shruthi Prabhakara, Daniel Golden, Rory Pilgrim, Krish Eswaran, Andrew Sellergren</author><pubDate>Wed, 02 Aug 2023 18:59:45 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2308.01317v1</guid></item><item><title>Patched Denoising Diffusion Models For High-Resolution Image Synthesis</title><link>http://arxiv.org/abs/2308.01316v1</link><description>We propose an effective denoising diffusion model for generatinghigh-resolution images (e.g., 1024$\times$512), trained on small-size imagepatches (e.g., 64$\times$64). We name our algorithm Patch-DM, in which a newfeature collage strategy is designed to avoid the boundary artifact whensynthesizing large-size images. Feature collage systematically crops andcombines partial features of the neighboring patches to predict the features ofa shifted image patch, allowing the seamless generation of the entire image dueto the overlap in the patch feature space. Patch-DM produces high-quality imagesynthesis results on our newly collected dataset of nature images(1024$\times$512), as well as on standard benchmarks of smaller sizes(256$\times$256), including LSUN-Bedroom, LSUN-Church, and FFHQ. We compare ourmethod with previous patch-based generation methods and achievestate-of-the-art FID scores on all four datasets. Further, Patch-DM alsoreduces memory complexity compared to the classic diffusion models.</description><author>Zheng Ding, Mengqi Zhang, Jiajun Wu, Zhuowen Tu</author><pubDate>Wed, 02 Aug 2023 18:58:01 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2308.01316v1</guid></item><item><title>More Context, Less Distraction: Visual Classification by Inferring and Conditioning on Contextual Attributes</title><link>http://arxiv.org/abs/2308.01313v1</link><description>CLIP, as a foundational vision language model, is widely used in zero-shotimage classification due to its ability to understand various visual conceptsand natural language descriptions. However, how to fully leverage CLIP'sunprecedented human-like understanding capabilities to achieve better zero-shotclassification is still an open question. This paper draws inspiration from thehuman visual perception process: a modern neuroscience view suggests that inclassifying an object, humans first infer its class-independent attributes(e.g., background and orientation) which help separate the foreground objectfrom the background, and then make decisions based on this information.Inspired by this, we observe that providing CLIP with contextual attributesimproves zero-shot classification and mitigates reliance on spurious features.We also observe that CLIP itself can reasonably infer the attributes from animage. With these observations, we propose a training-free, two-step zero-shotclassification method named PerceptionCLIP. Given an image, it first inferscontextual attributes (e.g., background) and then performs objectclassification conditioning on them. Our experiments show that PerceptionCLIPachieves better generalization, group robustness, and better interpretability.For example, PerceptionCLIP with ViT-L/14 improves the worst group accuracy by16.5% on the Waterbirds dataset and by 3.5% on CelebA.</description><author>Bang An, Sicheng Zhu, Michael-Andrei Panaitescu-Liess, Chaithanya Kumar Mummadi, Furong Huang</author><pubDate>Wed, 02 Aug 2023 18:57:25 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2308.01313v1</guid></item><item><title>Lode Encoder: AI-constrained co-creativity</title><link>http://arxiv.org/abs/2308.01312v1</link><description>We present Lode Encoder, a gamified mixed-initiative level creation systemfor the classic platform-puzzle game Lode Runner. The system is built aroundseveral autoencoders which are trained on sets of Lode Runner levels. When fedwith the user's design, each autoencoder produces a version of that designwhich is closer in style to the levels that it was trained on. The Lode Encoderinterface allows the user to build and edit levels through 'painting' from thesuggestions provided by the autoencoders. Crucially, in order to encouragedesigners to explore new possibilities, the system does not include moretraditional editing tools. We report on the system design and trainingprocedure, as well as on the evolution of the system itself and user tests.</description><author>Debosmita Bhaumik, Ahmed Khalifa, Julian Togelius</author><pubDate>Wed, 02 Aug 2023 18:56:29 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2308.01312v1</guid></item><item><title>CamemBERT-bio: a Tasty French Language Model Better for your Health</title><link>http://arxiv.org/abs/2306.15550v2</link><description>Clinical data in hospitals are increasingly accessible for research throughclinical data warehouses, however these documents are unstructured. It istherefore necessary to extract information from medical reports to conductclinical studies. Transfer learning with BERT-like models such as CamemBERT hasallowed major advances, especially for named entity recognition. However, thesemodels are trained for plain language and are less efficient on biomedicaldata. This is why we propose a new French public biomedical dataset on which wehave continued the pre-training of CamemBERT. Thus, we introduce a firstversion of CamemBERT-bio, a specialized public model for the French biomedicaldomain that shows 2.54 points of F1 score improvement on average on differentbiomedical named entity recognition tasks. Our findings demonstrate the successof continual pre-training from a French model and contrast with recentproposals on the same domain and language. One of our key contributionshighlights the importance of using a standard evaluation protocol that enablesa clear view of the current state-of-the-art for French biomedical models.</description><author>Rian Touchent, Laurent Romary, Eric de la Clergerie</author><pubDate>Wed, 02 Aug 2023 18:53:45 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.15550v2</guid></item><item><title>Masked and Swapped Sequence Modeling for Next Novel Basket Recommendation in Grocery Shopping</title><link>http://arxiv.org/abs/2308.01308v1</link><description>Next basket recommendation (NBR) is the task of predicting the next set ofitems based on a sequence of already purchased baskets. It is a recommendationtask that has been widely studied, especially in the context of groceryshopping. In next basket recommendation (NBR), it is useful to distinguishbetween repeat items, i.e., items that a user has consumed before, and exploreitems, i.e., items that a user has not consumed before. Most NBR work eitherignores this distinction or focuses on repeat items. We formulate the nextnovel basket recommendation (NNBR) task, i.e., the task of recommending abasket that only consists of novel items, which is valuable for both real-worldapplication and NBR evaluation. We evaluate how existing NBR methods perform onthe NNBR task and find that, so far, limited progress has been made w.r.t. theNNBR task. To address the NNBR task, we propose a simple bi-directionaltransformer basket recommendation model (BTBR), which is focused on directlymodeling item-to-item correlations within and across baskets instead oflearning complex basket representations. To properly train BTBR, we propose andinvestigate several masking strategies and training objectives: (i) item-levelrandom masking, (ii) item-level select masking, (iii) basket-level all masking,(iv) basket-level explore masking, and (v) joint masking. In addition, anitem-basket swapping strategy is proposed to enrich the item interactionswithin the same baskets. We conduct extensive experiments on three opendatasets with various characteristics. The results demonstrate theeffectiveness of BTBR and our masking and swapping strategies for the NNBRtask. BTBR with a properly selected masking and swapping strategy cansubstantially improve NNBR performance.</description><author>Ming Li, Mozhdeh Ariannezhad, Andrew Yates, Maarten de Rijke</author><pubDate>Wed, 02 Aug 2023 18:52:37 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2308.01308v1</guid></item><item><title>Revisiting DETR Pre-training for Object Detection</title><link>http://arxiv.org/abs/2308.01300v1</link><description>Motivated by that DETR-based approaches have established new records on COCOdetection and segmentation benchmarks, many recent endeavors show increasinginterest in how to further improve DETR-based approaches by pre-training theTransformer in a self-supervised manner while keeping the backbone frozen. Somestudies already claimed significant improvements in accuracy. In this paper, wetake a closer look at their experimental methodology and check if theirapproaches are still effective on the very recent state-of-the-art such as$\mathcal{H}$-Deformable-DETR. We conduct thorough experiments on COCO objectdetection tasks to study the influence of the choice of pre-training datasets,localization, and classification target generation schemes. Unfortunately, wefind the previous representative self-supervised approach such as DETReg, failsto boost the performance of the strong DETR-based approaches on full dataregimes. We further analyze the reasons and find that simply combining a moreaccurate box predictor and Objects$365$ benchmark can significantly improve theresults in follow-up experiments. We demonstrate the effectiveness of ourapproach by achieving strong object detection results of AP=$59.3\%$ on COCOval set, which surpasses $\mathcal{H}$-Deformable-DETR + Swin-L by +$1.4\%$.Last, we generate a series of synthetic pre-training datasets by combining thevery recent image-to-text captioning models (LLaVA) and text-to-imagegenerative models (SDXL). Notably, pre-training on these synthetic datasetsleads to notable improvements in object detection performance. Looking ahead,we anticipate substantial advantages through the future expansion of thesynthetic pre-training dataset.</description><author>Yan Ma, Weicong Liang, Yiduo Hao, Bohan Chen, Xiangyu Yue, Chao Zhang, Yuhui Yuan</author><pubDate>Wed, 02 Aug 2023 18:39:30 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2308.01300v1</guid></item><item><title>Towards Detecting Harmful Agendas in News Articles</title><link>http://arxiv.org/abs/2302.00102v3</link><description>Manipulated news online is a growing problem which necessitates the use ofautomated systems to curtail its spread. We argue that while misinformation anddisinformation detection have been studied, there has been a lack of investmentin the important open challenge of detecting harmful agendas in news articles;identifying harmful agendas is critical to flag news campaigns with thegreatest potential for real world harm. Moreover, due to real concerns aroundcensorship, harmful agenda detectors must be interpretable to be effective. Inthis work, we propose this new task and release a dataset, NewsAgendas, ofannotated news articles for agenda identification. We show how interpretablesystems can be effective on this task and demonstrate that they can performcomparably to black-box models.</description><author>Melanie Subbiah, Amrita Bhattacharjee, Yilun Hua, Tharindu Kumarage, Huan Liu, Kathleen McKeown</author><pubDate>Wed, 02 Aug 2023 18:16:48 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2302.00102v3</guid></item><item><title>Flows: Building Blocks of Reasoning and Collaborating AI</title><link>http://arxiv.org/abs/2308.01285v1</link><description>Recent advances in artificial intelligence (AI) have produced highly capableand controllable systems. This creates unprecedented opportunities forstructured reasoning as well as collaboration among multiple AI systems andhumans. To fully realize this potential, it is essential to develop aprincipled way of designing and studying such structured interactions. For thispurpose, we introduce the conceptual framework of Flows: a systematic approachto modeling complex interactions. Flows are self-contained building blocks ofcomputation, with an isolated state, communicating through a standardizedmessage-based interface. This modular design allows Flows to be recursivelycomposed into arbitrarily nested interactions, with a substantial reduction ofcomplexity. Crucially, any interaction can be implemented using this framework,including prior work on AI--AI and human--AI interactions, prompt engineeringschemes, and tool augmentation. We demonstrate the potential of Flows on thetask of competitive coding, a challenging task on which even GPT-4 struggles.Our results suggest that structured reasoning and collaboration substantiallyimprove generalization, with AI-only Flows adding +$21$ and human--AI Flowsadding +$54$ absolute points in terms of solve rate. To support rapid andrigorous research, we introduce the aiFlows library. The library comes with arepository of Flows that can be easily used, extended, and composed into novel,more complex Flows. The aiFlows library is available at https://github.com/epfl-dlab/aiflows.Data and Flows for reproducing our experiments are available athttps://github.com/epfl-dlab/cc_flows.</description><author>Martin Josifoski, Lars Klein, Maxime Peyrard, Yifei Li, Saibo Geng, Julian Paul Schnitzler, Yuxing Yao, Jiheng Wei, Debjit Paul, Robert West</author><pubDate>Wed, 02 Aug 2023 18:14:22 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2308.01285v1</guid></item><item><title>Fighting Fire with Fire: Can ChatGPT Detect AI-generated Text?</title><link>http://arxiv.org/abs/2308.01284v1</link><description>Large language models (LLMs) such as ChatGPT are increasingly being used forvarious use cases, including text content generation at scale. Althoughdetection methods for such AI-generated text exist already, we investigateChatGPT's performance as a detector on such AI-generated text, inspired byworks that use ChatGPT as a data labeler or annotator. We evaluate thezero-shot performance of ChatGPT in the task of human-written vs. AI-generatedtext detection, and perform experiments on publicly available datasets. Weempirically investigate if ChatGPT is symmetrically effective in detectingAI-generated or human-written text. Our findings provide insight on how ChatGPTand similar LLMs may be leveraged in automated detection pipelines by simplyfocusing on solving a specific aspect of the problem and deriving the rest fromthat solution. All code and data is available at\url{https://github.com/AmritaBh/ChatGPT-as-Detector}.</description><author>Amrita Bhattacharjee, Huan Liu</author><pubDate>Wed, 02 Aug 2023 18:11:37 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2308.01284v1</guid></item><item><title>BRNES: Enabling Security and Privacy-aware Experience Sharing in Multiagent Robotic and Autonomous Systems</title><link>http://arxiv.org/abs/2308.01274v1</link><description>Although experience sharing (ES) accelerates multiagent reinforcementlearning (MARL) in an advisor-advisee framework, attempts to apply ES todecentralized multiagent systems have so far relied on trusted environments andoverlooked the possibility of adversarial manipulation and inference.Nevertheless, in a real-world setting, some Byzantine attackers, disguised asadvisors, may provide false advice to the advisee and catastrophically degradethe overall learning performance. Also, an inference attacker, disguised as anadvisee, may conduct several queries to infer the advisors' private informationand make the entire ES process questionable in terms of privacy leakage. Toaddress and tackle these issues, we propose a novel MARL framework (BRNES) thatheuristically selects a dynamic neighbor zone for each advisee at each learningstep and adopts a weighted experience aggregation technique to reduce Byzantineattack impact. Furthermore, to keep the agent's private information safe fromadversarial inference attacks, we leverage the local differential privacy(LDP)-induced noise during the ES process. Our experiments show that ourframework outperforms the state-of-the-art in terms of the steps to goal,obtained reward, and time to goal metrics. Particularly, our evaluation showsthat the proposed framework is 8.32x faster than the current non-privateframeworks and 1.41x faster than the private frameworks in an adversarialsetting.</description><author>Md Tamjid Hossain, Hung Manh La, Shahriar Badsha, Anton Netchaev</author><pubDate>Wed, 02 Aug 2023 17:57:19 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2308.01274v1</guid></item><item><title>Knowing When to Stop: Delay-Adaptive Spiking Neural Network Classifiers with Reliability Guarantees</title><link>http://arxiv.org/abs/2305.11322v2</link><description>Spiking neural networks (SNNs) process time-series data via internalevent-driven neural dynamics whose energy consumption depends on the number ofspikes exchanged between neurons over the course of the input presentation.Typically, decisions are produced after the entire input sequence has beenprocessed, resulting in latency and energy consumption levels that are fairlyuniform across inputs. However, as explored in recent work, SNNs can produce anearly decision when the SNN model is sufficiently ``confident'', adapting delayand energy consumption to the difficulty of each example. Existing techniquesare based on heuristic measures of confidence that do not provide reliabilityguarantees, potentially exiting too early. In this paper, we introduce a noveldelay-adaptive SNN-based inference methodology that, wrapping around anypre-trained SNN classifier, provides guaranteed reliability for the decisionsproduced at input-dependent stopping times. The approach, dubbed SpikeCP,leverages tools from conformal prediction (CP), and it entails minimalcomplexity increase as compared to the underlying SNN, requiring onlyadditional thresholding and counting operations at run time. SpikeCP is alsoextended to integrate a CP-aware training phase that targets delay performance.Variants of CP based on alternative confidence correction schemes, fromBonferroni to Simes, are explored, and extensive experiments are describedusing the MNIST-DVS data set.</description><author>Jiechen Chen, Sangwoo Park, Osvaldo Simeone</author><pubDate>Wed, 02 Aug 2023 17:56:50 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.11322v2</guid></item><item><title>Sampling binary sparse coding QUBO models using a spiking neuromorphic processor</title><link>http://arxiv.org/abs/2306.01940v2</link><description>We consider the problem of computing a sparse binary representation of animage. To be precise, given an image and an overcomplete, non-orthonormalbasis, we aim to find a sparse binary vector indicating the minimal set ofbasis vectors that when added together best reconstruct the given input. Weformulate this problem with an $L_2$ loss on the reconstruction error, and an$L_0$ (or, equivalently, an $L_1$) loss on the binary vector enforcingsparsity. This yields a so-called Quadratic Unconstrained Binary Optimization(QUBO) problem, whose solution is generally NP-hard to find. The contributionof this work is twofold. First, the method of unsupervised and unnormalizeddictionary feature learning for a desired sparsity level to best match the datais presented. Second, the binary sparse coding problem is then solved on theLoihi 1 neuromorphic chip by the use of stochastic networks of neurons totraverse the non-convex energy landscape. The solutions are benchmarked againstthe classical heuristic simulated annealing. We demonstrate neuromorphiccomputing is suitable for sampling low energy solutions of binary sparse codingQUBO models, and although Loihi 1 is capable of sampling very sparse solutionsof the QUBO models, there needs to be improvement in the implementation inorder to be competitive with simulated annealing.</description><author>Kyle Henke, Elijah Pelofske, Georg Hahn, Garrett T. Kenyon</author><pubDate>Wed, 02 Aug 2023 17:55:29 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.01940v2</guid></item><item><title>A Probabilistic Approach to Self-Supervised Learning using Cyclical Stochastic Gradient MCMC</title><link>http://arxiv.org/abs/2308.01271v1</link><description>In this paper we present a practical Bayesian self-supervised learning methodwith Cyclical Stochastic Gradient Hamiltonian Monte Carlo (cSGHMC). Within thisframework, we place a prior over the parameters of a self-supervised learningmodel and use cSGHMC to approximate the high dimensional and multimodalposterior distribution over the embeddings. By exploring an expressiveposterior over the embeddings, Bayesian self-supervised learning producesinterpretable and diverse representations. Marginalizing over theserepresentations yields a significant gain in performance, calibration andout-of-distribution detection on a variety of downstream classification tasks.We provide experimental results on multiple classification tasks on fourchallenging datasets. Moreover, we demonstrate the effectiveness of theproposed method in out-of-distribution detection using the SVHN and CIFAR-10datasets.</description><author>Masoumeh Javanbakhat, Christoph Lippert</author><pubDate>Wed, 02 Aug 2023 17:52:56 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2308.01271v1</guid></item><item><title>Domain-adapted Learning and Imitation: DRL for Power Arbitrage</title><link>http://arxiv.org/abs/2301.08360v2</link><description>In this paper, we discuss the Dutch power market, which is comprised of aday-ahead market and an intraday balancing market that operates like anauction. Due to fluctuations in power supply and demand, there is often animbalance that leads to different prices in the two markets, providing anopportunity for arbitrage. To address this issue, we restructure the problemand propose a collaborative dual-agent reinforcement learning approach for thisbi-level simulation and optimization of European power arbitrage trading. Wealso introduce two new implementations designed to incorporate domain-specificknowledge by imitating the trading behaviours of power traders. By utilizingreward engineering to imitate domain expertise, we are able to reform thereward system for the RL agent, which improves convergence during training andenhances overall performance. Additionally, the tranching of orders increasesbidding success rates and significantly boosts profit and loss (P&amp;L). Our studydemonstrates that by leveraging domain expertise in a general learning problem,the performance can be improved substantially, and the final integratedapproach leads to a three-fold improvement in cumulative P&amp;L compared to theoriginal agent. Furthermore, our methodology outperforms the highest benchmarkpolicy by around 50% while maintaining efficient computational performance.</description><author>Yuanrong Wang, Vignesh Raja Swaminathan, Nikita P. Granger, Carlos Ros Perez, Christian Michler</author><pubDate>Wed, 02 Aug 2023 17:49:37 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2301.08360v2</guid></item><item><title>Exploring the psychology of GPT-4's Moral and Legal Reasoning</title><link>http://arxiv.org/abs/2308.01264v1</link><description>Large language models have been used as the foundation of highlysophisticated artificial intelligences, capable of delivering human-likeresponses to probes about legal and moral issues. However, these models areunreliable guides to their own inner workings, and even the engineering teamsbehind their creation are unable to explain exactly how they came to developall of the capabilities they currently have. The emerging field of machinepsychology seeks to gain insight into the processes and concepts that thesemodels possess. In this paper, we employ the methods of psychology to probeinto GPT-4's moral and legal reasoning. More specifically, we investigate thesimilarities and differences between GPT-4 and humans when it comes tointentionality ascriptions, judgments about causation, the morality ofdeception, moral foundations, the impact of moral luck on legal judgments, theconcept of consent, and rule violation judgments. We find high correlationsbetween human and AI responses, but also several significant systematicdifferences between them. We conclude with a discussion of the philosophicalimplications of our findings.</description><author>Guilherme F. C. F. Almeida, José Luiz Nunes, Neele Engelmann, Alex Wiegmann, Marcelo de Araújo</author><pubDate>Wed, 02 Aug 2023 17:36:58 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2308.01264v1</guid></item><item><title>XSTest: A Test Suite for Identifying Exaggerated Safety Behaviours in Large Language Models</title><link>http://arxiv.org/abs/2308.01263v1</link><description>Without proper safeguards, large language models will readily followmalicious instructions and generate toxic content. This motivates safetyefforts such as red-teaming and large-scale feedback learning, which aim tomake models both helpful and harmless. However, there is a tension betweenthese two objectives, since harmlessness requires models to refuse complyingwith unsafe prompts, and thus not be helpful. Recent anecdotal evidencesuggests that some models may have struck a poor balance, so that even clearlysafe prompts are refused if they use similar language to unsafe prompts ormention sensitive topics. In this paper, we introduce a new test suite calledXSTest to identify such eXaggerated Safety behaviours in a structured andsystematic way. In its current form, XSTest comprises 200 safe prompts acrossten prompt types that well-calibrated models should not refuse to comply with.We describe XSTest's creation and composition, and use the test suite tohighlight systematic failure modes in a recently-released state-of-the-artlanguage model.</description><author>Paul Röttger, Hannah Rose Kirk, Bertie Vidgen, Giuseppe Attanasio, Federico Bianchi, Dirk Hovy</author><pubDate>Wed, 02 Aug 2023 17:30:40 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2308.01263v1</guid></item><item><title>Incorporating Season and Solar Specificity into Renderings made by a NeRF Architecture using Satellite Images</title><link>http://arxiv.org/abs/2308.01262v1</link><description>As a result of Shadow NeRF and Sat-NeRF, it is possible to take the solarangle into account in a NeRF-based framework for rendering a scene from a novelviewpoint using satellite images for training. Our work extends thosecontributions and shows how one can make the renderings season-specific. Ourmain challenge was creating a Neural Radiance Field (NeRF) that could renderseasonal features independently of viewing angle and solar angle while stillbeing able to render shadows. We teach our network to render seasonal featuresby introducing one more input variable -- time of the year. However, the smalltraining datasets typical of satellite imagery can introduce ambiguities incases where shadows are present in the same location for every image of aparticular season. We add additional terms to the loss function to discouragethe network from using seasonal features for accounting for shadows. We showthe performance of our network on eight Areas of Interest containing imagescaptured by the Maxar WorldView-3 satellite. This evaluation includes testsmeasuring the ability of our framework to accurately render novel views,generate height maps, predict shadows, and specify seasonal featuresindependently from shadows. Our ablation studies justify the choices made fornetwork design parameters.</description><author>Michael Gableman, Avinash Kak</author><pubDate>Wed, 02 Aug 2023 17:30:18 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2308.01262v1</guid></item><item><title>Fabricated Flips: Poisoning Federated Learning without Data</title><link>http://arxiv.org/abs/2202.05877v2</link><description>Attacks on Federated Learning (FL) can severely reduce the quality of thegenerated models and limit the usefulness of this emerging learning paradigmthat enables on-premise decentralized learning. However, existing untargetedattacks are not practical for many scenarios as they assume that i) theattacker knows every update of benign clients, or ii) the attacker has a largedataset to locally train updates imitating benign parties. In this paper, wepropose a data-free untargeted attack (DFA) that synthesizes malicious data tocraft adversarial models without eavesdropping on the transmission of benignclients at all or requiring a large quantity of task-specific training data. Wedesign two variants of DFA, namely DFA-R and DFA-G, which differ in how theytrade off stealthiness and effectiveness. Specifically, DFA-R iterativelyoptimizes a malicious data layer to minimize the prediction confidence of alloutputs of the global model, whereas DFA-G interactively trains a maliciousdata generator network by steering the output of the global model toward aparticular class. Experimental results on Fashion-MNIST, Cifar-10, and SVHNshow that DFA, despite requiring fewer assumptions than existing attacks,achieves similar or even higher attack success rate than state-of-the-artuntargeted attacks against various state-of-the-art defense mechanisms.Concretely, they can evade all considered defense mechanisms in at least 50% ofthe cases for CIFAR-10 and often reduce the accuracy by more than a factor of2. Consequently, we design REFD, a defense specifically crafted to protectagainst data-free attacks. REFD leverages a reference dataset to detect updatesthat are biased or have a low confidence. It greatly improves upon existingdefenses by filtering out the malicious updates and achieves high global modelaccuracy</description><author>Jiyue Huang, Zilong Zhao, Lydia Y. Chen, Stefanie Roos</author><pubDate>Wed, 02 Aug 2023 17:27:26 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2202.05877v2</guid></item><item><title>Learning Spatial Distribution of Long-Term Trackers Scores</title><link>http://arxiv.org/abs/2308.01256v1</link><description>Long-Term tracking is a hot topic in Computer Vision. In this context,competitive models are presented every year, showing a constant growth rate inperformances, mainly measured in standardized protocols as Visual ObjectTracking (VOT) and Object Tracking Benchmark (OTB). Fusion-trackers strategyhas been applied over last few years for overcoming the known re-detectionproblem, turning out to be an important breakthrough. Following this approach,this work aims to generalize the fusion concept to an arbitrary number oftrackers used as baseline trackers in the pipeline, leveraging a learning phaseto better understand how outcomes correlate with each other, even when notarget is present. A model and data independence conjecture will be evidencedin the manuscript, yielding a recall of 0.738 on LTB-50 dataset when learningfrom VOT-LT2022, and 0.619 by reversing the two datasets. In both cases,results are strongly competitive with state-of-the-art and recall turns out tobe the first on the podium.</description><author>Vincenzo Mariano Scarrica, Antonino Staiano</author><pubDate>Wed, 02 Aug 2023 17:26:54 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2308.01256v1</guid></item><item><title>A Hyper-pixel-wise Contrastive Learning Augmented Segmentation Network for Old Landslide Detection Using High-Resolution Remote Sensing Images and Digital Elevation Model Data</title><link>http://arxiv.org/abs/2308.01251v1</link><description>As a harzard disaster, landslide often brings tremendous losses to humanity,so it's necessary to achieve reliable detection of landslide. However, theproblems of visual blur and small-sized dataset cause great challenges for oldlandslide detection task when using remote sensing data. To reliably extractsemantic features, a hyper-pixel-wise contrastive learning augmentedsegmentation network (HPCL-Net) is proposed, which augments the local salientfeature extraction from the boundaries of landslides through HPCL and fuses theheterogeneous infromation in the semantic space from High-Resolution RemoteSensing Images and Digital Elevation Model Data data. For full utilization ofthe precious samples, a global hyper-pixel-wise sample pair queues-basedcontrastive learning method, which includes the construction of global queuesthat store hyper-pixel-wise samples and the updating scheme of a momentumencoder, is developed, reliably enhancing the extraction ability of semanticfeatures. The proposed HPCL-Net is evaluated on a Loess Plateau old landslidedataset and experiment results show that the model greatly improves thereliablity of old landslide detection compared to the previous old landslidesegmentation model, where mIoU metric is increased from 0.620 to 0.651,Landslide IoU metric is increased from 0.334 to 0.394 and F1-score metric isincreased from 0.501 to 0.565.</description><author>Yiming Zhou, Yuexing Peng, Wei Li, Junchuan Yu, Daqing Ge, Wei Xiang</author><pubDate>Wed, 02 Aug 2023 17:11:51 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2308.01251v1</guid></item><item><title>InFusion: Inject and Attention Fusion for Multi Concept Zero Shot Text based Video Editing</title><link>http://arxiv.org/abs/2308.00135v2</link><description>Large text-to-image diffusion models have achieved remarkable success ingenerating diverse high-quality images in alignment with text prompt used forediting the input image. But, when these models applied to video the mainchallenge is to ensure temporal consistency and coherence across frames. Inthis paper, we proposed InFusion, a framework for zero-shot text-based videoediting leveraging large pre-trained image diffusion models. Our frameworkspecifically supports editing of multiple concepts with the pixel level controlover diverse concepts mentioned in the editing prompt. Specifically, we injectthe difference of features obtained with source and edit prompt from U-Netresidual blocks in decoder layers, this when combined with injected attentionfeatures make it feasible to query the source contents and scale editedconcepts along with the injection of unedited parts. The editing is furthercontrolled in fine-grained manner with mask extraction and attention fusionstrategy which cuts the edited part from source and paste it into the denoisingpipeline for editing prompt. Our framework is a low cost alternative ofone-shot tuned models for editing since it does not require training. Wedemonstrated the complex concept editing with generalised image model (StableDiffusion v1.5) using LoRA. Adaptation is compatible with all the existingimage diffusion techniques. Extensive experimental results demonstrate theeffectiveness over existing methods in rendering high-quality and temporallyconsistent videos.</description><author>Anant Khandelwal</author><pubDate>Wed, 02 Aug 2023 17:11:47 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2308.00135v2</guid></item><item><title>Q(D)O-ES: Population-based Quality (Diversity) Optimisation for Post Hoc Ensemble Selection in AutoML</title><link>http://arxiv.org/abs/2307.08364v2</link><description>Automated machine learning (AutoML) systems commonly ensemble models post hocto improve predictive performance, typically via greedy ensemble selection(GES). However, we believe that GES may not always be optimal, as it performs asimple deterministic greedy search. In this work, we introduce two novelpopulation-based ensemble selection methods, QO-ES and QDO-ES, and compare themto GES. While QO-ES optimises solely for predictive performance, QDO-ES alsoconsiders the diversity of ensembles within the population, maintaining adiverse set of well-performing ensembles during optimisation based on ideas ofquality diversity optimisation. The methods are evaluated using 71classification datasets from the AutoML benchmark, demonstrating that QO-ES andQDO-ES often outrank GES, albeit only statistically significant on validationdata. Our results further suggest that diversity can be beneficial for post hocensembling but also increases the risk of overfitting.</description><author>Lennart Purucker, Lennart Schneider, Marie Anastacio, Joeran Beel, Bernd Bischl, Holger Hoos</author><pubDate>Wed, 02 Aug 2023 17:09:56 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.08364v2</guid></item><item><title>Automated wildlife image classification: An active learning tool for ecological applications</title><link>http://arxiv.org/abs/2303.15823v3</link><description>Wildlife camera trap images are being used extensively to investigate animalabundance, habitat associations, and behavior, which is complicated by the factthat experts must first classify the images manually. Artificial intelligencesystems can take over this task but usually need a large number ofalready-labeled training images to achieve sufficient performance. Thisrequirement necessitates human expert labor and poses a particular challengefor projects with few cameras or short durations. We propose a label-efficientlearning strategy that enables researchers with small or medium-sized imagedatabases to leverage the potential of modern machine learning, thus freeingcrucial resources for subsequent analyses. Our methodological proposal is two-fold: (1) We improve current strategies ofcombining object detection and image classification by tuning thehyperparameters of both models. (2) We provide an active learning (AL) systemthat allows training deep learning models very efficiently in terms of requiredhuman-labeled training images. We supply a software package that enablesresearchers to use these methods directly and thereby ensure the broadapplicability of the proposed framework in ecological practice. We show that our tuning strategy improves predictive performance. Wedemonstrate how the AL pipeline reduces the amount of pre-labeled data neededto achieve a specific predictive performance and that it is especially valuablefor improving out-of-sample predictive performance. We conclude that the combination of tuning and AL increases predictiveperformance substantially. Furthermore, we argue that our work can broadlyimpact the community through the ready-to-use software package provided.Finally, the publication of our models tailored to European wildlife dataenriches existing model bases mostly trained on data from Africa and NorthAmerica.</description><author>Ludwig Bothmann, Lisa Wimmer, Omid Charrakh, Tobias Weber, Hendrik Edelhoff, Wibke Peters, Hien Nguyen, Caryl Benjamin, Annette Menzel</author><pubDate>Wed, 02 Aug 2023 17:04:47 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2303.15823v3</guid></item><item><title>A Hybrid Approach To Real-Time Multi-Object Tracking</title><link>http://arxiv.org/abs/2308.01248v1</link><description>Multi-Object Tracking, also known as Multi-Target Tracking, is a significantarea of computer vision that has many uses in a variety of settings. Thedevelopment of deep learning, which has encouraged researchers to propose moreand more work in this direction, has significantly impacted the scientificadvancement around the study of tracking as well as many other domains relatedto computer vision. In fact, all of the solutions that are currentlystate-of-the-art in the literature and in the tracking industry, are built ontop of deep learning methodologies that produce exceptionally good results.Deep learning is enabled thanks to the ever more powerful technologyresearchers can use to handle the significant computational resources demandedby these models. However, when real-time is a main requirement, developing atracking system without being constrained by expensive hardware support withenormous computational resources is necessary to widen tracking applications inreal-world contexts. To this end, a compromise is to combine powerful deepstrategies with more traditional approaches to favor considerably lowerprocessing solutions at the cost of less accurate tracking results even thoughsuitable for real-time domains. Indeed, the present work goes in thatdirection, proposing a hybrid strategy for real-time multi-target tracking thatcombines effectively a classical optical flow algorithm with a deep learningarchitecture, targeted to a human-crowd tracking system exhibiting a desirabletrade-off between performance in tracking precision and computational costs.The developed architecture was experimented with different settings, andyielded a MOTA of 0.608 out of the compared state-of-the-art 0.549 results, andabout half the running time when introducing the optical flow phase, achievingalmost the same performance in terms of accuracy.</description><author>Vincenzo Mariano Scarrica, Ciro Panariello, Alessio Ferone, Antonino Staiano</author><pubDate>Wed, 02 Aug 2023 17:02:42 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2308.01248v1</guid></item><item><title>Tirtha -- An Automated Platform to Crowdsource Images and Create 3D Models of Heritage Sites</title><link>http://arxiv.org/abs/2308.01246v1</link><description>Digital preservation of Cultural Heritage (CH) sites is crucial to protectthem against damage from natural disasters or human activities. Creating 3Dmodels of CH sites has become a popular method of digital preservation thanksto advancements in computer vision and photogrammetry. However, the process istime-consuming, expensive, and typically requires specialized equipment andexpertise, posing challenges in resource-limited developing countries.Additionally, the lack of an open repository for 3D models hinders research andpublic engagement with their heritage. To address these issues, we proposeTirtha, a web platform for crowdsourcing images of CH sites and creating their3D models. Tirtha utilizes state-of-the-art Structure from Motion (SfM) andMulti-View Stereo (MVS) techniques. It is modular, extensible andcost-effective, allowing for the incorporation of new techniques asphotogrammetry advances. Tirtha is accessible through a web interface athttps://tirtha.niser.ac.in and can be deployed on-premise or in a cloudenvironment. In our case studies, we demonstrate the pipeline's effectivenessby creating 3D models of temples in Odisha, India, using crowdsourced images.These models are available for viewing, interaction, and download on the Tirthawebsite. Our work aims to provide a dataset of crowdsourced images and 3Dreconstructions for research in computer vision, heritage conservation, andrelated domains. Overall, Tirtha is a step towards democratizing digitalpreservation, primarily in resource-limited developing countries.</description><author>Jyotirmaya Shivottam, Subhankar Mishra</author><pubDate>Wed, 02 Aug 2023 17:00:39 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2308.01246v1</guid></item><item><title>Bandit based centralized matching in two-sided markets for peer to peer lending</title><link>http://arxiv.org/abs/2105.02589v2</link><description>Sequential fundraising in two sided online platforms enable peer to peerlending by sequentially bringing potential contributors, each of whosedecisions impact other contributors in the market. However, understanding thedynamics of sequential contributions in online platforms for peer lending hasbeen an open ended research question. The centralized investment mechanism inthese platforms makes it difficult to understand the implicit competition thatborrowers face from a single lender at any point in time. Matching markets area model of pairing agents where the preferences of agents from both sides interms of their preferred pairing for transactions can allow to decentralize themarket. We study investment designs in two sided platforms using matchingmarkets when the investors or lenders also face restrictions on the investmentsbased on borrower preferences. This situation creates an implicit competitionamong the lenders in addition to the existing borrower competition, especiallywhen the lenders are uncertain about their standing in the market and therebythe probability of their investments being accepted or the borrower loanrequests for projects reaching the reserve price. We devise a technique basedon sequential decision making that allows the lenders to adjust their choicesbased on the dynamics of uncertainty from competition over time. We simulatetwo sided market matchings in a sequential decision framework and show thedynamics of the lender regret amassed compared to the optimal borrower-lendermatching and find that the lender regret depends on the initial preferences setby the lenders which could affect their learning over decision making steps.</description><author>Soumajyoti Sarkar</author><pubDate>Wed, 02 Aug 2023 16:57:02 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2105.02589v2</guid></item><item><title>Digital Twin Brain: a simulation and assimilation platform for whole human brain</title><link>http://arxiv.org/abs/2308.01241v1</link><description>In this work, we present a computing platform named digital twin brain (DTB)that can simulate spiking neuronal networks of the whole human brain scale andmore importantly, a personalized biological brain structure. In comparison tomost brain simulations with a homogeneous global structure, we highlight thatthe sparseness, couplingness and heterogeneity in the sMRI, DTI and PET data ofthe brain has an essential impact on the efficiency of brain simulation, whichis proved from the scaling experiments that the DTB of human brain simulationis communication-intensive and memory-access intensive computing systems ratherthan computation-intensive. We utilize a number of optimization techniques tobalance and integrate the computation loads and communication traffics from theheterogeneous biological structure to the general GPU-based HPC and achieveleading simulation performance for the whole human brain-scaled spikingneuronal networks. On the other hand, the biological structure, equipped with amesoscopic data assimilation, enables the DTB to investigate brain cognitivefunction by a reverse-engineering method, which is demonstrated by a digitalexperiment of visual evaluation on the DTB. Furthermore, we believe that thedeveloping DTB will be a promising powerful platform for a large of researchorients including brain-inspiredintelligence, rain disease medicine andbrain-machine interface.</description><author>Wenlian Lu, Longbin Zeng, Xin Du, Wenyong Zhang, Shitong Xiang, Huarui Wang, Jiexiang Wang, Mingda Ji, Yubo Hou, Minglong Wang, Yuhao Liu, Zhongyu Chen, Qibao Zheng, Ningsheng Xu, Jianfeng Feng</author><pubDate>Wed, 02 Aug 2023 16:56:43 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2308.01241v1</guid></item><item><title>Evaluating Instruction-Tuned Large Language Models on Code Comprehension and Generation</title><link>http://arxiv.org/abs/2308.01240v1</link><description>In this work, we evaluate 10 open-source instructed LLMs on fourrepresentative code comprehension and generation tasks. We have the followingmain findings. First, for the zero-shot setting, instructed LLMs are verycompetitive on code comprehension and generation tasks and sometimes evenbetter than small SOTA models specifically fine-tuned on each downstream task.We also find that larger instructed LLMs are not always better on code-relatedtasks. Second, for the few-shot setting, we find that adding demonstrationexamples substantially helps instructed LLMs perform better on most codecomprehension and generation tasks; however, the examples would sometimesinduce unstable or even worse performance. Furthermore, we find widely-usedBM25-based shot selection strategy significantly outperforms the basic randomselection or fixed selection only on generation problems. Third, for thefine-tuning setting, we find that fine-tuning could further improve the modelperformance on downstream code comprehension and generation tasks compared tothe zero-shot/one-shot performance. In addition, after being fine-tuned on thesame downstream task dataset, instructed LLMs outperform both the small SOTAmodels and similar-scaled LLMs without instruction tuning. Based on ourfindings, we further present practical implications on model and usagerecommendation, performance and cost trade-offs, and future direction.</description><author>Zhiqiang Yuan, Junwei Liu, Qiancheng Zi, Mingwei Liu, Xin Peng, Yiling Lou</author><pubDate>Wed, 02 Aug 2023 16:54:22 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2308.01240v1</guid></item><item><title>CMUNeXt: An Efficient Medical Image Segmentation Network based on Large Kernel and Skip Fusion</title><link>http://arxiv.org/abs/2308.01239v1</link><description>The U-shaped architecture has emerged as a crucial paradigm in the design ofmedical image segmentation networks. However, due to the inherent locallimitations of convolution, a fully convolutional segmentation network withU-shaped architecture struggles to effectively extract global contextinformation, which is vital for the precise localization of lesions. Whilehybrid architectures combining CNNs and Transformers can address these issues,their application in real medical scenarios is limited due to the computationalresource constraints imposed by the environment and edge devices. In addition,the convolutional inductive bias in lightweight networks adeptly fits thescarce medical data, which is lacking in the Transformer based network. Inorder to extract global context information while taking advantage of theinductive bias, we propose CMUNeXt, an efficient fully convolutionallightweight medical image segmentation network, which enables fast and accurateauxiliary diagnosis in real scene scenarios. CMUNeXt leverages large kernel andinverted bottleneck design to thoroughly mix distant spatial and locationinformation, efficiently extracting global context information. We alsointroduce the Skip-Fusion block, designed to enable smooth skip-connections andensure ample feature fusion. Experimental results on multiple medical imagedatasets demonstrate that CMUNeXt outperforms existing heavyweight andlightweight medical image segmentation networks in terms of segmentationperformance, while offering a faster inference speed, lighter weights, and areduced computational cost. The code is available athttps://github.com/FengheTan9/CMUNeXt.</description><author>Fenghe Tang, Jianrui Ding, Lingtao Wang, Chunping Ning, S. Kevin Zhou</author><pubDate>Wed, 02 Aug 2023 16:54:00 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2308.01239v1</guid></item><item><title>Grounded Image Text Matching with Mismatched Relation Reasoning</title><link>http://arxiv.org/abs/2308.01236v1</link><description>This paper introduces Grounded Image Text Matching with Mismatched Relation(GITM-MR), a novel visual-linguistic joint task that evaluates the relationunderstanding capabilities of transformer-based pre-trained models. GITM-MRrequires a model to first determine if an expression describes an image, thenlocalize referred objects or ground the mismatched parts of the text. Weprovide a benchmark for evaluating pre-trained models on this task, with afocus on the challenging settings of limited data and out-of-distributionsentence lengths. Our evaluation demonstrates that pre-trained models lack dataefficiency and length generalization ability. To address this, we propose theRelation-sensitive Correspondence Reasoning Network (RCRN), which incorporatesrelation-aware reasoning via bi-directional message propagation guided bylanguage structure. RCRN can be interpreted as a modular program and deliversstrong performance in both length generalization and data efficiency.</description><author>Yu Wu, Yana Wei, Haozhe Wang, Yongfei Liu, Sibei Yang, Xuming He</author><pubDate>Wed, 02 Aug 2023 16:44:36 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2308.01236v1</guid></item><item><title>Evolutionary Augmentation Policy Optimization for Self-supervised Learning</title><link>http://arxiv.org/abs/2303.01584v2</link><description>Self-supervised Learning (SSL) is a machine learning algorithm forpretraining Deep Neural Networks (DNNs) without requiring manually labeleddata. The central idea of this learning technique is based on an auxiliarystage aka pretext task in which labeled data are created automatically throughdata augmentation and exploited for pretraining the DNN. However, the effect ofeach pretext task is not well studied or compared in the literature. In thispaper, we study the contribution of augmentation operators on the performanceof self supervised learning algorithms in a constrained settings. We propose anevolutionary search method for optimization of data augmentation pipeline inpretext tasks and measure the impact of augmentation operators in several SOTASSL algorithms. By encoding different combination of augmentation operators inchromosomes we seek the optimal augmentation policies through an evolutionaryoptimization mechanism. We further introduce methods for analyzing andexplaining the performance of optimized SSL algorithms. Our results indicatethat our proposed method can find solutions that outperform the accuracy ofclassification of SSL algorithms which confirms the influence of augmentationpolicy choice on the overall performance of SSL algorithms. We also compareoptimal SSL solutions found by our evolutionary search mechanism and show theeffect of batch size in the pretext task on two visual datasets.</description><author>Noah Barrett, Zahra Sadeghi, Stan Matwin</author><pubDate>Wed, 02 Aug 2023 16:38:37 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2303.01584v2</guid></item><item><title>Do Multilingual Language Models Think Better in English?</title><link>http://arxiv.org/abs/2308.01223v1</link><description>Translate-test is a popular technique to improve the performance ofmultilingual language models. This approach works by translating the input intoEnglish using an external machine translation system, and running inferenceover the translated input. However, these improvements can be attributed to theuse of a separate translation system, which is typically trained on largeamounts of parallel data not seen by the language model. In this work, weintroduce a new approach called self-translate, which overcomes the need of anexternal translation system by leveraging the few-shot translation capabilitiesof multilingual language models. Experiments over 5 tasks show thatself-translate consistently outperforms direct inference, demonstrating thatlanguage models are unable to leverage their full multilingual potential whenprompted in non-English languages. Our code is available athttps://github.com/juletx/self-translate.</description><author>Julen Etxaniz, Gorka Azkune, Aitor Soroa, Oier Lopez de Lacalle, Mikel Artetxe</author><pubDate>Wed, 02 Aug 2023 16:29:22 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2308.01223v1</guid></item><item><title>Calibration in Deep Learning: A Survey of the State-of-the-Art</title><link>http://arxiv.org/abs/2308.01222v1</link><description>Calibrating deep neural models plays an important role in building reliable,robust AI systems in safety-critical applications. Recent work has shown thatmodern neural networks that possess high predictive capability are poorlycalibrated and produce unreliable model predictions. Though deep learningmodels achieve remarkable performance on various benchmarks, the study of modelcalibration and reliability is relatively underexplored. Ideal deep modelsshould have not only high predictive performance but also be well calibrated.There have been some recent methods proposed to calibrate deep models by usingdifferent mechanisms. In this survey, we review the state-of-the-artcalibration methods and provide an understanding of their principles forperforming model calibration. First, we start with the definition of modelcalibration and explain the root causes of model miscalibration. Then weintroduce the key metrics that can measure this aspect. It is followed by asummary of calibration methods that we roughly classified into four categories:post-hoc calibration, regularization methods, uncertainty estimation, andcomposition methods. We also covered some recent advancements in calibratinglarge models, particularly large language models (LLMs). Finally, we discusssome open issues, challenges, and potential directions.</description><author>Cheng Wang</author><pubDate>Wed, 02 Aug 2023 16:28:10 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2308.01222v1</guid></item><item><title>Using ScrutinAI for Visual Inspection of DNN Performance in a Medical Use Case</title><link>http://arxiv.org/abs/2308.01220v1</link><description>Our Visual Analytics (VA) tool ScrutinAI supports human analysts toinvestigate interactively model performanceand data sets. Model performancedepends on labeling quality to a large extent. In particular in medicalsettings, generation of high quality labels requires in depth expert knowledgeand is very costly. Often, data sets are labeled by collecting opinions ofgroups of experts. We use our VA tool to analyse the influence of labelvariations between different experts on the model performance. ScrutinAIfacilitates to perform a root cause analysis that distinguishes weaknesses ofdeep neural network (DNN) models caused by varying or missing labeling qualityfrom true weaknesses. We scrutinize the overall detection of intracranialhemorrhages and the more subtle differentiation between subtypes in a publiclyavailable data set.</description><author>Rebekka Görge, Elena Haedecke, Michael Mock</author><pubDate>Wed, 02 Aug 2023 16:26:08 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2308.01220v1</guid></item><item><title>TeachCLIP: Multi-Grained Teaching for Efficient Text-to-Video Retrieval</title><link>http://arxiv.org/abs/2308.01217v1</link><description>For text-to-video retrieval (T2VR), which aims to retrieve unlabeled videosby ad-hoc textual queries, CLIP-based methods are dominating. Compared toCLIP4Clip which is efficient and compact, the state-of-the-art models tend tocompute video-text similarity by fine-grained cross-modal feature interactionand matching, putting their scalability for large-scale T2VR into doubt. Forefficient T2VR, we propose TeachCLIP with multi-grained teaching to let aCLIP4Clip based student network learn from more advanced yet computationallyheavy models such as X-CLIP, TS2-Net and X-Pool . To improve the student'slearning capability, we add an Attentional frame-Feature Aggregation (AFA)block, which by design adds no extra storage/computation overhead at theretrieval stage. While attentive weights produced by AFA are commonly used forcombining frame-level features, we propose a novel use of the weights to letthem imitate frame-text relevance estimated by the teacher network. As such,AFA provides a fine-grained learning (teaching) channel for the student(teacher). Extensive experiments on multiple public datasets justify theviability of the proposed method.</description><author>Kaibin Tian, Ruixiang Zhao, Hu Hu, Runquan Xie, Fengzong Lian, Zhanhui Kang, Xirong Li</author><pubDate>Wed, 02 Aug 2023 16:22:00 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2308.01217v1</guid></item><item><title>Embedding Capabilities of Neural ODEs</title><link>http://arxiv.org/abs/2308.01213v1</link><description>A class of neural networks that gained particular interest in the last yearsare neural ordinary differential equations (neural ODEs). We study input-outputrelations of neural ODEs using dynamical systems theory and prove severalresults about the exact embedding of maps in different neural ODE architecturesin low and high dimension. The embedding capability of a neural ODEarchitecture can be increased by adding, for example, a linear layer, oraugmenting the phase space. Yet, there is currently no systematic theoryavailable and our work contributes towards this goal by developing variousembedding results as well as identifying situations, where no embedding ispossible. The mathematical techniques used include as main components iterativefunctional equations, Morse functions and suspension flows, as well as severalfurther ideas from analysis. Although practically, mainly universalapproximation theorems are used, our geometric dynamical systems viewpoint onuniversal embedding provides a fundamental understanding, why certain neuralODE architectures perform better than others.</description><author>Christian Kuehn, Sara-Viola Kuntz</author><pubDate>Wed, 02 Aug 2023 16:16:34 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2308.01213v1</guid></item><item><title>Global Hierarchical Neural Networks using Hierarchical Softmax</title><link>http://arxiv.org/abs/2308.01210v1</link><description>This paper presents a framework in which hierarchical softmax is used tocreate a global hierarchical classifier. The approach is applicable for anyclassification task where there is a natural hierarchy among classes. We showempirical results on four text classification datasets. In all datasets thehierarchical softmax improved on the regular softmax used in a flat classifierin terms of macro-F1 and macro-recall. In three out of four datasetshierarchical softmax achieved a higher micro-accuracy and macro-precision.</description><author>Jetze Schuurmans, Flavius Frasincar</author><pubDate>Wed, 02 Aug 2023 16:12:56 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2308.01210v1</guid></item><item><title>Improving Generalization in Visual Reinforcement Learning via Conflict-aware Gradient Agreement Augmentation</title><link>http://arxiv.org/abs/2308.01194v1</link><description>Learning a policy with great generalization to unseen environments remainschallenging but critical in visual reinforcement learning. Despite the successof augmentation combination in the supervised learning generalization, naivelyapplying it to visual RL algorithms may damage the training efficiency,suffering from serve performance degradation. In this paper, we first conductqualitative analysis and illuminate the main causes: (i) high-variance gradientmagnitudes and (ii) gradient conflicts existed in various augmentation methods.To alleviate these issues, we propose a general policy gradient optimizationframework, named Conflict-aware Gradient Agreement Augmentation (CG2A), andbetter integrate augmentation combination into visual RL algorithms to addressthe generalization bias. In particular, CG2A develops a Gradient AgreementSolver to adaptively balance the varying gradient magnitudes, and introduces aSoft Gradient Surgery strategy to alleviate the gradient conflicts. Extensiveexperiments demonstrate that CG2A significantly improves the generalizationperformance and sample efficiency of visual RL algorithms.</description><author>Siao Liu, Zhaoyu Chen, Yang Liu, Yuzheng Wang, Dingkang Yang, Zhile Zhao, Ziqing Zhou, Xie Yi, Wei Li, Wenqiang Zhang, Zhongxue Gan</author><pubDate>Wed, 02 Aug 2023 16:03:41 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2308.01194v1</guid></item><item><title>Mercury: An Automated Remote Side-channel Attack to Nvidia Deep Learning Accelerator</title><link>http://arxiv.org/abs/2308.01193v1</link><description>DNN accelerators have been widely deployed in many scenarios to speed up theinference process and reduce the energy consumption. One big concern about theusage of the accelerators is the confidentiality of the deployed models: modelinference execution on the accelerators could leak side-channel information,which enables an adversary to preciously recover the model details. Such modelextraction attacks can not only compromise the intellectual property of DNNmodels, but also facilitate some adversarial attacks. Although previous works have demonstrated a number of side-channel techniquesto extract models from DNN accelerators, they are not practical for tworeasons. (1) They only target simplified accelerator implementations, whichhave limited practicality in the real world. (2) They require heavy humananalysis and domain knowledge. To overcome these limitations, this paperpresents Mercury, the first automated remote side-channel attack against theoff-the-shelf Nvidia DNN accelerator. The key insight of Mercury is to modelthe side-channel extraction process as a sequence-to-sequence problem. Theadversary can leverage a time-to-digital converter (TDC) to remotely collectthe power trace of the target model's inference. Then he uses a learning modelto automatically recover the architecture details of the victim model from thepower trace without any prior knowledge. The adversary can further use theattention mechanism to localize the leakage points that contribute most to theattack. Evaluation results indicate that Mercury can keep the error rate ofmodel extraction below 1%.</description><author>Xiaobei Yan, Xiaoxuan Lou, Guowen Xu, Han Qiu, Shangwei Guo, Chip Hong Chang, Tianwei Zhang</author><pubDate>Wed, 02 Aug 2023 16:02:35 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2308.01193v1</guid></item><item><title>Data-Centric Diet: Effective Multi-center Dataset Pruning for Medical Image Segmentation</title><link>http://arxiv.org/abs/2308.01189v1</link><description>This paper seeks to address the dense labeling problems where a significantfraction of the dataset can be pruned without sacrificing much accuracy. Weobserve that, on standard medical image segmentation benchmarks, the lossgradient norm-based metrics of individual training examples applied in imageclassification fail to identify the important samples. To address this issue,we propose a data pruning method by taking into consideration the trainingdynamics on target regions using Dynamic Average Dice (DAD) score. To the bestof our knowledge, we are among the first to address the data importance indense labeling tasks in the field of medical image analysis, making thefollowing contributions: (1) investigating the underlying causes with rigorousempirical analysis, and (2) determining effective data pruning approach indense labeling problems. Our solution can be used as a strong yet simplebaseline to select important examples for medical image segmentation withcombined data sources.</description><author>Yongkang He, Mingjin Chen, Zhijing Yang, Yongyi Lu</author><pubDate>Wed, 02 Aug 2023 15:53:43 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2308.01189v1</guid></item><item><title>Generative Noisy-Label Learning by Implicit Dicriminative Approximation with Partial Label Prior</title><link>http://arxiv.org/abs/2308.01184v1</link><description>The learning with noisy labels has been addressed with both discriminativeand generative models. Although discriminative models have dominated the fielddue to their simpler modeling and more efficient computational trainingprocesses, generative models offer a more effective means of disentanglingclean and noisy labels and improving the estimation of the label transitionmatrix. However, generative approaches maximize the joint likelihood of noisylabels and data using a complex formulation that only indirectly optimizes themodel of interest associating data and clean labels. Additionally, theseapproaches rely on generative models that are challenging to train and tend touse uninformative clean label priors. In this paper, we propose a newgenerative noisy-label learning approach that addresses these three issues.First, we propose a new model optimisation that directly associates data andclean labels. Second, the generative model is implicitly estimated using adiscriminative model, eliminating the inefficient training of a generativemodel. Third, we propose a new informative label prior inspired by partiallabel learning as supervision signal for noisy label learning. Extensiveexperiments on several noisy-label benchmarks demonstrate that our generativemodel provides state-of-the-art results while maintaining a similarcomputational complexity as discriminative models.</description><author>Fengbei Liu, Yuanhong Chen, Chong Wang, Yuyuan Liu, Gustavo Carneiro</author><pubDate>Wed, 02 Aug 2023 15:48:25 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2308.01184v1</guid></item><item><title>Interpretable End-to-End Driving Model for Implicit Scene Understanding</title><link>http://arxiv.org/abs/2308.01180v1</link><description>Driving scene understanding is to obtain comprehensive scene informationthrough the sensor data and provide a basis for downstream tasks, which isindispensable for the safety of self-driving vehicles. Specific perceptiontasks, such as object detection and scene graph generation, are commonly used.However, the results of these tasks are only equivalent to the characterizationof sampling from high-dimensional scene features, which are not sufficient torepresent the scenario. In addition, the goal of perception tasks isinconsistent with human driving that just focuses on what may affect theego-trajectory. Therefore, we propose an end-to-end Interpretable ImplicitDriving Scene Understanding (II-DSU) model to extract implicit high-dimensionalscene features as scene understanding results guided by a planning module andto validate the plausibility of scene understanding using auxiliary perceptiontasks for visualization. Experimental results on CARLA benchmarks show that ourapproach achieves the new state-of-the-art and is able to obtain scene featuresthat embody richer scene information relevant to driving, enabling superiorperformance of the downstream planning.</description><author>Yiyang Sun, Xiaonian Wang, Yangyang Zhang, Jiagui Tang, Xiaqiang Tang, Jing Yao</author><pubDate>Wed, 02 Aug 2023 15:43:08 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2308.01180v1</guid></item><item><title>MARIO: Model Agnostic Recipe for Improving OOD Generalization of Graph Contrastive Learning</title><link>http://arxiv.org/abs/2307.13055v3</link><description>In this work, we investigate the problem of out-of-distribution (OOD)generalization for unsupervised learning methods on graph data. This scenariois particularly challenging because graph neural networks (GNNs) have beenshown to be sensitive to distributional shifts, even when labels are available.To address this challenge, we propose a \underline{M}odel-\underline{A}gnostic\underline{R}ecipe for \underline{I}mproving \underline{O}OD generalizabilityof unsupervised graph contrastive learning methods, which we refer to as MARIO.MARIO introduces two principles aimed at developing distributional-shift-robustgraph contrastive methods to overcome the limitations of existing frameworks:(i) Information Bottleneck (IB) principle for achieving generalizablerepresentations and (ii) Invariant principle that incorporates adversarial dataaugmentation to obtain invariant representations. To the best of our knowledge,this is the first work that investigates the OOD generalization problem ofgraph contrastive learning, with a specific focus on node-level tasks. Throughextensive experiments, we demonstrate that our method achieves state-of-the-artperformance on the OOD test set, while maintaining comparable performance onthe in-distribution test set when compared to existing approaches. The sourcecode for our method can be found at: https://github.com/ZhuYun97/MARIO</description><author>Yun Zhu, Haizhou Shi, Zhenshuo Zhang, Siliang Tang</author><pubDate>Wed, 02 Aug 2023 15:30:57 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.13055v3</guid></item><item><title>Memory Encoding Model</title><link>http://arxiv.org/abs/2308.01175v1</link><description>We explore a new class of brain encoding model by adding memory-relatedinformation as input. Memory is an essential brain mechanism that worksalongside visual stimuli. During a vision-memory cognitive task, we found thenon-visual brain is largely predictable using previously seen images. OurMemory Encoding Model (Mem) won the Algonauts 2023 visual brain competitioneven without model ensemble (single model score 66.8, ensemble score 70.8). Ourensemble model without memory input (61.4) can also stand a 3rd place.Furthermore, we observe periodic delayed brain response correlated to 6th-7thprior image, and hippocampus also showed correlated activity timed with thisperiodicity. We conjuncture that the periodic replay could be related to memorymechanism to enhance the working memory.</description><author>Huzheng Yang, James Gee, Jianbo Shi</author><pubDate>Wed, 02 Aug 2023 15:29:10 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2308.01175v1</guid></item><item><title>3D-Aware Object Localization using Gaussian Implicit Occupancy Function</title><link>http://arxiv.org/abs/2303.02058v2</link><description>To automatically localize a target object in an image is crucial for manycomputer vision applications. To represent the 2D object, ellipse labels haverecently been identified as a promising alternative to axis-aligned boundingboxes. This paper further considers 3D-aware ellipse labels, \textit{i.e.},ellipses which are projections of a 3D ellipsoidal approximation of the object,for 2D target localization. Indeed, projected ellipses carry more geometricinformation about the object geometry and pose (3D awareness) than traditional3D-agnostic bounding box labels. Moreover, such a generic 3D ellipsoidal modelallows for approximating known to coarsely known targets. We then propose tohave a new look at ellipse regression and replace the discontinuous geometricellipse parameters with the parameters of an implicit Gaussian distributionencoding object occupancy in the image. The models are trained to regress thevalues of this bivariate Gaussian distribution over the image pixels using astatistical loss function. We introduce a novel non-trainable differentiablelayer, E-DSNT, to extract the distribution parameters. Also, we describe how toreadily generate consistent 3D-aware Gaussian occupancy parameters using onlycoarse dimensions of the target and relative pose labels. We extend threeexisting spacecraft pose estimation datasets with 3D-aware Gaussian occupancylabels to validate our hypothesis. Labels and source code are publiclyaccessible here: https://cvi2.uni.lu/3d-aware-obj-loc/.</description><author>Vincent Gaudillière, Leo Pauly, Arunkumar Rathinam, Albert Garcia Sanchez, Mohamed Adel Musallam, Djamila Aouada</author><pubDate>Wed, 02 Aug 2023 15:21:18 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2303.02058v2</guid></item><item><title>Direct Gradient Temporal Difference Learning</title><link>http://arxiv.org/abs/2308.01170v1</link><description>Off-policy learning enables a reinforcement learning (RL) agent to reasoncounterfactually about policies that are not executed and is one of the mostimportant ideas in RL. It, however, can lead to instability when combined withfunction approximation and bootstrapping, two arguably indispensableingredients for large-scale reinforcement learning. This is the notoriousdeadly triad. Gradient Temporal Difference (GTD) is one powerful tool to solvethe deadly triad. Its success results from solving a doubling sampling issueindirectly with weight duplication or Fenchel duality. In this paper, weinstead propose a direct method to solve the double sampling issue by simplyusing two samples in a Markovian data stream with an increasing gap. Theresulting algorithm is as computationally efficient as GTD but gets rid ofGTD's extra weights. The only price we pay is a logarithmically increasingmemory as time progresses. We provide both asymptotic and finite sampleanalysis, where the convergence rate is on-par with the canonical on-policytemporal difference learning. Key to our analysis is a novel refineddiscretization of limiting ODEs.</description><author>Xiaochi Qian, Shangtong Zhang</author><pubDate>Wed, 02 Aug 2023 15:16:22 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2308.01170v1</guid></item><item><title>Universal Adversarial Defense in Remote Sensing Based on Pre-trained Denoising Diffusion Models</title><link>http://arxiv.org/abs/2307.16865v2</link><description>Deep neural networks (DNNs) have achieved tremendous success in many remotesensing (RS) applications, in which DNNs are vulnerable to adversarialperturbations. Unfortunately, current adversarial defense approaches in RSstudies usually suffer from performance fluctuation and unnecessary re-trainingcosts due to the need for prior knowledge of the adversarial perturbationsamong RS data. To circumvent these challenges, we propose a universaladversarial defense approach in RS imagery (UAD-RS) using pre-trained diffusionmodels to defend the common DNNs against multiple unknown adversarial attacks.Specifically, the generative diffusion models are first pre-trained ondifferent RS datasets to learn generalized representations in various datadomains. After that, a universal adversarial purification framework isdeveloped using the forward and reverse process of the pre-trained diffusionmodels to purify the perturbations from adversarial samples. Furthermore, anadaptive noise level selection (ANLS) mechanism is built to capture the optimalnoise level of the diffusion model that can achieve the best purificationresults closest to the clean samples according to their Frechet InceptionDistance (FID) in deep feature space. As a result, only a single pre-traineddiffusion model is needed for the universal purification of adversarial sampleson each dataset, which significantly alleviates the re-training efforts andmaintains high performance without prior knowledge of the adversarialperturbations. Experiments on four heterogeneous RS datasets regarding sceneclassification and semantic segmentation verify that UAD-RS outperformsstate-of-the-art adversarial purification approaches with a universal defenseagainst seven commonly existing adversarial perturbations. Codes and thepre-trained models are available online (https://github.com/EricYu97/UAD-RS).</description><author>Weikang Yu, Yonghao Xu, Pedram Ghamisi</author><pubDate>Wed, 02 Aug 2023 15:02:35 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.16865v2</guid></item><item><title>LLMs Understand Glass-Box Models, Discover Surprises, and Suggest Repairs</title><link>http://arxiv.org/abs/2308.01157v1</link><description>We show that large language models (LLMs) are remarkably good at working withinterpretable models that decompose complex outcomes into univariategraph-represented components. By adopting a hierarchical approach to reasoning,LLMs can provide comprehensive model-level summaries without ever requiring theentire model to fit in context. This approach enables LLMs to apply theirextensive background knowledge to automate common tasks in data science such asdetecting anomalies that contradict prior knowledge, describing potentialreasons for the anomalies, and suggesting repairs that would remove theanomalies. We use multiple examples in healthcare to demonstrate the utility ofthese new capabilities of LLMs, with particular emphasis on GeneralizedAdditive Models (GAMs). Finally, we present the package $\texttt{TalkToEBM}$ asan open-source LLM-GAM interface.</description><author>Benjamin J. Lengerich, Sebastian Bordt, Harsha Nori, Mark E. Nunnally, Yin Aphinyanaphongs, Manolis Kellis, Rich Caruana</author><pubDate>Wed, 02 Aug 2023 14:59:35 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2308.01157v1</guid></item><item><title>Arithmetic with Language Models: from Memorization to Computation</title><link>http://arxiv.org/abs/2308.01154v1</link><description>A better understanding of the emergent computation and problem-solvingcapabilities of recent large language models is of paramount importance tofurther improve them and broaden their applicability. This work investigateshow a language model, trained to predict the next token, can perform arithmeticcomputations generalizing beyond training data. Binary addition andmultiplication constitute a good testbed for this purpose, since they require avery small vocabulary and exhibit relevant input/output discontinuities makingsmooth input interpolation ineffective for novel data. We successfully traineda light language model to learn these tasks and ran a number of experiments toinvestigate the extrapolation capabilities and internal information processing.Our findings support the hypotheses that the language model works as anEncoding-Regression-Decoding machine where the computation takes place in thevalue space once the input token representation is mapped to an appropriateinternal representation.</description><author>Davide Maltoni, Matteo Ferrara</author><pubDate>Wed, 02 Aug 2023 14:58:37 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2308.01154v1</guid></item><item><title>ZRIGF: An Innovative Multimodal Framework for Zero-Resource Image-Grounded Dialogue Generation</title><link>http://arxiv.org/abs/2308.00400v2</link><description>Image-grounded dialogue systems benefit greatly from integrating visualinformation, resulting in high-quality response generation. However, currentmodels struggle to effectively utilize such information in zero-resourcescenarios, mainly due to the disparity between image and text modalities. Toovercome this challenge, we propose an innovative multimodal framework, calledZRIGF, which assimilates image-grounded information for dialogue generation inzero-resource situations. ZRIGF implements a two-stage learning strategy,comprising contrastive pre-training and generative pre-training. Contrastivepre-training includes a text-image matching module that maps images and textsinto a unified encoded vector space, along with a text-assisted masked imagemodeling module that preserves pre-training visual features and fosters furthermultimodal feature alignment. Generative pre-training employs a multimodalfusion module and an information transfer module to produce insightfulresponses based on harmonized multimodal representations. Comprehensiveexperiments conducted on both text-based and image-grounded dialogue datasetsdemonstrate ZRIGF's efficacy in generating contextually pertinent andinformative responses. Furthermore, we adopt a fully zero-resource scenario inthe image-grounded dialogue dataset to demonstrate our framework's robustgeneralization capabilities in novel domains. The code is available athttps://github.com/zhangbo-nlp/ZRIGF.</description><author>Bo Zhang, Jian Wang, Hui Ma, Bo Xu, Hongfei Lin</author><pubDate>Wed, 02 Aug 2023 14:53:30 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2308.00400v2</guid></item><item><title>Instance-Dependent Generalization Bounds via Optimal Transport</title><link>http://arxiv.org/abs/2211.01258v3</link><description>Existing generalization bounds fail to explain crucial factors that drivegeneralization of modern neural networks. Since such bounds often holduniformly over all parameters, they suffer from over-parametrization, and failto account for the strong inductive bias of initialization and stochasticgradient descent. As an alternative, we propose a novel optimal transportinterpretation of the generalization problem. This allows us to deriveinstance-dependent generalization bounds that depend on the local Lipschitzregularity of the earned prediction function in the data space. Therefore, ourbounds are agnostic to the parametrization of the model and work well when thenumber of training samples is much smaller than the number of parameters. Withsmall modifications, our approach yields accelerated rates for data onlow-dimensional manifolds, and guarantees under distribution shifts. Weempirically analyze our generalization bounds for neural networks, showing thatthe bound values are meaningful and capture the effect of popularregularization methods during training.</description><author>Songyan Hou, Parnian Kassraie, Anastasis Kratsios, Jonas Rothfuss, Andreas Krause</author><pubDate>Wed, 02 Aug 2023 14:52:37 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2211.01258v3</guid></item><item><title>Black Box Variational Inference with a Deterministic Objective: Faster, More Accurate, and Even More Black Box</title><link>http://arxiv.org/abs/2304.05527v2</link><description>Automatic differentiation variational inference (ADVI) offers fast andeasy-to-use posterior approximation in multiple modern probabilisticprogramming languages. However, its stochastic optimizer lacks clearconvergence criteria and requires tuning parameters. Moreover, ADVI inheritsthe poor posterior uncertainty estimates of mean-field variational Bayes(MFVB). We introduce ``deterministic ADVI'' (DADVI) to address these issues.DADVI replaces the intractable MFVB objective with a fixed Monte Carloapproximation, a technique known in the stochastic optimization literature asthe ``sample average approximation'' (SAA). By optimizing an approximate butdeterministic objective, DADVI can use off-the-shelf second-order optimization,and, unlike standard mean-field ADVI, is amenable to more accurate posteriorcovariances via linear response (LR). In contrast to existing worst-casetheory, we show that, on certain classes of common statistical problems, DADVIand the SAA can perform well with relatively few samples even in very highdimensions, though we also show that such favorable results cannot extend tovariational approximations that are too expressive relative to mean-field ADVI.We show on a variety of real-world problems that DADVI reliably finds goodsolutions with default settings (unlike ADVI) and, together with LRcovariances, is typically faster and more accurate than standard ADVI.</description><author>Ryan Giordano, Martin Ingram, Tamara Broderick</author><pubDate>Wed, 02 Aug 2023 14:49:32 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2304.05527v2</guid></item><item><title>Contrast-augmented Diffusion Model with Fine-grained Sequence Alignment for Markup-to-Image Generation</title><link>http://arxiv.org/abs/2308.01147v1</link><description>The recently rising markup-to-image generation poses greater challenges ascompared to natural image generation, due to its low tolerance for errors aswell as the complex sequence and context correlations between markup andrendered image. This paper proposes a novel model named "Contrast-augmentedDiffusion Model with Fine-grained Sequence Alignment" (FSA-CDM), whichintroduces contrastive positive/negative samples into the diffusion model toboost performance for markup-to-image generation. Technically, we design afine-grained cross-modal alignment module to well explore the sequencesimilarity between the two modalities for learning robust featurerepresentations. To improve the generalization ability, we propose acontrast-augmented diffusion model to explicitly explore positive and negativesamples by maximizing a novel contrastive variational objective, which ismathematically inferred to provide a tighter bound for the model'soptimization. Moreover, the context-aware cross attention module is developedto capture the contextual information within markup language during thedenoising process, yielding better noise prediction results. Extensiveexperiments are conducted on four benchmark datasets from different domains,and the experimental results demonstrate the effectiveness of the proposedcomponents in FSA-CDM, significantly exceeding state-of-the-art performance byabout 2%-12% DTW improvements. The code will be released athttps://github.com/zgj77/FSACDM.</description><author>Guojin Zhong, Jin Yuan, Pan Wang, Kailun Yang, Weili Guan, Zhiyong Li</author><pubDate>Wed, 02 Aug 2023 14:43:03 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2308.01147v1</guid></item><item><title>UCDFormer: Unsupervised Change Detection Using a Transformer-driven Image Translation</title><link>http://arxiv.org/abs/2308.01146v1</link><description>Change detection (CD) by comparing two bi-temporal images is a crucial taskin remote sensing. With the advantages of requiring no cumbersome labeledchange information, unsupervised CD has attracted extensive attention in thecommunity. However, existing unsupervised CD approaches rarely consider theseasonal and style differences incurred by the illumination and atmosphericconditions in multi-temporal images. To this end, we propose a change detectionwith domain shift setting for remote sensing images. Furthermore, we present anovel unsupervised CD method using a light-weight transformer, calledUCDFormer. Specifically, a transformer-driven image translation composed of alight-weight transformer and a domain-specific affinity weight is firstproposed to mitigate domain shift between two images with real-time efficiency.After image translation, we can generate the difference map between thetranslated before-event image and the original after-event image. Then, a novelreliable pixel extraction module is proposed to select significantlychanged/unchanged pixel positions by fusing the pseudo change maps of fuzzyc-means clustering and adaptive threshold. Finally, a binary change map isobtained based on these selected pixel pairs and a binary classifier.Experimental results on different unsupervised CD tasks with seasonal and stylechanges demonstrate the effectiveness of the proposed UCDFormer. For example,compared with several other related methods, UCDFormer improves performance onthe Kappa coefficient by more than 12\%. In addition, UCDFormer achievesexcellent performance for earthquake-induced landslide detection whenconsidering large-scale applications. The code is available at\url{https://github.com/zhu-xlab/UCDFormer}</description><author>Qingsong Xu, Yilei Shi, Jianhua Guo, Chaojun Ouyang, Xiao Xiang Zhu</author><pubDate>Wed, 02 Aug 2023 14:39:08 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2308.01146v1</guid></item><item><title>ADS-Cap: A Framework for Accurate and Diverse Stylized Captioning with Unpaired Stylistic Corpora</title><link>http://arxiv.org/abs/2308.01143v1</link><description>Generating visually grounded image captions with specific linguistic stylesusing unpaired stylistic corpora is a challenging task, especially since weexpect stylized captions with a wide variety of stylistic patterns. In thispaper, we propose a novel framework to generate Accurate and Diverse StylizedCaptions (ADS-Cap). Our ADS-Cap first uses a contrastive learning module toalign the image and text features, which unifies paired factual and unpairedstylistic corpora during the training process. A conditional variationalauto-encoder is then used to automatically memorize diverse stylistic patternsin latent space and enhance diversity through sampling. We also design a simplebut effective recheck module to boost style accuracy by filteringstyle-specific captions. Experimental results on two widely used stylized imagecaptioning datasets show that regarding consistency with the image, styleaccuracy and diversity, ADS-Cap achieves outstanding performances compared tovarious baselines. We finally conduct extensive analyses to understand theeffectiveness of our method. Our code is available athttps://github.com/njucckevin/ADS-Cap.</description><author>Kanzhi Cheng, Zheng Ma, Shi Zong, Jianbing Zhang, Xinyu Dai, Jiajun Chen</author><pubDate>Wed, 02 Aug 2023 14:33:20 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2308.01143v1</guid></item><item><title>DySTreSS: Dynamically Scaled Temperature in Self-Supervised Contrastive Learning</title><link>http://arxiv.org/abs/2308.01140v1</link><description>In contemporary self-supervised contrastive algorithms like SimCLR, MoCo,etc., the task of balancing attraction between two semantically similar samplesand repulsion between two samples from different classes is primarily affectedby the presence of hard negative samples. While the InfoNCE loss has been shownto impose penalties based on hardness, the temperature hyper-parameter is thekey to regulating the penalties and the trade-off between uniformity andtolerance. In this work, we focus our attention to improve the performance ofInfoNCE loss in SSL by studying the effect of temperature hyper-parametervalues. We propose a cosine similarity-dependent temperature scaling functionto effectively optimize the distribution of the samples in the feature space.We further analyze the uniformity and tolerance metrics to investigate theoptimal regions in the cosine similarity space for better optimization.Additionally, we offer a comprehensive examination of the behavior of local andglobal structures in the feature space throughout the pre-training phase, asthe temperature varies. Experimental evidence shows that the proposed frameworkoutperforms or is at par with the contrastive loss-based SSL algorithms. Webelieve our work (DySTreSS) on temperature scaling in SSL provides a foundationfor future research in contrastive learning.</description><author>Siladittya Manna, Soumitri Chattopadhyay, Rakesh Dey, Saumik Bhattacharya, Umapada Pal</author><pubDate>Wed, 02 Aug 2023 14:31:41 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2308.01140v1</guid></item><item><title>Dynamic Privacy Allocation for Locally Differentially Private Federated Learning with Composite Objectives</title><link>http://arxiv.org/abs/2308.01139v1</link><description>This paper proposes a locally differentially private federated learningalgorithm for strongly convex but possibly nonsmooth problems that protects thegradients of each worker against an honest but curious server. The proposedalgorithm adds artificial noise to the shared information to ensure privacy anddynamically allocates the time-varying noise variance to minimize an upperbound of the optimization error subject to a predefined privacy budgetconstraint. This allows for an arbitrarily large but finite number ofiterations to achieve both privacy protection and utility up to a neighborhoodof the optimal solution, removing the need for tuning the number of iterations.Numerical results show the superiority of the proposed algorithm overstate-of-the-art methods.</description><author>Jiaojiao Zhang, Dominik Fay, Mikael Johansson</author><pubDate>Wed, 02 Aug 2023 14:30:33 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2308.01139v1</guid></item><item><title>Vistaar: Diverse Benchmarks and Training Sets for Indian Language ASR</title><link>http://arxiv.org/abs/2305.15386v2</link><description>Improving ASR systems is necessary to make new LLM-based use-cases accessibleto people across the globe. In this paper, we focus on Indian languages, andmake the case that diverse benchmarks are required to evaluate and improve ASRsystems for Indian languages. To address this, we collate Vistaar as a set of59 benchmarks across various language and domain combinations, on which weevaluate 3 publicly available ASR systems and 2 commercial systems. We alsotrain IndicWhisper models by fine-tuning the Whisper models on publiclyavailable training datasets across 12 Indian languages totalling to 10.7Khours. We show that IndicWhisper significantly improves on considered ASRsystems on the Vistaar benchmark. Indeed, IndicWhisper has the lowest WER in 39out of the 59 benchmarks, with an average reduction of 4.1 WER. We open-sourceall datasets, code and models.</description><author>Kaushal Santosh Bhogale, Sai Sundaresan, Abhigyan Raman, Tahir Javed, Mitesh M. Khapra, Pratyush Kumar</author><pubDate>Wed, 02 Aug 2023 14:29:31 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.15386v2</guid></item><item><title>Can We Transfer Noise Patterns? An Multi-environment Spectrum Analysis Model Using Generated Cases</title><link>http://arxiv.org/abs/2308.01138v1</link><description>Spectrum analysis systems in online water quality testing are designed todetect types and concentrations of pollutants and enable regulatory agencies torespond promptly to pollution incidents. However, spectral data-based testingdevices suffer from complex noise patterns when deployed in non-laboratoryenvironments. To make the analysis model applicable to more environments, wepropose a noise patterns transferring model, which takes the spectrum ofstandard water samples in different environments as cases and learns thedifferences in their noise patterns, thus enabling noise patterns to transferto unknown samples. Unfortunately, the inevitable sample-level baseline noisemakes the model unable to obtain the paired data that only differ indataset-level environmental noise. To address the problem, we generate asample-to-sample case-base to exclude the interference of sample-level noise ondataset-level noise learning, enhancing the system's learning performance.Experiments on spectral data with different background noises demonstrate thegood noise-transferring ability of the proposed method against baseline systemsranging from wavelet denoising, deep neural networks, and generative models.From this research, we posit that our method can enhance the performance of DLmodels by generating high-quality cases. The source code is made publiclyavailable online at https://github.com/Magnomic/CNST.</description><author>Haiwen Du, Zheng Ju, Yu An, Honghui Du, Dongjie Zhu, Zhaoshuo Tian, Aonghus Lawlor, Ruihai Dong</author><pubDate>Wed, 02 Aug 2023 14:29:31 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2308.01138v1</guid></item><item><title>Multi-task learning for classification, segmentation, reconstruction, and detection on chest CT scans</title><link>http://arxiv.org/abs/2308.01137v1</link><description>Lung cancer and covid-19 have one of the highest morbidity and mortalityrates in the world. For physicians, the identification of lesions is difficultin the early stages of the disease and time-consuming. Therefore, multi-tasklearning is an approach to extracting important features, such as lesions, fromsmall amounts of medical data because it learns to generalize better. Wepropose a novel multi-task framework for classification, segmentation,reconstruction, and detection. To the best of our knowledge, we are the firstones who added detection to the multi-task solution. Additionally, we checkedthe possibility of using two different backbones and different loss functionsin the segmentation task.</description><author>Weronika Hryniewska-Guzik, Maria Kędzierska, Przemysław Biecek</author><pubDate>Wed, 02 Aug 2023 14:28:44 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2308.01137v1</guid></item><item><title>Leveraging Expert Models for Training Deep Neural Networks in Scarce Data Domains: Application to Offline Handwritten Signature Verification</title><link>http://arxiv.org/abs/2308.01136v1</link><description>This paper introduces a novel approach to leverage the knowledge of existingexpert models for training new Convolutional Neural Networks, on domains wheretask-specific data are limited or unavailable. The presented scheme is appliedin offline handwritten signature verification (OffSV) which, akin to otherbiometric applications, suffers from inherent data limitations due toregulatory restrictions. The proposed Student-Teacher (S-T) configurationutilizes feature-based knowledge distillation (FKD), combining graph-basedsimilarity for local activations with global similarity measures to supervisestudent's training, using only handwritten text data. Remarkably, the modelstrained using this technique exhibit comparable, if not superior, performanceto the teacher model across three popular signature datasets. More importantly,these results are attained without employing any signatures during the featureextraction training process. This study demonstrates the efficacy of leveragingexisting expert models to overcome data scarcity challenges in OffSV andpotentially other related domains.</description><author>Dimitrios Tsourounis, Ilias Theodorakopoulos, Elias N. Zois, George Economou</author><pubDate>Wed, 02 Aug 2023 14:28:12 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2308.01136v1</guid></item><item><title>Automated Hit-frame Detection for Badminton Match Analysis</title><link>http://arxiv.org/abs/2307.16000v2</link><description>Sports professionals constantly under pressure to perform at the highestlevel can benefit from sports analysis, which allows coaches and players toreduce manual efforts and systematically evaluate their performance usingautomated tools. This research aims to advance sports analysis in badminton,systematically detecting hit-frames automatically from match videos usingmodern deep learning techniques. The data included in hit-frames cansubsequently be utilized to synthesize players' strokes and on-court movement,as well as for other downstream applications such as analyzing training tasksand competition strategy. The proposed approach in this study comprises severalautomated procedures like rally-wise video trimming, player and court keypointsdetection, shuttlecock flying direction prediction, and hit-frame detection. Inthe study, we achieved 99% accuracy on shot angle recognition for videotrimming, over 92% accuracy for applying player keypoints sequences onshuttlecock flying direction prediction, and reported the evaluation results ofrally-wise video trimming and hit-frame detection.</description><author>Yu-Hang Chien, Fang Yu</author><pubDate>Wed, 02 Aug 2023 14:17:34 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.16000v2</guid></item><item><title>DiffusePast: Diffusion-based Generative Replay for Class Incremental Semantic Segmentation</title><link>http://arxiv.org/abs/2308.01127v1</link><description>The Class Incremental Semantic Segmentation (CISS) extends the traditionalsegmentation task by incrementally learning newly added classes. Previous workhas introduced generative replay, which involves replaying old class samplesgenerated from a pre-trained GAN, to address the issues of catastrophicforgetting and privacy concerns. However, the generated images lack semanticprecision and exhibit out-of-distribution characteristics, resulting ininaccurate masks that further degrade the segmentation performance. To tacklethese challenges, we propose DiffusePast, a novel framework featuring adiffusion-based generative replay module that generates semantically accurateimages with more reliable masks guided by different instructions (e.g., textprompts or edge maps). Specifically, DiffusePast introduces a dual-generatorparadigm, which focuses on generating old class images that align with thedistribution of downstream datasets while preserving the structure and layoutof the original images, enabling more precise masks. To adapt to the novelvisual concepts of newly added classes continuously, we incorporate class-wisetoken embedding when updating the dual-generator. Moreover, we assign adequatepseudo-labels of old classes to the background pixels in the new step images,further mitigating the forgetting of previously learned knowledge. Throughcomprehensive experiments, our method demonstrates competitive performanceacross mainstream benchmarks, striking a better balance between the performanceof old and novel classes.</description><author>Jingfan Chen, Yuxi Wang, Pengfei Wang, Xiao Chen, Zhaoxiang Zhang, Zhen Lei, Qing Li</author><pubDate>Wed, 02 Aug 2023 14:13:18 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2308.01127v1</guid></item><item><title>Beyond Generic: Enhancing Image Captioning with Real-World Knowledge using Vision-Language Pre-Training Model</title><link>http://arxiv.org/abs/2308.01126v1</link><description>Current captioning approaches tend to generate correct but "generic"descriptions that lack real-world knowledge, e.g., named entities andcontextual information. Considering that Vision-Language Pre-Training (VLP)models master massive such knowledge from large-scale web-harvested data, it ispromising to utilize the generalizability of VLP models to incorporateknowledge into image descriptions. However, using VLP models faces challenges:zero-shot inference suffers from knowledge hallucination that leads tolow-quality descriptions, but the generic bias in downstream task fine-tuninghinders the VLP model from expressing knowledge. To address these concerns, wepropose a simple yet effective method called Knowledge-guided Replay(K-Replay), which enables the retention of pre-training knowledge duringfine-tuning. Our approach consists of two parts: (1) a knowledge predictiontask on automatically collected replay exemplars to continuously awaken the VLPmodel's memory about knowledge, thus preventing the model from collapsing intothe generic pattern; (2) a knowledge distillation constraint to improve thefaithfulness of generated descriptions hence alleviating the knowledgehallucination. To evaluate knowledge-enhanced descriptions, we construct anovel captioning benchmark KnowCap, containing knowledge of landmarks, famousbrands, special foods and movie characters. Experimental results show that ourapproach effectively incorporates knowledge into descriptions, outperformingstrong VLP baseline by 20.9 points (78.7-&gt;99.6) in CIDEr score and 20.5percentage points (34.0%-&gt;54.5%) in knowledge recognition accuracy. Our codeand data is available at https://github.com/njucckevin/KnowCap.</description><author>Kanzhi Cheng, Wenpo Song, Zheng Ma, Wenhao Zhu, Zixuan Zhu, Jianbing Zhang</author><pubDate>Wed, 02 Aug 2023 14:09:57 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2308.01126v1</guid></item><item><title>Stereo Visual Odometry with Deep Learning-Based Point and Line Feature Matching using an Attention Graph Neural Network</title><link>http://arxiv.org/abs/2308.01125v1</link><description>Robust feature matching forms the backbone for most Visual SimultaneousLocalization and Mapping (vSLAM), visual odometry, 3D reconstruction, andStructure from Motion (SfM) algorithms. However, recovering feature matchesfrom texture-poor scenes is a major challenge and still remains an open area ofresearch. In this paper, we present a Stereo Visual Odometry (StereoVO)technique based on point and line features which uses a novel feature-matchingmechanism based on an Attention Graph Neural Network that is designed toperform well even under adverse weather conditions such as fog, haze, rain, andsnow, and dynamic lighting conditions such as nighttime illumination and glarescenarios. We perform experiments on multiple real and synthetic datasets tovalidate the ability of our method to perform StereoVO under low visibilityweather and lighting conditions through robust point and line matches. Theresults demonstrate that our method achieves more line feature matches thanstate-of-the-art line matching algorithms, which when complemented with pointfeature matches perform consistently well in adverse weather and dynamiclighting conditions.</description><author>Shenbagaraj Kannapiran, Nalin Bendapudi, Ming-Yuan Yu, Devarth Parikh, Spring Berman, Ankit Vora, Gaurav Pandey</author><pubDate>Wed, 02 Aug 2023 14:09:12 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2308.01125v1</guid></item><item><title>TeleViT: Teleconnection-driven Transformers Improve Subseasonal to Seasonal Wildfire Forecasting</title><link>http://arxiv.org/abs/2306.10940v2</link><description>Wildfires are increasingly exacerbated as a result of climate change,necessitating advanced proactive measures for effective mitigation. It isimportant to forecast wildfires weeks and months in advance to plan forest fuelmanagement, resource procurement and allocation. To achieve such accuratelong-term forecasts at a global scale, it is crucial to employ models thataccount for the Earth system's inherent spatio-temporal interactions, such asmemory effects and teleconnections. We propose a teleconnection-driven visiontransformer (TeleViT), capable of treating the Earth as one interconnectedsystem, integrating fine-grained local-scale inputs with global-scale inputs,such as climate indices and coarse-grained global variables. Throughcomprehensive experimentation, we demonstrate the superiority of TeleViT inaccurately predicting global burned area patterns for various forecastingwindows, up to four months in advance. The gain is especially pronounced inlarger forecasting windows, demonstrating the improved ability of deep learningmodels that exploit teleconnections to capture Earth system dynamics. Codeavailable at https://github.com/Orion-Ai-Lab/TeleViT.</description><author>Ioannis Prapas, Nikolaos Ioannis Bountos, Spyros Kondylatos, Dimitrios Michail, Gustau Camps-Valls, Ioannis Papoutsis</author><pubDate>Wed, 02 Aug 2023 14:04:50 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.10940v2</guid></item><item><title>Unlearning Spurious Correlations in Chest X-ray Classification</title><link>http://arxiv.org/abs/2308.01119v1</link><description>Medical image classification models are frequently trained using trainingdatasets derived from multiple data sources. While leveraging multiple datasources is crucial for achieving model generalization, it is important toacknowledge that the diverse nature of these sources inherently introducesunintended confounders and other challenges that can impact both model accuracyand transparency. A notable confounding factor in medical image classification,particularly in musculoskeletal image classification, is skeletalmaturation-induced bone growth observed during adolescence. We train a deeplearning model using a Covid-19 chest X-ray dataset and we showcase how thisdataset can lead to spurious correlations due to unintended confoundingregions. eXplanation Based Learning (XBL) is a deep learning approach that goesbeyond interpretability by utilizing model explanations to interactivelyunlearn spurious correlations. This is achieved by integrating interactive userfeedback, specifically feature annotations. In our study, we employed twonon-demanding manual feedback mechanisms to implement an XBL-based approach foreffectively eliminating these spurious correlations. Our results underscore thepromising potential of XBL in constructing robust models even in the presenceof confounding factors.</description><author>Misgina Tsighe Hagos, Kathleen M. Curran, Brian Mac Namee</author><pubDate>Wed, 02 Aug 2023 13:59:10 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2308.01119v1</guid></item><item><title>A Survey on Popularity Bias in Recommender Systems</title><link>http://arxiv.org/abs/2308.01118v1</link><description>Recommender systems help people find relevant content in a personalized way.One main promise of such systems is that they are able to increase thevisibility of items in the long tail, i.e., the lesser-known items in acatalogue. Existing research, however, suggests that in many situations today'srecommendation algorithms instead exhibit a popularity bias, meaning that theyoften focus on rather popular items in their recommendations. Such a bias maynot only lead to limited value of the recommendations for consumers andproviders in the short run, but it may also cause undesired reinforcementeffects over time. In this paper, we discuss the potential reasons forpopularity bias and we review existing approaches to detect, quantify andmitigate popularity bias in recommender systems. Our survey therefore includesboth an overview of the computational metrics used in the literature as well asa review of the main technical approaches to reduce the bias. We furthermorecritically discuss today's literature, where we observe that the research isalmost entirely based on computational experiments and on certain assumptionsregarding the practical effects of including long-tail items in therecommendations.</description><author>Anastasiia Klimashevskaia, Dietmar Jannach, Mehdi Elahi, Christoph Trattner</author><pubDate>Wed, 02 Aug 2023 13:58:11 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2308.01118v1</guid></item><item><title>Learning Combinatorial Prompts for Universal Controllable Image Captioning</title><link>http://arxiv.org/abs/2303.06338v3</link><description>Controllable Image Captioning (CIC) -- generating natural languagedescriptions about images under the guidance of given control signals -- is oneof the most promising directions towards next-generation captioning systems.Till now, various kinds of control signals for CIC have been proposed, rangingfrom content-related control to structure-related control. However, due to theformat and target gaps of different control signals, all existing CIC works (orarchitectures) only focus on one certain control signal, and overlook thehuman-like combinatorial ability. By ``combinatorial", we mean that our humanscan easily meet multiple needs (or constraints) simultaneously when generatingdescriptions. To this end, we propose a novel prompt-based framework for CIC bylearning Combinatorial Prompts, dubbed as ComPro. Specifically, we directlyutilize a pretrained language model GPT-2 as our language model, which can helpto bridge the gap between different signal-specific CIC architectures. Then, wereformulate the CIC as a prompt-guide sentence generation problem, and proposea new lightweight prompt generation network to generate the combinatorialprompts for different kinds of control signals. For different control signals,we further design a new mask attention mechanism to realize the prompt-basedCIC. Due to its simplicity, our ComPro can be further extended to more kinds ofcombined control signals by concatenating these prompts. Extensive experimentson two prevalent CIC benchmarks have verified the effectiveness and efficiencyof our ComPro on both single and combined control signals.</description><author>Zhen Wang, Jun Xiao, Yueting Zhuang, Fei Gao, Jian Shao, Long Chen</author><pubDate>Wed, 02 Aug 2023 13:56:53 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2303.06338v3</guid></item><item><title>Graph Soft-Contrastive Learning via Neighborhood Ranking</title><link>http://arxiv.org/abs/2209.13964v3</link><description>Graph Contrastive Learning (GCL) has emerged as a promising approach in therealm of graph self-supervised learning. Prevailing GCL methods mainly derivefrom the principles of contrastive learning in the field of computer vision:modeling invariance by specifying absolutely similar pairs. However, whenapplied to graph data, this paradigm encounters two significant limitations:(1) the validity of the generated views cannot be guaranteed: graphperturbation may produce invalid views against semantics and intrinsic topologyof graph data; (2) specifying absolutely similar pairs in the graph views isunreliable: for abstract and non-Euclidean graph data, it is difficult forhumans to decide the absolute similarity and dissimilarity intuitively. Despitethe notable performance of current GCL methods, these challenges necessitate areevaluation: Could GCL be more effectively tailored to the intrinsicproperties of graphs, rather than merely adopting principles from computervision? In response to this query, we propose a novel paradigm, GraphSoft-Contrastive Learning (GSCL). This approach facilitates GCL vianeighborhood ranking, avoiding the need to specify absolutely similar pairs.GSCL leverages the underlying graph characteristic of diminishing labelconsistency, asserting that nodes that are closer in the graph are overall moresimilar than far-distant nodes. Within the GSCL framework, we introducepairwise and listwise gated ranking InfoNCE loss functions to effectivelypreserve the relative similarity ranking within neighborhoods. Moreover, as theneighborhood size exponentially expands with more hops considered, we proposeneighborhood sampling strategies to improve learning efficiency. Our extensiveempirical results across 11 commonly used graph datasets-including 8 homophilygraphs and 3 heterophily graphs-demonstrate GSCL's superior performancecompared to 20 SOTA GCL methods.</description><author>Zhiyuan Ning, Pengfei Wang, Pengyang Wang, Ziyue Qiao, Wei Fan, Denghui Zhang, Yi Du, Yuanchun Zhou</author><pubDate>Wed, 02 Aug 2023 13:43:19 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2209.13964v3</guid></item><item><title>Literal-Aware Knowledge Graph Embedding for Welding Quality Monitoring: A Bosch Case</title><link>http://arxiv.org/abs/2308.01105v1</link><description>Recently there has been a series of studies in knowledge graph embedding(KGE), which attempts to learn the embeddings of the entities and relations asnumerical vectors and mathematical mappings via machine learning (ML). However,there has been limited research that applies KGE for industrial problems inmanufacturing. This paper investigates whether and to what extent KGE can beused for an important problem: quality monitoring for welding in manufacturingindustry, which is an impactful process accounting for production of millionsof cars annually. The work is in line with Bosch research of data-drivensolutions that intends to replace the traditional way of destroying cars, whichis extremely costly and produces waste. The paper tackles two very challengingquestions simultaneously: how large the welding spot diameter is; and to whichcar body the welded spot belongs to. The problem setting is difficult fortraditional ML because there exist a high number of car bodies that should beassigned as class labels. We formulate the problem as link prediction, andexperimented popular KGE methods on real industry data, with consideration ofliterals. Our results reveal both limitations and promising aspects of adaptedKGE methods.</description><author>Zhipeng Tan, Baifan Zhou, Zhuoxun Zheng, Ognjen Savkovic, Ziqi Huang, Irlan-Grangel Gonzalez, Ahmet Soylu, Evgeny Kharlamov</author><pubDate>Wed, 02 Aug 2023 13:22:35 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2308.01105v1</guid></item><item><title>Robust mmWave Beamforming by Self-Supervised Hybrid Deep Learning</title><link>http://arxiv.org/abs/2303.12653v2</link><description>Beamforming with large-scale antenna arrays has been widely used in recentyears, which is acknowledged as an important part in 5G and incoming 6G. Thus,various techniques are leveraged to improve its performance, e.g., deeplearning, advanced optimization algorithms, etc. Although its performance inmany previous research scenarios with deep learning is quite attractive,usually it drops rapidly when the environment or dataset is changed. Therefore,designing effective beamforming network with strong robustness is an open issuefor the intelligent wireless communications. In this paper, we propose a robustbeamforming self-supervised network, and verify it in two kinds of differentdatasets with various scenarios. Simulation results show that the proposedself-supervised network with hybrid learning performs well in both classicDeepMIMO and new WAIR-D dataset with the strong robustness under the variousenvironments. Also, we present the principle to explain the rationality of thiskind of hybrid learning, which is instructive to apply with more kinds ofdatasets.</description><author>Fenghao Zhu, Bohao Wang, Zhaohui Yang, Chongwen Huang, Zhaoyang Zhang, George C. Alexandropoulos, Chau Yuen, Merouane Debbah</author><pubDate>Wed, 02 Aug 2023 13:20:40 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2303.12653v2</guid></item><item><title>Bayesian Optimization of Expensive Nested Grey-Box Functions</title><link>http://arxiv.org/abs/2306.05150v2</link><description>We consider the problem of optimizing a grey-box objective function, i.e.,nested function composed of both black-box and white-box functions. A generalformulation for such grey-box problems is given, which covers the existinggrey-box optimization formulations as special cases. We then design anoptimism-driven algorithm to solve it. Under certain regularity assumptions,our algorithm achieves similar regret bound as that for the standard black-boxBayesian optimization algorithm, up to a constant multiplicative term dependingon the Lipschitz constants of the functions considered. We further extend ourmethod to the constrained case and discuss special cases. For the commonly usedkernel functions, the regret bounds allow us to derive a convergence rate tothe optimal solution. Experimental results show that our grey-box optimizationmethod empirically improves the speed of finding the global optimal solutionsignificantly, as compared to the standard black-box optimization algorithm.</description><author>Wenjie Xu, Yuning Jiang, Bratislav Svetozarevic, Colin N. Jones</author><pubDate>Wed, 02 Aug 2023 13:12:56 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.05150v2</guid></item><item><title>COCO-O: A Benchmark for Object Detectors under Natural Distribution Shifts</title><link>http://arxiv.org/abs/2307.12730v2</link><description>Practical object detection application can lose its effectiveness on imageinputs with natural distribution shifts. This problem leads the researchcommunity to pay more attention on the robustness of detectors underOut-Of-Distribution (OOD) inputs. Existing works construct datasets tobenchmark the detector's OOD robustness for a specific application scenario,e.g., Autonomous Driving. However, these datasets lack universality and arehard to benchmark general detectors built on common tasks such as COCO. To givea more comprehensive robustness assessment, we introduceCOCO-O(ut-of-distribution), a test dataset based on COCO with 6 types ofnatural distribution shifts. COCO-O has a large distribution gap with trainingdata and results in a significant 55.7% relative performance drop on a FasterR-CNN detector. We leverage COCO-O to conduct experiments on more than 100modern object detectors to investigate if their improvements are credible orjust over-fitting to the COCO test set. Unfortunately, most classic detectorsin early years do not exhibit strong OOD generalization. We further study therobustness effect on recent breakthroughs of detector's architecture design,augmentation and pre-training techniques. Some empirical findings are revealed:1) Compared with detection head or neck, backbone is the most important partfor robustness; 2) An end-to-end detection transformer design brings noenhancement, and may even reduce robustness; 3) Large-scale foundation modelshave made a great leap on robust object detection. We hope our COCO-O couldprovide a rich testbed for robustness study of object detection. The datasetwill be available athttps://github.com/alibaba/easyrobust/tree/main/benchmarks/coco_o.</description><author>Xiaofeng Mao, Yuefeng Chen, Yao Zhu, Da Chen, Hang Su, Rong Zhang, Hui Xue</author><pubDate>Wed, 02 Aug 2023 13:10:55 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.12730v2</guid></item><item><title>Towards Better Query Classification with Multi-Expert Knowledge Condensation in JD Ads Search</title><link>http://arxiv.org/abs/2308.01098v1</link><description>Search query classification, as an effective way to understand user intents,is of great importance in real-world online ads systems. To ensure a lowerlatency, a shallow model (e.g. FastText) is widely used for efficient onlineinference. However, the representation ability of the FastText model isinsufficient, resulting in poor classification performance, especially on somelow-frequency queries and tailed categories. Using a deeper and more complexmodel (e.g. BERT) is an effective solution, but it will cause a higher onlineinference latency and more expensive computing costs. Thus, how to juggle bothinference efficiency and classification performance is obviously of greatpractical importance. To overcome this challenge, in this paper, we proposeknowledge condensation (KC), a simple yet effective knowledge distillationframework to boost the classification performance of the online FastText modelunder strict low latency constraints. Specifically, we propose to train anoffline BERT model to retrieve more potentially relevant data. Benefiting fromits powerful semantic representation, more relevant labels not exposed in thehistorical data will be added into the training set for better FastText modeltraining. Moreover, a novel distribution-diverse multi-expert learning strategyis proposed to further improve the mining ability of relevant data. By trainingmultiple BERT models from different data distributions, it can respectivelyperform better at high, middle, and low-frequency search queries. The modelensemble from multi-distribution makes its retrieval ability more powerful. Wehave deployed two versions of this framework in JD search, and both offlineexperiments and online A/B testing from multiple datasets have validated theeffectiveness of the proposed approach.</description><author>Kun-Peng Ning, Ming Pang, Zheng Fang, Xue Jiang, Xi-Wei Zhao, Chang-Ping Peng, Zhan-Gang Lin, Jing-He Hu, Jing-Ping Shao</author><pubDate>Wed, 02 Aug 2023 13:05:01 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2308.01098v1</guid></item><item><title>Spatio-Temporal Branching for Motion Prediction using Motion Increments</title><link>http://arxiv.org/abs/2308.01097v1</link><description>Human motion prediction (HMP) has emerged as a popular research topic due toits diverse applications, but it remains a challenging task due to thestochastic and aperiodic nature of future poses. Traditional methods rely onhand-crafted features and machine learning techniques, which often struggle tomodel the complex dynamics of human motion. Recent deep learning-based methodshave achieved success by learning spatio-temporal representations of motion,but these models often overlook the reliability of motion data. Additionally,the temporal and spatial dependencies of skeleton nodes are distinct. Thetemporal relationship captures motion information over time, while the spatialrelationship describes body structure and the relationships between differentnodes. In this paper, we propose a novel spatio-temporal branching networkusing incremental information for HMP, which decouples the learning oftemporal-domain and spatial-domain features, extracts more motion information,and achieves complementary cross-domain knowledge learning through knowledgedistillation. Our approach effectively reduces noise interference and providesmore expressive information for characterizing motion by separately extractingtemporal and spatial features. We evaluate our approach on standard HMPbenchmarks and outperform state-of-the-art methods in terms of predictionaccuracy.</description><author>Jiexin Wang, Yujie Zhou, Wenwen Qiang, Ying Ba, Bing Su, Ji-Rong Wen</author><pubDate>Wed, 02 Aug 2023 13:04:28 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2308.01097v1</guid></item><item><title>AutoPoster: A Highly Automatic and Content-aware Design System for Advertising Poster Generation</title><link>http://arxiv.org/abs/2308.01095v1</link><description>Advertising posters, a form of information presentation, combine visual andlinguistic modalities. Creating a poster involves multiple steps andnecessitates design experience and creativity. This paper introducesAutoPoster, a highly automatic and content-aware system for generatingadvertising posters. With only product images and titles as inputs, AutoPostercan automatically produce posters of varying sizes through four key stages:image cleaning and retargeting, layout generation, tagline generation, andstyle attribute prediction. To ensure visual harmony of posters, twocontent-aware models are incorporated for layout and tagline generation.Moreover, we propose a novel multi-task Style Attribute Predictor (SAP) tojointly predict visual style attributes. Meanwhile, to our knowledge, wepropose the first poster generation dataset that includes visual attributeannotations for over 76k posters. Qualitative and quantitative outcomes fromuser studies and experiments substantiate the efficacy of our system and theaesthetic superiority of the generated posters compared to other postergeneration methods.</description><author>Jinpeng Lin, Min Zhou, Ye Ma, Yifan Gao, Chenxi Fei, Yangjian Chen, Zhang Yu, Tiezheng Ge</author><pubDate>Wed, 02 Aug 2023 12:58:43 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2308.01095v1</guid></item><item><title>Scaling Data Science Solutions with Semantics and Machine Learning: Bosch Case</title><link>http://arxiv.org/abs/2308.01094v1</link><description>Industry 4.0 and Internet of Things (IoT) technologies unlock unprecedentedamount of data from factory production, posing big data challenges in volumeand variety. In that context, distributed computing solutions such as cloudsystems are leveraged to parallelise the data processing and reduce computationtime. As the cloud systems become increasingly popular, there is increaseddemand that more users that were originally not cloud experts (such as datascientists, domain experts) deploy their solutions on the cloud systems.However, it is non-trivial to address both the high demand for cloud systemusers and the excessive time required to train them. To this end, we proposeSemCloud, a semantics-enhanced cloud system, that couples cloud system withsemantic technologies and machine learning. SemCloud relies on domainontologies and mappings for data integration, and parallelises the semanticdata integration and data analysis on distributed computing nodes. Furthermore,SemCloud adopts adaptive Datalog rules and machine learning for automatedresource configuration, allowing non-cloud experts to use the cloud system. Thesystem has been evaluated in industrial use case with millions of data,thousands of repeated runs, and domain users, showing promising results.</description><author>Baifan Zhou, Nikolay Nikolov, Zhuoxun Zheng, Xianghui Luo, Ognjen Savkovic, Dumitru Roman, Ahmet Soylu, Evgeny Kharlamov</author><pubDate>Wed, 02 Aug 2023 12:58:30 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2308.01094v1</guid></item><item><title>LMEye: An Interactive Perception Network for Large Language Models</title><link>http://arxiv.org/abs/2305.03701v5</link><description>Training a Large Visual Language Model (LVLM) from scratch, like GPT-4, isresource-intensive. Our paper presents a play-and-plug module for LargeLanguage Models (LLMs), namely Interactive Perception Network (IPN), aiming toachieve a LVLM by incorporating the image understanding capability into LLMs.Previous methods incorporate visual information into LLMs with a simple visualmapping network, where the image feature is projected into the embedding spaceof LLMs via a linear layer. Such mapping network projects the image featureonce yet does not consider the interaction between the image and the humaninput query. Hence, the obtained visual information with no connections withhuman intention may be inadequate for LLMs to make intention-followingresponses, which we term as static visual information. IPN addresses this issueby allowing the LLM to request the desired visual information aligned withvarious human instructions, which we term as the dynamic interaction betweenthe LLM and visual information. Specifically, IPN consists of a simple visualmapping network to provide the basic perception of an image for LLMs. It alsocontains additional modules responsible for acquiring requests from LLMs,performing request-based visual information interaction, and transmitting theresulting interacted visual information to LLMs, respectively. In this way,LLMs act to understand the human query, deliver the corresponding request tothe request-based visual information interaction module, and generate theresponse based on the interleaved multimodal information. We evaluate IPNthrough extensive experiments on multimodal question answering, reasoning, andso on, demonstrating that it significantly improves the zero-shot performanceof LVLMs on various multimodal tasks compared to previous methods.</description><author>Yunxin Li, Baotian Hu, Xinyu Chen, Lin Ma, Min Zhang</author><pubDate>Wed, 02 Aug 2023 12:52:16 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.03701v5</guid></item><item><title>Hand tracking for clinical applications: validation of the Google MediaPipe Hand (GMH) and the depth-enhanced GMH-D frameworks</title><link>http://arxiv.org/abs/2308.01088v1</link><description>Accurate 3D tracking of hand and fingers movements poses significantchallenges in computer vision. The potential applications span across multipledomains, including human-computer interaction, virtual reality, industry, andmedicine. While gesture recognition has achieved remarkable accuracy,quantifying fine movements remains a hurdle, particularly in clinicalapplications where the assessment of hand dysfunctions and rehabilitationtraining outcomes necessitate precise measurements. Several novel andlightweight frameworks based on Deep Learning have emerged to address thisissue; however, their performance in accurately and reliably measuring fingersmovements requires validation against well-established gold standard systems.In this paper, the aim is to validate the handtracking framework implemented byGoogle MediaPipe Hand (GMH) and an innovative enhanced version, GMH-D, thatexploits the depth estimation of an RGB-Depth camera to achieve more accuratetracking of 3D movements. Three dynamic exercises commonly administered byclinicians to assess hand dysfunctions, namely Hand Opening-Closing, SingleFinger Tapping and Multiple Finger Tapping are considered. Results demonstratehigh temporal and spectral consistency of both frameworks with the goldstandard. However, the enhanced GMH-D framework exhibits superior accuracy inspatial measurements compared to the baseline GMH, for both slow and fastmovements. Overall, our study contributes to the advancement of hand trackingtechnology, the establishment of a validation procedure as a good-practice toprove efficacy of deep-learning-based hand-tracking, and proves theeffectiveness of GMH-D as a reliable framework for assessing 3D hand movementsin clinical applications.</description><author>Gianluca Amprimo, Giulia Masi, Giuseppe Pettiti, Gabriella Olmo, Lorenzo Priano, Claudia Ferraris</author><pubDate>Wed, 02 Aug 2023 12:44:49 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2308.01088v1</guid></item><item><title>FaDIn: Fast Discretized Inference for Hawkes Processes with General Parametric Kernels</title><link>http://arxiv.org/abs/2210.04635v3</link><description>Temporal point processes (TPP) are a natural tool for modeling event-baseddata. Among all TPP models, Hawkes processes have proven to be the most widelyused, mainly due to their adequate modeling for various applications,particularly when considering exponential or non-parametric kernels. Althoughnon-parametric kernels are an option, such models require large datasets. Whileexponential kernels are more data efficient and relevant for specificapplications where events immediately trigger more events, they are ill-suitedfor applications where latencies need to be estimated, such as in neuroscience.This work aims to offer an efficient solution to TPP inference using generalparametric kernels with finite support. The developed solution consists of afast $\ell_2$ gradient-based solver leveraging a discretized version of theevents. After theoretically supporting the use of discretization, thestatistical and computational efficiency of the novel approach is demonstratedthrough various numerical experiments. Finally, the method's effectiveness isevaluated by modeling the occurrence of stimuli-induced patterns from brainsignals recorded with magnetoencephalography (MEG). Given the use of generalparametric kernels, results show that the proposed approach leads to animproved estimation of pattern latency than the state-of-the-art.</description><author>Guillaume Staerman, Cédric Allain, Alexandre Gramfort, Thomas Moreau</author><pubDate>Wed, 02 Aug 2023 12:42:11 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2210.04635v3</guid></item><item><title>Homography Estimation in Complex Topological Scenes</title><link>http://arxiv.org/abs/2308.01086v1</link><description>Surveillance videos and images are used for a broad set of applications,ranging from traffic analysis to crime detection. Extrinsic camera calibrationdata is important for most analysis applications. However, security cameras aresusceptible to environmental conditions and small camera movements, resultingin a need for an automated re-calibration method that can account for thesevarying conditions. In this paper, we present an automated camera-calibrationprocess leveraging a dictionary-based approach that does not require priorknowledge on any camera settings. The method consists of a customimplementation of a Spatial Transformer Network (STN) and a novel topologicalloss function. Experiments reveal that the proposed method improves the IoUmetric by up to 12% w.r.t. a state-of-the-art model across five syntheticdatasets and the World Cup 2014 dataset.</description><author>Giacomo D'Amicantonio, Egor Bondarau, Peter H. N. De With</author><pubDate>Wed, 02 Aug 2023 12:31:43 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2308.01086v1</guid></item><item><title>Spatial Intelligence of a Self-driving Car and Rule-Based Decision Making</title><link>http://arxiv.org/abs/2308.01085v1</link><description>In this paper we show how rule-based decision making can be combined withtraditional motion planning techniques to achieve human-like behavior of aself-driving vehicle in complex traffic situations. We give and discussexamples of decision rules in autonomous driving. We draw on these examples toillustrate that developing techniques for spatial awareness of robots is anexciting activity which deserves more attention from spatial reasoningcommunity that it had received so far.</description><author>Stanislav Kikot</author><pubDate>Wed, 02 Aug 2023 12:27:41 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2308.01085v1</guid></item><item><title>Data-Driven Identification of Quadratic Symplectic Representations of Nonlinear Hamiltonian Systems</title><link>http://arxiv.org/abs/2308.01084v1</link><description>We present a framework for learning Hamiltonian systems using data. This workis based on the lifting hypothesis, which posits that nonlinear Hamiltoniansystems can be written as nonlinear systems with cubic Hamiltonians. Byleveraging this, we obtain quadratic dynamics that are Hamiltonian in atransformed coordinate system. To that end, for given generalized position andmomentum data, we propose a methodology to learn quadratic dynamical systems,enforcing the Hamiltonian structure in combination with a symplecticauto-encoder. The enforced Hamiltonian structure exhibits long-term stabilityof the system, while the cubic Hamiltonian function provides relatively lowmodel complexity. For low-dimensional data, we determine a higher-ordertransformed coordinate system, whereas, for high-dimensional data, we find alower-order coordinate system with the desired properties. We demonstrate theproposed methodology by means of both low-dimensional and high-dimensionalnonlinear Hamiltonian systems.</description><author>Süleyman Yildiz, Pawan Goyal, Thomas Bendokat, Peter Benner</author><pubDate>Wed, 02 Aug 2023 12:26:33 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2308.01084v1</guid></item><item><title>An Auction-based Coordination Strategy for Task-Constrained Multi-Agent Stochastic Planning with Submodular Rewards</title><link>http://arxiv.org/abs/2212.14624v2</link><description>In many domains such as transportation and logistics, search and rescue, orcooperative surveillance, tasks are pending to be allocated with theconsideration of possible execution uncertainties. Existing task coordinationalgorithms either ignore the stochastic process or suffer from thecomputational intensity. Taking advantage of the weakly coupled feature of theproblem and the opportunity for coordination in advance, we propose adecentralized auction-based coordination strategy using a newly formulatedscore function which is generated by forming the problem into task-constrainedMarkov decision processes (MDPs). The proposed method guarantees convergenceand at least 50% optimality in the premise of a submodular reward function.Furthermore, for the implementation on large-scale applications, an approximatevariant of the proposed method, namely Deep Auction, is also suggested with theuse of neural networks, which is evasive of the troublesome for constructingMDPs. Inspired by the well-known actor-critic architecture, two Transformersare used to map observations to action probabilities and cumulative rewardsrespectively. Finally, we demonstrate the performance of the two proposedapproaches in the context of drone deliveries, where the stochastic planningfor the drone league is cast into a stochastic price-collecting Vehicle RoutingProblem (VRP) with time windows. Simulation results are compared withstate-of-the-art methods in terms of solution quality, planning efficiency andscalability.</description><author>Ruifan Liu, Hyo-Sang Shin, Binbin Yan, Antonios Tsourdos</author><pubDate>Wed, 02 Aug 2023 12:08:57 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2212.14624v2</guid></item><item><title>Leveraging Few-Shot Data Augmentation and Waterfall Prompting for Response Generation</title><link>http://arxiv.org/abs/2308.01080v1</link><description>This paper discusses our approaches for task-oriented conversationalmodelling using subjective knowledge, with a particular emphasis on responsegeneration. Our methodology was shaped by an extensive data analysis thatevaluated key factors such as response length, sentiment, and dialogue actspresent in the provided dataset. We used few-shot learning to augment the datawith newly generated subjective knowledge items and present three approachesfor DSTC11: (1) task-specific model exploration, (2) incorporation of the mostfrequent question into all generated responses, and (3) a waterfall promptingtechnique using a combination of both GPT-3 and ChatGPT.</description><author>Lea Krause, Selene Báez Santamaría, Michiel van der Meer, Urja Khurana</author><pubDate>Wed, 02 Aug 2023 12:04:27 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2308.01080v1</guid></item><item><title>Sparse Graph Learning from Spatiotemporal Time Series</title><link>http://arxiv.org/abs/2205.13492v3</link><description>Outstanding achievements of graph neural networks for spatiotemporal timeseries analysis show that relational constraints introduce an effectiveinductive bias into neural forecasting architectures. Often, however, therelational information characterizing the underlying data-generating process isunavailable and the practitioner is left with the problem of inferring fromdata which relational graph to use in the subsequent processing stages. Wepropose novel, principled - yet practical - probabilistic score-based methodsthat learn the relational dependencies as distributions over graphs whilemaximizing end-to-end the performance at task. The proposed graph learningframework is based on consolidated variance reduction techniques for MonteCarlo score-based gradient estimation, is theoretically grounded, and, as weshow, effective in practice. In this paper, we focus on the time seriesforecasting problem and show that, by tailoring the gradient estimators to thegraph learning problem, we are able to achieve state-of-the-art performancewhile controlling the sparsity of the learned graph and the computationalscalability. We empirically assess the effectiveness of the proposed method onsynthetic and real-world benchmarks, showing that the proposed solution can beused as a stand-alone graph identification procedure as well as a graphlearning component of an end-to-end forecasting architecture.</description><author>Andrea Cini, Daniele Zambon, Cesare Alippi</author><pubDate>Wed, 02 Aug 2023 12:02:52 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2205.13492v3</guid></item><item><title>A Practical Deep Learning-Based Acoustic Side Channel Attack on Keyboards</title><link>http://arxiv.org/abs/2308.01074v1</link><description>With recent developments in deep learning, the ubiquity of micro-phones andthe rise in online services via personal devices, acoustic side channel attackspresent a greater threat to keyboards than ever. This paper presents apractical implementation of a state-of-the-art deep learning model in order toclassify laptop keystrokes, using a smartphone integrated microphone. Whentrained on keystrokes recorded by a nearby phone, the classifier achieved anaccuracy of 95%, the highest accuracy seen without the use of a language model.When trained on keystrokes recorded using the video-conferencing software Zoom,an accuracy of 93% was achieved, a new best for the medium. Our results provethe practicality of these side channel attacks via off-the-shelf equipment andalgorithms. We discuss a series of mitigation methods to protect users againstthese series of attacks.</description><author>Joshua Harrison, Ehsan Toreini, Maryam Mehrnezhad</author><pubDate>Wed, 02 Aug 2023 11:51:36 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2308.01074v1</guid></item><item><title>Domain knowledge-informed Synthetic fault sample generation with Health Data Map for cross-domain Planetary Gearbox Fault Diagnosis</title><link>http://arxiv.org/abs/2305.19569v3</link><description>Extensive research has been conducted on fault diagnosis of planetarygearboxes using vibration signals and deep learning (DL) approaches. However,DL-based methods are susceptible to the domain shift problem caused by varyingoperating conditions of the gearbox. Although domain adaptation and datasynthesis methods have been proposed to overcome such domain shifts, they areoften not directly applicable in real-world situations where only healthy datais available in the target domain. To tackle the challenge of extreme domainshift scenarios where only healthy data is available in the target domain, thispaper proposes two novel domain knowledge-informed data synthesis methodsutilizing the health data map (HDMap). The two proposed approaches are referredto as scaled CutPaste and FaultPaste. The HDMap is used to physically representthe vibration signal of the planetary gearbox as an image-like matrix, allowingfor visualization of fault-related features. CutPaste and FaultPaste are thenapplied to generate faulty samples based on the healthy data in the targetdomain, using domain knowledge and fault signatures extracted from the sourcedomain, respectively. In addition to generating realistic faults, the proposedmethods introduce scaling of fault signatures for controlled synthesis offaults with various severity levels. A case study is conducted on a planetarygearbox testbed to evaluate the proposed approaches. The results show that theproposed methods are capable of accurately diagnosing faults, even in cases ofextreme domain shift, and can estimate the severity of faults that have notbeen previously observed in the target domain.</description><author>Jong Moon Ha, Olga Fink</author><pubDate>Wed, 02 Aug 2023 11:49:31 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.19569v3</guid></item><item><title>Automatic Feature Engineering for Time Series Classification: Evaluation and Discussion</title><link>http://arxiv.org/abs/2308.01071v1</link><description>Time Series Classification (TSC) has received much attention in the past twodecades and is still a crucial and challenging problem in data science andknowledge engineering. Indeed, along with the increasing availability of timeseries data, many TSC algorithms have been suggested by the research communityin the literature. Besides state-of-the-art methods based on similaritymeasures, intervals, shapelets, dictionaries, deep learning methods or hybridensemble methods, several tools for extracting unsupervised informative summarystatistics, aka features, from time series have been designed in the recentyears. Originally designed for descriptive analysis and visualization of timeseries with informative and interpretable features, very few of these featureengineering tools have been benchmarked for TSC problems and compared withstate-of-the-art TSC algorithms in terms of predictive performance. In thisarticle, we aim at filling this gap and propose a simple TSC process toevaluate the potential predictive performance of the feature sets obtained withexisting feature engineering tools. Thus, we present an empirical study of 11feature engineering tools branched with 9 supervised classifiers over 112 timeseries data sets. The analysis of the results of more than 10000 learningexperiments indicate that feature-based methods perform as accurately ascurrent state-of-the-art TSC algorithms, and thus should rightfully beconsidered further in the TSC literature.</description><author>Aurélien Renault, Alexis Bondu, Vincent Lemaire, Dominique Gay</author><pubDate>Wed, 02 Aug 2023 11:46:42 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2308.01071v1</guid></item><item><title>When Analytic Calculus Cracks AdaBoost Code</title><link>http://arxiv.org/abs/2308.01070v1</link><description>The principle of boosting in supervised learning involves combining multipleweak classifiers to obtain a stronger classifier. AdaBoost has the reputationto be a perfect example of this approach. We have previously shown thatAdaBoost is not truly an optimization algorithm. This paper shows that AdaBoostis an algorithm in name only, as the resulting combination of weak classifierscan be explicitly calculated using a truth table. This study is carried out byconsidering a problem with two classes and is illustrated by the particularcase of three binary classifiers and presents results in comparison with thosefrom the implementation of AdaBoost algorithm of the Python libraryscikit-learn.</description><author>Jean-Marc Brossier, Olivier Lafitte, Lenny Réthoré</author><pubDate>Wed, 02 Aug 2023 11:37:25 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2308.01070v1</guid></item><item><title>Graph Anomaly Detection at Group Level: A Topology Pattern Enhanced Unsupervised Approach</title><link>http://arxiv.org/abs/2308.01063v1</link><description>Graph anomaly detection (GAD) has achieved success and has been widelyapplied in various domains, such as fraud detection, cybersecurity, financesecurity, and biochemistry. However, existing graph anomaly detectionalgorithms focus on distinguishing individual entities (nodes or graphs) andoverlook the possibility of anomalous groups within the graph. To address thislimitation, this paper introduces a novel unsupervised framework for a new taskcalled Group-level Graph Anomaly Detection (Gr-GAD). The proposed frameworkfirst employs a variant of Graph AutoEncoder (GAE) to locate anchor nodes thatbelong to potential anomaly groups by capturing long-range inconsistencies.Subsequently, group sampling is employed to sample candidate groups, which arethen fed into the proposed Topology Pattern-based Graph Contrastive Learning(TPGCL) method. TPGCL utilizes the topology patterns of groups as clues togenerate embeddings for each candidate group and thus distinct anomaly groups.The experimental results on both real-world and synthetic datasets demonstratethat the proposed framework shows superior performance in identifying andlocalizing anomaly groups, highlighting it as a promising solution for Gr-GAD.Datasets and codes of the proposed framework are at the github repositoryhttps://anonymous.4open.science/r/Topology-Pattern-Enhanced-Unsupervised-Group-level-Graph-Anomaly-Detection.</description><author>Xing Ai, Jialong Zhou, Yulin Zhu, Gaolei Li, Tomasz P. Michalak, Xiapu Luo, Kai Zhou</author><pubDate>Wed, 02 Aug 2023 11:22:04 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2308.01063v1</guid></item><item><title>Improving Generalization of Synthetically Trained Sonar Image Descriptors for Underwater Place Recognition</title><link>http://arxiv.org/abs/2308.01058v1</link><description>Autonomous navigation in underwater environments presents challenges due tofactors such as light absorption and water turbidity, limiting theeffectiveness of optical sensors. Sonar systems are commonly used forperception in underwater operations as they are unaffected by theselimitations. Traditional computer vision algorithms are less effective whenapplied to sonar-generated acoustic images, while convolutional neural networks(CNNs) typically require large amounts of labeled training data that are oftenunavailable or difficult to acquire. To this end, we propose a novel compactdeep sonar descriptor pipeline that can generalize to real scenarios whilebeing trained exclusively on synthetic data. Our architecture is based on aResNet18 back-end and a properly parameterized random Gaussian projectionlayer, whereas input sonar data is enhanced with standard ad-hocnormalization/prefiltering techniques. A customized synthetic data generationprocedure is also presented. The proposed method has been evaluated extensivelyusing both synthetic and publicly available real data, demonstrating itseffectiveness compared to state-of-the-art methods.</description><author>Ivano Donadi, Emilio Olivastri, Daniel Fusaro, Wanmeng Li, Daniele Evangelista, Alberto Pretto</author><pubDate>Wed, 02 Aug 2023 11:10:25 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2308.01058v1</guid></item><item><title>MammoDG: Generalisable Deep Learning Breaks the Limits of Cross-Domain Multi-Center Breast Cancer Screening</title><link>http://arxiv.org/abs/2308.01057v1</link><description>Breast cancer is a major cause of cancer death among women, emphasising theimportance of early detection for improved treatment outcomes and quality oflife. Mammography, the primary diagnostic imaging test, poses challenges due tothe high variability and patterns in mammograms. Double reading of mammogramsis recommended in many screening programs to improve diagnostic accuracy butincreases radiologists' workload. Researchers explore Machine Learning modelsto support expert decision-making. Stand-alone models have shown comparable orsuperior performance to radiologists, but some studies note decreasedsensitivity with multiple datasets, indicating the need for high generalisationand robustness models. This work devises MammoDG, a novel deep-learningframework for generalisable and reliable analysis of cross-domain multi-centermammography data. MammoDG leverages multi-view mammograms and a novelcontrastive mechanism to enhance generalisation capabilities. Extensivevalidation demonstrates MammoDG's superiority, highlighting the criticalimportance of domain generalisation for trustworthy mammography analysis inimaging protocol variations.</description><author>Yijun Yang, Shujun Wang, Lihao Liu, Sarah Hickman, Fiona J Gilbert, Carola-Bibiane Schönlieb, Angelica I. Aviles-Rivero</author><pubDate>Wed, 02 Aug 2023 11:10:22 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2308.01057v1</guid></item><item><title>Simulation-based inference using surjective sequential neural likelihood estimation</title><link>http://arxiv.org/abs/2308.01054v1</link><description>We present Surjective Sequential Neural Likelihood (SSNL) estimation, a novelmethod for simulation-based inference in models where the evaluation of thelikelihood function is not tractable and only a simulator that can generatesynthetic data is available. SSNL fits a dimensionality-reducing surjectivenormalizing flow model and uses it as a surrogate likelihood function whichallows for conventional Bayesian inference using either Markov chain MonteCarlo methods or variational inference. By embedding the data in alow-dimensional space, SSNL solves several issues previous likelihood-basedmethods had when applied to high-dimensional data sets that, for instance,contain non-informative data dimensions or lie along a lower-dimensionalmanifold. We evaluate SSNL on a wide variety of experiments and show that itgenerally outperforms contemporary methods used in simulation-based inference,for instance, on a challenging real-world example from astrophysics whichmodels the magnetic field strength of the sun using a solar dynamo model.</description><author>Simon Dirmeier, Carlo Albert, Fernando Perez-Cruz</author><pubDate>Wed, 02 Aug 2023 11:02:38 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2308.01054v1</guid></item><item><title>A Counterfactual Safety Margin Perspective on the Scoring of Autonomous Vehicles' Riskiness</title><link>http://arxiv.org/abs/2308.01050v1</link><description>Autonomous Vehicles (AVs) have the potential to provide numerous societalbenefits, such as decreased road accidents and increased overall transportationefficiency. However, quantifying the risk associated with AVs is challengingdue to the lack of historical data and the rapidly evolving technology. Thispaper presents a data-driven framework for comparing the risk of different AVs'behaviors in various operational design domains (ODDs), based on counterfactualsimulations of "misbehaving" road users. We introduce the concept ofcounterfactual safety margin, which represents the minimum deviation fromnormal behavior that could lead to a collision. This concept helps to find themost critical scenarios but also to assess the frequency and severity of riskof AVs. We show that the proposed methodology is applicable even when the AV'sbehavioral policy is unknown -- through worst- and best-case analyses -- makingthe method useful also to external third-party risk assessors. Our experimentalresults demonstrate the correlation between the safety margin, the drivingpolicy quality, and the ODD shedding light on the relative risk associated withdifferent AV providers. This work contributes to AV safety assessment and aidsin addressing legislative and insurance concerns surrounding this emergingtechnology.</description><author>Alessandro Zanardi, Andrea Censi, Margherita Atzei, Luigi Di Lillo, Emilio Frazzoli</author><pubDate>Wed, 02 Aug 2023 10:48:08 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2308.01050v1</guid></item><item><title>Decoupled Diffusion Models with Explicit Transition Probability</title><link>http://arxiv.org/abs/2306.13720v3</link><description>Recent diffusion probabilistic models (DPMs) have shown remarkable abilitiesof generated content, however, they often suffer from complex forwardprocesses, resulting in inefficient solutions for the reversed process andprolonged sampling times. In this paper, we aim to address the aforementionedchallenges by focusing on the diffusion process itself that we propose todecouple the intricate diffusion process into two comparatively simpler processto improve the generative efficacy and speed. In particular, we present a noveldiffusion paradigm named DDM (Decoupled Diffusion Models) based on the Itodiffusion process, in which the image distribution is approximated by anexplicit transition probability while the noise path is controlled by thestandard Wiener process. We find that decoupling the diffusion process reducesthe learning difficulty and the explicit transition probability improves thegenerative speed significantly. We prove a new training objective for DPM,which enables the model to learn to predict the noise and image componentsseparately. Moreover, given the novel forward diffusion equation, we derive thereverse denoising formula of DDM that naturally supports fewer steps ofgeneration without ordinary differential equation (ODE) based accelerators. Ourexperiments demonstrate that DDM outperforms previous DPMs by a large margin infewer function evaluations setting and gets comparable performances in longfunction evaluations setting. We also show that our framework can be applied toimage-conditioned generation and high-resolution image synthesis, and that itcan generate high-quality images with only 10 function evaluations.</description><author>Yuhang Huang, Zheng Qin, Xinwang Liu, Kai Xu</author><pubDate>Wed, 02 Aug 2023 10:44:43 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.13720v3</guid></item><item><title>Attention for Robot Touch: Tactile Saliency Prediction for Robust Sim-to-Real Tactile Control</title><link>http://arxiv.org/abs/2307.14510v2</link><description>High-resolution tactile sensing can provide accurate information about localcontact in contact-rich robotic tasks. However, the deployment of such tasks inunstructured environments remains under-investigated. To improve the robustnessof tactile robot control in unstructured environments, we propose and study anew concept: \textit{tactile saliency} for robot touch, inspired by the humantouch attention mechanism from neuroscience and the visual saliency predictionproblem from computer vision. In analogy to visual saliency, this conceptinvolves identifying key information in tactile images captured by a tactilesensor. While visual saliency datasets are commonly annotated by humans,manually labelling tactile images is challenging due to their counterintuitivepatterns. To address this challenge, we propose a novel approach comprised ofthree interrelated networks: 1) a Contact Depth Network (ConDepNet), whichgenerates a contact depth map to localize deformation in a real tactile imagethat contains target and noise features; 2) a Tactile Saliency Network(TacSalNet), which predicts a tactile saliency map to describe the target areasfor an input contact depth map; 3) and a Tactile Noise Generator (TacNGen),which generates noise features to train the TacSalNet. Experimental results incontact pose estimation and edge-following in the presence of distractorsshowcase the accurate prediction of target features from real tactile images.Overall, our tactile saliency prediction approach gives robust sim-to-realtactile control in environments with unknown distractors. Project page:https://sites.google.com/view/tactile-saliency/.</description><author>Yijiong Lin, Mauro Comi, Alex Church, Dandan Zhang, Nathan F. Lepora</author><pubDate>Wed, 02 Aug 2023 10:42:58 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.14510v2</guid></item><item><title>Transformer and Snowball Graph Convolution Learning for Brain functional network Classification</title><link>http://arxiv.org/abs/2303.16132v3</link><description>Advanced deep learning methods, especially graph neural networks (GNNs), areincreasingly expected to learn from brain functional network data and predictbrain disorders. In this paper, we proposed a novel Transformer and snowballencoding networks (TSEN) for brain functional network classification, whichintroduced Transformer architecture with graph snowball connection into GNNsfor learning whole-graph representation. TSEN combined graph snowballconnection with graph Transformer by snowball encoding layers, which enhancedthe power to capture multi-scale information and global patterns of brainfunctional networks. TSEN also introduced snowball graph convolution asposition embedding in Transformer structure, which was a simple yet effectivemethod for capturing local patterns naturally. We evaluated the proposed modelby two large-scale brain functional network datasets from autism spectrumdisorder and major depressive disorder respectively, and the resultsdemonstrated that TSEN outperformed the state-of-the-art GNN models and thegraph-transformer based GNN models.</description><author>Jinlong Hu, Yangmin Huang, Shoubin Dong</author><pubDate>Wed, 02 Aug 2023 10:42:46 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2303.16132v3</guid></item></channel></rss>