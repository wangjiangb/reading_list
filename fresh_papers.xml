<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/"><channel><title>Arxivfresh papers</title><link></link><description>Arxiv paper</description><language>en-US</language><lastBuildDate>Mon, 29 May 2023 14:00:03 GMT</lastBuildDate><generator>rfeed v1.0.0</generator><docs>https://github.com/svpino/rfeed/blob/master/README.md</docs><item><title>Are We Really Making Much Progress in Text Classification? A Comparative Review</title><link>http://arxiv.org/abs/2204.03954v4</link><description>This study reviews and compares methods for single-label and multi-label textclassification, categorized into bag-of-words, sequence-based, graph-based, andhierarchical methods. The comparison aggregates results from the literatureover five single-label and seven multi-label datasets and complements them withnew experiments. The findings reveal that all recently proposed graph-based andhierarchy-based methods fail to outperform pre-trained language models andsometimes perform worse than standard machine learning methods like amultilayer perceptron on a bag-of-words. To assess the true scientific progressin text classification, future work should thoroughly test against strongbag-of-words baselines and state-of-the-art pre-trained language models.</description><author>Lukas Galke, Andor Diera, Bao Xin Lin, Bhakti Khera, Tim Meuser, Tushar Singhal, Fabian Karl, Ansgar Scherp</author><pubDate>Fri, 26 May 2023 18:59:37 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2204.03954v4</guid></item><item><title>Towards Reasoning in Large Language Models: A Survey</title><link>http://arxiv.org/abs/2212.10403v2</link><description>Reasoning is a fundamental aspect of human intelligence that plays a crucialrole in activities such as problem solving, decision making, and criticalthinking. In recent years, large language models (LLMs) have made significantprogress in natural language processing, and there is observation that thesemodels may exhibit reasoning abilities when they are sufficiently large.However, it is not yet clear to what extent LLMs are capable of reasoning. Thispaper provides a comprehensive overview of the current state of knowledge onreasoning in LLMs, including techniques for improving and eliciting reasoningin these models, methods and benchmarks for evaluating reasoning abilities,findings and implications of previous research in this field, and suggestionson future directions. Our aim is to provide a detailed and up-to-date review ofthis topic and stimulate meaningful discussion and future work.</description><author>Jie Huang, Kevin Chen-Chuan Chang</author><pubDate>Fri, 26 May 2023 18:59:33 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2212.10403v2</guid></item><item><title>NeuManifold: Neural Watertight Manifold Reconstruction with Efficient and High-Quality Rendering Support</title><link>http://arxiv.org/abs/2305.17134v1</link><description>We present a method for generating high-quality watertight manifold meshesfrom multi-view input images. Existing volumetric rendering methods are robustin optimization but tend to generate noisy meshes with poor topology.Differentiable rasterization-based methods can generate high-quality meshes butare sensitive to initialization. Our method combines the benefits of bothworlds; we take the geometry initialization obtained from neural volumetricfields, and further optimize the geometry as well as a compact neural texturerepresentation with differentiable rasterizers. Through extensive experiments,we demonstrate that our method can generate accurate mesh reconstructions withfaithful appearance that are comparable to previous volume rendering methodswhile being an order of magnitude faster in rendering. We also show that ourgenerated mesh and neural texture reconstruction is compatible with existinggraphics pipelines and enables downstream 3D applications such as simulation.Project page: https://sarahweiii.github.io/neumanifold/</description><author>Xinyue Wei, Fanbo Xiang, Sai Bi, Anpei Chen, Kalyan Sunkavalli, Zexiang Xu, Hao Su</author><pubDate>Fri, 26 May 2023 18:59:21 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.17134v1</guid></item><item><title>The Shrinkage-Delinkage Trade-off: An Analysis of Factorized Gaussian Approximations for Variational Inference</title><link>http://arxiv.org/abs/2302.09163v3</link><description>When factorized approximations are used for variational inference (VI), theytend to underestimate the uncertainty -- as measured in various ways -- of thedistributions they are meant to approximate. We consider two popular ways tomeasure the uncertainty deficit of VI: (i) the degree to which itunderestimates the componentwise variance, and (ii) the degree to which itunderestimates the entropy. To better understand these effects, and therelationship between them, we examine an informative setting where they can beexplicitly (and elegantly) analyzed: the approximation of a Gaussian,~$p$, witha dense covariance matrix, by a Gaussian,~$q$, with a diagonal covariancematrix. We prove that $q$ always underestimates both the componentwise varianceand the entropy of $p$, \textit{though not necessarily to the same degree}.Moreover we demonstrate that the entropy of $q$ is determined by the trade-offof two competing forces: it is decreased by the shrinkage of its componentwisevariances (our first measure of uncertainty) but it is increased by thefactorized approximation which delinks the nodes in the graphical model of $p$.We study various manifestations of this trade-off, notably one where, as thedimension of the problem grows, the per-component entropy gap between $p$ and$q$ becomes vanishingly small even though $q$ underestimates everycomponentwise variance by a constant multiplicative factor. We also use theshrinkage-delinkage trade-off to bound the entropy gap in terms of the problemdimension and the condition number of the correlation matrix of $p$. Finally wepresent empirical results on both Gaussian and non-Gaussian targets, the formerto validate our analysis and the latter to explore its limitations.</description><author>Charles C. Margossian, Lawrence K. Saul</author><pubDate>Fri, 26 May 2023 18:58:48 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2302.09163v3</guid></item><item><title>RAMP: Retrieval and Attribute-Marking Enhanced Prompting for Attribute-Controlled Translation</title><link>http://arxiv.org/abs/2305.17131v1</link><description>Attribute-controlled translation (ACT) is a subtask of machine translationthat involves controlling stylistic or linguistic attributes (like formalityand gender) of translation outputs. While ACT has garnered attention in recentyears due to its usefulness in real-world applications, progress in the task iscurrently limited by dataset availability, since most prior approaches rely onsupervised methods. To address this limitation, we propose Retrieval andAttribute-Marking enhanced Prompting (RAMP), which leverages large multilinguallanguage models to perform ACT in few-shot and zero-shot settings. RAMPimproves generation accuracy over the standard prompting approach by (1)incorporating a semantic similarity retrieval component for selecting similarin-context examples, and (2) marking in-context examples with attributeannotations. Our comprehensive experiments show that RAMP is a viable approachin both zero-shot and few-shot settings.</description><author>Gabriele Sarti, Phu Mon Htut, Xing Niu, Benjamin Hsu, Anna Currey, Georgiana Dinu, Maria Nadejde</author><pubDate>Fri, 26 May 2023 18:56:53 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.17131v1</guid></item><item><title>Characterizing and Measuring Linguistic Dataset Drift</title><link>http://arxiv.org/abs/2305.17127v1</link><description>NLP models often degrade in performance when real world data distributionsdiffer markedly from training data. However, existing dataset drift metrics inNLP have generally not considered specific dimensions of linguistic drift thataffect model performance, and they have not been validated in their ability topredict model performance at the individual example level, where such metricsare often used in practice. In this paper, we propose three dimensions oflinguistic dataset drift: vocabulary, structural, and semantic drift. Thesedimensions correspond to content word frequency divergences, syntacticdivergences, and meaning changes not captured by word frequencies (e.g. lexicalsemantic change). We propose interpretable metrics for all three driftdimensions, and we modify past performance prediction methods to predict modelperformance at both the example and dataset level for English sentimentclassification and natural language inference. We find that our drift metricsare more effective than previous metrics at predicting out-of-domain modelaccuracies (mean 16.8% root mean square error decrease), particularly whencompared to popular fine-tuned embedding distances (mean 47.7% error decrease).Fine-tuned embedding distances are much more effective at ranking individualexamples by expected performance, but decomposing into vocabulary, structural,and semantic drift produces the best example rankings of all consideredmodel-agnostic drift metrics (mean 6.7% ROC AUC increase).</description><author>Tyler A. Chang, Kishaloy Halder, Neha Anna John, Yogarshi Vyas, Yassine Benajiba, Miguel Ballesteros, Dan Roth</author><pubDate>Fri, 26 May 2023 18:50:51 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.17127v1</guid></item><item><title>Large Language Models as Tool Makers</title><link>http://arxiv.org/abs/2305.17126v1</link><description>Recent research shows the potential of enhancing the problem-solving abilityof large language models (LLMs) through the use of external tools. However,prior work along this line depends on the availability of existing tools. Inthis work, we take an initial step towards removing this dependency byproposing a closed-loop framework, referred to as LLMs As Tool Makers (LATM),where LLMs create their own reusable tools for problem-solving. Our approachconsists of two key phases: 1) tool making: an LLM acts as the tool maker thatcrafts tools for given tasks, where a tool is implemented as a Python utilityfunction. 2) tool using: an LLM acts as the tool user, which applies the toolbuilt by the tool maker for problem-solving. The tool user can be either thesame or a different LLM from the tool maker. Tool-making enables an LLM tocontinually generate tools that can be applied to different requests so thatfuture requests can call the corresponding APIs when beneficial for solving thetasks. Furthermore, the division of labor among LLMs for tool-making andtool-using phases introduces the opportunity to achieve cost effectivenesswithout degrading the quality of generated tools and problem solutions. Forexample, recognizing that tool-making demands more sophisticated capabilitiesthan tool-using, we can apply a powerful yet resource-intensive model as thetool maker, and a lightweight while cost-effective model as the tool user. Wevalidate the effectiveness of our approach across a variety of complexreasoning tasks, including Big-Bench tasks. With GPT-4 as the tool maker andGPT-3.5 as the tool user, LATM can achieve performance that is on par withusing GPT-4 for both tool making and tool using, while the inference cost issignificantly reduced.</description><author>Tianle Cai, Xuezhi Wang, Tengyu Ma, Xinyun Chen, Denny Zhou</author><pubDate>Fri, 26 May 2023 18:50:11 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.17126v1</guid></item><item><title>Sequence Modeling is a Robust Contender for Offline Reinforcement Learning</title><link>http://arxiv.org/abs/2305.14550v2</link><description>Offline reinforcement learning (RL) allows agents to learn effective,return-maximizing policies from a static dataset. Three major paradigms foroffline RL are Q-Learning, Imitation Learning, and Sequence Modeling. A keyopen question is: which paradigm is preferred under what conditions? We studythis question empirically by exploring the performance of representativealgorithms -- Conservative Q-Learning (CQL), Behavior Cloning (BC), andDecision Transformer (DT) -- across the commonly used D4RL and Robomimicbenchmarks. We design targeted experiments to understand their behaviorconcerning data suboptimality and task complexity. Our key findings are: (1)Sequence Modeling requires more data than Q-Learning to learn competitivepolicies but is more robust; (2) Sequence Modeling is a substantially betterchoice than both Q-Learning and Imitation Learning in sparse-reward andlow-quality data settings; and (3) Sequence Modeling and Imitation Learning arepreferable as task horizon increases, or when data is obtained from humandemonstrators. Based on the overall strength of Sequence Modeling, we alsoinvestigate architectural choices and scaling trends for DT on Atari and D4RLand make design recommendations. We find that scaling the amount of data for DTby 5x gives a 2.5x average score improvement on Atari.</description><author>Prajjwal Bhargava, Rohan Chitnis, Alborz Geramifard, Shagun Sodhani, Amy Zhang</author><pubDate>Fri, 26 May 2023 18:48:31 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.14550v2</guid></item><item><title>UNITE: A Unified Benchmark for Text-to-SQL Evaluation</title><link>http://arxiv.org/abs/2305.16265v2</link><description>A practical text-to-SQL system should generalize well on a wide variety ofnatural language questions, unseen database schemas, and novel SQL querystructures. To comprehensively evaluate text-to-SQL systems, we introduce a\textbf{UNI}fied benchmark for \textbf{T}ext-to-SQL \textbf{E}valuation(UNITE). It is composed of publicly available text-to-SQL datasets, containingnatural language questions from more than 12 domains, SQL queries from morethan 3.9K patterns, and 29K databases. Compared to the widely used Spiderbenchmark \cite{yu-etal-2018-spider}, we introduce $\sim$120K additionalexamples and a threefold increase in SQL patterns, such as comparative andboolean questions. We conduct a systematic study of six state-of-the-art (SOTA)text-to-SQL parsers on our new benchmark and show that: 1) Codex performssurprisingly well on out-of-domain datasets; 2) specially designed decodingmethods (e.g. constrained beam search) can improve performance for bothin-domain and out-of-domain settings; 3) explicitly modeling the relationshipbetween questions and schemas further improves the Seq2Seq models. Moreimportantly, our benchmark presents key challenges towards compositionalgeneralization and robustness issues -- which these SOTA models cannot addresswell. \footnote{Our code and data processing script will be available at\url{https://github.com/XXXX.}}</description><author>Wuwei Lan, Zhiguo Wang, Anuj Chauhan, Henghui Zhu, Alexander Li, Jiang Guo, Sheng Zhang, Chung-Wei Hang, Joseph Lilien, Yiqun Hu, Lin Pan, Mingwen Dong, Jun Wang, Jiarong Jiang, Stephen Ash, Vittorio Castelli, Patrick Ng, Bing Xiang</author><pubDate>Fri, 26 May 2023 18:43:07 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.16265v2</guid></item><item><title>Investigation of Proper Orthogonal Decomposition for Echo State Networks</title><link>http://arxiv.org/abs/2211.17179v3</link><description>Echo State Networks (ESN) are a type of Recurrent Neural Network that yieldspromising results in representing time series and nonlinear dynamic systems.Although they are equipped with a very efficient training procedure, ReservoirComputing strategies, such as the ESN, require high-order networks, i.e., manyneurons, resulting in a large number of states that are magnitudes higher thanthe number of model inputs and outputs. A large number of states not only makesthe time-step computation more costly but also may pose robustness issues,especially when applying ESNs to problems such as Model Predictive Control(MPC) and other optimal control problems. One way to circumvent this complexityissue is through Model Order Reduction strategies such as the Proper OrthogonalDecomposition (POD) and its variants (POD-DEIM), whereby we find an equivalentlower order representation to an already trained high dimension ESN. To thisend, this work aims to investigate and analyze the performance of POD methodsin Echo State Networks, evaluating their effectiveness through the MemoryCapacity (MC) of the POD-reduced network compared to the original (full-order)ESN. We also perform experiments on two numerical case studies: a NARMA10difference equation and an oil platform containing two wells and one riser. Theresults show that there is little loss of performance comparing the originalESN to a POD-reduced counterpart and that the performance of a POD-reduced ESNtends to be superior to a normal ESN of the same size. Also, the POD-reducednetwork achieves speedups of around $80\%$ compared to the original ESN.</description><author>Jean Panaioti Jordanou, Eric Aislan Antonelo, Eduardo Camponogara, Eduardo Gildin</author><pubDate>Fri, 26 May 2023 18:41:25 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2211.17179v3</guid></item><item><title>Manifold Regularization for Memory-Efficient Training of Deep Neural Networks</title><link>http://arxiv.org/abs/2305.17119v1</link><description>One of the prevailing trends in the machine- and deep-learning community isto gravitate towards the use of increasingly larger models in order to keeppushing the state-of-the-art performance envelope. This tendency makes accessto the associated technologies more difficult for the average practitioner andruns contrary to the desire to democratize knowledge production in the field.In this paper, we propose a framework for achieving improved memory efficiencyin the process of learning traditional neural networks by leveraginginductive-bias-driven network design principles and layer-wisemanifold-oriented regularization objectives. Use of the framework results inimproved absolute performance and empirical generalization error relative totraditional learning techniques. We provide empirical validation of theframework, including qualitative and quantitative evidence of its effectivenesson two standard image datasets, namely CIFAR-10 and CIFAR-100. The proposedframework can be seamlessly combined with existing network compression methodsfor further memory savings.</description><author>Shadi Sartipi, Edgar A. Bernal</author><pubDate>Fri, 26 May 2023 18:40:15 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.17119v1</guid></item><item><title>Scissorhands: Exploiting the Persistence of Importance Hypothesis for LLM KV Cache Compression at Test Time</title><link>http://arxiv.org/abs/2305.17118v1</link><description>Large language models(LLMs) have sparked a new wave of exciting AIapplications. Hosting these models at scale requires significant memoryresources. One crucial memory bottleneck for the deployment stems from thecontext window. It is commonly recognized that model weights are memory hungry;however, the size of key-value embedding stored during the generation process(KV cache) can easily surpass the model size. The enormous size of the KV cacheputs constraints on the inference batch size, which is crucial for highthroughput inference workload. Inspired by an interesting observation of theattention scores, we hypothesize the persistence of importance: only pivotaltokens, which had a substantial influence at one step, will significantlyinfluence future generations. Based on our empirical verification andtheoretical analysis around this hypothesis, we propose Scissorhands, a systemthat maintains the memory usage of the KV cache at a fixed budget withoutfinetuning the model. In essence, Scissorhands manages the KV cache by storingthe pivotal tokens with a higher probability. We validate that Scissorhandsreduces the inference memory usage of the KV cache by up to 5X withoutcompromising model quality. We further demonstrate that Scissorhands can becombined with 4-bit quantization, traditionally used to compress model weights,to achieve up to 20X compression.</description><author>Zichang Liu, Aditya Desai, Fangshuo Liao, Weitao Wang, Victor Xie, Zhaozhuo Xu, Anastasios Kyrillidis, Anshumali Shrivastava</author><pubDate>Fri, 26 May 2023 18:39:58 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.17118v1</guid></item><item><title>Improving accuracy of GPT-3/4 results on biomedical data using a retrieval-augmented language model</title><link>http://arxiv.org/abs/2305.17116v1</link><description>Large language models (LLMs) have made significant advancements in naturallanguage processing (NLP). Broad corpora capture diverse patterns but canintroduce irrelevance, while focused corpora enhance reliability by reducingmisleading information. Training LLMs on focused corpora poses computationalchallenges. An alternative approach is to use a retrieval-augmentation (RetA)method tested in a specific domain. To evaluate LLM performance, OpenAI's GPT-3, GPT-4, Bing's Prometheus, and acustom RetA model were compared using 19 questions on diffuse large B-celllymphoma (DLBCL) disease. Eight independent reviewers assessed responses basedon accuracy, relevance, and readability (rated 1-3). The RetA model performed best in accuracy (12/19 3-point scores, total=47)and relevance (13/19, 50), followed by GPT-4 (8/19, 43; 11/19, 49). GPT-4received the highest readability scores (17/19, 55), followed by GPT-3 (15/19,53) and the RetA model (11/19, 47). Prometheus underperformed in accuracy (34),relevance (32), and readability (38). Both GPT-3.5 and GPT-4 had more hallucinations in all 19 responses comparedto the RetA model and Prometheus. Hallucinations were mostly associated withnon-existent references or fabricated efficacy data. These findings suggest that RetA models, supplemented with domain-specificcorpora, may outperform general-purpose LLMs in accuracy and relevance withinspecific domains. However, this evaluation was limited to specific questionsand metrics and may not capture challenges in semantic search and other NLPtasks. Further research will explore different LLM architectures, RetAmethodologies, and evaluation methods to assess strengths and limitations morecomprehensively.</description><author>David Soong, Sriram Sridhar, Han Si, Jan-Samuel Wagner, Ana Caroline Costa Sá, Christina Y Yu, Kubra Karagoz, Meijian Guan, Hisham Hamadeh, Brandon W Higgs</author><pubDate>Fri, 26 May 2023 18:33:05 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.17116v1</guid></item><item><title>Policy Synthesis and Reinforcement Learning for Discounted LTL</title><link>http://arxiv.org/abs/2305.17115v1</link><description>The difficulty of manually specifying reward functions has led to an interestin using linear temporal logic (LTL) to express objectives for reinforcementlearning (RL). However, LTL has the downside that it is sensitive to smallperturbations in the transition probabilities, which prevents probablyapproximately correct (PAC) learning without additional assumptions. Timediscounting provides a way of removing this sensitivity, while retaining thehigh expressivity of the logic. We study the use of discounted LTL for policysynthesis in Markov decision processes with unknown transition probabilities,and show how to reduce discounted LTL to discounted-sum reward via a rewardmachine when all discount factors are identical.</description><author>Rajeev Alur, Osbert Bastani, Kishor Jothimurugan, Mateo Perez, Fabio Somenzi, Ashutosh Trivedi</author><pubDate>Fri, 26 May 2023 18:32:38 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.17115v1</guid></item><item><title>DIONYSUS: A Pre-trained Model for Low-Resource Dialogue Summarization</title><link>http://arxiv.org/abs/2212.10018v2</link><description>Dialogue summarization has recently garnered significant attention due to itswide range of applications. However, existing methods for summarizing dialogueshave limitations because they do not take into account the inherent structureof dialogue and rely heavily on labeled data, which can lead to poorperformance in new domains. In this work, we propose DIONYSUS (dynamic inputoptimization in pre-training for dialogue summarization), a pre-trainedencoder-decoder model for summarizing dialogues in any new domain. To pre-trainDIONYSUS, we create two pseudo summaries for each dialogue example: one isproduced by a fine-tuned summarization model, and the other is a collection ofdialogue turns that convey important information. We then choose one of thesepseudo summaries based on the difference in information distribution acrossdifferent types of dialogues. This selected pseudo summary serves as theobjective for pre-training DIONYSUS using a self-supervised approach on a largedialogue corpus. Our experiments show that DIONYSUS outperforms existingmethods on six datasets, as demonstrated by its ROUGE scores in zero-shot andfew-shot settings.</description><author>Yu Li, Baolin Peng, Pengcheng He, Michel Galley, Zhou Yu, Jianfeng Gao</author><pubDate>Fri, 26 May 2023 18:29:01 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2212.10018v2</guid></item><item><title>Chain-of-Skills: A Configurable Model for Open-domain Question Answering</title><link>http://arxiv.org/abs/2305.03130v2</link><description>The retrieval model is an indispensable component for real-worldknowledge-intensive tasks, e.g., open-domain question answering (ODQA). Asseparate retrieval skills are annotated for different datasets, recent workfocuses on customized methods, limiting the model transferability andscalability. In this work, we propose a modular retriever where individualmodules correspond to key skills that can be reused across datasets. Ourapproach supports flexible skill configurations based on the target domain toboost performance. To mitigate task interference, we design a novelmodularization parameterization inspired by sparse Transformer. We demonstratethat our model can benefit from self-supervised pretraining on Wikipedia andfine-tuning using multiple ODQA datasets, both in a multi-task fashion. Ourapproach outperforms recent self-supervised retrievers in zero-shot evaluationsand achieves state-of-the-art fine-tuned retrieval performance on NQ, HotpotQAand OTT-QA.</description><author>Kaixin Ma, Hao Cheng, Yu Zhang, Xiaodong Liu, Eric Nyberg, Jianfeng Gao</author><pubDate>Fri, 26 May 2023 18:19:58 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.03130v2</guid></item><item><title>Unifying gradient regularization for Heterogeneous Graph Neural Networks</title><link>http://arxiv.org/abs/2305.15811v2</link><description>Heterogeneous Graph Neural Networks (HGNNs) are a class of powerful deeplearning methods widely used to learn representations of heterogeneous graphs.Despite the fast development of HGNNs, they still face some challenges such asover-smoothing, and non-robustness. Previous studies have shown that theseproblems can be reduced by using gradient regularization methods. However, theexisting gradient regularization methods focus on either graph topology or nodefeatures. There is no universal approach to integrate these features, whichseverely affects the efficiency of regularization. In addition, the inclusionof gradient regularization into HGNNs sometimes leads to some problems, such asan unstable training process, increased complexity and insufficient coverageregularized information. Furthermore, there is still short of a completetheoretical analysis of the effects of gradient regularization on HGNNs. Inthis paper, we propose a novel gradient regularization method called Grug,which iteratively applies regularization to the gradients generated by bothpropagated messages and the node features during the message-passing process.Grug provides a unified framework integrating graph topology and node features,based on which we conduct a detailed theoretical analysis of theireffectiveness. Specifically, the theoretical analyses elaborate the advantagesof Grug: 1) Decreasing sample variance during the training process (Stability);2) Enhancing the generalization of the model (Universality); 3) Reducing thecomplexity of the model (Simplicity); 4) Improving the integrity and diversityof graph information utilization (Diversity). As a result, Grug has thepotential to surpass the theoretical upper bounds set by DropMessage (AAAI-23Distinguished Papers). In addition, we evaluate Grug on five public real-worlddatasets with two downstream tasks...</description><author>Xiao Yang, Xuejiao Zhao, Zhiqi Shen</author><pubDate>Fri, 26 May 2023 18:19:52 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.15811v2</guid></item><item><title>A dynamic programming algorithm for span-based nested named-entity recognition in O(n^2)</title><link>http://arxiv.org/abs/2210.04738v2</link><description>Span-based nested named-entity recognition (NER) has a cubic-time complexityusing a variant of the CYK algorithm. We show that by adding a supplementarystructural constraint on the search space, nested NER has a quadratic-timecomplexity, that is the same asymptotic complexity than the non-nested case.The proposed algorithm covers a large part of three standard English benchmarksand delivers comparable experimental results.</description><author>Caio Corro</author><pubDate>Fri, 26 May 2023 18:19:34 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2210.04738v2</guid></item><item><title>Reinforcement Learning with Simple Sequence Priors</title><link>http://arxiv.org/abs/2305.17109v1</link><description>Everything else being equal, simpler models should be preferred over morecomplex ones. In reinforcement learning (RL), simplicity is typicallyquantified on an action-by-action basis -- but this timescale ignores temporalregularities, like repetitions, often present in sequential strategies. Wetherefore propose an RL algorithm that learns to solve tasks with sequences ofactions that are compressible. We explore two possible sources of simple actionsequences: Sequences that can be learned by autoregressive models, andsequences that are compressible with off-the-shelf data compression algorithms.Distilling these preferences into sequence priors, we derive a novelinformation-theoretic objective that incentivizes agents to learn policies thatmaximize rewards while conforming to these priors. We show that the resultingRL algorithm leads to faster learning, and attains higher returns thanstate-of-the-art model-free approaches in a series of continuous control tasksfrom the DeepMind Control Suite. These priors also produce a powerfulinformation-regularized agent that is robust to noisy observations and canperform open-loop control.</description><author>Tankred Saanum, Noémi Éltető, Peter Dayan, Marcel Binz, Eric Schulz</author><pubDate>Fri, 26 May 2023 18:18:14 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.17109v1</guid></item><item><title>Random-Access Neural Compression of Material Textures</title><link>http://arxiv.org/abs/2305.17105v1</link><description>The continuous advancement of photorealism in rendering is accompanied by agrowth in texture data and, consequently, increasing storage and memorydemands. To address this issue, we propose a novel neural compression techniquespecifically designed for material textures. We unlock two more levels ofdetail, i.e., 16x more texels, using low bitrate compression, with imagequality that is better than advanced image compression techniques, such as AVIFand JPEG XL. At the same time, our method allows on-demand, real-timedecompression with random access similar to block texture compression on GPUs,enabling compression on disk and memory. The key idea behind our approach iscompressing multiple material textures and their mipmap chains together, andusing a small neural network, that is optimized for each material, todecompress them. Finally, we use a custom training implementation to achievepractical compression speeds, whose performance surpasses that of generalframeworks, like PyTorch, by an order of magnitude.</description><author>Karthik Vaidyanathan, Marco Salvi, Bartlomiej Wronski, Tomas Akenine-Möller, Pontus Ebelin, Aaron Lefohn</author><pubDate>Fri, 26 May 2023 18:16:22 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.17105v1</guid></item><item><title>PromptNER: Prompt Locating and Typing for Named Entity Recognition</title><link>http://arxiv.org/abs/2305.17104v1</link><description>Prompt learning is a new paradigm for utilizing pre-trained language modelsand has achieved great success in many tasks. To adopt prompt learning in theNER task, two kinds of methods have been explored from a pair of symmetricperspectives, populating the template by enumerating spans to predict theirentity types or constructing type-specific prompts to locate entities. However,these methods not only require a multi-round prompting manner with a high timeoverhead and computational cost, but also require elaborate prompt templates,that are difficult to apply in practical scenarios. In this paper, we unifyentity locating and entity typing into prompt learning, and design a dual-slotmulti-prompt template with the position slot and type slot to prompt locatingand typing respectively. Multiple prompts can be input to the modelsimultaneously, and then the model extracts all entities by parallelpredictions on the slots. To assign labels for the slots during training, wedesign a dynamic template filling mechanism that uses the extended bipartitegraph matching between prompts and the ground-truth entities. We conductexperiments in various settings, including resource-rich flat and nested NERdatasets and low-resource in-domain and cross-domain datasets. Experimentalresults show that the proposed model achieves a significant performanceimprovement, especially in the cross-domain few-shot setting, which outperformsthe state-of-the-art model by +7.7% on average.</description><author>Yongliang Shen, Zeqi Tan, Shuhui Wu, Wenqi Zhang, Rongsheng Zhang, Yadong Xi, Weiming Lu, Yueting Zhuang</author><pubDate>Fri, 26 May 2023 18:16:11 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.17104v1</guid></item><item><title>GeoVLN: Learning Geometry-Enhanced Visual Representation with Slot Attention for Vision-and-Language Navigation</title><link>http://arxiv.org/abs/2305.17102v1</link><description>Most existing works solving Room-to-Room VLN problem only utilize RGB imagesand do not consider local context around candidate views, which lack sufficientvisual cues about surrounding environment. Moreover, natural language containscomplex semantic information thus its correlations with visual inputs are hardto model merely with cross attention. In this paper, we propose GeoVLN, whichlearns Geometry-enhanced visual representation based on slot attention forrobust Visual-and-Language Navigation. The RGB images are compensated with thecorresponding depth maps and normal maps predicted by Omnidata as visualinputs. Technically, we introduce a two-stage module that combine local slotattention and CLIP model to produce geometry-enhanced representation from suchinput. We employ V&amp;L BERT to learn a cross-modal representation thatincorporate both language and vision informations. Additionally, a novelmultiway attention module is designed, encouraging different phrases of inputinstruction to exploit the most related features from visual input. Extensiveexperiments demonstrate the effectiveness of our newly designed modules andshow the compelling performance of the proposed method.</description><author>Jingyang Huo, Qiang Sun, Boyan Jiang, Haitao Lin, Yanwei Fu</author><pubDate>Fri, 26 May 2023 18:15:22 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.17102v1</guid></item><item><title>BiomedGPT: A Unified and Generalist Biomedical Generative Pre-trained Transformer for Vision, Language, and Multimodal Tasks</title><link>http://arxiv.org/abs/2305.17100v1</link><description>In this paper, we introduce a unified and generalist Biomedical GenerativePre-trained Transformer (BiomedGPT) model, which leverages self-supervision onlarge and diverse datasets to accept multi-modal inputs and perform a range ofdownstream tasks. Our experiments demonstrate that BiomedGPT delivers expansiveand inclusive representations of biomedical data, outperforming the majority ofpreceding state-of-the-art models across five distinct tasks with 20 publicdatasets spanning over 15 unique biomedical modalities. Through the ablationstudy, we also showcase the efficacy of our multi-modal and multi-taskpretraining approach in transferring knowledge to previously unseen data.Overall, our work presents a significant step forward in developing unified andgeneralist models for biomedicine, with far-reaching implications for improvinghealthcare outcomes.</description><author>Kai Zhang, Jun Yu, Zhiling Yan, Yixin Liu, Eashan Adhikarla, Sunyang Fu, Xun Chen, Chen Chen, Yuyin Zhou, Xiang Li, Lifang He, Brian D. Davison, Quanzheng Li, Yong Chen, Hongfang Liu, Lichao Sun</author><pubDate>Fri, 26 May 2023 18:14:43 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.17100v1</guid></item><item><title>I2D2: Inductive Knowledge Distillation with NeuroLogic and Self-Imitation</title><link>http://arxiv.org/abs/2212.09246v3</link><description>Commonsense capabilities of pre-trained language models dramatically improvewith scale, leading many to believe that scale is the only winning recipe. Butis it? Here, we investigate an alternative that a priori seems impossible: cansmaller language models (e.g., GPT-2) win over models that are orders ofmagnitude larger and better (e.g., GPT-3), if powered with novel commonsensedistillation algorithms? The key intellectual challenge is to design a learningalgorithm that achieve a competitive level of commonsense acquisition, withoutrelying on the benefits of scale. In particular, we study generative models ofcommonsense knowledge, focusing on the task of generating generics, statementsof commonsense facts about everyday concepts, e.g., birds can fly. We introduce I2D2, a novel commonsense distillation framework that looselyfollows the Symbolic Knowledge Distillation of West et al. but breaks thedependence on the extreme-scale teacher model with two innovations: (1) thenovel adaptation of NeuroLogic Decoding to enhance the generation quality ofthe weak, off-the-shelf language models, and (2) self-imitation learning toiteratively learn from the model's own enhanced commonsense acquisitioncapabilities. Empirical results suggest that scale is not the only way, asnovel algorithms can be a promising alternative. Moreover, our study leads to anew corpus of generics, Gen-A-tomic, that is the largest and highest qualityavailable to date.</description><author>Chandra Bhagavatula, Jena D. Hwang, Doug Downey, Ronan Le Bras, Ximing Lu, Lianhui Qin, Keisuke Sakaguchi, Swabha Swayamdipta, Peter West, Yejin Choi</author><pubDate>Fri, 26 May 2023 18:14:27 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2212.09246v3</guid></item><item><title>ControlVideo: Adding Conditional Control for One Shot Text-to-Video Editing</title><link>http://arxiv.org/abs/2305.17098v1</link><description>In this paper, we present ControlVideo, a novel method for text-driven videoediting. Leveraging the capabilities of text-to-image diffusion models andControlNet, ControlVideo aims to enhance the fidelity and temporal consistencyof videos that align with a given text while preserving the structure of thesource video. This is achieved by incorporating additional conditions such asedge maps, fine-tuning the key-frame and temporal attention on the sourcevideo-text pair with carefully designed strategies. An in-depth exploration ofControlVideo's design is conducted to inform future research on one-shot tuningvideo diffusion models. Quantitatively, ControlVideo outperforms a range ofcompetitive baselines in terms of faithfulness and consistency while stillaligning with the textual prompt. Additionally, it delivers videos with highvisual realism and fidelity w.r.t. the source content, demonstratingflexibility in utilizing controls containing varying degrees of source videoinformation, and the potential for multiple control combinations. The projectpage is available at\href{https://ml.cs.tsinghua.edu.cn/controlvideo/}{https://ml.cs.tsinghua.edu.cn/controlvideo/}.</description><author>Min Zhao, Rongzhen Wang, Fan Bao, Chongxuan Li, Jun Zhu</author><pubDate>Fri, 26 May 2023 18:13:55 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.17098v1</guid></item><item><title>GRAtt-VIS: Gated Residual Attention for Auto Rectifying Video Instance Segmentation</title><link>http://arxiv.org/abs/2305.17096v1</link><description>Recent trends in Video Instance Segmentation (VIS) have seen a growingreliance on online methods to model complex and lengthy video sequences.However, the degradation of representation and noise accumulation of the onlinemethods, especially during occlusion and abrupt changes, pose substantialchallenges. Transformer-based query propagation provides promising directionsat the cost of quadratic memory attention. However, they are susceptible to thedegradation of instance features due to the above-mentioned challenges andsuffer from cascading effects. The detection and rectification of such errorsremain largely underexplored. To this end, we introduce \textbf{GRAtt-VIS},\textbf{G}ated \textbf{R}esidual \textbf{Att}ention for \textbf{V}ideo\textbf{I}nstance \textbf{S}egmentation. Firstly, we leverage aGumbel-Softmax-based gate to detect possible errors in the current frame. Next,based on the gate activation, we rectify degraded features from its pastrepresentation. Such a residual configuration alleviates the need for dedicatedmemory and provides a continuous stream of relevant instance features.Secondly, we propose a novel inter-instance interaction using gate activationas a mask for self-attention. This masking strategy dynamically restricts theunrepresentative instance queries in the self-attention and preserves vitalinformation for long-term tracking. We refer to this novel combination of GatedResidual Connection and Masked Self-Attention as \textbf{GRAtt} block, whichcan easily be integrated into the existing propagation-based framework.Further, GRAtt blocks significantly reduce the attention overhead and simplifydynamic temporal modeling. GRAtt-VIS achieves state-of-the-art performance onYouTube-VIS and the highly challenging OVIS dataset, significantly improvingover previous methods. Code is available at\url{https://github.com/Tanveer81/GRAttVIS}.</description><author>Tanveer Hannan, Rajat Koner, Maximilian Bernhard, Suprosanna Shit, Bjoern Menze, Volker Tresp, Matthias Schubert, Thomas Seidl</author><pubDate>Fri, 26 May 2023 18:10:24 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.17096v1</guid></item><item><title>GENEVA: Benchmarking Generalizability for Event Argument Extraction with Hundreds of Event Types and Argument Roles</title><link>http://arxiv.org/abs/2205.12505v4</link><description>Recent works in Event Argument Extraction (EAE) have focused on improvingmodel generalizability to cater to new events and domains. However, standardbenchmarking datasets like ACE and ERE cover less than 40 event types and 25entity-centric argument roles. Limited diversity and coverage hinder thesedatasets from adequately evaluating the generalizability of EAE models. In thispaper, we first contribute by creating a large and diverse EAE ontology. Thisontology is created by transforming FrameNet, a comprehensive semantic rolelabeling (SRL) dataset for EAE, by exploiting the similarity between these twotasks. Then, exhaustive human expert annotations are collected to build theontology, concluding with 115 events and 220 argument roles, with a significantportion of roles not being entities. We utilize this ontology to furtherintroduce GENEVA, a diverse generalizability benchmarking dataset comprisingfour test suites, aimed at evaluating models' ability to handle limited dataand unseen event type generalization. We benchmark six EAE models from variousfamilies. The results show that owing to non-entity argument roles, even thebest-performing model can only achieve 39% F1 score, indicating how GENEVAprovides new challenges for generalization in EAE. Overall, our large anddiverse EAE ontology can aid in creating more comprehensive future resources,while GENEVA is a challenging benchmarking dataset encouraging further researchfor improving generalizability in EAE. The code and data can be found athttps://github.com/PlusLabNLP/GENEVA.</description><author>Tanmay Parekh, I-Hung Hsu, Kuan-Hao Huang, Kai-Wei Chang, Nanyun Peng</author><pubDate>Fri, 26 May 2023 18:10:14 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2205.12505v4</guid></item><item><title>Predicting Census Survey Response Rates With Parsimonious Additive Models and Structured Interactions</title><link>http://arxiv.org/abs/2108.11328v3</link><description>In this paper we consider the problem of predicting survey response ratesusing a family of flexible and interpretable nonparametric models. The study ismotivated by the US Census Bureau's well-known ROAM application which uses alinear regression model trained on the US Census Planning Database data toidentify hard-to-survey areas. A crowdsourcing competition organized around tenyears ago revealed that machine learning methods based on ensembles ofregression trees led to the best performance in predicting survey responserates; however, the corresponding models could not be adopted for the intendedapplication due to their black-box nature. We consider nonparametric additivemodels with small number of main and pairwise interaction effects using$\ell_0$-based penalization. From a methodological viewpoint, we study bothcomputational and statistical aspects of our estimator; and discuss variantsthat incorporate strong hierarchical interactions. Our algorithms (opensourcedon github) extend the computational frontiers of existing algorithms for sparseadditive models, to be able to handle datasets relevant for the application weconsider. We discuss and interpret findings from our model on the US CensusPlanning Database. In addition to being useful from an interpretabilitystandpoint, our models lead to predictions that appear to be better thanpopular black-box machine learning methods based on gradient boosting andfeedforward neural networks -- suggesting that it is possible to have modelsthat have the best of both worlds: good model accuracy and interpretability.</description><author>Shibal Ibrahim, Rahul Mazumder, Peter Radchenko, Emanuel Ben-David</author><pubDate>Fri, 26 May 2023 18:10:01 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2108.11328v3</guid></item><item><title>Synthesizing Rolling Bearing Fault Samples in New Conditions: A framework based on a modified CGAN</title><link>http://arxiv.org/abs/2206.12076v3</link><description>Bearings are one of the vital components of rotating machines that are proneto unexpected faults. Therefore, bearing fault diagnosis and conditionmonitoring is essential for reducing operational costs and downtime in numerousindustries. In various production conditions, bearings can be operated under arange of loads and speeds, which causes different vibration patterns associatedwith each fault type. Normal data is ample as systems usually work in desiredconditions. On the other hand, fault data is rare, and in many conditions,there is no data recorded for the fault classes. Accessing fault data iscrucial for developing data-driven fault diagnosis tools that can improve boththe performance and safety of operations. To this end, a novel algorithm basedon Conditional Generative Adversarial Networks (CGANs) is introduced. Trainedon the normal and fault data on any actual fault conditions, this algorithmgenerates fault data from normal data of target conditions. The proposed methodis validated on a real-world bearing dataset, and fault data are generated fordifferent conditions. Several state-of-the-art classifiers and visualizationmodels are implemented to evaluate the quality of the synthesized data. Theresults demonstrate the efficacy of the proposed algorithm.</description><author>Maryam Ahang, Masoud Jalayer, Ardeshir Shojaeinasab, Oluwaseyi Ogunfowora, Todd Charter, Homayoun Najjaran</author><pubDate>Fri, 26 May 2023 18:09:55 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2206.12076v3</guid></item><item><title>Benchmarking state-of-the-art gradient boosting algorithms for classification</title><link>http://arxiv.org/abs/2305.17094v1</link><description>This work explores the use of gradient boosting in the context ofclassification. Four popular implementations, including original GBM algorithmand selected state-of-the-art gradient boosting frameworks (i.e. XGBoost,LightGBM and CatBoost), have been thoroughly compared on several publiclyavailable real-world datasets of sufficient diversity. In the study, specialemphasis was placed on hyperparameter optimization, specifically comparing twotuning strategies, i.e. randomized search and Bayesian optimization using theTree-stuctured Parzen Estimator. The performance of considered methods wasinvestigated in terms of common classification accuracy metrics as well asruntime and tuning time. Additionally, obtained results have been validatedusing appropriate statistical testing. An attempt was made to indicate agradient boosting variant showing the right balance between effectiveness,reliability and ease of use.</description><author>Piotr Florek, Adam Zagdański</author><pubDate>Fri, 26 May 2023 18:06:15 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.17094v1</guid></item><item><title>SSSegmenation: An Open Source Supervised Semantic Segmentation Toolbox Based on PyTorch</title><link>http://arxiv.org/abs/2305.17091v1</link><description>This paper presents SSSegmenation, which is an open source supervisedsemantic image segmentation toolbox based on PyTorch. The design of thistoolbox is motivated by MMSegmentation while it is easier to use because offewer dependencies and achieves superior segmentation performance under acomparable training and testing setup. Moreover, the toolbox also providesplenty of trained weights for popular and contemporary semantic segmentationmethods, including Deeplab, PSPNet, OCRNet, MaskFormer, \emph{etc}. We expectthat this toolbox can contribute to the future development of semanticsegmentation. Codes and model zoos are available at\href{https://github.com/SegmentationBLWX/sssegmentation/}{SSSegmenation}.</description><author>Zhenchao Jin</author><pubDate>Fri, 26 May 2023 18:02:42 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.17091v1</guid></item><item><title>Communication-Efficient Reinforcement Learning in Swarm Robotic Networks for Maze Exploration</title><link>http://arxiv.org/abs/2305.17087v1</link><description>Smooth coordination within a swarm robotic system is essential for theeffective execution of collective robot missions. Having efficientcommunication is key to the successful coordination of swarm robots. This paperproposes a new communication-efficient decentralized cooperative reinforcementlearning algorithm for coordinating swarm robots. It is made efficient byhierarchically building on the use of local information exchanges. We considera case study application of maze solving through cooperation among a group ofrobots, where the time and costs are minimized while avoiding inter-robotcollisions and path overlaps during exploration. With a solid theoreticalbasis, we extensively analyze the algorithm with realistic CORE networksimulations and evaluate it against state-of-the-art solutions in terms of mazecoverage percentage and efficiency under communication-degraded environments.The results demonstrate significantly higher coverage accuracy and efficiencywhile reducing costs and overlaps even in high packet loss and lowcommunication range scenarios.</description><author>Ehsan Latif, WenZhan Song, Ramviyas Parasuraman</author><pubDate>Fri, 26 May 2023 17:56:00 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.17087v1</guid></item><item><title>A Policy Gradient Method for Confounded POMDPs</title><link>http://arxiv.org/abs/2305.17083v1</link><description>In this paper, we propose a policy gradient method for confounded partiallyobservable Markov decision processes (POMDPs) with continuous state andobservation spaces in the offline setting. We first establish a novelidentification result to non-parametrically estimate any history-dependentpolicy gradient under POMDPs using the offline data. The identification enablesus to solve a sequence of conditional moment restrictions and adopt the min-maxlearning procedure with general function approximation for estimating thepolicy gradient. We then provide a finite-sample non-asymptotic bound forestimating the gradient uniformly over a pre-specified policy class in terms ofthe sample size, length of horizon, concentratability coefficient and themeasure of ill-posedness in solving the conditional moment restrictions.Lastly, by deploying the proposed gradient estimation in the gradient ascentalgorithm, we show the global convergence of the proposed algorithm in findingthe history-dependent optimal policy under some technical conditions. To thebest of our knowledge, this is the first work studying the policy gradientmethod for POMDPs under the offline setting.</description><author>Mao Hong, Zhengling Qi, Yanxun Xu</author><pubDate>Fri, 26 May 2023 17:48:05 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.17083v1</guid></item><item><title>Towards Robust Low-Resource Fine-Tuning with Multi-View Compressed Representations</title><link>http://arxiv.org/abs/2211.08794v4</link><description>Due to the huge amount of parameters, fine-tuning of pretrained languagemodels (PLMs) is prone to overfitting in the low resource scenarios. In thiswork, we present a novel method that operates on the hidden representations ofa PLM to reduce overfitting. During fine-tuning, our method inserts randomautoencoders between the hidden layers of a PLM, which transform activationsfrom the previous layers into multi-view compressed representations beforefeeding them into the upper layers. The autoencoders are plugged out afterfine-tuning, so our method does not add extra parameters or increasecomputation cost during inference. Our method demonstrates promisingperformance improvement across a wide range of sequence- and token-levellow-resource NLP tasks.</description><author>Linlin Liu, Xingxuan Li, Megh Thakkar, Xin Li, Shafiq Joty, Luo Si, Lidong Bing</author><pubDate>Fri, 26 May 2023 17:47:18 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2211.08794v4</guid></item><item><title>Expand, Rerank, and Retrieve: Query Reranking for Open-Domain Question Answering</title><link>http://arxiv.org/abs/2305.17080v1</link><description>We propose EAR, a query Expansion And Reranking approach for improvingpassage retrieval, with the application to open-domain question answering. EARfirst applies a query expansion model to generate a diverse set of queries, andthen uses a query reranker to select the ones that could lead to betterretrieval results. Motivated by the observation that the best query expansionoften is not picked by greedy decoding, EAR trains its reranker to predict therank orders of the gold passages when issuing the expanded queries to a givenretriever. By connecting better the query expansion model and retriever, EARsignificantly enhances a traditional sparse retrieval method, BM25.Empirically, EAR improves top-5/20 accuracy by 3-8 and 5-10 points in in-domainand out-of-domain settings, respectively, when compared to a vanilla queryexpansion model, GAR, and a dense retrieval model, DPR.</description><author>Yung-Sung Chuang, Wei Fang, Shang-Wen Li, Wen-tau Yih, James Glass</author><pubDate>Fri, 26 May 2023 17:41:03 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.17080v1</guid></item><item><title>Learning and Leveraging Verifiers to Improve Planning Capabilities of Pre-trained Language Models</title><link>http://arxiv.org/abs/2305.17077v1</link><description>There have been wide spread claims in the literature about the emergentreasoning capabilities of Pretrained Large Language Models. However, recentstudies, have found that their ability to plan remains questionable. Throughour experiments using GPT-2, we empirically demonstrate that the performance ofa finetuned baseline remains poor because it violates pre-conditions of actionsin the plans that it generates. To improve the planning capabilities of afinetuned LLM, we train a verifier, which can classify actions as being validor invalid in a particular state. By randomly sampling actions from the samedataset, we generate examples of invalid actions which are then used to train averifier which can check for action applicability. In the presence of diversesampling from a generator and a verifier which can prune invalid trajectories,we show significant gains in the success rate on the Blocksworld domain.Additionally, we show that finetuning the GPT-2 generator itself to create theverifier generalizes better than finetuning the base GPT-2. Lastly, weinvestigate the role of the sampling temperature which can be used to controlthe exploration-exploitation tradeoff.</description><author>Daman Arora, Subbarao Kambhampati</author><pubDate>Fri, 26 May 2023 17:36:55 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.17077v1</guid></item><item><title>Exact Generalization Guarantees for (Regularized) Wasserstein Distributionally Robust Models</title><link>http://arxiv.org/abs/2305.17076v1</link><description>Wasserstein distributionally robust estimators have emerged as powerfulmodels for prediction and decision-making under uncertainty. These estimatorsprovide attractive generalization guarantees: the robust objective obtainedfrom the training distribution is an exact upper bound on the true risk withhigh probability. However, existing guarantees either suffer from the curse ofdimensionality, are restricted to specific settings, or lead to spurious errorterms. In this paper, we show that these generalization guarantees actuallyhold on general classes of models, do not suffer from the curse ofdimensionality, and can even cover distribution shifts at testing. We alsoprove that these results carry over to the newly-introduced regularizedversions of Wasserstein distributionally robust problems.</description><author>Waïss Azizian, Franck Iutzeler, Jérôme Malick</author><pubDate>Fri, 26 May 2023 17:35:57 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.17076v1</guid></item><item><title>CREST: A Joint Framework for Rationalization and Counterfactual Text Generation</title><link>http://arxiv.org/abs/2305.17075v1</link><description>Selective rationales and counterfactual examples have emerged as twoeffective, complementary classes of interpretability methods for analyzing andtraining NLP models. However, prior work has not explored how these methods canbe integrated to combine their complementary advantages. We overcome thislimitation by introducing CREST (ContRastive Edits with SparseraTionalization), a joint framework for selective rationalization andcounterfactual text generation, and show that this framework leads toimprovements in counterfactual quality, model robustness, and interpretability.First, CREST generates valid counterfactuals that are more natural than thoseproduced by previous methods, and subsequently can be used for dataaugmentation at scale, reducing the need for human-generated examples. Second,we introduce a new loss function that leverages CREST counterfactuals toregularize selective rationales and show that this regularization improves bothmodel robustness and rationale quality, compared to methods that do notleverage CREST counterfactuals. Our results demonstrate that CREST successfullybridges the gap between selective rationales and counterfactual examples,addressing the limitations of existing methods and providing a morecomprehensive view of a model's predictions.</description><author>Marcos Treviso, Alexis Ross, Nuno M. Guerreiro, André F. T. Martins</author><pubDate>Fri, 26 May 2023 17:34:58 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.17075v1</guid></item><item><title>NeuroX Library for Neuron Analysis of Deep NLP Models</title><link>http://arxiv.org/abs/2305.17073v1</link><description>Neuron analysis provides insights into how knowledge is structured inrepresentations and discovers the role of neurons in the network. In additionto developing an understanding of our models, neuron analysis enables variousapplications such as debiasing, domain adaptation and architectural search. Wepresent NeuroX, a comprehensive open-source toolkit to conduct neuron analysisof natural language processing models. It implements various interpretationmethods under a unified API, and provides a framework for data processing andevaluation, thus making it easier for researchers and practitioners to performneuron analysis. The Python toolkit is available athttps://www.github.com/fdalvi/NeuroX. Demo Video available athttps://youtu.be/mLhs2YMx4u8.</description><author>Fahim Dalvi, Hassan Sajjad, Nadir Durrani</author><pubDate>Fri, 26 May 2023 17:32:56 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.17073v1</guid></item><item><title>Stereotypes and Smut: The (Mis)representation of Non-cisgender Identities by Text-to-Image Models</title><link>http://arxiv.org/abs/2305.17072v1</link><description>Cutting-edge image generation has been praised for producing high-qualityimages, suggesting a ubiquitous future in a variety of applications. However,initial studies have pointed to the potential for harm due to predictive bias,reflecting and potentially reinforcing cultural stereotypes. In this work, weare the first to investigate how multimodal models handle diverse genderidentities. Concretely, we conduct a thorough analysis in which we compare theoutput of three image generation models for prompts containing cisgender vs.non-cisgender identity terms. Our findings demonstrate that certainnon-cisgender identities are consistently (mis)represented as less human, morestereotyped and more sexualised. We complement our experimental analysis with(a)~a survey among non-cisgender individuals and (b) a series of interviews, toestablish which harms affected individuals anticipate, and how they would liketo be represented. We find respondents are particularly concerned aboutmisrepresentation, and the potential to drive harmful behaviours and beliefs.Simple heuristics to limit offensive content are widely rejected, and insteadrespondents call for community involvement, curated training data and theability to customise. These improvements could pave the way for a future wherechange is led by the affected community, and technology is used to positively``[portray] queerness in ways that we haven't even thought of'' rather thanreproducing stale, offensive stereotypes.</description><author>Eddie L. Ungless, Björn Ross, Anne Lauscher</author><pubDate>Fri, 26 May 2023 17:28:49 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.17072v1</guid></item><item><title>Adversarial Attacks on Online Learning to Rank with Click Feedback</title><link>http://arxiv.org/abs/2305.17071v1</link><description>Online learning to rank (OLTR) is a sequential decision-making problem wherea learning agent selects an ordered list of items and receives feedback throughuser clicks. Although potential attacks against OLTR algorithms may causeserious losses in real-world applications, little is known about adversarialattacks on OLTR. This paper studies attack strategies against multiple variantsof OLTR. Our first result provides an attack strategy against the UCB algorithmon classical stochastic bandits with binary feedback, which solves the keyissues caused by bounded and discrete feedback that previous works can nothandle. Building on this result, we design attack algorithms against UCB-basedOLTR algorithms in position-based and cascade models. Finally, we propose ageneral attack strategy against any algorithm under the general click model.Each attack algorithm manipulates the learning agent into choosing the targetattack item $T-o(T)$ times, incurring a cumulative cost of $o(T)$. Experimentson synthetic and real data further validate the effectiveness of our proposedattack algorithms.</description><author>Jinhang Zuo, Zhiyao Zhang, Zhiyong Wang, Shuai Li, Mohammad Hajiesmaili, Adam Wierman</author><pubDate>Fri, 26 May 2023 17:28:26 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.17071v1</guid></item><item><title>Chakra: Advancing Performance Benchmarking and Co-design using Standardized Execution Traces</title><link>http://arxiv.org/abs/2305.14516v2</link><description>Benchmarking and co-design are essential for driving optimizations andinnovation around ML models, ML software, and next-generation hardware. Fullworkload benchmarks, e.g. MLPerf, play an essential role in enabling faircomparison across different software and hardware stacks especially oncesystems are fully designed and deployed. However, the pace of AI innovationdemands a more agile methodology to benchmark creation and usage by simulatorsand emulators for future system co-design. We propose Chakra, an open graphschema for standardizing workload specification capturing key operations anddependencies, also known as Execution Trace (ET). In addition, we propose acomplementary set of tools/capabilities to enable collection, generation, andadoption of Chakra ETs by a wide range of simulators, emulators, andbenchmarks. For instance, we use generative AI models to learn latentstatistical properties across thousands of Chakra ETs and use these models tosynthesize Chakra ETs. These synthetic ETs can obfuscate key proprietaryinformation and also target future what-if scenarios. As an example, wedemonstrate an end-to-end proof-of-concept that converts PyTorch ETs to ChakraETs and uses this to drive an open-source training system simulator(ASTRA-sim). Our end-goal is to build a vibrant industry-wide ecosystem ofagile benchmarks and tools to drive future AI system co-design.</description><author>Srinivas Sridharan, Taekyung Heo, Louis Feng, Zhaodong Wang, Matt Bergeron, Wenyin Fu, Shengbao Zheng, Brian Coutinho, Saeed Rashidi, Changhai Man, Tushar Krishna</author><pubDate>Fri, 26 May 2023 17:22:27 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.14516v2</guid></item><item><title>Algorithm Selection for Deep Active Learning with Imbalanced Datasets</title><link>http://arxiv.org/abs/2302.07317v2</link><description>Label efficiency has become an increasingly important objective in deeplearning applications. Active learning aims to reduce the number of labeledexamples needed to train deep networks, but the empirical performance of activelearning algorithms can vary dramatically across datasets and applications. Itis difficult to know in advance which active learning strategy will performwell or best in a given application. To address this, we propose the firstadaptive algorithm selection strategy for deep active learning. For anyunlabeled dataset, our (meta) algorithm TAILOR (Thompson ActIve LearningalgORithm selection) iteratively and adaptively chooses among a set ofcandidate active learning algorithms. TAILOR uses novel reward functions aimedat gathering class-balanced examples. Extensive experiments in multi-class andmulti-label applications demonstrate TAILOR's effectiveness in achievingaccuracy comparable or better than that of the best of the candidatealgorithms.</description><author>Jifan Zhang, Shuai Shao, Saurabh Verma, Robert Nowak</author><pubDate>Fri, 26 May 2023 17:22:19 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2302.07317v2</guid></item><item><title>Explainable Activity Recognition for Smart Home Systems</title><link>http://arxiv.org/abs/2105.09787v2</link><description>Smart home environments are designed to provide services that help improvethe quality of life for the occupant via a variety of sensors and actuatorsinstalled throughout the space. Many automated actions taken by a smart homeare governed by the output of an underlying activity recognition system.However, activity recognition systems may not be perfectly accurate andtherefore inconsistencies in smart home operations can lead users reliant onsmart home predictions to wonder "why did the smart home do that?" In thiswork, we build on insights from Explainable Artificial Intelligence (XAI)techniques and introduce an explainable activity recognition framework in whichwe leverage leading XAI methods to generate natural language explanations thatexplain what about an activity led to the given classification. Within thecontext of remote caregiver monitoring, we perform a two-step evaluation: (a)utilize ML experts to assess the sensibility of explanations, and (b) recruitnon-experts in two user remote caregiver monitoring scenarios, synchronous andasynchronous, to assess the effectiveness of explanations generated via ourframework. Our results show that the XAI approach, SHAP, has a 92% success ratein generating sensible explanations. Moreover, in 83% of sampled scenariosusers preferred natural language explanations over a simple activity label,underscoring the need for explainable activity recognition systems. Finally, weshow that explanations generated by some XAI methods can lead users to loseconfidence in the accuracy of the underlying activity recognition model. Wemake a recommendation regarding which existing XAI method leads to the bestperformance in the domain of smart home automation, and discuss a range oftopics for future work to further improve explainable activity recognition.</description><author>Devleena Das, Yasutaka Nishimura, Rajan P. Vivek, Naoto Takeda, Sean T. Fish, Thomas Ploetz, Sonia Chernova</author><pubDate>Fri, 26 May 2023 17:21:50 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2105.09787v2</guid></item><item><title>Mindstorms in Natural Language-Based Societies of Mind</title><link>http://arxiv.org/abs/2305.17066v1</link><description>Both Minsky's "society of mind" and Schmidhuber's "learning to think" inspirediverse societies of large multimodal neural networks (NNs) that solve problemsby interviewing each other in a "mindstorm." Recent implementations of NN-basedsocieties of minds consist of large language models (LLMs) and other NN-basedexperts communicating through a natural language interface. In doing so, theyovercome the limitations of single LLMs, improving multimodal zero-shotreasoning. In these natural language-based societies of mind (NLSOMs), newagents -- all communicating through the same universal symbolic language -- areeasily added in a modular fashion. To demonstrate the power of NLSOMs, weassemble and experiment with several of them (having up to 129 members),leveraging mindstorms in them to solve some practical AI tasks: visual questionanswering, image captioning, text-to-image synthesis, 3D generation, egocentricretrieval, embodied AI, and general language-based task solving. We view thisas a starting point towards much larger NLSOMs with billions of agents-some ofwhich may be humans. And with this emergence of great societies ofheterogeneous minds, many new research questions have suddenly become paramountto the future of artificial intelligence. What should be the social structureof an NLSOM? What would be the (dis)advantages of having a monarchical ratherthan a democratic structure? How can principles of NN economies be used tomaximize the total reward of a reinforcement learning NLSOM? In this work, weidentify, discuss, and try to answer some of these questions.</description><author>Mingchen Zhuge, Haozhe Liu, Francesco Faccio, Dylan R. Ashley, Róbert Csordás, Anand Gopalakrishnan, Abdullah Hamdi, Hasan Abed Al Kader Hammoud, Vincent Herrmann, Kazuki Irie, Louis Kirsch, Bing Li, Guohao Li, Shuming Liu, Jinjie Mai, Piotr Piękos, Aditya Ramesh, Imanol Schlag, Weimin Shi, Aleksandar Stanić, Wenyi Wang, Yuhui Wang, Mengmeng Xu, Deng-Ping Fan, Bernard Ghanem, Jürgen Schmidhuber</author><pubDate>Fri, 26 May 2023 17:21:25 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.17066v1</guid></item><item><title>Vecchia Gaussian Process Ensembles on Internal Representations of Deep Neural Networks</title><link>http://arxiv.org/abs/2305.17063v1</link><description>For regression tasks, standard Gaussian processes (GPs) provide naturaluncertainty quantification, while deep neural networks (DNNs) excel atrepresentation learning. We propose to synergistically combine these twoapproaches in a hybrid method consisting of an ensemble of GPs built on theoutput of hidden layers of a DNN. GP scalability is achieved via Vecchiaapproximations that exploit nearest-neighbor conditional independence. Theresulting deep Vecchia ensemble not only imbues the DNN with uncertaintyquantification but can also provide more accurate and robust predictions. Wedemonstrate the utility of our model on several datasets and carry outexperiments to understand the inner workings of the proposed method.</description><author>Felix Jimenez, Matthias Katzfuss</author><pubDate>Fri, 26 May 2023 17:19:26 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.17063v1</guid></item><item><title>Entity-to-Text based Data Augmentation for various Named Entity Recognition Tasks</title><link>http://arxiv.org/abs/2210.10343v2</link><description>Data augmentation techniques have been used to alleviate the problem ofscarce labeled data in various NER tasks (flat, nested, and discontinuous NERtasks). Existing augmentation techniques either manipulate the words in theoriginal text that break the semantic coherence of the text, or exploitgenerative models that ignore preserving entities in the original text, whichimpedes the use of augmentation techniques on nested and discontinuous NERtasks. In this work, we propose a novel Entity-to-Text based data augmentationtechnique named EnTDA to add, delete, replace or swap entities in the entitylist of the original texts, and adopt these augmented entity lists to generatesemantically coherent and entity preserving texts for various NER tasks.Furthermore, we introduce a diversity beam search to increase the diversityduring the text generation process. Experiments on thirteen NER datasets acrossthree tasks (flat, nested, and discontinuous NER tasks) and two settings (fulldata and low resource settings) show that EnTDA could bring more performanceimprovements compared to the baseline augmentation techniques.</description><author>Xuming Hu, Yong Jiang, Aiwei Liu, Zhongqiang Huang, Pengjun Xie, Fei Huang, Lijie Wen, Philip S. Yu</author><pubDate>Fri, 26 May 2023 17:14:43 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2210.10343v2</guid></item><item><title>A New Aligned Simple German Corpus</title><link>http://arxiv.org/abs/2209.01106v4</link><description>"Leichte Sprache", the German counterpart to Simple English, is a regulatedlanguage aiming to facilitate complex written language that would otherwisestay inaccessible to different groups of people. We present a newsentence-aligned monolingual corpus for Simple German -- German. It containsmultiple document-aligned sources which we have aligned using automaticsentence-alignment methods. We evaluate our alignments based on a manuallylabelled subset of aligned documents. The quality of our sentence alignments,as measured by F1-score, surpasses previous work. We publish the dataset underCC BY-SA and the accompanying code under MIT license.</description><author>Vanessa Toborek, Moritz Busch, Malte Boßert, Christian Bauckhage, Pascal Welke</author><pubDate>Fri, 26 May 2023 17:11:23 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2209.01106v4</guid></item><item><title>End-to-End Full-Atom Antibody Design</title><link>http://arxiv.org/abs/2302.00203v3</link><description>Antibody design is an essential yet challenging task in various domains liketherapeutics and biology. There are two major defects in current learning-basedmethods: 1) tackling only a certain subtask of the whole antibody designpipeline, making them suboptimal or resource-intensive. 2) omitting either theframework regions or side chains, thus incapable of capturing the full-atomgeometry. To address these pitfalls, we propose dynamic Multi-channelEquivariant grAph Network (dyMEAN), an end-to-end full-atom model forE(3)-equivariant antibody design given the epitope and the incomplete sequenceof the antibody. Specifically, we first explore structural initialization as aknowledgeable guess of the antibody structure and then propose shadow paratopeto bridge the epitope-antibody connections. Both 1D sequences and 3D structuresare updated via an adaptive multi-channel equivariant encoder that is able toprocess protein residues of variable sizes when considering full atoms.Finally, the updated antibody is docked to the epitope via the alignment of theshadow paratope. Experiments on epitope-binding CDR-H3 design, complexstructure prediction, and affinity optimization demonstrate the superiority ofour end-to-end framework and full-atom modeling.</description><author>Xiangzhe Kong, Wenbing Huang, Yang Liu</author><pubDate>Fri, 26 May 2023 17:10:02 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2302.00203v3</guid></item><item><title>Exact Bayesian Inference on Discrete Models via Probability Generating Functions: A Probabilistic Programming Approach</title><link>http://arxiv.org/abs/2305.17058v1</link><description>We present an exact Bayesian inference method for discrete statisticalmodels, which can find exact solutions to many discrete inference problems,even with infinite support and continuous priors. To express such models, weintroduce a probabilistic programming language that supports discrete andcontinuous sampling, discrete observations, affine functions, (stochastic)branching, and conditioning on events. Our key tool is probability generatingfunctions: they provide a compact closed-form representation of distributionsthat are definable by programs, thus enabling the exact computation ofposterior probabilities, expectation, variance, and higher moments. Ourinference method is provably correct, fully automated and uses automaticdifferentiation (specifically, Taylor polynomials), but does not requirecomputer algebra. Our experiments show that its performance on a range ofreal-world examples is competitive with approximate Monte Carlo methods, whileavoiding approximation errors.</description><author>Fabian Zaiser, Andrzej S. Murawski, Luke Ong</author><pubDate>Fri, 26 May 2023 17:09:59 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.17058v1</guid></item><item><title>UnitY: Two-pass Direct Speech-to-speech Translation with Discrete Units</title><link>http://arxiv.org/abs/2212.08055v2</link><description>Direct speech-to-speech translation (S2ST), in which all components can beoptimized jointly, is advantageous over cascaded approaches to achieve fastinference with a simplified pipeline. We present a novel two-pass direct S2STarchitecture, UnitY, which first generates textual representations and predictsdiscrete acoustic units subsequently. We enhance the model performance bysubword prediction in the first-pass decoder, advanced two-pass decoderarchitecture design and search strategy, and better training regularization. Toleverage large amounts of unlabeled text data, we pre-train the first-pass textdecoder based on the self-supervised denoising auto-encoding task. Experimentalevaluations on benchmark datasets at various data scales demonstrate that UnitYoutperforms a single-pass speech-to-unit translation model by 2.5-4.2 ASR-BLEUwith 2.83x decoding speed-up. We show that the proposed methods boost theperformance even when predicting spectrogram in the second pass. However,predicting discrete units achieves 2.51x decoding speed-up compared to thatcase.</description><author>Hirofumi Inaguma, Sravya Popuri, Ilia Kulikov, Peng-Jen Chen, Changhan Wang, Yu-An Chung, Yun Tang, Ann Lee, Shinji Watanabe, Juan Pino</author><pubDate>Fri, 26 May 2023 17:07:54 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2212.08055v2</guid></item><item><title>Hidden Schema Networks</title><link>http://arxiv.org/abs/2207.03777v2</link><description>Large, pretrained language models infer powerful representations that encoderich semantic and syntactic content, albeit implicitly. In this work weintroduce a novel neural language model that enforces, via inductive biases,explicit relational structures which allow for compositionality onto the outputrepresentations of pretrained language models. Specifically, the model encodessentences into sequences of symbols (composed representations), whichcorrespond to the nodes visited by biased random walkers on a global latentgraph, and infers the posterior distribution of the latter. We firstdemonstrate that the model is able to uncover ground-truth graphs fromartificially generated datasets of random token sequences. Next, we leveragepretrained BERT and GPT-2 language models as encoder and decoder, respectively,to infer networks of symbols (schemata) from natural language datasets. Ourexperiments show that (i) the inferred symbols can be interpreted as encodingdifferent aspects of language, as e.g. topics or sentiments, and that (ii)GPT-like models can effectively be conditioned on symbolic representations.Finally, we explore training autoregressive, random walk ``reasoning" models onschema networks inferred from commonsense knowledge databases, and using thesampled paths to enhance the performance of pretrained language models oncommonsense If-Then reasoning tasks.</description><author>Ramsés J. Sánchez, Lukas Conrads, Pascal Welke, Kostadin Cvejoski, César Ojeda</author><pubDate>Fri, 26 May 2023 17:06:36 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2207.03777v2</guid></item><item><title>Echo of Neighbors: Privacy Amplification for Personalized Private Federated Learning with Shuffle Model</title><link>http://arxiv.org/abs/2304.05516v2</link><description>Federated Learning, as a popular paradigm for collaborative training, isvulnerable against privacy attacks. Different privacy levels regarding users'attitudes need to be satisfied locally, while a strict privacy guarantee forthe global model is also required centrally. Personalized Local DifferentialPrivacy (PLDP) is suitable for preserving users' varying local privacy, yetonly provides a central privacy guarantee equivalent to the worst-case localprivacy level. Thus, achieving strong central privacy as well as personalizedlocal privacy with a utility-promising model is a challenging problem. In thiswork, a general framework (APES) is built up to strengthen model privacy underpersonalized local privacy by leveraging the privacy amplification effect ofthe shuffle model. To tighten the privacy bound, we quantify the heterogeneouscontributions to the central privacy user by user. The contributions arecharacterized by the ability of generating "echos" from the perturbation ofeach user, which is carefully measured by proposed methods Neighbor Divergenceand Clip-Laplace Mechanism. Furthermore, we propose a refined framework(S-APES) with the post-sparsification technique to reduce privacy loss inhigh-dimension scenarios. To the best of our knowledge, the impact of shufflingon personalized local privacy is considered for the first time. We provide astrong privacy amplification effect, and the bound is tighter than the baselineresult based on existing methods for uniform local privacy. Experimentsdemonstrate that our frameworks ensure comparable or higher accuracy for theglobal model.</description><author>Yixuan Liu, Suyun Zhao, Li Xiong, Yuhan Liu, Hong Chen</author><pubDate>Fri, 26 May 2023 17:04:43 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2304.05516v2</guid></item><item><title>Counterfactuals of Counterfactuals: a back-translation-inspired approach to analyse counterfactual editors</title><link>http://arxiv.org/abs/2305.17055v1</link><description>In the wake of responsible AI, interpretability methods, which attempt toprovide an explanation for the predictions of neural models have seen rapidprogress. In this work, we are concerned with explanations that are applicableto natural language processing (NLP) models and tasks, and we focusspecifically on the analysis of counterfactual, contrastive explanations. Wenote that while there have been several explainers proposed to producecounterfactual explanations, their behaviour can vary significantly and thelack of a universal ground truth for the counterfactual edits imposes aninsuperable barrier on their evaluation. We propose a new backtranslation-inspired evaluation methodology that utilises earlier outputs ofthe explainer as ground truth proxies to investigate the consistency ofexplainers. We show that by iteratively feeding the counterfactual to theexplainer we can obtain valuable insights into the behaviour of both thepredictor and the explainer models, and infer patterns that would be otherwiseobscured. Using this methodology, we conduct a thorough analysis and propose anovel metric to evaluate the consistency of counterfactual generationapproaches with different characteristics across available performanceindicators.</description><author>Giorgos Filandrianos, Edmund Dervakos, Orfeas Menis-Mastromichalakis, Chrysoula Zerva, Giorgos Stamou</author><pubDate>Fri, 26 May 2023 17:04:28 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.17055v1</guid></item><item><title>Python Code Generation by Asking Clarification Questions</title><link>http://arxiv.org/abs/2212.09885v2</link><description>Code generation from text requires understanding the user's intent from anatural language description and generating an executable code snippet thatsatisfies this intent. While recent pretrained language models demonstrateremarkable performance for this task, these models fail when the given naturallanguage description is under-specified. In this work, we introduce a novel andmore realistic setup for this task. We hypothesize that the under-specificationof a natural language description can be resolved by asking clarificationquestions. Therefore, we collect and introduce a new dataset named CodeClarQAcontaining pairs of natural language descriptions and code with createdsynthetic clarification questions and answers. The empirical results of ourevaluation of pretrained language model performance on code generation showthat clarifications result in more precisely generated code, as shown by thesubstantial improvement of model performance in all evaluation metrics.Alongside this, our task and dataset introduce new challenges to the community,including when and what clarification questions should be asked. Our code anddataset are available on GitHub.</description><author>Haau-Sing Li, Mohsen Mesgar, André F. T. Martins, Iryna Gurevych</author><pubDate>Fri, 26 May 2023 17:03:08 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2212.09885v2</guid></item><item><title>Extremely weakly-supervised blood vessel segmentation with physiologically based synthesis and domain adaptation</title><link>http://arxiv.org/abs/2305.17054v1</link><description>Accurate analysis and modeling of renal functions require a precisesegmentation of the renal blood vessels. Micro-CT scans provide image data athigher resolutions, making more small vessels near the renal cortex visible.Although deep-learning-based methods have shown state-of-the-art performance inautomatic blood vessel segmentations, they require a large amount of labeledtraining data. However, voxel-wise labeling in micro-CT scans is extremelytime-consuming given the huge volume sizes. To mitigate the problem, wesimulate synthetic renal vascular trees physiologically while generatingcorresponding scans of the simulated trees by training a generative model onunlabeled scans. This enables the generative model to learn the mappingimplicitly without the need for explicit functions to emulate the imageacquisition process. We further propose an additional segmentation branch overthe generative model trained on the generated scans. We demonstrate that themodel can directly segment blood vessels on real scans and validate our methodon both 3D micro-CT scans of rat kidneys and a proof-of-concept experiment on2D retinal images. Code and 3D results are available athttps://github.com/miccai2023anony/RenalVesselSeg</description><author>Peidi Xu, Olga Sosnovtseva, Charlotte Mehlin Sørensen, Kenny Erleben, Sune Darkner</author><pubDate>Fri, 26 May 2023 17:01:49 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.17054v1</guid></item><item><title>A Framework for Incentivized Collaborative Learning</title><link>http://arxiv.org/abs/2305.17052v1</link><description>Collaborations among various entities, such as companies, research labs, AIagents, and edge devices, have become increasingly crucial for achievingmachine learning tasks that cannot be accomplished by a single entity alone.This is likely due to factors such as security constraints, privacy concerns,and limitations in computation resources. As a result, collaborative learning(CL) research has been gaining momentum. However, a significant challenge inpractical applications of CL is how to effectively incentivize multipleentities to collaborate before any collaboration occurs. In this study, wepropose ICL, a general framework for incentivized collaborative learning, andprovide insights into the critical issue of when and why incentives can improvecollaboration performance. Furthermore, we show the broad applicability of ICLto specific cases in federated learning, assisted learning, and multi-armedbandit with both theory and experimental results.</description><author>Xinran Wang, Qi Le, Ahmad Faraz Khan, Jie Ding, Ali Anwar</author><pubDate>Fri, 26 May 2023 17:00:59 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.17052v1</guid></item><item><title>Exploiting Abstract Meaning Representation for Open-Domain Question Answering</title><link>http://arxiv.org/abs/2305.17050v1</link><description>The Open-Domain Question Answering (ODQA) task involves retrieving andsubsequently generating answers from fine-grained relevant passages within adatabase. Current systems leverage Pretrained Language Models (PLMs) to modelthe relationship between questions and passages. However, the diversity insurface form expressions can hinder the model's ability to capture accuratecorrelations, especially within complex contexts. Therefore, we utilizeAbstract Meaning Representation (AMR) graphs to assist the model inunderstanding complex semantic information. We introduce a method known asGraph-as-Token (GST) to incorporate AMRs into PLMs. Results from NaturalQuestions (NQ) and TriviaQA (TQ) demonstrate that our GST method cansignificantly improve performance, resulting in up to 2.44/3.17 Exact Matchscore improvements on NQ/TQ respectively. Furthermore, our method enhancesrobustness and outperforms alternative Graph Neural Network (GNN) methods forintegrating AMRs. To the best of our knowledge, we are the first to employsemantic graphs in ODQA.</description><author>Cunxiang Wang, Zhikun Xu, Qipeng Guo, Xiangkun Hu, Xuefeng Bai, Zheng Zhang, Yue Zhang</author><pubDate>Fri, 26 May 2023 17:00:16 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.17050v1</guid></item><item><title>Representation Online Matters: Practical End-to-End Diversification in Search and Recommender Systems</title><link>http://arxiv.org/abs/2305.15534v2</link><description>As the use of online platforms continues to grow across all demographics,users often express a desire to feel represented in the content. To improverepresentation in search results and recommendations, we introduce end-to-enddiversification, ensuring that diverse content flows throughout the variousstages of these systems, from retrieval to ranking. We develop, experiment, anddeploy scalable diversification mechanisms in multiple production surfaces onthe Pinterest platform, including Search, Related Products, and New UserHomefeed, to improve the representation of different skin tones in beauty andfashion content. Diversification in production systems includes threecomponents: identifying requests that will trigger diversification, ensuringdiverse content is retrieved from the large content corpus during the retrievalstage, and finally, balancing the diversity-utility trade-off in aself-adjusting manner in the ranking stage. Our approaches, which evolved fromusing Strong-OR logical operator to bucketized retrieval at the retrieval stageand from greedy re-rankers to multi-objective optimization using determinantalpoint processes for the ranking stage, balances diversity and utility whileenabling fast iterations and scalable expansion to diversification overmultiple dimensions. Our experiments indicate that these approachessignificantly improve diversity metrics, with a neutral to a positive impact onutility metrics and improved user satisfaction, both qualitatively andquantitatively, in production. An accessible PDF of this article is available athttps://drive.google.com/file/d/1p5PkqC-sdtX19Y_IAjZCtiSxSEX1IP3q/view</description><author>Pedro Silva, Bhawna Juneja, Shloka Desai, Ashudeep Singh, Nadia Fawaz</author><pubDate>Fri, 26 May 2023 17:00:08 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.15534v2</guid></item><item><title>SelfClean: A Self-Supervised Data Cleaning Strategy</title><link>http://arxiv.org/abs/2305.17048v1</link><description>Most commonly used benchmark datasets for computer vision contain irrelevantimages, near duplicates, and label errors. Consequently, model performance onthese benchmarks may not be an accurate estimate of generalization ability.This is a particularly acute concern in computer vision for medicine wheredatasets are typically small, stakes are high, and annotation processes areexpensive and error-prone. In this paper, we propose SelfClean, a generalprocedure to clean up image datasets exploiting a latent space learned withself-supervision. By relying on self-supervised learning, our approach focuseson intrinsic properties of the data and avoids annotation biases. We formulatedataset cleaning as either a set of ranking problems, where human experts canmake decisions with significantly reduced effort, or a set of scoring problems,where decisions can be fully automated based on score distributions. We compareSelfClean against other algorithms on common computer vision benchmarksenhanced with synthetic noise and demonstrate state-of-the-art performance ondetecting irrelevant images, near duplicates, and label errors. In addition, weapply our method to multiple image datasets and confirm an improvement inevaluation reliability.</description><author>Fabian Gröger, Simone Lionetti, Philippe Gottfrois, Alvaro Gonzalez-Jimenez, Ludovic Amruthalingam, Labelling Consortium, Matthew Groh, Alexander A. Navarini, Marc Pouly</author><pubDate>Fri, 26 May 2023 16:57:04 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.17048v1</guid></item><item><title>Reveal the Unknown: Out-of-Knowledge-Base Mention Discovery with Entity Linking</title><link>http://arxiv.org/abs/2302.07189v2</link><description>Discovering entity mentions that are out of a Knowledge Base (KB) from textsplays a critical role in KB maintenance, but has not yet been fully explored.The current methods are mostly limited to the simple threshold-based approachand feature-based classification, and the datasets for evaluation arerelatively rare. We propose BLINKout, a new BERT-based Entity Linking (EL)method which can identify mentions that do not have corresponding KB entitiesby matching them to a special NIL entity. To better utilize BERT, we proposenew techniques including NIL entity representation and classification, withsynonym enhancement. We also propose KB Pruning and Versioning strategies toautomatically construct out-of-KB datasets from common in-KB EL datasets.Results on five datasets of clinical notes, biomedical publications, andWikipedia articles in various domains show the advantages of BLINKout overexisting methods to identify out-of-KB mentions for the medical ontologies,UMLS, SNOMED CT, and the general KB, WikiData.</description><author>Hang Dong, Jiaoyan Chen, Yuan He, Yinan Liu, Ian Horrocks</author><pubDate>Fri, 26 May 2023 16:56:52 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2302.07189v2</guid></item><item><title>PAC-Bayesian Generalization Bounds for Adversarial Generative Models</title><link>http://arxiv.org/abs/2302.08942v2</link><description>We extend PAC-Bayesian theory to generative models and develop generalizationbounds for models based on the Wasserstein distance and the total variationdistance. Our first result on the Wasserstein distance assumes the instancespace is bounded, while our second result takes advantage of dimensionalityreduction. Our results naturally apply to Wasserstein GANs and Energy-BasedGANs, and our bounds provide new training objectives for these two. Althoughour work is mainly theoretical, we perform numerical experiments showingnon-vacuous generalization bounds for Wasserstein GANs on synthetic datasets.</description><author>Sokhna Diarra Mbacke, Florence Clerc, Pascal Germain</author><pubDate>Fri, 26 May 2023 16:54:29 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2302.08942v2</guid></item><item><title>Explaining Deep Learning for ECG Analysis: Building Blocks for Auditing and Knowledge Discovery</title><link>http://arxiv.org/abs/2305.17043v1</link><description>Deep neural networks have become increasingly popular for analyzing ECG databecause of their ability to accurately identify cardiac conditions and hiddenclinical factors. However, the lack of transparency due to the black box natureof these models is a common concern. To address this issue, explainable AI(XAI) methods can be employed. In this study, we present a comprehensiveanalysis of post-hoc XAI methods, investigating the local (attributions persample) and global (based on domain expert concepts) perspectives. We haveestablished a set of sanity checks to identify sensible attribution methods,and we provide quantitative evidence in accordance with expert rules. Thisdataset-wide analysis goes beyond anecdotal evidence by aggregating data acrosspatient subgroups. Furthermore, we demonstrate how these XAI techniques can beutilized for knowledge discovery, such as identifying subtypes of myocardialinfarction. We believe that these proposed methods can serve as building blocksfor a complementary assessment of the internal validity during a certificationprocess, as well as for knowledge discovery in the field of ECG analysis.</description><author>Patrick Wagner, Temesgen Mehari, Wilhelm Haverkamp, Nils Strodthoff</author><pubDate>Fri, 26 May 2023 16:52:08 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.17043v1</guid></item><item><title>RFiD: Towards Rational Fusion-in-Decoder for Open-Domain Question Answering</title><link>http://arxiv.org/abs/2305.17041v1</link><description>Open-Domain Question Answering (ODQA) systems necessitate a reader modelcapable of generating answers by simultaneously referring to multiple passages.Although representative models like Fusion-in-Decoder (FiD) have been proposedto address this challenge, these systems can inadvertently rely on spuriousfeatures instead of genuine causal relationships between the question and thepassages to generate answers. To counter this problem, we introduce theRational Fusion-in-Decoder (RFiD) model. Our model leverages the encoders ofFiD to differentiate between causal relationships and spurious features,subsequently guiding the decoder to generate answers informed by thisdiscernment. Experimental results on two ODQA datasets, Natural Questions (NQ)and TriviaQA (TQ), demonstrate that our model surpasses previous methods,achieving improvements of up to 1.5 and 0.7 in Exact Match scores on NQ, andexhibits an enhanced ability to identify causal relationships.</description><author>Cunxiang Wang, Haofei Yu, Yue Zhang</author><pubDate>Fri, 26 May 2023 16:51:25 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.17041v1</guid></item><item><title>Decision Diagram-Based Branch-and-Bound with Caching for Dominance and Suboptimality Detection</title><link>http://arxiv.org/abs/2211.13118v2</link><description>The branch-and-bound algorithm based on decision diagrams introduced byBergman et al. in 2016 is a framework for solving discrete optimizationproblems with a dynamic programming formulation. It works by compiling a seriesof bounded-width decision diagrams that can provide lower and upper bounds forany given subproblem. Eventually, every part of the search space will be eitherexplored or pruned by the algorithm, thus proving optimality. This paperpresents new ingredients to speed up the search by exploiting the structure ofdynamic programming models. The key idea is to prevent the repeated explorationof nodes corresponding to the same dynamic programming states by storing andquerying thresholds in a data structure called the Barrier. These thresholdsare based on dominance relations between partial solutions previously found.They can be further strengthened by integrating the filtering techniquesintroduced by Gillard et al. in 2021. Computational experiments show that thepruning brought by the Barrier allows to significantly reduce the number ofnodes expanded by the algorithm. This results in more benchmark instances ofdifficult optimization problems being solved in less time while using narrowerdecision diagrams.</description><author>Vianney Coppé, Xavier Gillard, Pierre Schaus</author><pubDate>Fri, 26 May 2023 16:51:22 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2211.13118v2</guid></item><item><title>A Mechanism for Sample-Efficient In-Context Learning for Sparse Retrieval Tasks</title><link>http://arxiv.org/abs/2305.17040v1</link><description>We study the phenomenon of \textit{in-context learning} (ICL) exhibited bylarge language models, where they can adapt to a new learning task, given ahandful of labeled examples, without any explicit parameter optimization. Ourgoal is to explain how a pre-trained transformer model is able to perform ICLunder reasonable assumptions on the pre-training process and the downstreamtasks. We posit a mechanism whereby a transformer can achieve the following:(a) receive an i.i.d. sequence of examples which have been converted into aprompt using potentially-ambiguous delimiters, (b) correctly segment the promptinto examples and labels, (c) infer from the data a \textit{sparse linearregressor} hypothesis, and finally (d) apply this hypothesis on the given testexample and return a predicted label. We establish that this entire procedureis implementable using the transformer mechanism, and we give sample complexityguarantees for this learning framework. Our empirical findings validate thechallenge of segmentation, and we show a correspondence between our positedmechanisms and observed attention maps for step (c).</description><author>Jacob Abernethy, Alekh Agarwal, Teodor V. Marinov, Manfred K. Warmuth</author><pubDate>Fri, 26 May 2023 16:49:43 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.17040v1</guid></item><item><title>Newer is not always better: Rethinking transferability metrics, their peculiarities, stability and performance</title><link>http://arxiv.org/abs/2110.06893v3</link><description>Fine-tuning of large pre-trained image and language models on smallcustomized datasets has become increasingly popular for improved prediction andefficient use of limited resources. Fine-tuning requires identification of bestmodels to transfer-learn from and quantifying transferability preventsexpensive re-training on all of the candidate models/tasks pairs. In thispaper, we show that the statistical problems with covariance estimation drivethe poor performance of H-score -- a common baseline for newer metrics -- andpropose shrinkage-based estimator. This results in up to 80% absolute gain inH-score correlation performance, making it competitive with thestate-of-the-art LogME measure. Our shrinkage-based H-score is$3\times$-10$\times$ faster to compute compared to LogME. Additionally, we lookinto a less common setting of target (as opposed to source) task selection. Wedemonstrate previously overlooked problems in such settings with differentnumber of labels, class-imbalance ratios etc. for some recent metrics e.g.,NCE, LEEP that resulted in them being misrepresented as leading measures. Wepropose a correction and recommend measuring correlation performance againstrelative accuracy in such settings. We support our findings with ~164,000(fine-tuning trials) experiments on both vision models and graph neuralnetworks.</description><author>Shibal Ibrahim, Natalia Ponomareva, Rahul Mazumder</author><pubDate>Fri, 26 May 2023 16:45:37 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2110.06893v3</guid></item><item><title>Justification vs. Transparency: Why and How Visual Explanations in a Scientific Literature Recommender System</title><link>http://arxiv.org/abs/2305.17034v1</link><description>Significant attention has been paid to enhancing recommender systems (RS)with explanation facilities to help users make informed decisions and increasetrust in and satisfaction with the RS. Justification and transparency representtwo crucial goals in explainable recommendation. Different from transparency,which faithfully exposes the reasoning behind the recommendation mechanism,justification conveys a conceptual model that may differ from that of theunderlying algorithm. An explanation is an answer to a question. In explainablerecommendation, a user would want to ask questions (referred to asintelligibility types) to understand results given by the RS. In this paper, weidentify relationships between Why and How explanation intelligibility typesand the explanation goals of justification and transparency. We followed theHuman-Centered Design (HCD) approach and leveraged the What-Why-Howvisualization framework to systematically design and implement Why and Howvisual explanations in the transparent Recommendation and Interest ModelingApplication (RIMA). Furthermore, we conducted a qualitative user study (N=12)to investigate the potential effects of providing Why and How explanationstogether in an explainable RS on the users' perceptions regarding transparency,trust, and satisfaction. Our study showed qualitative evidence confirming thatthe choice of the explanation intelligibility types depends on the explanationgoal and user type.</description><author>Mouadh Guesmi, Mohamed Amine Chatti, Shoeb Joarder, Qurat Ul Ain, Clara Siepmann, Hoda Ghanbarzadeh, Rawaa Alatrash</author><pubDate>Fri, 26 May 2023 16:40:46 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.17034v1</guid></item><item><title>The Brain Tumor Segmentation (BraTS) Challenge 2023: Focus on Pediatrics (CBTN-CONNECT-DIPGR-ASNR-MICCAI BraTS-PEDs)</title><link>http://arxiv.org/abs/2305.17033v1</link><description>Pediatric tumors of the central nervous system are the most common cause ofcancer-related death in children. The five-year survival rate for high-gradegliomas in children is less than 20\%. Due to their rarity, the diagnosis ofthese entities is often delayed, their treatment is mainly based on historictreatment concepts, and clinical trials require multi-institutionalcollaborations. The MICCAI Brain Tumor Segmentation (BraTS) Challenge is alandmark community benchmark event with a successful history of 12 years ofresource creation for the segmentation and analysis of adult glioma. Here wepresent the CBTN-CONNECT-DIPGR-ASNR-MICCAI BraTS-PEDs 2023 challenge, whichrepresents the first BraTS challenge focused on pediatric brain tumors withdata acquired across multiple international consortia dedicated to pediatricneuro-oncology and clinical trials. The BraTS-PEDs 2023 challenge focuses onbenchmarking the development of volumentric segmentation algorithms forpediatric brain glioma through standardized quantitative performance evaluationmetrics utilized across the BraTS 2023 cluster of challenges. Models gainingknowledge from the BraTS-PEDs multi-parametric structural MRI (mpMRI) trainingdata will be evaluated on separate validation and unseen test mpMRI dataofhigh-grade pediatric glioma. The CBTN-CONNECT-DIPGR-ASNR-MICCAI BraTS-PEDs 2023challenge brings together clinicians and AI/imaging scientists to lead tofaster development of automated segmentation techniques that could benefitclinical trials, and ultimately the care of children with brain tumors.</description><author>Anahita Fathi Kazerooni, Nastaran Khalili, Xinyang Liu, Debanjan Haldar, Zhifan Jiang, Syed Muhammed Anwar, Jake Albrecht, Maruf Adewole, Udunna Anazodo, Hannah Anderson, Sina Bagheri, Ujjwal Baid, Timothy Bergquist, Evan Calabrese, Verena Chung, Gian-Marco Conte, Farouk Dako, James Eddy, Ivan Ezhov, Ariana Familiar, Keyvan Farahani, Shuvanjan Haldar, Juan Eugenio Iglesias, Anastasia Janas, Elaine Johansen, Florian Kofler, Dominic LaBella, Koen Van Leemput, Hongwei Bran Li, Nazanin Maleki, Zeke Meier, Bjoern Menze, Ahmed W Moawad, Marie Piraud, Tina Poussaint, Zachary Reitman, Jeffrey D Rudie, Ibraheem Salman Shaikh, Russel Taki Shinohara, Wenxin Tu, Karthik Viswanathan, Chunhao Wang, Jeffrey B Ware, Benedikt Wiestler, Walter Wiggins, Anna Zapaishchykova, Mariam Aboian, Miriam Bornhorst, P</author><pubDate>Fri, 26 May 2023 16:40:11 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.17033v1</guid></item><item><title>Better Batch for Deep Probabilistic Time Series Forecasting</title><link>http://arxiv.org/abs/2305.17028v1</link><description>Deep probabilistic time series forecasting has gained significant attentiondue to its ability to provide valuable uncertainty quantification fordecision-making tasks. However, many existing models oversimplify the problemby assuming the error process is time-independent, thereby overlooking theserial correlation in the error process. This oversight can potentiallydiminish the accuracy of the forecasts, rendering these models less effectivefor decision-making purposes. To overcome this limitation, we propose aninnovative training method that incorporates error autocorrelation to enhancethe accuracy of probabilistic forecasting. Our method involves constructing amini-batch as a collection of $D$ consecutive time series segments for modeltraining and explicitly learning a covariance matrix over each mini-batch thatencodes the error correlation among adjacent time steps. The resultingcovariance matrix can be used to improve prediction accuracy and enhanceuncertainty quantification. We evaluate our method using DeepAR on multiplepublic datasets, and the experimental results confirm that our framework caneffectively capture the error autocorrelation and enhance probabilisticforecasting.</description><author>Vincent Zhihao Zheng, Seongjin Choi, Lijun Sun</author><pubDate>Fri, 26 May 2023 16:36:59 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.17028v1</guid></item><item><title>On the Computational Power of Decoder-Only Transformer Language Models</title><link>http://arxiv.org/abs/2305.17026v1</link><description>This article presents a theoretical evaluation of the computationaluniversality of decoder-only transformer models. We extend the theoreticalliterature on transformer models and show that decoder-only transformerarchitectures (even with only a single layer and single attention head) areTuring complete under reasonable assumptions. From the theoretical analysis, weshow sparsity/compressibility of the word embedding to be a necessary conditionfor Turing completeness to hold.</description><author>Jesse Roberts</author><pubDate>Fri, 26 May 2023 16:35:43 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.17026v1</guid></item><item><title>Bayesian Kernelized Tensor Factorization as Surrogate for Bayesian Optimization</title><link>http://arxiv.org/abs/2302.14510v2</link><description>Bayesian optimization (BO) primarily uses Gaussian processes (GP) as the keysurrogate model, mostly with a simple stationary and separable kernel functionsuch as the squared-exponential kernel with automatic relevance determination(SE-ARD). However, such simple kernel specifications are deficient in learningfunctions with complex features, such as being nonstationary, nonseparable, andmultimodal. Approximating such functions using a local GP, even in alow-dimensional space, requires a large number of samples, not to mention in ahigh-dimensional setting. In this paper, we propose to use Bayesian KernelizedTensor Factorization (BKTF) -- as a new surrogate model -- for BO in a$D$-dimensional Cartesian product space. Our key idea is to approximate theunderlying $D$-dimensional solid with a fully Bayesian low-rank tensor CPdecomposition, in which we place GP priors on the latent basis functions foreach dimension to encode local consistency and smoothness. With thisformulation, information from each sample can be shared not only with neighborsbut also across dimensions. Although BKTF no longer has an analyticalposterior, we can still efficiently approximate the posterior distributionthrough Markov chain Monte Carlo (MCMC) and obtain prediction and fulluncertainty quantification (UQ). We conduct numerical experiments on bothstandard BO test functions and machine learning hyperparameter tuning problems,and our results show that BKTF offers a flexible and highly effective approachfor characterizing complex functions with UQ, especially in cases where theinitial sample size and budget are severely limited.</description><author>Mengying Lei, Lijun Sun</author><pubDate>Fri, 26 May 2023 16:33:50 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2302.14510v2</guid></item><item><title>Understanding Sparse Feature Updates in Deep Networks using Iterative Linearisation</title><link>http://arxiv.org/abs/2211.12345v2</link><description>Larger and deeper networks generalise well despite their increased capacityto overfit. Understanding why this happens is theoretically and practicallyimportant. One approach has been to look at the infinitely wide limits of suchnetworks. However, these cannot fully explain finite networks as they do notlearn features and the empirical kernel changes significantly during trainingin contrast to infinite networks. In this work, we derive an iterativelinearised training method to investigate this distinction, allowing us tocontrol for sparse (i.e. infrequent) feature updates and quantify the frequencyof feature learning needed to achieve comparable performance. We justifyiterative linearisation as an interpolation between a finite analog of theinfinite width regime, which does not learn features, and standard gradientdescent training, which does. We also show that it is analogous to a dampedversion of the Gauss-Newton algorithm -- a second-order method. We show that ina variety of cases, iterative linearised training performs on par with standardtraining, noting in particular how much less frequent feature learning isrequired to achieve comparable performance. We also show that feature learningis essential for good performance. Since such feature learning inevitablycauses changes in the NTK kernel, it provides direct negative evidence for theNTK theory, which states the NTK kernel remains constant during training.</description><author>Adrian Goldwaser, Hong Ge</author><pubDate>Fri, 26 May 2023 16:32:41 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2211.12345v2</guid></item><item><title>Contouring by Unit Vector Field Regression</title><link>http://arxiv.org/abs/2305.17024v1</link><description>This work introduces a simple deep-learning based method to delineatecontours by `walking' along learnt unit vector fields. We demonstrate theeffectiveness of our pipeline on the unique case of open contours on the taskof delineating the sacroiliac joints (SIJs) in spinal MRIs. We show that: (i)95% of the time the average root mean square error of the predicted contouragainst the original ground truth is below 4.5 pixels (2.5mm for a standardT1-weighted SIJ MRI), and (ii) the proposed method is better than the baselineof regressing vertices or landmarks of contours.</description><author>Amir Jamaludin, Sarim Ather, Timor Kadir, Rhydian Windsor</author><pubDate>Fri, 26 May 2023 16:32:22 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.17024v1</guid></item><item><title>Are Deep Neural Networks Adequate Behavioural Models of Human Visual Perception?</title><link>http://arxiv.org/abs/2305.17023v1</link><description>Deep neural networks (DNNs) are machine learning algorithms that haverevolutionised computer vision due to their remarkable successes in tasks likeobject classification and segmentation. The success of DNNs as computer visionalgorithms has led to the suggestion that DNNs may also be good models of humanvisual perception. We here review evidence regarding current DNNs as adequatebehavioural models of human core object recognition. To this end, we argue thatit is important to distinguish between statistical tools and computationalmodels, and to understand model quality as a multidimensional concept whereclarity about modelling goals is key. Reviewing a large number ofpsychophysical and computational explorations of core object recognitionperformance in humans and DNNs, we argue that DNNs are highly valuablescientific tools but that as of today DNNs should only be regarded as promising-- but not yet adequate -- computational models of human core objectrecognition behaviour. On the way we dispel a number of myths surrounding DNNsin vision science.</description><author>Felix A. Wichmann, Robert Geirhos</author><pubDate>Fri, 26 May 2023 16:31:06 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.17023v1</guid></item><item><title>Multi-VALUE: A Framework for Cross-Dialectal English NLP</title><link>http://arxiv.org/abs/2212.08011v2</link><description>Dialect differences caused by regional, social, and economic factors causeperformance discrepancies for many groups of language technology users.Inclusive and equitable language technology must critically be dialectinvariant, meaning that performance remains constant over dialectal shifts.Current systems often fall short of this ideal since they are designed andtested on a single dialect: Standard American English (SAE). We introduce asuite of resources for evaluating and achieving English dialect invariance. Theresource is called Multi-VALUE, a controllable rule-based translation systemspanning 50 English dialects and 189 unique linguistic features. Multi-VALUEmaps SAE to synthetic forms of each dialect. First, we use this system tostress tests question answering, machine translation, and semantic parsing.Stress tests reveal significant performance disparities for leading models onnon-standard dialects. Second, we use this system as a data augmentationtechnique to improve the dialect robustness of existing systems. Finally, wepartner with native speakers of Chicano and Indian English to release newgold-standard variants of the popular CoQA task. To execute the transformationcode, run model checkpoints, and download both synthetic and gold-standarddialectal benchmark datasets, see http://value-nlp.org.</description><author>Caleb Ziems, William Held, Jingfeng Yang, Diyi Yang</author><pubDate>Fri, 26 May 2023 16:27:33 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2212.08011v2</guid></item><item><title>GLOBE-CE: A Translation-Based Approach for Global Counterfactual Explanations</title><link>http://arxiv.org/abs/2305.17021v1</link><description>Counterfactual explanations have been widely studied in explainability, witha range of application dependent methods prominent in fairness, recourse andmodel understanding. The major shortcoming associated with these methods,however, is their inability to provide explanations beyond the local orinstance-level. While many works touch upon the notion of a global explanation,typically suggesting to aggregate masses of local explanations in the hope ofascertaining global properties, few provide frameworks that are both reliableand computationally tractable. Meanwhile, practitioners are requesting moreefficient and interactive explainability tools. We take this opportunity topropose Global &amp; Efficient Counterfactual Explanations (GLOBE-CE), a flexibleframework that tackles the reliability and scalability issues associated withcurrent state-of-the-art, particularly on higher dimensional datasets and inthe presence of continuous features. Furthermore, we provide a uniquemathematical analysis of categorical feature translations, utilising it in ourmethod. Experimental evaluation with publicly available datasets and userstudies demonstrate that GLOBE-CE performs significantly better than thecurrent state-of-the-art across multiple metrics (e.g., speed, reliability).</description><author>Dan Ley, Saumitra Mishra, Daniele Magazzeni</author><pubDate>Fri, 26 May 2023 16:26:59 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.17021v1</guid></item><item><title>Diable: Efficient Dialogue State Tracking as Operations on Tables</title><link>http://arxiv.org/abs/2305.17020v1</link><description>Sequence-to-sequence state-of-the-art systems for dialogue state tracking(DST) use the full dialogue history as input, represent the current state as alist with all the slots, and generate the entire state from scratch at eachdialogue turn. This approach is inefficient, especially when the number ofslots is large and the conversation is long. In this paper, we propose Diable,a new task formalisation that simplifies the design and implementation ofefficient DST systems and allows one to easily plug and play large languagemodels. We represent the dialogue state as a table and formalise DST as a tablemanipulation task. At each turn, the system updates the previous state bygenerating table operations based on the dialogue context. Extensiveexperimentation on the MultiWoz datasets demonstrates that Diable (i)outperforms strong efficient DST baselines, (ii) is 2.4x more time efficientthan current state-of-the-art methods while retaining competitive Joint GoalAccuracy, and (iii) is robust to noisy data annotations due to the tableoperations approach.</description><author>Pietro Lesci, Yoshinari Fujinuma, Momchil Hardalov, Chao Shang, Lluis Marquez</author><pubDate>Fri, 26 May 2023 16:26:12 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.17020v1</guid></item><item><title>Commonsense Knowledge Graph Completion Via Contrastive Pretraining and Node Clustering</title><link>http://arxiv.org/abs/2305.17019v1</link><description>The nodes in the commonsense knowledge graph (CSKG) are normally representedby free-form short text (e.g., word or phrase). Different nodes may representthe same concept. This leads to the problems of edge sparsity and noderedundancy, which challenges CSKG representation and completion. On the onehand, edge sparsity limits the performance of graph representation learning; Onthe other hand, node redundancy makes different nodes corresponding to the sameconcept have inconsistent relations with other nodes. To address the twoproblems, we propose a new CSKG completion framework based on ContrastivePretraining and Node Clustering (CPNC). Contrastive Pretraining constructspositive and negative head-tail node pairs on CSKG and utilizes contrastivelearning to obtain better semantic node representation. Node Clusteringaggregates nodes with the same concept into a latent concept, assisting thetask of CSKG completion. We evaluate our CPNC approach on two CSKG completionbenchmarks (CN-100K and ATOMIC), where CPNC outperforms the state-of-the-artmethods. Extensive experiments demonstrate that both Contrastive Pretrainingand Node Clustering can significantly improve the performance of CSKGcompletion. The source code of CPNC is publicly available on\url{https://github.com/NUSTM/CPNC}.</description><author>Siwei Wu, Xiangqing Shen, Rui Xia</author><pubDate>Fri, 26 May 2023 16:24:32 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.17019v1</guid></item><item><title>Actor-Critic or Critic-Actor? A Tale of Two Time Scales</title><link>http://arxiv.org/abs/2210.04470v3</link><description>We revisit the standard formulation of tabular actor-critic algorithm as atwo time-scale stochastic approximation with value function computed on afaster time-scale and policy computed on a slower time-scale. This emulatespolicy iteration. We observe that reversal of the time scales will in factemulate value iteration and is a legitimate algorithm. We provide a proof ofconvergence and compare the two empirically with and without functionapproximation (with both linear and nonlinear function approximators) andobserve that our proposed critic-actor algorithm performs on par withactor-critic in terms of both accuracy and computational effort.</description><author>Shalabh Bhatnagar, Vivek S. Borkar, Soumyajit Guin</author><pubDate>Fri, 26 May 2023 16:23:39 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2210.04470v3</guid></item><item><title>Formal Modelling for Multi-Robot Systems Under Uncertainty</title><link>http://arxiv.org/abs/2305.17018v1</link><description>Purpose of Review: To effectively synthesise and analyse multi-robotbehaviour, we require formal task-level models which accurately capturemulti-robot execution. In this paper, we review modelling formalisms formulti-robot systems under uncertainty, and discuss how they can be used forplanning, reinforcement learning, model checking, and simulation. Recent Findings: Recent work has investigated models which more accuratelycapture multi-robot execution by considering different forms of uncertainty,such as temporal uncertainty and partial observability, and modelling theeffects of robot interactions on action execution. Other strands of work havepresented approaches for reducing the size of multi-robot models to admit moreefficient solution methods. This can be achieved by decoupling the robots underindependence assumptions, or reasoning over higher level macro actions. Summary: Existing multi-robot models demonstrate a trade off betweenaccurately capturing robot dependencies and uncertainty, and being small enoughto tractably solve real world problems. Therefore, future research shouldexploit realistic assumptions over multi-robot behaviour to develop smallermodels which retain accurate representations of uncertainty and robotinteractions; and exploit the structure of multi-robot problems, such asfactored state spaces, to develop scalable solution methods.</description><author>Charlie Street, Masoumeh Mansouri, Bruno Lacerda</author><pubDate>Fri, 26 May 2023 16:23:35 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.17018v1</guid></item><item><title>Investigating how ReLU-networks encode symmetries</title><link>http://arxiv.org/abs/2305.17017v1</link><description>Many data symmetries can be described in terms of group equivariance and themost common way of encoding group equivariances in neural networks is bybuilding linear layers that are group equivariant. In this work we investigatewhether equivariance of a network implies that all layers are equivariant. Onthe theoretical side we find cases where equivariance implies layerwiseequivariance, but also demonstrate that this is not the case generally.Nevertheless, we conjecture that CNNs that are trained to be equivariant willexhibit layerwise equivariance and explain how this conjecture is a weakerversion of the recent permutation conjecture by Entezari et al. [2022]. Weperform quantitative experiments with VGG-nets on CIFAR10 and qualitativeexperiments with ResNets on ImageNet to illustrate and support our theoreticalfindings. These experiments are not only of interest for understanding howgroup equivariance is encoded in ReLU-networks, but they also give a newperspective on Entezari et al.'s permutation conjecture as we find that it istypically easier to merge a network with a group-transformed version of itselfthan merging two different networks.</description><author>Georg Bökman, Fredrik Kahl</author><pubDate>Fri, 26 May 2023 16:23:20 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.17017v1</guid></item><item><title>D-CALM: A Dynamic Clustering-based Active Learning Approach for Mitigating Bias</title><link>http://arxiv.org/abs/2305.17013v1</link><description>Despite recent advancements, NLP models continue to be vulnerable to bias.This bias often originates from the uneven distribution of real-world data andcan propagate through the annotation process. Escalated integration of thesemodels in our lives calls for methods to mitigate bias without overbearingannotation costs. While active learning (AL) has shown promise in trainingmodels with a small amount of annotated data, AL's reliance on the model'sbehavior for selective sampling can lead to an accumulation of unwanted biasrather than bias mitigation. However, infusing clustering with AL can overcomethe bias issue of both AL and traditional annotation methods while exploitingAL's annotation efficiency. In this paper, we propose a novel adaptiveclustering-based active learning algorithm, D-CALM, that dynamically adjustsclustering and annotation efforts in response to an estimated classifiererror-rate. Experiments on eight datasets for a diverse set of textclassification tasks, including emotion, hatespeech, dialog act, and book typedetection, demonstrate that our proposed algorithm significantly outperformsbaseline AL approaches with both pretrained transformers and traditionalSupport Vector Machines. D-CALM showcases robustness against different measuresof information gain and, as evident from our analysis of label and errordistribution, can significantly reduce unwanted model bias.</description><author>Sabit Hassan, Malihe Alikhani</author><pubDate>Fri, 26 May 2023 16:17:43 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.17013v1</guid></item><item><title>Co-training with High-Confidence Pseudo Labels for Semi-supervised Medical Image Segmentation</title><link>http://arxiv.org/abs/2301.04465v3</link><description>Consistency regularization and pseudo labeling-based semi-supervised methodsperform co-training using the pseudo labels from multi-view inputs. However,such co-training models tend to converge early to a consensus, degenerating tothe self-training ones, and produce low-confidence pseudo labels from theperturbed inputs during training. To address these issues, we propose anUncertainty-guided Collaborative Mean-Teacher (UCMT) for semi-supervisedsemantic segmentation with the high-confidence pseudo labels. Concretely, UCMTconsists of two main components: 1) collaborative mean-teacher (CMT) forencouraging model disagreement and performing co-training between thesub-networks, and 2) uncertainty-guided region mix (UMIX) for manipulating theinput images according to the uncertainty maps of CMT and facilitating CMT toproduce high-confidence pseudo labels. Combining the strengths of UMIX withCMT, UCMT can retain model disagreement and enhance the quality of pseudolabels for the co-training segmentation. Extensive experiments on four publicmedical image datasets including 2D and 3D modalities demonstrate thesuperiority of UCMT over the state-of-the-art. Code is available at:https://github.com/Senyh/UCMT.</description><author>Zhiqiang Shen, Peng Cao, Hua Yang, Xiaoli Liu, Jinzhu Yang, Osmar R. Zaiane</author><pubDate>Fri, 26 May 2023 16:14:45 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2301.04465v3</guid></item><item><title>SOC: Semantic-Assisted Object Cluster for Referring Video Object Segmentation</title><link>http://arxiv.org/abs/2305.17011v1</link><description>This paper studies referring video object segmentation (RVOS) by boostingvideo-level visual-linguistic alignment. Recent approaches model the RVOS taskas a sequence prediction problem and perform multi-modal interaction as well assegmentation for each frame separately. However, the lack of a global view ofvideo content leads to difficulties in effectively utilizing inter-framerelationships and understanding textual descriptions of object temporalvariations. To address this issue, we propose Semantic-assisted Object Cluster(SOC), which aggregates video content and textual guidance for unified temporalmodeling and cross-modal alignment. By associating a group of frame-levelobject embeddings with language tokens, SOC facilitates joint space learningacross modalities and time steps. Moreover, we present multi-modal contrastivesupervision to help construct well-aligned joint space at the video level. Weconduct extensive experiments on popular RVOS benchmarks, and our methodoutperforms state-of-the-art competitors on all benchmarks by a remarkablemargin. Besides, the emphasis on temporal coherence enhances the segmentationstability and adaptability of our method in processing text expressions withtemporal variations. Code will be available.</description><author>Zhuoyan Luo, Yicheng Xiao, Yong Liu, Shuyan Li, Yitong Wang, Yansong Tang, Xiu Li, Yujiu Yang</author><pubDate>Fri, 26 May 2023 16:13:44 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.17011v1</guid></item><item><title>Let the Flows Tell: Solving Graph Combinatorial Optimization Problems with GFlowNets</title><link>http://arxiv.org/abs/2305.17010v1</link><description>Combinatorial optimization (CO) problems are often NP-hard and thus out ofreach for exact algorithms, making them a tempting domain to apply machinelearning methods. The highly structured constraints in these problems canhinder either optimization or sampling directly in the solution space. On theother hand, GFlowNets have recently emerged as a powerful machinery toefficiently sample from composite unnormalized densities sequentially and havethe potential to amortize such solution-searching processes in CO, as well asgenerate diverse solution candidates. In this paper, we design Markov decisionprocesses (MDPs) for different combinatorial problems and propose to trainconditional GFlowNets to sample from the solution space. Efficient trainingtechniques are also developed to benefit long-range credit assignment. Throughextensive experiments on a variety of different CO tasks with synthetic andrealistic data, we demonstrate that GFlowNet policies can efficiently findhigh-quality solutions.</description><author>Dinghuai Zhang, Hanjun Dai, Nikolay Malkin, Aaron Courville, Yoshua Bengio, Ling Pan</author><pubDate>Fri, 26 May 2023 16:13:09 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.17010v1</guid></item><item><title>NormBank: A Knowledge Bank of Situational Social Norms</title><link>http://arxiv.org/abs/2305.17008v1</link><description>We present NormBank, a knowledge bank of 155k situational norms. Thisresource is designed to ground flexible normative reasoning for interactive,assistive, and collaborative AI systems. Unlike prior commonsense resources,NormBank grounds each inference within a multivalent sociocultural frame, whichincludes the setting (e.g., restaurant), the agents' contingent roles (waiter,customer), their attributes (age, gender), and other physical, social, andcultural constraints (e.g., the temperature or the country of operation). Intotal, NormBank contains 63k unique constraints from a taxonomy that weintroduce and iteratively refine here. Constraints then apply in differentcombinations to frame social norms. Under these manipulations, norms arenon-monotonic - one can cancel an inference by updating its frame evenslightly. Still, we find evidence that neural models can help reliably extendthe scope and coverage of NormBank. We further demonstrate the utility of thisresource with a series of transfer experiments.</description><author>Caleb Ziems, Jane Dwivedi-Yu, Yi-Chia Wang, Alon Halevy, Diyi Yang</author><pubDate>Fri, 26 May 2023 16:09:11 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.17008v1</guid></item><item><title>Improving Knowledge Distillation via Regularizing Feature Norm and Direction</title><link>http://arxiv.org/abs/2305.17007v1</link><description>Knowledge distillation (KD) exploits a large well-trained model (i.e.,teacher) to train a small student model on the same dataset for the same task.Treating teacher features as knowledge, prevailing methods of knowledgedistillation train student by aligning its features with the teacher's, e.g.,by minimizing the KL-divergence between their logits or L2 distance betweentheir intermediate features. While it is natural to believe that betteralignment of student features to the teacher better distills teacher knowledge,simply forcing this alignment does not directly contribute to the student'sperformance, e.g., classification accuracy. In this work, we propose to alignstudent features with class-mean of teacher features, where class-meannaturally serves as a strong classifier. To this end, we explore baselinetechniques such as adopting the cosine distance based loss to encourage thesimilarity between student features and their corresponding class-means of theteacher. Moreover, we train the student to produce large-norm features,inspired by other lines of work (e.g., model pruning and domain adaptation),which find the large-norm features to be more significant. Finally, we proposea rather simple loss term (dubbed ND loss) to simultaneously (1) encouragestudent to produce large-\emph{norm} features, and (2) align the\emph{direction} of student features and teacher class-means. Experiments onstandard benchmarks demonstrate that our explored techniques help existing KDmethods achieve better performance, i.e., higher classification accuracy onImageNet and CIFAR100 datasets, and higher detection precision on COCO dataset.Importantly, our proposed ND loss helps the most, leading to thestate-of-the-art performance on these benchmarks. The source code is availableat \url{https://github.com/WangYZ1608/Knowledge-Distillation-via-ND}.</description><author>Yuzhu Wang, Lechao Cheng, Manni Duan, Yongheng Wang, Zunlei Feng, Shu Kong</author><pubDate>Fri, 26 May 2023 16:05:19 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.17007v1</guid></item><item><title>Zero-shot Visual Question Answering with Language Model Feedback</title><link>http://arxiv.org/abs/2305.17006v1</link><description>In this paper, we propose a novel language model guided captioning approach,LAMOC, for knowledge-based visual question answering (VQA). Our approachemploys the generated captions by a captioning model as the context of ananswer prediction model, which is a Pre-trained Language model (PLM). As themajor contribution, we leverage the guidance and feedback of the predictionmodel to improve the capability of the captioning model. In this way, thecaptioning model can become aware of the task goal and information need fromthe PLM. To develop our approach, we design two specific training stages, wherethe first stage adapts the captioning model to the prediction model (selectingmore suitable caption propositions for training) and the second stage tunes thecaptioning model according to the task goal (learning from feedback of thePLM). Extensive experiments demonstrate the effectiveness of the proposedapproach on the knowledge-based VQA task. Specifically, on the challengingA-OKVQA dataset, LAMOC outperforms several competitive zero-shot methods andeven achieves comparable results to a fine-tuned VLP model. Our code ispublicly available at https://github.com/RUCAIBox/LAMOC.</description><author>Yifan Du, Junyi Li, Tianyi Tang, Wayne Xin Zhao, Ji-Rong Wen</author><pubDate>Fri, 26 May 2023 16:04:20 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.17006v1</guid></item><item><title>Aggregating Capacity in FL through Successive Layer Training for Computationally-Constrained Devices</title><link>http://arxiv.org/abs/2305.17005v1</link><description>Federated learning (FL) is usually performed on resource-constrained edgedevices, e.g., with limited memory for the computation. If the required memoryto train a model exceeds this limit, the device will be excluded from thetraining. This can lead to a lower accuracy as valuable data and computationresources are excluded from training, also causing bias and unfairness. The FLtraining process should be adjusted to such constraints. The state-of-the-arttechniques propose training subsets of the FL model at constrained devices,reducing their resource requirements for training. But these techniques largelylimit the co-adaptation among parameters of the model and are highlyinefficient, as we show: it is actually better to train a smaller (lessaccurate) model by the system where all the devices can train the modelend-to-end, than applying such techniques. We propose a new method that enablessuccessive freezing and training of the parameters of the FL model at devices,reducing the training's resource requirements at the devices, while stillallowing enough co-adaptation between parameters. We show through extensiveexperimental evaluation that our technique greatly improves the accuracy of thetrained model (by 52.4 p.p.) compared with the state of the art, efficientlyaggregating the computation capacity available on distributed devices.</description><author>Kilian Pfeiffer, Ramin Khalili, Jörg Henkel</author><pubDate>Fri, 26 May 2023 16:04:06 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.17005v1</guid></item><item><title>An Empirical Comparison of LM-based Question and Answer Generation Methods</title><link>http://arxiv.org/abs/2305.17002v1</link><description>Question and answer generation (QAG) consists of generating a set ofquestion-answer pairs given a context (e.g. a paragraph). This task has avariety of applications, such as data augmentation for question answering (QA)models, information retrieval and education. In this paper, we establishbaselines with three different QAG methodologies that leveragesequence-to-sequence language model (LM) fine-tuning. Experiments show that anend-to-end QAG model, which is computationally light at both training andinference times, is generally robust and outperforms other more convolutedapproaches. However, there are differences depending on the underlyinggenerative LM. Finally, our analysis shows that QA models fine-tuned solely ongenerated question-answer pairs can be competitive when compared to supervisedQA models trained on human-labeled data.</description><author>Asahi Ushio, Fernando Alva-Manchego, Jose Camacho-Collados</author><pubDate>Fri, 26 May 2023 15:59:53 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.17002v1</guid></item><item><title>Leveraging characteristics of the output probability distribution for identifying adversarial audio examples</title><link>http://arxiv.org/abs/2305.17000v1</link><description>Adversarial attacks represent a security threat to machine learning basedautomatic speech recognition (ASR) systems. To prevent such attacks we proposean adversarial example detection strategy applicable to any ASR system thatpredicts a probability distribution over output tokens in each time step. Wemeasure a set of characteristics of this distribution: the median, maximum, andminimum over the output probabilities, the entropy, and the Jensen-Shannondivergence of the distributions of subsequent time steps. Then, we fit aGaussian distribution to the characteristics observed for benign data. Bycomputing the likelihood of incoming new audio we can distinguish maliciousinputs from samples from clean data with an area under the receiving operatorcharacteristic (AUROC) higher than 0.99, which drops to 0.98 for less-qualityaudio. To assess the robustness of our method we build adaptive attacks. Thisreduces the AUROC to 0.96 but results in more noisy adversarial clips.</description><author>Matías P. Pizarro B., Dorothea Kolossa, Asja Fischer</author><pubDate>Fri, 26 May 2023 15:59:28 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.17000v1</guid></item><item><title>Three Towers: Flexible Contrastive Learning with Pretrained Image Models</title><link>http://arxiv.org/abs/2305.16999v1</link><description>We introduce Three Towers (3T), a flexible method to improve the contrastivelearning of vision-language models by incorporating pretrained imageclassifiers. While contrastive models are usually trained from scratch, LiT(Zhai et al., 2022) has recently shown performance gains from using pretrainedclassifier embeddings. However, LiT directly replaces the image tower with thefrozen embeddings, excluding any potential benefits of contrastively trainingthe image tower. With 3T, we propose a more flexible strategy that allows theimage tower to benefit from both pretrained embeddings and contrastivetraining. To achieve this, we introduce a third tower that contains the frozenpretrained embeddings, and we encourage alignment between this third tower andthe main image-text towers. Empirically, 3T consistently improves over LiT andthe CLIP-style from-scratch baseline for retrieval tasks. For classification,3T reliably improves over the from-scratch baseline, and while it underperformsrelative to LiT for JFT-pretrained models, it outperforms LiT for ImageNet-21kand Places365 pretraining.</description><author>Jannik Kossen, Mark Collier, Basil Mustafa, Xiao Wang, Xiaohua Zhai, Lucas Beyer, Andreas Steiner, Jesse Berent, Rodolphe Jenatton, Efi Kokiopoulou</author><pubDate>Fri, 26 May 2023 15:59:16 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.16999v1</guid></item><item><title>A Tale of Two Approximations: Tightening Over-Approximation for DNN Robustness Verification via Under-Approximation</title><link>http://arxiv.org/abs/2305.16998v1</link><description>The robustness of deep neural networks (DNNs) is crucial to the hostingsystem's reliability and security. Formal verification has been demonstrated tobe effective in providing provable robustness guarantees. To improve itsscalability, over-approximating the non-linear activation functions in DNNs bylinear constraints has been widely adopted, which transforms the verificationproblem into an efficiently solvable linear programming problem. Many effortshave been dedicated to defining the so-called tightest approximations to reduceoverestimation imposed by over-approximation. In this paper, we study existingapproaches and identify a dominant factor in defining tight approximation,namely the approximation domain of the activation function. We find out thattight approximations defined on approximation domains may not be as tight asthe ones on their actual domains, yet existing approaches all rely only onapproximation domains. Based on this observation, we propose a noveldual-approximation approach to tighten over-approximations, leveraging anactivation function's underestimated domain to define tight approximationbounds. We implement our approach with two complementary algorithms basedrespectively on Monte Carlo simulation and gradient descent into a tool calledDualApp. We assess it on a comprehensive benchmark of DNNs with differentarchitectures. Our experimental results show that DualApp significantlyoutperforms the state-of-the-art approaches with 100% - 1000% improvement onthe verified robustness ratio and 10.64% on average (up to 66.53%) on thecertified lower bound.</description><author>Zhiyi Xue, Si Liu, Zhaodi Zhang, Yiting Wu, Min Zhang</author><pubDate>Fri, 26 May 2023 15:58:30 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.16998v1</guid></item><item><title>Sharp Bounds for Generalized Causal Sensitivity Analysis</title><link>http://arxiv.org/abs/2305.16988v1</link><description>Causal inference from observational data is crucial for many disciplines suchas medicine and economics. However, sharp bounds for causal effects underrelaxations of the unconfoundedness assumption (causal sensitivity analysis)are subject to ongoing research. So far, works with sharp bounds are restrictedto fairly simple settings (e.g., a single binary treatment). In this paper, wepropose a unified framework for causal sensitivity analysis under unobservedconfounding in various settings. For this, we propose a flexible generalizationof the marginal sensitivity model (MSM) and then derive sharp bounds for alarge class of causal effects. This includes (conditional) average treatmenteffects, effects for mediation analysis and path analysis, and distributionaleffects. Furthermore, our sensitivity model is applicable to discrete,continuous, and time-varying treatments. It allows us to interpret the partialidentification problem under unobserved confounding as a distribution shift inthe latent confounders while evaluating the causal effect of interest. In thespecial case of a single binary treatment, our bounds for (conditional) averagetreatment effects coincide with recent optimality results for causalsensitivity analysis. Finally, we propose a scalable algorithm to estimate oursharp bounds from observational data.</description><author>Dennis Frauen, Valentyn Melnychuk, Stefan Feuerriegel</author><pubDate>Fri, 26 May 2023 15:44:32 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.16988v1</guid></item><item><title>NavGPT: Explicit Reasoning in Vision-and-Language Navigation with Large Language Models</title><link>http://arxiv.org/abs/2305.16986v1</link><description>Trained with an unprecedented scale of data, large language models (LLMs)like ChatGPT and GPT-4 exhibit the emergence of significant reasoning abilitiesfrom model scaling. Such a trend underscored the potential of training LLMswith unlimited language data, advancing the development of a universal embodiedagent. In this work, we introduce the NavGPT, a purely LLM-basedinstruction-following navigation agent, to reveal the reasoning capability ofGPT models in complex embodied scenes by performing zero-shot sequential actionprediction for vision-and-language navigation (VLN). At each step, NavGPT takesthe textual descriptions of visual observations, navigation history, and futureexplorable directions as inputs to reason the agent's current status, and makesthe decision to approach the target. Through comprehensive experiments, wedemonstrate NavGPT can explicitly perform high-level planning for navigation,including decomposing instruction into sub-goal, integrating commonsenseknowledge relevant to navigation task resolution, identifying landmarks fromobserved scenes, tracking navigation progress, and adapting to exceptions withplan adjustment. Furthermore, we show that LLMs is capable of generatinghigh-quality navigational instructions from observations and actions along apath, as well as drawing accurate top-down metric trajectory given the agent'snavigation history. Despite the performance of using NavGPT to zero-shot R2Rtasks still falling short of trained models, we suggest adapting multi-modalityinputs for LLMs to use as visual navigation agents and applying the explicitreasoning of LLMs to benefit learning-based models.</description><author>Gengze Zhou, Yicong Hong, Qi Wu</author><pubDate>Fri, 26 May 2023 15:41:06 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.16986v1</guid></item><item><title>Inverse Dynamics Pretraining Learns Good Representations for Multitask Imitation</title><link>http://arxiv.org/abs/2305.16985v1</link><description>In recent years, domains such as natural language processing and imagerecognition have popularized the paradigm of using large datasets to pretrainrepresentations that can be effectively transferred to downstream tasks. Inthis work we evaluate how such a paradigm should be done in imitation learning,where both pretraining and finetuning data are trajectories collected byexperts interacting with an unknown environment. Namely, we consider a settingwhere the pretraining corpus consists of multitask demonstrations and the taskfor each demonstration is set by an unobserved latent context variable. Thegoal is to use the pretraining corpus to learn a low dimensional representationof the high dimensional (e.g., visual) observation space which can betransferred to a novel context for finetuning on a limited dataset ofdemonstrations. Among a variety of possible pretraining objectives, we arguethat inverse dynamics modeling -- i.e., predicting an action given theobservations appearing before and after it in the demonstration -- iswell-suited to this setting. We provide empirical evidence of this claimthrough evaluations on a variety of simulated visuomotor manipulation problems.While previous work has attempted various theoretical explanations regardingthe benefit of inverse dynamics modeling, we find that these arguments areinsufficient to explain the empirical advantages often observed in oursettings, and so we derive a novel analysis using a simple but generalenvironment model.</description><author>David Brandfonbrener, Ofir Nachum, Joan Bruna</author><pubDate>Fri, 26 May 2023 15:40:46 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.16985v1</guid></item><item><title>Multi-mode fiber reservoir computing overcomes shallow neural networks classifiers</title><link>http://arxiv.org/abs/2210.04745v2</link><description>In the field of disordered photonics, a common objective is to characterizeoptically opaque materials for controlling light delivery or performingimaging. Among various complex devices, multi-mode optical fibers stand out ascost-effective and easy-to-handle tools, making them attractive for severaltasks. In this context, we leverage the reservoir computing paradigm to recastthese fibers into random hardware projectors, transforming an input datasetinto a higher dimensional speckled image set. The goal of our study is todemonstrate that using such randomized data for classification by training asingle logistic regression layer improves accuracy compared to training ondirect raw images. Interestingly, we found that the classification accuracyachieved using the reservoir is also higher than that obtained with thestandard transmission matrix model, a widely accepted tool for describing lighttransmission through disordered devices. We find that the reason for suchimproved performance could be due to the fact that the hardware classifieroperates in a flatter region of the loss landscape when trained on fiber data,which aligns with the current theory of deep neural networks. These findingsstrongly suggest that multi-mode fibers possess robust generalizationproperties, positioning them as promising tools for optically-assisted neuralnetworks. With this study, in fact, we want to contribute to advancing theknowledge and practical utilization of these versatile instruments, which mayplay a significant role in shaping the future of machine learning.</description><author>Daniele Ancora, Matteo Negri, Antonio Gianfrate, Dimitris Trypogeorgos, Lorenzo Dominici, Daniele Sanvitto, Federico Ricci-Tersenghi, Luca Leuzzi</author><pubDate>Fri, 26 May 2023 15:40:26 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2210.04745v2</guid></item><item><title>TranSFormer: Slow-Fast Transformer for Machine Translation</title><link>http://arxiv.org/abs/2305.16982v1</link><description>Learning multiscale Transformer models has been evidenced as a viableapproach to augmenting machine translation systems. Prior research hasprimarily focused on treating subwords as basic units in developing suchsystems. However, the incorporation of fine-grained character-level featuresinto multiscale Transformer has not yet been explored. In this work, we presenta \textbf{S}low-\textbf{F}ast two-stream learning model, referred to asTran\textbf{SF}ormer, which utilizes a ``slow'' branch to deal with subwordsequences and a ``fast'' branch to deal with longer character sequences. Thismodel is efficient since the fast branch is very lightweight by reducing themodel width, and yet provides useful fine-grained features for the slow branch.Our TranSFormer shows consistent BLEU improvements (larger than 1 BLEU point)on several machine translation benchmarks.</description><author>Bei Li, Yi Jing, Xu Tan, Zhen Xing, Tong Xiao, Jingbo Zhu</author><pubDate>Fri, 26 May 2023 15:37:38 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.16982v1</guid></item><item><title>Adaptive PD Control using Deep Reinforcement Learning for Local-Remote Teleoperation with Stochastic Time Delays</title><link>http://arxiv.org/abs/2305.16979v1</link><description>Local-remote systems allow robots to execute complex tasks in hazardousenvironments such as space and nuclear power stations. However, establishingaccurate positional mapping between local and remote devices can be difficultdue to time delays that can compromise system performance and stability.Enhancing the synchronicity and stability of local-remote systems is vital forenabling robots to interact with environments at greater distances and underhighly challenging network conditions, including time delays. We introduce anadaptive control method employing reinforcement learning to tackle thetime-delayed control problem. By adjusting controller parameters in real-time,this adaptive controller compensates for stochastic delays and improvessynchronicity between local and remote robotic manipulators. To improve the adaptive PD controller's performance, we devise a model-basedreinforcement learning approach that effectively incorporates multi-step delaysinto the learning framework. Utilizing this proposed technique, thelocal-remote system's performance is stabilized for stochastic communicationtime-delays of up to 290ms. Our results demonstrate that the suggestedmodel-based reinforcement learning method surpasses the Soft-Actor Critic andaugmented state Soft-Actor Critic techniques. Access the code at:https://github.com/CAV-Research-Lab/Predictive-Model-Delay-Correction</description><author>Luc McCutcheon, Saber Fallah</author><pubDate>Fri, 26 May 2023 15:34:45 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.16979v1</guid></item></channel></rss>