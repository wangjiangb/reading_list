<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/"><channel><title>Arxivfresh papers</title><link></link><description>Arxiv paper</description><language>en-US</language><lastBuildDate>Thu, 29 Jun 2023 14:00:04 GMT</lastBuildDate><generator>rfeed v1.0.0</generator><docs>https://github.com/svpino/rfeed/blob/master/README.md</docs><item><title>On Practical Aspects of Aggregation Defenses against Data Poisoning Attacks</title><link>http://arxiv.org/abs/2306.16415v1</link><description>The increasing access to data poses both opportunities and risks in deeplearning, as one can manipulate the behaviors of deep learning models withmalicious training samples. Such attacks are known as data poisoning. Recentadvances in defense strategies against data poisoning have highlighted theeffectiveness of aggregation schemes in achieving state-of-the-art results incertified poisoning robustness. However, the practical implications of theseapproaches remain unclear. Here we focus on Deep Partition Aggregation, arepresentative aggregation defense, and assess its practical aspects, includingefficiency, performance, and robustness. For evaluations, we use ImageNetresized to a resolution of 64 by 64 to enable evaluations at a larger scalethan previous ones. Firstly, we demonstrate a simple yet practical approach toscaling base models, which improves the efficiency of training and inferencefor aggregation defenses. Secondly, we provide empirical evidence supportingthe data-to-complexity ratio, i.e. the ratio between the data set size andsample complexity, as a practical estimation of the maximum number of basemodels that can be deployed while preserving accuracy. Last but not least, wepoint out how aggregation defenses boost poisoning robustness empiricallythrough the poisoning overfitting phenomenon, which is the key underlyingmechanism for the empirical poisoning robustness of aggregations. Overall, ourfindings provide valuable insights for practical implementations of aggregationdefenses to mitigate the threat of data poisoning.</description><author>Wenxiao Wang, Soheil Feizi</author><pubDate>Wed, 28 Jun 2023 18:59:35 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.16415v1</guid></item><item><title>MultiZoo &amp; MultiBench: A Standardized Toolkit for Multimodal Deep Learning</title><link>http://arxiv.org/abs/2306.16413v1</link><description>Learning multimodal representations involves integrating information frommultiple heterogeneous sources of data. In order to accelerate progress towardsunderstudied modalities and tasks while ensuring real-world robustness, werelease MultiZoo, a public toolkit consisting of standardized implementationsof &gt; 20 core multimodal algorithms and MultiBench, a large-scale benchmarkspanning 15 datasets, 10 modalities, 20 prediction tasks, and 6 research areas.Together, these provide an automated end-to-end machine learning pipeline thatsimplifies and standardizes data loading, experimental setup, and modelevaluation. To enable holistic evaluation, we offer a comprehensive methodologyto assess (1) generalization, (2) time and space complexity, and (3) modalityrobustness. MultiBench paves the way towards a better understanding of thecapabilities and limitations of multimodal models, while ensuring ease of use,accessibility, and reproducibility. Our toolkits are publicly available, willbe regularly updated, and welcome inputs from the community.</description><author>Paul Pu Liang, Yiwei Lyu, Xiang Fan, Arav Agarwal, Yun Cheng, Louis-Philippe Morency, Ruslan Salakhutdinov</author><pubDate>Wed, 28 Jun 2023 18:59:10 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.16413v1</guid></item><item><title>High-Modality Multimodal Transformer: Quantifying Modality &amp; Interaction Heterogeneity for High-Modality Representation Learning</title><link>http://arxiv.org/abs/2203.01311v4</link><description>Many real-world problems are inherently multimodal, from spoken language,gestures, and paralinguistics humans use to communicate, to force,proprioception, and visual sensors on robots. While there has been an explosionof interest in multimodal learning, these methods are focused on a small set ofmodalities primarily in language, vision, and audio. In order to accelerategeneralization towards diverse and understudied modalities, this paper studiesefficient representation learning for high-modality scenarios involving a largeset of diverse modalities. Since adding new models for every new modalitybecomes prohibitively expensive, a critical technical challenge isheterogeneity quantification: how can we measure which modalities encodesimilar information and interactions in order to permit parameter sharing withprevious modalities? This paper proposes two new information theoretic metricsfor heterogeneity quantification: (1) modality heterogeneity studies howsimilar 2 modalities {X1,X2} are by measuring how much information can betransferred from X1 to X2, while (2) interaction heterogeneity studies howsimilarly pairs of modalities {X1,X2}, {X3,X4} interact by measuring how muchinformation can be transferred from fusing {X1,X2} to {X3,X4}. We show theimportance of these 2 proposed metrics as a way to automatically prioritize thefusion of modalities that contain unique information or interactions. Theresult is a single model, HighMMT, that scales up to 10 modalities (text,image, audio, video, sensors, proprioception, speech, time-series, sets, andtables) and 15 tasks from 5 research areas. Not only does HighMMT outperformprior methods on the tradeoff between performance and efficiency, it alsodemonstrates a crucial scaling behavior: performance continues to improve witheach modality added, and it transfers to entirely new modalities and tasksduring fine-tuning.</description><author>Paul Pu Liang, Yiwei Lyu, Xiang Fan, Jeffrey Tsaw, Yudong Liu, Shentong Mo, Dani Yogatama, Louis-Philippe Morency, Ruslan Salakhutdinov</author><pubDate>Wed, 28 Jun 2023 18:58:11 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2203.01311v4</guid></item><item><title>Towards Language Models That Can See: Computer Vision Through the LENS of Natural Language</title><link>http://arxiv.org/abs/2306.16410v1</link><description>We propose LENS, a modular approach for tackling computer vision problems byleveraging the power of large language models (LLMs). Our system uses alanguage model to reason over outputs from a set of independent and highlydescriptive vision modules that provide exhaustive information about an image.We evaluate the approach on pure computer vision settings such as zero- andfew-shot object recognition, as well as on vision and language problems. LENScan be applied to any off-the-shelf LLM and we find that the LLMs with LENSperform highly competitively with much bigger and much more sophisticatedsystems, without any multimodal training whatsoever. We open-source our code athttps://github.com/ContextualAI/lens and provide an interactive demo.</description><author>William Berrios, Gautam Mittal, Tristan Thrush, Douwe Kiela, Amanpreet Singh</author><pubDate>Wed, 28 Jun 2023 18:57:10 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.16410v1</guid></item><item><title>Efficient and Multiply Robust Risk Estimation under General Forms of Dataset Shift</title><link>http://arxiv.org/abs/2306.16406v1</link><description>Statistical machine learning methods often face the challenge of limited dataavailable from the population of interest. One remedy is to leverage data fromauxiliary source populations, which share some conditional distributions or arelinked in other ways with the target domain. Techniques leveraging such\emph{dataset shift} conditions are known as \emph{domain adaptation} or\emph{transfer learning}. Despite extensive literature on dataset shift,limited works address how to efficiently use the auxiliary populations toimprove the accuracy of risk evaluation for a given machine learning task inthe target population. In this paper, we study the general problem of efficiently estimating targetpopulation risk under various dataset shift conditions, leveragingsemiparametric efficiency theory. We consider a general class of dataset shiftconditions, which includes three popular conditions -- covariate, label andconcept shift -- as special cases. We allow for partially non-overlappingsupport between the source and target populations. We develop efficient andmultiply robust estimators along with a straightforward specification test ofthese dataset shift conditions. We also derive efficiency bounds for two otherdataset shift conditions, posterior drift and location-scale shift. Simulationstudies support the efficiency gains due to leveraging plausible dataset shiftconditions.</description><author>Hongxiang Qiu, Eric Tchetgen Tchetgen, Edgar Dobriban</author><pubDate>Wed, 28 Jun 2023 18:54:18 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.16406v1</guid></item><item><title>Sharper Model-free Reinforcement Learning for Average-reward Markov Decision Processes</title><link>http://arxiv.org/abs/2306.16394v1</link><description>We develop several provably efficient model-free reinforcement learning (RL)algorithms for infinite-horizon average-reward Markov Decision Processes(MDPs). We consider both online setting and the setting with access to asimulator. In the online setting, we propose model-free RL algorithms based onreference-advantage decomposition. Our algorithm achieves$\widetilde{O}(S^5A^2\mathrm{sp}(h^*)\sqrt{T})$ regret after $T$ steps, where$S\times A$ is the size of state-action space, and $\mathrm{sp}(h^*)$ the span of the optimal bias function. Our results are thefirst to achieve optimal dependence in $T$ for weakly communicating MDPs. In the simulator setting, we propose a model-free RL algorithm that finds an$\epsilon$-optimal policy using $\widetilde{O}\left(\frac{SA\mathrm{sp}^2(h^*)}{\epsilon^2}+\frac{S^2A\mathrm{sp}(h^*)}{\epsilon}\right)$ samples, whereas the minimax lower bound is$\Omega\left(\frac{SA\mathrm{sp}(h^*)}{\epsilon^2}\right)$. Our results are based on two new techniques that are unique in theaverage-reward setting: 1) better discounted approximation by value-differenceestimation; 2) efficient construction of confidence region for the optimal biasfunction with space complexity $O(SA)$.</description><author>Zihan Zhang, Qiaomin Xie</author><pubDate>Wed, 28 Jun 2023 18:43:19 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.16394v1</guid></item><item><title>The False Dawn: Reevaluating Google's Reinforcement Learning for Chip Macro Placement</title><link>http://arxiv.org/abs/2306.09633v4</link><description>Reinforcement learning (RL) for physical design of silicon chips in a Google2021 Nature paper stirred controversy due to poorly documented claims thatraised eyebrows and attracted critical media coverage. The Nature paperwithheld most inputs needed to produce reported results and some critical stepsin the methodology. But two separate evaluations filled in the gaps anddemonstrated that Google RL lags behind human designers, behind a well-knownalgorithm (Simulated Annealing), and also behind generally-available commercialsoftware. Crosschecked data indicate that the integrity of the Nature paper issubstantially undermined owing to errors in the conduct, analysis andreporting.</description><author>Igor L. Markov</author><pubDate>Wed, 28 Jun 2023 18:39:16 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.09633v4</guid></item><item><title>Topology Repairing of Disconnected Pulmonary Airways and Vessels: Baselines and a Dataset</title><link>http://arxiv.org/abs/2306.07089v2</link><description>Accurate segmentation of pulmonary airways and vessels is crucial for thediagnosis and treatment of pulmonary diseases. However, current deep learningapproaches suffer from disconnectivity issues that hinder their clinicalusefulness. To address this challenge, we propose a post-processing approachthat leverages a data-driven method to repair the topology of disconnectedpulmonary tubular structures. Our approach formulates the problem as a keypointdetection task, where a neural network is trained to predict keypoints that canbridge disconnected components. We use a training data synthesis pipeline thatgenerates disconnected data from complete pulmonary structures. Moreover, thenew Pulmonary Tree Repairing (PTR) dataset is publicly available, whichcomprises 800 complete 3D models of pulmonary airways, arteries, and veins, aswell as the synthetic disconnected data. Our code and data are available athttps://github.com/M3DV/pulmonary-tree-repairing.</description><author>Ziqiao Weng, Jiancheng Yang, Dongnan Liu, Weidong Cai</author><pubDate>Wed, 28 Jun 2023 18:33:27 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.07089v2</guid></item><item><title>Towards Measuring the Representation of Subjective Global Opinions in Language Models</title><link>http://arxiv.org/abs/2306.16388v1</link><description>Large language models (LLMs) may not equitably represent diverse globalperspectives on societal issues. In this paper, we develop a quantitativeframework to evaluate whose opinions model-generated responses are more similarto. We first build a dataset, GlobalOpinionQA, comprised of questions andanswers from cross-national surveys designed to capture diverse opinions onglobal issues across different countries. Next, we define a metric thatquantifies the similarity between LLM-generated survey responses and humanresponses, conditioned on country. With our framework, we run three experimentson an LLM trained to be helpful, honest, and harmless with Constitutional AI.By default, LLM responses tend to be more similar to the opinions of certainpopulations, such as those from the USA, and some European and South Americancountries, highlighting the potential for biases. When we prompt the model toconsider a particular country's perspective, responses shift to be more similarto the opinions of the prompted populations, but can reflect harmful culturalstereotypes. When we translate GlobalOpinionQA questions to a target language,the model's responses do not necessarily become the most similar to theopinions of speakers of those languages. We release our dataset for others touse and build on. Our data is athttps://huggingface.co/datasets/Anthropic/llm_global_opinions. We also providean interactive visualization at https://llmglobalvalues.anthropic.com.</description><author>Esin Durmus, Karina Nyugen, Thomas I. Liao, Nicholas Schiefer, Amanda Askell, Anton Bakhtin, Carol Chen, Zac Hatfield-Dodds, Danny Hernandez, Nicholas Joseph, Liane Lovitt, Sam McCandlish, Orowa Sikder, Alex Tamkin, Janel Thamkul, Jared Kaplan, Jack Clark, Deep Ganguli</author><pubDate>Wed, 28 Jun 2023 18:31:53 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.16388v1</guid></item><item><title>Tourist Attractions Recommendation based on Attention Knowledge Graph Convolution Network</title><link>http://arxiv.org/abs/2306.10946v3</link><description>The recommendation algorithm based on knowledge graphs is at a relativelymature stage. However, there are still some problems in the recommendation ofspecific areas. For example, in the tourism field, selecting suitable touristattraction attributes process is complicated as the recommendation basis fortourist attractions. In this paper, we propose the improved Attention KnowledgeGraph Convolution Network model, named (Att-KGCN), which automaticallydiscovers the neighboring entities of the target scenic spot semantically. Theattention layer aggregates relatively similar locations and represents themwith an adjacent vector. Then, according to the tourist's preferred choices,the model predicts the probability of similar spots as a recommendation system.A knowledge graph dataset of tourist attractions used based on tourism data onSocotra Island-Yemen. Through experiments, it is verified that the AttentionKnowledge Graph Convolution Network has a good effect on the recommendation oftourist attractions and can make more recommendations for tourists' choices.</description><author>Ahmad A. Mubarak, Afifa Kahled</author><pubDate>Wed, 28 Jun 2023 18:26:48 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.10946v3</guid></item><item><title>Rethinking Model Evaluation as Narrowing the Socio-Technical Gap</title><link>http://arxiv.org/abs/2306.03100v2</link><description>The recent development of generative and large language models (LLMs) posesnew challenges for model evaluation that the research community and industryare grappling with. While the versatile capabilities of these models igniteexcitement, they also inevitably make a leap toward homogenization: powering awide range of applications with a single, often referred to as``general-purpose'', model. In this position paper, we argue that modelevaluation practices must take on a critical task to cope with the challengesand responsibilities brought by this homogenization: providing validassessments for whether and how much human needs in downstream use cases can besatisfied by the given model (socio-technical gap). By drawing on lessons fromthe social sciences, human-computer interaction (HCI), and theinterdisciplinary field of explainable AI (XAI), we urge the community todevelop evaluation methods based on real-world socio-requirements and embracediverse evaluation methods with an acknowledgment of trade-offs between realismto socio-requirements and pragmatic costs to conduct the evaluation. By mappingHCI and current NLG evaluation methods, we identify opportunities forevaluation methods for LLMs to narrow the socio-technical gap and pose openquestions.</description><author>Q. Vera Liao, Ziang Xiao</author><pubDate>Wed, 28 Jun 2023 18:24:27 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.03100v2</guid></item><item><title>Accelerating Sampling and Aggregation Operations in GNN Frameworks with GPU Initiated Direct Storage Accesses</title><link>http://arxiv.org/abs/2306.16384v1</link><description>Graph Neural Networks (GNNs) are emerging as a powerful tool for learningfrom graph-structured data and performing sophisticated inference tasks invarious application domains. Although GNNs have been shown to be effective onmodest-sized graphs, training them on large-scale graphs remains a significantchallenge due to lack of efficient data access and data movement methods.Existing frameworks for training GNNs use CPUs for graph sampling and featureaggregation, while the training and updating of model weights are executed onGPUs. However, our in-depth profiling shows the CPUs cannot achieve thethroughput required to saturate GNN model training throughput, causing grossunder-utilization of expensive GPU resources. Furthermore, when the graph andits embeddings do not fit in the CPU memory, the overhead introduced by theoperating system, say for handling page-faults, comes in the critical path ofexecution. To address these issues, we propose the GPU Initiated Direct Storage Access(GIDS) dataloader, to enable GPU-oriented GNN training for large-scale graphswhile efficiently utilizing all hardware resources, such as CPU memory,storage, and GPU memory with a hybrid data placement strategy. By enabling GPUthreads to fetch feature vectors directly from storage, GIDS dataloader solvesthe memory capacity problem for GPU-oriented GNN training. Moreover, GIDSdataloader leverages GPU parallelism to tolerate storage latency and eliminatesexpensive page-fault overhead. Doing so enables us to design noveloptimizations for exploiting locality and increasing effective bandwidth forGNN training. Our evaluation using a single GPU on terabyte-scale GNN datasetsshows that GIDS dataloader accelerates the overall DGL GNN training pipeline byup to 392X when compared to the current, state-of-the-art DGL dataloader.</description><author>Jeongmin Brian Park, Vikram Sharma Mailthody, Zaid Qureshi, Wen-mei Hwu</author><pubDate>Wed, 28 Jun 2023 18:22:15 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.16384v1</guid></item><item><title>Spatiotemporal Besov Priors for Bayesian Inverse Problems</title><link>http://arxiv.org/abs/2306.16378v1</link><description>Fast development in science and technology has driven the need for properstatistical tools to capture special data features such as abrupt changes orsharp contrast. Many applications in the data science seek spatiotemporalreconstruction from a sequence of time-dependent objects with discontinuity orsingularity, e.g. dynamic computerized tomography (CT) images with edges.Traditional methods based on Gaussian processes (GP) may not providesatisfactory solutions since they tend to offer over-smooth prior candidates.Recently, Besov process (BP) defined by wavelet expansions with randomcoefficients has been proposed as a more appropriate prior for this type ofBayesian inverse problems. While BP outperforms GP in imaging analysis toproduce edge-preserving reconstructions, it does not automatically incorporatetemporal correlation inherited in the dynamically changing images. In thispaper, we generalize BP to the spatiotemporal domain (STBP) by replacing therandom coefficients in the series expansion with stochastic time functionsfollowing Q-exponential process which governs the temporal correlationstrength. Mathematical and statistical properties about STBP are carefullystudied. A white-noise representation of STBP is also proposed to facilitatethe point estimation through maximum a posterior (MAP) and the uncertaintyquantification (UQ) by posterior sampling. Two limited-angle CT reconstructionexamples and a highly non-linear inverse problem involving Navier-Stokesequation are used to demonstrate the advantage of the proposed STBP inpreserving spatial features while accounting for temporal changes compared withthe classic STGP and a time-uncorrelated approach.</description><author>Shiwei Lan, Mirjeta Pasha, Shuyi Li</author><pubDate>Wed, 28 Jun 2023 18:14:49 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.16378v1</guid></item><item><title>Lagrangian based A* algorithm for automated reasoning</title><link>http://arxiv.org/abs/2306.16368v1</link><description>In this paper, a modification of A* algorithm is considered for the shortestpath problem. A weightage is introduced in the heuristic part of the A*algorithm to improve its efficiency. An application of the algorithm isconsidered for UAV path planning wherein velocity is taken as the weigtage tothe heuristic. At the outset, calculus of variations based Lagrange's equationwas used to identify velocity as the decisive factor for the dynamical system.This approach would be useful for other problems as well to improve theefficiency of algorithms in those areas.</description><author>Renju Rajan</author><pubDate>Wed, 28 Jun 2023 18:01:03 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.16368v1</guid></item><item><title>Multi-Site Clinical Federated Learning using Recursive and Attentive Models and NVFlare</title><link>http://arxiv.org/abs/2306.16367v1</link><description>The prodigious growth of digital health data has precipitated a mountinginterest in harnessing machine learning methodologies, such as natural languageprocessing (NLP), to scrutinize medical records, clinical notes, and othertext-based health information. Although NLP techniques have exhibitedsubstantial potential in augmenting patient care and informing clinicaldecision-making, data privacy and adherence to regulations persist as criticalconcerns. Federated learning (FL) emerges as a viable solution, empoweringmultiple organizations to train machine learning models collaboratively withoutdisseminating raw data. This paper proffers a pragmatic approach to medical NLPby amalgamating FL, NLP models, and the NVFlare framework, developed by NVIDIA.We introduce two exemplary NLP models, the Long-Short Term Memory (LSTM)-basedmodel and Bidirectional Encoder Representations from Transformers (BERT), whichhave demonstrated exceptional performance in comprehending context andsemantics within medical data. This paper encompasses the development of anintegrated framework that addresses data privacy and regulatory compliancechallenges while maintaining elevated accuracy and performance, incorporatingBERT pretraining, and comprehensively substantiating the efficacy of theproposed approach.</description><author>Won Joon Yun, Samuel Kim, Joongheon Kim</author><pubDate>Wed, 28 Jun 2023 18:00:32 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.16367v1</guid></item><item><title>ETO Meets Scheduling: Learning Key Knowledge from Single-Objective Problems to Multi-Objective Problem</title><link>http://arxiv.org/abs/2206.12902v2</link><description>Evolutionary transfer optimization(ETO) serves as "a new frontier inevolutionary computation research", which will avoid zero reuse of experienceand knowledge from solved problems in traditional evolutionary computation. Inscheduling applications via ETO, a highly competitive "meeting" frameworkbetween them could be constituted towards both intelligent scheduling and greenscheduling, especially for carbon neutrality within the context of China. Tothe best of our knowledge, our study on scheduling here, is the 1st work of ETOfor complex optimization when multiobjective problem "meets" single-objectiveproblems in combinatorial case (not multitasking optimization). Morespecifically, key knowledge like positional building blocks clustered, could belearned and transferred for permutation flow shop scheduling problem (PFSP).Empirical studies on well-studied benchmarks validate relatively firmeffectiveness and great potential of our proposed ETO-PFSP framework.</description><author>Wendi Xu, Xianpeng Wang</author><pubDate>Wed, 28 Jun 2023 17:51:25 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2206.12902v2</guid></item><item><title>Beyond NTK with Vanilla Gradient Descent: A Mean-Field Analysis of Neural Networks with Polynomial Width, Samples, and Time</title><link>http://arxiv.org/abs/2306.16361v1</link><description>Despite recent theoretical progress on the non-convex optimization oftwo-layer neural networks, it is still an open question whether gradientdescent on neural networks without unnatural modifications can achieve bettersample complexity than kernel methods. This paper provides a clean mean-fieldanalysis of projected gradient flow on polynomial-width two-layer neuralnetworks. Different from prior works, our analysis does not require unnaturalmodifications of the optimization algorithm. We prove that with sample size $n= O(d^{3.1})$ where $d$ is the dimension of the inputs, the network convergesin polynomially many iterations to a non-trivial error that is not achievableby kernel methods using $n \ll d^4$ samples, hence demonstrating a clearseparation between unmodified gradient descent and NTK.</description><author>Arvind Mahankali, Jeff Z. Haochen, Kefan Dong, Margalit Glasgow, Tengyu Ma</author><pubDate>Wed, 28 Jun 2023 17:45:38 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.16361v1</guid></item><item><title>Theater Aid System for the Visually Impaired Through Transfer Learning of Spatio-Temporal Graph Convolution Networks</title><link>http://arxiv.org/abs/2306.16357v1</link><description>The aim of this research is to recognize human actions performed on stage toaid visually impaired and blind individuals. To achieve this, we have created atheatre human action recognition system that uses skeleton data captured bydepth image as input. We collected new samples of human actions in a theatreenvironment, and then tested the transfer learning technique with threepre-trained Spatio-Temporal Graph Convolution Networks for skeleton-based humanaction recognition: the spatio-temporal graph convolution network, thetwo-stream adaptive graph convolution network, and the multi-scale disentangledunified graph convolution network. We selected the NTU-RGBD human actionbenchmark as the source domain and used our collected dataset as the targetdomain. We analyzed the transferability of the pre-trained models and proposedtwo configurations to apply and adapt the transfer learning technique to thediversity between the source and target domains. The use of transfer learninghelped to improve the performance of the human action system within the contextof theatre. The results indicate that Spatio-Temporal Graph ConvolutionNetworks is positively transferred, and there was an improvement in performancecompared to the baseline without transfer learning.</description><author>Leyla Benhamida, Slimane Larabi</author><pubDate>Wed, 28 Jun 2023 17:40:52 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.16357v1</guid></item><item><title>SUPERNOVA: Automating Test Selection and Defect Prevention in AAA Video Games Using Risk Based Testing and Machine Learning</title><link>http://arxiv.org/abs/2203.05566v2</link><description>Testing video games is an increasingly difficult task as traditional methodsfail to scale with growing software systems. Manual testing is a verylabor-intensive process, and therefore quickly becomes cost prohibitive. Usingscripts for automated testing is affordable, however scripts are ineffective innon-deterministic environments, and knowing when to run each test is anotherproblem altogether. The modern game's complexity, scope, and playerexpectations are rapidly increasing where quality control is a big portion ofthe production cost and delivery risk. Reducing this risk and making productionhappen is a big challenge for the industry currently. To keep production costsrealistic up-to and after release, we are focusing on preventive qualityassurance tactics alongside testing and data analysis automation. We presentSUPERNOVA (Selection of tests and Universal defect Prevention in ExternalRepositories for Novel Objective Verification of software Anomalies), a systemresponsible for test selection and defect prevention while also functioning asan automation hub. By integrating data analysis functionality with machine anddeep learning capability, SUPERNOVA assists quality assurance testers infinding bugs and developers in reducing defects, which improves stabilityduring the production cycle and keeps testing costs under control. The directimpact of this has been observed to be a reduction in 55% or more testing hoursfor an undisclosed sports game title that has shipped, which was using thesetest selection optimizations. Furthermore, using risk scores generated by asemi-supervised machine learning model, we are able to detect with 71%precision and 77% recall the probability of a change-list being bug inducing,and provide a detailed breakdown of this inference to developers. These effortsimprove workflow and reduce testing hours required on game titles indevelopment.</description><author>Alexander Senchenko, Naomi Patterson, Hamman Samuel, Dan Isper</author><pubDate>Wed, 28 Jun 2023 17:35:23 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2203.05566v2</guid></item><item><title>cuSLINK: Single-linkage Agglomerative Clustering on the GPU</title><link>http://arxiv.org/abs/2306.16354v1</link><description>In this paper, we propose cuSLINK, a novel and state-of-the-art reformulationof the SLINK algorithm on the GPU which requires only $O(Nk)$ space and uses aparameter $k$ to trade off space and time. We also propose a set of novel andreusable building blocks that compose cuSLINK. These building blocks includehighly optimized computational patterns for $k$-NN graph construction, spanningtrees, and dendrogram cluster extraction. We show how we used our primitives toimplement cuSLINK end-to-end on the GPU, further enabling a wide range ofreal-world data mining and machine learning applications that were onceintractable. In addition to being a primary computational bottleneck in thepopular HDBSCAN algorithm, the impact of our end-to-end cuSLINK algorithm spansa large range of important applications, including cluster analysis in socialand computer networks, natural language processing, and computer vision. Userscan obtain cuSLINK athttps://docs.rapids.ai/api/cuml/latest/api/#agglomerative-clustering</description><author>Corey J. Nolet, Divye Gala, Alex Fender, Mahesh Doijade, Joe Eaton, Edward Raff, John Zedlewski, Brad Rees, Tim Oates</author><pubDate>Wed, 28 Jun 2023 17:34:50 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.16354v1</guid></item><item><title>Information-Computation Tradeoffs for Learning Margin Halfspaces with Random Classification Noise</title><link>http://arxiv.org/abs/2306.16352v1</link><description>We study the problem of PAC learning $\gamma$-margin halfspaces with RandomClassification Noise. We establish an information-computation tradeoffsuggesting an inherent gap between the sample complexity of the problem and thesample complexity of computationally efficient algorithms. Concretely, thesample complexity of the problem is $\widetilde{\Theta}(1/(\gamma^2\epsilon))$. We start by giving a simple efficient algorithm with samplecomplexity $\widetilde{O}(1/(\gamma^2 \epsilon^2))$. Our main result is a lowerbound for Statistical Query (SQ) algorithms and low-degree polynomial testssuggesting that the quadratic dependence on $1/\epsilon$ in the samplecomplexity is inherent for computationally efficient algorithms. Specifically,our results imply a lower bound of $\widetilde{\Omega}(1/(\gamma^{1/2}\epsilon^2))$ on the sample complexity of any efficient SQ learner orlow-degree test.</description><author>Ilias Diakonikolas, Jelena Diakonikolas, Daniel M. Kane, Puqian Wang, Nikos Zarifis</author><pubDate>Wed, 28 Jun 2023 17:33:39 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.16352v1</guid></item><item><title>A DeepONet multi-fidelity approach for residual learning in reduced order modeling</title><link>http://arxiv.org/abs/2302.12682v2</link><description>In the present work, we introduce a novel approach to enhance the precisionof reduced order models by exploiting a multi-fidelity perspective andDeepONets. Reduced models provide a real-time numerical approximation bysimplifying the original model. The error introduced by the such operation isusually neglected and sacrificed in order to reach a fast computation. Wepropose to couple the model reduction to a machine learning residual learning,such that the above-mentioned error can be learned by a neural network andinferred for new predictions. We emphasize that the framework maximizes theexploitation of high-fidelity information, using it for building the reducedorder model and for learning the residual. In this work, we explore theintegration of proper orthogonal decomposition (POD), and gappy POD for sensorsdata, with the recent DeepONet architecture. Numerical investigations for aparametric benchmark function and a nonlinear parametric Navier-Stokes problemare presented.</description><author>Nicola Demo, Marco Tezzele, Gianluigi Rozza</author><pubDate>Wed, 28 Jun 2023 17:27:38 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2302.12682v2</guid></item><item><title>Support Vector Regression: Risk Quadrangle Framework</title><link>http://arxiv.org/abs/2212.09178v4</link><description>This paper investigates Support Vector Regression (SVR) in the context of thefundamental risk quadrangle theory, which links optimization, risk management,and statistical estimation. It is shown that both formulations of SVR,$\varepsilon$-SVR and $\nu$-SVR, correspond to the minimization of equivalenterror measures (Vapnik error and CVaR norm, respectively) with a regularizationpenalty. These error measures, in turn, define the corresponding riskquadrangles. By constructing the fundamental risk quadrangle, which correspondsto SVR, we show that SVR is the asymptotically unbiased estimator of theaverage of two symmetric conditional quantiles. Further, we prove theequivalence of the $\varepsilon$-SVR and $\nu$-SVR in a general stochasticsetting. Additionally, SVR is formulated as a regular deviation minimizationproblem with a regularization penalty. Finally, the dual formulation of SVR inthe risk quadrangle framework is derived.</description><author>Anton Malandii, Stan Uryasev</author><pubDate>Wed, 28 Jun 2023 17:22:01 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2212.09178v4</guid></item><item><title>Emulating the dynamics of complex systems using autoregressive models on manifolds (mNARX)</title><link>http://arxiv.org/abs/2306.16335v1</link><description>In this study, we propose a novel surrogate modelling approach to efficientlyand accurately approximate the response of complex dynamical systems driven bytime-varying exogenous excitations over extended time periods. Our approach,that we name \emph{manifold nonlinear autoregressive modelling with exogenousinput} (mNARX), involves constructing a problem-specific exogenous inputmanifold that is optimal for constructing autoregressive surrogates. Themanifold, which forms the core of mNARX, is constructed incrementally byincorporating the physics of the system, as well as prior expert- and domain-knowledge. Because mNARX decomposes the full problem into a series of smallersub-problems, each with a lower complexity than the original, it scales wellwith the complexity of the problem, both in terms of training and evaluationcosts of the final surrogate. Furthermore, mNARX synergizes well withtraditional dimensionality reduction techniques, making it highly suitable formodelling dynamical systems with high-dimensional exogenous inputs, a class ofproblems that is typically challenging to solve.Since domain knowledge isparticularly abundant in physical systems, such as those found in engineeringapplications, mNARX is well suited for these applications. We demonstrate thatmNARX outperforms traditional autoregressive surrogates in predicting theresponse of a classical coupled spring-mass system excited by a one-dimensionalrandom excitation. Additionally, we show that mNARX is well suited foremulating very high-dimensional time- and state-dependent systems, even whenaffected by active controllers, by surrogating the dynamics of a realisticaero-servo-elastic onshore wind turbine simulator. In general, our resultsdemonstrate that mNARX offers promising prospects for modelling complexdynamical systems, in terms of accuracy and efficiency.</description><author>Styfen Schär, Stefano Marelli, Bruno Sudret</author><pubDate>Wed, 28 Jun 2023 17:11:50 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.16335v1</guid></item><item><title>MIMIC: Masked Image Modeling with Image Correspondences</title><link>http://arxiv.org/abs/2306.15128v2</link><description>Many pixelwise dense prediction tasks-depth estimation and semanticsegmentation in computer vision today rely on pretrained image representations.Therefore, curating effective pretraining datasets is vital. Unfortunately, theeffective pretraining datasets are those with multi-view scenes and have onlybeen curated using annotated 3D meshes, point clouds, and camera parametersfrom simulated environments. We propose a dataset-curation mechanism that doesnot require any annotations. We mine two datasets: MIMIC-1M with 1.3M andMIMIC-3M with 3.1M multi-view image pairs from open-sourced video datasets andfrom synthetic 3D environments. We train multiple self-supervised models withdifferent masked image modeling objectives to showcase the following findings:Representations trained on MIMIC-3M outperform those mined using annotations onmultiple downstream tasks, including depth estimation, semantic segmentation,surface normals, and pose estimation. They also outperform representations thatare frozen and when downstream training data is limited to few-shot. Largerdataset (MIMIC-3M) significantly improves performance, which is promising sinceour curation method can arbitrarily scale to produce even larger datasets.MIMIC code, dataset, and pretrained models are open-sourced athttps://github.com/RAIVNLab/MIMIC.</description><author>Kalyani Marathe, Mahtab Bigverdi, Nishat Khan, Tuhin Kundu, Aniruddha Kembhavi, Linda G. Shapiro, Ranjay Krishna</author><pubDate>Wed, 28 Jun 2023 17:10:48 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.15128v2</guid></item><item><title>Identifiability of Discretized Latent Coordinate Systems via Density Landmarks Detection</title><link>http://arxiv.org/abs/2306.16334v1</link><description>Disentanglement aims to recover meaningful latent ground-truth factors fromonly the observed distribution. Identifiability provides the theoreticalgrounding for disentanglement to be well-founded. Unfortunately, unsupervisedidentifiability of independent latent factors is a theoretically provenimpossibility in the i.i.d. setting under a general nonlinear smooth map fromfactors to observations. In this work, we show that, remarkably, it is possibleto recover discretized latent coordinates under a highly generic nonlinearsmooth mapping (a diffeomorphism) without any additional inductive bias on themapping. This is, assuming that latent density has axis-aligned discontinuitylandmarks, but without making the unrealistic assumption of statisticalindependence of the factors. We introduce this novel form of identifiability,termed quantized coordinate identifiability, and provide a comprehensive proofof the recovery of discretized coordinates.</description><author>Vitória Barin-Pacela, Kartik Ahuja, Simon Lacoste-Julien, Pascal Vincent</author><pubDate>Wed, 28 Jun 2023 17:10:01 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.16334v1</guid></item><item><title>Improved dimension dependence of a proximal algorithm for sampling</title><link>http://arxiv.org/abs/2302.10081v2</link><description>We propose a sampling algorithm that achieves superior complexity bounds inall the classical settings (strongly log-concave, log-concave,Logarithmic-Sobolev inequality (LSI), Poincar\'e inequality) as well as moregeneral settings with semi-smooth or composite potentials. Our algorithm isbased on the proximal sampler introduced in~\citet{lee2021structured}. Theperformance of this proximal sampler is determined by that of the restrictedGaussian oracle (RGO), a key step in the proximal sampler. The maincontribution of this work is an inexact realization of RGO based on approximaterejection sampling. To bound the inexactness of RGO, we establish a newconcentration inequality for semi-smooth functions over Gaussian distributions,extending the well-known concentration inequality for Lipschitz functions.Applying our RGO implementation to the proximal sampler, we achievestate-of-the-art complexity bounds in almost all settings. For instance, forstrongly log-concave distributions, our method has complexity bound$\tilde\mathcal{O}(\kappa d^{1/2})$ without warm start, better than the minimaxbound for MALA. For distributions satisfying the LSI, our bound is $\tilde\mathcal{O}(\hat \kappa d^{1/2})$ where $\hat \kappa$ is the ratio betweensmoothness and the LSI constant, better than all existing bounds.</description><author>Jiaojiao Fan, Bo Yuan, Yongxin Chen</author><pubDate>Wed, 28 Jun 2023 17:09:48 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2302.10081v2</guid></item><item><title>Transformer-based Annotation Bias-aware Medical Image Segmentation</title><link>http://arxiv.org/abs/2306.01340v2</link><description>Manual medical image segmentation is subjective and suffers fromannotator-related bias, which can be mimicked or amplified by deep learningmethods. Recently, researchers have suggested that such bias is the combinationof the annotator preference and stochastic error, which are modeled byconvolution blocks located after decoder and pixel-wise independent Gaussiandistribution, respectively. It is unlikely that convolution blocks caneffectively model the varying degrees of preference at the full resolutionlevel. Additionally, the independent pixel-wise Gaussian distributiondisregards pixel correlations, leading to a discontinuous boundary. This paperproposes a Transformer-based Annotation Bias-aware (TAB) medical imagesegmentation model, which tackles the annotator-related bias via modelingannotator preference and stochastic errors. TAB employs the Transformer withlearnable queries to extract the different preference-focused features. Thisenables TAB to produce segmentation with various preferences simultaneouslyusing a single segmentation head. Moreover, TAB takes the multivariant normaldistribution assumption that models pixel correlations, and learns theannotation distribution to disentangle the stochastic error. We evaluated ourTAB on an OD/OC segmentation benchmark annotated by six annotators. Our resultssuggest that TAB outperforms existing medical image segmentation models whichtake into account the annotator-related bias.</description><author>Zehui Liao, Yutong Xie, Shishuai Hu, Yong Xia</author><pubDate>Wed, 28 Jun 2023 17:08:39 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.01340v2</guid></item><item><title>DiffComplete: Diffusion-based Generative 3D Shape Completion</title><link>http://arxiv.org/abs/2306.16329v1</link><description>We introduce a new diffusion-based approach for shape completion on 3D rangescans. Compared with prior deterministic and probabilistic methods, we strike abalance between realism, multi-modality, and high fidelity. We proposeDiffComplete by casting shape completion as a generative task conditioned onthe incomplete shape. Our key designs are two-fold. First, we devise ahierarchical feature aggregation mechanism to inject conditional features in aspatially-consistent manner. So, we can capture both local details and broadercontexts of the conditional inputs to control the shape completion. Second, wepropose an occupancy-aware fusion strategy in our model to enable thecompletion of multiple partial shapes and introduce higher flexibility on theinput conditions. DiffComplete sets a new SOTA performance (e.g., 40% decreaseon l_1 error) on two large-scale 3D shape completion benchmarks. Our completedshapes not only have a realistic outlook compared with the deterministicmethods but also exhibit high similarity to the ground truths compared with theprobabilistic alternatives. Further, DiffComplete has strong generalizabilityon objects of entirely unseen classes for both synthetic and real data,eliminating the need for model re-training in various applications.</description><author>Ruihang Chu, Enze Xie, Shentong Mo, Zhenguo Li, Matthias Nießner, Chi-Wing Fu, Jiaya Jia</author><pubDate>Wed, 28 Jun 2023 17:07:36 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.16329v1</guid></item><item><title>Representation Learning via Variational Bayesian Networks</title><link>http://arxiv.org/abs/2306.16326v1</link><description>We present Variational Bayesian Network (VBN) - a novel Bayesian entityrepresentation learning model that utilizes hierarchical and relational sideinformation and is particularly useful for modeling entities in the``long-tail'', where the data is scarce. VBN provides better modeling forlong-tail entities via two complementary mechanisms: First, VBN employsinformative hierarchical priors that enable information propagation betweenentities sharing common ancestors. Additionally, VBN models explicit relationsbetween entities that enforce complementary structure and consistency, guidingthe learned representations towards a more meaningful arrangement in space.Second, VBN represents entities by densities (rather than vectors), hencemodeling uncertainty that plays a complementary role in coping with datascarcity. Finally, we propose a scalable Variational Bayes optimizationalgorithm that enables fast approximate Bayesian inference. We evaluate theeffectiveness of VBN on linguistic, recommendations, and medical inferencetasks. Our findings show that VBN outperforms other existing methods acrossmultiple datasets, and especially in the long-tail.</description><author>Oren Barkan, Avi Caciularu, Idan Rejwan, Ori Katz, Jonathan Weill, Itzik Malkiel, Noam Koenigstein</author><pubDate>Wed, 28 Jun 2023 17:00:45 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.16326v1</guid></item><item><title>DoseDiff: Distance-aware Diffusion Model for Dose Prediction in Radiotherapy</title><link>http://arxiv.org/abs/2306.16324v1</link><description>Treatment planning is a critical component of the radiotherapy workflow,typically carried out by a medical physicist using a time-consumingtrial-and-error manner. Previous studies have proposed knowledge-based or deeplearning-based methods for predicting dose distribution maps to assist medicalphysicists in improving the efficiency of treatment planning. However, thesedose prediction methods usuallylack the effective utilization of distanceinformation between surrounding tissues andtargets or organs-at-risk (OARs).Moreover, they are poor in maintaining the distribution characteristics of raypaths in the predicted dose distribution maps, resulting in a loss of valuableinformation obtained by medical physicists. In this paper, we propose adistance-aware diffusion model (DoseDiff) for precise prediction of dosedistribution. We define dose prediction as a sequence of denoising steps,wherein the predicted dose distribution map is generated with the conditions ofthe CT image and signed distance maps (SDMs). The SDMs are obtained by adistance transformation from the masks of targets or OARs, which provide thedistance information from each pixel in the image to the outline of the targetsor OARs. Besides, we propose a multiencoder and multi-scale fusion network(MMFNet) that incorporates a multi-scale fusion and a transformer-based fusionmodule to enhance information fusion between the CT image and SDMs at thefeature level. Our model was evaluated on two datasets collected from patientswith breast cancer and nasopharyngeal cancer, respectively. The resultsdemonstrate that our DoseDiff outperforms the state-of-the-art dose predictionmethods in terms of both quantitative and visual quality.</description><author>Yiwen Zhang, Chuanpu Li, Liming Zhong, Zeli Chen, Wei Yang, Xuetao Wang</author><pubDate>Wed, 28 Jun 2023 16:58:53 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.16324v1</guid></item><item><title>Taqyim: Evaluating Arabic NLP Tasks Using ChatGPT Models</title><link>http://arxiv.org/abs/2306.16322v1</link><description>Large language models (LLMs) have demonstrated impressive performance onvarious downstream tasks without requiring fine-tuning, including ChatGPT, achat-based model built on top of LLMs such as GPT-3.5 and GPT-4. Despite havinga lower training proportion compared to English, these models also exhibitremarkable capabilities in other languages. In this study, we assess theperformance of GPT-3.5 and GPT-4 models on seven distinct Arabic NLP tasks:sentiment analysis, translation, transliteration, paraphrasing, part of speechtagging, summarization, and diacritization. Our findings reveal that GPT-4outperforms GPT-3.5 on five out of the seven tasks. Furthermore, we conduct anextensive analysis of the sentiment analysis task, providing insights into howLLMs achieve exceptional results on a challenging dialectal dataset.Additionally, we introduce a new Python interfacehttps://github.com/ARBML/Taqyim that facilitates the evaluation of these taskseffortlessly.</description><author>Zaid Alyafeai, Maged S. Alshaibani, Badr AlKhamissi, Hamzah Luqman, Ebrahim Alareqi, Ali Fadel</author><pubDate>Wed, 28 Jun 2023 16:54:29 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.16322v1</guid></item><item><title>Integrating Geometric Control into Text-to-Image Diffusion Models for High-Quality Detection Data Generation via Text Prompt</title><link>http://arxiv.org/abs/2306.04607v4</link><description>Diffusion models have attracted significant attention due to their remarkableability to create content and generate data for tasks such as imageclassification. However, the usage of diffusion models to generate high-qualityobject detection data remains an underexplored area, where not only theimage-level perceptual quality but also geometric conditions such as boundingboxes and camera views are essential. Previous studies have utilized eithercopy-paste synthesis or layout-to-image (L2I) generation with specificallydesigned modules to encode semantic layouts. In this paper, we proposeGeoDiffusion, a simple framework that can flexibly translate various geometricconditions into text prompts and empower the pre-trained text-to-image (T2I)diffusion models for high-quality detection data generation. Unlike previousL2I methods, our GeoDiffusion is able to encode not only bounding boxes butalso extra geometric conditions such as camera views in self-driving scenes.Extensive experiments demonstrate GeoDiffusion outperforms previous L2I methodswhile maintaining 4x training time faster. To the best of our knowledge, thisis the first work to adopt diffusion models for layout-to-image generation withgeometric conditions and demonstrate that L2I-generated images can bebeneficial for improving the performance of object detectors.</description><author>Kai Chen, Enze Xie, Zhe Chen, Lanqing Hong, Zhenguo Li, Dit-Yan Yeung</author><pubDate>Wed, 28 Jun 2023 16:52:13 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.04607v4</guid></item><item><title>An Adversarial Multi-Task Learning Method for Chinese Text Correction with Semantic Detection</title><link>http://arxiv.org/abs/2306.16313v1</link><description>Text correction, especially the semantic correction of more widely usedscenes, is strongly required to improve, for the fluency and writing efficiencyof the text. An adversarial multi-task learning method is proposed to enhancethe modeling and detection ability of character polysemy in Chinese sentencecontext. Wherein, two models, the masked language model and scoring languagemodel, are introduced as a pair of not only coupled but also adversariallearning tasks. Moreover, the Monte Carlo tree search strategy and a policynetwork are introduced to accomplish the efficient Chinese text correction taskwith semantic detection. The experiments are executed on three datasets andfive comparable methods, and the experimental results show that our method canobtain good performance in Chinese text correction task for better semanticrationality.</description><author>Fanyu Wang, Zhenping Xie</author><pubDate>Wed, 28 Jun 2023 16:46:00 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.16313v1</guid></item><item><title>Solar Coronal Hole Analysis and Prediction using Computer Vision and LSTM Neural Network</title><link>http://arxiv.org/abs/2301.06732v4</link><description>As humanity has begun to explore space, the significance of space weather hasbecome apparent. It has been established that coronal holes, a type of spaceweather phenomenon, can impact the operation of aircraft and satellites. Thecoronal hole is an area on the sun characterized by open magnetic field linesand relatively low temperatures, which result in the emission of the solar windat higher than average rates. In this study, To prepare for the impact ofcoronal holes on the Earth, we use computer vision to detect the coronal holeregion and calculate its size based on images from the Solar DynamicsObservatory (SDO). We compare the coronal holes for each region of the Sun andanalyze the correlation. We then implement deep learning techniques,specifically the Long Short-Term Memory (LSTM) method, to analyze trends in thecoronal hole area data and predict its size for different sun regions over 7days. By analyzing time series data on the coronal hole area, this study aimsto identify patterns and trends in coronal hole behavior and understand howthey may impact space weather events. This research represents an importantstep towards improving our ability to predict and prepare for space weatherevents that can affect Earth and technological systems.</description><author>Juyoung Yun</author><pubDate>Wed, 28 Jun 2023 16:45:16 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2301.06732v4</guid></item><item><title>Generalization on the Unseen, Logic Reasoning and Degree Curriculum</title><link>http://arxiv.org/abs/2301.13105v2</link><description>This paper considers the learning of logical (Boolean) functions with focuson the generalization on the unseen (GOTU) setting, a strong case ofout-of-distribution generalization. This is motivated by the fact that the richcombinatorial nature of data in certain reasoning tasks (e.g.,arithmetic/logic) makes representative data sampling challenging, and learningsuccessfully under GOTU gives a first vignette of an 'extrapolating' or'reasoning' learner. We then study how different network architectures trainedby (S)GD perform under GOTU and provide both theoretical and experimentalevidence that for a class of network models including instances ofTransformers, random features models, and diagonal linear networks, amin-degree-interpolator is learned on the unseen. We also provide evidence thatother instances with larger learning rates or mean-field networks reach leakymin-degree solutions. These findings lead to two implications: (1) we providean explanation to the length generalization problem (e.g., Anil et al. 2022);(2) we introduce a curriculum learning algorithm called Degree-Curriculum thatlearns monomials more efficiently by incrementing supports.</description><author>Emmanuel Abbe, Samy Bengio, Aryo Lotfi, Kevin Rizk</author><pubDate>Wed, 28 Jun 2023 16:41:49 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2301.13105v2</guid></item><item><title>Asynchronous Algorithmic Alignment with Cocycles</title><link>http://arxiv.org/abs/2306.15632v2</link><description>State-of-the-art neural algorithmic reasoners make use of message passing ingraph neural networks (GNNs). But typical GNNs blur the distinction between thedefinition and invocation of the message function, forcing a node to sendmessages to its neighbours at every layer, synchronously. When applying GNNs tolearn to execute dynamic programming algorithms, however, on most steps only ahandful of the nodes would have meaningful updates to send. One, hence, runsthe risk of inefficiencies by sending too much irrelevant data across the graph-- with many intermediate GNN steps having to learn identity functions. In thiswork, we explicitly separate the concepts of node state update and messagefunction invocation. With this separation, we obtain a mathematical formulationthat allows us to reason about asynchronous computation in both algorithms andneural networks.</description><author>Andrew Dudzik, Tamara von Glehn, Razvan Pascanu, Petar Veličković</author><pubDate>Wed, 28 Jun 2023 16:41:21 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.15632v2</guid></item><item><title>CoCoFL: Communication- and Computation-Aware Federated Learning via Partial NN Freezing and Quantization</title><link>http://arxiv.org/abs/2203.05468v3</link><description>Devices participating in federated learning (FL) typically have heterogeneouscommunication, computation, and memory resources. However, in synchronous FL,all devices need to finish training by the same deadline dictated by theserver. Our results show that training a smaller subset of the neural network(NN) at constrained devices, i.e., dropping neurons/filters as proposed bystate of the art, is inefficient, preventing these devices to make an effectivecontribution to the model. This causes unfairness w.r.t the achievableaccuracies of constrained devices, especially in cases with a skeweddistribution of class labels across devices. We present a novel FL technique,CoCoFL, which maintains the full NN structure on all devices. To adapt to thedevices' heterogeneous resources, CoCoFL freezes and quantizes selected layers,reducing communication, computation, and memory requirements, whereas otherlayers are still trained in full precision, enabling to reach a high accuracy.Thereby, CoCoFL efficiently utilizes the available resources on devices andallows constrained devices to make a significant contribution to the FL system,increasing fairness among participants (accuracy parity) and significantlyimproving the final accuracy of the model.</description><author>Kilian Pfeiffer, Martin Rapp, Ramin Khalili, Jörg Henkel</author><pubDate>Wed, 28 Jun 2023 16:36:27 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2203.05468v3</guid></item><item><title>Gaussian random field approximation via Stein's method with applications to wide random neural networks</title><link>http://arxiv.org/abs/2306.16308v1</link><description>We derive upper bounds on the Wasserstein distance ($W_1$), with respect to$\sup$-norm, between any continuous $\mathbb{R}^d$ valued random field indexedby the $n$-sphere and the Gaussian, based on Stein's method. We develop a novelGaussian smoothing technique that allows us to transfer a bound in a smoothermetric to the $W_1$ distance. The smoothing is based on covariance functionsconstructed using powers of Laplacian operators, designed so that theassociated Gaussian process has a tractable Cameron-Martin or ReproducingKernel Hilbert Space. This feature enables us to move beyond one dimensionalinterval-based index sets that were previously considered in the literature.Specializing our general result, we obtain the first bounds on the Gaussianrandom field approximation of wide random neural networks of any depth andLipschitz activation functions at the random field level. Our bounds areexplicitly expressed in terms of the widths of the network and moments of therandom weights. We also obtain tighter bounds when the activation function hasthree bounded derivatives.</description><author>Krishnakumar Balasubramanian, Larry Goldstein, Nathan Ross, Adil Salim</author><pubDate>Wed, 28 Jun 2023 16:35:10 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.16308v1</guid></item><item><title>Point2Point : A Framework for Efficient Deep Learning on Hilbert sorted Point Clouds with applications in Spatio-Temporal Occupancy Prediction</title><link>http://arxiv.org/abs/2306.16306v1</link><description>The irregularity and permutation invariance of point cloud data posechallenges for effective learning. Conventional methods for addressing thisissue involve converting raw point clouds to intermediate representations suchas 3D voxel grids or range images. While such intermediate representationssolve the problem of permutation invariance, they can result in significantloss of information. Approaches that do learn on raw point clouds either havetrouble in resolving neighborhood relationships between points or are toocomplicated in their formulation. In this paper, we propose a novel approach torepresenting point clouds as a locality preserving 1D ordering induced by theHilbert space-filling curve. We also introduce Point2Point, a neuralarchitecture that can effectively learn on Hilbert-sorted point clouds. We showthat Point2Point shows competitive performance on point cloud segmentation andgeneration tasks. Finally, we show the performance of Point2Point onSpatio-temporal Occupancy prediction from Point clouds.</description><author>Athrva Atul Pandhare</author><pubDate>Wed, 28 Jun 2023 16:30:08 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.16306v1</guid></item><item><title>Human-Aligned Calibration for AI-Assisted Decision Making</title><link>http://arxiv.org/abs/2306.00074v2</link><description>Whenever a binary classifier is used to provide decision support, ittypically provides both a label prediction and a confidence value. Then, thedecision maker is supposed to use the confidence value to calibrate how much totrust the prediction. In this context, it has been often argued that theconfidence value should correspond to a well calibrated estimate of theprobability that the predicted label matches the ground truth label. However,multiple lines of empirical evidence suggest that decision makers havedifficulties at developing a good sense on when to trust a prediction usingthese confidence values. In this paper, our goal is first to understand why andthen investigate how to construct more useful confidence values. We first arguethat, for a broad class of utility functions, there exist data distributionsfor which a rational decision maker is, in general, unlikely to discover theoptimal decision policy using the above confidence values -- an optimaldecision maker would need to sometimes place more (less) trust on predictionswith lower (higher) confidence values. However, we then show that, if theconfidence values satisfy a natural alignment property with respect to thedecision maker's confidence on her own predictions, there always exists anoptimal decision policy under which the level of trust the decision maker wouldneed to place on predictions is monotone on the confidence values, facilitatingits discoverability. Further, we show that multicalibration with respect to thedecision maker's confidence on her own predictions is a sufficient conditionfor alignment. Experiments on four different AI-assisted decision making taskswhere a classifier provides decision support to real human experts validate ourtheoretical results and suggest that alignment may lead to better decisions.</description><author>Nina L. Corvelo Benz, Manuel Gomez Rodriguez</author><pubDate>Wed, 28 Jun 2023 16:27:05 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.00074v2</guid></item><item><title>Social World Knowledge: Modeling and Applications</title><link>http://arxiv.org/abs/2306.16299v1</link><description>Social world knowledge is a key ingredient in effective communication andinformation processing by humans and machines alike. As of today, there existmany knowledge bases that represent factual world knowledge. Yet, there is noresource that is designed to capture social aspects of world knowledge. Webelieve that this work makes an important step towards the formulation andconstruction of such a resource. We introduce SocialVec, a general frameworkfor eliciting low-dimensional entity embeddings from the social contexts inwhich they occur in social networks. In this framework, entities correspond tohighly popular accounts which invoke general interest. We assume that entitiesthat individual users tend to co-follow are socially related, and use thisdefinition of social context to learn the entity embeddings. Similar to wordembeddings which facilitate tasks that involve text semantics, we expect thelearned social entity embeddings to benefit multiple tasks of social flavor. Inthis work, we elicited the social embeddings of roughly 200K entities from asample of 1.3M Twitter users and the accounts that they follow. We employ andgauge the resulting embeddings on two tasks of social importance. First, weassess the political bias of news sources in terms of entity similarity in thesocial embedding space. Second, we predict the personal traits of individualTwitter users based on the social embeddings of entities that they follow. Inboth cases, we show advantageous or competitive performance using our approachcompared with task-specific baselines. We further show that existing entityembedding schemes, which are fact-based, fail to capture social aspects ofknowledge. We make the learned social entity embeddings available to theresearch community to support further exploration of social world knowledge andits applications.</description><author>Nir Lotan, Einat Minkov</author><pubDate>Wed, 28 Jun 2023 16:25:30 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.16299v1</guid></item><item><title>A Meta-Learning Method for Estimation of Causal Excursion Effects to Assess Time-Varying Moderation</title><link>http://arxiv.org/abs/2306.16297v1</link><description>Twin revolutions in wearable technologies and smartphone-delivered digitalhealth interventions have significantly expanded the accessibility and uptakeof mobile health (mHealth) interventions across various health science domains.Sequentially randomized experiments called micro-randomized trials (MRTs) havegrown in popularity to empirically evaluate the effectiveness of these mHealthintervention components. MRTs have given rise to a new class of causalestimands known as "causal excursion effects", which enable health scientiststo assess how intervention effectiveness changes over time or is moderated byindividual characteristics, context, or responses in the past. However, currentdata analysis methods for estimating causal excursion effects requirepre-specified features of the observed high-dimensional history to construct aworking model of an important nuisance parameter. While machine learningalgorithms are ideal for automatic feature construction, their naiveapplication to causal excursion estimation can lead to bias under modelmisspecification, potentially yielding incorrect conclusions about interventioneffectiveness. To address this issue, this paper revisits the estimation ofcausal excursion effects from a meta-learner perspective, where the analystremains agnostic to the choices of supervised learning algorithms used toestimate nuisance parameters. The paper presents asymptotic properties of thenovel estimators and compares them theoretically and through extensivesimulation experiments, demonstrating relative efficiency gains and supportingthe recommendation for a doubly robust alternative to existing methods.Finally, the practical utility of the proposed methods is demonstrated byanalyzing data from a multi-institution cohort of first-year medical residentsin the United States (NeCamp et al., 2020).</description><author>Jieru Shi, Walter Dempsey</author><pubDate>Wed, 28 Jun 2023 16:19:33 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.16297v1</guid></item><item><title>Relevant Entity Selection: Knowledge Graph Bootstrapping via Zero-Shot Analogical Pruning</title><link>http://arxiv.org/abs/2306.16296v1</link><description>Knowledge Graph Construction (KGC) can be seen as an iterative processstarting from a high quality nucleus that is refined by knowledge extractionapproaches in a virtuous loop. Such a nucleus can be obtained from knowledgeexisting in an open KG like Wikidata. However, due to the size of such genericKGs, integrating them as a whole may entail irrelevant content and scalabilityissues. We propose an analogy-based approach that starts from seed entities ofinterest in a generic KG, and keeps or prunes their neighboring entities. Weevaluate our approach on Wikidata through two manually labeled datasets thatcontain either domain-homogeneous or -heterogeneous seed entities. Weempirically show that our analogy-based approach outperforms LSTM, RandomForest, SVM, and MLP, with a drastically lower number of parameters. We alsoevaluate its generalization potential in a transfer learning setting. Theseresults advocate for the further integration of analogy-based inference intasks related to the KG lifecycle.</description><author>Lucas Jarnac, Miguel Couceiro, Pierre Monnin</author><pubDate>Wed, 28 Jun 2023 16:17:59 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.16296v1</guid></item><item><title>EHRSQL: A Practical Text-to-SQL Benchmark for Electronic Health Records</title><link>http://arxiv.org/abs/2301.07695v4</link><description>We present a new text-to-SQL dataset for electronic health records (EHRs).The utterances were collected from 222 hospital staff members, includingphysicians, nurses, and insurance review and health records teams. To constructthe QA dataset on structured EHR data, we conducted a poll at a universityhospital and used the responses to create seed questions. We then manuallylinked these questions to two open-source EHR databases, MIMIC-III and eICU,and included various time expressions and held-out unanswerable questions inthe dataset, which were also collected from the poll. Our dataset poses aunique set of challenges: the model needs to 1) generate SQL queries thatreflect a wide range of needs in the hospital, including simple retrieval andcomplex operations such as calculating survival rate, 2) understand varioustime expressions to answer time-sensitive questions in healthcare, and 3)distinguish whether a given question is answerable or unanswerable. We believeour dataset, EHRSQL, can serve as a practical benchmark for developing andassessing QA models on structured EHR data and take a step further towardsbridging the gap between text-to-SQL research and its real-life deployment inhealthcare. EHRSQL is available at https://github.com/glee4810/EHRSQL.</description><author>Gyubok Lee, Hyeonji Hwang, Seongsu Bae, Yeonsu Kwon, Woncheol Shin, Seongjun Yang, Minjoon Seo, Jong-Yeup Kim, Edward Choi</author><pubDate>Wed, 28 Jun 2023 16:16:51 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2301.07695v4</guid></item><item><title>Generalizing Surgical Instruments Segmentation to Unseen Domains with One-to-Many Synthesis</title><link>http://arxiv.org/abs/2306.16285v1</link><description>Despite their impressive performance in various surgical scene understandingtasks, deep learning-based methods are frequently hindered from deploying toreal-world surgical applications for various causes. Particularly, datacollection, annotation, and domain shift in-between sites and patients are themost common obstacles. In this work, we mitigate data-related issues byefficiently leveraging minimal source images to generate synthetic surgicalinstrument segmentation datasets and achieve outstanding generalizationperformance on unseen real domains. Specifically, in our framework, only onebackground tissue image and at most three images of each foreground instrumentare taken as the seed images. These source images are extensively transformedand employed to build up the foreground and background image pools, from whichrandomly sampled tissue and instrument images are composed with multipleblending techniques to generate new surgical scene images. Besides, weintroduce hybrid training-time augmentations to diversify the training datafurther. Extensive evaluation on three real-world datasets, i.e., Endo2017,Endo2018, and RoboTool, demonstrates that our one-to-many synthetic surgicalinstruments datasets generation and segmentation framework can achieveencouraging performance compared with training with real data. Notably, on theRoboTool dataset, where a more significant domain gap exists, our frameworkshows its superiority of generalization by a considerable margin. We expectthat our inspiring results will attract research attention to improving modelgeneralization with data synthesizing.</description><author>An Wang, Mobarakol Islam, Mengya Xu, Hongliang Ren</author><pubDate>Wed, 28 Jun 2023 16:06:44 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.16285v1</guid></item><item><title>Deep Learning assisted microwave-plasma interaction based technique for plasma density estimation</title><link>http://arxiv.org/abs/2304.14807v2</link><description>The electron density is a key parameter to characterize any plasma. Most ofthe plasma applications and research in the area of low-temperature plasmas(LTPs) are based on the accurate estimations of plasma density and plasmatemperature. The conventional methods for electron density measurements offeraxial and radial profiles for any given linear LTP device. These methods havemajor disadvantages of operational range (not very wide), cumbersomeinstrumentation, and complicated data analysis procedures. The article proposesa Deep Learning (DL) assisted microwave-plasma interaction-based non-invasivestrategy, which can be used as a new alternative approach to address some ofthe challenges associated with existing plasma density measurement techniques.The electric field pattern due to microwave scattering from plasma is utilizedto estimate the density profile. The proof of concept is tested for a simulatedtraining data set comprising a low-temperature, unmagnetized, collisionalplasma. Different types of symmetric (Gaussian-shaped) and asymmetrical densityprofiles, in the range $10^{16}-10^{19}$ m$^{-3}$, addressing a range ofexperimental configurations have been considered in our study. Real-lifeexperimental issues such as the presence of noise and the amount of measureddata (dense vs sparse) have been taken into consideration while preparing thesynthetic training data-sets. The DL-based technique has the capability todetermine the electron density profile within the plasma. The performance ofthe proposed deep learning-based approach has been evaluated using threemetrics- SSIM, RMSLE, and MAPE. The obtained results show promising performancein estimating the 2D radial profile of the density for the given linear plasmadevice and affirms the potential of the proposed ML-based approach in plasmadiagnostics.</description><author>Pratik Ghosh, Bhaskar Chaudhury, Shishir Purohit, Vishv Joshi, Ashray Kothari, Devdeep Shetranjiwala</author><pubDate>Wed, 28 Jun 2023 15:55:30 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2304.14807v2</guid></item><item><title>Leveraging GPT-4 for Food Effect Summarization to Enhance Product-Specific Guidance Development via Iterative Prompting</title><link>http://arxiv.org/abs/2306.16275v1</link><description>Food effect summarization from New Drug Application (NDA) is an essentialcomponent of product-specific guidance (PSG) development and assessment.However, manual summarization of food effect from extensive drug applicationreview documents is time-consuming, which arouses a need to develop automatedmethods. Recent advances in large language models (LLMs) such as ChatGPT andGPT-4, have demonstrated great potential in improving the effectiveness ofautomated text summarization, but its ability regarding the accuracy insummarizing food effect for PSG assessment remains unclear. In this study, weintroduce a simple yet effective approach, iterative prompting, which allowsone to interact with ChatGPT or GPT-4 more effectively and efficiently throughmulti-turn interaction. Specifically, we propose a three-turn iterativeprompting approach to food effect summarization in which the keyword-focusedand length-controlled prompts are respectively provided in consecutive turns torefine the quality of the generated summary. We conduct a series of extensiveevaluations, ranging from automated metrics to FDA professionals and evenevaluation by GPT-4, on 100 NDA review documents selected over the past fiveyears. We observe that the summary quality is progressively improved throughoutthe process. Moreover, we find that GPT-4 performs better than ChatGPT, asevaluated by FDA professionals (43% vs. 12%) and GPT-4 (64% vs. 35%).Importantly, all the FDA professionals unanimously rated that 85% of thesummaries generated by GPT-4 are factually consistent with the golden referencesummary, a finding further supported by GPT-4 rating of 72% consistency. Theseresults strongly suggest a great potential for GPT-4 to draft food effectsummaries that could be reviewed by FDA professionals, thereby improving theefficiency of PSG assessment cycle and promoting the generic drug productdevelopment.</description><author>Yiwen Shi, Ping Ren, Jing Wang, Biao Han, Taha ValizadehAslani, Felix Agbavor, Yi Zhang, Meng Hu, Liang Zhao, Hualou Liang</author><pubDate>Wed, 28 Jun 2023 15:55:13 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.16275v1</guid></item><item><title>S2SNet: A Pretrained Neural Network for Superconductivity Discovery</title><link>http://arxiv.org/abs/2306.16270v1</link><description>Superconductivity allows electrical current to flow without any energy loss,and thus making solids superconducting is a grand goal of physics, materialscience, and electrical engineering. More than 16 Nobel Laureates have beenawarded for their contribution to superconductivity research. Superconductorsare valuable for sustainable development goals (SDGs), such as climate changemitigation, affordable and clean energy, industry, innovation andinfrastructure, and so on. However, a unified physics theory explaining allsuperconductivity mechanism is still unknown. It is believed thatsuperconductivity is microscopically due to not only molecular compositions butalso the geometric crystal structure. Hence a new dataset, S2S, containing bothcrystal structures and superconducting critical temperature, is built uponSuperCon and Material Project. Based on this new dataset, we propose a novelmodel, S2SNet, which utilizes the attention mechanism for superconductivityprediction. To overcome the shortage of data, S2SNet is pre-trained on thewhole Material Project dataset with Masked-Language Modeling (MLM). S2SNetmakes a new state-of-the-art, with out-of-sample accuracy of 92% and Area UnderCurve (AUC) of 0.92. To the best of our knowledge, S2SNet is the first work topredict superconductivity with only information of crystal structures. Thiswork is beneficial to superconductivity discovery and further SDGs. Code anddatasets are available in https://github.com/zjuKeLiu/S2SNet</description><author>Ke Liu, Kaifan Yang, Jiahong Zhang, Renjun Xu</author><pubDate>Wed, 28 Jun 2023 15:52:50 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.16270v1</guid></item><item><title>RSPrompter: Learning to Prompt for Remote Sensing Instance Segmentation based on Visual Foundation Model</title><link>http://arxiv.org/abs/2306.16269v1</link><description>Leveraging vast training data (SA-1B), the foundation Segment Anything Model(SAM) proposed by Meta AI Research exhibits remarkable generalization andzero-shot capabilities. Nonetheless, as a category-agnostic instancesegmentation method, SAM heavily depends on prior manual guidance involvingpoints, boxes, and coarse-grained masks. Additionally, its performance onremote sensing image segmentation tasks has yet to be fully explored anddemonstrated. In this paper, we consider designing an automated instancesegmentation approach for remote sensing images based on the SAM foundationmodel, incorporating semantic category information. Inspired by promptlearning, we propose a method to learn the generation of appropriate promptsfor SAM input. This enables SAM to produce semantically discerniblesegmentation results for remote sensing images, which we refer to asRSPrompter. We also suggest several ongoing derivatives for instancesegmentation tasks, based on recent developments in the SAM community, andcompare their performance with RSPrompter. Extensive experimental results onthe WHU building, NWPU VHR-10, and SSDD datasets validate the efficacy of ourproposed method. Our code is accessible at\url{https://kyanchen.github.io/RSPrompter}.</description><author>Keyan Chen, Chenyang Liu, Hao Chen, Haotian Zhang, Wenyuan Li, Zhengxia Zou, Zhenwei Shi</author><pubDate>Wed, 28 Jun 2023 15:51:34 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.16269v1</guid></item><item><title>Emotion Analysis of Tweets Banning Education in Afghanistan</title><link>http://arxiv.org/abs/2306.16268v1</link><description>This paper introduces the first emotion annotated dataset for the Darivariant of Persian spoken in Afghanistan. The LetHerLearn dataset contains7,600 tweets posted in reaction to the Taliban ban of women rights to educationin 2022 and has been manually annotated according to Ekman emotion categories.We here detail the data collection and annotation process, present relevantdataset statistics as well as initial experiments on the resulting dataset,benchmarking a number of different neural architectures for the task of Dariemotion classification.</description><author>Mohammad Ali Hussiny, Lilja Øvrelid</author><pubDate>Wed, 28 Jun 2023 15:50:49 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.16268v1</guid></item><item><title>G-NM: A Group of Numerical Time Series Prediction Models</title><link>http://arxiv.org/abs/2306.11667v2</link><description>In this study, we focus on the development and implementation of acomprehensive ensemble of numerical time series forecasting models,collectively referred to as the Group of Numerical Time Series Prediction Model(G-NM). This inclusive set comprises traditional models such as AutoregressiveIntegrated Moving Average (ARIMA), Holt-Winters' method, and Support VectorRegression (SVR), in addition to modern neural network models includingRecurrent Neural Network (RNN) and Long Short-Term Memory (LSTM). G-NM isexplicitly constructed to augment our predictive capabilities related topatterns and trends inherent in complex natural phenomena. By utilizing timeseries data relevant to these events, G-NM facilitates the prediction of suchphenomena over extended periods. The primary objective of this research is toboth advance our understanding of such occurrences and to significantly enhancethe accuracy of our forecasts. G-NM encapsulates both linear and non-lineardependencies, seasonalities, and trends present in time series data. Each ofthese models contributes distinct strengths, from ARIMA's resilience inhandling linear trends and seasonality, SVR's proficiency in capturingnon-linear patterns, to LSTM's adaptability in modeling various components oftime series data. Through the exploitation of the G-NM potential, we strive toadvance the state-of-the-art in large-scale time series forecasting models. Weanticipate that this research will represent a significant stepping stone inour ongoing endeavor to comprehend and forecast the complex events thatconstitute the natural world.</description><author>Juyoung Yun</author><pubDate>Wed, 28 Jun 2023 15:48:59 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.11667v2</guid></item><item><title>Deep Unfolded Simulated Bifurcation for Massive MIMO Signal Detection</title><link>http://arxiv.org/abs/2306.16264v1</link><description>Multiple-input multiple-output (MIMO) is a key ingredient of next-generationwireless communications. Recently, various MIMO signal detectors based on deeplearning techniques and quantum(-inspired) algorithms have been proposed toimprove the detection performance compared with conventional detectors. Thispaper focuses on the simulated bifurcation (SB) algorithm, a quantum-inspiredalgorithm. This paper proposes two techniques to improve its detectionperformance. The first is modifying the algorithm inspired by theLevenberg-Marquardt algorithm to eliminate local minima of maximum likelihooddetection. The second is the use of deep unfolding, a deep learning techniqueto train the internal parameters of an iterative algorithm. We propose adeep-unfolded SB by making the update rule of SB differentiable. The numericalresults show that these proposed detectors significantly improve the signaldetection performance in massive MIMO systems.</description><author>Satoshi Takabe</author><pubDate>Wed, 28 Jun 2023 15:46:55 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.16264v1</guid></item><item><title>Maximum Likelihood Training of Autoencoders</title><link>http://arxiv.org/abs/2306.01843v2</link><description>Maximum likelihood training has favorable statistical properties and ispopular for generative modeling, especially with normalizing flows. On theother hand, generative autoencoders promise to be more efficient thannormalizing flows due to the manifold hypothesis. In this work, we introducesuccessful maximum likelihood training of unconstrained autoencoders for thefirst time, bringing the two paradigms together. To do so, we identify andovercome two challenges: Firstly, existing maximum likelihood estimators forfree-form networks are unacceptably slow, relying on iteration schemes whosecost scales linearly with latent dimension. We introduce an improved estimatorwhich eliminates iteration, resulting in constant cost (roughly double theruntime per batch of a vanilla autoencoder). Secondly, we demonstrate thatnaively applying maximum likelihood to autoencoders can lead to divergentsolutions and use this insight to motivate a stable maximum likelihood trainingobjective. We perform extensive experiments on toy, tabular and image data,demonstrating the competitive performance of the resulting model. We call ourmodel the maximum likelihood autoencoder (MLAE).</description><author>Peter Sorrenson, Felix Draxler, Armand Rousselot, Sander Hummerich, Lea Zimmermann, Ullrich Köthe</author><pubDate>Wed, 28 Jun 2023 15:43:16 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.01843v2</guid></item><item><title>Sequential Gradient Coding For Straggler Mitigation</title><link>http://arxiv.org/abs/2211.13802v2</link><description>In distributed computing, slower nodes (stragglers) usually become abottleneck. Gradient Coding (GC), introduced by Tandon et al., is an efficienttechnique that uses principles of error-correcting codes to distribute gradientcomputation in the presence of stragglers. In this paper, we consider thedistributed computation of a sequence of gradients $\{g(1),g(2),\ldots,g(J)\}$,where processing of each gradient $g(t)$ starts in round-$t$ and finishes byround-$(t+T)$. Here $T\geq 0$ denotes a delay parameter. For the GC scheme,coding is only across computing nodes and this results in a solution where$T=0$. On the other hand, having $T&gt;0$ allows for designing schemes whichexploit the temporal dimension as well. In this work, we propose two schemesthat demonstrate improved performance compared to GC. Our first scheme combinesGC with selective repetition of previously unfinished tasks and achievesimproved straggler mitigation. In our second scheme, which constitutes our maincontribution, we apply GC to a subset of the tasks and repetition for theremainder of the tasks. We then multiplex these two classes of tasks acrossworkers and rounds in an adaptive manner, based on past straggler patterns.Using theoretical analysis, we demonstrate that our second scheme achievessignificant reduction in the computational load. In our experiments, we study apractical setting of concurrently training multiple neural networks over an AWSLambda cluster involving 256 worker nodes, where our framework naturallyapplies. We demonstrate that the latter scheme can yield a 16\% improvement inruntime over the baseline GC scheme, in the presence of naturally occurring,non-simulated stragglers.</description><author>M. Nikhil Krishnan, MohammadReza Ebrahimi, Ashish Khisti</author><pubDate>Wed, 28 Jun 2023 15:42:36 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2211.13802v2</guid></item><item><title>Auto-AVSR: Audio-Visual Speech Recognition with Automatic Labels</title><link>http://arxiv.org/abs/2303.14307v3</link><description>Audio-visual speech recognition has received a lot of attention due to itsrobustness against acoustic noise. Recently, the performance of automatic,visual, and audio-visual speech recognition (ASR, VSR, and AV-ASR,respectively) has been substantially improved, mainly due to the use of largermodels and training sets. However, accurate labelling of datasets istime-consuming and expensive. Hence, in this work, we investigate the use ofautomatically-generated transcriptions of unlabelled datasets to increase thetraining set size. For this purpose, we use publicly-available pre-trained ASRmodels to automatically transcribe unlabelled datasets such as AVSpeech andVoxCeleb2. Then, we train ASR, VSR and AV-ASR models on the augmented trainingset, which consists of the LRS2 and LRS3 datasets as well as the additionalautomatically-transcribed data. We demonstrate that increasing the size of thetraining set, a recent trend in the literature, leads to reduced WER despiteusing noisy transcriptions. The proposed model achieves new state-of-the-artperformance on AV-ASR on LRS2 and LRS3. In particular, it achieves a WER of0.9% on LRS3, a relative improvement of 30% over the current state-of-the-artapproach, and outperforms methods that have been trained on non-publiclyavailable datasets with 26 times more training data.</description><author>Pingchuan Ma, Alexandros Haliassos, Adriana Fernandez-Lopez, Honglie Chen, Stavros Petridis, Maja Pantic</author><pubDate>Wed, 28 Jun 2023 15:41:17 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2303.14307v3</guid></item><item><title>Multi-task Hierarchical Adversarial Inverse Reinforcement Learning</title><link>http://arxiv.org/abs/2305.12633v2</link><description>Multi-task Imitation Learning (MIL) aims to train a policy capable ofperforming a distribution of tasks based on multi-task expert demonstrations,which is essential for general-purpose robots. Existing MIL algorithms sufferfrom low data efficiency and poor performance on complex long-horizontal tasks.We develop Multi-task Hierarchical Adversarial Inverse Reinforcement Learning(MH-AIRL) to learn hierarchically-structured multi-task policies, which is morebeneficial for compositional tasks with long horizons and has higher expertdata efficiency through identifying and transferring reusable basic skillsacross tasks. To realize this, MH-AIRL effectively synthesizes context-basedmulti-task learning, AIRL (an IL approach), and hierarchical policy learning.Further, MH-AIRL can be adopted to demonstrations without the task or skillannotations (i.e., state-action pairs only) which are more accessible inpractice. Theoretical justifications are provided for each module of MH-AIRL,and evaluations on challenging multi-task settings demonstrate superiorperformance and transferability of the multi-task policies learned with MH-AIRLas compared to SOTA MIL baselines.</description><author>Jiayu Chen, Dipesh Tamboli, Tian Lan, Vaneet Aggarwal</author><pubDate>Wed, 28 Jun 2023 15:32:42 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.12633v2</guid></item><item><title>Land Cover Segmentation with Sparse Annotations from Sentinel-2 Imagery</title><link>http://arxiv.org/abs/2306.16252v1</link><description>Land cover (LC) segmentation plays a critical role in various applications,including environmental analysis and natural disaster management. However,generating accurate LC maps is a complex and time-consuming task that requiresthe expertise of multiple annotators and regular updates to account forenvironmental changes. In this work, we introduce SPADA, a framework for fuelmap delineation that addresses the challenges associated with LC segmentationusing sparse annotations and domain adaptation techniques for semanticsegmentation. Performance evaluations using reliable ground truths, such asLUCAS and Urban Atlas, demonstrate the technique's effectiveness. SPADAoutperforms state-of-the-art semantic segmentation approaches as well asthird-party products, achieving a mean Intersection over Union (IoU) score of42.86 and an F1 score of 67.93 on Urban Atlas and LUCAS, respectively.</description><author>Marco Galatola, Edoardo Arnaudo, Luca Barco, Claudio Rossi, Fabrizio Dominici</author><pubDate>Wed, 28 Jun 2023 15:26:57 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.16252v1</guid></item><item><title>Hierarchical MixUp Multi-label Classification with Imbalanced Interdisciplinary Research Proposals</title><link>http://arxiv.org/abs/2209.13912v2</link><description>Funding agencies are largely relied on a topic matching between domainexperts and research proposals to assign proposal reviewers. As proposals areincreasingly interdisciplinary, it is challenging to profile theinterdisciplinary nature of a proposal, and, thereafter, find expert reviewerswith an appropriate set of expertise. An essential step in solving thischallenge is to accurately model and classify the interdisciplinary labels of aproposal. Existing methodological and application-related literature, such astextual classification and proposal classification, are insufficient in jointlyaddressing the three key unique issues introduced by interdisciplinary proposaldata: 1) the hierarchical structure of discipline labels of a proposal fromcoarse-grain to fine-grain, e.g., from information science to AI tofundamentals of AI. 2) the heterogeneous semantics of various main textualparts that play different roles in a proposal; 3) the number of proposals isimbalanced between non-interdisciplinary and interdisciplinary research. Can wesimultaneously address the three issues in understanding the proposal'sinterdisciplinary nature? In response to this question, we propose ahierarchical mixup multiple-label classification framework, which we calledH-MixUp. H-MixUp leverages a transformer-based semantic information extractorand a GCN-based interdisciplinary knowledge extractor for the first and secondissues. H-MixUp develops a fused training method of Wold-level MixUp,Word-level CutMix, Manifold MixUp, and Document-level MixUp to address thethird issue.</description><author>Meng Xiao, Min Wu, Ziyue Qiao, Zhiyuan Ning, Yi Du, Yanjie Fu, Yuanchun Zhou</author><pubDate>Wed, 28 Jun 2023 15:24:54 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2209.13912v2</guid></item><item><title>Optimal tests following sequential experiments</title><link>http://arxiv.org/abs/2305.00403v2</link><description>Recent years have seen tremendous advances in the theory and application ofsequential experiments. While these experiments are not always designed withhypothesis testing in mind, researchers may still be interested in performingtests after the experiment is completed. The purpose of this paper is to aid inthe development of optimal tests for sequential experiments by analyzing theirasymptotic properties. Our key finding is that the asymptotic power function ofany test can be matched by a test in a limit experiment where a Gaussianprocess is observed for each treatment, and inference is made for the drifts ofthese processes. This result has important implications, including a powerfulsufficiency result: any candidate test only needs to rely on a fixed set ofstatistics, regardless of the type of sequential experiment. These statisticsare the number of times each treatment has been sampled by the end of theexperiment, along with final value of the score (for parametric models) orefficient influence function (for non-parametric models) process for eachtreatment. We then characterize asymptotically optimal tests under variousrestrictions such as unbiasedness, \alpha-spending constraints etc. Finally, weapply our our results to three key classes of sequential experiments: costlysampling, group sequential trials, and bandit experiments, and show how optimalinference can be conducted in these scenarios.</description><author>Karun Adusumilli</author><pubDate>Wed, 28 Jun 2023 15:21:07 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.00403v2</guid></item><item><title>Latent SDEs on Homogeneous Spaces</title><link>http://arxiv.org/abs/2306.16248v1</link><description>We consider the problem of variational Bayesian inference in a latentvariable model where a (possibly complex) observed stochastic process isgoverned by the solution of a latent stochastic differential equation (SDE).Motivated by the challenges that arise when trying to learn an (almostarbitrary) latent neural SDE from large-scale data, such as efficient gradientcomputation, we take a step back and study a specific subclass instead. In ourcase, the SDE evolves on a homogeneous latent space and is induced bystochastic dynamics of the corresponding (matrix) Lie group. In learningproblems, SDEs on the unit $n$-sphere are arguably the most relevantincarnation of this setup. Notably, for variational inference, the sphere notonly facilitates using a truly uninformative prior SDE, but we also obtain aparticularly simple and intuitive expression for the Kullback-Leiblerdivergence between the approximate posterior and prior process in the evidencelower bound. Experiments demonstrate that a latent SDE of the proposed type canbe learned efficiently by means of an existing one-step geometricEuler-Maruyama scheme. Despite restricting ourselves to a less diverse class ofSDEs, we achieve competitive or even state-of-the-art performance on varioustime series interpolation and classification benchmarks.</description><author>Sebastian Zeng, Florian Graf, Roland Kwitt</author><pubDate>Wed, 28 Jun 2023 15:18:52 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.16248v1</guid></item><item><title>A Cookbook of Self-Supervised Learning</title><link>http://arxiv.org/abs/2304.12210v2</link><description>Self-supervised learning, dubbed the dark matter of intelligence, is apromising path to advance machine learning. Yet, much like cooking, trainingSSL methods is a delicate art with a high barrier to entry. While manycomponents are familiar, successfully training a SSL method involves a dizzyingset of choices from the pretext tasks to training hyper-parameters. Our goal isto lower the barrier to entry into SSL research by laying the foundations andlatest SSL recipes in the style of a cookbook. We hope to empower the curiousresearcher to navigate the terrain of methods, understand the role of thevarious knobs, and gain the know-how required to explore how delicious SSL canbe.</description><author>Randall Balestriero, Mark Ibrahim, Vlad Sobal, Ari Morcos, Shashank Shekhar, Tom Goldstein, Florian Bordes, Adrien Bardes, Gregoire Mialon, Yuandong Tian, Avi Schwarzschild, Andrew Gordon Wilson, Jonas Geiping, Quentin Garrido, Pierre Fernandez, Amir Bar, Hamed Pirsiavash, Yann LeCun, Micah Goldblum</author><pubDate>Wed, 28 Jun 2023 15:15:22 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2304.12210v2</guid></item><item><title>CBBQ: A Chinese Bias Benchmark Dataset Curated with Human-AI Collaboration for Large Language Models</title><link>http://arxiv.org/abs/2306.16244v1</link><description>Holistically measuring societal biases of large language models is crucialfor detecting and reducing ethical risks in highly capable AI models. In thiswork, we present a Chinese Bias Benchmark dataset that consists of over 100Kquestions jointly constructed by human experts and generative language models,covering stereotypes and societal biases in 14 social dimensions related toChinese culture and values. The curation process contains 4 essential steps:bias identification via extensive literature review, ambiguous contextgeneration, AI-assisted disambiguous context generation, snd manual review \&amp;recomposition. The testing instances in the dataset are automatically derivedfrom 3K+ high-quality templates manually authored with stringent qualitycontrol. The dataset exhibits wide coverage and high diversity. Extensiveexperiments demonstrate the effectiveness of the dataset in detecting modelbias, with all 10 publicly available Chinese large language models exhibitingstrong bias in certain categories. Additionally, we observe from ourexperiments that fine-tuned models could, to a certain extent, heedinstructions and avoid generating outputs that are morally harmful in sometypes, in the way of "moral self-correction". Our dataset and results arepublicly available at\href{https://github.com/YFHuangxxxx/CBBQ}{https://github.com/YFHuangxxxx/CBBQ},offering debiasing research opportunities to a widened community.</description><author>Yufei Huang, Deyi Xiong</author><pubDate>Wed, 28 Jun 2023 15:14:44 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.16244v1</guid></item><item><title>Deep Learning for Cancer Prognosis Prediction Using Portrait Photos by StyleGAN Embedding</title><link>http://arxiv.org/abs/2306.14596v2</link><description>Survival prediction for cancer patients is critical for optimal treatmentselection and patient management. Current patient survival prediction methodstypically extract survival information from patients' clinical record data orbiological and imaging data. In practice, experienced clinicians can have apreliminary assessment of patients' health status based on patients' observablephysical appearances, which are mainly facial features. However, suchassessment is highly subjective. In this work, the efficacy of objectivelycapturing and using prognostic information contained in conventional portraitphotographs using deep learning for survival predication purposes isinvestigated for the first time. A pre-trained StyleGAN2 model is fine-tuned ona custom dataset of our cancer patients' photos to empower its generator withgenerative ability suitable for patients' photos. The StyleGAN2 is then used toembed the photographs to its highly expressive latent space. Utilizing thestate-of-the-art survival analysis models and based on StyleGAN's latent spacephoto embeddings, this approach achieved a C-index of 0.677, which is notablyhigher than chance and evidencing the prognostic value embedded in simple 2Dfacial images. In addition, thanks to StyleGAN's interpretable latent space,our survival prediction model can be validated for relying on essential facialfeatures, eliminating any biases from extraneous information like clothing orbackground. Moreover, a health attribute is obtained from regressioncoefficients, which has important potential value for patient care.</description><author>Amr Hagag, Ahmed Gomaa, Dominik Kornek, Andreas Maier, Rainer Fietkau, Christoph Bert, Florian Putz, Yixing Huang</author><pubDate>Wed, 28 Jun 2023 15:13:28 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.14596v2</guid></item><item><title>DeepSMILE: Contrastive self-supervised pre-training benefits MSI and HRD classification directly from H&amp;E whole-slide images in colorectal and breast cancer</title><link>http://arxiv.org/abs/2107.09405v3</link><description>We propose a Deep learning-based weak label learning method for analyzingwhole slide images (WSIs) of Hematoxylin and Eosin (H&amp;E) stained tumor tissuenot requiring pixel-level or tile-level annotations using Self-supervisedpre-training and heterogeneity-aware deep Multiple Instance LEarning(DeepSMILE). We apply DeepSMILE to the task of Homologous recombinationdeficiency (HRD) and microsatellite instability (MSI) prediction. We utilizecontrastive self-supervised learning to pre-train a feature extractor onhistopathology tiles of cancer tissue. Additionally, we use variability-awaredeep multiple instance learning to learn the tile feature aggregation functionwhile modeling tumor heterogeneity. For MSI prediction in a tumor-annotated andcolor normalized subset of TCGA-CRC (n=360 patients), contrastiveself-supervised learning improves the tile supervision baseline from 0.77 to0.87 AUROC, on par with our proposed DeepSMILE method. On TCGA-BC (n=1041patients) without any manual annotations, DeepSMILE improves HRD classificationperformance from 0.77 to 0.81 AUROC compared to tile supervision with either aself-supervised or ImageNet pre-trained feature extractor. Our proposed methodsreach the baseline performance using only 40% of the labeled data on bothdatasets. These improvements suggest we can use standard self-supervisedlearning techniques combined with multiple instance learning in thehistopathology domain to improve genomic label classification performance withfewer labeled data.</description><author>Yoni Schirris, Efstratios Gavves, Iris Nederlof, Hugo Mark Horlings, Jonas Teuwen</author><pubDate>Wed, 28 Jun 2023 14:52:29 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2107.09405v3</guid></item><item><title>GeoT: A Geometry-aware Transformer for Reliable Molecular Property Prediction and Chemically Interpretable Representation Learning</title><link>http://arxiv.org/abs/2106.15516v3</link><description>In recent years, molecular representation learning has emerged as a key areaof focus in various chemical tasks. However, many existing models fail to fullyconsider the geometric information of molecular structures, resulting in lessintuitive representations. Moreover, the widely used message-passing mechanismis limited to provide the interpretation of experimental results from achemical perspective. To address these challenges, we introduce a novelTransformer-based framework for molecular representation learning, named theGeometry-aware Transformer (GeoT). GeoT learns molecular graph structuresthrough attention-based mechanisms specifically designed to offer reliableinterpretability, as well as molecular property prediction. Consequently, GeoTcan generate attention maps of interatomic relationships associated withtraining objectives. In addition, GeoT demonstrates comparable performance toMPNN-based models while achieving reduced computational complexity. Ourcomprehensive experiments, including an empirical simulation, reveal that GeoTeffectively learns the chemical insights into molecular structures, bridgingthe gap between artificial intelligence and molecular sciences.</description><author>Bumju Kwak, Jiwon Park, Taewon Kang, Jeonghee Jo, Byunghan Lee, Sungroh Yoon</author><pubDate>Wed, 28 Jun 2023 14:51:49 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2106.15516v3</guid></item><item><title>MAF-Net: Multiple attention-guided fusion network for fundus vascular image segmentation</title><link>http://arxiv.org/abs/2305.03617v3</link><description>Accurately segmenting blood vessels in retinal fundus images is crucial inthe early screening, diagnosing, and evaluating some ocular diseases, yet itposes a nontrivial uncertainty for the segmentation task due to various factorssuch as significant light variations, uneven curvilinear structures, andnon-uniform contrast. As a result, a multiple attention-guided fusion network(MAF-Net) is proposed to accurately detect blood vessels in retinal fundusimages. Currently, traditional UNet-based models may lose partial informationdue to explicitly modeling long-distance dependencies, which may lead tounsatisfactory results. To enrich contextual information for the loss of sceneinformation compensation, an attention fusion mechanism that combines thechannel attention with spatial attention mechanisms constructed by Transformeris employed to extract various features of blood vessels from retinal fundusimages. Subsequently, a unique spatial attention mechanism is applied in theskip connection to filter out redundant information and noise from low-levelfeatures, thus enabling better integration with high-level features. Inaddition, a DropOut layer is employed to randomly discard some neurons, whichcan prevent overfitting of the deep learning network and improve itsgeneralization performance. Experimental results were verified in publicdatasets DRIVE, STARE and CHASEDB1 with F1 scores of 0.818, 0.836 and 0.811,and Acc values of 0.968, 0.973 and 0.973, respectively. Both visual inspectionand quantitative evaluation demonstrate that our method produces satisfactoryresults compared to some state-of-the-art methods.</description><author>Yuanyuan Peng, Pengpeng Luan, Zixu Zhang</author><pubDate>Wed, 28 Jun 2023 14:49:32 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.03617v3</guid></item><item><title>Towards Revealing the Mystery behind Chain of Thought: A Theoretical Perspective</title><link>http://arxiv.org/abs/2305.15408v3</link><description>Recent studies have discovered that Chain-of-Thought prompting (CoT) candramatically improve the performance of Large Language Models (LLMs),particularly when dealing with complex tasks involving mathematics orreasoning. Despite the enormous empirical success, the underlying mechanismsbehind CoT and how it unlocks the potential of LLMs remain elusive. In thispaper, we take a first step towards theoretically answering these questions.Specifically, we examine the expressivity of LLMs with CoT in solvingfundamental mathematical and decision-making problems. We start by giving animpossibility result showing that bounded-depth Transformers are unable todirectly produce correct answers for basic arithmetic/equation tasks unless themodel size grows super-polynomially with respect to the input length. Incontrast, we then prove by construction that autoregressive Transformers ofconstant size suffice to solve both tasks by generating CoT derivations using acommonly-used math language format. Moreover, we show LLMs with CoT are capableof solving a general class of decision-making problems known as DynamicProgramming, thus justifying its power in tackling complex real-world tasks.Finally, extensive experiments on four tasks show that, while Transformersalways fail to predict the answers directly, they can consistently learn togenerate correct solutions step-by-step given sufficient CoT demonstrations.</description><author>Guhao Feng, Bohang Zhang, Yuntian Gu, Haotian Ye, Di He, Liwei Wang</author><pubDate>Wed, 28 Jun 2023 14:44:19 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.15408v3</guid></item><item><title>Inferring the Goals of Communicating Agents from Actions and Instructions</title><link>http://arxiv.org/abs/2306.16207v1</link><description>When humans cooperate, they frequently coordinate their activity through bothverbal communication and non-verbal actions, using this information to infer ashared goal and plan. How can we model this inferential ability? In this paper,we introduce a model of a cooperative team where one agent, the principal, maycommunicate natural language instructions about their shared plan to anotheragent, the assistant, using GPT-3 as a likelihood function for instructionutterances. We then show how a third person observer can infer the team's goalvia multi-modal Bayesian inverse planning from actions and instructions,computing the posterior distribution over goals under the assumption thatagents will act and communicate rationally to achieve them. We evaluate thisapproach by comparing it with human goal inferences in a multi-agent gridworld,finding that our model's inferences closely correlate with human judgments (R =0.96). When compared to inference from actions alone, we also find thatinstructions lead to more rapid and less uncertain goal inference, highlightingthe importance of verbal communication for cooperative agents.</description><author>Lance Ying, Tan Zhi-Xuan, Vikash Mansinghka, Joshua B. Tenenbaum</author><pubDate>Wed, 28 Jun 2023 14:43:46 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.16207v1</guid></item><item><title>Continuous-Time q-learning for McKean-Vlasov Control Problems</title><link>http://arxiv.org/abs/2306.16208v1</link><description>This paper studies the q-learning, recently coined as the continuous-timecounterpart of Q-learning by Jia and Zhou (2022c), for continuous timeMckean-Vlasov control problems in the setting of entropy-regularizedreinforcement learning. In contrast to the single agent's control problem inJia and Zhou (2022c), the mean-field interaction of agents render thedefinition of q-function more subtle, for which we reveal that two distinctq-functions naturally arise: (i) the integrated q-function (denoted by $q$) asthe first-order approximation of the integrated Q-function introduced in Gu,Guo, Wei and Xu (2023) that can be learnt by a weak martingale conditioninvolving test policies; and (ii) the essential q-function (denoted by $q_e$)that is employed in the policy improvement iterations. We show that twoq-functions are related via an integral representation under all test policies.Based on the weak martingale condition of the integrated q-function and ourproposed searching method of test policies, some model-free offline and onlinelearning algorithms are devised. In two financial applications, one in LQcontrol framework and one beyond LQ control framework, we can obtain the exactparameterization of the value function and two q-functions and illustrate ouralgorithms with simulation experiments.</description><author>Xiaoli Wei, Xiang Yu</author><pubDate>Wed, 28 Jun 2023 14:43:46 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.16208v1</guid></item><item><title>Towards a Better Understanding of Learning with Multiagent Teams</title><link>http://arxiv.org/abs/2306.16205v1</link><description>While it has long been recognized that a team of individual learning agentscan be greater than the sum of its parts, recent work has shown that largerteams are not necessarily more effective than smaller ones. In this paper, westudy why and under which conditions certain team structures promote effectivelearning for a population of individual learning agents. We show that,depending on the environment, some team structures help agents learn tospecialize into specific roles, resulting in more favorable global results.However, large teams create credit assignment challenges that reducecoordination, leading to large teams performing poorly compared to smallerones. We support our conclusions with both theoretical analysis and empiricalresults.</description><author>David Radke, Kate Larson, Tim Brecht, Kyle Tilbury</author><pubDate>Wed, 28 Jun 2023 14:37:48 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.16205v1</guid></item><item><title>Improving Differentially Private SGD via Randomly Sparsified Gradients</title><link>http://arxiv.org/abs/2112.00845v3</link><description>Differentially private stochastic gradient descent (DP-SGD) has been widelyadopted in deep learning to provide rigorously defined privacy, which requiresgradient clipping to bound the maximum norm of individual gradients andadditive isotropic Gaussian noise. With analysis of the convergence rate ofDP-SGD in a non-convex setting, we identify that randomly sparsifying gradientsbefore clipping and noisification adjusts a trade-off between internalcomponents of the convergence bound and leads to a smaller upper bound when thenoise is dominant. Additionally, our theoretical analysis and empiricalevaluations show that the trade-off is not trivial but possibly a uniqueproperty of DP-SGD, as either canceling noisification or gradient clippingeliminates the trade-off in the bound. This observation is indicative, as itimplies DP-SGD has special inherent room for (even simply random) gradientcompression. To verify the observation and utilize it, we propose an efficientand lightweight extension using random sparsification (RS) to strengthenDP-SGD. Experiments with various DP-SGD frameworks show that RS can improveperformance. Additionally, the produced sparse gradients of RS exhibitadvantages in reducing communication cost and strengthening privacy againstreconstruction attacks, which are also key problems in private machinelearning.</description><author>Junyi Zhu, Matthew B. Blaschko</author><pubDate>Wed, 28 Jun 2023 14:30:48 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2112.00845v3</guid></item><item><title>Low-Confidence Samples Mining for Semi-supervised Object Detection</title><link>http://arxiv.org/abs/2306.16201v1</link><description>Reliable pseudo-labels from unlabeled data play a key role in semi-supervisedobject detection (SSOD). However, the state-of-the-art SSOD methods all rely onpseudo-labels with high confidence, which ignore valuable pseudo-labels withlower confidence. Additionally, the insufficient excavation for unlabeled dataresults in an excessively low recall rate thus hurting the network training. Inthis paper, we propose a novel Low-confidence Samples Mining (LSM) method toutilize low-confidence pseudo-labels efficiently. Specifically, we develop anadditional pseudo information mining (PIM) branch on account of low-resolutionfeature maps to extract reliable large-area instances, the IoUs of which arehigher than small-area ones. Owing to the complementary predictions between PIMand the main branch, we further design self-distillation (SD) to compensate forboth in a mutually-learning manner. Meanwhile, the extensibility of the aboveapproaches enables our LSM to apply to Faster-RCNN and Deformable-DETRrespectively. On the MS-COCO benchmark, our method achieves 3.54% mAPimprovement over state-of-the-art methods under 5% labeling ratios.</description><author>Guandu Liu, Fangyuan Zhang, Tianxiang Pan, Bin Wang</author><pubDate>Wed, 28 Jun 2023 14:29:06 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.16201v1</guid></item><item><title>IRGen: Generative Modeling for Image Retrieval</title><link>http://arxiv.org/abs/2303.10126v3</link><description>While generative modeling has been ubiquitous in natural language processingand computer vision, its application to image retrieval remains unexplored. Inthis paper, we recast image retrieval as a form of generative modeling byemploying a sequence-to-sequence model, contributing to the current unifiedtheme. Our framework, IRGen, is a unified model that enables end-to-enddifferentiable search, thus achieving superior performance thanks to directoptimization. While developing IRGen we tackle the key technical challenge ofconverting an image into quite a short sequence of semantic units in order toenable efficient and effective retrieval. Empirical experiments demonstratethat our model yields significant improvement over three commonly usedbenchmarks, for example, 22.9\% higher than the best baseline method inprecision@10 on In-shop dataset with comparable recall@10 score.</description><author>Yidan Zhang, Ting Zhang, Dong Chen, Yujing Wang, Qi Chen, Xing Xie, Hao Sun, Weiwei Deng, Qi Zhang, Fan Yang, Mao Yang, Qingmin Liao, Baining Guo</author><pubDate>Wed, 28 Jun 2023 14:28:06 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2303.10126v3</guid></item><item><title>Multi-IMU with Online Self-Consistency for Freehand 3D Ultrasound Reconstruction</title><link>http://arxiv.org/abs/2306.16197v1</link><description>Ultrasound (US) imaging is a popular tool in clinical diagnosis, offeringsafety, repeatability, and real-time capabilities. Freehand 3D US is atechnique that provides a deeper understanding of scanned regions withoutincreasing complexity. However, estimating elevation displacement andaccumulation error remains challenging, making it difficult to infer therelative position using images alone. The addition of external lightweightsensors has been proposed to enhance reconstruction performance without addingcomplexity, which has been shown to be beneficial. We propose a novel onlineself-consistency network (OSCNet) using multiple inertial measurement units(IMUs) to improve reconstruction performance. OSCNet utilizes a modal-levelself-supervised strategy to fuse multiple IMU information and reducedifferences between reconstruction results obtained from each IMU data.Additionally, a sequence-level self-consistency strategy is proposed to improvethe hierarchical consistency of prediction results among the scanning sequenceand its sub-sequences. Experiments on large-scale arm and carotid datasets withmultiple scanning tactics demonstrate that our OSCNet outperforms previousmethods, achieving state-of-the-art reconstruction performance.</description><author>Mingyuan Luo, Xin Yang, Zhongnuo Yan, Yuanji Zhang, Junyu Li, Jiongquan Chen, Xindi Hu, Jikuan Qian, Jun Cheng, Dong Ni</author><pubDate>Wed, 28 Jun 2023 14:23:33 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.16197v1</guid></item><item><title>Enhancing Dialogue Generation via Dynamic Graph Knowledge Aggregation</title><link>http://arxiv.org/abs/2306.16195v1</link><description>Incorporating external graph knowledge into neural chatbot models has beenproven effective for enhancing dialogue generation. However, in conventionalgraph neural networks (GNNs), message passing on a graph is independent fromtext, resulting in the graph representation hidden space differing from that ofthe text. This training regime of existing models therefore leads to a semanticgap between graph knowledge and text. In this study, we propose a novelframework for knowledge graph enhanced dialogue generation. We dynamicallyconstruct a multi-hop knowledge graph with pseudo nodes to involve the languagemodel in feature aggregation within the graph at all steps. To avoid thesemantic biases caused by learning on vanilla subgraphs, the proposed frameworkapplies hierarchical graph attention to aggregate graph features on pseudonodes and then attains a global feature. Therefore, the framework can betterutilise the heterogeneous features from both the post and external graphknowledge. Extensive experiments demonstrate that our framework outperformsstate-of-the-art (SOTA) baselines on dialogue generation. Further analysis alsoshows that our representation learning framework can fill the semantic gap bycoagulating representations of both text and graph knowledge. Moreover, thelanguage model also learns how to better select knowledge triples for a moreinformative response via exploiting subgraph patterns within our featureaggregation process. Our code and resources are available athttps://github.com/tangg555/SaBART.</description><author>Chen Tang, Hongbo Zhang, Tyler Loakman, Chenghua Lin, Frank Guerin</author><pubDate>Wed, 28 Jun 2023 14:21:00 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.16195v1</guid></item><item><title>Geometric Ultrasound Localization Microscopy</title><link>http://arxiv.org/abs/2306.15548v2</link><description>Contrast-Enhanced Ultra-Sound (CEUS) has become a viable method fornon-invasive, dynamic visualization in medical diagnostics, yet UltrasoundLocalization Microscopy (ULM) has enabled a revolutionary breakthrough byoffering ten times higher resolution. To date, Delay-And-Sum (DAS) beamformersare used to render ULM frames, ultimately determining the image resolutioncapability. To take full advantage of ULM, this study questions whetherbeamforming is the most effective processing step for ULM, suggesting analternative approach that relies solely on Time-Difference-of-Arrival (TDoA)information. To this end, a novel geometric framework for micro bubblelocalization via ellipse intersections is proposed to overcome existingbeamforming limitations. We present a benchmark comparison based on a publicdataset for which our geometric ULM outperforms existing baseline methods interms of accuracy and reliability while only utilizing a portion of theavailable transducer data.</description><author>Christopher Hahne, Raphael Sznitman</author><pubDate>Wed, 28 Jun 2023 14:14:31 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.15548v2</guid></item><item><title>Effective Transfer of Pretrained Large Visual Model for Fabric Defect Segmentation via Specifc Knowledge Injection</title><link>http://arxiv.org/abs/2306.16186v1</link><description>Fabric defect segmentation is integral to textile quality control. Despitethis, the scarcity of high-quality annotated data and the diversity of fabricdefects present significant challenges to the application of deep learning inthis field. These factors limit the generalization and segmentation performanceof existing models, impeding their ability to handle the complexity of diversefabric types and defects. To overcome these obstacles, this study introduces aninnovative method to infuse specialized knowledge of fabric defects into theSegment Anything Model (SAM), a large-scale visual model. By introducing andtraining a unique set of fabric defect-related parameters, this approachseamlessly integrates domain-specific knowledge into SAM without the need forextensive modifications to the pre-existing model parameters. The revamped SAMmodel leverages generalized image understanding learned from large-scalenatural image datasets while incorporating fabric defect-specific knowledge,ensuring its proficiency in fabric defect segmentation tasks. The experimentalresults reveal a significant improvement in the model's segmentationperformance, attributable to this novel amalgamation of generic andfabric-specific knowledge. When benchmarking against popular existingsegmentation models across three datasets, our proposed model demonstrates asubstantial leap in performance. Its impressive results in cross-datasetcomparisons and few-shot learning experiments further demonstrate its potentialfor practical applications in textile quality control.</description><author>Zhewei Chen, Wai Keung Wong, Zuofeng Zhong, Jinpiao Liao, Ying Qu</author><pubDate>Wed, 28 Jun 2023 14:08:08 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.16186v1</guid></item><item><title>Learning to Pan-sharpening with Memories of Spatial Details</title><link>http://arxiv.org/abs/2306.16181v1</link><description>Pan-sharpening, as one of the most commonly used techniques in remote sensingsystems, aims to inject spatial details from panchromatic images intomulti-spectral images to obtain high-resolution MS images. Since deep learninghas received widespread attention because of its powerful fitting ability andefficient feature extraction, a variety of pan-sharpening methods have beenproposed to achieve remarkable performance. However, current pan-sharpeningmethods usually require the paired PAN and MS images as the input, which limitstheir usage in some scenarios. To address this issue, in this paper, we observethat the spatial details from PAN images are mainly high-frequency cues, i.e.,the edges reflect the contour of input PAN images. This motivates us to developa PAN-agnostic representation to store some base edges, so as to compose thecontour for the corresponding PAN image via them. As a result, we can performthe pan-sharpening task with only the MS image when inference. To this end, amemory-based network is adapted to extract and memorize the spatial detailsduring the training phase and is used to replace the process of obtainingspatial information from PAN images when inference, which is calledMemory-based Spatial Details Network (MSDN). We finally integrate the proposedMSDN module into the existing DL-based pan-sharpening methods to achieve anend-to-end pan-sharpening network. With extensive experiments on the Gaofen1and WorldView-4 satellites, we verify that our method constructs good spatialdetails without PAN images and achieves the best performance. The code isavailable athttps://github.com/Zhao-Tian-yi/Learning-to-Pan-sharpening-with-Memories-of-Spatial-Details.git.</description><author>Maoxun Yuan, Tianyi Zhao, Bo Li, Xingxing Wei</author><pubDate>Wed, 28 Jun 2023 14:03:43 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.16181v1</guid></item><item><title>Towards fully covariant machine learning</title><link>http://arxiv.org/abs/2301.13724v2</link><description>Any representation of data involves arbitrary investigator choices. Becausethose choices are external to the data-generating process, each choice leads toan exact symmetry, corresponding to the group of transformations that takes onepossible representation to another. These are the passive symmetries; theyinclude coordinate freedom, gauge symmetry, and units covariance, all of whichhave led to important results in physics. In machine learning, the most visiblepassive symmetry is the relabeling or permutation symmetry of graphs. Our goalis to understand the implications for machine learning of the many passivesymmetries in play. We discuss dos and don'ts for machine learning practice ifpassive symmetries are to be respected. We discuss links to causal modeling,and argue that the implementation of passive symmetries is particularlyvaluable when the goal of the learning problem is to generalize out of sample.This paper is conceptual: It translates among the languages of physics,mathematics, and machine-learning. We believe that consideration andimplementation of passive symmetries might help machine learning in the sameways that it transformed physics in the twentieth century.</description><author>Soledad Villar, David W. Hogg, Weichi Yao, George A. Kevrekidis, Bernhard Schölkopf</author><pubDate>Wed, 28 Jun 2023 14:02:31 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2301.13724v2</guid></item><item><title>Pseudo-Bag Mixup Augmentation for Multiple Instance Learning Based Whole Slide Image Classification</title><link>http://arxiv.org/abs/2306.16180v1</link><description>Given the special situation of modeling gigapixel images, multiple instancelearning (MIL) has become one of the most important frameworks for Whole SlideImage (WSI) classification. In current practice, most MIL networks often facetwo unavoidable problems in training: i) insufficient WSI data, and ii) thedata memorization nature inherent in neural networks. These problems may hinderMIL models from adequate and efficient training, suppressing the continuousperformance promotion of classification models on WSIs. Inspired by the basicidea of Mixup, this paper proposes a Pseudo-bag Mixup (PseMix) dataaugmentation scheme to improve the training of MIL models. This schemegeneralizes the Mixup strategy for general images to special WSIs viapseudo-bags so as to be applied in MIL-based WSI classification. Cooperated bypseudo-bags, our PseMix fulfills the critical size alignment and semanticalignment in Mixup strategy. Moreover, it is designed as an efficient anddecoupled method adaptive to MIL, neither involving time-consuming operationsnor relying on MIL model predictions. Comparative experiments and ablationstudies are specially designed to evaluate the effectiveness and advantages ofour PseMix. Test results show that PseMix could often improve the performanceof MIL networks in WSI classification. Besides, it could also boost thegeneralization capacity of MIL models, and promote their robustness to patchocclusion and noisy labels. Our source code is available athttps://github.com/liupei101/PseMix.</description><author>Pei Liu, Luping Ji, Xinyu Zhang, Feng Ye</author><pubDate>Wed, 28 Jun 2023 14:02:30 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.16180v1</guid></item><item><title>Defining data science: a new field of inquiry</title><link>http://arxiv.org/abs/2306.16177v1</link><description>Data science is not a science. It is a research paradigm. Its power, scope,and scale will surpass science, our most powerful research paradigm, to enableknowledge discovery and change our world. We have yet to understand and defineit, vital to realizing its potential and managing its risks. Modern datascience is in its infancy. Emerging slowly since 1962 and rapidly since 2000,it is a fundamentally new field of inquiry, one of the most active, powerful,and rapidly evolving 21st century innovations. Due to its value, power, andapplicability, it is emerging in 40+ disciplines, hundreds of research areas,and thousands of applications. Millions of data science publications containmyriad definitions of data science and data science problem solving. Due to itsinfancy, many definitions are independent, application-specific, mutuallyincomplete, redundant, or inconsistent, hence so is data science. This researchaddresses this data science multiple definitions challenge by proposing thedevelopment of coherent, unified definition based on a data science referenceframework using a data science journal for the data science community toachieve such a definition. This paper provides candidate definitions foressential data science artifacts that are required to discuss such adefinition. They are based on the classical research paradigm conceptconsisting of a philosophy of data science, the data science problem solvingparadigm, and the six component data science reference framework (axiology,ontology, epistemology, methodology, methods, technology) that is a frequentlycalled for unifying framework with which to define, unify, and evolve datascience. It presents challenges for defining data science, solution approaches,i.e., means for defining data science, and their requirements and benefits asthe basis of a comprehensive solution.</description><author>Michael L Brodie</author><pubDate>Wed, 28 Jun 2023 13:58:42 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.16177v1</guid></item><item><title>TrickVOS: A Bag of Tricks for Video Object Segmentation</title><link>http://arxiv.org/abs/2306.15377v2</link><description>Space-time memory (STM) network methods have been dominant in semi-supervisedvideo object segmentation (SVOS) due to their remarkable performance. In thiswork, we identify three key aspects where we can improve such methods; i)supervisory signal, ii) pretraining and iii) spatial awareness. We then proposeTrickVOS; a generic, method-agnostic bag of tricks addressing each aspect withi) a structure-aware hybrid loss, ii) a simple decoder pretraining regime andiii) a cheap tracker that imposes spatial constraints in model predictions.Finally, we propose a lightweight network and show that when trained withTrickVOS, it achieves competitive results to state-of-the-art methods on DAVISand YouTube benchmarks, while being one of the first STM-based SVOS methodsthat can run in real-time on a mobile device.</description><author>Evangelos Skartados, Konstantinos Georgiadis, Mehmet Kerim Yucel, Koskinas Ioannis, Armando Domi, Anastasios Drosou, Bruno Manganelli, Albert Saa-Garriga</author><pubDate>Wed, 28 Jun 2023 13:57:11 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.15377v2</guid></item><item><title>SkillNet-X: A Multilingual Multitask Model with Sparsely Activated Skills</title><link>http://arxiv.org/abs/2306.16176v1</link><description>Traditional multitask learning methods basically can only exploit commonknowledge in task- or language-wise, which lose either cross-language orcross-task knowledge. This paper proposes a general multilingual multitaskmodel, named SkillNet-X, which enables a single model to tackle many differenttasks from different languages. To this end, we define severallanguage-specific skills and task-specific skills, each of which corresponds toa skill module. SkillNet-X sparsely activates parts of the skill modules whichare relevant either to the target task or the target language. Acting asknowledge transit hubs, skill modules are capable of absorbing task-relatedknowledge and language-related knowledge consecutively. Based on Transformer,we modify the multi-head attention layer and the feed forward network layer toaccommodate skill modules. We evaluate SkillNet-X on eleven natural languageunderstanding datasets in four languages. Results show that SkillNet-X performsbetter than task-specific baselines and two multitask learning baselines (i.e.,dense joint model and Mixture-of-Experts model). Furthermore, skillpre-training further improves the performance of SkillNet-X on almost alldatasets. To investigate the generalization of our model, we conductexperiments on two new tasks and find that SkillNet-X significantly outperformsbaselines.</description><author>Zhangyin Feng, Yong Dai, Fan Zhang, Duyu Tang, Xiaocheng Feng, Shuangzhi Wu, Bing Qin, Yunbo Cao, Shuming Shi</author><pubDate>Wed, 28 Jun 2023 13:53:30 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.16176v1</guid></item><item><title>$\mathbf{C}^2$Former: Calibrated and Complementary Transformer for RGB-Infrared Object Detection</title><link>http://arxiv.org/abs/2306.16175v1</link><description>Object detection on visible (RGB) and infrared (IR) images, as an emergingsolution to facilitate robust detection for around-the-clock applications, hasreceived extensive attention in recent years. With the help of IR images,object detectors have been more reliable and robust in practical applicationsby using RGB-IR combined information. However, existing methods still sufferfrom modality miscalibration and fusion imprecision problems. Since transformerhas the powerful capability to model the pairwise correlations betweendifferent features, in this paper, we propose a novel Calibrated andComplementary Transformer called $\mathrm{C}^2$Former to address these twoproblems simultaneously. In $\mathrm{C}^2$Former, we design an Inter-modalityCross-Attention (ICA) module to obtain the calibrated and complementaryfeatures by learning the cross-attention relationship between the RGB and IRmodality. To reduce the computational cost caused by computing the globalattention in ICA, an Adaptive Feature Sampling (AFS) module is introduced todecrease the dimension of feature maps. Because $\mathrm{C}^2$Former performsin the feature domain, it can be embedded into existed RGB-IR object detectorsvia the backbone network. Thus, one single-stage and one two-stage objectdetector both incorporating our $\mathrm{C}^2$Former are constructed toevaluate its effectiveness and versatility. With extensive experiments on theDroneVehicle and KAIST RGB-IR datasets, we verify that our method can fullyutilize the RGB-IR complementary information and achieve robust detectionresults. The code is available athttps://github.com/yuanmaoxun/Calibrated-and-Complementary-Transformer-for-RGB-Infrared-Object-Detection.git.</description><author>Maoxun Yuan, Xingxing Wei</author><pubDate>Wed, 28 Jun 2023 13:52:48 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.16175v1</guid></item><item><title>Understanding Graph Neural Networks with Asymmetric Geometric Scattering Transforms</title><link>http://arxiv.org/abs/1911.06253v4</link><description>The scattering transform is a multilayered wavelet-based deep learningarchitecture that acts as a model of convolutional neural networks. Recently,several works have introduced generalizations of the scattering transform fornon-Euclidean settings such as graphs. Our work builds upon these constructionsby introducing windowed and non-windowed geometric scattering transforms forgraphs based upon a very general class of asymmetric wavelets. We show thatthese asymmetric graph scattering transforms have many of the same theoreticalguarantees as their symmetric counterparts. As a result, the proposedconstruction unifies and extends known theoretical results for many of theexisting graph scattering architectures. In doing so, this work helps bridgethe gap between geometric scattering and other graph neural networks byintroducing a large family of networks with provable stability and invarianceguarantees. These results lay the groundwork for future deep learningarchitectures for graph-structured data that have learned filters and alsoprovably have desirable theoretical properties.</description><author>Michael Perlmutter, Alexander Tong, Feng Gao, Guy Wolf, Matthew Hirn</author><pubDate>Wed, 28 Jun 2023 13:50:59 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/1911.06253v4</guid></item><item><title>A systematic literature review on source code similarity measurement and clone detection: techniques, applications, and challenges</title><link>http://arxiv.org/abs/2306.16171v1</link><description>Measuring and evaluating source code similarity is a fundamental softwareengineering activity that embraces a broad range of applications, including butnot limited to code recommendation, duplicate code, plagiarism, malware, andsmell detection. This paper proposes a systematic literature review andmeta-analysis on code similarity measurement and evaluation techniques to shedlight on the existing approaches and their characteristics in differentapplications. We initially found over 10000 articles by querying four digitallibraries and ended up with 136 primary studies in the field. The studies wereclassified according to their methodology, programming languages, datasets,tools, and applications. A deep investigation reveals 80 software tools,working with eight different techniques on five application domains. Nearly 49%of the tools work on Java programs and 37% support C and C++, while there is nosupport for many programming languages. A noteworthy point was the existence of12 datasets related to source code similarity measurement and duplicate codes,of which only eight datasets were publicly accessible. The lack of reliabledatasets, empirical evaluations, hybrid methods, and focuses on multi-paradigmlanguages are the main challenges in the field. Emerging applications of codesimilarity measurement concentrate on the development phase in addition to themaintenance.</description><author>Morteza Zakeri-Nasrabadi, Saeed Parsa, Mohammad Ramezani, Chanchal Roy, Masoud Ekhtiarzadeh</author><pubDate>Wed, 28 Jun 2023 13:49:22 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.16171v1</guid></item><item><title>Mitigating the Accuracy-Robustness Trade-off via Multi-Teacher Adversarial Distillation</title><link>http://arxiv.org/abs/2306.16170v1</link><description>Adversarial training is a practical approach for improving the robustness ofdeep neural networks against adversarial attacks. Although bringing reliablerobustness, the performance toward clean examples is negatively affected afteradversarial training, which means a trade-off exists between accuracy androbustness. Recently, some studies have tried to use knowledge distillationmethods in adversarial training, achieving competitive performance in improvingthe robustness but the accuracy for clean samples is still limited. In thispaper, to mitigate the accuracy-robustness trade-off, we introduce theMulti-Teacher Adversarial Robustness Distillation (MTARD) to guide the model'sadversarial training process by applying a strong clean teacher and a strongrobust teacher to handle the clean examples and adversarial examples,respectively. During the optimization process, to ensure that differentteachers show similar knowledge scales, we design the Entropy-Based Balancealgorithm to adjust the teacher's temperature and keep the teachers'information entropy consistent. Besides, to ensure that the student has arelatively consistent learning speed from multiple teachers, we propose theNormalization Loss Balance algorithm to adjust the learning weights ofdifferent types of knowledge. A series of experiments conducted on publicdatasets demonstrate that MTARD outperforms the state-of-the-art adversarialtraining and distillation methods against various adversarial attacks.</description><author>Shiji Zhao, Xizhe Wang, Xingxing Wei</author><pubDate>Wed, 28 Jun 2023 13:47:01 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.16170v1</guid></item><item><title>Communication Resources Constrained Hierarchical Federated Learning for End-to-End Autonomous Driving</title><link>http://arxiv.org/abs/2306.16169v1</link><description>While federated learning (FL) improves the generalization of end-to-endautonomous driving by model aggregation, the conventional single-hop FL (SFL)suffers from slow convergence rate due to long-range communications amongvehicles and cloud server. Hierarchical federated learning (HFL) overcomes suchdrawbacks via introduction of mid-point edge servers. However, theorchestration between constrained communication resources and HFL performancebecomes an urgent problem. This paper proposes an optimization-basedCommunication Resource Constrained Hierarchical Federated Learning (CRCHFL)framework to minimize the generalization error of the autonomous driving modelusing hybrid data and model aggregation. The effectiveness of the proposedCRCHFL is evaluated in the Car Learning to Act (CARLA) simulation platform.Results show that the proposed CRCHFL both accelerates the convergence rate andenhances the generalization of federated learning autonomous driving model.Moreover, under the same communication resource budget, it outperforms the HFLby 10.33% and the SFL by 12.44%.</description><author>Wei-Bin Kou, Shuai Wang, Guangxu Zhu, Bin Luo, Yingxian Chen, Derrick Wing Kwan Ng, Yik-Chung Wu</author><pubDate>Wed, 28 Jun 2023 13:44:59 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.16169v1</guid></item><item><title>Recent Advances in Optimal Transport for Machine Learning</title><link>http://arxiv.org/abs/2306.16156v1</link><description>Recently, Optimal Transport has been proposed as a probabilistic framework inMachine Learning for comparing and manipulating probability distributions. Thisis rooted in its rich history and theory, and has offered new solutions todifferent problems in machine learning, such as generative modeling andtransfer learning. In this survey we explore contributions of Optimal Transportfor Machine Learning over the period 2012 -- 2022, focusing on four sub-fieldsof Machine Learning: supervised, unsupervised, transfer and reinforcementlearning. We further highlight the recent development in computational OptimalTransport, and its interplay with Machine Learning practice.</description><author>Eduardo Fernandes Montesuma, Fred Ngolè Mboula, Antoine Souloumiac</author><pubDate>Wed, 28 Jun 2023 13:37:23 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.16156v1</guid></item><item><title>Just a Glimpse: Rethinking Temporal Information for Video Continual Learning</title><link>http://arxiv.org/abs/2305.18418v2</link><description>Class-incremental learning is one of the most important settings for thestudy of Continual Learning, as it closely resembles real-world applicationscenarios. With constrained memory sizes, catastrophic forgetting arises as thenumber of classes/tasks increases. Studying continual learning in the videodomain poses even more challenges, as video data contains a large number offrames, which places a higher burden on the replay memory. The current commonpractice is to sub-sample frames from the video stream and store them in thereplay memory. In this paper, we propose SMILE a novel replay mechanism foreffective video continual learning based on individual/single frames. Throughextensive experimentation, we show that under extreme memory constraints, videodiversity plays a more significant role than temporal information. Therefore,our method focuses on learning from a small number of frames that represent alarge number of unique videos. On three representative video datasets,Kinetics, UCF101, and ActivityNet, the proposed method achievesstate-of-the-art performance, outperforming the previous state-of-the-art by upto 21.49%.</description><author>Lama Alssum, Juan Leon Alcazar, Merey Ramazanova, Chen Zhao, Bernard Ghanem</author><pubDate>Wed, 28 Jun 2023 13:34:22 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.18418v2</guid></item><item><title>Towards KAB2S: Learning Key Knowledge from Single-Objective Problems to Multi-Objective Problem</title><link>http://arxiv.org/abs/2206.12906v2</link><description>As "a new frontier in evolutionary computation research", evolutionarytransfer optimization(ETO) will overcome the traditional paradigm of zero reuseof related experience and knowledge from solved past problems in researches ofevolutionary computation. In scheduling applications via ETO, a quite appealingand highly competitive framework "meeting" between them could be formed forboth intelligent scheduling and green scheduling, especially for internationalpledge of "carbon neutrality" from China. To the best of our knowledge, ourpaper on scheduling here, serves as the 1st work of a class of ETO frameworkswhen multiobjective optimization problem "meets" single-objective optimizationproblems in discrete case (not multitasking optimization). More specifically,key knowledge conveyed for industrial applications, like positional buildingblocks with genetic algorithm based settings, could be used via the new coretransfer mechanism and learning techniques for permutation flow shop schedulingproblem(PFSP). Extensive studies on well-studied benchmarks validate firmeffectiveness and great universality of our proposed ETO-PFSP frameworkempirically. Our investigations (1) enrich the ETO frameworks, (2) contributeto the classical and fundamental theory of building block for geneticalgorithms and memetic algorithms, and (3) head towards the paradigm shift ofevolutionary scheduling via learning by proposal and practice of paradigm of"knowledge and building-block based scheduling" (KAB2S) for "industrialintelligence" in China.</description><author>Xu Wendi, Wang Xianpeng, Guo Qingxin, Song Xiangman, Zhao Ren, Zhao Guodong, Yang Yang, Xu Te, He Dakuo</author><pubDate>Wed, 28 Jun 2023 13:25:04 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2206.12906v2</guid></item><item><title>Generative User-Experience Research for Developing Domain-specific Natural Language Processing Applications</title><link>http://arxiv.org/abs/2306.16143v1</link><description>User experience (UX) is a part of human-computer interaction (HCI) researchand focuses on increasing intuitiveness, transparency, simplicity, and trustfor system users. Most of the UX research for machine learning (ML) or naturallanguage processing (NLP) focuses on a data-driven methodology, i.e., it failsto focus on users' requirements, and engages domain users mainly for usabilityevaluation. Moreover, more typical UX methods tailor the systems towards userusability, unlike learning about the user needs first. The paper proposes amethodology for integrating generative UX research into developing domain NLPapplications. Generative UX research employs domain users at the initial stagesof prototype development, i.e., ideation and concept evaluation, and the laststage for evaluating the change in user value. In the case study, we report thefull-cycle prototype development of a domain-specific semantic search for dailyoperations in the process industry. Our case study shows that involving domainexperts increases their interest and trust in the final NLP application.Moreover, we show that synergetic UX+NLP research efficiently considers data-and user-driven opportunities and constraints, which can be crucial for NLPapplications in narrow domains</description><author>Anastasia Zhukova, Lukas von Sperl, Christian E. Matt, Bela Gipp</author><pubDate>Wed, 28 Jun 2023 13:17:45 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.16143v1</guid></item><item><title>Neural directional distance field object representation for uni-directional path-traced rendering</title><link>http://arxiv.org/abs/2306.16142v1</link><description>Faster rendering of synthetic images is a core problem in the field ofcomputer graphics. Rendering algorithms, such as path-tracing is dependent onparameters like size of the image, number of light bounces, number of samplesper pixel, all of which, are fixed if one wants to obtain a image of a desiredquality. It is also dependent on the size and complexity of the scene beingrendered. One of the largest bottleneck in rendering, particularly when thescene is very large, is querying for objects in the path of a given ray in thescene. By changing the data type that represents the objects in the scene, onemay reduce render time, however, a different representation of a scene requiresthe modification of the rendering algorithm. In this paper, (a) we introducedirected distance field, as a functional representation of a object; (b) howthe directed distance functions, when stored as a neural network, be optimizedand; (c) how such an object can be rendered with a modified path-tracingalgorithm.</description><author>Annada Prasad Behera, Subhankar Mishra</author><pubDate>Wed, 28 Jun 2023 13:16:38 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.16142v1</guid></item><item><title>Learning with Noisy Labels by Adaptive Gradient-Based Outlier Removal</title><link>http://arxiv.org/abs/2306.04502v2</link><description>An accurate and substantial dataset is essential for training a reliable andwell-performing model. However, even manually annotated datasets contain labelerrors, not to mention automatically labeled ones. Previous methods for labeldenoising have primarily focused on detecting outliers and their permanentremoval - a process that is likely to over- or underfilter the dataset. In thiswork, we propose AGRA: a new method for learning with noisy labels by usingAdaptive GRAdient-based outlier removal. Instead of cleaning the dataset priorto model training, the dataset is dynamically adjusted during the trainingprocess. By comparing the aggregated gradient of a batch of samples and anindividual example gradient, our method dynamically decides whether acorresponding example is helpful for the model at this point or iscounter-productive and should be left out for the current update. Extensiveevaluation on several datasets demonstrates AGRA's effectiveness, while acomprehensive results analysis supports our initial hypothesis: permanent hardoutlier removal is not always what model benefits the most from.</description><author>Anastasiia Sedova, Lena Zellinger, Benjamin Roth</author><pubDate>Wed, 28 Jun 2023 13:14:29 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.04502v2</guid></item><item><title>On the link between generative semi-supervised learning and generative open-set recognition</title><link>http://arxiv.org/abs/2303.11702v3</link><description>This study investigates the relationship between semi-supervised learning(SSL) and open-set recognition (OSR) under the context of generativeadversarial networks (GANs). Although no previous study has formally linked SSLand OSR, their respective methods share striking similarities. Specifically,SSL-GANs and OSR-GANs require their generators to produce samples in thecomplementary space, which are then used to regularise their respectiveclassifier networks. In turn, classifiers trained under SSL and OSR generalisethe open space by tightening classification boundaries around the labelledcategories. In other words, a classifier trained using an SSL-GAN intrinsicallyachieves OSR and vice-versa. To prove this SSL-OSR link, we theoretically andexperimentally compare the state-of-the-art SSL-GAN with the state-of-the-artOSR-GAN. Our results find that all SSL-GANs and OSR-GANs work towards the samegoal, and that the SSL-optimised Margin-GANs set the new state-of-the-art forthe combined task of SSL-OSR. Future studies could further explore thetheoretical similarities between SSL-GANs and OSR-GANs, as well as extendSSL-OSR to other learning policies.</description><author>Emile Reyn Engelbrecht, Johan du Preez</author><pubDate>Wed, 28 Jun 2023 13:03:48 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2303.11702v3</guid></item><item><title>Training Deep Surrogate Models with Large Scale Online Learning</title><link>http://arxiv.org/abs/2306.16133v1</link><description>The spatiotemporal resolution of Partial Differential Equations (PDEs) playsimportant roles in the mathematical description of the world's physicalphenomena. In general, scientists and engineers solve PDEs numerically by theuse of computationally demanding solvers. Recently, deep learning algorithmshave emerged as a viable alternative for obtaining fast solutions for PDEs.Models are usually trained on synthetic data generated by solvers, stored ondisk and read back for training. This paper advocates that relying on atraditional static dataset to train these models does not allow the fullbenefit of the solver to be used as a data generator. It proposes an opensource online training framework for deep surrogate models. The frameworkimplements several levels of parallelism focused on simultaneously generatingnumerical simulations and training deep neural networks. This approachsuppresses the I/O and storage bottleneck associated with disk-loaded datasets,and opens the way to training on significantly larger datasets. Experimentscompare the offline and online training of four surrogate models, includingstate-of-the-art architectures. Results indicate that exposing deep surrogatemodels to more dataset diversity, up to hundreds of GB, can increase modelgeneralization capabilities. Fully connected neural networks, Fourier NeuralOperator (FNO), and Message Passing PDE Solver prediction accuracy is improvedby 68%, 16% and 7%, respectively.</description><author>Lucas Meyer, Marc Schouler, Robert Alexander Caulk, Alejandro Ribés, Bruno Raffin</author><pubDate>Wed, 28 Jun 2023 13:02:27 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.16133v1</guid></item><item><title>INSTA-BEEER: Explicit Error Estimation and Refinement for Fast and Accurate Unseen Object Instance Segmentation</title><link>http://arxiv.org/abs/2306.16132v1</link><description>Efficient and accurate segmentation of unseen objects is crucial for roboticmanipulation. However, it remains challenging due to over- orunder-segmentation. Although existing refinement methods can enhance thesegmentation quality, they fix only minor boundary errors or are notsufficiently fast. In this work, we propose INSTAnce Boundary Explicit ErrorEstimation and Refinement (INSTA-BEEER), a novel refinement model that allowsfor adding and deleting instances and sharpening boundaries. Leveraging anerror-estimation-then-refinement scheme, the model first estimates thepixel-wise boundary explicit errors: true positive, true negative, falsepositive, and false negative pixels of the instance boundary in the initialsegmentation. It then refines the initial segmentation using these errorestimates as guidance. Experiments show that the proposed model significantlyenhances segmentation, achieving state-of-the-art performance. Furthermore,with a fast runtime (less than 0.1 s), the model consistently improvesperformance across various initial segmentation methods, making it highlysuitable for practical robotic applications.</description><author>Seunghyeok Back, Sangbeom Lee, Kangmin Kim, Joosoon Lee, Sungho Shin, Jaemo Maeng, Kyoobin Lee</author><pubDate>Wed, 28 Jun 2023 13:01:51 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.16132v1</guid></item><item><title>Distributional Modeling for Location-Aware Adversarial Patches</title><link>http://arxiv.org/abs/2306.16131v1</link><description>Adversarial patch is one of the important forms of performing adversarialattacks in the physical world. To improve the naturalness and aggressiveness ofexisting adversarial patches, location-aware patches are proposed, where thepatch's location on the target object is integrated into the optimizationprocess to perform attacks. Although it is effective, efficiently finding theoptimal location for placing the patches is challenging, especially under theblack-box attack settings. In this paper, we propose the Distribution-OptimizedAdversarial Patch (DOPatch), a novel method that optimizes a multimodaldistribution of adversarial locations instead of individual ones. DOPatch hasseveral benefits: Firstly, we find that the locations' distributions acrossdifferent models are pretty similar, and thus we can achieve efficientquery-based attacks to unseen models using a distributional prior optimized ona surrogate model. Secondly, DOPatch can generate diverse adversarial samplesby characterizing the distribution of adversarial locations. Thus we canimprove the model's robustness to location-aware patches via carefully designedDistributional-Modeling Adversarial Training (DOP-DMAT). We evaluate DOPatch onvarious face recognition and image recognition tasks and demonstrate itssuperiority and efficiency over existing methods. We also conduct extensiveablation studies and analyses to validate the effectiveness of our method andprovide insights into the distribution of adversarial locations.</description><author>Xingxing Wei, Shouwei Ruan, Yinpeng Dong, Hang Su</author><pubDate>Wed, 28 Jun 2023 13:01:50 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.16131v1</guid></item><item><title>Unified machine learning: Classification with simultaneous observed and unobserved novelty detection</title><link>http://arxiv.org/abs/2002.01368v7</link><description>A unified approach of Positive and Unlabelled (PU)-learning, Semi-SupervisedLearning (SSL), and Open-Set Recognition (OSR) would significantly enhance thedevelopment of cost-efficient application-grade classifiers. However, previousattempts have conflated the definitions of \mbox{\textit{observed}} and\mbox{\textit{unobserved}} novel categories. Observed novel categories aredefined in PU-learning as those in unlabelled training data and exist due to anincomplete set of category labels for the training set. In contrast, unobservednovel categories are defined in OSR as those that only exist in the testingdata and represent new and interesting patterns that emerge over time. Tomaintain safe and practical classifier development, models must generalise thedifference between these novel category types. In this letter, we thoroughlyreview the relevant machine learning research fields to propose a new unifiedmachine learning policy called Open-set Learning with Augmented Categories byexploiting Unlabelled data or Open-LACU. Specifically, Open-LACU requiresmodels to accurately classify $K &gt; 1$ number of labelled categories whilesimultaneously detecting and separating observed novel categories into theaugmented background category ($K + 1$) and further detecting and separatingunobserved novel categories into the augmented unknown category ($K + 2$).Open-LACU is the first machine learning policy to generalise observed andunobserved novel categories. The significance of Open-LACU is also highlightedby discussing its application in semantic segmentation of remote sensingimages, object detection within medical radiology images and diseaseidentification through cough sound analysis.</description><author>Emile R. Engelbrecht, Johan A. du Preez</author><pubDate>Wed, 28 Jun 2023 13:00:14 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2002.01368v7</guid></item></channel></rss>