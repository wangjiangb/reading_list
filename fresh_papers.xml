<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/"><channel><title>Arxivfresh papers</title><link></link><description>Arxiv paper</description><language>en-US</language><lastBuildDate>Mon, 08 Jan 2024 06:00:07 GMT</lastBuildDate><generator>rfeed v1.0.0</generator><docs>https://github.com/svpino/rfeed/blob/master/README.md</docs><item><title>Denoising Vision Transformers</title><link>http://arxiv.org/abs/2401.02957v1</link><description>We delve into a nuanced but significant challenge inherent to VisionTransformers (ViTs): feature maps of these models exhibit grid-like artifacts,which detrimentally hurt the performance of ViTs in downstream tasks. Ourinvestigations trace this fundamental issue down to the positional embeddingsat the input stage. To address this, we propose a novel noise model, which isuniversally applicable to all ViTs. Specifically, the noise model dissects ViToutputs into three components: a semantics term free from noise artifacts andtwo artifact-related terms that are conditioned on pixel locations. Such adecomposition is achieved by enforcing cross-view feature consistency withneural fields in a per-image basis. This per-image optimization processextracts artifact-free features from raw ViT outputs, providing clean featuresfor offline applications. Expanding the scope of our solution to support onlinefunctionality, we introduce a learnable denoiser to predict artifact-freefeatures directly from unprocessed ViT outputs, which shows remarkablegeneralization capabilities to novel data without the need for per-imageoptimization. Our two-stage approach, termed Denoising Vision Transformers(DVT), does not require re-training existing pre-trained ViTs and isimmediately applicable to any Transformer-based architecture. We evaluate ourmethod on a variety of representative ViTs (DINO, MAE, DeiT-III, EVA02, CLIP,DINOv2, DINOv2-reg). Extensive evaluations demonstrate that our DVTconsistently and significantly improves existing state-of-the-artgeneral-purpose models in semantic and geometric tasks across multiple datasets(e.g., +3.84 mIoU). We hope our study will encourage a re-evaluation of ViTdesign, especially regarding the naive use of positional embeddings.</description><author>Jiawei Yang, Katie Z Luo, Jiefeng Li, Kilian Q Weinberger, Yonglong Tian, Yue Wang</author><pubDate>Fri, 05 Jan 2024 18:59:52 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.02957v1</guid></item><item><title>MC-ViViT: Multi-branch Classifier-ViViT to detect Mild Cognitive Impairment in older adults using facial videos</title><link>http://arxiv.org/abs/2304.05292v4</link><description>Deep machine learning models including Convolutional Neural Networks (CNN)have been successful in the detection of Mild Cognitive Impairment (MCI) usingmedical images, questionnaires, and videos. This paper proposes a novelMulti-branch Classifier-Video Vision Transformer (MC-ViViT) model todistinguish MCI from those with normal cognition by analyzing facial features.The data comes from the I-CONECT, a behavioral intervention trial aimed atimproving cognitive function by providing frequent video chats. MC-ViViTextracts spatiotemporal features of videos in one branch and augmentsrepresentations by the MC module. The I-CONECT dataset is challenging as thedataset is imbalanced containing Hard-Easy and Positive-Negative samples, whichimpedes the performance of MC-ViViT. We propose a loss function for Hard-Easyand Positive-Negative Samples (HP Loss) by combining Focal loss and AD-CORREloss to address the imbalanced problem. Our experimental results on theI-CONECT dataset show the great potential of MC-ViViT in predicting MCI with ahigh accuracy of 90.63% accuracy on some of the interview videos.</description><author>Jian Sun, Hiroko H. Dodge, Mohammad H. Mahoor</author><pubDate>Fri, 05 Jan 2024 18:59:41 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2304.05292v4</guid></item><item><title>Open-Vocabulary SAM: Segment and Recognize Twenty-thousand Classes Interactively</title><link>http://arxiv.org/abs/2401.02955v1</link><description>The CLIP and Segment Anything Model (SAM) are remarkable vision foundationmodels (VFMs). SAM excels in segmentation tasks across diverse domains, whileCLIP is renowned for its zero-shot recognition capabilities. This paperpresents an in-depth exploration of integrating these two models into a unifiedframework. Specifically, we introduce the Open-Vocabulary SAM, a SAM-inspiredmodel designed for simultaneous interactive segmentation and recognition,leveraging two unique knowledge transfer modules: SAM2CLIP and CLIP2SAM. Theformer adapts SAM's knowledge into the CLIP via distillation and learnabletransformer adapters, while the latter transfers CLIP knowledge into SAM,enhancing its recognition capabilities. Extensive experiments on variousdatasets and detectors show the effectiveness of Open-Vocabulary SAM in bothsegmentation and recognition tasks, significantly outperforming the naivebaselines of simply combining SAM and CLIP. Furthermore, aided with imageclassification data training, our method can segment and recognizeapproximately 22,000 classes.</description><author>Haobo Yuan, Xiangtai Li, Chong Zhou, Yining Li, Kai Chen, Chen Change Loy</author><pubDate>Fri, 05 Jan 2024 18:59:22 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.02955v1</guid></item><item><title>DeepSeek LLM: Scaling Open-Source Language Models with Longtermism</title><link>http://arxiv.org/abs/2401.02954v1</link><description>The rapid development of open-source large language models (LLMs) has beentruly remarkable. However, the scaling law described in previous literaturepresents varying conclusions, which casts a dark cloud over scaling LLMs. Wedelve into the study of scaling laws and present our distinctive findings thatfacilitate scaling of large scale models in two commonly used open-sourceconfigurations, 7B and 67B. Guided by the scaling laws, we introduce DeepSeekLLM, a project dedicated to advancing open-source language models with along-term perspective. To support the pre-training phase, we have developed adataset that currently consists of 2 trillion tokens and is continuouslyexpanding. We further conduct supervised fine-tuning (SFT) and DirectPreference Optimization (DPO) on DeepSeek LLM Base models, resulting in thecreation of DeepSeek Chat models. Our evaluation results demonstrate thatDeepSeek LLM 67B surpasses LLaMA-2 70B on various benchmarks, particularly inthe domains of code, mathematics, and reasoning. Furthermore, open-endedevaluations reveal that DeepSeek LLM 67B Chat exhibits superior performancecompared to GPT-3.5.</description><author>DeepSeek-AI, :, Xiao Bi, Deli Chen, Guanting Chen, Shanhuang Chen, Damai Dai, Chengqi Deng, Honghui Ding, Kai Dong, Qiushi Du, Zhe Fu, Huazuo Gao, Kaige Gao, Wenjun Gao, Ruiqi Ge, Kang Guan, Daya Guo, Jianzhong Guo, Guangbo Hao, Zhewen Hao, Ying He, Wenjie Hu, Panpan Huang, Erhang Li, Guowei Li, Jiashi Li, Yao Li, Y. K. Li, Wenfeng Liang, Fangyun Lin, A. X. Liu, Bo Liu, Wen Liu, Xiaodong Liu, Xin Liu, Yiyuan Liu, Haoyu Lu, Shanghao Lu, Fuli Luo, Shirong Ma, Xiaotao Nie, Tian Pei, Yishi Piao, Junjie Qiu, Hui Qu, Tongzheng Ren, Zehui Ren, Chong Ruan, Zhangli Sha, Zhihong Shao, Junxiao Song, Xuecheng Su, Jingxiang Sun, Yaofeng Sun, Minghui Tang, Bingxuan Wang, Peiyi Wang, Shiyu Wang, Yaohui Wang, Yongji Wang, Tong Wu, Y. Wu, Xin Xie, Zhenda Xie, Ziwei Xie, Yiliang Xiong, Hanwei Xu, R. X. Xu, </author><pubDate>Fri, 05 Jan 2024 18:59:13 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.02954v1</guid></item><item><title>TreeLearn: A Comprehensive Deep Learning Method for Segmenting Individual Trees from Ground-Based LiDAR Forest Point Clouds</title><link>http://arxiv.org/abs/2309.08471v2</link><description>Laser-scanned point clouds of forests make it possible to extract valuableinformation for forest management. To consider single trees, a forest pointcloud needs to be segmented into individual tree point clouds. Existingsegmentation methods are usually based on hand-crafted algorithms, such asidentifying trunks and growing trees from them, and face difficulties in denseforests with overlapping tree crowns. In this study, we propose TreeLearn, adeep learning-based approach for tree instance segmentation of forest pointclouds. Unlike previous methods, TreeLearn is trained on already segmentedpoint clouds in a data-driven manner, making it less reliant on predefinedfeatures and algorithms. Furthermore, TreeLearn is implemented as a fullyautomatic pipeline and does not rely on extensive hyperparameter tuning, whichmakes it easy to use. Additionally, we introduce a new manually segmentedbenchmark forest dataset containing 156 full trees, and 79 partial trees, thathave been cleanly segmented by hand. The data is generated by mobile laserscanning and contributes to create a larger and more diverse data basis formodel development and fine-grained instance segmentation evaluation. We trainedTreeLearn on forest point clouds of 6665 trees, labeled using the Lidar360software. An evaluation on the benchmark dataset shows that TreeLearn performsequally well or better than the algorithm used to generate its training data.Furthermore, the method's performance can be vastly improved by fine-tuning onthe cleanly labeled benchmark dataset. The TreeLearn code is available fromhttps://github.com/ecker-lab/TreeLearn. The data as well as trained models canbe found at https://doi.org/10.25625/VPMPID.</description><author>Jonathan Henrich, Jan van Delden, Dominik Seidel, Thomas Kneib, Alexander Ecker</author><pubDate>Fri, 05 Jan 2024 18:57:34 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2309.08471v2</guid></item><item><title>The Tactician's Web of Large-Scale Formal Knowledge</title><link>http://arxiv.org/abs/2401.02950v1</link><description>The Tactician's Web is a platform offering a large web of stronglyinterconnected, machine-checked, formal mathematical knowledge convenientlypackaged for machine learning, analytics, and proof engineering. Built on topof the Coq proof assistant, the platform exports a dataset containing a widevariety of formal theories, presented as a web of definitions, theorems, proofterms, tactics, and proof states. Theories are encoded both as a semantic graph(rendered below) and as human-readable text, each with a unique set ofadvantages and disadvantages. Proving agents may interact with Coq through thesame rich data representation and can be automatically benchmarked on a set oftheorems. Tight integration with Coq provides the unique possibility to makeagents available to proof engineers as practical tools.</description><author>Lasse Blaauwbroek</author><pubDate>Fri, 05 Jan 2024 18:52:35 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.02950v1</guid></item><item><title>Graph2Tac: Learning Hierarchical Representations of Math Concepts in Theorem proving</title><link>http://arxiv.org/abs/2401.02949v1</link><description>Concepts abound in mathematics and its applications. They vary greatlybetween subject areas, and new ones are introduced in each mathematical paperor application. A formal theory builds a hierarchy of definitions, theorems andproofs that reference each other. When an AI agent is proving a new theorem,most of the mathematical concepts and lemmas relevant to that theorem may havenever been seen during training. This is especially true in the Coq proofassistant, which has a diverse library of Coq projects, each with its owndefinitions, lemmas, and even custom tactic procedures used to prove thoselemmas. It is essential for agents to incorporate such new information intotheir knowledge base on the fly. We work towards this goal by utilizing a new,large-scale, graph-based dataset for machine learning in Coq. We leverage afaithful graph-representation of Coq terms that induces a directed graph ofdependencies between definitions to create a novel graph neural network,Graph2Tac (G2T), that takes into account not only the current goal, but alsothe entire hierarchy of definitions that led to the current goal. G2T is anonline model that is deeply integrated into the users' workflow and can adaptin real time to new Coq projects and their definitions. It complements wellwith other online models that learn in real time from new proof scripts. Ournovel definition embedding task, which is trained to compute representations ofmathematical concepts not seen during training, boosts the performance of theneural network to rival state-of-the-art k-nearest neighbor predictors.</description><author>Jason Rute, Miroslav Olšák, Lasse Blaauwbroek, Fidel Ivan Schaposnik Massolo, Jelle Piepenbrock, Vasily Pestun</author><pubDate>Fri, 05 Jan 2024 18:52:09 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.02949v1</guid></item><item><title>A Novel Skip Orthogonal List for Dynamic Optimal Transport Problem</title><link>http://arxiv.org/abs/2310.18446v4</link><description>Optimal transport is a fundamental topic that has attracted a great amount ofattention from the optimization community in the past decades. In this paper,we consider an interesting discrete dynamic optimal transport problem: can weefficiently update the optimal transport plan when the weights or the locationsof the data points change? This problem is naturally motivated by severalapplications in machine learning. For example, we often need to compute theoptimal transport cost between two different data sets; if some changes happento a few data points, should we re-compute the high complexity cost function orupdate the cost by some efficient dynamic data structure? We are aware thatseveral dynamic maximum flow algorithms have been proposed before, however, theresearch on dynamic minimum cost flow problem is still quite limited, to thebest of our knowledge. We propose a novel 2D Skip Orthogonal List together withsome dynamic tree techniques. Although our algorithm is based on theconventional simplex method, it can efficiently find the variable to pivotwithin expected $O(1)$ time, and complete each pivoting operation withinexpected $O(|V|)$ time where $V$ is the set of all supply and demand nodes.Since dynamic modifications typically do not introduce significant changes, ouralgorithm requires only a few simplex iterations in practice. So our algorithmis more efficient than re-computing the optimal transport cost that needs atleast one traversal over all $|E| = O(|V|^2)$ variables, where $|E|$ denotesthe number of edges in the network. Our experiments demonstrate that ouralgorithm significantly outperforms existing algorithms in the dynamicscenarios.</description><author>Xiaoyang Xu, Hu Ding</author><pubDate>Fri, 05 Jan 2024 18:47:22 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.18446v4</guid></item><item><title>Digital-analog quantum learning on Rydberg atom arrays</title><link>http://arxiv.org/abs/2401.02940v1</link><description>We propose hybrid digital-analog learning algorithms on Rydberg atom arrays,combining the potentially practical utility and near-term realizability ofquantum learning with the rapidly scaling architectures of neutral atoms. Ourconstruction requires only single-qubit operations in the digital setting andglobal driving according to the Rydberg Hamiltonian in the analog setting. Weperform a comprehensive numerical study of our algorithm on both classical andquantum data, given respectively by handwritten digit classification andunsupervised quantum phase boundary learning. We show in the two representativeproblems that digital-analog learning is not only feasible in the near term,but also requires shorter circuit depths and is more robust to realistic errormodels as compared to digital learning schemes. Our results suggest thatdigital-analog learning opens a promising path towards improved variationalquantum learning experiments in the near term.</description><author>Jonathan Z. Lu, Lucy Jiao, Kristina Wolinski, Milan Kornjača, Hong-Ye Hu, Sergio Cantu, Fangli Liu, Susanne F. Yelin, Sheng-Tao Wang</author><pubDate>Fri, 05 Jan 2024 18:31:00 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.02940v1</guid></item><item><title>Locally Adaptive Neural 3D Morphable Models</title><link>http://arxiv.org/abs/2401.02937v1</link><description>We present the Locally Adaptive Morphable Model (LAMM), a highly flexibleAuto-Encoder (AE) framework for learning to generate and manipulate 3D meshes.We train our architecture following a simple self-supervised training scheme inwhich input displacements over a set of sparse control vertices are used tooverwrite the encoded geometry in order to transform one training sample intoanother. During inference, our model produces a dense output that adhereslocally to the specified sparse geometry while maintaining the overallappearance of the encoded object. This approach results in state-of-the-artperformance in both disentangling manipulated geometry and 3D meshreconstruction. To the best of our knowledge LAMM is the first end-to-endframework that enables direct local control of 3D vertex geometry in a singleforward pass. A very efficient computational graph allows our network to trainwith only a fraction of the memory required by previous methods and run fasterduring inference, generating 12k vertex meshes at $&gt;$60fps on a single CPUthread. We further leverage local geometry control as a primitive for higherlevel editing operations and present a set of derivative capabilities such asswapping and sampling object parts. Code and pretrained models can be found athttps://github.com/michaeltrs/LAMM.</description><author>Michail Tarasiou, Rolandos Alexandros Potamias, Eimear O'Sullivan, Stylianos Ploumpis, Stefanos Zafeiriou</author><pubDate>Fri, 05 Jan 2024 18:28:51 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.02937v1</guid></item><item><title>Enhancing Network Initialization for Medical AI Models Using Large-Scale, Unlabeled Natural Images</title><link>http://arxiv.org/abs/2308.07688v4</link><description>Pre-training datasets, like ImageNet, have become the gold standard inmedical image analysis. However, the emergence of self-supervised learning(SSL), which leverages unlabeled data to learn robust features, presents anopportunity to bypass the intensive labeling process. In this study, weexplored if SSL for pre-training on non-medical images can be applied to chestradiographs and how it compares to supervised pre-training on non-medicalimages and on medical images. We utilized a vision transformer and initializedits weights based on (i) SSL pre-training on natural images (DINOv2), (ii) SLpre-training on natural images (ImageNet dataset), and (iii) SL pre-training onchest radiographs from the MIMIC-CXR database. We tested our approach on over800,000 chest radiographs from six large global datasets, diagnosing more than20 different imaging findings. Our SSL pre-training on curated images not onlyoutperformed ImageNet-based pre-training (P&lt;0.001 for all datasets) but, incertain cases, also exceeded SL on the MIMIC-CXR dataset. Our findings suggestthat selecting the right pre-training strategy, especially with SSL, can bepivotal for improving artificial intelligence (AI)'s diagnostic accuracy inmedical imaging. By demonstrating the promise of SSL in chest radiographanalysis, we underline a transformative shift towards more efficient andaccurate AI models in medical imaging.</description><author>Soroosh Tayebi Arasteh, Leo Misera, Jakob Nikolas Kather, Daniel Truhn, Sven Nebelung</author><pubDate>Fri, 05 Jan 2024 18:25:42 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2308.07688v4</guid></item><item><title>SPFormer: Enhancing Vision Transformer with Superpixel Representation</title><link>http://arxiv.org/abs/2401.02931v1</link><description>In this work, we introduce SPFormer, a novel Vision Transformer enhanced bysuperpixel representation. Addressing the limitations of traditional VisionTransformers' fixed-size, non-adaptive patch partitioning, SPFormer employssuperpixels that adapt to the image's content. This approach divides the imageinto irregular, semantically coherent regions, effectively capturing intricatedetails and applicable at both initial and intermediate feature levels. SPFormer, trainable end-to-end, exhibits superior performance across variousbenchmarks. Notably, it exhibits significant improvements on the challengingImageNet benchmark, achieving a 1.4% increase over DeiT-T and 1.1% over DeiT-Srespectively. A standout feature of SPFormer is its inherent explainability.The superpixel structure offers a window into the model's internal processes,providing valuable insights that enhance the model's interpretability. Thislevel of clarity significantly improves SPFormer's robustness, particularly inchallenging scenarios such as image rotations and occlusions, demonstrating itsadaptability and resilience.</description><author>Jieru Mei, Liang-Chieh Chen, Alan Yuille, Cihang Xie</author><pubDate>Fri, 05 Jan 2024 18:15:26 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.02931v1</guid></item><item><title>Dagma-DCE: Interpretable, Non-Parametric Differentiable Causal Discovery</title><link>http://arxiv.org/abs/2401.02930v1</link><description>We introduce Dagma-DCE, an interpretable and model-agnostic scheme fordifferentiable causal discovery. Current non- or over-parametric methods indifferentiable causal discovery use opaque proxies of ``independence'' tojustify the inclusion or exclusion of a causal relationship. We showtheoretically and empirically that these proxies may be arbitrarily differentthan the actual causal strength. Juxtaposed to existing differentiable causaldiscovery algorithms, \textsc{Dagma-DCE} uses an interpretable measure ofcausal strength to define weighted adjacency matrices. In a number of simulateddatasets, we show our method achieves state-of-the-art level performance. Weadditionally show that \textsc{Dagma-DCE} allows for principled thresholdingand sparsity penalties by domain-experts. The code for our method is availableopen-source at https://github.com/DanWaxman/DAGMA-DCE, and can easily beadapted to arbitrary differentiable models.</description><author>Daniel Waxman, Kurt Butler, Petar M. Djuric</author><pubDate>Fri, 05 Jan 2024 18:15:19 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.02930v1</guid></item><item><title>Towards ASR Robust Spoken Language Understanding Through In-Context Learning With Word Confusion Networks</title><link>http://arxiv.org/abs/2401.02921v1</link><description>In the realm of spoken language understanding (SLU), numerous naturallanguage understanding (NLU) methodologies have been adapted by supplying largelanguage models (LLMs) with transcribed speech instead of conventional writtentext. In real-world scenarios, prior to input into an LLM, an automated speechrecognition (ASR) system generates an output transcript hypothesis, whereinherent errors can degrade subsequent SLU tasks. Here we introduce a methodthat utilizes the ASR system's lattice output instead of relying solely on thetop hypothesis, aiming to encapsulate speech ambiguities and enhance SLUoutcomes. Our in-context learning experiments, covering spoken questionanswering and intent classification, underline the LLM's resilience to noisyspeech transcripts with the help of word confusion networks from lattices,bridging the SLU performance gap between using the top ASR hypothesis and anoracle upper bound. Additionally, we delve into the LLM's robustness to varyingASR performance conditions and scrutinize the aspects of in-context learningwhich prove the most influential.</description><author>Kevin Everson, Yile Gu, Huck Yang, Prashanth Gurunath Shivakumar, Guan-Ting Lin, Jari Kolehmainen, Ivan Bulyko, Ankur Gandhe, Shalini Ghosh, Wael Hamza, Hung-yi Lee, Ariya Rastrow, Andreas Stolcke</author><pubDate>Fri, 05 Jan 2024 17:58:10 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.02921v1</guid></item><item><title>Language-free Compositional Action Generation via Decoupling Refinement</title><link>http://arxiv.org/abs/2307.03538v2</link><description>Composing simple elements into complex concepts is crucial yet challenging,especially for 3D action generation. Existing methods largely rely on extensiveneural language annotations to discern composable latent semantics, a processthat is often costly and labor-intensive. In this study, we introduce a novelframework to generate compositional actions without reliance on languageauxiliaries. Our approach consists of three main components: Action Coupling,Conditional Action Generation, and Decoupling Refinement. Action Couplingutilizes an energy model to extract the attention masks of each sub-action,subsequently integrating two actions using these attentions to generatepseudo-training examples. Then, we employ a conditional generative model, CVAE,to learn a latent space, facilitating the diverse generation. Finally, wepropose Decoupling Refinement, which leverages a self-supervised pre-trainedmodel MAE to ensure semantic consistency between the sub-actions andcompositional actions. This refinement process involves rendering generated 3Dactions into 2D space, decoupling these images into two sub-segments, using theMAE model to restore the complete image from sub-segments, and constraining therecovered images to match images rendered from raw sub-actions. Due to the lackof existing datasets containing both sub-actions and compositional actions, wecreated two new datasets, named HumanAct-C and UESTC-C, and present acorresponding evaluation metric. Both qualitative and quantitative assessmentsare conducted to show our efficacy.</description><author>Xiao Liu, Guangyi Chen, Yansong Tang, Guangrun Wang, Ser-Nam Lim</author><pubDate>Fri, 05 Jan 2024 17:56:56 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.03538v2</guid></item><item><title>Analytically-Driven Resource Management for Cloud-Native Microservices</title><link>http://arxiv.org/abs/2401.02920v1</link><description>Resource management for cloud-native microservices has attracted a lot ofrecent attention. Previous work has shown that machine learning (ML)-drivenapproaches outperform traditional techniques, such as autoscaling, in terms ofboth SLA maintenance and resource efficiency. However, ML-driven approachesalso face challenges including lengthy data collection processes and limitedscalability. We present Ursa, a lightweight resource management system forcloud-native microservices that addresses these challenges. Ursa uses ananalytical model that decomposes the end-to-end SLA into per-service SLA, andmaps per-service SLA to individual resource allocations per microservice tier.To speed up the exploration process and avoid prolonged SLA violations, Ursaexplores each microservice individually, and swiftly stops exploration iflatency exceeds its SLA. We evaluate Ursa on a set of representative and end-to-end microservicetopologies, including a social network, media service and video processingpipeline, each consisting of multiple classes and priorities of requests withdifferent SLAs, and compare it against two representative ML-driven systems,Sinan and Firm. Compared to these ML-driven approaches, Ursa providessignificant advantages: It shortens the data collection process by more than128x, and its control plane is 43x faster than ML-driven approaches. At thesame time, Ursa does not sacrifice resource efficiency or SLAs. During onlinedeployment, Ursa reduces the SLA violation rate by 9.0% up to 49.9%, andreduces CPU allocation by up to 86.2% compared to ML-driven approaches.</description><author>Yanqi Zhang, Zhuangzhuang Zhou, Sameh Elnikety, Christina Delimitrou</author><pubDate>Fri, 05 Jan 2024 17:55:32 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.02920v1</guid></item><item><title>Uncovering the human motion pattern: Pattern Memory-based Diffusion Model for Trajectory Prediction</title><link>http://arxiv.org/abs/2401.02916v1</link><description>Human trajectory forecasting is a critical challenge in fields such asrobotics and autonomous driving. Due to the inherent uncertainty of humanactions and intentions in real-world scenarios, various unexpected occurrencesmay arise. To uncover latent motion patterns in human behavior, we introduce anovel memory-based method, named Motion Pattern Priors Memory Network. Ourmethod involves constructing a memory bank derived from clustered priorknowledge of motion patterns observed in the training set trajectories. Weintroduce an addressing mechanism to retrieve the matched pattern and thepotential target distributions for each prediction from the memory bank, whichenables the identification and retrieval of natural motion patterns exhibitedby agents, subsequently using the target priors memory token to guide thediffusion model to generate predictions. Extensive experiments validate theeffectiveness of our approach, achieving state-of-the-art trajectory predictionaccuracy. The code will be made publicly available.</description><author>Yuxin Yang, Pengfei Zhu, Mengshi Qi, Huadong Ma</author><pubDate>Fri, 05 Jan 2024 17:39:52 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.02916v1</guid></item><item><title>A unified uncertainty-aware exploration: Combining epistemic and aleatory uncertainty</title><link>http://arxiv.org/abs/2401.02914v1</link><description>Exploration is a significant challenge in practical reinforcement learning(RL), and uncertainty-aware exploration that incorporates the quantification ofepistemic and aleatory uncertainty has been recognized as an effectiveexploration strategy. However, capturing the combined effect of aleatory andepistemic uncertainty for decision-making is difficult. Existing works estimatealeatory and epistemic uncertainty separately and consider the compositeuncertainty as an additive combination of the two. Nevertheless, the additiveformulation leads to excessive risk-taking behavior, causing instability. Inthis paper, we propose an algorithm that clarifies the theoretical connectionbetween aleatory and epistemic uncertainty, unifies aleatory and epistemicuncertainty estimation, and quantifies the combined effect of bothuncertainties for a risk-sensitive exploration. Our method builds on a novelextension of distributional RL that estimates a parameterized returndistribution whose parameters are random variables encoding epistemicuncertainty. Experimental results on tasks with exploration and risk challengesshow that our method outperforms alternative approaches.</description><author>Parvin Malekzadeh, Ming Hou, Konstantinos N. Plataniotis</author><pubDate>Fri, 05 Jan 2024 17:39:00 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.02914v1</guid></item><item><title>Astrocyte Regulated Neuromorphic Central Pattern Generator Control of Legged Robotic Locomotion</title><link>http://arxiv.org/abs/2312.15805v2</link><description>Neuromorphic computing systems, where information is transmitted throughaction potentials in a bio-plausible fashion, is gaining increasing interestdue to its promise of low-power event-driven computing. Application ofneuromorphic computing in robotic locomotion research have largely focused onCentral Pattern Generators (CPGs) for bionics robotic control algorithms -inspired from neural circuits governing the collaboration of the limb musclesin animal movement. Implementation of artificial CPGs on neuromorphic hardwareplatforms can potentially enable adaptive and energy-efficient edge roboticsapplications in resource constrained environments. However, underlying rewiringmechanisms in CPG for gait emergence process is not well understood. This workaddresses the missing gap in literature pertaining to CPG plasticity andunderscores the critical homeostatic functionality of astrocytes - a cellularcomponent in the brain that is believed to play a major role in multiple brainfunctions. This paper introduces an astrocyte regulated Spiking Neural Network(SNN)-based CPG for learning locomotion gait through Reward-Modulated STDP forquadruped robots, where the astrocytes help build inhibitory connections amongthe artificial motor neurons in different limbs. The SNN-based CPG is simulatedon a multi-object physics simulation platform resulting in the emergence of atrotting gait while running the robot on flat ground. $23.3\times$computational power savings is observed in comparison to a state-of-the-artreinforcement learning based robot control algorithm. Such aneuroscience-algorithm co-design approach can potentially enable a quantum leapin the functionality of neuromorphic systems incorporating glial cellfunctionality.</description><author>Zhuangyu Han, Abhronil Sengupta</author><pubDate>Fri, 05 Jan 2024 17:38:18 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.15805v2</guid></item><item><title>Variational Quantum and Quantum-Inspired Clustering</title><link>http://arxiv.org/abs/2206.09893v2</link><description>Here we present a quantum algorithm for clustering data based on avariational quantum circuit. The algorithm allows to classify data into manyclusters, and can easily be implemented in few-qubit Noisy Intermediate-ScaleQuantum (NISQ) devices. The idea of the algorithm relies on reducing theclustering problem to an optimization, and then solving it via a VariationalQuantum Eigensolver (VQE) combined with non-orthogonal qubit states. Inpractice, the method uses maximally-orthogonal states of the target Hilbertspace instead of the usual computational basis, allowing for a large number ofclusters to be considered even with few qubits. We benchmark the algorithm withnumerical simulations using real datasets, showing excellent performance evenwith one single qubit. Moreover, a tensor network simulation of the algorithmimplements, by construction, a quantum-inspired clustering algorithm that canrun on current classical hardware.</description><author>Pablo Bermejo, Roman Orus</author><pubDate>Fri, 05 Jan 2024 17:25:03 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2206.09893v2</guid></item><item><title>Surgical Aggregation: Federated Class-Heterogeneous Learning</title><link>http://arxiv.org/abs/2301.06683v5</link><description>The release of numerous chest x-ray datasets has spearheaded the developmentof deep learning models with expert-level performance. However, they havelimited interoperability due to class-heterogeneity -- a result of inconsistentlabeling schemes and partial annotations. Therefore, it is challenging toleverage these datasets in aggregate to train models with a completerepresentation of abnormalities that may occur within the thorax. In this work,we propose surgical aggregation, a federated learning framework for aggregatingknowledge from class-heterogeneous datasets and learn a model that cansimultaneously predict the presence of all disease labels present across thedatasets. We evaluate our method using simulated and real-worldclass-heterogeneous datasets across both independent and identicallydistributed (iid) and non-iid settings. Our results show that surgicalaggregation outperforms current methods, has better generalizability, and is acrucial first step towards tackling class-heterogeneity in federated learningto facilitate the development of clinically-useful models using previouslynon-interoperable chest x-ray datasets.</description><author>Pranav Kulkarni, Adway Kanhere, Paul H. Yi, Vishwa S. Parekh</author><pubDate>Fri, 05 Jan 2024 17:18:56 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2301.06683v5</guid></item><item><title>Introducing Bode: A Fine-Tuned Large Language Model for Portuguese Prompt-Based Task</title><link>http://arxiv.org/abs/2401.02909v1</link><description>Large Language Models (LLMs) are increasingly bringing advances to NaturalLanguage Processing. However, low-resource languages, those lacking extensiveprominence in datasets for various NLP tasks, or where existing datasets arenot as substantial, such as Portuguese, already obtain several benefits fromLLMs, but not to the same extent. LLMs trained on multilingual datasetsnormally struggle to respond to prompts in Portuguese satisfactorily,presenting, for example, code switching in their responses. This work proposesa fine-tuned LLaMA 2-based model for Portuguese prompts named Bode in twoversions: 7B and 13B. We evaluate the performance of this model inclassification tasks using the zero-shot approach with in-context learning, andcompare it with other LLMs. Our main contribution is to bring an LLM withsatisfactory results in the Portuguese language, as well as to provide a modelthat is free for research or commercial purposes.</description><author>Gabriel Lino Garcia, Pedro Henrique Paiola, Luis Henrique Morelli, Giovani Candido, Arnaldo Cândido Júnior, Danilo Samuel Jodas, Luis C. S. Afonso, Ivan Rizzo Guilherme, Bruno Elias Penteado, João Paulo Papa</author><pubDate>Fri, 05 Jan 2024 17:15:01 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.02909v1</guid></item><item><title>MLLM-Protector: Ensuring MLLM's Safety without Hurting Performance</title><link>http://arxiv.org/abs/2401.02906v1</link><description>The deployment of multimodal large language models (MLLMs) has brought fortha unique vulnerability: susceptibility to malicious attacks through visualinputs. We delve into the novel challenge of defending MLLMs against suchattacks. We discovered that images act as a "foreign language" that is notconsidered during alignment, which can make MLLMs prone to producing harmfulresponses. Unfortunately, unlike the discrete tokens considered in text-basedLLMs, the continuous nature of image signals presents significant alignmentchallenges, which poses difficulty to thoroughly cover the possible scenarios.This vulnerability is exacerbated by the fact that open-source MLLMs arepredominantly fine-tuned on limited image-text pairs that is much less than theextensive text-based pretraining corpus, which makes the MLLMs more prone tocatastrophic forgetting of their original abilities during explicit alignmenttuning. To tackle these challenges, we introduce MLLM-Protector, aplug-and-play strategy combining a lightweight harm detector and a responsedetoxifier. The harm detector's role is to identify potentially harmful outputsfrom the MLLM, while the detoxifier corrects these outputs to ensure theresponse stipulates to the safety standards. This approach effectivelymitigates the risks posed by malicious visual inputs without compromising themodel's overall performance. Our results demonstrate that MLLM-Protector offersa robust solution to a previously unaddressed aspect of MLLM security.</description><author>Renjie Pi, Tianyang Han, Yueqi Xie, Rui Pan, Qing Lian, Hanze Dong, Jipeng Zhang, Tong Zhang</author><pubDate>Fri, 05 Jan 2024 17:05:42 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.02906v1</guid></item><item><title>H2G2-Net: A Hierarchical Heterogeneous Graph Generative Network Framework for Discovery of Multi-Modal Physiological Responses</title><link>http://arxiv.org/abs/2401.02905v1</link><description>Discovering human cognitive and emotional states using multi-modalphysiological signals draws attention across various research applications.Physiological responses of the human body are influenced by human cognition andcommonly used to analyze cognitive states. From a network science perspective,the interactions of these heterogeneous physiological modalities in a graphstructure may provide insightful information to support prediction of cognitivestates. However, there is no clue to derive exact connectivity betweenheterogeneous modalities and there exists a hierarchical structure ofsub-modalities. Existing graph neural networks are designed to learn onnon-hierarchical homogeneous graphs with pre-defined graph structures; theyfailed to learn from hierarchical, multi-modal physiological data without apre-defined graph structure. To this end, we propose a hierarchicalheterogeneous graph generative network (H2G2-Net) that automatically learns agraph structure without domain knowledge, as well as a powerful representationon the hierarchical heterogeneous graph in an end-to-end fashion. We validatethe proposed method on the CogPilot dataset that consists of multi-modalphysiological signals. Extensive experiments demonstrate that our proposedmethod outperforms the state-of-the-art GNNs by 5%-20% in prediction accuracy.</description><author>Haidong Gu, Nathan Gaw, Yinan Wang, Chancellor Johnstone, Christine Beauchene, Sophia Yuditskaya, Hrishikesh Rao, Chun-An Chou</author><pubDate>Fri, 05 Jan 2024 17:05:33 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.02905v1</guid></item><item><title>Class-wise Generalization Error: an Information-Theoretic Analysis</title><link>http://arxiv.org/abs/2401.02904v1</link><description>Existing generalization theories of supervised learning typically take aholistic approach and provide bounds for the expected generalization over thewhole data distribution, which implicitly assumes that the model generalizessimilarly for all the classes. In practice, however, there are significantvariations in generalization performance among different classes, which cannotbe captured by the existing generalization bounds. In this work, we tackle thisproblem by theoretically studying the class-generalization error, whichquantifies the generalization performance of each individual class. We derive anovel information-theoretic bound for class-generalization error using the KLdivergence, and we further obtain several tighter bounds using the conditionalmutual information (CMI), which are significantly easier to estimate inpractice. We empirically validate our proposed bounds in different neuralnetworks and show that they accurately capture the complex class-generalizationerror behavior. Moreover, we show that the theoretical tools developed in thispaper can be applied in several applications beyond this context.</description><author>Firas Laakom, Yuheng Bu, Moncef Gabbouj</author><pubDate>Fri, 05 Jan 2024 17:05:14 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.02904v1</guid></item><item><title>Deep Reinforcement Learning for Local Path Following of an Autonomous Formula SAE Vehicle</title><link>http://arxiv.org/abs/2401.02903v1</link><description>With the continued introduction of driverless events to Formula:Society ofAutomotive Engineers (F:SAE) competitions around the world, teams areinvestigating all aspects of the autonomous vehicle stack. This paper presentsthe use of Deep Reinforcement Learning (DRL) and Inverse Reinforcement Learning(IRL) to map locally-observed cone positions to a desired steering angle forrace track following. Two state-of-the-art algorithms not previously tested inthis context: soft actor critic (SAC) and adversarial inverse reinforcementlearning (AIRL), are used to train models in a representative simulation. Threenovel reward functions for use by RL algorithms in an autonomous racing contextare also discussed. Tests performed in simulation and the real world suggestthat both algorithms can successfully train models for local path following.Suggestions for future work are presented to allow these models to scale to afull F:SAE vehicle.</description><author>Harvey Merton, Thomas Delamore, Karl Stol, Henry Williams</author><pubDate>Fri, 05 Jan 2024 17:04:43 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.02903v1</guid></item><item><title>State Derivative Normalization for Continuous-Time Deep Neural Networks</title><link>http://arxiv.org/abs/2401.02902v1</link><description>The importance of proper data normalization for deep neural networks is wellknown. However, in continuous-time state-space model estimation, it has beenobserved that improper normalization of either the hidden state or hidden statederivative of the model estimate, or even of the time interval can lead tonumerical and optimization challenges with deep learning based methods. Thisresults in a reduced model quality. In this contribution, we show that thesethree normalization tasks are inherently coupled. Due to the existence of thiscoupling, we propose a solution to all three normalization challenges byintroducing a normalization constant at the state derivative level. We showthat the appropriate choice of the normalization constant is related to thedynamics of the to-be-identified system and we derive multiple methods ofobtaining an effective normalization constant. We compare and discuss all thenormalization strategies on a benchmark problem based on experimental data froma cascaded tanks system and compare our results with other methods of theidentification literature.</description><author>Jonas Weigand, Gerben I. Beintema, Jonas Ulmen, Daniel Görges, Roland Tóth, Maarten Schoukens, Martin Ruskowski</author><pubDate>Fri, 05 Jan 2024 17:04:33 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.02902v1</guid></item><item><title>Nonlinear functional regression by functional deep neural network with kernel embedding</title><link>http://arxiv.org/abs/2401.02890v1</link><description>With the rapid development of deep learning in various fields of science andtechnology, such as speech recognition, image classification, and naturallanguage processing, recently it is also widely applied in the functional dataanalysis (FDA) with some empirical success. However, due to the infinitedimensional input, we need a powerful dimension reduction method for functionallearning tasks, especially for the nonlinear functional regression. In thispaper, based on the idea of smooth kernel integral transformation, we propose afunctional deep neural network with an efficient and fully data-dependentdimension reduction method. The architecture of our functional net consists ofa kernel embedding step: an integral transformation with a data-dependentsmooth kernel; a projection step: a dimension reduction by projection witheigenfunction basis based on the embedding kernel; and finally an expressivedeep ReLU neural network for the prediction. The utilization of smooth kernelembedding enables our functional net to be discretization invariant, efficient,and robust to noisy observations, capable of utilizing information in bothinput functions and responses data, and have a low requirement on the number ofdiscrete points for an unimpaired generalization performance. We conducttheoretical analysis including approximation error and generalization erroranalysis, and numerical simulations to verify these advantages of ourfunctional net.</description><author>Zhongjie Shi, Jun Fan, Linhao Song, Ding-Xuan Zhou, Johan A. K. Suykens</author><pubDate>Fri, 05 Jan 2024 16:43:39 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.02890v1</guid></item><item><title>A Distributed Block Chebyshev-Davidson Algorithm for Parallel Spectral Clustering</title><link>http://arxiv.org/abs/2212.04443v2</link><description>We develop a distributed Block Chebyshev-Davidson algorithm to solvelarge-scale leading eigenvalue problems for spectral analysis in spectralclustering. First, the efficiency of the Chebyshev-Davidson algorithm relies onthe prior knowledge of the eigenvalue spectrum, which could be expensive toestimate. This issue can be lessened by the analytic spectrum estimation of theLaplacian or normalized Laplacian matrices in spectral clustering, making theproposed algorithm very efficient for spectral clustering. Second, to make theproposed algorithm capable of analyzing big data, a distributed and parallelversion has been developed with attractive scalability. The speedup by parallelcomputing is approximately equivalent to $\sqrt{p}$, where $p$ denotes thenumber of processes. {Numerical results will be provided to demonstrate itsefficiency in spectral clustering and scalability advantage over existingeigensolvers used for spectral clustering in parallel computing environments.}</description><author>Qiyuan Pang, Haizhao Yang</author><pubDate>Fri, 05 Jan 2024 16:40:44 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2212.04443v2</guid></item><item><title>Energy-Preserving Reduced Operator Inference for Efficient Design and Control</title><link>http://arxiv.org/abs/2401.02889v1</link><description>Many-query computations, in which a computational model for an engineeringsystem must be evaluated many times, are crucial in design and control. Forsystems governed by partial differential equations (PDEs), typicalhigh-fidelity numerical models are high-dimensional and too computationallyexpensive for the many-query setting. Thus, efficient surrogate models arerequired to enable low-cost computations in design and control. This workpresents a physics-preserving reduced model learning approach that targets PDEswhose quadratic operators preserve energy, such as those arising in governingequations in many fluids problems. The approach is based on the OperatorInference method, which fits reduced model operators to state snapshot and timederivative data in a least-squares sense. However, Operator Inference does notgenerally learn a reduced quadratic operator with the energy-preservingproperty of the original PDE. Thus, we propose a new energy-preserving OperatorInference (EP-OpInf) approach, which imposes this structure on the learnedreduced model via constrained optimization. Numerical results using the viscousBurgers' and Kuramoto-Sivashinksy equation (KSE) demonstrate that EP-OpInflearns efficient and accurate reduced models that retain this energy-preservingstructure.</description><author>Tomoki Koike, Elizabeth Qian</author><pubDate>Fri, 05 Jan 2024 16:39:48 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.02889v1</guid></item><item><title>Application of federated learning techniques for arrhythmia classification using 12-lead ECG signals</title><link>http://arxiv.org/abs/2208.10993v3</link><description>Artificial Intelligence-based (AI) analysis of large, curated medicaldatasets is promising for providing early detection, faster diagnosis, and moreeffective treatment using low-power Electrocardiography (ECG) monitoringdevices information. However, accessing sensitive medical data from diversesources is highly restricted since improper use, unsafe storage, or dataleakage could violate a person's privacy. This work uses a Federated Learning(FL) privacy-preserving methodology to train AI models over heterogeneous setsof high-definition ECG from 12-lead sensor arrays collected from sixheterogeneous sources. We evaluated the capacity of the resulting models toachieve equivalent performance compared to state-of-the-art models trained in aCentralized Learning (CL) fashion. Moreover, we assessed the performance of oursolution over Independent and Identical distributed (IID) and non-IID federateddata. Our methodology involves machine learning techniques based on Deep NeuralNetworks and Long-Short-Term Memory models. It has a robust data preprocessingpipeline with feature engineering, selection, and data balancing techniques.Our AI models demonstrated comparable performance to models trained using CL,IID, and non-IID approaches. They showcased advantages in reduced complexityand faster training time, making them well-suited for cloud-edge architectures.</description><author>Daniel Mauricio Jimenez Gutierrez, Hafiz Muuhammad Hassan, Lorella Landi, Andrea Vitaletti, Ioannis Chatzigiannakis</author><pubDate>Fri, 05 Jan 2024 16:32:10 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2208.10993v3</guid></item><item><title>MsDC-DEQ-Net: Deep Equilibrium Model (DEQ) with Multi-scale Dilated Convolution for Image Compressive Sensing (CS)</title><link>http://arxiv.org/abs/2401.02884v1</link><description>Compressive sensing (CS) is a technique that enables the recovery of sparsesignals using fewer measurements than traditional sampling methods. To addressthe computational challenges of CS reconstruction, our objective is to developan interpretable and concise neural network model for reconstructing naturalimages using CS. We achieve this by mapping one step of the iterative shrinkagethresholding algorithm (ISTA) to a deep network block, representing oneiteration of ISTA. To enhance learning ability and incorporate structuraldiversity, we integrate aggregated residual transformations (ResNeXt) andsqueeze-and-excitation (SE) mechanisms into the ISTA block. This block servesas a deep equilibrium layer, connected to a semi-tensor product network(STP-Net) for convenient sampling and providing an initial reconstruction. Theresulting model, called MsDC-DEQ-Net, exhibits competitive performance comparedto state-of-the-art network-based methods. It significantly reduces storagerequirements compared to deep unrolling methods, using only one iteration blockinstead of multiple iterations. Unlike deep unrolling models, MsDC-DEQ-Net canbe iteratively used, gradually improving reconstruction accuracy whileconsidering computation trade-offs. Additionally, the model benefits frommulti-scale dilated convolutions, further enhancing performance.</description><author>Youhao Yu, Richard M. Dansereau</author><pubDate>Fri, 05 Jan 2024 16:25:58 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.02884v1</guid></item><item><title>AutoGL: A Library for Automated Graph Learning</title><link>http://arxiv.org/abs/2104.04987v3</link><description>Recent years have witnessed an upsurge in research interests and applicationsof machine learning on graphs. However, manually designing the optimal machinelearning algorithms for different graph datasets and tasks is inflexible,labor-intensive, and requires expert knowledge, limiting its adaptivity andapplicability. Automated machine learning (AutoML) on graphs, aiming toautomatically design the optimal machine learning algorithm for a given graphdataset and task, has received considerable attention. However, none of theexisting libraries can fully support AutoML on graphs. To fill this gap, wepresent Automated Graph Learning (AutoGL), the first dedicated library forautomated machine learning on graphs. AutoGL is open-source, easy to use, andflexible to be extended. Specifically, we propose a three-layer architecture,consisting of backends to interface with devices, a complete automated graphlearning pipeline, and supported graph applications. The automated machinelearning pipeline further contains five functional modules: auto featureengineering, neural architecture search, hyper-parameter optimization, modeltraining, and auto ensemble, covering the majority of existing AutoML methodson graphs. For each module, we provide numerous state-of-the-art methods andflexible base classes and APIs, which allow easy usage and customization. Wefurther provide experimental results to showcase the usage of our AutoGLlibrary. We also present AutoGL-light, a lightweight version of AutoGL tofacilitate customizing pipelines and enriching applications, as well asbenchmarks for graph neural architecture search. The codes of AutoGL arepublicly available at https://github.com/THUMNLab/AutoGL.</description><author>Ziwei Zhang, Yijian Qin, Zeyang Zhang, Chaoyu Guan, Jie Cai, Heng Chang, Jiyan Jiang, Haoyang Li, Zixin Sun, Beini Xie, Yang Yao, Yipeng Zhang, Xin Wang, Wenwu Zhu</author><pubDate>Fri, 05 Jan 2024 16:15:40 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2104.04987v3</guid></item><item><title>Advancing Ischemic Stroke Diagnosis: A Novel Two-Stage Approach for Blood Clot Origin Identification</title><link>http://arxiv.org/abs/2304.13775v2</link><description>An innovative two-stage methodology for categorizing blood clot origins ispresented in this paper, which is important for the diagnosis and treatment ofischemic stroke. First, a background classifier based on MobileNetV3 segmentsbig whole-slide digital pathology images into numerous tiles to detect thepresence of cellular material. After that, different pre-trained imageclassification algorithms are fine-tuned to determine the origin of bloodclots. Due to complex blood flow dynamics and limitations in conventionalimaging methods such as computed tomography (CT), magnetic resonance imaging(MRI), and ultrasound, identifying the sources of blood clots is a challengingtask. Although these techniques are useful for identifying blood clots, theyare not very good at determining how they originated. To address thesechallenges, our method makes use of robust computer vision models that havebeen refined using information from whole-slide digital pathology images. Outof all the models tested, the PoolFormer \cite{yu2022metaformer} performsbetter than the others, with 93.4\% accuracy, 93.4\% precision, 93.4\% recall,and 93.4\% F1-score. Moreover, it achieves the good weighted multi-classlogarithmic loss (WMCLL) of 0.4361, which emphasizes how effective it is inthis particular application. These encouraging findings suggest that ourapproach can successfully identify the origin of blood clots in a variety ofvascular locations, potentially advancing ischemic stroke diagnosis andtreatment approaches.</description><author>Koushik Sivarama Krishnan, P. J. Joe Nikesh, Swathi Gnanasekar, Karthik Sivarama Krishnan</author><pubDate>Fri, 05 Jan 2024 16:13:31 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2304.13775v2</guid></item><item><title>Efficient Parameter Optimisation for Quantum Kernel Alignment: A Sub-sampling Approach in Variational Training</title><link>http://arxiv.org/abs/2401.02879v1</link><description>Quantum machine learning with quantum kernels for classification problems isa growing area of research. Recently, quantum kernel alignment techniques thatparameterise the kernel have been developed, allowing the kernel to be trainedand therefore aligned with a specific dataset. While quantum kernel alignmentis a promising technique, it has been hampered by considerable training costsbecause the full kernel matrix must be constructed at every training iteration.Addressing this challenge, we introduce a novel method that seeks to balanceefficiency and performance. We present a sub-sampling training approach thatuses a subset of the kernel matrix at each training step, thereby reducing theoverall computational cost of the training. In this work, we apply thesub-sampling method to synthetic datasets and a real-world breast cancerdataset and demonstrate considerable reductions in the number of circuitsrequired to train the quantum kernel while maintaining classification accuracy.</description><author>M. Emre Sahin, Benjamin C. B. Symons, Pushpak Pati, Fayyaz Minhas, Declan Millar, Maria Gabrani, Jan Lukas Robertus, Stefano Mensa</author><pubDate>Fri, 05 Jan 2024 16:11:34 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.02879v1</guid></item><item><title>Analyzing Wrap-Up Effects through an Information-Theoretic Lens</title><link>http://arxiv.org/abs/2203.17213v2</link><description>Numerous analyses of reading time (RT) data have been implemented -- all inan effort to better understand the cognitive processes driving readingcomprehension. However, data measured on words at the end of a sentence -- oreven at the end of a clause -- is often omitted due to the confounding factorsintroduced by so-called "wrap-up effects," which manifests as a skeweddistribution of RTs for these words. Consequently, the understanding of thecognitive processes that might be involved in these wrap-up effects is limited.In this work, we attempt to learn more about these processes by examining therelationship between wrap-up effects and information-theoretic quantities, suchas word and context surprisals. We find that the distribution of information inprior contexts is often predictive of sentence- and clause-final RTs (while notof sentence-medial RTs). This lends support to several prior hypotheses aboutthe processes involved in wrap-up effects.</description><author>Clara Meister, Tiago Pimentel, Thomas Hikaru Clark, Ryan Cotterell, Roger Levy</author><pubDate>Fri, 05 Jan 2024 16:10:15 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2203.17213v2</guid></item><item><title>Optimal Chaining of Vehicle Plans with Time Windows</title><link>http://arxiv.org/abs/2401.02873v1</link><description>For solving problems from the domain of vehicle routing with time windows, weoften need to connect vehicle plans into sequences spanning a longer timehorizon or, in other words, we need to perform a plan chaining. Recently, anetwork-based solution has been proposed to solve the fleet-sizing problem. Themethod, however, does not consider the time flexibility of the plans, anessential property of all vehicle routing problems with time windows. Instead,plans have fixed times and cannot be delayed. This work presents a new problemformulation that considers delays in line with the given time windows and amethod that can be used to solve it. Moreover, we prove that the method isoptimal, and we analyze its complexity. Finally, we list some practicalapplications and perform a demonstration for one of them: the method forsolving the static Dial-a-ride problem. The demonstration results show that fora significant number of instances, the proposed method provides a bettersolution than the other two heuristic baseline methods we have evaluated, whilenot having the largest computational time requirements.</description><author>David Fiedler, Fabio V. Difonzo, Jan Mrkos</author><pubDate>Fri, 05 Jan 2024 16:04:55 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.02873v1</guid></item><item><title>On the Efficacy of Sampling Adapters</title><link>http://arxiv.org/abs/2307.03749v2</link><description>Sampling is a common strategy for generating text from probabilistic models,yet standard ancestral sampling often results in text that is incoherent orungrammatical. To alleviate this issue, various modifications to a model'ssampling distribution, such as nucleus or top-k sampling, have been introducedand are now ubiquitously used in language generation systems. We propose aunified framework for understanding these techniques, which we term samplingadapters. Sampling adapters often lead to qualitatively better text, whichraises the question: From a formal perspective, how are they changing the(sub)word-level distributions of language generation models? And why do theselocal changes lead to higher-quality text? We argue that the shift they enforcecan be viewed as a trade-off between precision and recall: while the modelloses its ability to produce certain strings, its precision rate on desirabletext increases. While this trade-off is not reflected in standard metrics ofdistribution quality (such as perplexity), we find that severalprecision-emphasizing measures indeed indicate that sampling adapters can leadto probability distributions more aligned with the true distribution. Further,these measures correlate with higher sequence-level quality scores,specifically, Mauve.</description><author>Clara Meister, Tiago Pimentel, Luca Malagutti, Ethan G. Wilcox, Ryan Cotterell</author><pubDate>Fri, 05 Jan 2024 15:55:23 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.03749v2</guid></item><item><title>AFSPP: Agent Framework for Shaping Preference and Personality with Large Language Models</title><link>http://arxiv.org/abs/2401.02870v1</link><description>The evolution of Large Language Models (LLMs) has introduced a new paradigmfor investigating human behavior emulation. Recent research has employedLLM-based Agents to create a sociological research environment, in which agentsexhibit behavior based on the unfiltered characteristics of large languagemodels. However, these studies overlook the iterative development within ahuman-like setting - Human preferences and personalities are complex, shaped byvarious factors and subject to ongoing change as a result of environmental andsubjective influences. In light of this observation, we propose Agent Frameworkfor Shaping Preference and Personality (AFSPP), exploring the multifacetedimpact of social networks and subjective consciousness on LLM-based Agents'preference and personality formation. With AFSPP, we have, for the first time,successfully replicated several key findings from human personalityexperiments. And other AFSPP-based experimental results indicate that planmaking, sensory perceptions and social networking with subjective information,wield the most pronounced influence on preference shaping. AFSPP cansignificantly enhance the efficiency and scope of psychological experiments,while yielding valuable insights for Trustworthy Artificial Intelligenceresearch for strategies to prevent undesirable preference and personalitydevelopment.</description><author>Zihong He, Changwang Zhang</author><pubDate>Fri, 05 Jan 2024 15:52:59 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.02870v1</guid></item><item><title>LITE: A Stable Framework for Lattice-Integrated Embedding of Topological Descriptors</title><link>http://arxiv.org/abs/2312.17093v2</link><description>In this paper, we introduce a new family of descriptors for persistencediagrams. Our approach transforms these diagrams into elements of afinite-dimensional vector space using functionals based on the discretemeasures they induce. While our focus is primarily on identity andfrequency-based transformations, we do not restrict our approach exclusively tothis types of techniques. We term this family of transformations as LITE(Lattice Integrated Topological Embedding) and prove stability for some membersof this family against the 1-$Kantorovitch$-$Rubinstein$ metric, ensuring itsresponsiveness to subtle data variations. Extensive comparative analysisreveals that our descriptor performs competitively with the currentstate-of-art from the topological data analysis literature, and oftensurpasses, the existing methods. This research not only introduces aninnovative perspective for data scientists but also critiques the currenttrajectory of literature on methodologies for vectorizing diagrams. Itestablishes a foundation for future progress in applying persistence diagramsto data analysis and machine learning under a more simple and effective lens.</description><author>Michael Etienne Van Huffel, Matteo Palo</author><pubDate>Fri, 05 Jan 2024 15:48:43 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.17093v2</guid></item><item><title>"It's not like Jarvis, but it's pretty close!" -- Examining ChatGPT's Usage among Undergraduate Students in Computer Science</title><link>http://arxiv.org/abs/2311.09651v2</link><description>Large language models (LLMs) such as ChatGPT and Google Bard have garneredsignificant attention in the academic community. Previous research hasevaluated these LLMs for various applications such as generating programmingexercises and solutions. However, these evaluations have predominantly beenconducted by instructors and researchers, not considering the actual usage ofLLMs by students. This study adopts a student-first approach to comprehensivelyunderstand how undergraduate computer science students utilize ChatGPT, apopular LLM, released by OpenAI. We employ a combination of student surveys andinterviews to obtain valuable insights into the benefits, challenges, andsuggested improvements related to ChatGPT. Our findings suggest that a majorityof students (over 57%) have a convincingly positive outlook towards adoptingChatGPT as an aid in coursework-related tasks. However, our research alsohighlights various challenges that must be resolved for long-term acceptance ofChatGPT amongst students. The findings from this investigation have broaderimplications and may be applicable to other LLMs and their role in computingeducation.</description><author>Ishika Joshi, Ritvik Budhiraja, Harshal D Akolekar, Jagat Sesh Challa, Dhruv Kumar</author><pubDate>Fri, 05 Jan 2024 15:47:03 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.09651v2</guid></item><item><title>Hierarchical Randomized Smoothing</title><link>http://arxiv.org/abs/2310.16221v3</link><description>Real-world data is complex and often consists of objects that can bedecomposed into multiple entities (e.g. images into pixels, graphs intointerconnected nodes). Randomized smoothing is a powerful framework for makingmodels provably robust against small changes to their inputs - by guaranteeingrobustness of the majority vote when randomly adding noise beforeclassification. Yet, certifying robustness on such complex data via randomizedsmoothing is challenging when adversaries do not arbitrarily perturb entireobjects (e.g. images) but only a subset of their entities (e.g. pixels). As asolution, we introduce hierarchical randomized smoothing: We partially smoothobjects by adding random noise only on a randomly selected subset of theirentities. By adding noise in a more targeted manner than existing methods weobtain stronger robustness guarantees while maintaining high accuracy. Weinitialize hierarchical smoothing using different noising distributions,yielding novel robustness certificates for discrete and continuous domains. Weexperimentally demonstrate the importance of hierarchical smoothing in imageand node classification, where it yields superior robustness-accuracytrade-offs. Overall, hierarchical smoothing is an important contributiontowards models that are both - certifiably robust to perturbations andaccurate.</description><author>Yan Scholten, Jan Schuchardt, Aleksandar Bojchevski, Stephan Günnemann</author><pubDate>Fri, 05 Jan 2024 15:43:12 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.16221v3</guid></item><item><title>Patterns of Persistence and Diffusibility across the World's Languages</title><link>http://arxiv.org/abs/2401.01698v2</link><description>Language similarities can be caused by genetic relatedness, areal contact,universality, or chance. Colexification, i.e. a type of similarity where asingle lexical form is used to convey multiple meanings, is underexplored. Inour work, we shed light on the linguistic causes of cross-lingual similarity incolexification and phonology, by exploring genealogical stability (persistence)and contact-induced change (diffusibility). We construct large-scale graphsincorporating semantic, genealogical, phonological and geographical data for1,966 languages. We then show the potential of this resource, by investigatingseveral established hypotheses from previous work in linguistics, whileproposing new ones. Our results strongly support a previously establishedhypothesis in the linguistic literature, while offering contradicting evidenceto another. Our large scale resource opens for further research acrossdisciplines, e.g.~in multilingual NLP and comparative linguistics.</description><author>Yiyi Chen, Johannes Bjerva</author><pubDate>Fri, 05 Jan 2024 15:33:40 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.01698v2</guid></item><item><title>Reversing the Irreversible: A Survey on Inverse Biometrics</title><link>http://arxiv.org/abs/2401.02861v1</link><description>With the widespread use of biometric recognition, several issues related tothe privacy and security provided by this technology have been recently raisedand analysed. As a result, the early common belief among the biometricscommunity of templates irreversibility has been proven wrong. It is now anaccepted fact that it is possible to reconstruct from an unprotected template asynthetic sample that matches the bona fide one. This reverse engineeringprocess, commonly referred to as \textit{inverse biometrics}, constitutes asevere threat for biometric systems from two different angles: on the one hand,sensitive personal data (i.e., biometric data) can be derived from compromisedunprotected templates; on the other hand, other powerful attacks can belaunched building upon these reconstructed samples. Given its importantimplications, biometric stakeholders have produced over the last fifteen yearsnumerous works analysing the different aspects related to inverse biometrics:development of reconstruction algorithms for different characteristics;proposal of methodologies to assess the vulnerabilities of biometric systems tothe aforementioned algorithms; development of countermeasures to reduce thepossible effects of attacks. The present article is an effort to condense allthis information in one comprehensive review of: the problem itself, theevaluation of the problem, and the mitigation of the problem. The presentarticle is an effort to condense all this information in one comprehensivereview of: the problem itself, the evaluation of the problem, and themitigation of the problem.</description><author>Marta Gomez-Barrero, Javier Galbally</author><pubDate>Fri, 05 Jan 2024 15:32:40 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.02861v1</guid></item><item><title>Framework for Variable-lag Motif Following Relation Inference In Time Series using Matrix Profile analysis</title><link>http://arxiv.org/abs/2401.02860v1</link><description>Knowing who follows whom and what patterns they are following are crucialsteps to understand collective behaviors (e.g. a group of human, a school offish, or a stock market). Time series is one of resources that can be used toget insight regarding following relations. However, the concept of followingpatterns or motifs and the solution to find them in time series are notobvious. In this work, we formalize a concept of following motifs between twotime series and present a framework to infer following patterns between twotime series. The framework utilizes one of efficient and scalable methods toretrieve motifs from time series called the Matrix Profile Method. We compareour proposed framework with several baselines. The framework performs betterthan baselines in the simulation datasets. In the dataset of sound recording,the framework is able to retrieve the following motifs within a pair of timeseries that two singers sing following each other. In the cryptocurrencydataset, the framework is capable of capturing the following motifs within apair of time series from two digital currencies, which implies that the valuesof one currency follow the values of another currency patterns. Our frameworkcan be utilized in any field of time series to get insight regarding followingpatterns between time series.</description><author>Naaek Chinpattanakarn, Chainarong Amornbunchornvej</author><pubDate>Fri, 05 Jan 2024 15:32:24 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.02860v1</guid></item><item><title>Generative Large Language Models are autonomous practitioners of evidence-based medicine</title><link>http://arxiv.org/abs/2401.02851v1</link><description>Background: Evidence-based medicine (EBM) is fundamental to modern clinicalpractice, requiring clinicians to continually update their knowledge and applythe best clinical evidence in patient care. The practice of EBM faceschallenges due to rapid advancements in medical research, leading toinformation overload for clinicians. The integration of artificial intelligence(AI), specifically Generative Large Language Models (LLMs), offers a promisingsolution towards managing this complexity. Methods: This study involved the curation of real-world clinical cases acrossvarious specialties, converting them into .json files for analysis. LLMs,including proprietary models like ChatGPT 3.5 and 4, Gemini Pro, andopen-source models like LLaMA v2 and Mixtral-8x7B, were employed. These modelswere equipped with tools to retrieve information from case files and makeclinical decisions similar to how clinicians must operate in the real world.Model performance was evaluated based on correctness of final answer, judicioususe of tools, conformity to guidelines, and resistance to hallucinations. Results: GPT-4 was most capable of autonomous operation in a clinicalsetting, being generally more effective in ordering relevant investigations andconforming to clinical guidelines. Limitations were observed in terms of modelability to handle complex guidelines and diagnostic nuances. RetrievalAugmented Generation made recommendations more tailored to patients andhealthcare systems. Conclusions: LLMs can be made to function as autonomous practitioners ofevidence-based medicine. Their ability to utilize tooling can be harnessed tointeract with the infrastructure of a real-world healthcare system and performthe tasks of patient management in a guideline directed manner. Promptengineering may help to further enhance this potential and transform healthcarefor the clinician and the patient.</description><author>Akhil Vaid, Joshua Lampert, Juhee Lee, Ashwin Sawant, Donald Apakama, Ankit Sakhuja, Ali Soroush, Denise Lee, Isotta Landi, Nicole Bussola, Ismail Nabeel, Robbie Freeman, Patricia Kovatch, Brendan Carr, Benjamin Glicksberg, Edgar Argulian, Stamatios Lerakis, Monica Kraft, Alexander Charney, Girish Nadkarni</author><pubDate>Fri, 05 Jan 2024 15:09:57 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.02851v1</guid></item><item><title>Generating Non-Stationary Textures using Self-Rectification</title><link>http://arxiv.org/abs/2401.02847v1</link><description>This paper addresses the challenge of example-based non-stationary texturesynthesis. We introduce a novel twostep approach wherein users first modify areference texture using standard image editing tools, yielding an initial roughtarget for the synthesis. Subsequently, our proposed method, termed"self-rectification", automatically refines this target into a coherent,seamless texture, while faithfully preserving the distinct visualcharacteristics of the reference exemplar. Our method leverages a pre-traineddiffusion network, and uses self-attention mechanisms, to gradually align thesynthesized texture with the reference, ensuring the retention of thestructures in the provided target. Through experimental validation, ourapproach exhibits exceptional proficiency in handling non-stationary textures,demonstrating significant advancements in texture synthesis when compared toexisting state-of-the-art techniques. Code is available athttps://github.com/xiaorongjun000/Self-Rectification</description><author>Yang Zhou, Rongjun Xiao, Dani Lischinski, Daniel Cohen-Or, Hui Huang</author><pubDate>Fri, 05 Jan 2024 15:07:05 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.02847v1</guid></item><item><title>Thousands of AI Authors on the Future of AI</title><link>http://arxiv.org/abs/2401.02843v1</link><description>In the largest survey of its kind, 2,778 researchers who had published intop-tier artificial intelligence (AI) venues gave predictions on the pace of AIprogress and the nature and impacts of advanced AI systems The aggregateforecasts give at least a 50% chance of AI systems achieving several milestonesby 2028, including autonomously constructing a payment processing site fromscratch, creating a song indistinguishable from a new song by a popularmusician, and autonomously downloading and fine-tuning a large language model.If science continues undisrupted, the chance of unaided machines outperforminghumans in every possible task was estimated at 10% by 2027, and 50% by 2047.The latter estimate is 13 years earlier than that reached in a similar surveywe conducted only one year earlier [Grace et al., 2022]. However, the chance ofall human occupations becoming fully automatable was forecast to reach 10% by2037, and 50% as late as 2116 (compared to 2164 in the 2022 survey). Most respondents expressed substantial uncertainty about the long-term valueof AI progress: While 68.3% thought good outcomes from superhuman AI are morelikely than bad, of these net optimists 48% gave at least a 5% chance ofextremely bad outcomes such as human extinction, and 59% of net pessimists gave5% or more to extremely good outcomes. Between 38% and 51% of respondents gaveat least a 10% chance to advanced AI leading to outcomes as bad as humanextinction. More than half suggested that "substantial" or "extreme" concern iswarranted about six different AI-related scenarios, including misinformation,authoritarian control, and inequality. There was disagreement about whetherfaster or slower AI progress would be better for the future of humanity.However, there was broad agreement that research aimed at minimizing potentialrisks from AI systems ought to be prioritized more.</description><author>Katja Grace, Harlan Stewart, Julia Fabienne Sandkühler, Stephen Thomas, Ben Weinstein-Raun, Jan Brauner</author><pubDate>Fri, 05 Jan 2024 14:53:09 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.02843v1</guid></item><item><title>Multi-Stage Contrastive Regression for Action Quality Assessment</title><link>http://arxiv.org/abs/2401.02841v1</link><description>In recent years, there has been growing interest in the video-based actionquality assessment (AQA). Most existing methods typically solve AQA problem byconsidering the entire video yet overlooking the inherent stage-levelcharacteristics of actions. To address this issue, we design a novelMulti-stage Contrastive Regression (MCoRe) framework for the AQA task. Thisapproach allows us to efficiently extract spatial-temporal information, whilesimultaneously reducing computational costs by segmenting the input video intomultiple stages or procedures. Inspired by the graph contrastive learning, wepropose a new stage-wise contrastive learning loss function to enhanceperformance. As a result, MCoRe demonstrates the state-of-the-art result so faron the widely-adopted fine-grained AQA dataset.</description><author>Qi An, Mengshi Qi, Huadong Ma</author><pubDate>Fri, 05 Jan 2024 14:48:19 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.02841v1</guid></item><item><title>Pheme: Efficient and Conversational Speech Generation</title><link>http://arxiv.org/abs/2401.02839v1</link><description>In recent years, speech generation has seen remarkable progress, nowachieving one-shot generation capability that is often virtuallyindistinguishable from real human voice. Integrating such advancements inspeech generation with large language models might revolutionize a wide rangeof applications. However, certain applications, such as assistiveconversational systems, require natural and conversational speech generationtools that also operate efficiently in real time. Current state-of-the-artmodels like VALL-E and SoundStorm, powered by hierarchical neural audio codecs,require large neural components and extensive training data to work well. Incontrast, MQTTS aims to build more compact conversational TTS models whilecapitalizing on smaller-scale real-life conversational speech data. However,its autoregressive nature yields high inference latency and thus limits itsreal-time usage. In order to mitigate the current limitations of thestate-of-the-art TTS models while capitalizing on their strengths, in this workwe introduce the Pheme model series that 1) offers compact yet high-performingmodels, 2) allows for parallel speech generation of 3) natural conversationalspeech, and 4) it can be trained efficiently on smaller-scale conversationaldata, cutting data demands by more than 10x but still matching the quality ofthe autoregressive TTS models. We also show that through simple teacher-studentdistillation we can meet significant improvements in voice quality forsingle-speaker setups on top of pretrained Pheme checkpoints, relying solely onsynthetic speech generated by much larger teacher models. Audio samples andpretrained models are available online.</description><author>Paweł Budzianowski, Taras Sereda, Tomasz Cichy, Ivan Vulić</author><pubDate>Fri, 05 Jan 2024 14:47:20 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.02839v1</guid></item><item><title>Anatomy-aware and acquisition-agnostic joint registration with SynthMorph</title><link>http://arxiv.org/abs/2301.11329v2</link><description>Affine image registration is a cornerstone of medical-image analysis. Whileclassical algorithms can achieve excellent accuracy, they solve atime-consuming optimization for every image pair. Deep-learning (DL) methodslearn a function that maps an image pair to an output transform. Evaluating thefunction is fast, but capturing large transforms can be challenging, andnetworks tend to struggle if a test-image characteristic shifts from thetraining domain, such as resolution. Most affine methods are agnostic toanatomy, meaning the registration will be inaccurate if algorithms consider allstructures in the image. We address these shortcomings with SynthMorph, an easy-to-use DL tool forjoint affine-deformable registration of any brain image without preprocessing,right off the MRI scanner. First, we leverage a strategy to train networks withwildly varying images synthesized from label maps, yielding robust performanceacross acquisition specifics unseen at training. Second, we optimize thespatial overlap of select anatomical labels. This enables networks todistinguish anatomy of interest from irrelevant structures, removing the needfor preprocessing that excludes content which would impinge on anatomy-specificregistration. Third, we combine the affine model with a deformable hypernetworkthat lets users choose the optimal deformation-field regularity for theirspecific data, at registration time, in a fraction of the time required byclassical methods. We rigorously analyze how competing architectures learn affine transforms andcompare state-of-the-art registration tools across an extremely diverse set ofneuroimaging data, aiming to truly capture the behavior of methods in the realworld. SynthMorph demonstrates consistent and improved accuracy. It isavailable at https://w3id.org/synthmorph, as a single complete end-to-endsolution for registration of brain MRI.</description><author>Malte Hoffmann, Andrew Hoopes, Douglas N. Greve, Bruce Fischl, Adrian V. Dalca</author><pubDate>Thu, 04 Jan 2024 18:59:56 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2301.11329v2</guid></item><item><title>Learning to Prompt with Text Only Supervision for Vision-Language Models</title><link>http://arxiv.org/abs/2401.02418v1</link><description>Foundational vision-language models such as CLIP are becoming a new paradigmin vision, due to their excellent generalization abilities. However, adaptingthese models for downstream tasks while maintaining their generalizationremains a challenge. In literature, one branch of methods adapts CLIP bylearning prompts using visual information. While effective, most of these worksrequire labeled data which is not practical, and often struggle to generalizetowards new datasets due to over-fitting on the source data. An alternativeapproach resorts to training-free methods by generating class descriptions fromlarge language models (LLMs) and perform prompt ensembling. However, thesemethods often generate class specific prompts that cannot be transferred toother classes, which incur higher costs by generating LLM descriptions for eachclass separately. In this work, we propose to combine the strengths of theseboth streams of methods by learning prompts using only text data derived fromLLMs. As supervised training of prompts is not trivial due to absence ofimages, we develop a training approach that allows prompts to extract richcontextual knowledge from LLM data. Moreover, with LLM contextual data mappedwithin the learned prompts, it enables zero-shot transfer of prompts to newclasses and datasets potentially cutting the LLM prompt engineering cost. Tothe best of our knowledge, this is the first work that learns generalizedprompts using text only data. We perform extensive evaluations on 4 benchmarkswhere our method improves over prior ensembling works while being competitiveto those utilizing labeled images. Our code and pre-trained models areavailable at https://github.com/muzairkhattak/ProText.</description><author>Muhammad Uzair Khattak, Muhammad Ferjad Naeem, Muzammal Naseer, Luc Van Gool, Federico Tombari</author><pubDate>Thu, 04 Jan 2024 18:59:49 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.02418v1</guid></item><item><title>Task Oriented Dialogue as a Catalyst for Self-Supervised Automatic Speech Recognition</title><link>http://arxiv.org/abs/2401.02417v1</link><description>While word error rates of automatic speech recognition (ASR) systems haveconsistently fallen, natural language understanding (NLU) applications built ontop of ASR systems still attribute significant numbers of failures tolow-quality speech recognition results. Existing assistant systems collectlarge numbers of these unsuccessful interactions, but these systems usuallyfail to learn from these interactions, even in an offline fashion. In thiswork, we introduce CLC: Contrastive Learning for Conversations, a family ofmethods for contrastive fine-tuning of models in a self-supervised fashion,making use of easily detectable artifacts in unsuccessful conversations withassistants. We demonstrate that our CLC family of approaches can improve theperformance of ASR models on OD3, a new public large-scale semi-syntheticmeta-dataset of audio task-oriented dialogues, by up to 19.2%. These gainstransfer to real-world systems as well, where we show that CLC can help toimprove performance by up to 6.7% over baselines. We make OD3 publiclyavailable at https://github.com/amazon-science/amazon-od3 .</description><author>David M. Chan, Shalini Ghosh, Hitesh Tulsiani, Ariya Rastrow, Björn Hoffmeister</author><pubDate>Thu, 04 Jan 2024 18:59:31 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.02417v1</guid></item><item><title>ODIN: A Single Model for 2D and 3D Perception</title><link>http://arxiv.org/abs/2401.02416v1</link><description>State-of-the-art models on contemporary 3D perception benchmarks like ScanNetconsume and label dataset-provided 3D point clouds, obtained through postprocessing of sensed multiview RGB-D images. They are typically trainedin-domain, forego large-scale 2D pre-training and outperform alternatives thatfeaturize the posed RGB-D multiview images instead. The gap in performancebetween methods that consume posed images versus post-processed 3D point cloudshas fueled the belief that 2D and 3D perception require distinct modelarchitectures. In this paper, we challenge this view and propose ODIN(Omni-Dimensional INstance segmentation), a model that can segment and labelboth 2D RGB images and 3D point clouds, using a transformer architecture thatalternates between 2D within-view and 3D cross-view information fusion. Ourmodel differentiates 2D and 3D feature operations through the positionalencodings of the tokens involved, which capture pixel coordinates for 2D patchtokens and 3D coordinates for 3D feature tokens. ODIN achieves state-of-the-artperformance on ScanNet200, Matterport3D and AI2THOR 3D instance segmentationbenchmarks, and competitive performance on ScanNet, S3DIS and COCO. Itoutperforms all previous works by a wide margin when the sensed 3D point cloudis used in place of the point cloud sampled from 3D mesh. When used as the 3Dperception engine in an instructable embodied agent architecture, it sets a newstate-of-the-art on the TEACh action-from-dialogue benchmark. Our code andcheckpoints can be found at the project website: https://odin-seg.github.io.</description><author>Ayush Jain, Pushkal Katara, Nikolaos Gkanatsios, Adam W. Harley, Gabriel Sarch, Kriti Aggarwal, Vishrav Chaudhary, Katerina Fragkiadaki</author><pubDate>Thu, 04 Jan 2024 18:59:25 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.02416v1</guid></item><item><title>LLaMA Pro: Progressive LLaMA with Block Expansion</title><link>http://arxiv.org/abs/2401.02415v1</link><description>Humans generally acquire new skills without compromising the old; however,the opposite holds for Large Language Models (LLMs), e.g., from LLaMA toCodeLLaMA. To this end, we propose a new post-pretraining method for LLMs withan expansion of Transformer blocks. We tune the expanded blocks using only newcorpus, efficiently and effectively improving the model's knowledge withoutcatastrophic forgetting. In this paper, we experiment on the corpus of code andmath, yielding LLaMA Pro-8.3B, a versatile foundation model initialized fromLLaMA2-7B, excelling in general tasks, programming, and mathematics. LLaMA Proand its instruction-following counterpart (LLaMA Pro-Instruct) achieve advancedperformance among various benchmarks, demonstrating superiority over existingopen models in the LLaMA family and the immense potential of reasoning andaddressing diverse tasks as an intelligent agent. Our findings provide valuableinsights into integrating natural and programming languages, laying a solidfoundation for developing advanced language agents that operate effectively invarious environments.</description><author>Chengyue Wu, Yukang Gan, Yixiao Ge, Zeyu Lu, Jiahao Wang, Ye Feng, Ping Luo, Ying Shan</author><pubDate>Thu, 04 Jan 2024 18:59:12 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.02415v1</guid></item><item><title>Controlling Moments with Kernel Stein Discrepancies</title><link>http://arxiv.org/abs/2211.05408v2</link><description>Kernel Stein discrepancies (KSDs) measure the quality of a distributionalapproximation and can be computed even when the target density has anintractable normalizing constant. Notable applications include the diagnosis ofapproximate MCMC samplers and goodness-of-fit tests for unnormalizedstatistical models. The present work analyzes the convergence controlproperties of KSDs. We first show that standard KSDs used for weak convergencecontrol fail to control moment convergence. To address this limitation, we nextprovide sufficient conditions under which alternative diffusion KSDs controlboth moment and weak convergence. As an immediate consequence we develop, foreach $q &gt; 0$, the first KSDs known to exactly characterize $q$-Wassersteinconvergence.</description><author>Heishiro Kanagawa, Alessandro Barp, Arthur Gretton, Lester Mackey</author><pubDate>Thu, 04 Jan 2024 18:55:56 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2211.05408v2</guid></item><item><title>Bring Metric Functions into Diffusion Models</title><link>http://arxiv.org/abs/2401.02414v1</link><description>We introduce a Cascaded Diffusion Model (Cas-DM) that improves a DenoisingDiffusion Probabilistic Model (DDPM) by effectively incorporating additionalmetric functions in training. Metric functions such as the LPIPS loss have beenproven highly effective in consistency models derived from the score matching.However, for the diffusion counterparts, the methodology and efficacy of addingextra metric functions remain unclear. One major challenge is the mismatchbetween the noise predicted by a DDPM at each step and the desired clean imagethat the metric function works well on. To address this problem, we proposeCas-DM, a network architecture that cascades two network modules to effectivelyapply metric functions to the diffusion model training. The first module,similar to a standard DDPM, learns to predict the added noise and is unaffectedby the metric function. The second cascaded module learns to predict the cleanimage, thereby facilitating the metric function computation. Experiment resultsshow that the proposed diffusion model backbone enables the effective use ofthe LPIPS loss, leading to state-of-the-art image quality (FID, sFID, IS) onvarious established benchmarks.</description><author>Jie An, Zhengyuan Yang, Jianfeng Wang, Linjie Li, Zicheng Liu, Lijuan Wang, Jiebo Luo</author><pubDate>Thu, 04 Jan 2024 18:55:01 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.02414v1</guid></item><item><title>Simulation-Based Inference with Quantile Regression</title><link>http://arxiv.org/abs/2401.02413v1</link><description>We present Neural Quantile Estimation (NQE), a novel Simulation-BasedInference (SBI) method based on conditional quantile regression. NQEautoregressively learns individual one dimensional quantiles for each posteriordimension, conditioned on the data and previous posterior dimensions. Posteriorsamples are obtained by interpolating the predicted quantiles using monotoniccubic Hermite spline, with specific treatment for the tail behavior andmulti-modal distributions. We introduce an alternative definition for theBayesian credible region using the local Cumulative Density Function (CDF),offering substantially faster evaluation than the traditional Highest PosteriorDensity Region (HPDR). In case of limited simulation budget and/or known modelmisspecification, a post-processing broadening step can be integrated into NQEto ensure the unbiasedness of the posterior estimation with negligibleadditional computational cost. We demonstrate that the proposed NQE methodachieves state-of-the-art performance on a variety of benchmark problems.</description><author>He Jia</author><pubDate>Thu, 04 Jan 2024 18:53:50 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.02413v1</guid></item><item><title>LLM Augmented LLMs: Expanding Capabilities through Composition</title><link>http://arxiv.org/abs/2401.02412v1</link><description>Foundational models with billions of parameters which have been trained onlarge corpora of data have demonstrated non-trivial skills in a variety ofdomains. However, due to their monolithic structure, it is challenging andexpensive to augment them or impart new skills. On the other hand, due to theiradaptation abilities, several new instances of these models are being trainedtowards new domains and tasks. In this work, we study the problem of efficientand practical composition of existing foundation models with more specificmodels to enable newer capabilities. To this end, we propose CALM --Composition to Augment Language Models -- which introduces cross-attentionbetween models to compose their representations and enable new capabilities.Salient features of CALM are: (i) Scales up LLMs on new tasks by 're-using'existing LLMs along with a few additional parameters and data, (ii) Existingmodel weights are kept intact, and hence preserves existing capabilities, and(iii) Applies to diverse domains and settings. We illustrate that augmentingPaLM2-S with a smaller model trained on low-resource languages results in anabsolute improvement of up to 13\% on tasks like translation into English andarithmetic reasoning for low-resource languages. Similarly, when PaLM2-S isaugmented with a code-specific model, we see a relative improvement of 40\%over the base model for code generation and explanation tasks -- on-par withfully fine-tuned counterparts.</description><author>Rachit Bansal, Bidisha Samanta, Siddharth Dalmia, Nitish Gupta, Shikhar Vashishth, Sriram Ganapathy, Abhishek Bapna, Prateek Jain, Partha Talukdar</author><pubDate>Thu, 04 Jan 2024 18:53:01 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.02412v1</guid></item><item><title>What You See is What You GAN: Rendering Every Pixel for High-Fidelity Geometry in 3D GANs</title><link>http://arxiv.org/abs/2401.02411v1</link><description>3D-aware Generative Adversarial Networks (GANs) have shown remarkableprogress in learning to generate multi-view-consistent images and 3D geometriesof scenes from collections of 2D images via neural volume rendering. Yet, thesignificant memory and computational costs of dense sampling in volumerendering have forced 3D GANs to adopt patch-based training or employlow-resolution rendering with post-processing 2D super resolution, whichsacrifices multiview consistency and the quality of resolved geometry.Consequently, 3D GANs have not yet been able to fully resolve the rich 3Dgeometry present in 2D images. In this work, we propose techniques to scaleneural volume rendering to the much higher resolution of native 2D images,thereby resolving fine-grained 3D geometry with unprecedented detail. Ourapproach employs learning-based samplers for accelerating neural rendering for3D GAN training using up to 5 times fewer depth samples. This enables us toexplicitly "render every pixel" of the full-resolution image during trainingand inference without post-processing superresolution in 2D. Together with ourstrategy to learn high-quality surface geometry, our method synthesizeshigh-resolution 3D geometry and strictly view-consistent images whilemaintaining image quality on par with baselines relying on post-processingsuper resolution. We demonstrate state-of-the-art 3D gemetric quality on FFHQand AFHQ, setting a new standard for unsupervised learning of 3D shapes in 3DGANs.</description><author>Alex Trevithick, Matthew Chan, Towaki Takikawa, Umar Iqbal, Shalini De Mello, Manmohan Chandraker, Ravi Ramamoorthi, Koki Nagano</author><pubDate>Thu, 04 Jan 2024 18:50:38 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.02411v1</guid></item><item><title>Evaluating Language-Model Agents on Realistic Autonomous Tasks</title><link>http://arxiv.org/abs/2312.11671v2</link><description>In this report, we explore the ability of language model agents to acquireresources, create copies of themselves, and adapt to novel challenges theyencounter in the wild. We refer to this cluster of capabilities as "autonomousreplication and adaptation" or ARA. We believe that systems capable of ARAcould have wide-reaching and hard-to-anticipate consequences, and thatmeasuring and forecasting ARA may be useful for informing measures aroundsecurity, monitoring, and alignment. Additionally, once a system is capable ofARA, placing bounds on a system's capabilities may become significantly moredifficult. We construct four simple example agents that combine language models withtools that allow them to take actions in the world. We then evaluate theseagents on 12 tasks relevant to ARA. We find that these language model agentscan only complete the easiest tasks from this list, although they make someprogress on the more challenging tasks. Unfortunately, these evaluations arenot adequate to rule out the possibility that near-future agents will becapable of ARA. In particular, we do not think that these evaluations providegood assurance that the ``next generation'' of language models (e.g. 100xeffective compute scaleup on existing models) will not yield agents capable ofARA, unless intermediate evaluations are performed during pretraining.Relatedly, we expect that fine-tuning of the existing models could producesubstantially more competent agents, even if the fine-tuning is not directlytargeted at ARA.</description><author>Megan Kinniment, Lucas Jun Koba Sato, Haoxing Du, Brian Goodrich, Max Hasin, Lawrence Chan, Luke Harold Miles, Tao R. Lin, Hjalmar Wijk, Joel Burget, Aaron Ho, Elizabeth Barnes, Paul Christiano</author><pubDate>Thu, 04 Jan 2024 18:46:39 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.11671v2</guid></item><item><title>Sliced gradient-enhanced Kriging for high-dimensional function approximation</title><link>http://arxiv.org/abs/2204.03562v3</link><description>Gradient-enhanced Kriging (GE-Kriging) is a well-established surrogatemodelling technique for approximating expensive computational models. However,it tends to get impractical for high-dimensional problems due to the size ofthe inherent correlation matrix and the associated high-dimensionalhyper-parameter tuning problem. To address these issues, a new method, calledsliced GE-Kriging (SGE-Kriging), is developed in this paper for reducing boththe size of the correlation matrix and the number of hyper-parameters. We firstsplit the training sample set into multiple slices, and invoke Bayes' theoremto approximate the full likelihood function via a sliced likelihood function,in which multiple small correlation matrices are utilized to describe thecorrelation of the sample set rather than one large one. Then, we replace theoriginal high-dimensional hyper-parameter tuning problem with a low-dimensionalcounterpart by learning the relationship between the hyper-parameters and thederivative-based global sensitivity indices. The performance of SGE-Kriging isfinally validated by means of numerical experiments with several benchmarks anda high-dimensional aerodynamic modeling problem. The results show that theSGE-Kriging model features an accuracy and robustness that is comparable to thestandard one but comes at much less training costs. The benefits are mostevident for high-dimensional problems with tens of variables.</description><author>Kai Cheng, Ralf Zimmermann</author><pubDate>Thu, 04 Jan 2024 18:42:31 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2204.03562v3</guid></item><item><title>Real-Time 2D Temperature Field Prediction in Metal Additive Manufacturing Using Physics-Informed Neural Networks</title><link>http://arxiv.org/abs/2401.02403v1</link><description>Accurately predicting the temperature field in metal additive manufacturing(AM) processes is critical to preventing overheating, adjusting processparameters, and ensuring process stability. While physics-based computationalmodels offer precision, they are often time-consuming and unsuitable forreal-time predictions and online control in iterative design scenarios.Conversely, machine learning models rely heavily on high-quality datasets,which can be costly and challenging to obtain within the metal AM domain. Ourwork addresses this by introducing a physics-informed neural network frameworkspecifically designed for temperature field prediction in metal AM. Thisframework incorporates a physics-informed input, physics-informed lossfunction, and a Convolutional Long Short-Term Memory (ConvLSTM) architecture.Utilizing real-time temperature data from the process, our model predicts 2Dtemperature fields for future timestamps across diverse geometries, depositionpatterns, and process parameters. We validate the proposed framework in twoscenarios: full-field temperature prediction for a thin wall and 2D temperaturefield prediction for cylinder and cubic parts, demonstrating errors below 3%and 1%, respectively. Our proposed framework exhibits the flexibility to beapplied across diverse scenarios with varying process parameters, geometries,and deposition patterns.</description><author>Pouyan Sajadi, Mostafa Rahmani Dehaghani, Yifan Tang, G. Gary Wang</author><pubDate>Thu, 04 Jan 2024 18:42:28 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.02403v1</guid></item><item><title>3D Open-Vocabulary Panoptic Segmentation with 2D-3D Vision-Language Distillation</title><link>http://arxiv.org/abs/2401.02402v1</link><description>3D panoptic segmentation is a challenging perception task, which aims topredict both semantic and instance annotations for 3D points in a scene.Although prior 3D panoptic segmentation approaches have achieved greatperformance on closed-set benchmarks, generalizing to novel categories remainsan open problem. For unseen object categories, 2D open-vocabulary segmentationhas achieved promising results that solely rely on frozen CLIP backbones andensembling multiple classification outputs. However, we find that simplyextending these 2D models to 3D does not achieve good performance due to poorper-mask classification quality on novel categories. In this paper, we proposethe first method to tackle 3D open-vocabulary panoptic segmentation. Our modeltakes advantage of the fusion between learnable LiDAR features and dense frozenvision CLIP features, using a single classification head to make predictionsfor both base and novel classes. To further improve the classificationperformance on novel classes and leverage the CLIP model, we propose two novelloss functions: object-level distillation loss and voxel-level distillationloss. Our experiments on the nuScenes and SemanticKITTI datasets show that ourmethod outperforms strong baselines by a large margin.</description><author>Zihao Xiao, Longlong Jing, Shangxuan Wu, Alex Zihao Zhu, Jingwei Ji, Chiyu Max Jiang, Wei-Chih Hung, Thomas Funkhouser, Weicheng Kuo, Anelia Angelova, Yin Zhou, Shiwei Sheng</author><pubDate>Thu, 04 Jan 2024 18:39:32 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.02402v1</guid></item><item><title>Learning to Generalize towards Unseen Domains via a Content-Aware Style Invariant Model for Disease Detection from Chest X-rays</title><link>http://arxiv.org/abs/2302.13991v3</link><description>Performance degradation due to distribution discrepancy is a longstandingchallenge in intelligent imaging, particularly for chest X-rays (CXRs). Recentstudies have demonstrated that CNNs are biased toward styles (e.g.,uninformative textures) rather than content (e.g., shape), in stark contrast tothe human vision system. Radiologists tend to learn visual cues from CXRs andthus perform well across multiple domains. Motivated by this, we employ thenovel on-the-fly style randomization modules at both image (SRM-IL) and feature(SRM-FL) levels to create rich style perturbed features while keeping thecontent intact for robust cross-domain performance. Previous methods simulateunseen domains by constructing new styles via interpolation or swapping stylesfrom existing data, limiting them to available source domains during training.However, SRM-IL samples the style statistics from the possible value range of aCXR image instead of the training data to achieve more diversifiedaugmentations. Moreover, we utilize pixel-wise learnable parameters in theSRM-FL compared to pre-defined channel-wise mean and standard deviations asstyle embeddings for capturing more representative style features.Additionally, we leverage consistency regularizations on global semanticfeatures and predictive distributions from with and without style-perturbedversions of the same CXR to tweak the model's sensitivity toward contentmarkers for accurate predictions. Our proposed method, trained on CheXpert andMIMIC-CXR datasets, achieves 77.32$\pm$0.35, 88.38$\pm$0.19, 82.63$\pm$0.13AUCs(%) on the unseen domain test datasets, i.e., BRAX, VinDr-CXR, and NIHchest X-ray14, respectively, compared to 75.56$\pm$0.80, 87.57$\pm$0.46,82.07$\pm$0.19 from state-of-the-art models on five-fold cross-validation withstatistically significant results in thoracic disease classification.</description><author>Mohammad Zunaed, Md. Aynal Haque, Taufiq Hasan</author><pubDate>Thu, 04 Jan 2024 18:35:21 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2302.13991v3</guid></item><item><title>Learning the 3D Fauna of the Web</title><link>http://arxiv.org/abs/2401.02400v1</link><description>Learning 3D models of all animals on the Earth requires massively scaling upexisting solutions. With this ultimate goal in mind, we develop 3D-Fauna, anapproach that learns a pan-category deformable 3D animal model for more than100 animal species jointly. One crucial bottleneck of modeling animals is thelimited availability of training data, which we overcome by simply learningfrom 2D Internet images. We show that prior category-specific attempts fail togeneralize to rare species with limited training images. We address thischallenge by introducing the Semantic Bank of Skinned Models (SBSM), whichautomatically discovers a small set of base animal shapes by combininggeometric inductive priors with semantic knowledge implicitly captured by anoff-the-shelf self-supervised feature extractor. To train such a model, we alsocontribute a new large-scale dataset of diverse animal species. At inferencetime, given a single image of any quadruped animal, our model reconstructs anarticulated 3D mesh in a feed-forward fashion within seconds.</description><author>Zizhang Li, Dor Litvak, Ruining Li, Yunzhi Zhang, Tomas Jakab, Christian Rupprecht, Shangzhe Wu, Andrea Vedaldi, Jiajun Wu</author><pubDate>Thu, 04 Jan 2024 18:32:48 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.02400v1</guid></item><item><title>Generating synthetic data for neural operators</title><link>http://arxiv.org/abs/2401.02398v1</link><description>Numerous developments in the recent literature show the promising potentialof deep learning in obtaining numerical solutions to partial differentialequations (PDEs) beyond the reach of current numerical solvers. However,data-driven neural operators all suffer from the same problem: the data neededto train a network depends on classical numerical solvers such as finitedifference or finite element, among others. In this paper, we propose a newapproach to generating synthetic functional training data that does not requiresolving a PDE numerically. The way we do this is simple: we draw a large number$N$ of independent and identically distributed `random functions' $u_j$ fromthe underlying solution space (e.g., $H_0^1(\Omega)$) in which we know thesolution lies according to classical theory. We then plug each such randomcandidate solution into the equation and get a corresponding right-hand sidefunction $f_j$ for the equation, and consider $(f_j, u_j)_{j=1}^N$ assupervised training data for learning the underlying inverse problem $f\rightarrow u$. This `backwards' approach to generating training data onlyrequires derivative computations, in contrast to standard `forward' approaches,which require a numerical PDE solver, enabling us to generate a large number ofsuch data points quickly and efficiently. While the idea is simple, we hopethat this method will expand the potential for developing neural PDE solversthat do not depend on classical numerical solvers.</description><author>Erisa Hasani, Rachel A. Ward</author><pubDate>Thu, 04 Jan 2024 18:31:21 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.02398v1</guid></item><item><title>One Shot Learning as Instruction Data Prospector for Large Language Models</title><link>http://arxiv.org/abs/2312.10302v3</link><description>Aligning large language models(LLMs) with human is a critical step ineffectively utilizing their pre-trained capabilities across a wide array oflanguage tasks. Current instruction tuning practices often rely on expandingdataset size without a clear strategy for ensuring data quality, which caninadvertently introduce noise and degrade model performance. To address thischallenge, we introduce Nuggets, a novel and efficient methodology that employsone shot learning to select high-quality instruction data from expansivedatasets. Nuggets assesses the potential of individual instruction examples toact as effective one shot examples, thereby identifying those that cansignificantly enhance diverse task performance. Nuggets utilizes a scoringsystem based on the impact of candidate examples on the perplexity of a diverseanchor set, facilitating the selection of the most beneficial data forinstruction tuning. Through rigorous testing on two benchmarks, includingMT-Bench and Alpaca-Eval, we demonstrate that instruction tuning with the top1% of Nuggets-curated examples substantially outperforms conventional methodsthat use the full dataset. These findings advocate for a data selectionparadigm that prioritizes quality, offering a more efficient pathway to alignLLMs with humans.</description><author>Yunshui Li, Binyuan Hui, Xiaobo Xia, Jiaxi Yang, Min Yang, Lei Zhang, Shuzheng Si, Junhao Liu, Tongliang Liu, Fei Huang, Yongbin Li</author><pubDate>Thu, 04 Jan 2024 18:00:11 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.10302v3</guid></item><item><title>UpFusion: Novel View Diffusion from Unposed Sparse View Observations</title><link>http://arxiv.org/abs/2312.06661v2</link><description>We propose UpFusion, a system that can perform novel view synthesis and infer3D representations for an object given a sparse set of reference images withoutcorresponding pose information. Current sparse-view 3D inference methodstypically rely on camera poses to geometrically aggregate information frominput views, but are not robust in-the-wild when such information isunavailable/inaccurate. In contrast, UpFusion sidesteps this requirement bylearning to implicitly leverage the available images as context in aconditional generative model for synthesizing novel views. We incorporate twocomplementary forms of conditioning into diffusion models for leveraging theinput views: a) via inferring query-view aligned features using a scene-leveltransformer, b) via intermediate attentional layers that can directly observethe input image tokens. We show that this mechanism allows generatinghigh-fidelity novel views while improving the synthesis quality givenadditional (unposed) images. We evaluate our approach on the Co3Dv2 and GoogleScanned Objects datasets and demonstrate the benefits of our method overpose-reliant sparse-view methods as well as single-view methods that cannotleverage additional views. Finally, we also show that our learned model cangeneralize beyond the training categories and even allow reconstruction fromself-captured images of generic objects in-the-wild.</description><author>Bharath Raj Nagoor Kani, Hsin-Ying Lee, Sergey Tulyakov, Shubham Tulsiani</author><pubDate>Thu, 04 Jan 2024 17:59:04 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.06661v2</guid></item><item><title>TinyLlama: An Open-Source Small Language Model</title><link>http://arxiv.org/abs/2401.02385v1</link><description>We present TinyLlama, a compact 1.1B language model pretrained on around 1trillion tokens for approximately 3 epochs. Building on the architecture andtokenizer of Llama 2, TinyLlama leverages various advances contributed by theopen-source community (e.g., FlashAttention), achieving better computationalefficiency. Despite its relatively small size, TinyLlama demonstratesremarkable performance in a series of downstream tasks. It significantlyoutperforms existing open-source language models with comparable sizes. Ourmodel checkpoints and code are publicly available on GitHub athttps://github.com/jzhang38/TinyLlama.</description><author>Peiyuan Zhang, Guangtao Zeng, Tianduo Wang, Wei Lu</author><pubDate>Thu, 04 Jan 2024 17:54:59 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.02385v1</guid></item><item><title>ChartAssisstant: A Universal Chart Multimodal Language Model via Chart-to-Table Pre-training and Multitask Instruction Tuning</title><link>http://arxiv.org/abs/2401.02384v1</link><description>Charts play a vital role in data visualization, understanding data patterns,and informed decision-making. However, their unique combination of graphicalelements (e.g., bars, lines) and textual components (e.g., labels, legends)poses challenges for general-purpose multimodal models. While vision-languagemodels trained on chart data excel in comprehension, they struggle withgeneralization and require task-specific fine-tuning. To address thesechallenges, we propose ChartAssistant, a chart-based vision-language model foruniversal chart comprehension and reasoning. ChartAssistant leverages ChartSFT,a comprehensive dataset covering diverse chart-related tasks with basic andspecialized chart types. It undergoes a two-stage training process, startingwith pre-training on chart-to-table parsing to align chart and text, followedby multitask instruction-following fine-tuning. This approach enablesChartAssistant to achieve competitive performance across various chart taskswithout task-specific fine-tuning. Experimental results demonstrate significantperformance gains over the state-of-the-art UniChart method, outperformingOpenAI's GPT-4V(ision) on real-world chart data. The code and data areavailable at https://github.com/OpenGVLab/ChartAst.</description><author>Fanqing Meng, Wenqi Shao, Quanfeng Lu, Peng Gao, Kaipeng Zhang, Yu Qiao, Ping Luo</author><pubDate>Thu, 04 Jan 2024 17:51:48 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.02384v1</guid></item><item><title>Survey of 3D Human Body Pose and Shape Estimation Methods for Contemporary Dance Applications</title><link>http://arxiv.org/abs/2401.02383v1</link><description>3D human body shape and pose estimation from RGB images is a challengingproblem with potential applications in augmented/virtual reality, healthcareand fitness technology and virtual retail. Recent solutions have focused onthree types of inputs: i) single images, ii) multi-view images and iii) videos.In this study, we surveyed and compared 3D body shape and pose estimationmethods for contemporary dance and performing arts, with a special focus onhuman body pose and dressing, camera viewpoint, illumination conditions andbackground conditions. We demonstrated that multi-frame methods, such as PHALP,provide better results than single-frame method for pose estimation whendancers are performing contemporary dances.</description><author>Darshan Venkatrayappa, Alain Tremeau, Damien Muselet, Philippe Colantoni</author><pubDate>Thu, 04 Jan 2024 17:51:44 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.02383v1</guid></item><item><title>Generalized Quadratic Embeddings for Nonlinear Dynamics using Deep Learning</title><link>http://arxiv.org/abs/2211.00357v2</link><description>The engineering design process often relies on mathematical modeling that candescribe the underlying dynamic behavior. In this work, we present adata-driven methodology for modeling the dynamics of nonlinear systems. Tosimplify this task, we aim to identify a coordinate transformation that allowsus to represent the dynamics of nonlinear systems using a common, simple modelstructure. The advantage of a common simple model is that customized designtools developed for it can be applied to study a large variety of nonlinearsystems. The simplest common model -- one can think of -- is linear, but linearsystems often fall short in accurately capturing the complex dynamics ofnonlinear systems. In this work, we propose using quadratic systems as thecommon structure, inspired by the lifting principle. According to thisprinciple, smooth nonlinear systems can be expressed as quadratic systems insuitable coordinates without approximation errors. However, finding thesecoordinates solely from data is challenging. Here, we leverage deep learning toidentify such lifted coordinates using only data, enabling a quadraticdynamical system to describe the system's dynamics. Additionally, we discussthe asymptotic stability of these quadratic dynamical systems. We illustratethe approach using data collected from various numerical examples,demonstrating its superior performance with the existing well-known techniques.</description><author>Pawan Goyal, Peter Benner</author><pubDate>Thu, 04 Jan 2024 17:51:13 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2211.00357v2</guid></item><item><title>Vietnamese Poem Generation &amp; The Prospect Of Cross-Language Poem-To-Poem Translation</title><link>http://arxiv.org/abs/2401.01078v3</link><description>Poetry generation has been a challenging task in the field of NaturalLanguage Processing, as it requires the model to understand the nuances oflanguage, sentiment, and style. In this paper, we propose using Large LanguageModels to generate Vietnamese poems of various genres from natural languageprompts, thereby facilitating an intuitive process with enhanced contentcontrol. Our most efficacious model, the GPT-3 Babbage variant, achieves acustom evaluation score of 0.8, specifically tailored to the "luc bat" genre ofVietnamese poetry. Furthermore, we also explore the idea of paraphrasing poemsinto normal text prompts and yield a relatively high score of 0.781 in the "lucbat" genre. This experiment presents the potential for cross-Languagepoem-to-poem translation with translated poems as the inputs while concurrentlymaintaining complete control over the generated content.</description><author>Triet Minh Huynh, Quan Le Bao</author><pubDate>Thu, 04 Jan 2024 17:29:47 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.01078v3</guid></item><item><title>SPEER: Sentence-Level Planning of Long Clinical Summaries via Embedded Entity Retrieval</title><link>http://arxiv.org/abs/2401.02369v1</link><description>Clinician must write a lengthy summary each time a patient is discharged fromthe hospital. This task is time-consuming due to the sheer number of uniqueclinical concepts covered in the admission. Identifying and covering saliententities is vital for the summary to be clinically useful. We fine-tuneopen-source LLMs (Mistral-7B-Instruct and Zephyr-7B-\b{eta}) on the task andfind that they generate incomplete and unfaithful summaries. To increase entitycoverage, we train a smaller, encoder-only model to predict salient entities,which are treated as content-plans to guide the LLM. To encourage the LLM tofocus on specific mentions in the source notes, we propose SPEER:Sentence-level Planning via Embedded Entity Retrieval. Specifically, we markeach salient entity span with special "{{ }}" boundary tags and instruct theLLM to retrieve marked spans before generating each sentence. Sentence-levelplanning acts as a form of state tracking in that the model is explicitlyrecording the entities it uses. We fine-tune Mistral and Zephyr variants on alarge-scale, diverse dataset of ~167k in-patient hospital admissions andevaluate on 3 datasets. SPEER shows gains in both coverage and faithfulnessmetrics over non-guided and guided baselines.</description><author>Griffin Adams, Jason Zucker, Noémie Elhadad</author><pubDate>Thu, 04 Jan 2024 17:23:44 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.02369v1</guid></item><item><title>A Generalizable Physics-informed Learning Framework for Risk Probability Estimation</title><link>http://arxiv.org/abs/2305.06432v2</link><description>Accurate estimates of long-term risk probabilities and their gradients arecritical for many stochastic safe control methods. However, computing such riskprobabilities in real-time and in unseen or changing environments ischallenging. Monte Carlo (MC) methods cannot accurately evaluate theprobabilities and their gradients as an infinitesimal devisor can amplify thesampling noise. In this paper, we develop an efficient method to evaluate theprobabilities of long-term risk and their gradients. The proposed methodexploits the fact that long-term risk probability satisfies certain partialdifferential equations (PDEs), which characterize the neighboring relationsbetween the probabilities, to integrate MC methods and physics-informed neuralnetworks. We provide theoretical guarantees of the estimation error givencertain choices of training configurations. Numerical results show the proposedmethod has better sample efficiency, generalizes well to unseen regions, andcan adapt to systems with changing parameters. The proposed method can alsoaccurately estimate the gradients of risk probabilities, which enables first-and second-order techniques on risk probabilities to be used for learning andcontrol.</description><author>Zhuoyuan Wang, Yorie Nakahira</author><pubDate>Thu, 04 Jan 2024 17:19:39 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.06432v2</guid></item><item><title>Integration of physics-informed operator learning and finite element method for parametric learning of partial differential equations</title><link>http://arxiv.org/abs/2401.02363v1</link><description>We present a method that employs physics-informed deep learning techniquesfor parametrically solving partial differential equations. The focus is on thesteady-state heat equations within heterogeneous solids exhibiting significantphase contrast. Similar equations manifest in diverse applications likechemical diffusion, electrostatics, and Darcy flow. The neural network aims toestablish the link between the complex thermal conductivity profiles andtemperature distributions, as well as heat flux components within themicrostructure, under fixed boundary conditions. A distinctive aspect is ourindependence from classical solvers like finite element methods for data. Anoteworthy contribution lies in our novel approach to defining the lossfunction, based on the discretized weak form of the governing equation. Thisnot only reduces the required order of derivatives but also eliminates the needfor automatic differentiation in the construction of loss terms, acceptingpotential numerical errors from the chosen discretization method. As a result,the loss function in this work is an algebraic equation that significantlyenhances training efficiency. We benchmark our methodology against the standardfinite element method, demonstrating accurate yet faster predictions using thetrained neural network for temperature and flux profiles. We also show higheraccuracy by using the proposed method compared to purely data-driven approachesfor unforeseen scenarios.</description><author>Shahed Rezaei, Ahmad Moeineddin, Michael Kaliske, Markus Apel</author><pubDate>Thu, 04 Jan 2024 17:01:54 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.02363v1</guid></item><item><title>An Open and Comprehensive Pipeline for Unified Object Grounding and Detection</title><link>http://arxiv.org/abs/2401.02361v1</link><description>Grounding-DINO is a state-of-the-art open-set detection model that tacklesmultiple vision tasks including Open-Vocabulary Detection (OVD), PhraseGrounding (PG), and Referring Expression Comprehension (REC). Its effectivenesshas led to its widespread adoption as a mainstream architecture for variousdownstream applications. However, despite its significance, the originalGrounding-DINO model lacks comprehensive public technical details due to theunavailability of its training code. To bridge this gap, we presentMM-Grounding-DINO, an open-source, comprehensive, and user-friendly baseline,which is built with the MMDetection toolbox. It adopts abundant vision datasetsfor pre-training and various detection and grounding datasets for fine-tuning.We give a comprehensive analysis of each reported result and detailed settingsfor reproduction. The extensive experiments on the benchmarks mentioneddemonstrate that our MM-Grounding-DINO-Tiny outperforms the Grounding-DINO-Tinybaseline. We release all our models to the research community. Codes andtrained models are released athttps://github.com/open-mmlab/mmdetection/configs/mm_grounding_dino.</description><author>Xiangyu Zhao, Yicheng Chen, Shilin Xu, Xiangtai Li, Xinjiang Wang, Yining Li, Haian Huang</author><pubDate>Thu, 04 Jan 2024 17:00:49 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.02361v1</guid></item><item><title>A novel method to enhance pneumonia detection via a model-level ensembling of CNN and vision transformer</title><link>http://arxiv.org/abs/2401.02358v1</link><description>Pneumonia remains a leading cause of morbidity and mortality worldwide. ChestX-ray (CXR) imaging is a fundamental diagnostic tool, but traditional analysisrelies on time-intensive expert evaluation. Recently, deep learning has shownimmense potential for automating pneumonia detection from CXRs. This paperexplores applying neural networks to improve CXR-based pneumonia diagnosis. Wedeveloped a novel model fusing Convolution Neural networks (CNN) and VisionTransformer networks via model-level ensembling. Our fusion architecturecombines a ResNet34 variant and a Multi-Axis Vision Transformer small model.Both base models are initialized with ImageNet pre-trained weights. The outputlayers are removed, and features are combined using a flattening layer beforefinal classification. Experiments used the Kaggle pediatric pneumonia datasetcontaining 1,341 normal and 3,875 pneumonia CXR images. We compared our modelagainst standalone ResNet34, Vision Transformer, and Swin Transformer Tinybaseline models using identical training procedures. Extensive dataaugmentation, Adam optimization, learning rate warmup, and decay were employed.The fusion model achieved a state-of-the-art accuracy of 94.87%, surpassing thebaselines. We also attained excellent sensitivity, specificity, kappa score,and positive predictive value. Confusion matrix analysis confirms fewermisclassifications. The ResNet34 and Vision Transformer combination enablesjointly learning robust features from CNNs and Transformer paradigms. Thismodel-level ensemble technique effectively integrates their complementarystrengths for enhanced pneumonia classification.</description><author>Sandeep Angara, Nishith Reddy Mannuru, Aashrith Mannuru, Sharath Thirunagaru</author><pubDate>Thu, 04 Jan 2024 16:58:31 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.02358v1</guid></item><item><title>Fit-NGP: Fitting Object Models to Neural Graphics Primitives</title><link>http://arxiv.org/abs/2401.02357v1</link><description>Accurate 3D object pose estimation is key to enabling many roboticapplications that involve challenging object interactions. In this work, weshow that the density field created by a state-of-the-art efficient radiancefield reconstruction method is suitable for highly accurate and robust poseestimation for objects with known 3D models, even when they are very small andwith challenging reflective surfaces. We present a fully automatic object poseestimation system based on a robot arm with a single wrist-mounted camera,which can scan a scene from scratch, detect and estimate the 6-Degrees ofFreedom (DoF) poses of multiple objects within a couple of minutes ofoperation. Small objects such as bolts and nuts are estimated with accuracy onorder of 1mm.</description><author>Marwan Taher, Ignacio Alzugaray, Andrew J. Davison</author><pubDate>Thu, 04 Jan 2024 16:57:56 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.02357v1</guid></item><item><title>Audiovisual Masked Autoencoders</title><link>http://arxiv.org/abs/2212.05922v3</link><description>Can we leverage the audiovisual information already present in video toimprove self-supervised representation learning? To answer this question, westudy various pretraining architectures and objectives within the maskedautoencoding framework, motivated by the success of similar methods in naturallanguage and image understanding. We show that we can achieve significantimprovements on audiovisual downstream classification tasks, surpassing thestate-of-the-art on VGGSound and AudioSet. Furthermore, we can leverage ouraudiovisual pretraining scheme for multiple unimodal downstream tasks using asingle audiovisual pretrained model. We additionally demonstrate thetransferability of our representations, achieving state-of-the-art audiovisualresults on Epic Kitchens without pretraining specifically for this dataset.</description><author>Mariana-Iuliana Georgescu, Eduardo Fonseca, Radu Tudor Ionescu, Mario Lucic, Cordelia Schmid, Anurag Arnab</author><pubDate>Thu, 04 Jan 2024 16:52:34 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2212.05922v3</guid></item><item><title>Towards a Foundation Purchasing Model: Pretrained Generative Autoregression on Transaction Sequences</title><link>http://arxiv.org/abs/2401.01641v2</link><description>Machine learning models underpin many modern financial systems for use casessuch as fraud detection and churn prediction. Most are based on supervisedlearning with hand-engineered features, which relies heavily on theavailability of labelled data. Large self-supervised generative models haveshown tremendous success in natural language processing and computer vision,yet so far they haven't been adapted to multivariate time series of financialtransactions. In this paper, we present a generative pretraining method thatcan be used to obtain contextualised embeddings of financial transactions.Benchmarks on public datasets demonstrate that it outperforms state-of-the-artself-supervised methods on a range of downstream tasks. We additionally performlarge-scale pretraining of an embedding model using a corpus of data from 180issuing banks containing 5.1 billion transactions and apply it to the cardfraud detection problem on hold-out datasets. The embedding model significantlyimproves value detection rate at high precision thresholds and transfers wellto out-of-domain distributions.</description><author>Piotr Skalski, David Sutton, Stuart Burrell, Iker Perez, Jason Wong</author><pubDate>Thu, 04 Jan 2024 16:52:11 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.01641v2</guid></item><item><title>A Survey Analyzing Generalization in Deep Reinforcement Learning</title><link>http://arxiv.org/abs/2401.02349v1</link><description>Reinforcement learning research obtained significant success and attentionwith the utilization of deep neural networks to solve problems in highdimensional state or action spaces. While deep reinforcement learning policiesare currently being deployed in many different fields from medical applicationsto self driving vehicles, there are still ongoing questions the field is tryingto answer on the generalization capabilities of deep reinforcement learningpolicies. In this paper, we will outline the fundamental reasons why deepreinforcement learning policies encounter overfitting problems that limit theirrobustness and generalization capabilities. Furthermore, we will formalize andunify the diverse solution approaches to increase generalization, and overcomeoverfitting in state-action value functions. We believe our study can provide acompact systematic unified analysis for the current advancements in deepreinforcement learning, and help to construct robust deep neural policies withimproved generalization abilities.</description><author>Ezgi Korkmaz</author><pubDate>Thu, 04 Jan 2024 16:45:01 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.02349v1</guid></item><item><title>Mining Fine-Grained Image-Text Alignment for Zero-Shot Captioning via Text-Only Training</title><link>http://arxiv.org/abs/2401.02347v1</link><description>Image captioning aims at generating descriptive and meaningful textualdescriptions of images, enabling a broad range of vision-language applications.Prior works have demonstrated that harnessing the power of Contrastive ImageLanguage Pre-training (CLIP) offers a promising approach to achieving zero-shotcaptioning, eliminating the need for expensive caption annotations. However,the widely observed modality gap in the latent space of CLIP harms theperformance of zero-shot captioning by breaking the alignment between pairedimage-text features. To address this issue, we conduct an analysis on the CLIPlatent space which leads to two findings. Firstly, we observe that the CLIP'svisual feature of image subregions can achieve closer proximity to the pairedcaption due to the inherent information loss in text descriptions. In addition,we show that the modality gap between a paired image-text can be empiricallymodeled as a zero-mean Gaussian distribution. Motivated by the findings, wepropose a novel zero-shot image captioning framework with text-only training toreduce the modality gap. In particular, we introduce a subregion featureaggregation to leverage local region information, which produces a compactvisual representation for matching text representation. Moreover, weincorporate a noise injection and CLIP reranking strategy to boost captioningperformance. We also extend our framework to build a zero-shot VQA pipeline,demonstrating its generality. Through extensive experiments on commoncaptioning and VQA datasets such as MSCOCO, Flickr30k and VQAV2, we show thatour method achieves remarkable performance improvements. Code is available athttps://github.com/Artanic30/MacCap.</description><author>Longtian Qiu, Shan Ning, Xuming He</author><pubDate>Thu, 04 Jan 2024 16:43:46 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.02347v1</guid></item><item><title>Multi-Source Domain Adaptation with Transformer-based Feature Generation for Subject-Independent EEG-based Emotion Recognition</title><link>http://arxiv.org/abs/2401.02344v1</link><description>Although deep learning-based algorithms have demonstrated excellentperformance in automated emotion recognition via electroencephalogram (EEG)signals, variations across brain signal patterns of individuals can diminishthe model's effectiveness when applied across different subjects. Whiletransfer learning techniques have exhibited promising outcomes, they stillencounter challenges related to inadequate feature representations and mayoverlook the fact that source subjects themselves can possess distinctcharacteristics. In this work, we propose a multi-source domain adaptationapproach with a transformer-based feature generator (MSDA-TF) designed toleverage information from multiple sources. The proposed feature generatorretains convolutional layers to capture shallow spatial, temporal, and spectralEEG data representations, while self-attention mechanisms extract globaldependencies within these features. During the adaptation process, we group thesource subjects based on correlation values and aim to align the moments of thetarget subject with each source as well as within the sources. MSDA-TF isvalidated on the SEED dataset and is shown to yield promising results.</description><author>Shadi Sartipi, Mujdat Cetin</author><pubDate>Thu, 04 Jan 2024 16:38:47 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.02344v1</guid></item><item><title>Evasive Hardware Trojan through Adversarial Power Trace</title><link>http://arxiv.org/abs/2401.02342v1</link><description>The globalization of the Integrated Circuit (IC) supply chain, driven bytime-to-market and cost considerations, has made ICs vulnerable to hardwareTrojans (HTs). Against this threat, a promising approach is to use MachineLearning (ML)-based side-channel analysis, which has the advantage of being anon-intrusive method, along with efficiently detecting HTs under goldenchip-free settings. In this paper, we question the trustworthiness of ML-basedHT detection via side-channel analysis. We introduce a HT obfuscation (HTO)approach to allow HTs to bypass this detection method. Rather thantheoretically misleading the model by simulated adversarial traces, a keyaspect of our approach is the design and implementation of adversarial noise aspart of the circuitry, alongside the HT. We detail HTO methodologies for ASICsand FPGAs, and evaluate our approach using TrustHub benchmark. Interestingly,we found that HTO can be implemented with only a single transistor for ASICdesigns to generate adversarial power traces that can fool the defense with100% efficiency. We also efficiently implemented our approach on a Spartan 6Xilinx FPGA using 2 different variants: (i) DSP slices-based, and (ii)ring-oscillator-based design. Additionally, we assess the efficiency ofcountermeasures like spectral domain analysis, and we show that an adaptiveattacker can still design evasive HTOs by constraining the design with aspectral noise budget. In addition, while adversarial training (AT) offershigher protection against evasive HTs, AT models suffer from a considerableutility loss, potentially rendering them unsuitable for such securityapplication. We believe this research represents a significant step inunderstanding and exploiting ML vulnerabilities in a hardware security context,and we make all resources and designs openly available online:https://dev.d18uu4lqwhbmka.amplifyapp.com</description><author>Behnam Omidi, Khaled N. Khasawneh, Ihsen Alouani</author><pubDate>Thu, 04 Jan 2024 16:28:15 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.02342v1</guid></item><item><title>Adversarial Data Poisoning for Fake News Detection: How to Make a Model Misclassify a Target News without Modifying It</title><link>http://arxiv.org/abs/2312.15228v2</link><description>Fake news detection models are critical to countering disinformation but canbe manipulated through adversarial attacks. In this position paper, we analyzehow an attacker can compromise the performance of an online learning detectoron specific news content without being able to manipulate the original targetnews. In some contexts, such as social networks, where the attacker cannotexert complete control over all the information, this scenario can indeed bequite plausible. Therefore, we show how an attacker could potentially introducepoisoning data into the training data to manipulate the behavior of an onlinelearning method. Our initial findings reveal varying susceptibility of logisticregression models based on complexity and attack type.</description><author>Federico Siciliano, Luca Maiano, Lorenzo Papa, Federica Baccini, Irene Amerini, Fabrizio Silvestri</author><pubDate>Thu, 04 Jan 2024 16:20:42 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.15228v2</guid></item><item><title>Linguistic Profiling of Deepfakes: An Open Database for Next-Generation Deepfake Detection</title><link>http://arxiv.org/abs/2401.02335v1</link><description>The emergence of text-to-image generative models has revolutionized the fieldof deepfakes, enabling the creation of realistic and convincing visual contentdirectly from textual descriptions. However, this advancement presentsconsiderably greater challenges in detecting the authenticity of such content.Existing deepfake detection datasets and methods often fall short ineffectively capturing the extensive range of emerging deepfakes and offeringsatisfactory explanatory information for detection. To address the significantissue, this paper introduces a deepfake database (DFLIP-3K) for the developmentof convincing and explainable deepfake detection. It encompasses about 300Kdiverse deepfake samples from approximately 3K generative models, which boaststhe largest number of deepfake models in the literature. Moreover, it collectsaround 190K linguistic footprints of these deepfakes. The two distinguishedfeatures enable DFLIP-3K to develop a benchmark that promotes progress inlinguistic profiling of deepfakes, which includes three sub-tasks namelydeepfake detection, model identification, and prompt prediction. The deepfakemodel and prompt are two essential components of each deepfake, and thusdissecting them linguistically allows for an invaluable exploration oftrustworthy and interpretable evidence in deepfake detection, which we believeis the key for the next-generation deepfake detection. Furthermore, DFLIP-3K isenvisioned as an open database that fosters transparency and encouragescollaborative efforts to further enhance its growth. Our extensive experimentson the developed benchmark verify that our DFLIP-3K database is capable ofserving as a standardized resource for evaluating and comparinglinguistic-based deepfake detection, identification, and prompt predictiontechniques.</description><author>Yabin Wang, Zhiwu Huang, Zhiheng Ma, Xiaopeng Hong</author><pubDate>Thu, 04 Jan 2024 16:19:52 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.02335v1</guid></item><item><title>Beyond Extraction: Contextualising Tabular Data for Efficient Summarisation by Language Models</title><link>http://arxiv.org/abs/2401.02333v1</link><description>The conventional use of the Retrieval-Augmented Generation (RAG) architecturehas proven effective for retrieving information from diverse documents.However, challenges arise in handling complex table queries, especially withinPDF documents containing intricate tabular structures.This research introducesan innovative approach to enhance the accuracy of complex table queries inRAG-based systems. Our methodology involves storing PDFs in the retrievaldatabase and extracting tabular content separately. The extracted tablesundergo a process of context enrichment, concatenating headers withcorresponding values. To ensure a comprehensive understanding of the enricheddata, we employ a fine-tuned version of the Llama-2-chat language model forsummarisation within the RAG architecture. Furthermore, we augment the tabulardata with contextual sense using the ChatGPT 3.5 API through a one-shot prompt.This enriched data is then fed into the retrieval database alongside otherPDFs. Our approach aims to significantly improve the precision of complex tablequeries, offering a promising solution to a longstanding challenge ininformation retrieval.</description><author>Uday Allu, Biddwan Ahmed, Vishesh Tripathi</author><pubDate>Thu, 04 Jan 2024 16:16:14 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.02333v1</guid></item><item><title>LLaVA-$φ$: Efficient Multi-Modal Assistant with Small Language Model</title><link>http://arxiv.org/abs/2401.02330v1</link><description>In this paper, we introduce LLaVA-$\phi$ (LLaVA-Phi), an efficientmulti-modal assistant that harnesses the power of the recently advanced smalllanguage model, Phi-2, to facilitate multi-modal dialogues. LLaVA-Phi marks anotable advancement in the realm of compact multi-modal models. It demonstratesthat even smaller language models, with as few as 2.7B parameters, caneffectively engage in intricate dialogues that integrate both textual andvisual elements, provided they are trained with high-quality corpora. Our modeldelivers commendable performance on publicly available benchmarks thatencompass visual comprehension, reasoning, and knowledge-based perception.Beyond its remarkable performance in multi-modal dialogue tasks, our modelopens new avenues for applications in time-sensitive environments and systemsthat require real-time interaction, such as embodied agents. It highlights thepotential of smaller language models to achieve sophisticated levels ofunderstanding and interaction, while maintaining greater resourceefficiency.The project is available at {https://github.com/zhuyiche/llava-phi}.</description><author>Yichen Zhu, Minjie Zhu, Ning Liu, Zhicai Ou, Xiaofeng Mou, Jian Tang</author><pubDate>Thu, 04 Jan 2024 16:07:43 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.02330v1</guid></item><item><title>Not all Minorities are Equal: Empty-Class-Aware Distillation for Heterogeneous Federated Learning</title><link>http://arxiv.org/abs/2401.02329v1</link><description>Data heterogeneity, characterized by disparities in local data distributionacross clients, poses a significant challenge in federated learning.Substantial efforts have been devoted to addressing the heterogeneity in locallabel distribution. As minority classes suffer from worse accuracy due tooverfitting on local imbalanced data, prior methods often incorporateclass-balanced learning techniques during local training. Despite the improvedmean accuracy across all classes, we observe that empty classes-referring tocategories absent from a client's data distribution-are still not wellrecognized. This paper introduces FedED, a novel approach in heterogeneousfederated learning that integrates both empty-class distillation and logitsuppression simultaneously. Specifically, empty-class distillation leveragesknowledge distillation during local training on each client to retain essentialinformation related to empty classes from the global model. Moreover, logitsuppression directly penalizes network logits for non-label classes,effectively addressing misclassifications in minority classes that may bebiased toward majority classes. Extensive experiments validate the efficacy ofFedED, surpassing previous state-of-the-art methods across diverse datasetswith varying degrees of label distribution shift.</description><author>Kuangpu Guo, Yuhe Ding, Jian Liang, Ran He, Zilei Wang, Tieniu Tan</author><pubDate>Thu, 04 Jan 2024 16:06:31 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.02329v1</guid></item><item><title>ClassWise-SAM-Adapter: Parameter Efficient Fine-tuning Adapts Segment Anything to SAR Domain for Semantic Segmentation</title><link>http://arxiv.org/abs/2401.02326v1</link><description>In the realm of artificial intelligence, the emergence of foundation models,backed by high computing capabilities and extensive data, has beenrevolutionary. Segment Anything Model (SAM), built on the Vision Transformer(ViT) model with millions of parameters and vast training dataset SA-1B, excelsin various segmentation scenarios relying on its significance of semanticinformation and generalization ability. Such achievement of visual foundationmodel stimulates continuous researches on specific downstream tasks in computervision. The ClassWise-SAM-Adapter (CWSAM) is designed to adapt thehigh-performing SAM for landcover classification on space-borne SyntheticAperture Radar (SAR) images. The proposed CWSAM freezes most of SAM'sparameters and incorporates lightweight adapters for parameter efficientfine-tuning, and a classwise mask decoder is designed to achieve semanticsegmentation task. This adapt-tuning method allows for efficient landcoverclassification of SAR images, balancing the accuracy with computational demand.In addition, the task specific input module injects low frequency informationof SAR images by MLP-based layers to improve the model performance. Compared toconventional state-of-the-art semantic segmentation algorithms by extensiveexperiments, CWSAM showcases enhanced performance with fewer computingresources, highlighting the potential of leveraging foundational models likeSAM for specific downstream tasks in the SAR domain. The source code isavailable at: https://github.com/xypu98/CWSAM.</description><author>Xinyang Pu, Hecheng Jia, Linghao Zheng, Feng Wang, Feng Xu</author><pubDate>Thu, 04 Jan 2024 15:54:45 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.02326v1</guid></item><item><title>A Robust Quantile Huber Loss With Interpretable Parameter Adjustment In Distributional Reinforcement Learning</title><link>http://arxiv.org/abs/2401.02325v1</link><description>Distributional Reinforcement Learning (RL) estimates return distributionmainly by learning quantile values via minimizing the quantile Huber lossfunction, entailing a threshold parameter often selected heuristically or viahyperparameter search, which may not generalize well and can be suboptimal.This paper introduces a generalized quantile Huber loss function derived fromWasserstein distance (WD) calculation between Gaussian distributions, capturingnoise in predicted (current) and target (Bellman-updated) quantile values.Compared to the classical quantile Huber loss, this innovative loss functionenhances robustness against outliers. Notably, the classical Huber lossfunction can be seen as an approximation of our proposed loss, enablingparameter adjustment by approximating the amount of noise in the data duringthe learning process. Empirical tests on Atari games, a common application indistributional RL, and a recent hedging strategy using distributional RL,validate the effectiveness of our proposed loss function and its potential forparameter adjustments in distributional RL.</description><author>Parvin Malekzadeh, Konstantinos N. Plataniotis, Zissis Poulos, Zeyu Wang</author><pubDate>Thu, 04 Jan 2024 15:51:49 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.02325v1</guid></item><item><title>From 2D Images to 3D Model:Weakly Supervised Multi-View Face Reconstruction with Deep Fusion</title><link>http://arxiv.org/abs/2204.03842v3</link><description>While weakly supervised multi-view face reconstruction (MVR) is garneringincreased attention, one critical issue still remains open: how to effectivelyfuse multiple image information to reconstruct high-precision 3D models. Inthis regard, we propose a novel model called Deep Fusion MVR (DF-MVR) anddesign a multi-view encoding to single decoding framework with skipconnections, able to extract, integrate, and compensate deep features withattention from multi-view images. Furthermore, we adopt the involution kernelto enrich deep fusion features with channel features. In addition, we developthe face parse network to learn, identify, and emphasize the critical commonface area within multi-view images. Experiments on Pixel-Face and Bosphorusdatasets indicate the superiority of our model. Without 3D annotation, DF-MVRachieves 5.2% and 3.0% RMSE improvement over the existing weakly supervisedMVRs respectively on Pixel-Face and Bosphorus dataset. Code will be availablepublicly at https://github.com/weiguangzhao/DF_MVR.</description><author>Weiguang Zhao, Chaolong Yang, Jianan Ye, Rui Zhang, Yuyao Yan, Xi Yang, Bin Dong, Amir Hussain, Kaizhu Huang</author><pubDate>Thu, 04 Jan 2024 15:50:25 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2204.03842v3</guid></item><item><title>Multi-Agent Context Learning Strategy for Interference-Aware Beam Allocation in mmWave Vehicular Communications</title><link>http://arxiv.org/abs/2401.02323v1</link><description>Millimeter wave (mmWave) has been recognized as one of key technologies for5G and beyond networks due to its potential to enhance channel bandwidth andnetwork capacity. The use of mmWave for various applications includingvehicular communications has been extensively discussed. However, applyingmmWave to vehicular communications faces challenges of high mobility nodes andnarrow coverage along the mmWave beams. Due to high mobility in dense networks,overlapping beams can cause strong interference which leads to performancedegradation. As a remedy, beam switching capability in mmWave can be utilized.Then, frequent beam switching and cell change become inevitable to manageinterference, which increase computational and signalling complexity. In orderto deal with the complexity in interference control, we develop a new strategycalled Multi-Agent Context Learning (MACOL), which utilizes Contextual Banditto manage interference while allocating mmWave beams to serve vehicles in thenetwork. Our approach demonstrates that by leveraging knowledge of neighbouringbeam status, the machine learning agent can identify and avoid potentialinterfering transmissions to other ongoing transmissions. Furthermore, we showthat even under heavy traffic loads, our proposed MACOL strategy is able tomaintain low interference levels at around 10%.</description><author>Abdulkadir Kose, Haeyoung Lee, Chuan Heng Foh, Mohammad Shojafar</author><pubDate>Thu, 04 Jan 2024 15:43:55 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.02323v1</guid></item><item><title>BA-SAM: Scalable Bias-Mode Attention Mask for Segment Anything Model</title><link>http://arxiv.org/abs/2401.02317v1</link><description>In this paper, we address the challenge of image resolution variation for theSegment Anything Model (SAM). SAM, known for its zero-shot generalizability,exhibits a performance degradation when faced with datasets with varying imagesizes. Previous approaches tend to resize the image to a fixed size or adoptstructure modifications, hindering the preservation of SAM's rich priorknowledge. Besides, such task-specific tuning necessitates a completeretraining of the model, which is cost-expensive and unacceptable fordeployment in the downstream tasks. In this paper, we reformulate this issue asa length extrapolation problem, where token sequence length varies whilemaintaining a consistent patch size for images of different sizes. To this end,we propose Scalable Bias-Mode Attention Mask (BA-SAM) to enhance SAM'sadaptability to varying image resolutions while eliminating the need forstructure modifications. Firstly, we introduce a new scaling factor to ensureconsistent magnitude in the attention layer's dot product values when the tokensequence length changes. Secondly, we present a bias-mode attention mask thatallows each token to prioritize neighboring information, mitigating the impactof untrained distant information. Our BA-SAM demonstrates efficacy in twoscenarios: zero-shot and fine-tuning. Extensive evaluation on diverse datasets,including DIS5K, DUTS, ISIC, COD10K, and COCO, reveals its ability tosignificantly mitigate performance degradation in the zero-shot setting andachieve state-of-the-art performance with minimal fine-tuning. Furthermore, wepropose a generalized model and benchmark, showcasing BA-SAM's generalizabilityacross all four datasets simultaneously.</description><author>Yiran Song, Qianyu Zhou, Xiangtai Li, Deng-Ping Fan, Xuequan Lu, Lizhuang Ma</author><pubDate>Thu, 04 Jan 2024 15:34:44 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.02317v1</guid></item><item><title>SuperEdge: Towards a Generalization Model for Self-Supervised Edge Detection</title><link>http://arxiv.org/abs/2401.02313v1</link><description>Edge detection is a fundamental technique in various computer vision tasks.Edges are indeed effectively delineated by pixel discontinuity and can offerreliable structural information even in textureless areas. State-of-the-artheavily relies on pixel-wise annotations, which are labor-intensive and subjectto inconsistencies when acquired manually. In this work, we propose a novelself-supervised approach for edge detection that employs a multi-level,multi-homography technique to transfer annotations from synthetic to real-worlddatasets. To fully leverage the generated edge annotations, we developedSuperEdge, a streamlined yet efficient model capable of concurrently extractingedges at pixel-level and object-level granularity. Thanks to self-supervisedtraining, our method eliminates the dependency on manual annotated edge labels,thereby enhancing its generalizability across diverse datasets. Comparativeevaluations reveal that SuperEdge advances edge detection, demonstratingimprovements of 4.9% in ODS and 3.3% in OIS over the existing STEdge method onBIPEDv2.</description><author>Leng Kai, Zhang Zhijie, Liu Jie, Zed Boukhers, Sui Wei, Cong Yang, Li Zhijun</author><pubDate>Thu, 04 Jan 2024 15:21:53 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.02313v1</guid></item><item><title>The Brain Tumor Segmentation (BraTS) Challenge 2023: Focus on Pediatrics (CBTN-CONNECT-DIPGR-ASNR-MICCAI BraTS-PEDs)</title><link>http://arxiv.org/abs/2305.17033v4</link><description>Pediatric tumors of the central nervous system are the most common cause ofcancer-related death in children. The five-year survival rate for high-gradegliomas in children is less than 20\%. Due to their rarity, the diagnosis ofthese entities is often delayed, their treatment is mainly based on historictreatment concepts, and clinical trials require multi-institutionalcollaborations. The MICCAI Brain Tumor Segmentation (BraTS) Challenge is alandmark community benchmark event with a successful history of 12 years ofresource creation for the segmentation and analysis of adult glioma. Here wepresent the CBTN-CONNECT-DIPGR-ASNR-MICCAI BraTS-PEDs 2023 challenge, whichrepresents the first BraTS challenge focused on pediatric brain tumors withdata acquired across multiple international consortia dedicated to pediatricneuro-oncology and clinical trials. The BraTS-PEDs 2023 challenge focuses onbenchmarking the development of volumentric segmentation algorithms forpediatric brain glioma through standardized quantitative performance evaluationmetrics utilized across the BraTS 2023 cluster of challenges. Models gainingknowledge from the BraTS-PEDs multi-parametric structural MRI (mpMRI) trainingdata will be evaluated on separate validation and unseen test mpMRI dataofhigh-grade pediatric glioma. The CBTN-CONNECT-DIPGR-ASNR-MICCAI BraTS-PEDs 2023challenge brings together clinicians and AI/imaging scientists to lead tofaster development of automated segmentation techniques that could benefitclinical trials, and ultimately the care of children with brain tumors.</description><author>Anahita Fathi Kazerooni, Nastaran Khalili, Xinyang Liu, Debanjan Haldar, Zhifan Jiang, Syed Muhammed Anwar, Jake Albrecht, Maruf Adewole, Udunna Anazodo, Hannah Anderson, Sina Bagheri, Ujjwal Baid, Timothy Bergquist, Austin J. Borja, Evan Calabrese, Verena Chung, Gian-Marco Conte, Farouk Dako, James Eddy, Ivan Ezhov, Ariana Familiar, Keyvan Farahani, Shuvanjan Haldar, Juan Eugenio Iglesias, Anastasia Janas, Elaine Johansen, Blaise V Jones, Florian Kofler, Dominic LaBella, Hollie Anne Lai, Koen Van Leemput, Hongwei Bran Li, Nazanin Maleki, Aaron S McAllister, Zeke Meier, Bjoern Menze, Ahmed W Moawad, Khanak K Nandolia, Julija Pavaine, Marie Piraud, Tina Poussaint, Sanjay P Prabhu, Zachary Reitman, Andres Rodriguez, Jeffrey D Rudie, Ibraheem Salman Shaikh, Lubdha M. Shah, Nakul Sheth, Russel</author><pubDate>Thu, 04 Jan 2024 15:10:34 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.17033v4</guid></item><item><title>Perceptual Musical Features for Interpretable Audio Tagging</title><link>http://arxiv.org/abs/2312.11234v2</link><description>In the age of music streaming platforms, the task of automatically taggingmusic audio has garnered significant attention, driving researchers to devisemethods aimed at enhancing performance metrics on standard datasets. Mostrecent approaches rely on deep neural networks, which, despite their impressiveperformance, possess opacity, making it challenging to elucidate their outputfor a given input. While the issue of interpretability has been emphasized inother fields like medicine, it has not received attention in music-relatedtasks. In this study, we explored the relevance of interpretability in thecontext of automatic music tagging. We constructed a workflow that incorporatesthree different information extraction techniques: a) leveraging symbolicknowledge, b) utilizing auxiliary deep neural networks, and c) employing signalprocessing to extract perceptual features from audio files. These features weresubsequently used to train an interpretable machine-learning model for tagprediction. We conducted experiments on two datasets, namely the MTG-Jamendodataset and the GTZAN dataset. Our method surpassed the performance of baselinemodels in both tasks and, in certain instances, demonstrated competitivenesswith the current state-of-the-art. We conclude that there are use cases wherethe deterioration in performance is outweighed by the value ofinterpretability.</description><author>Vassilis Lyberatos, Spyridon Kantarelis, Edmund Dervakos, Giorgos Stamou</author><pubDate>Thu, 04 Jan 2024 15:09:37 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.11234v2</guid></item><item><title>On Model Compression for Neural Networks: Framework, Algorithm, and Convergence Guarantee</title><link>http://arxiv.org/abs/2303.06815v2</link><description>Model compression is a crucial part of deploying neural networks (NNs),especially when the memory and storage of computing devices are limited in manyapplications. This paper focuses on two model compression techniques: low-rankapproximation and weight pruning in neural networks, which are very popularnowadays. However, training NN with low-rank approximation and weight pruningalways suffers significant accuracy loss and convergence issues. In this paper,a holistic framework is proposed for model compression from a novel perspectiveof nonconvex optimization by designing an appropriate objective function. Then,we introduce NN-BCD, a block coordinate descent (BCD) algorithm to solve thenonconvex optimization. One advantage of our algorithm is that an efficientiteration scheme can be derived with closed-form, which is gradient-free.Therefore, our algorithm will not suffer from vanishing/exploding gradientproblems. Furthermore, with the Kurdyka-{\L}ojasiewicz (K{\L}) property of ourobjective function, we show that our algorithm globally converges to a criticalpoint at the rate of O(1/k), where k denotes the number of iterations. Lastly,extensive experiments with tensor train decomposition and weight pruningdemonstrate the efficiency and superior performance of the proposed framework.Our code implementation is available at https://github.com/ChenyangLi-97/NN-BCD</description><author>Chenyang Li, Jihoon Chung, Biao Cai, Haimin Wang, Xianlian Zhou, Bo Shen</author><pubDate>Thu, 04 Jan 2024 15:06:41 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2303.06815v2</guid></item></channel></rss>