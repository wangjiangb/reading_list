<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/"><channel><title>Arxivfresh papers</title><link></link><description>Arxiv paper</description><language>en-US</language><lastBuildDate>Wed, 05 Jul 2023 06:00:17 GMT</lastBuildDate><generator>rfeed v1.0.0</generator><docs>https://github.com/svpino/rfeed/blob/master/README.md</docs><item><title>Real-time Monocular Full-body Capture in World Space via Sequential Proxy-to-Motion Learning</title><link>http://arxiv.org/abs/2307.01200v1</link><description>Learning-based approaches to monocular motion capture have recently shownpromising results by learning to regress in a data-driven manner. However, dueto the challenges in data collection and network designs, it remainschallenging for existing solutions to achieve real-time full-body capture whilebeing accurate in world space. In this work, we contribute a sequentialproxy-to-motion learning scheme together with a proxy dataset of 2D skeletonsequences and 3D rotational motions in world space. Such proxy data enables usto build a learning-based network with accurate full-body supervision whilealso mitigating the generalization issues. For more accurate and physicallyplausible predictions, a contact-aware neural motion descent module is proposedin our network so that it can be aware of foot-ground contact and motionmisalignment with the proxy observations. Additionally, we share the body-handcontext information in our network for more compatible wrist poses recoverywith the full-body model. With the proposed learning-based solution, wedemonstrate the first real-time monocular full-body capture system withplausible foot-ground contact in world space. More video results can be foundat our project page: https://liuyebin.com/proxycap.</description><author>Yuxiang Zhang, Hongwen Zhang, Liangxiao Hu, Hongwei Yi, Shengping Zhang, Yebin Liu</author><pubDate>Mon, 03 Jul 2023 18:59:45 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.01200v1</guid></item><item><title>NeuBTF: Neural fields for BTF encoding and transfer</title><link>http://arxiv.org/abs/2307.01199v1</link><description>Neural material representations are becoming a popular way to representmaterials for rendering. They are more expressive than analytic models andoccupy less memory than tabulated BTFs. However, existing neural materials areimmutable, meaning that their output for a certain query of UVs, camera, andlight vector is fixed once they are trained. While this is practical when thereis no need to edit the material, it can become very limiting when the fragmentof the material used for training is too small or not tileable, whichfrequently happens when the material has been captured with agonioreflectometer. In this paper, we propose a novel neural materialrepresentation which jointly tackles the problems of BTF compression, tiling,and extrapolation. At test time, our method uses a guidance image as input tocondition the neural BTF to the structural features of this input image. Then,the neural BTF can be queried as a regular BTF using UVs, camera, and lightvectors. Every component in our framework is purposefully designed to maximizeBTF encoding quality at minimal parameter count and computational complexity,achieving competitive compression rates compared with previous work. Wedemonstrate the results of our method on a variety of synthetic and capturedmaterials, showing its generality and capacity to learn to represent manyoptical properties.</description><author>Carlos Rodriguez-Pardo, Konstantinos Kazatzis, Jorge Lopez-Moreno, Elena Garces</author><pubDate>Mon, 03 Jul 2023 18:59:20 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.01199v1</guid></item><item><title>Improved sampling via learned diffusions</title><link>http://arxiv.org/abs/2307.01198v1</link><description>Recently, a series of papers proposed deep learning-based approaches tosample from unnormalized target densities using controlled diffusion processes.In this work, we identify these approaches as special cases of theSchr\"odinger bridge problem, seeking the most likely stochastic evolutionbetween a given prior distribution and the specified target. We furthergeneralize this framework by introducing a variational formulation based ondivergences between path space measures of time-reversed diffusion processes.This abstract perspective leads to practical losses that can be optimized bygradient-based algorithms and includes previous objectives as special cases. Atthe same time, it allows us to consider divergences other than the reverseKullback-Leibler divergence that is known to suffer from mode collapse. Inparticular, we propose the so-called log-variance loss, which exhibitsfavorable numerical properties and leads to significantly improved performanceacross all considered approaches.</description><author>Lorenz Richter, Julius Berner, Guan-Horng Liu</author><pubDate>Mon, 03 Jul 2023 18:58:26 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.01198v1</guid></item><item><title>Segment Anything Meets Point Tracking</title><link>http://arxiv.org/abs/2307.01197v1</link><description>The Segment Anything Model (SAM) has established itself as a powerfulzero-shot image segmentation model, employing interactive prompts such aspoints to generate masks. This paper presents SAM-PT, a method extending SAM'scapability to tracking and segmenting anything in dynamic videos. SAM-PTleverages robust and sparse point selection and propagation techniques for maskgeneration, demonstrating that a SAM-based segmentation tracker can yieldstrong zero-shot performance across popular video object segmentationbenchmarks, including DAVIS, YouTube-VOS, and MOSE. Compared to traditionalobject-centric mask propagation strategies, we uniquely use point propagationto exploit local structure information that is agnostic to object semantics. Wehighlight the merits of point-based tracking through direct evaluation on thezero-shot open-world Unidentified Video Objects (UVO) benchmark. To furtherenhance our approach, we utilize K-Medoids clustering for point initializationand track both positive and negative points to clearly distinguish the targetobject. We also employ multiple mask decoding passes for mask refinement anddevise a point re-initialization strategy to improve tracking accuracy. Ourcode integrates different point trackers and video segmentation benchmarks andwill be released at https://github.com/SysCV/sam-pt.</description><author>Frano Rajiƒç, Lei Ke, Yu-Wing Tai, Chi-Keung Tang, Martin Danelljan, Fisher Yu</author><pubDate>Mon, 03 Jul 2023 18:58:01 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.01197v1</guid></item><item><title>Online Heavy-tailed Change-point detection</title><link>http://arxiv.org/abs/2306.09548v2</link><description>We study algorithms for online change-point detection (OCPD), where samplesthat are potentially heavy-tailed, are presented one at a time and a change inthe underlying mean must be detected as early as possible. We present analgorithm based on clipped Stochastic Gradient Descent (SGD), that works evenif we only assume that the second moment of the data generating process isbounded. We derive guarantees on worst-case, finite-sample false-positive rate(FPR) over the family of all distributions with bounded second moment. Thus,our method is the first OCPD algorithm that guarantees finite-sample FPR, evenif the data is high dimensional and the underlying distributions areheavy-tailed. The technical contribution of our paper is to show thatclipped-SGD can estimate the mean of a random vector and simultaneously provideconfidence bounds at all confidence values. We combine this robust estimatewith a union bound argument and construct a sequential change-point algorithmwith finite-sample FPR guarantees. We show empirically that our algorithm workswell in a variety of situations, whether the underlying data are heavy-tailed,light-tailed, high dimensional or discrete. No other algorithm achieves boundedFPR theoretically or empirically, over all settings we study simultaneously.</description><author>Abishek Sankararaman, Balakrishnan, Narayanaswamy</author><pubDate>Mon, 03 Jul 2023 18:56:15 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.09548v2</guid></item><item><title>Squeezing Large-Scale Diffusion Models for Mobile</title><link>http://arxiv.org/abs/2307.01193v1</link><description>The emergence of diffusion models has greatly broadened the scope ofhigh-fidelity image synthesis, resulting in notable advancements in bothpractical implementation and academic research. With the active adoption of themodel in various real-world applications, the need for on-device deployment hasgrown considerably. However, deploying large diffusion models such as StableDiffusion with more than one billion parameters to mobile devices posesdistinctive challenges due to the limited computational and memory resources,which may vary according to the device. In this paper, we present thechallenges and solutions for deploying Stable Diffusion on mobile devices withTensorFlow Lite framework, which supports both iOS and Android devices. Theresulting Mobile Stable Diffusion achieves the inference latency of smallerthan 7 seconds for a 512x512 image generation on Android devices with mobileGPUs.</description><author>Jiwoong Choi, Minkyu Kim, Daehyun Ahn, Taesu Kim, Yulhwa Kim, Dongwon Jo, Hyesung Jeon, Jae-Joon Kim, Hyungjun Kim</author><pubDate>Mon, 03 Jul 2023 18:54:40 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.01193v1</guid></item><item><title>Trainable Transformer in Transformer</title><link>http://arxiv.org/abs/2307.01189v1</link><description>Recent works attribute the capability of in-context learning (ICL) in largepre-trained language models to implicitly simulating and fine-tuning aninternal model (e.g., linear or 2-layer MLP) during inference. However, suchconstructions require large memory overhead, which makes simulation of moresophisticated internal models intractable. In this work, we propose anefficient construction, Transformer in Transformer (in short, TinT), thatallows a transformer to simulate and fine-tune complex models internally duringinference (e.g., pre-trained language models). In particular, we introduceinnovative approximation techniques that allow a TinT model with less than 2billion parameters to simulate and fine-tune a 125 million parametertransformer model within a single forward pass. TinT accommodates many commontransformer variants and its design ideas also improve the efficiency of pastinstantiations of simple models inside transformers. We conduct end-to-endexperiments to validate the internal fine-tuning procedure of TinT on variouslanguage modeling and downstream tasks. For example, even with a limitedone-step budget, we observe TinT for a OPT-125M model improves performance by4-16% absolute on average compared to OPT-125M. These findings suggest thatlarge pre-trained language models are capable of performing intricatesubroutines. To facilitate further work, a modular and extensible codebase forTinT is included.</description><author>Abhishek Panigrahi, Sadhika Malladi, Mengzhou Xia, Sanjeev Arora</author><pubDate>Mon, 03 Jul 2023 18:53:39 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.01189v1</guid></item><item><title>SAMAug: Point Prompt Augmentation for Segment Anything Model</title><link>http://arxiv.org/abs/2307.01187v1</link><description>This paper introduces SAMAug, a novel visual point augmentation method forthe Segment Anything Model (SAM) that enhances interactive image segmentationperformance. SAMAug generates augmented point prompts to provide moreinformation to SAM. From the initial point prompt, SAM produces the initialmask, which is then fed into our proposed SAMAug to generate augmented pointprompts. By incorporating these extra points, SAM can generate augmentedsegmentation masks based on the augmented point prompts and the initial prompt,resulting in improved segmentation performance. We evaluate four pointaugmentation techniques: random selection, maximum difference entropy, maximumdistance, and a saliency model. Experiments on the COCO, Fundus, and ChestX-ray datasets demonstrate that SAMAug can boost SAM's segmentation results,especially using the maximum distance and saliency model methods. SAMAugunderscores the potential of visual prompt engineering to advance interactivecomputer vision models.</description><author>Haixing Dai, Chong Ma, Zhengliang Liu, Yiwei Li, Peng Shu, Xiaozheng Wei, Lin Zhao, Zihao Wu, Dajiang Zhu, Wei Liu, Quanzheng Li, Tianming Liu, Xiang Li</author><pubDate>Mon, 03 Jul 2023 18:52:44 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.01187v1</guid></item><item><title>Fitting an ellipsoid to a quadratic number of random points</title><link>http://arxiv.org/abs/2307.01181v1</link><description>We consider the problem $(\mathrm{P})$ of fitting $n$ standard Gaussianrandom vectors in $\mathbb{R}^d$ to the boundary of a centered ellipsoid, as$n, d \to \infty$. This problem is conjectured to have a sharp feasibilitytransition: for any $\varepsilon &gt; 0$, if $n \leq (1 - \varepsilon) d^2 / 4$then $(\mathrm{P})$ has a solution with high probability, while $(\mathrm{P})$has no solutions with high probability if $n \geq (1 + \varepsilon) d^2 /4$. Sofar, only a trivial bound $n \geq d^2 / 2$ is known on the negative side, whilethe best results on the positive side assume $n \leq d^2 /\mathrm{polylog}(d)$. In this work, we improve over previous approaches using akey result of Bartl &amp; Mendelson on the concentration of Gram matrices of randomvectors under mild assumptions on their tail behavior. This allows us to give asimple proof that $(\mathrm{P})$ is feasible with high probability when $n \leqd^2 / C$, for a (possibly large) constant $C &gt; 0$.</description><author>Afonso S. Bandeira, Antoine Maillard, Shahar Mendelson, Elliot Paquette</author><pubDate>Mon, 03 Jul 2023 18:46:23 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.01181v1</guid></item><item><title>PlanE: Representation Learning over Planar Graphs</title><link>http://arxiv.org/abs/2307.01180v1</link><description>Graph neural networks are prominent models for representation learning overgraphs, where the idea is to iteratively compute representations of nodes of aninput graph through a series of transformations in such a way that the learnedgraph function is isomorphism invariant on graphs, which makes the learnedrepresentations graph invariants. On the other hand, it is well-known thatgraph invariants learned by these class of models are incomplete: there arepairs of non-isomorphic graphs which cannot be distinguished by standard graphneural networks. This is unsurprising given the computational difficulty ofgraph isomorphism testing on general graphs, but the situation begs to differfor special graph classes, for which efficient graph isomorphism testingalgorithms are known, such as planar graphs. The goal of this work is to designarchitectures for efficiently learning complete invariants of planar graphs.Inspired by the classical planar graph isomorphism algorithm of Hopcroft andTarjan, we propose PlanE as a framework for planar representation learning.PlanE includes architectures which can learn complete invariants over planargraphs while remaining practically scalable. We empirically validate the strongperformance of the resulting model architectures on well-known planar graphbenchmarks, achieving multiple state-of-the-art results.</description><author>Radoslav Dimitrov, Zeyang Zhao, Ralph Abboud, ƒ∞smail ƒ∞lkan Ceylan</author><pubDate>Mon, 03 Jul 2023 18:45:01 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.01180v1</guid></item><item><title>Learning Mixtures of Gaussians Using the DDPM Objective</title><link>http://arxiv.org/abs/2307.01178v1</link><description>Recent works have shown that diffusion models can learn essentially anydistribution provided one can perform score estimation. Yet it remains poorlyunderstood under what settings score estimation is possible, let alone whenpractical gradient-based algorithms for this task can provably succeed. In this work, we give the first provably efficient results along these linesfor one of the most fundamental distribution families, Gaussian mixture models.We prove that gradient descent on the denoising diffusion probabilistic model(DDPM) objective can efficiently recover the ground truth parameters of themixture model in the following two settings: 1) We show gradient descent withrandom initialization learns mixtures of two spherical Gaussians in $d$dimensions with $1/\text{poly}(d)$-separated centers. 2) We show gradientdescent with a warm start learns mixtures of $K$ spherical Gaussians with$\Omega(\sqrt{\log(\min(K,d))})$-separated centers. A key ingredient in ourproofs is a new connection between score-based methods and two other approachesto distribution learning, the EM algorithm and spectral methods.</description><author>Kulin Shah, Sitan Chen, Adam Klivans</author><pubDate>Mon, 03 Jul 2023 18:44:22 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.01178v1</guid></item><item><title>ELQA: A Corpus of Metalinguistic Questions and Answers about English</title><link>http://arxiv.org/abs/2205.00395v2</link><description>We present ELQA, a corpus of questions and answers in and about the Englishlanguage. Collected from two online forums, the &gt;70k questions (from Englishlearners and others) cover wide-ranging topics including grammar, meaning,fluency, and etymology. The answers include descriptions of general propertiesof English vocabulary and grammar as well as explanations about specific(correct and incorrect) usage examples. Unlike most NLP datasets, this corpusis metalinguistic -- it consists of language about language. As such, it canfacilitate investigations of the metalinguistic capabilities of NLU models, aswell as educational applications in the language learning domain. To studythis, we define a free-form question answering task on our dataset and conductevaluations on multiple LLMs (Large Language Models) to analyze their capacityto generate metalinguistic answers.</description><author>Shabnam Behzad, Keisuke Sakaguchi, Nathan Schneider, Amir Zeldes</author><pubDate>Mon, 03 Jul 2023 18:42:36 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2205.00395v2</guid></item><item><title>Neural Hilbert Ladders: Multi-Layer Neural Networks in Function Space</title><link>http://arxiv.org/abs/2307.01177v1</link><description>The characterization of the functions spaces explored by neural networks(NNs) is an important aspect of deep learning theory. In this work, we view amulti-layer NN with arbitrary width as defining a particular hierarchy ofreproducing kernel Hilbert spaces (RKHSs), named a Neural Hilbert Ladder (NHL).This allows us to define a function space and a complexity measure thatgeneralize prior results for shallow NNs, and we then examine their theoreticalproperties and implications in several aspects. First, we prove acorrespondence between functions expressed by L-layer NNs and those belongingto L-level NHLs. Second, we prove generalization guarantees for learning an NHLwith the complexity measure controlled. Third, corresponding to the training ofmulti-layer NNs in the infinite-width mean-field limit, we derive an evolutionof the NHL characterized as the dynamics of multiple random fields. Fourth, weshow examples of depth separation in NHLs under ReLU and quadratic activationfunctions. Finally, we complement the theory with numerical results toillustrate the learning of RKHS in NN training.</description><author>Zhengdao Chen</author><pubDate>Mon, 03 Jul 2023 18:40:58 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.01177v1</guid></item><item><title>Quantum Neural Estimation of Entropies</title><link>http://arxiv.org/abs/2307.01171v1</link><description>Entropy measures quantify the amount of information and correlations presentin a quantum system. In practice, when the quantum state is unknown and onlycopies thereof are available, one must resort to the estimation of such entropymeasures. Here we propose a variational quantum algorithm for estimating thevon Neumann and R\'enyi entropies, as well as the measured relative entropy andmeasured R\'enyi relative entropy. Our approach first parameterizes avariational formula for the measure of interest by a quantum circuit and aclassical neural network, and then optimizes the resulting objective overparameter space. Numerical simulations of our quantum algorithm are provided,using a noiseless quantum simulator. The algorithm provides accurate estimatesof the various entropy measures for the examples tested, which renders it as apromising approach for usage in downstream tasks.</description><author>Ziv Goldfeld, Dhrumil Patel, Sreejith Sreekumar, Mark M. Wilde</author><pubDate>Mon, 03 Jul 2023 18:30:09 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.01171v1</guid></item><item><title>Online nearest neighbor classification</title><link>http://arxiv.org/abs/2307.01170v1</link><description>We study an instance of online non-parametric classification in therealizable setting. In particular, we consider the classical 1-nearest neighboralgorithm, and show that it achieves sublinear regret - that is, a vanishingmistake rate - against dominated or smoothed adversaries in the realizablesetting.</description><author>Sanjoy Dasgupta, Geelon So</author><pubDate>Mon, 03 Jul 2023 18:29:58 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.01170v1</guid></item><item><title>Analyzing and Improving Greedy 2-Coordinate Updates for Equality-Constrained Optimization via Steepest Descent in the 1-Norm</title><link>http://arxiv.org/abs/2307.01169v1</link><description>We consider minimizing a smooth function subject to a summation constraintover its variables. By exploiting a connection between the greedy 2-coordinateupdate for this problem and equality-constrained steepest descent in the1-norm, we give a convergence rate for greedy selection under a proximalPolyak-Lojasiewicz assumption that is faster than random selection andindependent of the problem dimension $n$. We then consider minimizing with botha summation constraint and bound constraints, as arises in the support vectormachine dual problem. Existing greedy rules for this setting either guaranteetrivial progress only or require $O(n^2)$ time to compute. We show that bound-and summation-constrained steepest descent in the L1-norm guarantees moreprogress per iteration than previous rules and can be computed in only $O(n\log n)$ time.</description><author>Amrutha Varshini Ramesh, Aaron Mishkin, Mark Schmidt, Yihan Zhou, Jonathan Wilder Lavington, Jennifer She</author><pubDate>Mon, 03 Jul 2023 18:27:18 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.01169v1</guid></item><item><title>Don't freeze: Finetune encoders for better Self-Supervised HAR</title><link>http://arxiv.org/abs/2307.01168v1</link><description>Recently self-supervised learning has been proposed in the field of humanactivity recognition as a solution to the labelled data availability problem.The idea being that by using pretext tasks such as reconstruction orcontrastive predictive coding, useful representations can be learned that thencan be used for classification. Those approaches follow the pretrain, freezeand fine-tune procedure. In this paper we will show how a simple change - notfreezing the representation - leads to substantial performance gains acrosspretext tasks. The improvement was found in all four investigated datasets andacross all four pretext tasks and is inversely proportional to amount oflabelled data. Moreover the effect is present whether the pretext task iscarried on the Capture24 dataset or directly in unlabelled data of the targetdataset.</description><author>Vitor Fortes Rey, Dominique Nshimyimana, Paul Lukowicz</author><pubDate>Mon, 03 Jul 2023 18:23:34 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.01168v1</guid></item><item><title>Coupled Gradient Flows for Strategic Non-Local Distribution Shift</title><link>http://arxiv.org/abs/2307.01166v1</link><description>We propose a novel framework for analyzing the dynamics of distribution shiftin real-world systems that captures the feedback loop between learningalgorithms and the distributions on which they are deployed. Prior work largelymodels feedback-induced distribution shift as adversarial or via an overlysimplistic distribution-shift structure. In contrast, we propose a coupledpartial differential equation model that captures fine-grained changes in thedistribution over time by accounting for complex dynamics that arise due tostrategic responses to algorithmic decision-making, non-local endogenouspopulation interactions, and other exogenous sources of distribution shift. Weconsider two common settings in machine learning: cooperative settings withinformation asymmetries, and competitive settings where a learner facesstrategic users. For both of these settings, when the algorithm retrains viagradient descent, we prove asymptotic convergence of the retraining procedureto a steady-state, both in finite and in infinite dimensions, obtainingexplicit rates in terms of the model parameters. To do so we derive new resultson the convergence of coupled PDEs that extends what is known on multi-speciessystems. Empirically, we show that our approach captures well-documented formsof distribution shifts like polarization and disparate impacts that simplermodels cannot capture.</description><author>Lauren Conger, Franca Hoffmann, Eric Mazumdar, Lillian Ratliff</author><pubDate>Mon, 03 Jul 2023 18:18:50 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.01166v1</guid></item><item><title>Improving Language Plasticity via Pretraining with Active Forgetting</title><link>http://arxiv.org/abs/2307.01163v1</link><description>Pretrained language models (PLMs) are today the primary model for naturallanguage processing. Despite their impressive downstream performance, it can bedifficult to apply PLMs to new languages, a barrier to making theircapabilities universally accessible. While prior work has shown it possible toaddress this issue by learning a new embedding layer for the new language,doing so is both data and compute inefficient. We propose to use an activeforgetting mechanism during pretraining, as a simple way of creating PLMs thatcan quickly adapt to new languages. Concretely, by resetting the embeddinglayer every K updates during pretraining, we encourage the PLM to improve itsability of learning new embeddings within a limited number of updates, similarto a meta-learning effect. Experiments with RoBERTa show that models pretrainedwith our forgetting mechanism not only demonstrate faster convergence duringlanguage adaptation but also outperform standard ones in a low-data regime,particularly for languages that are distant from English.</description><author>Yihong Chen, Kelly Marchisio, Roberta Raileanu, David Ifeoluwa Adelani, Pontus Stenetor, Sebastian Riedel, Mikel Artetx</author><pubDate>Mon, 03 Jul 2023 18:12:44 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.01163v1</guid></item><item><title>Soft Gripping: Specifying for Trustworthiness</title><link>http://arxiv.org/abs/2307.01159v1</link><description>Soft robotics is an emerging technology in which engineers create flexibledevices for use in a variety of applications. In order to advance the wideadoption of soft robots, ensuring their trustworthiness is essential; if softrobots are not trusted, they will not be used to their full potential. In orderto demonstrate trustworthiness, a specification needs to be formulated todefine what is trustworthy. However, even for soft robotic grippers, which isone of the most mature areas in soft robotics, the soft robotics community hasso far given very little attention to formulating specifications. In this work,we discuss the importance of developing specifications during development ofsoft robotic systems, and present an extensive example specification for a softgripper for pick-and-place tasks for grocery items. The proposed specificationcovers both functional and non-functional requirements, such as reliability,safety, adaptability, predictability, ethics, and regulations. We alsohighlight the need to promote verifiability as a first-class objective in thedesign of a soft gripper.</description><author>Dhaminda B. Abeywickrama, Nguyen Hao Le, Greg Chance, Peter D. Winter, Arianna Manzini, Alix J. Partridge, Jonathan Ives, John Downer, Graham Deacon, Jonathan Rossiter, Kerstin Eder, Shane Windsor</author><pubDate>Mon, 03 Jul 2023 18:10:19 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.01159v1</guid></item><item><title>Neural Algorithmic Reasoning with Causal Regularisation</title><link>http://arxiv.org/abs/2302.10258v2</link><description>Recent work on neural algorithmic reasoning has investigated the reasoningcapabilities of neural networks, effectively demonstrating they can learn toexecute classical algorithms on unseen data coming from the train distribution.However, the performance of existing neural reasoners significantly degrades onout-of-distribution (OOD) test data, where inputs have larger sizes. In thiswork, we make an important observation: there are many different inputs forwhich an algorithm will perform certain intermediate computations identically.This insight allows us to develop data augmentation procedures that, given analgorithm's intermediate trajectory, produce inputs for which the targetalgorithm would have exactly the same next trajectory step. We ensureinvariance in the next-step prediction across such inputs, by employing aself-supervised objective derived by our observation, formalised in a causalgraph. We prove that the resulting method, which we call Hint-ReLIC, improvesthe OOD generalisation capabilities of the reasoner. We evaluate our method onthe CLRS algorithmic reasoning benchmark, where we show up to 3$\times$improvements on the OOD test data.</description><author>Beatrice Bevilacqua, Kyriacos Nikiforou, Borja Ibarz, Ioana Bica, Michela Paganini, Charles Blundell, Jovana Mitrovic, Petar Veliƒçkoviƒá</author><pubDate>Mon, 03 Jul 2023 18:08:05 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2302.10258v2</guid></item><item><title>Theory of Mind as Intrinsic Motivation for Multi-Agent Reinforcement Learning</title><link>http://arxiv.org/abs/2307.01158v1</link><description>The ability to model the mental states of others is crucial to human socialintelligence, and can offer similar benefits to artificial agents with respectto the social dynamics induced in multi-agent settings. We present a method ofgrounding semantically meaningful, human-interpretable beliefs within policiesmodeled by deep networks. We then consider the task of 2nd-order beliefprediction. We propose that ability of each agent to predict the beliefs of theother agents can be used as an intrinsic reward signal for multi-agentreinforcement learning. Finally, we present preliminary empirical results in amixed cooperative-competitive environment.</description><author>Ini Oguntola, Joseph Campbell, Simon Stepputtis, Katia Sycara</author><pubDate>Mon, 03 Jul 2023 18:07:18 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.01158v1</guid></item><item><title>A novel approach for predicting epidemiological forecasting parameters based on real-time signals and Data Assimilation</title><link>http://arxiv.org/abs/2307.01157v1</link><description>This paper proposes a novel approach to predict epidemiological parameters byintegrating new real-time signals from various sources of information, such asnovel social media-based population density maps and Air Quality data. Weimplement an ensemble of Convolutional Neural Networks (CNN) models usingvarious data sources and fusion methodology to build robust predictions andsimulate several dynamic parameters that could improve the decision-makingprocess for policymakers. Additionally, we used data assimilation to estimatethe state of our system from fused CNN predictions. The combination ofmeteorological signals and social media-based population density maps improvedthe performance and flexibility of our prediction of the COVID-19 outbreak inLondon. While the proposed approach outperforms standard models, such ascompartmental models traditionally used in disease forecasting (SEIR),generating robust and consistent predictions allows us to increase thestability of our model while increasing its accuracy.</description><author>Romain Molinas, C√©sar Quilodr√°n Casas, Rossella Arcucci, Ovidiu ≈ûerban</author><pubDate>Mon, 03 Jul 2023 18:05:29 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.01157v1</guid></item><item><title>Investigating Data Memorization in 3D Latent Diffusion Models for Medical Image Synthesis</title><link>http://arxiv.org/abs/2307.01148v1</link><description>Generative latent diffusion models have been established as state-of-the-artin data generation. One promising application is generation of realisticsynthetic medical imaging data for open data sharing without compromisingpatient privacy. Despite the promise, the capacity of such models to memorizesensitive patient training data and synthesize samples showing high resemblanceto training data samples is relatively unexplored. Here, we assess thememorization capacity of 3D latent diffusion models on photon-counting coronarycomputed tomography angiography and knee magnetic resonance imaging datasets.To detect potential memorization of training samples, we utilizeself-supervised models based on contrastive learning. Our results suggest thatsuch latent diffusion models indeed memorize training data, and there is a direneed for devising strategies to mitigate memorization.</description><author>Salman Ul Hassan Dar, Arman Ghanaat, Jannik Kahmann, Isabelle Ayx, Theano Papavassiliou, Stefan O. Schoenberg, Sandy Engelhardt</author><pubDate>Mon, 03 Jul 2023 17:39:28 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.01148v1</guid></item><item><title>AVSegFormer: Audio-Visual Segmentation with Transformer</title><link>http://arxiv.org/abs/2307.01146v1</link><description>The combination of audio and vision has long been a topic of interest in themulti-modal community. Recently, a new audio-visual segmentation (AVS) task hasbeen introduced, aiming to locate and segment the sounding objects in a givenvideo. This task demands audio-driven pixel-level scene understanding for thefirst time, posing significant challenges. In this paper, we proposeAVSegFormer, a novel framework for AVS tasks that leverages the transformerarchitecture. Specifically, we introduce audio queries and learnable queriesinto the transformer decoder, enabling the network to selectively attend tointerested visual features. Besides, we present an audio-visual mixer, whichcan dynamically adjust visual features by amplifying relevant and suppressingirrelevant spatial channels. Additionally, we devise an intermediate mask lossto enhance the supervision of the decoder, encouraging the network to producemore accurate intermediate predictions. Extensive experiments demonstrate thatAVSegFormer achieves state-of-the-art results on the AVS benchmark. The code isavailable at https://github.com/vvvb-github/AVSegFormer.</description><author>Shengyi Gao, Zhe Chen, Guo Chen, Wenhai Wang, Tong Lu</author><pubDate>Mon, 03 Jul 2023 17:37:10 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.01146v1</guid></item><item><title>Lower Complexity Adaptation for Empirical Entropic Optimal Transport</title><link>http://arxiv.org/abs/2306.13580v2</link><description>Entropic optimal transport (EOT) presents an effective and computationallyviable alternative to unregularized optimal transport (OT), offering diverseapplications for large-scale data analysis. In this work, we derive novelstatistical bounds for empirical plug-in estimators of the EOT cost and showthat their statistical performance in the entropy regularization parameter$\epsilon$ and the sample size $n$ only depends on the simpler of the twoprobability measures. For instance, under sufficiently smooth costs this yieldsthe parametric rate $n^{-1/2}$ with factor $\epsilon^{-d/2}$, where $d$ is theminimum dimension of the two population measures. This confirms that empiricalEOT also adheres to the lower complexity adaptation principle, a hallmarkfeature only recently identified for unregularized OT. As a consequence of ourtheory, we show that the empirical entropic Gromov-Wasserstein distance and itsunregularized version for measures on Euclidean spaces also obey thisprinciple. Additionally, we comment on computational aspects and complement ourfindings with Monte Carlo simulations. Our techniques employ empirical processtheory and rely on a dual formulation of EOT over a single function class.Crucial to our analysis is the observation that the entropiccost-transformation of a function class does not increase its uniform metricentropy by much.</description><author>Michel Groppe, Shayan Hundrieser</author><pubDate>Mon, 03 Jul 2023 17:37:05 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.13580v2</guid></item><item><title>Statler: State-Maintaining Language Models for Embodied Reasoning</title><link>http://arxiv.org/abs/2306.17840v2</link><description>Large language models (LLMs) provide a promising tool that enable robots toperform complex robot reasoning tasks. However, the limited context window ofcontemporary LLMs makes reasoning over long time horizons difficult. Embodiedtasks such as those that one might expect a household robot to performtypically require that the planner consider information acquired a long timeago (e.g., properties of the many objects that the robot previously encounteredin the environment). Attempts to capture the world state using an LLM'simplicit internal representation is complicated by the paucity of task- andenvironment-relevant information available in a robot's action history, whilemethods that rely on the ability to convey information via the prompt to theLLM are subject to its limited context window. In this paper, we proposeStatler, a framework that endows LLMs with an explicit representation of theworld state as a form of ``memory'' that is maintained over time. Integral toStatler is its use of two instances of general LLMs -- a world-model reader anda world-model writer -- that interface with and maintain the world state. Byproviding access to this world state ``memory'', Statler improves the abilityof existing LLMs to reason over longer time horizons without the constraint ofcontext length. We evaluate the effectiveness of our approach on threesimulated table-top manipulation domains and a real robot domain, and show thatit improves the state-of-the-art in LLM-based robot reasoning. Project website:https://statler-lm.github.io/</description><author>Takuma Yoneda, Jiading Fang, Peng Li, Huanyu Zhang, Tianchong Jiang, Shengjie Lin, Ben Picker, David Yunis, Hongyuan Mei, Matthew R. Walter</author><pubDate>Mon, 03 Jul 2023 17:32:03 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.17840v2</guid></item><item><title>SCITUNE: Aligning Large Language Models with Scientific Multimodal Instructions</title><link>http://arxiv.org/abs/2307.01139v1</link><description>Instruction finetuning is a popular paradigm to align large language models(LLM) with human intent. Despite its popularity, this idea is less explored inimproving the LLMs to align existing foundation models with scientificdisciplines, concepts and goals. In this work, we present SciTune as a tuningframework to improve the ability of LLMs to follow scientific multimodalinstructions. To test our methodology, we use a human-generated scientificinstruction tuning dataset and train a large multimodal model LLaMA-SciTunethat connects a vision encoder and LLM for science-focused visual and languageunderstanding. In comparison to the models that are finetuned with machinegenerated data only, LLaMA-SciTune surpasses human performance on average andin many sub-categories on the ScienceQA benchmark.</description><author>Sameera Horawalavithana, Sai Munikoti, Ian Stewart, Henry Kvinge</author><pubDate>Mon, 03 Jul 2023 17:25:49 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.01139v1</guid></item><item><title>SparseOptimizer: Sparsify Language Models through Moreau-Yosida Regularization and Accelerate via Compiler Co-design</title><link>http://arxiv.org/abs/2306.15656v2</link><description>This paper introduces SparseOptimizer, a novel deep learning optimizer thatexploits Moreau-Yosida regularization to naturally induce sparsity in largelanguage models such as BERT, ALBERT and GPT. Key to the design ofSparseOptimizer is an embedded shrinkage operator, which imparts sparsitydirectly within the optimization process. This operator, backed by a soundtheoretical framework, includes an analytical solution, thereby reinforcing theoptimizer's robustness and efficacy. Crucially, SparseOptimizer's plug-and-playfunctionality eradicates the need for code modifications, making it auniversally adaptable tool for a wide array of large language models. Empiricalevaluations on benchmark datasets such as GLUE, RACE, SQuAD1, and SQuAD2confirm that SparseBERT and SparseALBERT, when sparsified usingSparseOptimizer, achieve performance comparable to their dense counterparts,BERT and ALBERT, while significantly reducing their parameter count. Further,this work proposes an innovative optimizer-compiler co-design strategy,demonstrating the potential of inference acceleration (\textbf{3.37x},\textbf{6.30x}, and \textbf{7.15x} in comparison with Pytorch, TensorFlow, andLLVM generic compile, respectively) in SparseBERT when paired with anappropriately designed compiler. This study represents a significant stepforward in the evolution of efficient, scalable, and high-performing largelanguage models, setting a precedent for future exploration and optimization inthis domain. The SparseOptimizer code and SparseALBERT model will be publiclyavailable upon paper acceptance.</description><author>Fu-Ming Guo</author><pubDate>Mon, 03 Jul 2023 17:25:34 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.15656v2</guid></item><item><title>Exploring the In-context Learning Ability of Large Language Model for Biomedical Concept Linking</title><link>http://arxiv.org/abs/2307.01137v1</link><description>The biomedical field relies heavily on concept linking in various areas suchas literature mining, graph alignment, information retrieval,question-answering, data, and knowledge integration. Although large languagemodels (LLMs) have made significant strides in many natural language processingtasks, their effectiveness in biomedical concept mapping is yet to be fullyexplored. This research investigates a method that exploits the in-contextlearning (ICL) capabilities of large models for biomedical concept linking. Theproposed approach adopts a two-stage retrieve-and-rank framework. Initially,biomedical concepts are embedded using language models, and then embeddingsimilarity is utilized to retrieve the top candidates. These candidates'contextual information is subsequently incorporated into the prompt andprocessed by a large language model to re-rank the concepts. This approachachieved an accuracy of 90.% in BC5CDR disease entity normalization and 94.7%in chemical entity normalization, exhibiting a competitive performance relativeto supervised learning methods. Further, it showed a significant improvement,with an over 20-point absolute increase in F1 score on an oncology matchingdataset. Extensive qualitative assessments were conducted, and the benefits andpotential shortcomings of using large language models within the biomedicaldomain were discussed. were discussed.</description><author>Qinyong Wang, Zhenxiang Gao, Rong Xu</author><pubDate>Mon, 03 Jul 2023 17:19:50 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.01137v1</guid></item><item><title>Networked Time Series Prediction with Incomplete Data</title><link>http://arxiv.org/abs/2110.02271v2</link><description>A networked time series (NETS) is a family of time series on a given graph,one for each node. It has found a wide range of applications from intelligenttransportation, environment monitoring to mobile network management. Animportant task in such applications is to predict the future values of a NETSbased on its historical values and the underlying graph. Most existing methodsrequire complete data for training. However, in real-world scenarios, it is notuncommon to have missing data due to sensor malfunction, incomplete sensingcoverage, etc. In this paper, we study the problem of NETS prediction withincomplete data. We propose NETS-ImpGAN, a novel deep learning framework thatcan be trained on incomplete data with missing values in both history andfuture. Furthermore, we propose novel Graph Temporal Attention Networks byincorporating the attention mechanism to capture both inter-time seriescorrelations and temporal correlations. We conduct extensive experiments onthree real-world datasets under different missing patterns and missing rates.The experimental results show that NETS-ImpGAN outperforms existing methodsexcept when data exhibit very low variance, in which case NETS-ImpGAN stillachieves competitive performance.</description><author>Yichen Zhu, Mengtian Zhang, Bo Jiang, Haiming Jin, Jianqiang Huang, Xinbing Wang</author><pubDate>Mon, 03 Jul 2023 17:18:31 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2110.02271v2</guid></item><item><title>ChatGPT vs. Google: A Comparative Study of Search Performance and User Experience</title><link>http://arxiv.org/abs/2307.01135v1</link><description>The advent of ChatGPT, a large language model-powered chatbot, has promptedquestions about its potential implications for traditional search engines. Inthis study, we investigate the differences in user behavior when employingsearch engines and chatbot tools for information-seeking tasks. We carry out arandomized online experiment, dividing participants into two groups: one usinga ChatGPT-like tool and the other using a Google Search-like tool. Our findingsreveal that the ChatGPT group consistently spends less time on all tasks, withno significant difference in overall task performance between the groups.Notably, ChatGPT levels user search performance across different educationlevels and excels in answering straightforward questions and providing generalsolutions but falls short in fact-checking tasks. Users perceive ChatGPT'sresponses as having higher information quality compared to Google Search,despite displaying a similar level of trust in both tools. Furthermore,participants using ChatGPT report significantly better user experiences interms of usefulness, enjoyment, and satisfaction, while perceived ease of useremains comparable between the two tools. However, ChatGPT may also lead tooverreliance and generate or replicate misinformation, yielding inconsistentresults. Our study offers valuable insights for search engine management andhighlights opportunities for integrating chatbot technologies into searchengine designs.</description><author>Ruiyun Xu, Yue Feng, Hailiang Chen</author><pubDate>Mon, 03 Jul 2023 17:15:34 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.01135v1</guid></item><item><title>Increasing Fairness via Combination with Learning Guarantees</title><link>http://arxiv.org/abs/2301.10813v2</link><description>The concern about underlying discrimination hidden in ML models isincreasing, as ML systems have been widely applied in more and more real-worldscenarios and any discrimination hidden in them will directly affect humanlife. Many techniques have been developed to enhance fairness includingcommonly-used group fairness measures and several fairness-aware methodscombining ensemble learning. However, existing fairness measures can only focuson one aspect -- either group or individual fairness, and the hardcompatibility among them indicates a possibility of remaining biases even ifone of them is satisfied. Moreover, existing mechanisms to boost fairnessusually present empirical results to show validity, yet few of them discusswhether fairness can be boosted with certain theoretical guarantees. To addressthese issues, we propose a fairness quality measure named discriminative riskin this paper to reflect both individual and group fairness aspects.Furthermore, we investigate the properties of the proposed measure and proposefirst- and second-order oracle bounds to show that fairness can be boosted viaensemble combination with theoretical learning guarantees. Note that theanalysis is suitable for both binary and multi-class classification. A pruningmethod is also proposed to utilise our proposed measure and comprehensiveexperiments are conducted to evaluate the effectiveness of the proposed methodsin this paper.</description><author>Yijun Bian, Kun Zhang, Anqi Qiu</author><pubDate>Mon, 03 Jul 2023 17:12:19 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2301.10813v2</guid></item><item><title>Shikra: Unleashing Multimodal LLM's Referential Dialogue Magic</title><link>http://arxiv.org/abs/2306.15195v2</link><description>In human conversations, individuals can indicate relevant regions within ascene while addressing others. In turn, the other person can then respond byreferring to specific regions if necessary. This natural referential ability indialogue remains absent in current Multimodal Large Language Models (MLLMs). Tofill this gap, this paper proposes an MLLM called Shikra, which can handlespatial coordinate inputs and outputs in natural language. Its architectureconsists of a vision encoder, an alignment layer, and a LLM. It is designed tobe straightforward and simple, without the need for extra vocabularies,position encoder, pre-/post-detection modules, or external plug-in models. Allinputs and outputs are in natural language form. Referential dialogue is asuperset of various vision-language (VL) tasks. Shikra can naturally handlelocation-related tasks like REC and PointQA, as well as conventional VL taskssuch as Image Captioning and VQA. Experimental results showcase Shikra'spromising performance. Furthermore, it enables numerous exciting applications,like providing mentioned objects' coordinates in chains of thoughts andcomparing user-pointed regions similarities. Our code, model and dataset areaccessed at https://github.com/shikras/shikra.</description><author>Keqin Chen, Zhao Zhang, Weili Zeng, Richong Zhang, Feng Zhu, Rui Zhao</author><pubDate>Mon, 03 Jul 2023 17:08:00 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.15195v2</guid></item><item><title>Iterative Zero-Shot LLM Prompting for Knowledge Graph Construction</title><link>http://arxiv.org/abs/2307.01128v1</link><description>In the current digitalization era, capturing and effectively representingknowledge is crucial in most real-world scenarios. In this context, knowledgegraphs represent a potent tool for retrieving and organizing a vast amount ofinformation in a properly interconnected and interpretable structure. However,their generation is still challenging and often requires considerable humaneffort and domain expertise, hampering the scalability and flexibility acrossdifferent application fields. This paper proposes an innovative knowledge graphgeneration approach that leverages the potential of the latest generative largelanguage models, such as GPT-3.5, that can address all the main critical issuesin knowledge graph building. The approach is conveyed in a pipeline thatcomprises novel iterative zero-shot and external knowledge-agnostic strategiesin the main stages of the generation process. Our unique manifold approach mayencompass significant benefits to the scientific community. In particular, themain contribution can be summarized by: (i) an innovative strategy foriteratively prompting large language models to extract relevant components ofthe final graph; (ii) a zero-shot strategy for each prompt, meaning that thereis no need for providing examples for "guiding" the prompt result; (iii) ascalable solution, as the adoption of LLMs avoids the need for any externalresources or human expertise. To assess the effectiveness of our proposedmodel, we performed experiments on a dataset that covered a specific domain. Weclaim that our proposal is a suitable solution for scalable and versatileknowledge graph construction and may be applied to different and novelcontexts.</description><author>Salvatore Carta, Alessandro Giuliani, Leonardo Piano, Alessandro Sebastian Podda, Livio Pompianu, Sandro Gabriele Tiddia</author><pubDate>Mon, 03 Jul 2023 17:01:45 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.01128v1</guid></item><item><title>Cross-modality Attention Adapter: A Glioma Segmentation Fine-tuning Method for SAM Using Multimodal Brain MR Images</title><link>http://arxiv.org/abs/2307.01124v1</link><description>According to the 2021 World Health Organization (WHO) Classification schemefor gliomas, glioma segmentation is a very important basis for diagnosis andgenotype prediction. In general, 3D multimodal brain MRI is an effectivediagnostic tool. In the past decade, there has been an increase in the use ofmachine learning, particularly deep learning, for medical images processing.Thanks to the development of foundation models, models pre-trained withlarge-scale datasets have achieved better results on a variety of tasks.However, for medical images with small dataset sizes, deep learning methodsstruggle to achieve better results on real-world image datasets. In this paper,we propose a cross-modality attention adapter based on multimodal fusion tofine-tune the foundation model to accomplish the task of glioma segmentation inmultimodal MRI brain images with better results. The effectiveness of theproposed method is validated via our private glioma data set from the FirstAffiliated Hospital of Zhengzhou University (FHZU) in Zhengzhou, China. Ourproposed method is superior to current state-of-the-art methods with a Dice of88.38% and Hausdorff distance of 10.64, thereby exhibiting a 4% increase inDice to segment the glioma region for glioma treatment.</description><author>Xiaoyu Shi, Shurong Chai, Yinhao Li, Jingliang Cheng, Jie Bai, Guohua Zhao, Yen-Wei Chen</author><pubDate>Mon, 03 Jul 2023 16:55:18 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.01124v1</guid></item><item><title>Artifacts Mapping: Multi-Modal Semantic Mapping for Object Detection and 3D Localization</title><link>http://arxiv.org/abs/2307.01121v1</link><description>Geometric navigation is nowadays a well-established field of robotics and theresearch focus is shifting towards higher-level scene understanding, such asSemantic Mapping. When a robot needs to interact with its environment, it mustbe able to comprehend the contextual information of its surroundings. This workfocuses on classifying and localising objects within a map, which is underconstruction (SLAM) or already built. To further explore this direction, wepropose a framework that can autonomously detect and localize predefinedobjects in a known environment using a multi-modal sensor fusion approach(combining RGB and depth data from an RGB-D camera and a lidar). The frameworkconsists of three key elements: understanding the environment through RGB data,estimating depth through multi-modal sensor fusion, and managing artifacts(i.e., filtering and stabilizing measurements). The experiments show that theproposed framework can accurately detect 98% of the objects in the real sampleenvironment, without post-processing, while 85% and 80% of the objects weremapped using the single RGBD camera or RGB + lidar setup respectively. Thecomparison with single-sensor (camera or lidar) experiments is performed toshow that sensor fusion allows the robot to accurately detect near and farobstacles, which would have been noisy or imprecise in a purely visual orlaser-based approach.</description><author>Federico Rollo, Gennaro Raiola, Andrea Zunino, Nikolaos Tsagarakis, Arash Ajoudani</author><pubDate>Mon, 03 Jul 2023 16:51:39 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.01121v1</guid></item><item><title>Embeddings as Epistemic States: Limitations on the Use of Pooling Operators for Accumulating Knowledge</title><link>http://arxiv.org/abs/2210.05723v2</link><description>Various neural network architectures rely on pooling operators to aggregateinformation coming from different sources. It is often implicitly assumed insuch contexts that vectors encode epistemic states, i.e. that vectors capturethe evidence that has been obtained about some properties of interest, and thatpooling these vectors yields a vector that combines this evidence. We study,for a number of standard pooling operators, under what conditions they arecompatible with this idea, which we call the epistemic pooling principle. Whilewe find that all the considered pooling operators can satisfy the epistemicpooling principle, this only holds when embeddings are sufficientlyhigh-dimensional and, for most pooling operators, when the embeddings satisfyparticular constraints (e.g. having non-negative coordinates). We furthermoreshow that these constraints have important implications on how the embeddingscan be used in practice. In particular, we find that when the epistemic poolingprinciple is satisfied, in most cases it is impossible to verify thesatisfaction of propositional formulas using linear scoring functions, with twoexceptions: (i) max-pooling with embeddings that are upper-bounded and (ii)Hadamard pooling with non-negative embeddings. This finding helps to clarify,among others, why Graph Neural Networks sometimes under-perform in reasoningtasks. Finally, we also study an extension of the epistemic pooling principleto weighted epistemic states, which are important in the context ofnon-monotonic reasoning, where max-pooling emerges as the most suitableoperator.</description><author>Steven Schockaert</author><pubDate>Mon, 03 Jul 2023 16:46:06 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2210.05723v2</guid></item><item><title>MeT: A Graph Transformer for Semantic Segmentation of 3D Meshes</title><link>http://arxiv.org/abs/2307.01115v1</link><description>Polygonal meshes have become the standard for discretely approximating 3Dshapes, thanks to their efficiency and high flexibility in capturingnon-uniform shapes. This non-uniformity, however, leads to irregularity in themesh structure, making tasks like segmentation of 3D meshes particularlychallenging. Semantic segmentation of 3D mesh has been typically addressedthrough CNN-based approaches, leading to good accuracy. Recently, transformershave gained enough momentum both in NLP and computer vision fields, achievingperformance at least on par with CNN models, supporting the long-soughtarchitecture universalism. Following this trend, we propose a transformer-basedmethod for semantic segmentation of 3D mesh motivated by a better modeling ofthe graph structure of meshes, by means of global attention mechanisms. Inorder to address the limitations of standard transformer architectures inmodeling relative positions of non-sequential data, as in the case of 3Dmeshes, as well as in capturing the local context, we perform positionalencoding by means the Laplacian eigenvectors of the adjacency matrix, replacingthe traditional sinusoidal positional encodings, and by introducingclustering-based features into the self-attention and cross-attentionoperators. Experimental results, carried out on three sets of the Shape COSEGDataset, on the human segmentation dataset proposed in Maron et al., 2017 andon the ShapeNet benchmark, show how the proposed approach yieldsstate-of-the-art performance on semantic segmentation of 3D meshes.</description><author>Giuseppe Vecchio, Luca Prezzavento, Carmelo Pino, Francesco Rundo, Simone Palazzo, Concetto Spampinato</author><pubDate>Mon, 03 Jul 2023 16:45:14 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.01115v1</guid></item><item><title>EVD Surgical Guidance with Retro-Reflective Tool Tracking and Spatial Reconstruction using Head-Mounted Augmented Reality Device</title><link>http://arxiv.org/abs/2306.15490v2</link><description>Augmented Reality (AR) has been used to facilitate surgical guidance duringExternal Ventricular Drain (EVD) surgery, reducing the risks of misplacement inmanual operations. During this procedure, the key challenge is accuratelyestimating the spatial relationship between pre-operative images and actualpatient anatomy in AR environment. This research proposes a novel frameworkutilizing Time of Flight (ToF) depth sensors integrated in commerciallyavailable AR Head Mounted Devices (HMD) for precise EVD surgical guidance. Asprevious studies have proven depth errors for ToF sensors, we first assessedtheir properties on AR-HMDs. Subsequently, a depth error model andpatient-specific parameter identification method are introduced for accuratesurface information. A tracking pipeline combining retro-reflective markers andpoint clouds is then proposed for accurate head tracking. The head surface isreconstructed using depth data for spatial registration, avoiding fixingtracking targets rigidly on the patient's skull. Firstly, $7.580\pm 1.488 mm$depth value error was revealed on human skin, indicating the significance ofdepth correction. Our results showed that the error was reduced by over $85\%$using proposed depth correction method on head phantoms in different materials.Meanwhile, the head surface reconstructed with corrected depth data achievedsub-millimetre accuracy. An experiment on sheep head revealed $0.79 mm$reconstruction error. Furthermore, a user study was conducted for theperformance in simulated EVD surgery, where five surgeons performed nine k-wireinjections on a head phantom with virtual guidance. Results of this studyrevealed $2.09 \pm 0.16 mm$ translational accuracy and $2.97\pm 0.91$ degreeorientational accuracy.</description><author>Haowei Li, Wenqing Yan, Du Liu, Long Qian, Yuxing Yang, Yihao Liu, Zhe Zhao, Hui Ding, Guangzhi Wang</author><pubDate>Mon, 03 Jul 2023 16:42:19 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.15490v2</guid></item><item><title>A Survey on Generative Diffusion Model</title><link>http://arxiv.org/abs/2209.02646v9</link><description>Deep generative models are a prominent approach for data generation, and havebeen used to produce high quality samples in various domains. Diffusion models,an emerging class of deep generative models, have attracted considerableattention owing to their exceptional generative quality. Despite this, theyhave certain limitations, including a time-consuming iterative generationprocess and confinement to high-dimensional Euclidean space. This surveypresents a plethora of advanced techniques aimed at enhancing diffusion models,including sampling acceleration and the design of new diffusion processes. Inaddition, we delve into strategies for implementing diffusion models inmanifold and discrete spaces, maximum likelihood training for diffusion models,and methods for creating bridges between two arbitrary distributions. Theinnovations we discuss represent the efforts for improving the functionalityand efficiency of diffusion models in recent years. To examine the efficacy ofexisting models, a benchmark of FID score, IS, and NLL is presented in aspecific NFE. Furthermore, diffusion models are found to be useful in variousdomains such as computer vision, audio, sequence modeling, and AI for science.The paper concludes with a summary of this field, along with existinglimitations and future directions. Summation of existing well-classifiedmethods is in our Github:https://github.com/chq1155/A-Survey-on-Generative-Diffusion-Model</description><author>Hanqun Cao, Cheng Tan, Zhangyang Gao, Yilun Xu, Guangyong Chen, Pheng-Ann Heng, Stan Z. Li</author><pubDate>Mon, 03 Jul 2023 16:37:01 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2209.02646v9</guid></item><item><title>Sampling the lattice Nambu-Goto string using Continuous Normalizing Flows</title><link>http://arxiv.org/abs/2307.01107v1</link><description>Effective String Theory (EST) represents a powerful non-perturbative approachto describe confinement in Yang-Mills theory that models the confining fluxtube as a thin vibrating string. EST calculations are usually performed usingthe zeta-function regularization: however there are situations (for instancethe study of the shape of the flux tube or of the higher order correctionsbeyond the Nambu-Goto EST) which involve observables that are too complex to beaddressed in this way. In this paper we propose a numerical approach based onrecent advances in machine learning methods to circumvent this problem. Usingas a laboratory the Nambu-Goto string, we show that by using a new class ofdeep generative models called Continuous Normalizing Flows it is possible toobtain reliable numerical estimates of EST predictions.</description><author>Michele Caselle, Elia Cellini, Alessandro Nada</author><pubDate>Mon, 03 Jul 2023 16:34:36 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.01107v1</guid></item><item><title>Spatio-Angular Convolutions for Super-resolution in Diffusion MRI</title><link>http://arxiv.org/abs/2306.00854v2</link><description>Diffusion MRI (dMRI) is a widely used imaging modality, but requires longscanning times to acquire high resolution datasets. By leveraging the uniquegeometry present within this domain, we present a novel approach to dMRIangular super-resolution that extends upon the parametric continuousconvolution (PCConv) framework. We introduce several additions to the operationincluding a Fourier feature mapping, global coordinates, and domain specificcontext. Using this framework, we build a fully parametric continuousconvolution network (PCCNN) and compare against existing models. We demonstratethe PCCNN performs competitively while using significantly less parameters.Moreover, we show that this formulation generalises well to clinically relevantdownstream analyses such as fixel-based analysis, and neurite orientationdispersion and density imaging.</description><author>Matthew Lyon, Paul Armitage, Mauricio A √Ålvarez</author><pubDate>Mon, 03 Jul 2023 16:33:56 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.00854v2</guid></item><item><title>ContriMix: Unsupervised disentanglement of content and attribute for domain generalization in microscopy image analysis</title><link>http://arxiv.org/abs/2306.04527v2</link><description>Domain generalization is critical for real-world applications of machinelearning models to microscopy images, including histopathology and fluorescenceimaging. Artifacts in histopathology arise through a complex combination offactors relating to tissue collection and laboratory processing, as well asfactors intrinsic to patient samples. In fluorescence imaging, these artifactsstem from variations across experimental batches. The complexity and subtletyof these artifacts make the enumeration of data domains intractable. Therefore,augmentation-based methods of domain generalization that require domainidentifiers and manual fine-tuning are inadequate in this setting. To overcomethis challenge, we introduce ContriMix, a domain generalization technique thatlearns to generate synthetic images by disentangling and permuting thebiological content ("content") and technical variations ("attributes") inmicroscopy images. ContriMix does not rely on domain identifiers or handcraftedaugmentations and makes no assumptions about the input characteristics ofimages. We assess the performance of ContriMix on two pathology datasets(Camelyon17-WILDS and a prostate cell classification dataset) and onefluorescence microscopy dataset (RxRx1-WILDS). ContriMix outperforms currentstate-of-the-art methods in all datasets, motivating its usage for microscopyimage analysis in real-world settings where domain information is hard to comeby.</description><author>Tan H. Nguyen, Dinkar Juyal, Jin Li, Aaditya Prakash, Shima Nofallah, Chintan Shah, Sai Chowdary Gullapally, Michael Griffin, Anand Sampat, John Abel, Justin Lee, Amaro Taylor-Weiner</author><pubDate>Mon, 03 Jul 2023 16:29:43 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.04527v2</guid></item><item><title>Generalized iterated-sums signatures</title><link>http://arxiv.org/abs/2012.04597v3</link><description>We explore the algebraic properties of a generalized version of theiterated-sums signature, inspired by previous work of F.~Kir\'aly andH.~Oberhauser. In particular, we show how to recover the character property ofthe associated linear map over the tensor algebra by considering a deformedquasi-shuffle product of words on the latter. We introduce three non-lineartransformations on iterated-sums signatures, close in spirit to MachineLearning applications, and show some of their properties.</description><author>Joscha Diehl, Kurusch Ebrahimi-Fard, Nikolas Tapia</author><pubDate>Mon, 03 Jul 2023 16:24:56 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2012.04597v3</guid></item><item><title>Is ChatGPT Fair for Recommendation? Evaluating Fairness in Large Language Model Recommendation</title><link>http://arxiv.org/abs/2305.07609v2</link><description>The remarkable achievements of Large Language Models (LLMs) have led to theemergence of a novel recommendation paradigm -- Recommendation via LLM(RecLLM). Nevertheless, it is important to note that LLMs may contain socialprejudices, and therefore, the fairness of recommendations made by RecLLMrequires further investigation. To avoid the potential risks of RecLLM, it isimperative to evaluate the fairness of RecLLM with respect to various sensitiveattributes on the user side. Due to the differences between the RecLLM paradigmand the traditional recommendation paradigm, it is problematic to directly usethe fairness benchmark of traditional recommendation. To address the dilemma,we propose a novel benchmark called Fairness of Recommendation via LLM(FaiRLLM). This benchmark comprises carefully crafted metrics and a datasetthat accounts for eight sensitive attributes1 in two recommendation scenarios:music and movies. By utilizing our FaiRLLM benchmark, we conducted anevaluation of ChatGPT and discovered that it still exhibits unfairness to somesensitive attributes when generating recommendations. Our code and dataset canbe found at https://github.com/jizhi-zhang/FaiRLLM.</description><author>Jizhi Zhang, Keqin Bao, Yang Zhang, Wenjie Wang, Fuli Feng, Xiangnan He</author><pubDate>Mon, 03 Jul 2023 16:24:39 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.07609v2</guid></item><item><title>Variations of Squeeze and Excitation networks</title><link>http://arxiv.org/abs/2304.06502v2</link><description>Convolutional neural networks learns spatial features and are heavilyinterlinked within kernels. The SE module have broken the traditional route ofneural networks passing the entire result to next layer. Instead SE only passesimportant features to be learned with its squeeze and excitation (SE) module.We propose variations of the SE module which improvises the process of squeezeand excitation and enhances the performance. The proposed squeezing or excitingthe layer makes it possible for having a smooth transition of layer weights.These proposed variations also retain the characteristics of SE module. Theexperimented results are carried out on residual networks and the results aretabulated.</description><author>Mahendran NV</author><pubDate>Mon, 03 Jul 2023 16:20:03 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2304.06502v2</guid></item><item><title>MVDiffusion: Enabling Holistic Multi-view Image Generation with Correspondence-Aware Diffusion</title><link>http://arxiv.org/abs/2307.01097v1</link><description>This paper introduces MVDiffusion, a simple yet effective multi-view imagegeneration method for scenarios where pixel-to-pixel correspondences areavailable, such as perspective crops from panorama or multi-view images givengeometry (depth maps and poses). Unlike prior models that rely on iterativeimage warping and inpainting, MVDiffusion concurrently generates all imageswith a global awareness, encompassing high resolution and rich content,effectively addressing the error accumulation prevalent in preceding models.MVDiffusion specifically incorporates a correspondence-aware attentionmechanism, enabling effective cross-view interaction. This mechanism underpinsthree pivotal modules: 1) a generation module that produces low-resolutionimages while maintaining global correspondence, 2) an interpolation module thatdensifies spatial coverage between images, and 3) a super-resolution modulethat upscales into high-resolution outputs. In terms of panoramic imagery,MVDiffusion can generate high-resolution photorealistic images up to1024$\times$1024 pixels. For geometry-conditioned multi-view image generation,MVDiffusion demonstrates the first method capable of generating a textured mapof a scene mesh. The project page is at https://mvdiffusion.github.io.</description><author>Shitao Tang, Fuyang Zhang, Jiacheng Chen, Peng Wang, Yasutaka Furukawa</author><pubDate>Mon, 03 Jul 2023 16:19:17 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.01097v1</guid></item><item><title>Att-KGCN: Tourist Attractions Recommendation System by using Attention mechanism and Knowledge Graph Convolution Network</title><link>http://arxiv.org/abs/2306.10946v4</link><description>The recommendation algorithm based on knowledge graphs is at a relativelymature stage. However, there are still some problems in the recommendation ofspecific areas. For example, in the tourism field, selecting suitable touristattraction attributes process is complicated as the recommendation basis fortourist attractions. In this paper, we propose the improved Attention KnowledgeGraph Convolution Network model, named ($Att-KGCN$), which automaticallydiscovers the neighboring entities of the target scenic spot semantically. Theattention layer aggregates relatively similar locations and represents themwith an adjacent vector. Then, according to the tourist's preferred choices,the model predicts the probability of similar spots as a recommendation system.A knowledge graph dataset of tourist attractions used based on tourism data onSocotra Island-Yemen. Through experiments, it is verified that the AttentionKnowledge Graph Convolution Network has a good effect on the recommendation oftourist attractions and can make more recommendations for tourists' choices.</description><author>Ahmad A. Mubarak, JingJing Li, Han Cao</author><pubDate>Mon, 03 Jul 2023 16:19:08 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.10946v4</guid></item><item><title>UW-ProCCaps: UnderWater Progressive Colourisation with Capsules</title><link>http://arxiv.org/abs/2307.01091v1</link><description>Underwater images are fundamental for studying and understanding the statusof marine life. We focus on reducing the memory space required for imagestorage while the memory space consumption in the collecting phase limits thetime lasting of this phase leading to the need for more image collectioncampaigns. We present a novel machine-learning model that reconstructs thecolours of underwater images from their luminescence channel, thus saving 2/3of the available storage space. Our model specialises in underwater colourreconstruction and consists of an encoder-decoder architecture. The encoder iscomposed of a convolutional encoder and a parallel specialised classifiertrained with webly-supervised data. The encoder and the decoder use layers ofcapsules to capture the features of the entities in the image. The colourreconstruction process recalls the progressive and the generative adversarialtraining procedures. The progressive training gives the ground for a generativeadversarial routine focused on the refining of colours giving the image brightand saturated colours which bring the image back to life. We validate the modelboth qualitatively and quantitatively on four benchmark datasets. This is thefirst attempt at colour reconstruction in greyscale underwater images.Extensive results on four benchmark datasets demonstrate that our solutionoutperforms state-of-the-art (SOTA) solutions. We also demonstrate that thegenerated colourisation enhances the quality of images compared to enhancementmodels at the SOTA.</description><author>Rita Pucci, Niki Martine</author><pubDate>Mon, 03 Jul 2023 16:09:32 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.01091v1</guid></item><item><title>Streamlined Lensed Quasar Identification in Multiband Images via Ensemble Networks</title><link>http://arxiv.org/abs/2307.01090v1</link><description>Quasars experiencing strong lensing offer unique viewpoints on subjects likethe cosmic expansion rate, the dark matter profile within the foregrounddeflectors, and the quasar host galaxies. Unfortunately, identifying them inastronomical images is challenging since they are overwhelmed by the abundanceof non-lenses. To address this, we have developed a novel approach byensembling cutting-edge convolutional networks (CNNs) -- i.e., ResNet,Inception, NASNet, MobileNet, EfficientNet, and RegNet -- along with visiontransformers (ViTs) trained on realistic galaxy-quasar lens simulations basedon the Hyper Suprime-Cam (HSC) multiband images. While the individual modelexhibits remarkable performance when evaluated against the test dataset,achieving an area under the receiver operating characteristic curve of $&gt;$97.4%and a median false positive rate of 3.1%, it struggles to generalize in realdata, indicated by numerous spurious sources picked by each classifier. Asignificant improvement is achieved by averaging these CNNs and ViTs, resultingin the impurities being downsized by factors up to 40. Subsequently, combiningthe HSC images with the UKIRT, VISTA, and unWISE data, we retrieveapproximately 60 million sources as parent samples and reduce this to 892,609after employing a photometry preselection to discover $z&gt;1.5$ lensed quasarswith Einstein radii of $\theta_\mathrm{E}&lt;5$ arcsec. Afterward, the ensembleclassifier indicates 3991 sources with a high probability of being lenses, forwhich we visually inspect, yielding 161 prevailing candidates awaitingspectroscopic confirmation. These outcomes suggest that automated deep learningpipelines hold great potential in effectively detecting strong lenses in vastdatasets with minimal manual visual inspection involved.</description><author>Irham Taufik Andika, Sherry H. Suyu, Raoul Ca√±ameras, Alejandra Melo, Stefan Schuldt, Yiping Shu, Anna-Christina Eilers, Anton Timur Jaelani, Minghao Yue</author><pubDate>Mon, 03 Jul 2023 16:09:10 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.01090v1</guid></item><item><title>Empirically Validating Conformal Prediction on Modern Vision Architectures Under Distribution Shift and Long-tailed Data</title><link>http://arxiv.org/abs/2307.01088v1</link><description>Conformal prediction has emerged as a rigorous means of providing deeplearning models with reliable uncertainty estimates and safety guarantees. Yet,its performance is known to degrade under distribution shift and long-tailedclass distributions, which are often present in real world applications. Here,we characterize the performance of several post-hoc and training-basedconformal prediction methods under these settings, providing the firstempirical evaluation on large-scale datasets and models. We show that acrossnumerous conformal methods and neural network families, performance greatlydegrades under distribution shifts violating safety guarantees. Similarly, weshow that in long-tailed settings the guarantees are frequently violated onmany classes. Understanding the limitations of these methods is necessary fordeployment in real world and safety-critical applications.</description><author>Kevin Kasa, Graham W. Taylor</author><pubDate>Mon, 03 Jul 2023 16:08:28 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.01088v1</guid></item><item><title>Some challenges of calibrating differentiable agent-based models</title><link>http://arxiv.org/abs/2307.01085v1</link><description>Agent-based models (ABMs) are a promising approach to modelling and reasoningabout complex systems, yet their application in practice is impeded by theircomplexity, discrete nature, and the difficulty of performing parameterinference and optimisation tasks. This in turn has sparked interest in theconstruction of differentiable ABMs as a strategy for combatting thesedifficulties, yet a number of challenges remain. In this paper, we discuss andpresent experiments that highlight some of these challenges, along withpotential solutions.</description><author>Arnau Quera-Bofarull, Joel Dyer, Anisoara Calinescu, Michael Wooldridge</author><pubDate>Mon, 03 Jul 2023 16:07:10 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.01085v1</guid></item><item><title>Improving Online Continual Learning Performance and Stability with Temporal Ensembles</title><link>http://arxiv.org/abs/2306.16817v2</link><description>Neural networks are very effective when trained on large datasets for a largenumber of iterations. However, when they are trained on non-stationary streamsof data and in an online fashion, their performance is reduced (1) by theonline setup, which limits the availability of data, (2) due to catastrophicforgetting because of the non-stationary nature of the data. Furthermore,several recent works (Caccia et al., 2022; Lange et al., 2023) arXiv:2205.13452showed that replay methods used in continual learning suffer from the stabilitygap, encountered when evaluating the model continually (rather than only ontask boundaries). In this article, we study the effect of model ensembling as away to improve performance and stability in online continual learning. Wenotice that naively ensembling models coming from a variety of training tasksincreases the performance in online continual learning considerably. Startingfrom this observation, and drawing inspirations from semi-supervised learningensembling methods, we use a lightweight temporal ensemble that computes theexponential moving average of the weights (EMA) at test time, and show that itcan drastically increase the performance and stability when used in combinationwith several methods from the literature.</description><author>Albin Soutif--Cormerais, Antonio Carta, Joost Van de Weijer</author><pubDate>Mon, 03 Jul 2023 15:55:43 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.16817v2</guid></item><item><title>Supervised Manifold Learning via Random Forest Geometry-Preserving Proximities</title><link>http://arxiv.org/abs/2307.01077v1</link><description>Manifold learning approaches seek the intrinsic, low-dimensional datastructure within a high-dimensional space. Mainstream manifold learningalgorithms, such as Isomap, UMAP, $t$-SNE, Diffusion Map, and LaplacianEigenmaps do not use data labels and are thus considered unsupervised. Existingsupervised extensions of these methods are limited to classification problemsand fall short of uncovering meaningful embeddings due to their constructionusing order non-preserving, class-conditional distances. In this paper, we showthe weaknesses of class-conditional manifold learning quantitatively andvisually and propose an alternate choice of kernel for superviseddimensionality reduction using a data-geometry-preserving variant of randomforest proximities as an initialization for manifold learning methods. We showthat local structure preservation using these proximities is near universalacross manifold learning approaches and global structure is properly maintainedusing diffusion-based algorithms.</description><author>Jake S. Rhodes</author><pubDate>Mon, 03 Jul 2023 15:55:11 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.01077v1</guid></item><item><title>Analyzing Multiple-Choice Reading and Listening Comprehension Tests</title><link>http://arxiv.org/abs/2307.01076v1</link><description>Multiple-choice reading and listening comprehension tests are an importantpart of language assessment. Content creators for standard educational testsneed to carefully curate questions that assess the comprehension abilities ofcandidates taking the tests. However, recent work has shown that a large numberof questions in general multiple-choice reading comprehension datasets can beanswered without comprehension, by leveraging world knowledge instead. Thiswork investigates how much of a contextual passage needs to be read inmultiple-choice reading based on conversation transcriptions and listeningcomprehension tests to be able to work out the correct answer. We find thatautomated reading comprehension systems can perform significantly better thanrandom with partial or even no access to the context passage. These findingsoffer an approach for content creators to automatically capture the trade-offbetween comprehension and world knowledge required for their proposedquestions.</description><author>Vatsal Raina, Adian Liusie, Mark Gales</author><pubDate>Mon, 03 Jul 2023 15:55:02 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.01076v1</guid></item><item><title>DataCI: A Platform for Data-Centric AI on Streaming Data</title><link>http://arxiv.org/abs/2306.15538v2</link><description>We introduce DataCI, a comprehensive open-source platform designedspecifically for data-centric AI in dynamic streaming data settings. DataCIprovides 1) an infrastructure with rich APIs for seamless streaming datasetmanagement, data-centric pipeline development and evaluation on streamingscenarios, 2) an carefully designed versioning control function to track thepipeline lineage, and 3) an intuitive graphical interface for a betterinteractive user experience. Preliminary studies and demonstrations attest tothe easy-to-use and effectiveness of DataCI, highlighting its potential torevolutionize the practice of data-centric AI in streaming data contexts.</description><author>Huaizheng Zhang, Yizheng Huang, Yuanming Li</author><pubDate>Mon, 03 Jul 2023 15:54:57 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.15538v2</guid></item><item><title>When Can Linear Learners be Robust to Indiscriminate Poisoning Attacks?</title><link>http://arxiv.org/abs/2307.01073v1</link><description>We study indiscriminate poisoning for linear learners where an adversaryinjects a few crafted examples into the training data with the goal of forcingthe induced model to incur higher test error. Inspired by the observation thatlinear learners on some datasets are able to resist the best known attacks evenwithout any defenses, we further investigate whether datasets can be inherentlyrobust to indiscriminate poisoning attacks for linear learners. For theoreticalGaussian distributions, we rigorously characterize the behavior of an optimalpoisoning attack, defined as the poisoning strategy that attains the maximumrisk of the induced model at a given poisoning budget. Our results prove thatlinear learners can indeed be robust to indiscriminate poisoning if theclass-wise data distributions are well-separated with low variance and the sizeof the constraint set containing all permissible poisoning points is alsosmall. These findings largely explain the drastic variation in empirical attackperformance of the state-of-the-art poisoning attacks on linear learners acrossbenchmark datasets, making an important initial step towards understanding theunderlying reasons some learning tasks are vulnerable to data poisoningattacks.</description><author>Fnu Suya, Xiao Zhang, Yuan Tian, David Evans</author><pubDate>Mon, 03 Jul 2023 15:54:13 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.01073v1</guid></item><item><title>A unified stochastic approximation framework for learning in games</title><link>http://arxiv.org/abs/2206.03922v2</link><description>We develop a flexible stochastic approximation framework for analyzing thelong-run behavior of learning in games (both continuous and finite). Theproposed analysis template incorporates a wide array of popular learningalgorithms, including gradient-based methods, the exponential/multiplicativeweights algorithm for learning in finite games, optimistic and bandit variantsof the above, etc. In addition to providing an integrated view of thesealgorithms, our framework further allows us to obtain several new convergenceresults, both asymptotic and in finite time, in both continuous and finitegames. Specifically, we provide a range of criteria for identifying classes ofNash equilibria and sets of action profiles that are attracting with highprobability, and we also introduce the notion of coherence, a game-theoreticproperty that includes strict and sharp equilibria, and which leads toconvergence in finite time. Importantly, our analysis applies to bothoracle-based and bandit, payoff-based methods - that is, when players onlyobserve their realized payoffs.</description><author>Panayotis Mertikopoulos, Ya-Ping Hsieh, Volkan Cevher</author><pubDate>Mon, 03 Jul 2023 15:51:31 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2206.03922v2</guid></item><item><title>Shi-NeSS: Detecting Good and Stable Keypoints with a Neural Stability Score</title><link>http://arxiv.org/abs/2307.01069v1</link><description>Learning a feature point detector presents a challenge both due to theambiguity of the definition of a keypoint and correspondingly the need for aspecially prepared ground truth labels for such points. In our work, we addressboth of these issues by utilizing a combination of a hand-crafted Shi detectorand a neural network. We build on the principled and localized keypointsprovided by the Shi detector and perform their selection using the keypointstability score regressed by the neural network - Neural Stability Score(NeSS). Therefore, our method is named Shi-NeSS since it combines the Shidetector and the properties of the keypoint stability score, and it onlyrequires for training sets of images without dataset pre-labeling or the needfor reconstructed correspondence labels. We evaluate Shi-NeSS on HPatches,ScanNet, MegaDepth and IMC-PT, demonstrating state-of-the-art performance andgood generalization on downstream tasks.</description><author>Konstantin Pakulev, Alexander Vakhitov, Gonzalo Ferrer</author><pubDate>Mon, 03 Jul 2023 15:50:14 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.01069v1</guid></item><item><title>Localized Questions in Medical Visual Question Answering</title><link>http://arxiv.org/abs/2307.01067v1</link><description>Visual Question Answering (VQA) models aim to answer natural languagequestions about given images. Due to its ability to ask questions that differfrom those used when training the model, medical VQA has received substantialattention in recent years. However, existing medical VQA models typically focuson answering questions that refer to an entire image rather than where therelevant content may be located in the image. Consequently, VQA models arelimited in their interpretability power and the possibility to probe the modelabout specific image regions. This paper proposes a novel approach for medicalVQA that addresses this limitation by developing a model that can answerquestions about image regions while considering the context necessary to answerthe questions. Our experimental results demonstrate the effectiveness of ourproposed model, outperforming existing methods on three datasets. Our code anddata are available at https://github.com/sergiotasconmorales/locvqa.</description><author>Sergio Tascon-Morales, Pablo M√°rquez-Neila, Raphael Sznitman</author><pubDate>Mon, 03 Jul 2023 15:47:18 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.01067v1</guid></item><item><title>Active Acquisition for Multimodal Temporal Data: A Challenging Decision-Making Task</title><link>http://arxiv.org/abs/2211.05039v2</link><description>We introduce a challenging decision-making task that we call activeacquisition for multimodal temporal data (A2MT). In many real-world scenarios,input features are not readily available at test time and must instead beacquired at significant cost. With A2MT, we aim to learn agents that activelyselect which modalities of an input to acquire, trading off acquisition costand predictive performance. A2MT extends a previous task called active featureacquisition to temporal decision making about high-dimensional inputs. Wepropose a method based on the Perceiver IO architecture to address A2MT inpractice. Our agents are able to solve a novel synthetic scenario requiringpractically relevant cross-modal reasoning skills. On two large-scale,real-world datasets, Kinetics-700 and AudioSet, our agents successfully learncost-reactive acquisition behavior. However, an ablation reveals they areunable to learn adaptive acquisition strategies, emphasizing the difficulty ofthe task even for state-of-the-art models. Applications of A2MT may beimpactful in domains like medicine, robotics, or finance, where modalitiesdiffer in acquisition cost and informativeness.</description><author>Jannik Kossen, CƒÉtƒÉlina Cangea, Eszter V√©rtes, Andrew Jaegle, Viorica Patraucean, Ira Ktena, Nenad Tomasev, Danielle Belgrave</author><pubDate>Mon, 03 Jul 2023 15:47:18 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2211.05039v2</guid></item><item><title>A versatile deep learning-based protein-ligand interaction prediction model for accurate binding affinity scoring and virtual screening</title><link>http://arxiv.org/abs/2307.01066v1</link><description>Protein--ligand interaction (PLI) prediction is critical in drug discovery,aiding the identification and enhancement of molecules that effectively bind totarget proteins. Despite recent advances in deep learning-based PLI prediction,developing a versatile model capable of accurate binding affinity scoring andvirtual screening in PLI prediction is an ongoing challenge. This is primarilydue to the lack of structure--affinity data, resulting in low modelgeneralization ability. We here propose a viable solution to this challenge byintroducing a novel data augmentation strategy along with a physics-informedneural network. The resulting model exhibits significant improvement in bothscoring and screening capabilities. Its performance was compared totask-specific deep learning-based PLI prediction models, confirming itsversatility. Notably, it even outperformed computationally expensive moleculardynamics simulations as well as the other deep learning models in a derivativebenchmark while maintaining sufficiently high performance in virtual screening.This underscores the potential of this approach in drug discovery,demonstrating its applicability to both binding affinity scoring and virtualscreening.</description><author>Seokhyun Moon, Sang-Yeon Hwang, Jaechang Lim, Woo Youn Kim</author><pubDate>Mon, 03 Jul 2023 15:46:49 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.01066v1</guid></item><item><title>TomatoDIFF: On-plant Tomato Segmentation with Denoising Diffusion Models</title><link>http://arxiv.org/abs/2307.01064v1</link><description>Artificial intelligence applications enable farmers to optimize crop growthand production while reducing costs and environmental impact. Computervision-based algorithms in particular, are commonly used for fruitsegmentation, enabling in-depth analysis of the harvest quality and accurateyield estimation. In this paper, we propose TomatoDIFF, a novel diffusion-basedmodel for semantic segmentation of on-plant tomatoes. When evaluated againstother competitive methods, our model demonstrates state-of-the-art (SOTA)performance, even in challenging environments with highly occluded fruits.Additionally, we introduce Tomatopia, a new, large and challenging dataset ofgreenhouse tomatoes. The dataset comprises high-resolution RGB-D images andpixel-level annotations of the fruits.</description><author>Marija Ivanovska, Vitomir Struc, Janez Pers</author><pubDate>Mon, 03 Jul 2023 15:43:40 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.01064v1</guid></item><item><title>A Systematic Survey in Geometric Deep Learning for Structure-based Drug Design</title><link>http://arxiv.org/abs/2306.11768v3</link><description>Structure-based drug design (SBDD), which utilizes the three-dimensionalgeometry of proteins to identify potential drug candidates, is becomingincreasingly vital in drug discovery. However, traditional methods based onphysiochemical modeling and experts' domain knowledge are time-consuming andlaborious. The recent advancements in geometric deep learning, which integratesand processes 3D geometric data, coupled with the availability of accurateprotein 3D structure predictions from tools like AlphaFold, have significantlypropelled progress in structure-based drug design. In this paper, wesystematically review the recent progress of geometric deep learning forstructure-based drug design. We start with a brief discussion of the mainstreamtasks in structure-based drug design, commonly used 3D protein representationsand representative predictive/generative models. Then we delve into detailedreviews for each task (binding site prediction, binding pose generation,\emph{de novo} molecule generation, linker design, and binding affinityprediction), including the problem setup, representative methods, datasets, andevaluation metrics. Finally, we conclude this survey with the currentchallenges and highlight potential opportunities of geometric deep learning forstructure-based drug design.We curate a GitHub repo containing the relatedpapers \url{https://github.com/zaixizhang/Awesome-SBDD}.</description><author>Zaixi Zhang, Jiaxian Yan, Qi Liu, Enhong Chen</author><pubDate>Mon, 03 Jul 2023 15:38:17 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.11768v3</guid></item><item><title>The ROAD to discovery: machine learning-driven anomaly detection in radio astronomy spectrograms</title><link>http://arxiv.org/abs/2307.01054v1</link><description>As radio telescopes increase in sensitivity and flexibility, so do theircomplexity and data-rates. For this reason automated system health managementapproaches are becoming increasingly critical to ensure nominal telescopeoperations. We propose a new machine learning anomaly detection framework forclassifying both commonly occurring anomalies in radio telescopes as well asdetecting unknown rare anomalies that the system has potentially not yet seen.To evaluate our method, we present a dataset consisting of 7050autocorrelation-based spectrograms from the Low Frequency Array (LOFAR)telescope and assign 10 different labels relating to the system-wide anomaliesfrom the perspective of telescope operators. This includes electronic failures,miscalibration, solar storms, network and compute hardware errors among manymore. We demonstrate how a novel Self Supervised Learning (SSL) paradigm, thatutilises both context prediction and reconstruction losses, is effective inlearning normal behaviour of the LOFAR telescope. We present the RadioObservatory Anomaly Detector (ROAD), a framework that combines both SSL-basedanomaly detection and a supervised classification, thereby enabling bothclassification of both commonly occurring anomalies and detection of unseenanomalies. We demonstrate that our system is real-time in the context of theLOFAR data processing pipeline, requiring &lt;1ms to process a single spectrogram.Furthermore, ROAD obtains an anomaly detection F-2 score of 0.92 whilemaintaining a false positive rate of ~2\%, as well as a mean per-classclassification F-2 score 0.89, outperforming other related works.</description><author>Michael Mesarcik, Albert-Jan Boonstra, Marco Iacobelli, Elena Ranguelova, Cees de Laat, Rob van Nieuwpoort</author><pubDate>Mon, 03 Jul 2023 15:34:27 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.01054v1</guid></item><item><title>ENGAGE: Explanation Guided Data Augmentation for Graph Representation Learning</title><link>http://arxiv.org/abs/2307.01053v1</link><description>The recent contrastive learning methods, due to their effectiveness inrepresentation learning, have been widely applied to modeling graph data.Random perturbation is widely used to build contrastive views for graph data,which however, could accidentally break graph structures and lead to suboptimalperformance. In addition, graph data is usually highly abstract, so it is hardto extract intuitive meanings and design more informed augmentation schemes.Effective representations should preserve key characteristics in data andabandon superfluous information. In this paper, we propose ENGAGE (ExplaNationGuided data AuGmEntation), where explanation guides the contrastiveaugmentation process to preserve the key parts in graphs and explore removingsuperfluous information. Specifically, we design an efficient unsupervisedexplanation method called smoothed activation map as the indicator of nodeimportance in representation learning. Then, we design two data augmentationschemes on graphs for perturbing structural and feature information,respectively. We also provide justification for the proposed method in theframework of information theories. Experiments of both graph-level andnode-level tasks, on various model architectures and on different real-worldgraphs, are conducted to demonstrate the effectiveness and flexibility ofENGAGE. The code of ENGAGE can be found: https://github.com/sycny/ENGAGE.</description><author>Yucheng Shi, Kaixiong Zhou, Ninghao Liu</author><pubDate>Mon, 03 Jul 2023 15:33:14 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.01053v1</guid></item><item><title>Transport, Variational Inference and Diffusions: with Applications to Annealed Flows and Schr√∂dinger Bridges</title><link>http://arxiv.org/abs/2307.01050v1</link><description>This paper explores the connections between optimal transport and variationalinference, with a focus on forward and reverse time stochastic differentialequations and Girsanov transformations.We present a principled and systematicframework for sampling and generative modelling centred around divergences onpath space. Our work culminates in the development of a novel score-basedannealed flow technique (with connections to Jarzynski and Crooks identitiesfrom statistical physics) and a regularised iterative proportional fitting(IPF)-type objective, departing from the sequential nature of standard IPF.Through a series of generative modelling examples and a double-well-based rareevent task, we showcase the potential of the proposed methods.</description><author>Francisco Vargas, Nikolas N√ºsken</author><pubDate>Mon, 03 Jul 2023 15:28:36 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.01050v1</guid></item><item><title>Doubly Robust Estimation of Direct and Indirect Quantile Treatment Effects with Machine Learning</title><link>http://arxiv.org/abs/2307.01049v1</link><description>We suggest double/debiased machine learning estimators of direct and indirectquantile treatment effects under a selection-on-observables assumption. Thispermits disentangling the causal effect of a binary treatment at a specificoutcome rank into an indirect component that operates through an intermediatevariable called mediator and an (unmediated) direct impact. The proposed methodis based on the efficient score functions of the cumulative distributionfunctions of potential outcomes, which are robust to certain misspecificationsof the nuisance parameters, i.e., the outcome, treatment, and mediator models.We estimate these nuisance parameters by machine learning and use cross-fittingto reduce overfitting bias in the estimation of direct and indirect quantiletreatment effects. We establish uniform consistency and asymptotic normality ofour effect estimators. We also propose a multiplier bootstrap for statisticalinference and show the validity of the multiplier bootstrap. Finally, weinvestigate the finite sample performance of our method in a simulation studyand apply it to empirical data from the National Job Corp Study to assess thedirect and indirect earnings effects of training.</description><author>Yu-Chin Hsu, Martin Huber, Yu-Min Yen</author><pubDate>Mon, 03 Jul 2023 15:27:15 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.01049v1</guid></item><item><title>IndicMT Eval: A Dataset to Meta-Evaluate Machine Translation metrics for Indian Languages</title><link>http://arxiv.org/abs/2212.10180v2</link><description>The rapid growth of machine translation (MT) systems has necessitatedcomprehensive studies to meta-evaluate evaluation metrics being used, whichenables a better selection of metrics that best reflect MT quality.Unfortunately, most of the research focuses on high-resource languages, mainlyEnglish, the observations for which may not always apply to other languages.Indian languages, having over a billion speakers, are linguistically differentfrom English, and to date, there has not been a systematic study of evaluatingMT systems from English into Indian languages. In this paper, we fill this gapby creating an MQM dataset consisting of 7000 fine-grained annotations,spanning 5 Indian languages and 7 MT systems, and use it to establishcorrelations between annotator scores and scores obtained using existingautomatic metrics. Our results show that pre-trained metrics, such as COMET,have the highest correlations with annotator scores. Additionally, we find thatthe metrics do not adequately capture fluency-based errors in Indian languages,and there is a need to develop metrics focused on Indian languages. We hopethat our dataset and analysis will help promote further research in this area.</description><author>Ananya B. Sai, Vignesh Nagarajan, Tanay Dixit, Raj Dabre, Anoop Kunchukuttan, Pratyush Kumar, Mitesh M. Khapra</author><pubDate>Mon, 03 Jul 2023 15:26:38 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2212.10180v2</guid></item><item><title>Cross-modal Place Recognition in Image Databases using Event-based Sensors</title><link>http://arxiv.org/abs/2307.01047v1</link><description>Visual place recognition is an important problem towards global localizationin many robotics tasks. One of the biggest challenges is that it may sufferfrom illumination or appearance changes in surrounding environments. Eventcameras are interesting alternatives to frame-based sensors as their highdynamic range enables robust perception in difficult illumination conditions.However, current event-based place recognition methods only rely on eventinformation, which restricts downstream applications of VPR. In this paper, wepresent the first cross-modal visual place recognition framework that iscapable of retrieving regular images from a database given an event query. Ourmethod demonstrates promising results with respect to the state-of-the-artframe-based and event-based methods on the Brisbane-Event-VPR dataset underdifferent scenarios. We also verify the effectiveness of the combination ofretrieval and classification, which can boost performance by a large margin.</description><author>Xiang Ji, Jiaxin Wei, Yifu Wang, Huiliang Shang, Laurent Kneip</author><pubDate>Mon, 03 Jul 2023 15:24:04 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.01047v1</guid></item><item><title>Vector Quantile Regression on Manifolds</title><link>http://arxiv.org/abs/2307.01037v1</link><description>Quantile regression (QR) is a statistical tool for distribution-freeestimation of conditional quantiles of a target variable given explanatoryfeatures. QR is limited by the assumption that the target distribution isunivariate and defined on an Euclidean domain. Although the notion of quantileswas recently extended to multi-variate distributions, QR for multi-variatedistributions on manifolds remains underexplored, even though many importantapplications inherently involve data distributed on, e.g., spheres (climatemeasurements), tori (dihedral angles in proteins), or Lie groups (attitude innavigation). By leveraging optimal transport theory and the notion of$c$-concave functions, we meaningfully define conditional vector quantilefunctions of high-dimensional variables on manifolds (M-CVQFs). Our approachallows for quantile estimation, regression, and computation of conditionalconfidence sets. We demonstrate the approach's efficacy and provide insightsregarding the meaning of non-Euclidean quantiles through preliminary syntheticdata experiments.</description><author>Marco Pegoraro, Sanketh Vedula, Aviv A. Rosenberg, Irene Tallini, Emanuele Rodol√†, Alex M. Bronstein</author><pubDate>Mon, 03 Jul 2023 15:17:12 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.01037v1</guid></item><item><title>Shapley Curves: A Smoothing Perspective</title><link>http://arxiv.org/abs/2211.13289v3</link><description>Originating from cooperative game theory, Shapley values have become one ofthe most widely used measures for variable importance in applied MachineLearning. However, the statistical understanding of Shapley values is stilllimited. In this paper, we take a nonparametric (or smoothing) perspective byintroducing Shapley curves as a local measure of variable importance. Wepropose two estimation strategies and derive the consistency and asymptoticnormality both under independence and dependence among the features. Thisallows us to construct confidence intervals and conduct inference on theestimated Shapley curves. We propose a novel version of the wild bootstrapprocedure, specifically adjusted to give good finite sample coverage of theShapley curves. The asymptotic results are validated in extensive experiments.In an empirical application, we analyze which attributes drive the prices ofvehicles.</description><author>Ratmir Miftachov, Georg Keilbar, Wolfgang Karl H√§rdle</author><pubDate>Mon, 03 Jul 2023 15:15:37 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2211.13289v3</guid></item><item><title>Zero-Shot Cross-Lingual Summarization via Large Language Models</title><link>http://arxiv.org/abs/2302.14229v3</link><description>Given a document in a source language, cross-lingual summarization (CLS) aimsto generate a summary in a different target language. Recently, the emergenceof Large Language Models (LLMs), such as GPT-3.5, ChatGPT and GPT-4, hasattracted wide attention from the computational linguistics community. However,it is not yet known the performance of LLMs on CLS. In this report, weempirically use various prompts to guide LLMs to perform zero-shot CLS fromdifferent paradigms (i.e., end-to-end and pipeline), and provide a preliminaryevaluation on the generated summaries. We find that ChatGPT and GPT-4originally prefer to produce lengthy summaries with detailed information. Thesetwo LLMs can further balance informativeness and conciseness with the help ofan interactive prompt, significantly improving their CLS performance.Experimental results on three widely-used CLS datasets show that GPT-4 achievesstate-of-the-art zero-shot CLS performance, and performs competitively comparedwith the fine-tuned mBART-50. Moreover, we also find some multi-lingual andbilingual LLMs (i.e., BLOOMZ, ChatGLM-6B, Vicuna-13B and ChatYuan) have limitedzero-shot CLS ability. Due to the composite nature of CLS, which requiresmodels to perform summarization and translation simultaneously, accomplishingthis task in a zero-shot manner is even a challenge for LLMs. Therefore, wesincerely hope and recommend future LLM research could use CLS as a testbed.</description><author>Jiaan Wang, Yunlong Liang, Fandong Meng, Beiqi Zou, Zhixu Li, Jianfeng Qu, Jie Zhou</author><pubDate>Mon, 03 Jul 2023 15:11:38 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2302.14229v3</guid></item><item><title>Bipol: Multi-axes Evaluation of Bias with Explainability in Benchmark Datasets</title><link>http://arxiv.org/abs/2301.12139v2</link><description>We investigate five English NLP benchmark datasets (on the superGLUEleaderboard) and two Swedish datasets for bias, along multiple axes. Thedatasets are the following: Boolean Question (Boolq), CommitmentBank (CB),Winograd Schema Challenge (WSC), Wino-gender diagnostic (AXg), RecognisingTextual Entailment (RTE), Swedish CB, and SWEDN. Bias can be harmful and it isknown to be common in data, which ML models learn from. In order to mitigatebias in data, it is crucial to be able to estimate it objectively. We usebipol, a novel multi-axes bias metric with explainability, to estimate andexplain how much bias exists in these datasets. Multilingual, multi-axes biasevaluation is not very common. Hence, we also contribute a new, large Swedishbias-labelled dataset (of 2 million samples), translated from the Englishversion and train the SotA mT5 model on it. In addition, we contribute newmulti-axes lexica for bias detection in Swedish. We make the codes, model, andnew dataset publicly available.</description><author>Tosin Adewumi, Isabella S√∂dergren, Lama Alkhaled, Sana Sabah Sabry, Foteini Liwicki, Marcus Liwicki</author><pubDate>Mon, 03 Jul 2023 15:00:36 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2301.12139v2</guid></item><item><title>Temporal Graph Benchmark for Machine Learning on Temporal Graphs</title><link>http://arxiv.org/abs/2307.01026v1</link><description>We present the Temporal Graph Benchmark (TGB), a collection of challengingand diverse benchmark datasets for realistic, reproducible, and robustevaluation of machine learning models on temporal graphs. TGB datasets are oflarge scale, spanning years in duration, incorporate both node and edge-levelprediction tasks and cover a diverse set of domains including social, trade,transaction, and transportation networks. For both tasks, we design evaluationprotocols based on realistic use-cases. We extensively benchmark each datasetand find that the performance of common models can vary drastically acrossdatasets. In addition, on dynamic node property prediction tasks, we show thatsimple methods often achieve superior performance compared to existing temporalgraph models. We believe that these findings open up opportunities for futureresearch on temporal graphs. Finally, TGB provides an automated machinelearning pipeline for reproducible and accessible temporal graph research,including data loading, experiment setup and performance evaluation. TGB willbe maintained and updated on a regular basis and welcomes community feedback.TGB datasets, data loaders, example codes, evaluation setup, and leaderboardsare publicly available at https://tgb.complexdatalab.com/ .</description><author>Shenyang Huang, Farimah Poursafaei, Jacob Danovitch, Matthias Fey, Weihua Hu, Emanuele Rossi, Jure Leskovec, Michael Bronstein, Guillaume Rabusseau, Reihaneh Rabbany</author><pubDate>Mon, 03 Jul 2023 14:58:20 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.01026v1</guid></item><item><title>SAM-DA: UAV Tracks Anything at Night with SAM-Powered Domain Adaptation</title><link>http://arxiv.org/abs/2307.01024v1</link><description>Domain adaptation (DA) has demonstrated significant promise for real-timenighttime unmanned aerial vehicle (UAV) tracking. However, the state-of-the-art(SOTA) DA still lacks the potential object with accurate pixel-level locationand boundary to generate the high-quality target domain training sample. Thiskey issue constrains the transfer learning of the real-time daytime SOTAtrackers for challenging nighttime UAV tracking. Recently, the notable SegmentAnything Model (SAM) has achieved remarkable zero-shot generalization abilityto discover abundant potential objects due to its huge data-driven trainingapproach. To solve the aforementioned issue, this work proposes a novelSAM-powered DA framework for real-time nighttime UAV tracking, i.e., SAM-DA.Specifically, an innovative SAM-powered target domain training sample swellingis designed to determine enormous high-quality target domain training samplesfrom every single raw nighttime image. This novel one-to-many methodsignificantly expands the high-quality target domain training sample for DA.Comprehensive experiments on extensive nighttime UAV videos prove therobustness and domain adaptability of SAM-DA for nighttime UAV tracking.Especially, compared to the SOTA DA, SAM-DA can achieve better performance withfewer raw nighttime images, i.e., the fewer-better training. This economizedtraining approach facilitates the quick validation and deployment of algorithmsfor UAVs. The code is available at https://github.com/vision4robotics/SAM-DA.</description><author>Liangliang Yao, Haobo Zuo, Guangze Zheng, Changhong Fu, Jia Pan</author><pubDate>Mon, 03 Jul 2023 14:55:44 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.01024v1</guid></item><item><title>Neural Chronos ODE: Unveiling Temporal Patterns and Forecasting Future and Past Trends in Time Series Data</title><link>http://arxiv.org/abs/2307.01023v1</link><description>This work introduces Neural Chronos Ordinary Differential Equations (NeuralCODE), a deep neural network architecture that fits a continuous-time ODEdynamics for predicting the chronology of a system both forward and backward intime. To train the model, we solve the ODE as an initial value problem and afinal value problem, similar to Neural ODEs. We also explore two approaches tocombining Neural CODE with Recurrent Neural Networks by replacing Neural ODEwith Neural CODE (CODE-RNN), and incorporating a bidirectional RNN for fullinformation flow in both time directions (CODE-BiRNN), and variants with otherupdate cells namely GRU and LSTM: CODE-GRU, CODE-BiGRU, CODE-LSTM, CODE-BiLSTM. Experimental results demonstrate that Neural CODE outperforms Neural ODE inlearning the dynamics of a spiral forward and backward in time, even withsparser data. We also compare the performance of CODE-RNN/-GRU/-LSTM andCODE-BiRNN/-BiGRU/-BiLSTM against ODE-RNN/-GRU/-LSTM on three real-life timeseries data tasks: imputation of missing data for lower and higher dimensionaldata, and forward and backward extrapolation with shorter and longer timehorizons. Our findings show that the proposed architectures converge faster,with CODE-BiRNN/-BiGRU/-BiLSTM consistently outperforming the otherarchitectures on all tasks.</description><author>C. Coelho, M. Fernanda P. Costa, L. L. Ferr√°s</author><pubDate>Mon, 03 Jul 2023 14:54:50 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.01023v1</guid></item><item><title>From Noisy Fixed-Point Iterations to Private ADMM for Centralized and Federated Learning</title><link>http://arxiv.org/abs/2302.12559v2</link><description>We study differentially private (DP) machine learning algorithms as instancesof noisy fixed-point iterations, in order to derive privacy and utility resultsfrom this well-studied framework. We show that this new perspective recoverspopular private gradient-based methods like DP-SGD and provides a principledway to design and analyze new private optimization algorithms in a flexiblemanner. Focusing on the widely-used Alternating Directions Method ofMultipliers (ADMM) method, we use our general framework to derive novel privateADMM algorithms for centralized, federated and fully decentralized learning.For these three algorithms, we establish strong privacy guarantees leveragingprivacy amplification by iteration and by subsampling. Finally, we provideutility guarantees using a unified analysis that exploits a recent linearconvergence result for noisy fixed-point iterations.</description><author>Edwige Cyffers, Aur√©lien Bellet, Debabrota Basu</author><pubDate>Mon, 03 Jul 2023 14:49:19 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2302.12559v2</guid></item><item><title>Estimating Post-OCR Denoising Complexity on Numerical Texts</title><link>http://arxiv.org/abs/2307.01020v1</link><description>Post-OCR processing has significantly improved over the past few years.However, these have been primarily beneficial for texts consisting of natural,alphabetical words, as opposed to documents of numerical nature such asinvoices, payslips, medical certificates, etc. To evaluate the OCRpost-processing difficulty of these datasets, we propose a method to estimatethe denoising complexity of a text and evaluate it on several datasets ofvarying nature, and show that texts of numerical nature have a significantdisadvantage. We evaluate the estimated complexity ranking with respect to theerror rates of modern-day denoising approaches to show the validity of ourestimator.</description><author>Arthur Hemmer, J√©r√¥me Brachat, Micka√´l Coustaty, Jean-Marc Ogier</author><pubDate>Mon, 03 Jul 2023 14:49:14 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.01020v1</guid></item><item><title>Rethinking the U-Net, ResUnet, and U-Net3+ architectures with dual skip connections for building footprint extraction</title><link>http://arxiv.org/abs/2303.09064v3</link><description>The importance of building footprints and their inventory has been recognisedas foundational spatial information for multiple societal problems. Extractingcomplex urban buildings involves the segmentation of very high-resolution (VHR)earth observation (EO) images. U-Net is a common deep learning network andfoundation for its new incarnations like ResUnet, U-Net++ and U-Net3+ for suchsegmentation. The re-incarnations look for efficiency gain by re-designing theskip connection component and exploiting the multi-scale features in U-Net.However, skip connections do not always improve these networks and removingsome of them provides efficiency gains and reduced network parameters. In thispaper, we propose three dual skip connection mechanisms for U-Net, ResUnet, andU-Net3+. These mechanisms deepen the feature maps forwarded by the skipconnections and allow us to study which skip connections need to be denser toyield the highest efficiency gain. The mechanisms are evaluated on feature mapsof different scales in the three networks, producing nine new networkconfigurations. The networks are evaluated against their original vanillaversions using four building footprint datasets (three existing and one new) ofdifferent spatial resolutions: VHR (0.3m), high-resolution (1m and 1.2m), andmulti-resolution (0.3+0.6+1.2m). The proposed mechanisms report efficiency gainon four evaluation measures for U-Net and ResUnet, and up to 17.7% and 18.4%gain in F1 score and Intersection over Union (IoU) for U-Net3+. The codes willbe available in a GitHub link after peer review.</description><author>Bipul Neupane, Jagannath Aryal, Abbas Rajabifard</author><pubDate>Mon, 03 Jul 2023 14:46:51 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2303.09064v3</guid></item><item><title>CGAM: Click-Guided Attention Module for Interactive Pathology Image Segmentation via Backpropagating Refinement</title><link>http://arxiv.org/abs/2307.01015v1</link><description>Tumor region segmentation is an essential task for the quantitative analysisof digital pathology. Recently presented deep neural networks have shownstate-of-the-art performance in various image-segmentation tasks. However,because of the unclear boundary between the cancerous and normal regions inpathology images, despite using modern methods, it is difficult to producesatisfactory segmentation results in terms of the reliability and accuracyrequired for medical data. In this study, we propose an interactivesegmentation method that allows users to refine the output of deep neuralnetworks through click-type user interactions. The primary method is toformulate interactive segmentation as an optimization problem that leveragesboth user-provided click constraints and semantic information in a feature mapusing a click-guided attention module (CGAM). Unlike other existing methods,CGAM avoids excessive changes in segmentation results, which can lead to theoverfitting of user clicks. Another advantage of CGAM is that the model size isindependent of input image size. Experimental results on pathology imagedatasets indicated that our method performs better than existingstate-of-the-art methods.</description><author>Seonghui Min, Won-Ki Jeong</author><pubDate>Mon, 03 Jul 2023 14:45:24 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.01015v1</guid></item><item><title>SynthCal: A Synthetic Benchmarking Pipeline to Compare Camera Calibration Algorithms</title><link>http://arxiv.org/abs/2307.01013v1</link><description>Accurate camera calibration is crucial for various computer visionapplications. However, measuring camera parameters in the real world ischallenging and arduous, and there needs to be a dataset with ground truth toevaluate calibration algorithms' accuracy. In this paper, we present SynthCal,a synthetic camera calibration benchmarking pipeline that generates images ofcalibration patterns to measure and enable accurate quantification ofcalibration algorithm performance in camera parameter estimation. We present aSynthCal-generated calibration dataset with four common patterns, two cameratypes, and two environments with varying view, distortion, lighting, and noiselevels. The dataset evaluates single-view calibration algorithms by measuringreprojection and root-mean-square errors for identical patterns and camerasettings. Additionally, we analyze the significance of different patterns usingZhang's method, which estimates intrinsic and extrinsic camera parameters withknown correspondences between 3D points and their 2D projections in differentconfigurations and environments. The experimental results demonstrate theeffectiveness of SynthCal in evaluating various calibration algorithms andpatterns.</description><author>Lala Shakti Swarup Ray, Bo Zhou, Lars Krupp, Sungho Suh, Paul Lukowicz</author><pubDate>Mon, 03 Jul 2023 14:44:36 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.01013v1</guid></item><item><title>Deep Direct Discriminative Decoders for High-dimensional Time-series Data Analysis</title><link>http://arxiv.org/abs/2205.10947v2</link><description>The state-space models (SSMs) are widely utilized in the analysis oftime-series data. SSMs rely on an explicit definition of the state andobservation processes. Characterizing these processes is not always easy andbecomes a modeling challenge when the dimension of observed data grows or theobserved data distribution deviates from the normal distribution. Here, wepropose a new formulation of SSM for high-dimensional observation processes. Wecall this solution the deep direct discriminative decoder (D4). The D4 bringsdeep neural networks' expressiveness and scalability to the SSM formulationletting us build a novel solution that efficiently estimates the underlyingstate processes through high-dimensional observation signal. We demonstrate theD4 solutions in simulated and real data such as Lorenz attractors, Langevindynamics, random walk dynamics, and rat hippocampus spiking neural data andshow that the D4 performs better than traditional SSMs and RNNs. The D4 can beapplied to a broader class of time-series data where the connection betweenhigh-dimensional observation and the underlying latent process is hard tocharacterize.</description><author>Mohammad R. Rezaei, Milos R. Popovic, Milad Lankarany, Ali Yousefi</author><pubDate>Mon, 03 Jul 2023 14:40:46 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2205.10947v2</guid></item><item><title>Joint Coordinate Regression and Association For Multi-Person Pose Estimation, A Pure Neural Network Approach</title><link>http://arxiv.org/abs/2307.01004v1</link><description>We introduce a novel one-stage end-to-end multi-person 2D pose estimationalgorithm, known as Joint Coordinate Regression and Association (JCRA), thatproduces human pose joints and associations without requiring anypost-processing. The proposed algorithm is fast, accurate, effective, andsimple. The one-stage end-to-end network architecture significantly improvesthe inference speed of JCRA. Meanwhile, we devised a symmetric networkstructure for both the encoder and decoder, which ensures high accuracy inidentifying keypoints. It follows an architecture that directly outputs partpositions via a transformer network, resulting in a significant improvement inperformance. Extensive experiments on the MS COCO and CrowdPose benchmarksdemonstrate that JCRA outperforms state-of-the-art approaches in both accuracyand efficiency. Moreover, JCRA demonstrates 69.2 mAP and is 78\% faster atinference acceleration than previous state-of-the-art bottom-up algorithms. Thecode for this algorithm will be publicly available.</description><author>Dongyang Yu, Yunshi Xie, Wangpeng An, Li Zhang, Yufeng Yao</author><pubDate>Mon, 03 Jul 2023 14:40:20 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.01004v1</guid></item><item><title>Visual Instruction Tuning with Polite Flamingo</title><link>http://arxiv.org/abs/2307.01003v1</link><description>Recent research has demonstrated that the multi-task fine-tuning ofmulti-modal Large Language Models (LLMs) using an assortment of annotateddownstream vision-language datasets significantly enhances their performance.Yet, during this process, a side effect, which we termed as the "multi-modalalignment tax", surfaces. This side effect negatively impacts the model'sability to format responses appropriately -- for instance, its "politeness" --due to the overly succinct and unformatted nature of raw annotations, resultingin reduced human preference. In this paper, we introduce Polite Flamingo, amulti-modal response rewriter that transforms raw annotations into a moreappealing, "polite" format. Polite Flamingo is trained to reconstructhigh-quality responses from their automatically distorted counterparts and issubsequently applied to a vast array of vision-language datasets for responserewriting. After rigorous filtering, we generate the PF-1M dataset and furthervalidate its value by fine-tuning a multi-modal LLM with it. Combined withnovel methodologies including U-shaped multi-stage tuning and multi-turnaugmentation, the resulting model, Clever Flamingo, demonstrates its advantagesin both multi-modal understanding and response politeness according toautomated and human evaluations.</description><author>Delong Chen, Jianfeng Liu, Wenliang Dai, Baoyuan Wang</author><pubDate>Mon, 03 Jul 2023 14:37:00 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.01003v1</guid></item><item><title>Extensible Motion-based Identification of XR Users using Non-Specific Motion Data</title><link>http://arxiv.org/abs/2302.07517v4</link><description>In this paper, we combine the strengths of distance-based andclassification-based approaches for the task of identifying extended realityusers by their movements. For this we explore an embedding-based model thatleverages deep metric learning. We train the model on a dataset of usersplaying the VR game ``Half-Life: Alyx'' and conduct multiple experiments andanalyses using a state of the art classification-based model as baseline. Theresults show that the embedding-based method 1) is able to identify new usersfrom non-specific movements using only a few minutes of enrollment data, 2) canenroll new users within seconds, while retraining the baseline approach takesalmost a day, 3) is more reliable than the baseline approach when only littleenrollment data is available, 4) can be used to identify new users from anotherdataset recorded with different VR devices. Altogether, our solution is a foundation for easily extensible XR useridentification systems, applicable to a wide range of user motions. It alsopaves the way for production-ready models that could be used by XRpractitioners without the requirements of expertise, hardware, or data fortraining deep learning models.</description><author>Christian Rack, Konstantin Kobs, Tamara Fernando, Andreas Hotho, Marc Erich Latoschik</author><pubDate>Mon, 03 Jul 2023 14:33:21 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2302.07517v4</guid></item><item><title>Pareto optimal proxy metrics</title><link>http://arxiv.org/abs/2307.01000v1</link><description>North star metrics and online experimentation play a central role in howtechnology companies improve their products. In many practical settings,however, evaluating experiments based on the north star metric directly can bedifficult. The two most significant issues are 1) low sensitivity of the northstar metric and 2) differences between the short-term and long-term impact onthe north star metric. A common solution is to rely on proxy metrics ratherthan the north star in experiment evaluation and launch decisions. Existingliterature on proxy metrics concentrates mainly on the estimation of thelong-term impact from short-term experimental data. In this paper, instead, wefocus on the trade-off between the estimation of the long-term impact and thesensitivity in the short term. In particular, we propose the Pareto optimalproxy metrics method, which simultaneously optimizes prediction accuracy andsensitivity. In addition, we give an efficient multi-objective optimizationalgorithm that outperforms standard methods. We applied our methodology toexperiments from a large industrial recommendation system, and found proxymetrics that are eight times more sensitive than the north star andconsistently moved in the same direction, increasing the velocity and thequality of the decisions to launch new features.</description><author>Lee Richardson, Alessandro Zito, Dylan Greaves, Jacopo Soriano</author><pubDate>Mon, 03 Jul 2023 14:29:14 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.01000v1</guid></item><item><title>RefSAM: Efficiently Adapting Segmenting Anything Model for Referring Video Object Segmentation</title><link>http://arxiv.org/abs/2307.00997v1</link><description>The Segment Anything Model (SAM) has gained significant attention for itsimpressive performance in image segmentation. However, it lacks proficiency inreferring video object segmentation (RVOS) due to the need for preciseuser-interactive prompts and limited understanding of different modalities,such as language and vision. This paper presents the RefSAM model, which forthe first time explores the potential of SAM for RVOS by incorporatingmulti-view information from diverse modalities and successive frames atdifferent timestamps. Our proposed approach adapts the original SAM model toenhance cross-modality learning by employing a lightweight Cross-Modal MLP thatprojects the text embedding of the referring expression into sparse and denseembeddings, serving as user-interactive prompts. Subsequently, aparameter-efficient tuning strategy is employed to effectively align and fusethe language and vision features. Through comprehensive ablation studies, wedemonstrate the practical and effective design choices of our strategy.Extensive experiments conducted on Ref-Youtu-VOS and Ref-DAVIS17 datasetsvalidate the superiority and effectiveness of our RefSAM model over existingmethods. The code and models will be made publicly at\href{https://github.com/LancasterLi/RefSAM}{github.com/LancasterLi/RefSAM}.</description><author>Yonglin Li, Jing Zhang, Xiao Teng, Long Lan</author><pubDate>Mon, 03 Jul 2023 14:21:58 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.00997v1</guid></item><item><title>Towards Suicide Prevention from Bipolar Disorder with Temporal Symptom-Aware Multitask Learning</title><link>http://arxiv.org/abs/2307.00995v1</link><description>Bipolar disorder (BD) is closely associated with an increased risk ofsuicide. However, while the prior work has revealed valuable insight intounderstanding the behavior of BD patients on social media, little attention hasbeen paid to developing a model that can predict the future suicidality of a BDpatient. Therefore, this study proposes a multi-task learning model forpredicting the future suicidality of BD patients by jointly learning currentsymptoms. We build a novel BD dataset clinically validated by psychiatrists,including 14 years of posts on bipolar-related subreddits written by 818 BDpatients, along with the annotations of future suicidality and BD symptoms. Wealso suggest a temporal symptom-aware attention mechanism to determine whichsymptoms are the most influential for predicting future suicidality over timethrough a sequence of BD posts. Our experiments demonstrate that the proposedmodel outperforms the state-of-the-art models in both BD symptom identificationand future suicidality prediction tasks. In addition, the proposed temporalsymptom-aware attention provides interpretable attention weights, helpingclinicians to apprehend BD patients more comprehensively and to provide timelyintervention by tracking mental state progression.</description><author>Daeun Lee, Sejung Son, Hyolim Jeon, Seungbae Kim, Jinyoung Han</author><pubDate>Mon, 03 Jul 2023 14:18:55 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.00995v1</guid></item><item><title>Environmental effects on emergent strategy in micro-scale multi-agent reinforcement learning</title><link>http://arxiv.org/abs/2307.00994v1</link><description>Multi-Agent Reinforcement Learning (MARL) is a promising candidate forrealizing efficient control of microscopic particles, of which micro-robots area subset. However, the microscopic particles' environment presents uniquechallenges, such as Brownian motion at sufficiently small length-scales. Inthis work, we explore the role of temperature in the emergence and efficacy ofstrategies in MARL systems using particle-based Langevin molecular dynamicssimulations as a realistic representation of micro-scale environments. To thisend, we perform experiments on two different multi-agent tasks in microscopicenvironments at different temperatures, detecting the source of a concentrationgradient and rotation of a rod. We find that at higher temperatures, the RLagents identify new strategies for achieving these tasks, highlighting theimportance of understanding this regime and providing insight into optimaltraining strategies for bridging the generalization gap between simulation andreality. We also introduce a novel Python package for studying microscopicagents using reinforcement learning (RL) to accompany our results.</description><author>Samuel Tovey, David Zimmer, Christoph Lohrmann, Tobias Merkt, Simon Koppenhoefer, Veit-Lorenz Heuthe, Clemens Bechinger, Christian Holm</author><pubDate>Mon, 03 Jul 2023 14:18:25 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.00994v1</guid></item><item><title>Derandomized Novelty Detection with FDR Control via Conformal E-values</title><link>http://arxiv.org/abs/2302.07294v2</link><description>Conformal inference provides a general distribution-free method to rigorouslycalibrate the output of any machine learning algorithm for novelty detection.While this approach has many strengths, it has the limitation of beingrandomized, in the sense that it may lead to different results when analyzingtwice the same data, and this can hinder the interpretation of any findings. Wepropose to make conformal inferences more stable by leveraging suitableconformal e-values instead of p-values to quantify statistical significance.This solution allows the evidence gathered from multiple analyses of the samedata to be aggregated effectively while provably controlling the falsediscovery rate. Further, we show that the proposed method can reduce randomnesswithout much loss of power compared to standard conformal inference, partlythanks to an innovative way of weighting conformal e-values based on additionalside information carefully extracted from the same data. Simulations withsynthetic and real data confirm this solution can be effective at eliminatingrandom noise in the inferences obtained with state-of-the-art alternativetechniques, sometimes also leading to higher power.</description><author>Meshi Bashari, Amir Epstein, Yaniv Romano, Matteo Sesia</author><pubDate>Mon, 03 Jul 2023 14:14:00 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2302.07294v2</guid></item><item><title>Reinforcement Learning with Human Feedback: Learning Dynamic Choices via Pessimism</title><link>http://arxiv.org/abs/2305.18438v3</link><description>In this paper, we study offline Reinforcement Learning with Human Feedback(RLHF) where we aim to learn the human's underlying reward and the MDP'soptimal policy from a set of trajectories induced by human choices. RLHF ischallenging for multiple reasons: large state space but limited human feedback,the bounded rationality of human decisions, and the off-policy distributionshift. In this paper, we focus on the Dynamic Discrete Choice (DDC) model formodeling and understanding human choices. DCC, rooted in econometrics anddecision theory, is widely used to model a human decision-making process withforward-looking and bounded rationality. We propose a\underline{D}ynamic-\underline{C}hoice-\underline{P}essimistic-\underline{P}olicy-\underline{O}ptimization(DCPPO) method. \ The method involves a three-stage process: The first step isto estimate the human behavior policy and the state-action value function viamaximum likelihood estimation (MLE); the second step recovers the human rewardfunction via minimizing Bellman mean squared error using the learned valuefunctions; the third step is to plug in the learned reward and invokepessimistic value iteration for finding a near-optimal policy. With onlysingle-policy coverage (i.e., optimal policy) of the dataset, we prove that thesuboptimality of DCPPO almost matches the classical pessimistic offline RLalgorithm in terms of suboptimality's dependency on distribution shift anddimension. To the best of our knowledge, this paper presents the firsttheoretical guarantees for off-policy offline RLHF with dynamic discrete choicemodel.</description><author>Zihao Li, Zhuoran Yang, Mengdi Wang</author><pubDate>Mon, 03 Jul 2023 14:08:46 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.18438v3</guid></item><item><title>Predicting beauty, liking, and aesthetic quality: A comparative analysis of image databases for visual aesthetics research</title><link>http://arxiv.org/abs/2307.00984v1</link><description>In the fields of Experimental and Computational Aesthetics, numerous imagedatasets have been created over the last two decades. In the present work, weprovide a comparative overview of twelve image datasets that include aestheticratings (beauty, liking or aesthetic quality) and investigate thereproducibility of results across different datasets. Specifically, we examinehow consistently the ratings can be predicted by using either (A) a set of 20previously studied statistical image properties, or (B) the layers of aconvolutional neural network developed for object recognition. Our findingsreveal substantial variation in the predictability of aesthetic ratings acrossthe different datasets. However, consistent similarities were found fordatasets containing either photographs or paintings, suggesting differentrelevant features in the aesthetic evaluation of these two image genres. To oursurprise, statistical image properties and the convolutional neural networkpredict aesthetic ratings with similar accuracy, highlighting a significantoverlap in the image information captured by the two methods. Nevertheless, thediscrepancies between the datasets call into question the generalizability ofprevious research findings on single datasets. Our study underscores theimportance of considering multiple datasets to improve the validity andgeneralizability of research results in the fields of experimental andcomputational aesthetics.</description><author>Ralf Bartho, Katja Thoemmes, Christoph Redies</author><pubDate>Mon, 03 Jul 2023 14:03:17 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.00984v1</guid></item><item><title>Cracking Double-Blind Review: Authorship Attribution with Deep Learning</title><link>http://arxiv.org/abs/2211.07467v3</link><description>Double-blind peer review is considered a pillar of academic research becauseit is perceived to ensure a fair, unbiased, and fact-centered scientificdiscussion. Yet, experienced researchers can often correctly guess from whichresearch group an anonymous submission originates, biasing the peer-reviewprocess. In this work, we present a transformer-based, neural-networkarchitecture that only uses the text content and the author names in thebibliography to attribute an anonymous manuscript to an author. To train andevaluate our method, we created the largest authorship identification datasetto date. It leverages all research papers publicly available on arXiv amountingto over 2 million manuscripts. In arXiv-subsets with up to 2,000 differentauthors, our method achieves an unprecedented authorship attribution accuracy,where up to 73% of papers are attributed correctly. We present a scalinganalysis to highlight the applicability of the proposed method to even largerdatasets when sufficient compute capabilities are more widely available to theacademic community. Furthermore, we analyze the attribution accuracy insettings where the goal is to identify all authors of an anonymous manuscript.Thanks to our method, we are not only able to predict the author of ananonymous work, but we also provide empirical evidence of the key aspects thatmake a paper attributable. We have open-sourced the necessary tools toreproduce our experiments.</description><author>Leonard Bauersfeld, Angel Romero, Manasi Muglikar, Davide Scaramuzza</author><pubDate>Mon, 03 Jul 2023 13:49:54 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2211.07467v3</guid></item><item><title>Autism Spectrum Disorder Classification in Children based on Structural MRI Features Extracted using Contrastive Variational Autoencoder</title><link>http://arxiv.org/abs/2307.00976v1</link><description>Autism spectrum disorder (ASD) is a highly disabling mental disease thatbrings significant impairments of social interaction ability to the patients,making early screening and intervention of ASD critical. With the developmentof the machine learning and neuroimaging technology, extensive research hasbeen conducted on machine classification of ASD based on structural MRI(s-MRI). However, most studies involve with datasets where participants' ageare above 5. Few studies conduct machine classification of ASD for participantsbelow 5-year-old, but, with mediocre predictive accuracy. In this paper, wepush the boundary of predictive accuracy (above 0.97) of machine classificationof ASD in children (age range: 0.92-4.83 years), based on s-MRI featuresextracted using contrastive variational autoencoder (CVAE). 78 s-MRI, collectedfrom Shenzhen Children's Hospital, are used for training CVAE, which consistsof both ASD-specific feature channel and common shared feature channel. The ASDparticipants represented by ASD-specific features can be easily discriminatedfrom TC participants represented by the common shared features, leading to highclassification accuracy. In case of degraded predictive accuracy when data sizeis extremely small, a transfer learning strategy is proposed here as apotential solution. Finally, we conduct neuroanatomical interpretation based onthe correlation between s-MRI features extracted from CVAE and surface area ofdifferent cortical regions, which discloses potential biomarkers that couldhelp target treatments of ASD in the future.</description><author>Ruimin Ma, Ruitao Xie, Yanlin Wang, Jintao Meng, Yanjie Wei, Wenhui Xi, Yi Pan</author><pubDate>Mon, 03 Jul 2023 13:46:19 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.00976v1</guid></item><item><title>Over-The-Air Federated Learning: Status Quo, Open Challenges, and Future Directions</title><link>http://arxiv.org/abs/2307.00974v1</link><description>The development of applications based on artificial intelligence andimplemented over wireless networks is increasingly rapidly and is expected togrow dramatically in the future. The resulting demand for the aggregation oflarge amounts of data has caused serious communication bottlenecks in wirelessnetworks and particularly at the network edge. Over-the-air federated learning(OTA-FL), leveraging the superposition feature of multi-access channels (MACs),enables users at the network edge to share spectrum resources and achievesefficient and low-latency global model aggregation. This paper provides aholistic review of progress in OTA-FL and points to potential future researchdirections. Specifically, we classify OTA-FL from the perspective of systemsettings, including single-antenna OTA-FL, multi-antenna OTA-FL, and OTA-FLwith the aid of the emerging reconfigurable intelligent surface (RIS)technology, and the contributions of existing works in these areas aresummarized. Moreover, we discuss the trust, security and privacy aspects ofOTA-FL, and highlight concerns arising from security and privacy. Finally,challenges and potential research directions are discussed to promote thefuture development of OTA-FL in terms of improving system performance,reliability, and trustworthiness. Specifical challenges to be addressed includemodel distortion under channel fading, the ineffective OTA aggregation of localmodels trained on substantially unbalanced data, and the limited accessibilityand verifiability of individual local models.</description><author>Bingnan Xiao, Xichen Yu, Wei Ni, Xin Wang, H. Vincent Poor</author><pubDate>Mon, 03 Jul 2023 13:44:52 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.00974v1</guid></item><item><title>MoVie: Visual Model-Based Policy Adaptation for View Generalization</title><link>http://arxiv.org/abs/2307.00972v1</link><description>Visual Reinforcement Learning (RL) agents trained on limited views facesignificant challenges in generalizing their learned abilities to unseen views.This inherent difficulty is known as the problem of $\textit{viewgeneralization}$. In this work, we systematically categorize this fundamentalproblem into four distinct and highly challenging scenarios that closelyresemble real-world situations. Subsequently, we propose a straightforward yeteffective approach to enable successful adaptation of visual$\textbf{Mo}$del-based policies for $\textbf{Vie}$w generalization($\textbf{MoVie}$) during test time, without any need for explicit rewardsignals and any modification during training time. Our method demonstratessubstantial advancements across all four scenarios encompassing a total of$\textbf{18}$ tasks sourced from DMControl, xArm, and Adroit, with a relativeimprovement of $\mathbf{33}$%, $\mathbf{86}$%, and $\mathbf{152}$%respectively. The superior results highlight the immense potential of ourapproach for real-world robotics applications. Videos are available athttps://yangsizhe.github.io/MoVie/ .</description><author>Sizhe Yang, Yanjie Ze, Huazhe Xu</author><pubDate>Mon, 03 Jul 2023 13:44:07 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.00972v1</guid></item><item><title>REAL: A Representative Error-Driven Approach for Active Learning</title><link>http://arxiv.org/abs/2307.00968v1</link><description>Given a limited labeling budget, active learning (AL) aims to sample the mostinformative instances from an unlabeled pool to acquire labels for subsequentmodel training. To achieve this, AL typically measures the informativeness ofunlabeled instances based on uncertainty and diversity. However, it does notconsider erroneous instances with their neighborhood error density, which havegreat potential to improve the model performance. To address this limitation,we propose $REAL$, a novel approach to select data instances with$\underline{R}$epresentative $\underline{E}$rrors for $\underline{A}$ctive$\underline{L}$earning. It identifies minority predictions as \emph{pseudoerrors} within a cluster and allocates an adaptive sampling budget for thecluster based on estimated error density. Extensive experiments on five textclassification datasets demonstrate that $REAL$ consistently outperforms allbest-performing baselines regarding accuracy and F1-macro scores across a widerange of hyperparameter settings. Our analysis also shows that $REAL$ selectsthe most representative pseudo errors that match the distribution ofground-truth errors along the decision boundary. Our code is publicly availableat https://github.com/withchencheng/ECML_PKDD_23_Real.</description><author>Cheng Chen, Yong Wang, Lizi Liao, Yueguo Chen, Xiaoyong Du</author><pubDate>Mon, 03 Jul 2023 13:39:26 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.00968v1</guid></item><item><title>OpenClinicalAI: An Open and Dynamic Model for Alzheimer's Disease Diagnosis</title><link>http://arxiv.org/abs/2307.00965v1</link><description>Although Alzheimer's disease (AD) cannot be reversed or cured, timelydiagnosis can significantly reduce the burden of treatment and care. Currentresearch on AD diagnosis models usually regards the diagnosis task as a typicalclassification task with two primary assumptions: 1) All target categories areknown a priori; 2) The diagnostic strategy for each patient is consistent, thatis, the number and type of model input data for each patient are the same.However, real-world clinical settings are open, with complexity and uncertaintyin terms of both subjects and the resources of the medical institutions. Thismeans that diagnostic models may encounter unseen disease categories and needto dynamically develop diagnostic strategies based on the subject's specificcircumstances and available medical resources. Thus, the AD diagnosis task istangled and coupled with the diagnosis strategy formulation. To promote theapplication of diagnostic systems in real-world clinical settings, we proposeOpenClinicalAI for direct AD diagnosis in complex and uncertain clinicalsettings. This is the first powerful end-to-end model to dynamically formulatediagnostic strategies and provide diagnostic results based on the subject'sconditions and available medical resources. OpenClinicalAI combinesreciprocally coupled deep multiaction reinforcement learning (DMARL) fordiagnostic strategy formulation and multicenter meta-learning (MCML) foropen-set recognition. The experimental results show that OpenClinicalAIachieves better performance and fewer clinical examinations than thestate-of-the-art model. Our method provides an opportunity to embed the ADdiagnostic system into the current health care system to cooperate withclinicians to improve current health care.</description><author>Yunyou Huang, Xiaoshuang Liang, Xiangjiang Lu, Xiuxia Miao, Jiyue Xie, Wenjing Liu, Fan Zhang, Guoxin Kang, Li Ma, Suqin Tang, Zhifei Zhang, Jianfeng Zhan</author><pubDate>Mon, 03 Jul 2023 13:35:03 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.00965v1</guid></item></channel></rss>