<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/"><channel><title>Arxivfresh papers</title><link></link><description>Arxiv paper</description><language>en-US</language><lastBuildDate>Fri, 02 Aug 2024 13:00:18 GMT</lastBuildDate><generator>rfeed v1.0.0</generator><docs>https://github.com/svpino/rfeed/blob/master/README.md</docs><item><title>Tiered Reward: Designing Rewards for Specification and Fast Learning of Desired Behavior</title><link>http://arxiv.org/abs/2212.03733v3</link><description>Reinforcement-learning agents seek to maximize a reward signal throughenvironmental interactions. As humans, our job in the learning process is todesign reward functions to express desired behavior and enable the agent tolearn such behavior swiftly. However, designing good reward functions to inducethe desired behavior is generally hard, let alone the question of which rewardsmake learning fast. In this work, we introduce a family of a reward structureswe call Tiered Reward that addresses both of these questions. We consider thereward-design problem in tasks formulated as reaching desirable states andavoiding undesirable states. To start, we propose a strict partial ordering ofthe policy space to resolve trade-offs in behavior preference. We preferpolicies that reach the good states faster and with higher probability whileavoiding the bad states longer. Next, we introduce Tiered Reward, a class ofenvironment-independent reward functions and show it is guaranteed to inducepolicies that are Pareto-optimal according to our preference relation. Finally,we demonstrate that Tiered Reward leads to fast learning with multiple tabularand deep reinforcement-learning algorithms.</description><author>Zhiyuan Zhou, Shreyas Sundara Raman, Henry Sowerby, Michael L. Littman</author><pubDate>Thu, 01 Aug 2024 17:47:24 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2212.03733v3</guid></item><item><title>Seed Kernel Counting using Domain Randomization and Object Tracking Neural Networks</title><link>http://arxiv.org/abs/2308.05846v2</link><description>High-throughput phenotyping (HTP) of seeds, also known as seed phenotyping,is the comprehensive assessment of complex seed traits such as growth,development, tolerance, resistance, ecology, yield, and the measurement ofparameters that form more complex traits. One of the key aspects of seedphenotyping is cereal yield estimation that the seed production industry reliesupon to conduct their business. While mechanized seed kernel counters areavailable in the market currently, they are often priced high and sometimesoutside the range of small scale seed production firms' affordability. Thedevelopment of object tracking neural network models such as You Only Look Once(YOLO) enables computer scientists to design algorithms that can estimatecereal yield inexpensively. The key bottleneck with neural network models isthat they require a plethora of labelled training data before they can be putto task. We demonstrate that the use of synthetic imagery serves as a feasiblesubstitute to train neural networks for object tracking that includes the tasksof object classification and detection. Furthermore, we propose a seed kernelcounter that uses a low-cost mechanical hopper, trained YOLOv8 neural networkmodel, and object tracking algorithms on StrongSORT and ByteTrack to estimatecereal yield from videos. The experiment yields a seed kernel count with anaccuracy of 95.2\% and 93.2\% for Soy and Wheat respectively using theStrongSORT algorithm, and an accuray of 96.8\% and 92.4\% for Soy and Wheatrespectively using the ByteTrack algorithm.</description><author>Venkat Margapuri, Prapti Thapaliya, Mitchell Neilsen</author><pubDate>Thu, 01 Aug 2024 17:46:38 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2308.05846v2</guid></item><item><title>Self-Supervised Learning Based Handwriting Verification</title><link>http://arxiv.org/abs/2405.18320v2</link><description>We present SSL-HV: Self-Supervised Learning approaches applied to the task ofHandwriting Verification. This task involves determining whether a given pairof handwritten images originate from the same or different writer distribution.We have compared the performance of multiple generative, contrastive SSLapproaches against handcrafted feature extractors and supervised learning onCEDAR AND dataset. We show that ResNet based Variational Auto-Encoder (VAE)outperforms other generative approaches achieving 76.3% accuracy, whileResNet-18 fine-tuned using Variance-Invariance-Covariance Regularization(VICReg) outperforms other contrastive approaches achieving 78% accuracy. Usinga pre-trained VAE and VICReg for the downstream task of writer verification weobserved a relative improvement in accuracy of 6.7% and 9% over ResNet-18supervised baseline with 10% writer labels.</description><author>Mihir Chauhan, Mohammad Abuzar Hashemi, Abhishek Satbhai, Mir Basheer Ali, Bina Ramamurthy, Mingchen Gao, Siwei Lyu, Sargur Srihari</author><pubDate>Thu, 01 Aug 2024 17:43:19 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.18320v2</guid></item><item><title>Jumping Ahead: Improving Reconstruction Fidelity with JumpReLU Sparse Autoencoders</title><link>http://arxiv.org/abs/2407.14435v3</link><description>Sparse autoencoders (SAEs) are a promising unsupervised approach foridentifying causally relevant and interpretable linear features in a languagemodel's (LM) activations. To be useful for downstream tasks, SAEs need todecompose LM activations faithfully; yet to be interpretable the decompositionmust be sparse -- two objectives that are in tension. In this paper, weintroduce JumpReLU SAEs, which achieve state-of-the-art reconstruction fidelityat a given sparsity level on Gemma 2 9B activations, compared to other recentadvances such as Gated and TopK SAEs. We also show that this improvement doesnot come at the cost of interpretability through manual and automatedinterpretability studies. JumpReLU SAEs are a simple modification of vanilla(ReLU) SAEs -- where we replace the ReLU with a discontinuous JumpReLUactivation function -- and are similarly efficient to train and run. Byutilising straight-through-estimators (STEs) in a principled manner, we showhow it is possible to train JumpReLU SAEs effectively despite the discontinuousJumpReLU function introduced in the SAE's forward pass. Similarly, we use STEsto directly train L0 to be sparse, instead of training on proxies such as L1,avoiding problems like shrinkage.</description><author>Senthooran Rajamanoharan, Tom Lieberum, Nicolas Sonnerat, Arthur Conmy, Vikrant Varma, János Kramár, Neel Nanda</author><pubDate>Thu, 01 Aug 2024 17:42:04 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.14435v3</guid></item><item><title>End-to-End Reinforcement Learning of Koopman Models for Economic Nonlinear Model Predictive Control</title><link>http://arxiv.org/abs/2308.01674v4</link><description>(Economic) nonlinear model predictive control ((e)NMPC) requires dynamicmodels that are sufficiently accurate and computationally tractable.Data-driven surrogate models for mechanistic models can reduce thecomputational burden of (e)NMPC; however, such models are typically trained bysystem identification for maximum prediction accuracy on simulation samples andperform suboptimally in (e)NMPC. We present a method for end-to-endreinforcement learning of Koopman surrogate models for optimal performance aspart of (e)NMPC. We apply our method to two applications derived from anestablished nonlinear continuous stirred-tank reactor model. The controllerperformance is compared to that of (e)NMPCs utilizing models trained usingsystem identification, and model-free neural network controllers trained usingreinforcement learning. We show that the end-to-end trained models outperformthose trained using system identification in (e)NMPC, and that, in contrast tothe neural network controllers, the (e)NMPC controllers can react to changes inthe control setting without retraining.</description><author>Daniel Mayfrank, Alexander Mitsos, Manuel Dahmen</author><pubDate>Thu, 01 Aug 2024 17:41:27 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2308.01674v4</guid></item><item><title>Sparks of Quantum Advantage and Rapid Retraining in Machine Learning</title><link>http://arxiv.org/abs/2407.16020v3</link><description>The advent of quantum computing holds the potential to revolutionize variousfields by solving complex problems more efficiently than classical computers.Despite this promise, practical quantum advantage is hindered by currenthardware limitations, notably the small number of qubits and high noise levels.In this study, we leverage adiabatic quantum computers to optimizeKolmogorov-Arnold Networks, a powerful neural network architecture forrepresenting complex functions with minimal parameters. By modifying thenetwork to use Bezier curves as the basis functions and formulating theoptimization problem into a Quadratic Unconstrained Binary Optimizationproblem, we create a fixed-sized solution space, independent of the number oftraining samples. Our approach demonstrates sparks of quantum advantage throughfaster training times compared to classical optimizers such as the Adam,Stochastic Gradient Descent, Adaptive Gradient, and simulated annealing.Additionally, we introduce a novel rapid retraining capability, enabling thenetwork to be retrained with new data without reprocessing old samples, thusenhancing learning efficiency in dynamic environments. Experimental results oninitial training of classification and regression tasks validate the efficacyof our approach, showcasing significant speedups and comparable performance toclassical methods. While experiments on retraining demonstrate a sixty timesspeed up using adiabatic quantum computing based optimization compared to thatof the gradient descent based optimizers, with theoretical models allowing thisspeed up to be even larger! Our findings suggest that with further advancementsin quantum hardware and algorithm optimization, quantum-optimized machinelearning models could have broad applications across various domains, withinitial focus on rapid retraining.</description><author>William Troy</author><pubDate>Thu, 01 Aug 2024 17:40:36 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.16020v3</guid></item><item><title>Enhanced Local Explainability and Trust Scores with Random Forest Proximities</title><link>http://arxiv.org/abs/2310.12428v2</link><description>We initiate a novel approach to explain the predictions and out of sampleperformance of random forest (RF) regression and classification models byexploiting the fact that any RF can be mathematically formulated as an adaptiveweighted K nearest-neighbors model. Specifically, we employ a recent resultthat, for both regression and classification tasks, any RF prediction can berewritten exactly as a weighted sum of the training targets, where the weightsare RF proximities between the corresponding pairs of data points. We show thatthis linearity facilitates a local notion of explainability of RF predictionsthat generates attributions for any model prediction across observations in thetraining set, and thereby complements established feature-based methods likeSHAP, which generate attributions for a model prediction across input features.We show how this proximity-based approach to explainability can be used inconjunction with SHAP to explain not just the model predictions, but alsoout-of-sample performance, in the sense that proximities furnish a novel meansof assessing when a given model prediction is more or less likely to becorrect. We demonstrate this approach in the modeling of US corporate bondprices and returns in both regression and classification cases.</description><author>Joshua Rosaler, Dhruv Desai, Bhaskarjit Sarmah, Dimitrios Vamvourellis, Deran Onay, Dhagash Mehta, Stefano Pasquali</author><pubDate>Thu, 01 Aug 2024 17:38:27 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.12428v2</guid></item><item><title>Evaluating Neural Radiance Fields (NeRFs) for 3D Plant Geometry Reconstruction in Field Conditions</title><link>http://arxiv.org/abs/2402.10344v2</link><description>We evaluate different Neural Radiance Fields (NeRFs) techniques forreconstructing (3D) plants in varied environments, from indoor settings tooutdoor fields. Traditional techniques often struggle to capture the complexdetails of plants, which is crucial for botanical and agriculturalunderstanding. We evaluate three scenarios with increasing complexity andcompare the results with the point cloud obtained using LiDAR as ground truthdata. In the most realistic field scenario, the NeRF models achieve a 74.65% F1score with 30 minutes of training on the GPU, highlighting the efficiency andaccuracy of NeRFs in challenging environments. These findings not onlydemonstrate the potential of NeRF in detailed and realistic 3D plant modelingbut also suggest practical approaches for enhancing the speed and efficiency ofthe 3D reconstruction process.</description><author>Muhammad Arbab Arshad, Talukder Jubery, James Afful, Anushrut Jignasu, Aditya Balu, Baskar Ganapathysubramanian, Soumik Sarkar, Adarsh Krishnamurthy</author><pubDate>Thu, 01 Aug 2024 17:34:51 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.10344v2</guid></item><item><title>Prover-Verifier Games improve legibility of LLM outputs</title><link>http://arxiv.org/abs/2407.13692v2</link><description>One way to increase confidence in the outputs of Large Language Models (LLMs)is to support them with reasoning that is clear and easy to check -- a propertywe call legibility. We study legibility in the context of solving grade-schoolmath problems and show that optimizing chain-of-thought solutions only foranswer correctness can make them less legible. To mitigate the loss inlegibility, we propose a training algorithm inspired by Prover-Verifier Gamefrom Anil et al. (2021). Our algorithm iteratively trains small verifiers topredict solution correctness, "helpful" provers to produce correct solutionsthat the verifier accepts, and "sneaky" provers to produce incorrect solutionsthat fool the verifier. We find that the helpful prover's accuracy and theverifier's robustness to adversarial attacks increase over the course oftraining. Furthermore, we show that legibility training transfers totime-constrained humans tasked with verifying solution correctness. Over courseof LLM training human accuracy increases when checking the helpful prover'ssolutions, and decreases when checking the sneaky prover's solutions. Hence,training for checkability by small verifiers is a plausible technique forincreasing output legibility. Our results suggest legibility training againstsmall verifiers as a practical avenue for increasing legibility of large LLMsto humans, and thus could help with alignment of superhuman models.</description><author>Jan Hendrik Kirchner, Yining Chen, Harri Edwards, Jan Leike, Nat McAleese, Yuri Burda</author><pubDate>Thu, 01 Aug 2024 17:18:54 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.13692v2</guid></item><item><title>Deblurring Neural Radiance Fields with Event-driven Bundle Adjustment</title><link>http://arxiv.org/abs/2406.14360v2</link><description>Neural Radiance Fields (NeRF) achieves impressive 3D representation learningand novel view synthesis results with high-quality multi-view images as input.However, motion blur in images often occurs in low-light and high-speed motionscenes, which significantly degrades the reconstruction quality of NeRF.Previous deblurring NeRF methods struggle to estimate pose and lighting changesduring the exposure time, making them unable to accurately model the motionblur. The bio-inspired event camera measuring intensity changes with hightemporal resolution makes up this information deficiency. In this paper, wepropose Event-driven Bundle Adjustment for Deblurring Neural Radiance Fields(EBAD-NeRF) to jointly optimize the learnable poses and NeRF parameters byleveraging the hybrid event-RGB data. An intensity-change-metric event loss anda photo-metric blur loss are introduced to strengthen the explicit modeling ofcamera motion blur. Experiments on both synthetic and real-captured datademonstrate that EBAD-NeRF can obtain accurate camera trajectory during theexposure time and learn a sharper 3D representations compared to prior works.</description><author>Yunshan Qi, Lin Zhu, Yifan Zhao, Nan Bao, Jia Li</author><pubDate>Thu, 01 Aug 2024 17:14:17 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.14360v2</guid></item><item><title>Low-Rank Covariance Completion for Graph Quilting with Applications to Functional Connectivity</title><link>http://arxiv.org/abs/2209.08273v2</link><description>As a tool for estimating networks in high dimensions, graphical models arecommonly applied to calcium imaging data to estimate functional neuronalconnectivity, i.e. relationships between the activities of neurons. However, inmany calcium imaging data sets, the full population of neurons is not recordedsimultaneously, but instead in partially overlapping blocks. This leads to theGraph Quilting problem, as first introduced by (Vinci et.al. 2019), in whichthe goal is to infer the structure of the full graph when only subsets offeatures are jointly observed. In this paper, we study a novel two-stepapproach to Graph Quilting, which first imputes the complete covariance matrixusing low-rank covariance completion techniques before estimating the graphstructure. We introduce three approaches to solve this problem: block singularvalue decomposition, nuclear norm penalization, and non-convex low-rankfactorization. While prior works have studied low-rank matrix completion, weaddress the challenges brought by the block-wise missingness and are the firstto investigate the problem in the context of graph learning. We discusstheoretical properties of the two-step procedure, showing graph selectionconsistency of one proposed approach by proving novel L infinity-norm errorbounds for matrix completion with block-missingness. We then investigate theempirical performance of the proposed methods on simulations and on real-worlddata examples, through which we show the efficacy of these methods forestimating functional connectivity from calcium imaging data.</description><author>Andersen Chang, Lili Zheng, Genevera I. Allen</author><pubDate>Thu, 01 Aug 2024 17:07:03 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2209.08273v2</guid></item><item><title>Grasp, See and Place: Efficient Unknown Object Rearrangement with Policy Structure Prior</title><link>http://arxiv.org/abs/2402.15402v2</link><description>We focus on the task of unknown object rearrangement, where a robot issupposed to re-configure the objects into a desired goal configurationspecified by an RGB-D image. Recent works explore unknown object rearrangementsystems by incorporating learning-based perception modules. However, they aresensitive to perception error, and pay less attention to task-levelperformance. In this paper, we aim to develop an effective system for unknownobject rearrangement amidst perception noise. We theoretically reveal the noisyperception impacts grasp and place in a decoupled way, and show such adecoupled structure is valuable to improve task optimality. We propose GSP, adual-loop system with the decoupled structure as prior. For the inner loop, welearn a see policy for self-confident in-hand object matching. For the outerloop, we learn a grasp policy aware of object matching and grasp capabilityguided by task-level rewards. We leverage the foundation model CLIP for objectmatching, policy learning and self-termination. A series of experimentsindicate that GSP can conduct unknown object rearrangement with highercompletion rates and fewer steps.</description><author>Kechun Xu, Zhongxiang Zhou, Jun Wu, Haojian Lu, Rong Xiong, Yue Wang</author><pubDate>Thu, 01 Aug 2024 16:31:00 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.15402v2</guid></item><item><title>The Impact of Quantization on Retrieval-Augmented Generation: An Analysis of Small LLMs</title><link>http://arxiv.org/abs/2406.10251v3</link><description>Post-training quantization reduces the computational demand of Large LanguageModels (LLMs) but can weaken some of their capabilities. Since LLM abilitiesemerge with scale, smaller LLMs are more sensitive to quantization. In thispaper, we explore how quantization affects smaller LLMs' ability to performretrieval-augmented generation (RAG), specifically in longer contexts. We chosepersonalization for evaluation because it is a challenging domain to performusing RAG as it requires long-context reasoning over multiple documents. Wecompare the original FP16 and the quantized INT4 performance of multiple 7B and8B LLMs on two tasks while progressively increasing the number of retrieveddocuments to test how quantized models fare against longer contexts. To betterunderstand the effect of retrieval, we evaluate three retrieval models in ourexperiments. Our findings reveal that if a 7B LLM performs the task well,quantization does not impair its performance and long-context reasoningcapabilities. We conclude that it is possible to utilize RAG with quantizedsmaller LLMs.</description><author>Mert Yazan, Suzan Verberne, Frederik Situmeang</author><pubDate>Thu, 01 Aug 2024 16:27:20 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.10251v3</guid></item><item><title>Grappa -- A Machine Learned Molecular Mechanics Force Field</title><link>http://arxiv.org/abs/2404.00050v2</link><description>Simulating large molecular systems over long timescales requires force fieldsthat are both accurate and efficient. In recent years, E(3) equivariant neuralnetworks have lifted the tension between computational efficiency and accuracyof force fields, but they are still several orders of magnitude more expensivethan established molecular mechanics (MM) force fields. Here, we proposeGrappa, a machine learning framework to predict MM parameters from themolecular graph, employing a graph attentional neural network and a transformerwith symmetry-preserving positional encoding. The resulting Grappa force fieldoutperformstabulated and machine-learned MM force fields in terms of accuracyat the same computational efficiency and can be used in existing MolecularDynamics (MD) engines like GROMACS and OpenMM. It predicts energies and forcesof small molecules, peptides, RNA and - showcasing its extensibility touncharted regions of chemical space - radicals at state-of-the-art MM accuracy.We demonstrate Grappa's transferability to macromolecules in MD simulationsfrom a small fast folding protein up to a whole virus particle. Our force fieldsets the stage for biomolecular simulations closer to chemical accuracy, butwith the same computational cost as established protein force fields.</description><author>Leif Seute, Eric Hartmann, Jan Stühmer, Frauke Gräter</author><pubDate>Thu, 01 Aug 2024 16:14:27 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.00050v2</guid></item><item><title>Predicting the Geolocation of Tweets Using transformer models on Customized Data</title><link>http://arxiv.org/abs/2303.07865v4</link><description>This research is aimed to solve the tweet/user geolocation prediction taskand provide a flexible methodology for the geotagging of textual big data. Thesuggested approach implements neural networks for natural language processing(NLP) to estimate the location as coordinate pairs (longitude, latitude) andtwo-dimensional Gaussian Mixture Models (GMMs). The scope of proposed modelshas been finetuned on a Twitter dataset using pretrained Bidirectional EncoderRepresentations from Transformers (BERT) as base models. Performance metricsshow a median error of fewer than 30 km on a worldwide-level, and fewer than 15km on the US-level datasets for the models trained and evaluated on textfeatures of tweets' content and metadata context. Our source code and data areavailable at https://github.com/K4TEL/geo-twitter.git</description><author>Kateryna Lutsai, Christoph H. Lampert</author><pubDate>Thu, 01 Aug 2024 16:14:04 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2303.07865v4</guid></item><item><title>MimiQ: Low-Bit Data-Free Quantization of Vision Transformers with Encouraging Inter-Head Attention Similarity</title><link>http://arxiv.org/abs/2407.20021v3</link><description>Data-free quantization (DFQ) is a technique that creates a lightweightnetwork from its full-precision counterpart without the original training data,often through a synthetic dataset. Although several DFQ methods have beenproposed for vision transformer (ViT) architectures, they fail to achieveefficacy in low-bit settings. Examining the existing methods, we identify thattheir synthetic data produce misaligned attention maps, while those of the realsamples are highly aligned. From the observation of aligned attention, we findthat aligning attention maps of synthetic data helps to improve the overallperformance of quantized ViTs. Motivated by this finding, we devise MimiQ, anovel DFQ method designed for ViTs that focuses on inter-head attentionsimilarity. First, we generate synthetic data by aligning head-wise attentionresponses in relation to spatial query patches. Then, we apply head-wisestructural attention distillation to align the attention maps of the quantizednetwork to those of the full-precision teacher. The experimental results showthat the proposed method significantly outperforms baselines, setting a newstate-of-the-art performance for data-free ViT quantization.</description><author>Kanghyun Choi, Hye Yoon Lee, Dain Kwon, SunJong Park, Kyuyeun Kim, Noseong Park, Jinho Lee</author><pubDate>Thu, 01 Aug 2024 16:13:45 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.20021v3</guid></item><item><title>Evaluate Fine-tuning Strategies for Fetal Head Ultrasound Image Segmentation with U-Net</title><link>http://arxiv.org/abs/2307.09067v2</link><description>Fetal head segmentation is a crucial step in measuring the fetal headcircumference (HC) during gestation, an important biometric in obstetrics formonitoring fetal growth. However, manual biometry generation is time-consumingand results in inconsistent accuracy. To address this issue, convolutionalneural network (CNN) models have been utilized to improve the efficiency ofmedical biometry. But training a CNN network from scratch is a challengingtask, we proposed a Transfer Learning (TL) method. Our approach involvesfine-tuning (FT) a U-Net network with a lightweight MobileNet as the encoder toperform segmentation on a set of fetal head ultrasound (US) images with limitedeffort. This method addresses the challenges associated with training a CNNnetwork from scratch. It suggests that our proposed FT strategy yieldssegmentation performance that is comparable when trained with a reduced numberof parameters by 85.8%. And our proposed FT strategy outperforms otherstrategies with smaller trainable parameter sizes below 4.4 million. Thus, wecontend that it can serve as a dependable FT approach for reducing the size ofmodels in medical image analysis. Our key findings highlight the importance ofthe balance between model performance and size in developing ArtificialIntelligence (AI) applications by TL methods. Code is available athttps://github.com/13204942/FT_Methods_for_Fetal_Head_Segmentation.</description><author>Fangyijie Wang, Guénolé Silvestre, Kathleen M. Curran</author><pubDate>Thu, 01 Aug 2024 16:09:50 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.09067v2</guid></item><item><title>An introduction to reinforcement learning for neuroscience</title><link>http://arxiv.org/abs/2311.07315v2</link><description>Reinforcement learning has a rich history in neuroscience, from early work ondopamine as a reward prediction error signal for temporal difference learning(Schultz et al., 1997) to recent work suggesting that dopamine could implementa form of 'distributional reinforcement learning' popularized in deep learning(Dabney et al., 2020). Throughout this literature, there has been a tight linkbetween theoretical advances in reinforcement learning and neuroscientificexperiments and findings. As a result, the theories describing our experimentaldata have become increasingly complex and difficult to navigate. In thisreview, we cover the basic theory underlying classical work in reinforcementlearning and build up to an introductory overview of methods in modern deepreinforcement learning that have found applications in systems neuroscience. Westart with an overview of the reinforcement learning problem and classicaltemporal difference algorithms, followed by a discussion of 'model-free' and'model-based' reinforcement learning together with methods such as DYNA andsuccessor representations that fall in between these two extremes. Throughoutthese sections, we highlight the close parallels between such machine learningmethods and related work in both experimental and theoretical neuroscience. Wethen provide an introduction to deep reinforcement learning with examples ofhow these methods have been used to model different learning phenomena insystems neuroscience, such as meta-reinforcement learning (Wang et al., 2018)and distributional reinforcement learning (Dabney et al., 2020). Code thatimplements the methods discussed in this work and generates the figures is alsoprovided.</description><author>Kristopher T. Jensen</author><pubDate>Thu, 01 Aug 2024 16:07:02 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.07315v2</guid></item><item><title>A Unified Framework for Pattern Recovery in Penalized and Thresholded Estimation and its Geometry</title><link>http://arxiv.org/abs/2307.10158v4</link><description>We consider the framework of penalized estimation where the penalty term isgiven by a real-valued polyhedral gauge, which encompasses methods such asLASSO, generalized LASSO, SLOPE, OSCAR, PACS and others. Each of theseestimators can uncover a different structure or ``pattern'' of the unknownparameter vector. We define a novel and general notion of patterns based onsubdifferentials and formalize an approach to measure pattern complexity. Forpattern recovery, we provide a minimal condition for a particular pattern to bedetected by the procedure with positive probability, the so-calledaccessibility condition. Using our approach, we also introduce the strongernoiseless recovery condition. For the LASSO, it is well known that theirrepresentability condition is necessary for pattern recovery with probabilitylarger than $1/2$ and we show that the noiseless recovery plays exactly thesame role in our general framework, thereby unifying and extending theirrepresentability condition to a broad class of penalized estimators. We alsoshow that the noiseless recovery condition can be relaxed when turning toso-called thresholded penalized estimators: we prove that the accessibilitycondition is already sufficient (and necessary) for sure pattern recovery bythresholded penalized estimation provided that the signal of the pattern islarge enough. Throughout the article, we demonstrate how our findings can beinterpreted through a geometrical lens.</description><author>Piotr Graczyk, Ulrike Schneider, Tomasz Skalski, Patrick Tardivel</author><pubDate>Thu, 01 Aug 2024 16:03:44 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.10158v4</guid></item><item><title>Switching the Loss Reduces the Cost in Batch (Offline) Reinforcement Learning</title><link>http://arxiv.org/abs/2403.05385v5</link><description>We propose training fitted Q-iteration with log-loss (FQI-log) for batchreinforcement learning (RL). We show that the number of samples needed to learna near-optimal policy with FQI-log scales with the accumulated cost of theoptimal policy, which is zero in problems where acting optimally achieves thegoal and incurs no cost. In doing so, we provide a general framework forproving small-cost bounds, i.e. bounds that scale with the optimal achievablecost, in batch RL. Moreover, we empirically verify that FQI-log uses fewersamples than FQI trained with squared loss on problems where the optimal policyreliably achieves the goal.</description><author>Alex Ayoub, Kaiwen Wang, Vincent Liu, Samuel Robertson, James McInerney, Dawen Liang, Nathan Kallus, Csaba Szepesvári</author><pubDate>Thu, 01 Aug 2024 16:02:06 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.05385v5</guid></item><item><title>Towards Self-Supervised FG-SBIR with Unified Sample Feature Alignment and Multi-Scale Token Recycling</title><link>http://arxiv.org/abs/2406.11551v3</link><description>Fine-Grained Sketch-Based Image Retrieval (FG-SBIR) aims to minimize thedistance between sketches and corresponding images in the embedding space.However, scalability is hindered by the growing complexity of solutions, mainlydue to the abstract nature of fine-grained sketches. In this paper, we proposean effective approach to narrow the gap between the two domains. It mainlyfacilitates unified mutual information sharing both intra- and inter-samples,rather than treating them as a single feature alignment problem betweenmodalities. Specifically, our approach includes: (i) Employing dualweight-sharing networks to optimize alignment within the sketch and imagedomain, which also effectively mitigates model learning saturation issues. (ii)Introducing an objective optimization function based on contrastive loss toenhance the model's ability to align features in both intra- and inter-samples.(iii) Presenting a self-supervised Multi-Scale Token Recycling (MSTR) Modulefeatured by recycling discarded patch tokens in multi-scale features, furtherenhancing representation capability and retrieval performance. Our frameworkachieves excellent results on CNN- and ViT-based backbones. Extensiveexperiments demonstrate its superiority over existing methods. We alsointroduce Cloths-V1, the first professional fashion sketch-image dataset,utilized to validate our method and will be beneficial for other applications</description><author>Jianan Jiang, Hao Tang, Zhilin Jiang, Weiren Yu, Di Wu</author><pubDate>Thu, 01 Aug 2024 16:00:04 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.11551v3</guid></item><item><title>Vivim: a Video Vision Mamba for Medical Video Segmentation</title><link>http://arxiv.org/abs/2401.14168v4</link><description>Medical video segmentation gains increasing attention in clinical practicedue to the redundant dynamic references in video frames. However, traditionalconvolutional neural networks have a limited receptive field andtransformer-based networks are mediocre in constructing long-term dependencyfrom the perspective of computational complexity. This bottleneck poses asignificant challenge when processing longer sequences in medical videoanalysis tasks using available devices with limited memory. Recently, statespace models (SSMs), famous by Mamba, have exhibited impressive achievements inefficient long sequence modeling, which develops deep neural networks byexpanding the receptive field on many vision tasks significantly.Unfortunately, vanilla SSMs failed to simultaneously capture causal temporalcues and preserve non-casual spatial information. To this end, this paperpresents a Video Vision Mamba-based framework, dubbed as Vivim, for medicalvideo segmentation tasks. Our Vivim can effectively compress the long-termspatiotemporal representation into sequences at varying scales with ourdesigned Temporal Mamba Block. We also introduce an improved boundary-awareaffine constraint across frames to enhance the discriminative ability of Vivimon ambiguous lesions. Extensive experiments on thyroid segmentation, breastlesion segmentation in ultrasound videos, and polyp segmentation in colonoscopyvideos demonstrate the effectiveness and efficiency of our Vivim, superior toexisting methods. The code is available at:https://github.com/scott-yjyang/Vivim. The dataset will be released onceaccepted.</description><author>Yijun Yang, Zhaohu Xing, Lequan Yu, Chunwang Huang, Huazhu Fu, Lei Zhu</author><pubDate>Thu, 01 Aug 2024 15:56:43 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.14168v4</guid></item><item><title>Improving Steering and Verification in AI-Assisted Data Analysis with Interactive Task Decomposition</title><link>http://arxiv.org/abs/2407.02651v2</link><description>LLM-powered tools like ChatGPT Data Analysis, have the potential to helpusers tackle the challenging task of data analysis programming, which requiresexpertise in data processing, programming, and statistics. However, ourformative study (n=15) uncovered serious challenges in verifying AI-generatedresults and steering the AI (i.e., guiding the AI system to produce the desiredoutput). We developed two contrasting approaches to address these challenges.The first (Stepwise) decomposes the problem into step-by-step subgoals withpairs of editable assumptions and code until task completion, while the second(Phasewise) decomposes the entire problem into three editable, logical phases:structured input/output assumptions, execution plan, and code. A controlled,within-subjects experiment (n=18) compared these systems against aconversational baseline. Users reported significantly greater control with theStepwise and Phasewise systems, and found intervention, correction, andverification easier, compared to the baseline. The results suggest designguidelines and trade-offs for AI-assisted data analysis tools.</description><author>Majeed Kazemitabaar, Jack Williams, Ian Drosos, Tovi Grossman, Austin Henley, Carina Negreanu, Advait Sarkar</author><pubDate>Thu, 01 Aug 2024 15:56:00 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.02651v2</guid></item><item><title>Technical Note: Defining and Quantifying AND-OR Interactions for Faithful and Concise Explanation of DNNs</title><link>http://arxiv.org/abs/2304.13312v2</link><description>In this technical note, we aim to explain a deep neural network (DNN) byquantifying the encoded interactions between input variables, which reflectsthe DNN's inference logic. Specifically, we first rethink the definition ofinteractions, and then formally define faithfulness and conciseness forinteraction-based explanation. To this end, we propose two kinds ofinteractions, i.e., the AND interaction and the OR interaction. Forfaithfulness, we prove the uniqueness of the AND (OR) interaction inquantifying the effect of the AND (OR) relationship between input variables.Besides, based on AND-OR interactions, we design techniques to boost theconciseness of the explanation, while not hurting the faithfulness. In thisway, the inference logic of a DNN can be faithfully and concisely explained bya set of symbolic concepts.</description><author>Mingjie Li, Quanshi Zhang</author><pubDate>Thu, 01 Aug 2024 15:54:29 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2304.13312v2</guid></item><item><title>Application of Transformers for Nonlinear Channel Compensation in Optical Systems</title><link>http://arxiv.org/abs/2304.13119v3</link><description>In this paper, we introduce a new nonlinear optical channel equalizer basedon Transformers. By leveraging parallel computation and attending directly tothe memory across a sequence of symbols, we show that Transformers can be usedeffectively for nonlinear compensation (NLC) in coherent long-haul transmissionsystems. For this application, we present an implementation of the encoder partof the Transformer and analyze its performance over a wide range of differenthyper-parameters. It is shown that by proper embeddings and processing blocksof symbols at each iteration and also carefully selecting subsets of theencoder's output to be processed together, an efficient nonlinear equalizationcan be achieved for different complexity constraints. To reduce thecomputational complexity of the attention mechanism, we further propose the useof a physic-informed mask inspired by nonlinear perturbation theory. We alsocompare the Transformer-NLC with digital back-propagation (DBP) under differenttransmission scenarios in order to demonstrate the flexibility andgeneralizability of the proposed data-driven solution.</description><author>Behnam Behinaein Hamgini, Hossein Najafi, Ali Bakhshali, Zhuhong Zhang</author><pubDate>Thu, 01 Aug 2024 15:52:32 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2304.13119v3</guid></item><item><title>Text Image Inpainting via Global Structure-Guided Diffusion Models</title><link>http://arxiv.org/abs/2401.14832v3</link><description>Real-world text can be damaged by corrosion issues caused by environmental orhuman factors, which hinder the preservation of the complete styles of texts,e.g., texture and structure. These corrosion issues, such as graffiti signs andincomplete signatures, bring difficulties in understanding the texts, therebyposing significant challenges to downstream applications, e.g., scene textrecognition and signature identification. Notably, current inpaintingtechniques often fail to adequately address this problem and have difficultiesrestoring accurate text images along with reasonable and consistent styles.Formulating this as an open problem of text image inpainting, this paper aimsto build a benchmark to facilitate its study. In doing so, we establish twospecific text inpainting datasets which contain scene text images andhandwritten text images, respectively. Each of them includes images revamped byreal-life and synthetic datasets, featuring pairs of original images, corruptedimages, and other assistant information. On top of the datasets, we furtherdevelop a novel neural framework, Global Structure-guided Diffusion Model(GSDM), as a potential solution. Leveraging the global structure of the text asa prior, the proposed GSDM develops an efficient diffusion model to recoverclean texts. The efficacy of our approach is demonstrated by thorough empiricalstudy, including a substantial boost in both recognition accuracy and imagequality. These findings not only highlight the effectiveness of our method butalso underscore its potential to enhance the broader field of text imageunderstanding and processing. Code and datasets are available at:https://github.com/blackprotoss/GSDM.</description><author>Shipeng Zhu, Pengfei Fang, Chenjie Zhu, Zuoyan Zhao, Qiang Xu, Hui Xue</author><pubDate>Thu, 01 Aug 2024 15:46:43 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.14832v3</guid></item><item><title>A Notion of Complexity for Theory of Mind via Discrete World Models</title><link>http://arxiv.org/abs/2406.11911v2</link><description>Theory of Mind (ToM) can be used to assess the capabilities of Large LanguageModels (LLMs) in complex scenarios where social reasoning is required. Whilethe research community has proposed many ToM benchmarks, their hardness variesgreatly, and their complexity is not well defined. This work proposes aframework to measure the complexity of ToM tasks. We quantify a problem'scomplexity as the number of states necessary to solve it correctly. Ourcomplexity measure also accounts for spurious states of a ToM problem designedto make it apparently harder. We use our method to assess the complexity offive widely adopted ToM benchmarks. On top of this framework, we design aprompting technique that augments the information available to a model with adescription of how the environment changes with the agents' interactions. Wename this technique Discrete World Models (DWM) and show how it elicitssuperior performance on ToM tasks.</description><author>X. Angelo Huang, Emanuele La Malfa, Samuele Marro, Andrea Asperti, Anthony Cohn, Michael Wooldridge</author><pubDate>Thu, 01 Aug 2024 15:44:19 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.11911v2</guid></item><item><title>SC-MIL: Sparsely Coded Multiple Instance Learning for Whole Slide Image Classification</title><link>http://arxiv.org/abs/2311.00048v2</link><description>Multiple Instance Learning (MIL) has been widely used in weakly supervisedwhole slide image (WSI) classification. Typical MIL methods include a featureembedding part, which embeds the instances into features via a pre-trainedfeature extractor, and an MIL aggregator that combines instance embeddings intopredictions. Most efforts have typically focused on improving these parts. Thisinvolves refining the feature embeddings through self-supervised pre-trainingas well as modeling the correlations between instances separately. In this paper, we proposed a sparsely coding MIL (SC-MIL) method thataddresses those two aspects at the same time by leveraging sparse dictionarylearning. The sparse dictionary learning captures the similarities of instancesby expressing them as sparse linear combinations of atoms in an over-completedictionary. In addition, imposing sparsity improves instance feature embeddingsby suppressing irrelevant instances while retaining the most relevant ones. Tomake the conventional sparse coding algorithm compatible with deep learning, weunrolled it into a sparsely coded module leveraging deep unrolling. Theproposed SC module can be incorporated into any existing MIL framework in aplug-and-play manner with an acceptable computational cost. The experimentalresults on multiple datasets demonstrated that the proposed SC module couldsubstantially boost the performance of state-of-the-art MIL methods. The codesare available at\href{https://github.com/sotiraslab/SCMIL.git}{https://github.com/sotiraslab/SCMIL.git}.</description><author>Peijie Qiu, Pan Xiao, Wenhui Zhu, Yalin Wang, Aristeidis Sotiras</author><pubDate>Thu, 01 Aug 2024 15:37:52 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.00048v2</guid></item><item><title>Genetic Algorithms with Neural Cost Predictor for Solving Hierarchical Vehicle Routing Problems</title><link>http://arxiv.org/abs/2310.14157v3</link><description>When vehicle routing decisions are intertwined with higher-level decisions,the resulting optimization problems pose significant challenges forcomputation. Examples are the multi-depot vehicle routing problem (MDVRP),where customers are assigned to depots before delivery, and the capacitatedlocation routing problem (CLRP), where the locations of depots should bedetermined first. A simple and straightforward approach for such hierarchicalproblems would be to separate the higher-level decisions from the complicatedvehicle routing decisions. For each higher-level decision candidate, we mayevaluate the underlying vehicle routing problems to assess the candidate. Asthis approach requires solving vehicle routing problems multiple times, it hasbeen regarded as impractical in most cases. We propose a noveldeep-learning-based approach called Genetic Algorithm with Neural CostPredictor (GANCP) to tackle the challenge and simplify algorithm developments.For each higher-level decision candidate, we predict the objective functionvalues of the underlying vehicle routing problems using a pre-trained graphneural network without actually solving the routing problems. In particular,our proposed neural network learns the objective values of the HGS-CVRPopen-source package that solves capacitated vehicle routing problems. Ournumerical experiments show that this simplified approach is effective andefficient in generating high-quality solutions for both MDVRP and CLRP and hasthe potential to expedite algorithm developments for complicated hierarchicalproblems. We provide computational results evaluated in the standard benchmarkinstances used in the literature.</description><author>Abhay Sobhanan, Junyoung Park, Jinkyoo Park, Changhyun Kwon</author><pubDate>Thu, 01 Aug 2024 15:37:22 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.14157v3</guid></item><item><title>Actor-Critic Physics-informed Neural Lyapunov Control</title><link>http://arxiv.org/abs/2403.08448v2</link><description>Designing control policies for stabilization tasks with provable guaranteesis a long-standing problem in nonlinear control. A crucial performance metricis the size of the resulting region of attraction, which essentially serves asa robustness "margin" of the closed-loop system against uncertainties. In thispaper, we propose a new method to train a stabilizing neural network controlleralong with its corresponding Lyapunov certificate, aiming to maximize theresulting region of attraction while respecting the actuation constraints.Crucial to our approach is the use of Zubov's Partial Differential Equation(PDE), which precisely characterizes the true region of attraction of a givencontrol policy. Our framework follows an actor-critic pattern where wealternate between improving the control policy (actor) and learning a Zubovfunction (critic). Finally, we compute the largest certifiable region ofattraction by invoking an SMT solver after the training procedure. Ournumerical experiments on several design problems show consistent andsignificant improvements in the size of the resulting region of attraction.</description><author>Jiarui Wang, Mahyar Fazlyab</author><pubDate>Thu, 01 Aug 2024 15:16:26 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.08448v2</guid></item><item><title>The opportunities and risks of large language models in mental health</title><link>http://arxiv.org/abs/2403.14814v3</link><description>Global rates of mental health concerns are rising, and there is increasingrealization that existing models of mental health care will not adequatelyexpand to meet the demand. With the emergence of large language models (LLMs)has come great optimism regarding their promise to create novel, large-scalesolutions to support mental health. Despite their nascence, LLMs have alreadybeen applied to mental health related tasks. In this paper, we summarize theextant literature on efforts to use LLMs to provide mental health education,assessment, and intervention and highlight key opportunities for positiveimpact in each area. We then highlight risks associated with LLMs' applicationto mental health and encourage the adoption of strategies to mitigate theserisks. The urgent need for mental health support must be balanced withresponsible development, testing, and deployment of mental health LLMs. It isespecially critical to ensure that mental health LLMs are fine-tuned for mentalhealth, enhance mental health equity, and adhere to ethical standards and thatpeople, including those with lived experience with mental health concerns, areinvolved in all stages from development through deployment. Prioritizing theseefforts will minimize potential harms to mental health and maximize thelikelihood that LLMs will positively impact mental health globally.</description><author>Hannah R. Lawrence, Renee A. Schneider, Susan B. Rubin, Maja J. Mataric, Daniel J. McDuff, Megan Jones Bell</author><pubDate>Thu, 01 Aug 2024 15:15:34 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.14814v3</guid></item><item><title>Untangling the Effects of Down-Sampling and Selection in Genetic Programming</title><link>http://arxiv.org/abs/2304.07089v2</link><description>Genetic programming systems often use large training sets to evaluate thequality of candidate solutions for selection, which is often computationallyexpensive. Down-sampling training sets has long been used to decrease thecomputational cost of evaluation in a wide range of application domains. Morespecifically, recent studies have shown that both random and informeddown-sampling can substantially improve problem-solving success for GP systemsthat use the lexicase parent selection algorithm. We test whether thesedown-sampling techniques can also improve problem-solving success in thecontext of three other commonly used selection methods, fitness-proportionate,tournament, implicit fitness sharing plus tournament selection, across sixprogram synthesis GP problems. We verified that down-sampling can significantlyimprove the problem-solving success for all three of these other selectionschemes, demonstrating its general efficacy. We discern that the selectionpressure imposed by the selection scheme does not interact with thedown-sampling method. However, we find that informed down-sampling can improveproblem solving success significantly over random down-sampling when theselection scheme has a mechanism for diversity maintenance like lexicase orimplicit fitness sharing. Overall, our results suggest that down-samplingshould be considered more often when solving test-based problems, regardless ofthe selection scheme in use.</description><author>Ryan Boldi, Ashley Bao, Martin Briesch, Thomas Helmuth, Dominik Sobania, Lee Spector, Alexander Lalejini</author><pubDate>Thu, 01 Aug 2024 15:13:42 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2304.07089v2</guid></item><item><title>Graph neural network-based surrogate modelling for real-time hydraulic prediction of urban drainage networks</title><link>http://arxiv.org/abs/2404.10324v2</link><description>Physics-based models are computationally time-consuming and infeasible forreal-time scenarios of urban drainage networks, and a surrogate model is neededto accelerate the online predictive modelling. Fully-connected neural networks(NNs) are potential surrogate models, but may suffer from low interpretabilityand efficiency in fitting complex targets. Owing to the state-of-the-artmodelling power of graph neural networks (GNNs) and their match with urbandrainage networks in the graph structure, this work proposes a GNN-basedsurrogate of the flow routing model for the hydraulic prediction problem ofdrainage networks, which regards recent hydraulic states as initial conditions,and future runoff and control policy as boundary conditions. To incorporatehydraulic constraints and physical relationships into drainage modelling,physics-guided mechanisms are designed on top of the surrogate model torestrict the prediction variables with flow balance and flooding occurrenceconstraints. According to case results in a stormwater network, the GNN-basedmodel is more cost-effective with better hydraulic prediction accuracy than theNN-based model after equal training epochs, and the designed mechanisms furtherlimit prediction errors with interpretable domain knowledge. As the modelstructure adheres to the flow routing mechanisms and hydraulic constraints inurban drainage networks, it provides an interpretable and effective solutionfor data-driven surrogate modelling. Simultaneously, the surrogate modelaccelerates the predictive modelling of urban drainage networks for real-timeuse compared with the physics-based model.</description><author>Zhiyu Zhang, Chenkaixiang Lu, Wenchong Tian, Zhenliang Liao, Zhiguo Yuan</author><pubDate>Thu, 01 Aug 2024 15:10:45 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.10324v2</guid></item><item><title>How Are LLMs Mitigating Stereotyping Harms? Learning from Search Engine Studies</title><link>http://arxiv.org/abs/2407.11733v2</link><description>With the widespread availability of LLMs since the release of ChatGPT andincreased public scrutiny, commercial model development appears to have focusedtheir efforts on 'safety' training concerning legal liabilities at the expenseof social impact evaluation. This mimics a similar trend which we could observefor search engine autocompletion some years prior. We draw on scholarship fromNLP and search engine auditing and present a novel evaluation task in the styleof autocompletion prompts to assess stereotyping in LLMs. We assess LLMs byusing four metrics, namely refusal rates, toxicity, sentiment and regard, withand without safety system prompts. Our findings indicate an improvement tostereotyping outputs with the system prompt, but overall a lack of attention byLLMs under study to certain harms classified as toxic, particularly for promptsabout peoples/ethnicities and sexual orientation. Mentions of intersectionalidentities trigger a disproportionate amount of stereotyping. Finally, wediscuss the implications of these findings about stereotyping harms in light ofthe coming intermingling of LLMs and search and the choice of stereotypingmitigation policy to adopt. We address model builders, academics, NLPpractitioners and policy makers, calling for accountability and awarenessconcerning stereotyping harms, be it for training data curation, leader boarddesign and usage, or social impact measurement.</description><author>Alina Leidinger, Richard Rogers</author><pubDate>Thu, 01 Aug 2024 15:09:12 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.11733v2</guid></item><item><title>Neyman-Pearson Multi-class Classification via Cost-sensitive Learning</title><link>http://arxiv.org/abs/2111.04597v4</link><description>Most existing classification methods aim to minimize the overallmisclassification error rate. However, in applications such as loan defaultprediction, different types of errors can have varying consequences. To addressthis asymmetry issue, two popular paradigms have been developed: theNeyman-Pearson (NP) paradigm and the cost-sensitive (CS) paradigm. Previousstudies on the NP paradigm have primarily focused on the binary case, while themulti-class NP problem poses a greater challenge due to its unknownfeasibility. In this work, we tackle the multi-class NP problem by establishinga connection with the CS problem via strong duality and propose two algorithms.We extend the concept of NP oracle inequalities, crucial in binaryclassifications, to NP oracle properties in the multi-class context. Ouralgorithms satisfy these NP oracle properties under certain conditions.Furthermore, we develop practical algorithms to assess the feasibility andstrong duality in multi-class NP problems, which can offer practitioners thelandscape of a multi-class NP problem with various target error levels.Simulations and real data studies validate the effectiveness of our algorithms.To our knowledge, this is the first study to address the multi-class NP problemwith theoretical guarantees. The proposed algorithms have been implemented inthe R package \texttt{npcs}, which is available on CRAN.</description><author>Ye Tian, Yang Feng</author><pubDate>Thu, 01 Aug 2024 14:38:06 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2111.04597v4</guid></item><item><title>A Survey of Text Watermarking in the Era of Large Language Models</title><link>http://arxiv.org/abs/2312.07913v5</link><description>Text watermarking algorithms are crucial for protecting the copyright oftextual content. Historically, their capabilities and application scenarioswere limited. However, recent advancements in large language models (LLMs) haverevolutionized these techniques. LLMs not only enhance text watermarkingalgorithms with their advanced abilities but also create a need for employingthese algorithms to protect their own copyrights or prevent potential misuse.This paper conducts a comprehensive survey of the current state of textwatermarking technology, covering four main aspects: (1) an overview andcomparison of different text watermarking techniques; (2) evaluation methodsfor text watermarking algorithms, including their detectability, impact on textor LLM quality, robustness under target or untargeted attacks; (3) potentialapplication scenarios for text watermarking technology; (4) current challengesand future directions for text watermarking. This survey aims to provideresearchers with a thorough understanding of text watermarking technology inthe era of LLM, thereby promoting its further advancement.</description><author>Aiwei Liu, Leyi Pan, Yijian Lu, Jingjing Li, Xuming Hu, Xi Zhang, Lijie Wen, Irwin King, Hui Xiong, Philip S. Yu</author><pubDate>Thu, 01 Aug 2024 14:35:52 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.07913v5</guid></item><item><title>YourMT3+: Multi-instrument Music Transcription with Enhanced Transformer Architectures and Cross-dataset Stem Augmentation</title><link>http://arxiv.org/abs/2407.04822v3</link><description>Multi-instrument music transcription aims to convert polyphonic musicrecordings into musical scores assigned to each instrument. This task ischallenging for modeling as it requires simultaneously identifying multipleinstruments and transcribing their pitch and precise timing, and the lack offully annotated data adds to the training difficulties. This paper introducesYourMT3+, a suite of models for enhanced multi-instrument music transcriptionbased on the recent language token decoding approach of MT3. We enhance itsencoder by adopting a hierarchical attention transformer in the time-frequencydomain and integrating a mixture of experts. To address data limitations, weintroduce a new multi-channel decoding method for training with incompleteannotations and propose intra- and cross-stem augmentation for dataset mixing.Our experiments demonstrate direct vocal transcription capabilities,eliminating the need for voice separation pre-processors. Benchmarks across tenpublic datasets show our models' competitiveness with, or superiority to,existing transcription models. Further testing on pop music recordingshighlights the limitations of current models. Fully reproducible code anddatasets are available with demos at \url{https://github.com/mimbres/YourMT3}.</description><author>Sungkyun Chang, Emmanouil Benetos, Holger Kirchhoff, Simon Dixon</author><pubDate>Thu, 01 Aug 2024 14:32:05 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.04822v3</guid></item><item><title>eSPARQL: Representing and Reconciling Agnostic and Atheistic Beliefs in RDF-star Knowledge Graphs</title><link>http://arxiv.org/abs/2407.21483v2</link><description>Over the past few years, we have seen the emergence of large knowledge graphscombining information from multiple sources. Sometimes, this information isprovided in the form of assertions about other assertions, defining contextswhere assertions are valid. A recent extension to RDF which admits statementsover statements, called RDF-star, is in revision to become a W3C standard.However, there is no proposal for a semantics of these RDF-star statements nora built-in facility to operate over them. In this paper, we propose a querylanguage for epistemic RDF-star metadata based on a four-valued logic, calledeSPARQL. Our proposed query language extends SPARQL-star, the query languagefor RDF-star, with a new type of FROM clause to facilitate operating withmultiple and sometimes conflicting beliefs. We show that the proposed querylanguage can express four use case queries, including the following features:(i) querying the belief of an individual, (ii) the aggregating of beliefs,(iii) querying who is conflicting with somebody, and (iv) beliefs about beliefs(i.e., nesting of beliefs).</description><author>Xiny Pan, Daniel Hernández, Philipp Seifer, Ralf Lämmel, Steffen Staab</author><pubDate>Thu, 01 Aug 2024 14:22:58 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.21483v2</guid></item><item><title>The DSA Transparency Database: Auditing Self-reported Moderation Actions by Social Media</title><link>http://arxiv.org/abs/2312.10269v3</link><description>Since September 2023, the Digital Services Act (DSA) obliges large onlineplatforms to submit detailed data on each moderation action they take withinthe European Union (EU) to the DSA Transparency Database. From its inception,this centralized database has sparked scholarly interest as an unprecedentedand potentially unique trove of data on real-world online moderation. Here, wethoroughly analyze all 353.12M records submitted by the eight largest socialmedia platforms in the EU during the first 100 days of the database.Specifically, we conduct a platform-wise comparative study of their: volume ofmoderation actions, grounds for decision, types of applied restrictions, typesof moderated content, timeliness in undertaking and submitting moderationactions, and use of automation. Furthermore, we systematically cross-check thecontents of the database with the platforms' own transparency reports. Ouranalyses reveal that (i) the platforms adhered only in part to the philosophyand structure of the database, (ii) the structure of the database is partiallyinadequate for the platforms' reporting needs, (iii) the platforms exhibitedsubstantial differences in their moderation actions, (iv) a remarkable fractionof the database data is inconsistent, (v) the platform X (formerly Twitter)presents the most inconsistencies. Our findings have far-reaching implicationsfor policymakers and scholars across diverse disciplines. They offer guidancefor future regulations that cater to the reporting needs of online platforms ingeneral, but also highlight opportunities to improve and refine the databaseitself.</description><author>Amaury Trujillo, Tiziano Fagni, Stefano Cresci</author><pubDate>Thu, 01 Aug 2024 14:22:11 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.10269v3</guid></item><item><title>A Likelihood-Based Generative Approach for Spatially Consistent Precipitation Downscaling</title><link>http://arxiv.org/abs/2407.04724v2</link><description>Deep learning has emerged as a promising tool for precipitation downscaling.However, current models rely on likelihood-based loss functions to properlymodel the precipitation distribution, leading to spatially inconsistentprojections when sampling. This work explores a novel approach by fusing thestrengths of likelihood-based and adversarial losses used in generative models.As a result, we propose a likelihood-based generative approach forprecipitation downscaling, leveraging the benefits of both methods.</description><author>Jose González-Abad</author><pubDate>Thu, 01 Aug 2024 14:18:32 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.04724v2</guid></item><item><title>Understanding Vector-Valued Neural Networks and Their Relationship with Real and Hypercomplex-Valued Neural Networks</title><link>http://arxiv.org/abs/2309.07716v2</link><description>Despite the many successful applications of deep learning models formultidimensional signal and image processing, most traditional neural networksprocess data represented by (multidimensional) arrays of real numbers. Theintercorrelation between feature channels is usually expected to be learnedfrom the training data, requiring numerous parameters and careful training. Incontrast, vector-valued neural networks are conceived to process arrays ofvectors and naturally consider the intercorrelation between feature channels.Consequently, they usually have fewer parameters and often undergo more robusttraining than traditional neural networks. This paper aims to present a broadframework for vector-valued neural networks, referred to as V-nets. In thiscontext, hypercomplex-valued neural networks are regarded as vector-valuedmodels with additional algebraic properties. Furthermore, this paper explainsthe relationship between vector-valued and traditional neural networks.Precisely, a vector-valued neural network can be obtained by placingrestrictions on a real-valued model to consider the intercorrelation betweenfeature channels. Finally, we show how V-nets, including hypercomplex-valuedneural networks, can be implemented in current deep-learning libraries asreal-valued networks.</description><author>Marcos Eduardo Valle</author><pubDate>Thu, 01 Aug 2024 14:16:23 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2309.07716v2</guid></item><item><title>Generative AI for Health Technology Assessment: Opportunities, Challenges, and Policy Considerations</title><link>http://arxiv.org/abs/2407.11054v2</link><description>This review introduces the transformative potential of generative ArtificialIntelligence (AI) and foundation models, including large language models(LLMs), for health technology assessment (HTA). We explore their applicationsin four critical areas, evidence synthesis, evidence generation, clinicaltrials and economic modeling: (1) Evidence synthesis: Generative AI has thepotential to assist in automating literature reviews and meta-analyses byproposing search terms, screening abstracts, and extracting data with notableaccuracy; (2) Evidence generation: These models can potentially facilitateautomating the process and analyze the increasingly available large collectionsof real-world data (RWD), including unstructured clinical notes and imaging,enhancing the speed and quality of real-world evidence (RWE) generation; (3)Clinical trials: Generative AI can be used to optimize trial design, improvepatient matching, and manage trial data more efficiently; and (4) Economicmodeling: Generative AI can also aid in the development of health economicmodels, from conceptualization to validation, thus streamlining the overall HTAprocess. Despite their promise, these technologies, while rapidly improving,are still nascent and continued careful evaluation in their applications to HTAis required. To ensure their responsible use and implementation, bothdevelopers and users of research incorporating these tools, should familiarizethemselves with their current limitations, including the issues related toscientific validity, risk of bias, and consider equity and ethicalimplications. We also surveyed the current policy landscape and providesuggestions for HTA agencies on responsibly integrating generative AI intotheir workflows, emphasizing the importance of human oversight and thefast-evolving nature of these tools.</description><author>Rachael Fleurence, Jiang Bian, Xiaoyan Wang, Hua Xu, Dalia Dawoud, Mitch Higashi, Jagpreet Chhatwal</author><pubDate>Thu, 01 Aug 2024 14:10:22 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.11054v2</guid></item><item><title>The Susceptibility of Example-Based Explainability Methods to Class Outliers</title><link>http://arxiv.org/abs/2407.20678v2</link><description>This study explores the impact of class outliers on the effectiveness ofexample-based explainability methods for black-box machine learning models. Wereformulate existing explainability evaluation metrics, such as correctness andrelevance, specifically for example-based methods, and introduce a new metric,distinguishability. Using these metrics, we highlight the shortcomings ofcurrent example-based explainability methods, including those who attempt tosuppress class outliers. We conduct experiments on two datasets, a textclassification dataset and an image classification dataset, and evaluate theperformance of four state-of-the-art explainability methods. Our findingsunderscore the need for robust techniques to tackle the challenges posed byclass outliers.</description><author>Ikhtiyor Nematov, Dimitris Sacharidis, Tomer Sagi, Katja Hose</author><pubDate>Thu, 01 Aug 2024 14:09:12 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.20678v2</guid></item><item><title>Prediction Instability in Machine Learning Ensembles</title><link>http://arxiv.org/abs/2407.03194v3</link><description>In machine learning ensembles predictions from multiple models areaggregated. Despite widespread use and strong performance of ensembles inapplied problems little is known about the mathematical properties ofaggregating models and associated consequences for safe, explainable use ofsuch models. In this paper we prove a theorem that shows that any ensemble willexhibit at least one of the following forms of prediction instability. It willeither ignore agreement among all underlying models, change its mind when noneof the underlying models have done so, or be manipulable through inclusion orexclusion of options it would never actually predict. As a consequence,ensemble aggregation procedures will always need to balance the benefits ofinformation use against the risk of these prediction instabilities. Thisanalysis also sheds light on what specific forms of prediction instability toexpect from particular ensemble algorithms; for example popular tree ensembleslike random forest, or xgboost will violate basic, intuitive fairnessproperties. Finally, we show that this can be ameliorated by using consistentmodels in asymptotic conditions.</description><author>Jeremy Kedziora</author><pubDate>Thu, 01 Aug 2024 14:08:53 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.03194v3</guid></item><item><title>TriDeNT: Triple Deep Network Training for Privileged Knowledge Distillation in Histopathology</title><link>http://arxiv.org/abs/2312.02111v3</link><description>Computational pathology models rarely utilise data that will not be availablefor inference. This means most models cannot learn from highly informative datasuch as additional immunohistochemical (IHC) stains and spatialtranscriptomics. We present TriDeNT, a novel self-supervised method forutilising privileged data that is not available during inference to improveperformance. We demonstrate the efficacy of this method for a range ofdifferent paired data including immunohistochemistry, spatial transcriptomicsand expert nuclei annotations. In all settings, TriDeNT outperforms otherstate-of-the-art methods in downstream tasks, with observed improvements of upto 101%. Furthermore, we provide qualitative and quantitative measurements ofthe features learned by these models and how they differ from baselines.TriDeNT offers a novel method to distil knowledge from scarce or costly dataduring training, to create significantly better models for routine inputs.</description><author>Lucas Farndale, Robert Insall, Ke Yuan</author><pubDate>Thu, 01 Aug 2024 14:01:56 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.02111v3</guid></item><item><title>Decoder-only Architecture for Streaming End-to-end Speech Recognition</title><link>http://arxiv.org/abs/2406.16107v2</link><description>Decoder-only language models (LMs) have been successfully adopted forspeech-processing tasks including automatic speech recognition (ASR). The LMshave ample expressiveness and perform efficiently. This efficiency is asuitable characteristic for streaming applications of ASR. In this work, wepropose to use a decoder-only architecture for blockwise streaming ASR. In ourapproach, speech features are compressed using CTC output and context embeddingusing blockwise speech subnetwork, and are sequentially provided as prompts tothe decoder. The decoder estimates the output tokens promptly at each block. Tothis end, we also propose a novel training scheme using random-length prefixprompts to make the model robust to the truncated prompts caused by blockwiseprocessing. An experimental comparison shows that our proposed decoder-onlystreaming ASR achieves 8% relative word error rate reduction in the LibriSpeechtest-other set while being twice as fast as the baseline model.</description><author>Emiru Tsunoo, Hayato Futami, Yosuke Kashiwagi, Siddhant Arora, Shinji Watanabe</author><pubDate>Thu, 01 Aug 2024 13:55:54 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.16107v2</guid></item><item><title>Optimized Deep Learning Models for Malware Detection under Concept Drift</title><link>http://arxiv.org/abs/2308.10821v2</link><description>Despite the promising results of machine learning models in malicious filesdetection, they face the problem of concept drift due to their constantevolution. This leads to declining performance over time, as the datadistribution of the new files differs from the training one, requiring frequentmodel update. In this work, we propose a model-agnostic protocol to improve abaseline neural network against drift. We show the importance of featurereduction and training with the most recent validation set possible, andpropose a loss function named Drift-Resilient Binary Cross-Entropy, animprovement to the classical Binary Cross-Entropy more effective against drift.We train our model on the EMBER dataset, published in2018, and evaluate it on adataset of recent malicious files, collected between 2020 and 2023. Ourimproved model shows promising results, detecting 15.2% more malware than abaseline model.</description><author>William Maillet, Benjamin Marais</author><pubDate>Thu, 01 Aug 2024 13:53:48 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2308.10821v2</guid></item><item><title>Enhancing convolutional neural network generalizability via low-rank weight approximation</title><link>http://arxiv.org/abs/2209.12715v2</link><description>Noise is ubiquitous during image acquisition. Sufficient denoising is oftenan important first step for image processing. In recent decades, deep neuralnetworks (DNNs) have been widely used for image denoising. Most DNN-based imagedenoising methods require a large-scale dataset or focus on supervisedsettings, in which single/pairs of clean images or a set of noisy images arerequired. This poses a significant burden on the image acquisition process.Moreover, denoisers trained on datasets of limited scale may incurover-fitting. To mitigate these issues, we introduce a new self-supervisedframework for image denoising based on the Tucker low-rank tensorapproximation. With the proposed design, we are able to characterize ourdenoiser with fewer parameters and train it based on a single image, whichconsiderably improves the model's generalizability and reduces the cost of dataacquisition. Extensive experiments on both synthetic and real-world noisyimages have been conducted. Empirical results show that our proposed methodoutperforms existing non-learning-based methods (e.g., low-pass filter,non-local mean), single-image unsupervised denoisers (e.g., DIP, NN+BM3D)evaluated on both in-sample and out-sample datasets. The proposed method evenachieves comparable performances with some supervised methods (e.g., DnCNN).</description><author>Chenyin Gao, Shu Yang, Anru R. Zhang</author><pubDate>Thu, 01 Aug 2024 13:53:43 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2209.12715v2</guid></item><item><title>Textualized and Feature-based Models for Compound Multimodal Emotion Recognition in the Wild</title><link>http://arxiv.org/abs/2407.12927v2</link><description>Systems for multimodal emotion recognition (ER) are commonly trained toextract features from different modalities (e.g., visual, audio, and textual)that are combined to predict individual basic emotions. However, compoundemotions often occur in real-world scenarios, and the uncertainty ofrecognizing such complex emotions over diverse modalities is challenging forfeature-based models As an alternative, emerging multimodal large languagemodels (LLMs) like BERT and LLaMA rely on explicit non-verbal cues that may betranslated from different non-textual modalities (e.g., audio and visual) intotext. Textualization of modalities augments data with emotional cues to helpthe LLM encode the interconnections between all modalities in a shared textspace. In such text-based models, prior knowledge of ER tasks is leveraged totextualize relevant nonverbal cues such as audio tone from vocal expressions,and action unit intensity from facial expressions. Since the pre-trainedweights are publicly available for many LLMs, training on large-scale datasetsis unnecessary, allowing fine-tuning for downstream tasks such as compound ER(CER). This paper compares the potential of text- and feature-based approachesfor compound multimodal ER in videos. Experiments were conducted on thechallenging C-EXPR-DB dataset in the wild for CER, and contrasted with resultson the MELD dataset for basic ER. Our results indicate that multimodaltextualization provides lower accuracy than feature-based models on C-EXPR-DB,where text transcripts are captured in the wild. However, higher accuracy canbe achieved when the video data has rich transcripts. Our code is available.</description><author>Nicolas Richet, Soufiane Belharbi, Haseeb Aslam, Meike Emilie Schadt, Manuela González-González, Gustave Cortal, Alessandro Lameiras Koerich, Marco Pedersoli, Alain Finkel, Simon Bacon, Eric Granger</author><pubDate>Thu, 01 Aug 2024 13:51:26 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.12927v2</guid></item><item><title>Evolutionary Reinforcement Learning via Cooperative Coevolution</title><link>http://arxiv.org/abs/2404.14763v3</link><description>Recently, evolutionary reinforcement learning has obtained much attention invarious domains. Maintaining a population of actors, evolutionary reinforcementlearning utilises the collected experiences to improve the behaviour policythrough efficient exploration. However, the poor scalability of geneticoperators limits the efficiency of optimising high-dimensional neuralnetworks.To address this issue, this paper proposes a novel cooperativecoevolutionary reinforcement learning (CoERL) algorithm. Inspired bycooperative coevolution, CoERL periodically and adaptively decomposes thepolicy optimisation problem into multiple subproblems and evolves a populationof neural networks for each of the subproblems. Instead of using geneticoperators, CoERL directly searches for partial gradients to update the policy.Updating policy with partial gradients maintains consistency between thebehaviour spaces of parents and offspring across generations.The experiencescollected by the population are then used to improve the entire policy, whichenhances the sampling efficiency.Experiments on six benchmark locomotion tasksdemonstrate that CoERL outperforms seven state-of-the-art algorithms andbaselines.Ablation study verifies the unique contribution of CoERL's coreingredients.</description><author>Chengpeng Hu, Jialin Liu, Xin Yao</author><pubDate>Thu, 01 Aug 2024 13:35:22 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.14763v3</guid></item><item><title>MoE-Infinity: Offloading-Efficient MoE Model Serving</title><link>http://arxiv.org/abs/2401.14361v2</link><description>This paper presents MoE-Infinity, an offloading-efficient serving system forsparse mixture-of-experts (MoE) models. To optimize offloading, MoE-Infinityachieves novel request-level tracing for expert activation, capturing MoE'ssparse execution patterns such as selective activation, group activation, andskewed reuse. Leveraging the request-level trace, MoE-Infinity performseffective expert prefetching and expert caching, achieving high efficiency intransferring model parameters from host memory to GPU memory. Experimentalresults demonstrate that MoE-Infinity achieves low latency comparable toexpensive full-GPU deployments, which require up to 4X more GPU resources thanMoE-Infinity. Compared to offloading-supporting LLM serving systems such asDeepSpeed-Inference, Llama.cpp, Mixtral Offloading, and BrainStorm,MoE-Infinity exhibits superior latency performance, providing 2-20Ximprovements when serving various MoE models for a large collection of LLMtasks. MoE-Infinity's source code is publicly available ahttps://github.com/TorchMoE/MoE-Infinity</description><author>Leyang Xue, Yao Fu, Zhan Lu, Luo Mai, Mahesh Marina</author><pubDate>Thu, 01 Aug 2024 13:21:24 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.14361v2</guid></item><item><title>The Devil is in the Statistics: Mitigating and Exploiting Statistics Difference for Generalizable Semi-supervised Medical Image Segmentation</title><link>http://arxiv.org/abs/2407.11356v2</link><description>Despite the recent success of domain generalization in medical imagesegmentation, voxel-wise annotation for all source domains remains a hugeburden. Semi-supervised domain generalization has been proposed very recentlyto combat this challenge by leveraging limited labeled data along with abundantunlabeled data collected from multiple medical institutions, depending onprecisely harnessing unlabeled data while improving generalizationsimultaneously. In this work, we observe that domain shifts between medicalinstitutions cause disparate feature statistics, which significantlydeteriorates pseudo-label quality due to an unexpected normalization process.Nevertheless, this phenomenon could be exploited to facilitate unseen domaingeneralization. Therefore, we propose 1) multiple statistics-individualbranches to mitigate the impact of domain shifts for reliable pseudo-labels and2) one statistics-aggregated branch for domain-invariant feature learning.Furthermore, to simulate unseen domains with statistics difference, we approachthis from two aspects, i.e., a perturbation with histogram matching at imagelevel and a random batch normalization selection strategy at feature level,producing diverse statistics to expand the training distribution. Evaluationresults on three medical image datasets demonstrate the effectiveness of ourmethod compared with recent SOTA methods. The code is available athttps://github.com/qiumuyang/SIAB.</description><author>Muyang Qiu, Jian Zhang, Lei Qi, Qian Yu, Yinghuan Shi, Yang Gao</author><pubDate>Thu, 01 Aug 2024 12:58:29 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.11356v2</guid></item><item><title>A causal intervention framework for synthesizing mobility data and evaluating predictive neural networks</title><link>http://arxiv.org/abs/2311.11749v3</link><description>Deep neural networks are increasingly utilized in mobility prediction tasks,yet their intricate internal workings pose challenges for interpretability,especially in comprehending how various aspects of mobility behavior affectpredictions. This study introduces a causal intervention framework to assessthe impact of mobility-related factors on neural networks designed for nextlocation prediction -- a task focusing on predicting the immediate nextlocation of an individual. To achieve this, we employ individual mobilitymodels to synthesize location visit sequences and control behavior dynamics byintervening in their data generation process. We evaluate the interventionallocation sequences using mobility metrics and input them into well-trainednetworks to analyze performance variations. The results demonstrate theeffectiveness in producing location sequences with distinct mobility behaviors,thereby facilitating the simulation of diverse yet realistic spatial andtemporal changes. These changes result in performance fluctuations in nextlocation prediction networks, revealing impacts of critical mobility behaviorfactors, including sequential patterns in location transitions, proclivity forexploring new locations, and preferences in location choices at population andindividual levels. The gained insights hold value for the real-worldapplication of mobility prediction networks, and the framework is expected topromote the use of causal inference to enhance the interpretability androbustness of neural networks in mobility applications.</description><author>Ye Hong, Yanan Xin, Simon Dirmeier, Fernando Perez-Cruz, Martin Raubal</author><pubDate>Thu, 01 Aug 2024 12:37:13 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.11749v3</guid></item><item><title>Enhancing Semantic Similarity Understanding in Arabic NLP with Nested Embedding Learning</title><link>http://arxiv.org/abs/2407.21139v2</link><description>This work presents a novel framework for training Arabic nested embeddingmodels through Matryoshka Embedding Learning, leveraging multilingual,Arabic-specific, and English-based models, to highlight the power of nestedembeddings models in various Arabic NLP downstream tasks. Our innovativecontribution includes the translation of various sentence similarity datasetsinto Arabic, enabling a comprehensive evaluation framework to compare thesemodels across different dimensions. We trained several nested embedding modelson the Arabic Natural Language Inference triplet dataset and assessed theirperformance using multiple evaluation metrics, including Pearson and Spearmancorrelations for cosine similarity, Manhattan distance, Euclidean distance, anddot product similarity. The results demonstrate the superior performance of theMatryoshka embedding models, particularly in capturing semantic nuances uniqueto the Arabic language. Results demonstrated that Arabic Matryoshka embeddingmodels have superior performance in capturing semantic nuances unique to theArabic language, significantly outperforming traditional models by up to20-25\% across various similarity metrics. These results underscore theeffectiveness of language-specific training and highlight the potential ofMatryoshka models in enhancing semantic textual similarity tasks for ArabicNLP.</description><author>Omer Nacar, Anis Koubaa</author><pubDate>Thu, 01 Aug 2024 12:24:01 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.21139v2</guid></item><item><title>Defending Jailbreak Attack in VLMs via Cross-modality Information Detector</title><link>http://arxiv.org/abs/2407.21659v2</link><description>Vision Language Models (VLMs) extend the capacity of LLMs to comprehensivelyunderstand vision information, achieving remarkable performance in manyvision-centric tasks. Despite that, recent studies have shown that these modelsare susceptible to jailbreak attacks, which refer to an exploitative techniquewhere malicious users can break the safety alignment of the target model andgenerate misleading and harmful answers. This potential threat is caused byboth the inherent vulnerabilities of LLM and the larger attack scope introducedby vision input. To enhance the security of VLMs against jailbreak attacks,researchers have developed various defense techniques. However, these methodseither require modifications to the model's internal structure or demandsignificant computational resources during the inference phase. Multimodalinformation is a double-edged sword. While it increases the risk of attacks, italso provides additional data that can enhance safeguards. Inspired by this, wepropose $\underline{\textbf{C}}$ross-modality$\underline{\textbf{I}}$nformation$\underline{\textbf{DE}}$tecto$\underline{\textbf{R}}$ ($\textit{CIDER})$, aplug-and-play jailbreaking detector designed to identify maliciously perturbedimage inputs, utilizing the cross-modal similarity between harmful queries andadversarial images. This simple yet effective cross-modality informationdetector, $\textit{CIDER}$, is independent of the target VLMs and requires lesscomputation cost. Extensive experimental results demonstrate the effectivenessand efficiency of $\textit{CIDER}$, as well as its transferability to bothwhite-box and black-box VLMs.</description><author>Yue Xu, Xiuyuan Qi, Zhan Qin, Wenjie Wang</author><pubDate>Thu, 01 Aug 2024 12:22:28 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.21659v2</guid></item><item><title>Digital Twin-Empowered Task Assignment in Aerial MEC Network: A Resource Coalition Cooperation Approach with Generative Model</title><link>http://arxiv.org/abs/2405.01555v3</link><description>To meet the demands for ubiquitous communication and temporary edge computingin 6G networks, aerial mobile edge computing (MEC) networks have beenenvisioned as a new paradigm. However, dynamic user requests pose challengesfor task assignment strategies. Most of the existing research assumes that thestrategy is deployed on ground-based stations or UAVs, which will beineffective in an environment lacking infrastructure and continuous energysupply. Moreover, the resource mutual exclusion problem of dynamic taskassignment has not been effectively solved. Toward this end, we introduce thedigital twin (DT) into the aerial MEC network to study the resource coalitioncooperation approach with the generative model (GM), which provides apreliminary coalition structure for the coalition game. Specifically, wepropose a novel network framework that is composed of an application plane, aphysical plane, and a virtual plane. After that, the task assignment problem issimplified to convex optimization programming with linear constraints. Andthen, we also propose a resource coalition cooperation approach that is basedon a transferable utility (TU) coalition game to obtain an approximate optimalsolution. Numerical results confirm the effectiveness of our proposed approachin terms of energy consumption and utilization of resources.</description><author>Xin Tang, Qian Chen, Rong Yu, Xiaohuan Li</author><pubDate>Thu, 01 Aug 2024 11:54:46 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.01555v3</guid></item><item><title>Conformal prediction for frequency-severity modeling</title><link>http://arxiv.org/abs/2307.13124v3</link><description>We present a model-agnostic framework for the construction of predictionintervals of insurance claims, with finite sample statistical guarantees,extending the technique of split conformal prediction to the domain oftwo-stage frequency-severity modeling. The framework effectiveness is showcasedwith simulated and real datasets using classical parametric models andcontemporary machine learning methods. When the underlying severity model is arandom forest, we extend the two-stage split conformal prediction algorithm,showing how the out-of-bag mechanism can be leveraged to eliminate the need fora calibration set in the conformal procedure.</description><author>Helton Graziadei, Paulo C. Marques F., Eduardo F. L. de Melo, Rodrigo S. Targino</author><pubDate>Thu, 01 Aug 2024 11:51:44 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.13124v3</guid></item><item><title>Contextual Bandits with Packing and Covering Constraints: A Modular Lagrangian Approach via Regression</title><link>http://arxiv.org/abs/2211.07484v6</link><description>We consider contextual bandits with linear constraints (CBwLC), a variant ofcontextual bandits in which the algorithm consumes multiple resources subjectto linear constraints on total consumption. This problem generalizes contextualbandits with knapsacks (CBwK), allowing for packing and covering constraints,as well as positive and negative resource consumption. We provide the firstalgorithm for CBwLC (or CBwK) that is based on regression oracles. Thealgorithm is simple, computationally efficient, and statistically optimal undermild assumptions. Further, we provide the first vanishing-regret guarantees forCBwLC (or CBwK) that extend beyond the stochastic environment. We side-stepstrong impossibility results from prior work by identifying a weaker (and,arguably, fairer) benchmark to compare against. Our algorithm builds onLagrangeBwK (Immorlica et al., FOCS 2019), a Lagrangian-based technique forCBwK, and SquareCB (Foster and Rakhlin, ICML 2020), a regression-basedtechnique for contextual bandits. Our analysis leverages the inherentmodularity of both techniques.</description><author>Aleksandrs Slivkins, Xingyu Zhou, Karthik Abinav Sankararaman, Dylan J. Foster</author><pubDate>Thu, 01 Aug 2024 11:49:04 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2211.07484v6</guid></item><item><title>A Nested Model for AI Design and Validation</title><link>http://arxiv.org/abs/2407.16888v2</link><description>The growing AI field faces trust, transparency, fairness, and discriminationchallenges. Despite the need for new regulations, there is a mismatch betweenregulatory science and AI, preventing a consistent framework. A five-layernested model for AI design and validation aims to address these issues andstreamline AI application design and validation, improving fairness, trust, andAI adoption. This model aligns with regulations, addresses AI practitioner'sdaily challenges, and offers prescriptive guidance for determining appropriateevaluation approaches by identifying unique validity threats. We have threerecommendations motivated by this model: authors should distinguish betweenlayers when claiming contributions to clarify the specific areas in which thecontribution is made and to avoid confusion, authors should explicitly stateupstream assumptions to ensure that the context and limitations of their AIsystem are clearly understood, AI venues should promote thorough testing andvalidation of AI systems and their compliance with regulatory requirements.</description><author>Akshat Dubey, Zewen Yang, Georges Hattab</author><pubDate>Thu, 01 Aug 2024 11:46:26 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.16888v2</guid></item><item><title>Psychoacoustic Challenges Of Speech Enhancement On VoIP Platforms</title><link>http://arxiv.org/abs/2310.07161v3</link><description>Within the ambit of VoIP (Voice over Internet Protocol) telecommunications,the complexities introduced by acoustic transformations merit rigorousanalysis. This research, rooted in the exploration of proprietary sender-sidedenoising effects, meticulously evaluates platforms such as Google Meets andZoom. The study draws upon the Deep Noise Suppression (DNS) 2020 dataset,ensuring a structured examination tailored to various denoising settings andreceiver interfaces. A methodological novelty is introduced via Blinder-Oaxacadecomposition, traditionally an econometric tool, repurposed herein to analyzeacoustic-phonetic perturbations within VoIP systems. To further ground theimplications of these transformations, psychoacoustic metrics, specificallyPESQ and STOI, were used to explain of perceptual quality and intelligibility.Cumulatively, the insights garnered underscore the intricate landscape ofVoIP-influenced acoustic dynamics. In addition to the primary findings, amultitude of metrics are reported, extending the research purview. Moreover,out-of-domain benchmarking for both time and time-frequency domain speechenhancement models is included, thereby enhancing the depth and applicabilityof this inquiry.</description><author>Joseph Konan, Shikhar Agnihotri, Ojas Bhargave, Shuo Han, Yunyang Zeng, Ankit Shah, Bhiksha Raj</author><pubDate>Thu, 01 Aug 2024 11:37:16 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.07161v3</guid></item><item><title>A Hybrid Intelligence Method for Argument Mining</title><link>http://arxiv.org/abs/2403.09713v2</link><description>Large-scale survey tools enable the collection of citizen feedback in opinioncorpora. Extracting the key arguments from a large and noisy set of opinionshelps in understanding the opinions quickly and accurately. Fully automatedmethods can extract arguments but (1) require large labeled datasets thatinduce large annotation costs and (2) work well for known viewpoints, but notfor novel points of view. We propose HyEnA, a hybrid (human + AI) method forextracting arguments from opinionated texts, combining the speed of automatedprocessing with the understanding and reasoning capabilities of humans. Weevaluate HyEnA on three citizen feedback corpora. We find that, on the onehand, HyEnA achieves higher coverage and precision than a state-of-the-artautomated method when compared to a common set of diverse opinions, justifyingthe need for human insight. On the other hand, HyEnA requires less human effortand does not compromise quality compared to (fully manual) expert analysis,demonstrating the benefit of combining human and artificial intelligence.</description><author>Michiel van der Meer, Enrico Liscio, Catholijn M. Jonker, Aske Plaat, Piek Vossen, Pradeep K. Murukannaiah</author><pubDate>Thu, 01 Aug 2024 11:24:13 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.09713v2</guid></item><item><title>DATENeRF: Depth-Aware Text-based Editing of NeRFs</title><link>http://arxiv.org/abs/2404.04526v2</link><description>Recent advancements in diffusion models have shown remarkable proficiency inediting 2D images based on text prompts. However, extending these techniques toedit scenes in Neural Radiance Fields (NeRF) is complex, as editing individual2D frames can result in inconsistencies across multiple views. Our crucialinsight is that a NeRF scene's geometry can serve as a bridge to integratethese 2D edits. Utilizing this geometry, we employ a depth-conditionedControlNet to enhance the coherence of each 2D image modification. Moreover, weintroduce an inpainting approach that leverages the depth information of NeRFscenes to distribute 2D edits across different images, ensuring robustnessagainst errors and resampling challenges. Our results reveal that thismethodology achieves more consistent, lifelike, and detailed edits thanexisting leading methods for text-driven NeRF scene editing.</description><author>Sara Rojas, Julien Philip, Kai Zhang, Sai Bi, Fujun Luan, Bernard Ghanem, Kalyan Sunkavall</author><pubDate>Thu, 01 Aug 2024 11:17:28 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.04526v2</guid></item><item><title>Towards Assessing Data Replication in Music Generation with Music Similarity Metrics on Raw Audio</title><link>http://arxiv.org/abs/2407.14364v2</link><description>Recent advancements in music generation are raising multiple concerns aboutthe implications of AI in creative music processes, current business models andimpacts related to intellectual property management. A relevant discussion andrelated technical challenge is the potential replication and plagiarism of thetraining set in AI-generated music, which could lead to misuse of data andintellectual property rights violations. To tackle this issue, we present theMusic Replication Assessment (MiRA) tool: a model-independent open evaluationmethod based on diverse audio music similarity metrics to assess datareplication. We evaluate the ability of five metrics to identify exactreplication by conducting a controlled replication experiment in differentmusic genres using synthetic samples. Our results show that the proposedmethodology can estimate exact data replication with a proportion higher than10%. By introducing the MiRA tool, we intend to encourage the open evaluationof music-generative models by researchers, developers, and users concerningdata replication, highlighting the importance of the ethical, social, legal,and economic consequences. Code and examples are available for reproducibilitypurposes.</description><author>Roser Batlle-Roca, Wei-Hisang Liao, Xavier Serra, Yuki Mitsufuji, Emilia Gómez</author><pubDate>Thu, 01 Aug 2024 11:16:30 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.14364v2</guid></item><item><title>QuestGen: Effectiveness of Question Generation Methods for Fact-Checking Applications</title><link>http://arxiv.org/abs/2407.21441v2</link><description>Verifying fact-checking claims poses a significant challenge, even forhumans. Recent approaches have demonstrated that decomposing claims intorelevant questions to gather evidence enhances the efficiency of thefact-checking process. In this paper, we provide empirical evidence showingthat this question decomposition can be effectively automated. We demonstratethat smaller generative models, fine-tuned for the question generation taskusing data augmentation from various datasets, outperform large language modelsby up to 8%. Surprisingly, in some cases, the evidence retrieved usingmachine-generated questions proves to be significantly more effective forfact-checking than that obtained from human-written questions. We also performmanual evaluation of the decomposed questions to assess the quality of thequestions generated.</description><author>Ritvik Setty, Vinay Setty</author><pubDate>Thu, 01 Aug 2024 10:35:57 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.21441v2</guid></item><item><title>Label merge-and-split: A graph-colouring approach for memory-efficient brain parcellation</title><link>http://arxiv.org/abs/2404.10572v2</link><description>Whole brain parcellation requires inferring hundreds of segmentation labelsin large image volumes and thus presents significant practical challenges fordeep learning approaches. We introduce label merge-and-split, a method thatfirst greatly reduces the effective number of labels required forlearning-based whole brain parcellation and then recovers original labels.Using a greedy graph colouring algorithm, our method automatically groups andmerges multiple spatially separate labels prior to model training andinference. The merged labels may be semantically unrelated. A deep learningmodel is trained to predict merged labels. At inference time, original labelsare restored using atlas-based influence regions. In our experiments, theproposed approach reduces the number of labels by up to 68% while achievingsegmentation accuracy comparable to the baseline method without label mergingand splitting. Moreover, model training and inference times as well as GPUmemory requirements were reduced significantly. The proposed method can beapplied to all semantic segmentation tasks with a large number of spatiallyseparate classes within an atlas-based prior.</description><author>Aaron Kujawa, Reuben Dorent, Sebastien Ourselin, Tom Vercauteren</author><pubDate>Thu, 01 Aug 2024 10:34:47 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.10572v2</guid></item><item><title>GLiNER multi-task: Generalist Lightweight Model for Various Information Extraction Tasks</title><link>http://arxiv.org/abs/2406.12925v2</link><description>Information extraction tasks require both accurate, efficient, andgeneralisable models. Classical supervised deep learning approaches can achievethe required performance, but they need large datasets and are limited in theirability to adapt to different tasks. On the other hand, large language models(LLMs) demonstrate good generalization, meaning that they can adapt to manydifferent tasks based on user requests. However, LLMs are computationallyexpensive and tend to fail to generate structured outputs. In this article, wewill introduce a new kind of GLiNER model that can be used for variousinformation extraction tasks while being a small encoder model. Our modelachieved SoTA performance on zero-shot NER benchmarks and leading performanceon question-answering, summarization and relation extraction tasks.Additionally, in this article, we will cover experimental results onself-learning approaches for named entity recognition using GLiNER models.</description><author>Ihor Stepanov, Mykhailo Shtopko</author><pubDate>Thu, 01 Aug 2024 10:09:15 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.12925v2</guid></item><item><title>An AI-Enabled Framework Within Reach for Enhancing Healthcare Sustainability and Fairness</title><link>http://arxiv.org/abs/2406.07558v2</link><description>Good health and well-being is among key issues in the United Nations 2030Sustainable Development Goals. The rising prevalence of large-scale infectiousdiseases and the accelerated aging of the global population are driving thetransformation of healthcare technologies. In this context, establishinglarge-scale public health datasets, developing medical models, and creatingdecision-making systems with a human-centric approach are of strategicsignificance. Recently, by leveraging the extraordinary number of accessiblecameras, groundbreaking advancements have emerged in AI methods forphysiological signal monitoring and disease diagnosis using camera sensors.These approaches, requiring no specialized medical equipment, offer convenientmanners of collecting large-scale medical data in response to public healthevents. Therefore, we outline a prospective framework and heuristic vision fora camera-based public health (CBPH) framework utilizing visual physiologicalmonitoring technology. The CBPH can be considered as a convenient and universalframework for public health, advancing the United Nations SustainableDevelopment Goals, particularly in promoting the universality, sustainability,and equity of healthcare in low- and middle-income countries or regions.Furthermore, CBPH provides a comprehensive solution for building a large-scaleand human-centric medical database, and a multi-task large medical model forpublic health and medical scientific discoveries. It has a significantpotential to revolutionize personal monitoring technologies, digital medicine,telemedicine, and primary health care in public health. Therefore, it can bedeemed that the outcomes of this paper will contribute to the establishment ofa sustainable and fair framework for public health, which serves as a crucialbridge for advancing scientific discoveries in the realm of AI for medicine(AI4Medicine).</description><author>Bin Huang, Changchen Zhao, Zimeng Liu, Shenda Hong, Baochang Zhang, Hao Lu, Zhijun Liu, Wenjin Wang, Hui Liu</author><pubDate>Thu, 01 Aug 2024 09:57:28 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.07558v2</guid></item><item><title>What makes for good morphology representations for spatial omics?</title><link>http://arxiv.org/abs/2407.20660v2</link><description>Spatial omics has transformed our understanding of tissue architecture bypreserving spatial context of gene expression patterns. Simultaneously,advances in imaging AI have enabled extraction of morphological featuresdescribing the tissue. The intersection of spatial omics and imaging AIpresents opportunities for a more holistic understanding. In this review weintroduce a framework for categorizing spatial omics-morphology combinationmethods, focusing on how morphological features can be translated or integratedinto spatial omics analyses. By translation we mean finding morphologicalfeatures that spatially correlate with gene expression patterns with thepurpose of predicting gene expression. Such features can be used to generatesuper-resolution gene expression maps or infer genetic information fromclinical H&amp;E-stained samples. By integration we mean finding morphologicalfeatures that spatially complement gene expression patterns with the purpose ofenriching information. Such features can be used to define spatial domains,especially where gene expression has preceded morphological changes and wheremorphology remains after gene expression. We discuss learning strategies anddirections for further development of the field.</description><author>Eduard Chelebian, Christophe Avenel, Carolina Wählby</author><pubDate>Thu, 01 Aug 2024 09:56:15 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.20660v2</guid></item><item><title>Instructive Dialogue Summarization with Query Aggregations</title><link>http://arxiv.org/abs/2310.10981v3</link><description>Conventional dialogue summarization methods directly generate summaries anddo not consider user's specific interests. This poses challenges in cases wherethe users are more focused on particular topics or aspects. With theadvancement of instruction-finetuned language models, we introduceinstruction-tuning to dialogues to expand the capability set of dialoguesummarization models. To overcome the scarcity of instructive dialoguesummarization data, we propose a three-step approach to synthesize high-qualityquery-based summarization triples. This process involves summary-anchored querygeneration, query filtering, and query-based summary generation. By training aunified model called InstructDS (Instructive Dialogue Summarization) on threesummarization datasets with multi-purpose instructive triples, we expand thecapability of dialogue summarization models. We evaluate our method on fourdatasets, including dialogue summarization and dialogue reading comprehension.Experimental results show that our approach outperforms the state-of-the-artmodels and even models with larger sizes. Additionally, our model exhibitshigher generalizability and faithfulness, as confirmed by human subjectiveevaluations.</description><author>Bin Wang, Zhengyuan Liu, Nancy F. Chen</author><pubDate>Thu, 01 Aug 2024 09:53:49 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.10981v3</guid></item><item><title>Informed Meta-Learning</title><link>http://arxiv.org/abs/2402.16105v4</link><description>In noisy and low-data regimes prevalent in real-world applications, a keychallenge of machine learning lies in effectively incorporating inductivebiases that promote data efficiency and robustness. Meta-learning and informedML stand out as two approaches for incorporating prior knowledge into MLpipelines. While the former relies on a purely data-driven source of priors,the latter is guided by prior domain knowledge. In this paper, we formalise ahybrid paradigm, informed meta-learning, facilitating the incorporation ofpriors from unstructured knowledge representations, such as natural language;thus, unlocking complementarity in cross-task knowledge sharing of humans andmachines. We establish the foundational components of informed meta-learningand present a concrete instantiation of this framework--the Informed NeuralProcess. Through a series of experiments, we demonstrate the potential benefitsof informed meta-learning in improving data efficiency, robustness toobservational noise and task distribution shifts.</description><author>Katarzyna Kobalczyk, Mihaela van der Schaar</author><pubDate>Thu, 01 Aug 2024 09:53:03 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.16105v4</guid></item><item><title>Temporally Disentangled Representation Learning under Unknown Nonstationarity</title><link>http://arxiv.org/abs/2310.18615v2</link><description>In unsupervised causal representation learning for sequential data withtime-delayed latent causal influences, strong identifiability results for thedisentanglement of causally-related latent variables have been established instationary settings by leveraging temporal structure. However, in nonstationarysetting, existing work only partially addressed the problem by either utilizingobserved auxiliary variables (e.g., class labels and/or domain indexes) as sideinformation or assuming simplified latent causal dynamics. Both constrain themethod to a limited range of scenarios. In this study, we further explored theMarkov Assumption under time-delayed causally related process in nonstationarysetting and showed that under mild conditions, the independent latentcomponents can be recovered from their nonlinear mixture up to a permutationand a component-wise transformation, without the observation of auxiliaryvariables. We then introduce NCTRL, a principled estimation framework, toreconstruct time-delayed latent causal variables and identify their relationsfrom measured sequential data only. Empirical evaluations demonstrated thereliable identification of time-delayed latent causal influences, with ourmethodology substantially outperforming existing baselines that fail to exploitthe nonstationarity adequately and then, consequently, cannot distinguishdistribution shifts.</description><author>Xiangchen Song, Weiran Yao, Yewen Fan, Xinshuai Dong, Guangyi Chen, Juan Carlos Niebles, Eric Xing, Kun Zhang</author><pubDate>Thu, 01 Aug 2024 09:43:57 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.18615v2</guid></item><item><title>CultureVo: The Serious Game of Utilizing Gen AI for Enhancing Cultural Intelligence</title><link>http://arxiv.org/abs/2407.20685v2</link><description>CultureVo, Inc. has developed the Integrated Culture Learning Suite (ICLS) todeliver foundational knowledge of world cultures through a combination ofinteractive lessons and gamified experiences. This paper explores howGenerative AI powered by open source Large Langauge Models are utilized withinthe ICLS to enhance cultural intelligence. The suite employs Generative AItechniques to automate the assessment of learner knowledge, analyze behavioralpatterns, and manage interactions with non-player characters using real timelearner assessment. Additionally, ICLS provides contextual hint and recommendcourse content by assessing learner proficiency, while Generative AIfacilitates the automated creation and validation of educational content.</description><author>Ajita Agarwala, Anupam Purwar, Viswanadhasai Rao</author><pubDate>Thu, 01 Aug 2024 09:34:15 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.20685v2</guid></item><item><title>A Correlation-induced Finite Difference Estimator</title><link>http://arxiv.org/abs/2405.05638v3</link><description>Finite difference (FD) approximation is a classic approach to stochasticgradient estimation when only noisy function realizations are available. Inthis paper, we first provide a sample-driven method via the bootstrap techniqueto estimate the optimal perturbation, and then propose an efficient FDestimator based on correlated samples at the estimated optimal perturbation.Furthermore, theoretical analyses of both the perturbation estimator and the FDestimator reveal that, {\it surprisingly}, the correlation enables the proposedFD estimator to achieve a reduction in variance and, in some cases, a decreasein bias compared to the traditional optimal FD estimator. Numerical resultsconfirm the efficiency of our estimators and align well with the theorypresented, especially in scenarios with small sample sizes. Finally, we applythe estimator to solve derivative-free optimization (DFO) problems, andnumerical studies show that DFO problems with 100 dimensions can be effectivelysolved.</description><author>Guo Liang, Guangwu Liu, Kun Zhang</author><pubDate>Thu, 01 Aug 2024 09:25:20 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.05638v3</guid></item><item><title>HiMTM: Hierarchical Multi-Scale Masked Time Series Modeling with Self-Distillation for Long-Term Forecasting</title><link>http://arxiv.org/abs/2401.05012v2</link><description>Time series forecasting is a critical and challenging task in practicalapplication. Recent advancements in pre-trained foundation models for timeseries forecasting have gained significant interest. However, current methodsoften overlook the multi-scale nature of time series, which is essential foraccurate forecasting. To address this, we propose HiMTM, a hierarchicalmulti-scale masked time series modeling with self-distillation for long-termforecasting. HiMTM integrates four key components: (1) hierarchical multi-scaletransformer (HMT) to capture temporal information at different scales; (2)decoupled encoder-decoder (DED) that directs the encoder towards featureextraction while the decoder focuses on pretext tasks; (3) hierarchicalself-distillation (HSD) for multi-stage feature-level supervision signalsduring pre-training; and (4) cross-scale attention fine-tuning (CSA-FT) tocapture dependencies between different scales for downstream tasks. Thesecomponents collectively enhance multi-scale feature extraction in masked timeseries modeling, improving forecasting accuracy. Extensive experiments on sevenmainstream datasets show that HiMTM surpasses state-of-the-art self-supervisedand end-to-end learning methods by a considerable margin of 3.16-68.54\%.Additionally, HiMTM outperforms the latest robust self-supervised learningmethod, PatchTST, in cross-domain forecasting by a significant margin of 2.3\%.The effectiveness of HiMTM is further demonstrated through its application innatural gas demand forecasting.</description><author>Shubao Zhao, Ming Jin, Zhaoxiang Hou, Chengyi Yang, Zengxiang Li, Qingsong Wen, Yi Wang</author><pubDate>Thu, 01 Aug 2024 09:18:17 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.05012v2</guid></item><item><title>Advancing Multimodal Data Fusion in Pain Recognition: A Strategy Leveraging Statistical Correlation and Human-Centered Perspectives</title><link>http://arxiv.org/abs/2404.00320v2</link><description>This research presents a novel multimodal data fusion methodology for painbehavior recognition, integrating statistical correlation analysis withhuman-centered insights. Our approach introduces two key innovations: 1)integrating data-driven statistical relevance weights into the fusion strategyto effectively utilize complementary information from heterogeneous modalities,and 2) incorporating human-centric movement characteristics into multimodalrepresentation learning for detailed modeling of pain behaviors. Validatedacross various deep learning architectures, our method demonstrates superiorperformance and broad applicability. We propose a customizable framework thataligns each modality with a suitable classifier based on statisticalsignificance, advancing personalized and effective multimodal fusion.Furthermore, our methodology provides explainable analysis of multimodal data,contributing to interpretable and explainable AI in healthcare. By highlightingthe importance of data diversity and modality-specific representations, weenhance traditional fusion techniques and set new standards for recognizingcomplex pain behaviors. Our findings have significant implications forpromoting patient-centered healthcare interventions and supporting explainableclinical decision-making.</description><author>Xingrui Gu, Zhixuan Wang, Irisa Jin, Zekun Wu</author><pubDate>Thu, 01 Aug 2024 09:07:45 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.00320v2</guid></item><item><title>Spectral-Spatial Mamba for Hyperspectral Image Classification</title><link>http://arxiv.org/abs/2404.18401v3</link><description>Recently, deep learning models have achieved excellent performance inhyperspectral image (HSI) classification. Among the many deep models,Transformer has gradually attracted interest for its excellence in modeling thelong-range dependencies of spatial-spectral features in HSI. However,Transformer has the problem of quadratic computational complexity due to theself-attention mechanism, which is heavier than other models and thus haslimited adoption in HSI processing. Fortunately, the recently emerging statespace model-based Mamba shows great computational efficiency while achievingthe modeling power of Transformers. Therefore, in this paper, we make apreliminary attempt to apply the Mamba to HSI classification, leading to theproposed spectral-spatial Mamba (SS-Mamba). Specifically, the proposed SS-Mambamainly consists of spectral-spatial token generation module and several stackedspectral-spatial Mamba blocks. Firstly, the token generation module convertsany given HSI cube to spatial and spectral tokens as sequences. And then thesetokens are sent to stacked spectral-spatial mamba blocks (SS-MB). Each SS-MBblock consists of two basic mamba blocks and a spectral-spatial featureenhancement module. The spatial and spectral tokens are processed separately bythe two basic mamba blocks, respectively. Besides, the feature enhancementmodule modulates spatial and spectral tokens using HSI sample's center regioninformation. In this way, the spectral and spatial tokens cooperate with eachother and achieve information fusion within each block. The experimentalresults conducted on widely used HSI datasets reveal that the proposed modelachieves competitive results compared with the state-of-the-art methods. TheMamba-based method opens a new window for HSI classification.</description><author>Lingbo Huang, Yushi Chen, Xin He</author><pubDate>Thu, 01 Aug 2024 09:04:39 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.18401v3</guid></item><item><title>Goal-conditioned reinforcement learning for ultrasound navigation guidance</title><link>http://arxiv.org/abs/2405.01409v3</link><description>Transesophageal echocardiography (TEE) plays a pivotal role in cardiology fordiagnostic and interventional procedures. However, using it effectivelyrequires extensive training due to the intricate nature of image acquisitionand interpretation. To enhance the efficiency of novice sonographers and reducevariability in scan acquisitions, we propose a novel ultrasound (US) navigationassistance method based on contrastive learning as goal-conditionedreinforcement learning (GCRL). We augment the previous framework using a novelcontrastive patient batching method (CPB) and a data-augmented contrastiveloss, both of which we demonstrate are essential to ensure generalization toanatomical variations across patients. The proposed framework enablesnavigation to both standard diagnostic as well as intricate interventionalviews with a single model. Our method was developed with a large dataset of 789patients and obtained an average error of 6.56 mm in position and 9.36 degreesin angle on a testing dataset of 140 patients, which is competitive or superiorto models trained on individual views. Furthermore, we quantitatively validateour method's ability to navigate to interventional views such as the LeftAtrial Appendage (LAA) view used in LAA closure. Our approach holds promise inproviding valuable guidance during transesophageal ultrasound examinations,contributing to the advancement of skill acquisition for cardiac ultrasoundpractitioners.</description><author>Abdoul Aziz Amadou, Vivek Singh, Florin C. Ghesu, Young-Ho Kim, Laura Stanciulescu, Harshitha P. Sai, Puneet Sharma, Alistair Young, Ronak Rajani, Kawal Rhode</author><pubDate>Thu, 01 Aug 2024 08:58:40 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.01409v3</guid></item><item><title>Robust Unsupervised Multi-task and Transfer Learning on Gaussian Mixture Models</title><link>http://arxiv.org/abs/2209.15224v3</link><description>Unsupervised learning has been widely used in many real-world applications.One of the simplest and most important unsupervised learning models is theGaussian mixture model (GMM). In this work, we study the multi-task learningproblem on GMMs, which aims to leverage potentially similar GMM parameterstructures among tasks to obtain improved learning performance compared tosingle-task learning. We propose a multi-task GMM learning procedure based onthe EM algorithm that effectively utilizes unknown similarities between relatedtasks and is robust against a fraction of outlier tasks from arbitrarydistributions. The proposed procedure is shown to achieve the minimax optimalrate of convergence for both parameter estimation error and the excessmis-clustering error, in a wide range of regimes. Moreover, we generalize ourapproach to tackle the problem of transfer learning for GMMs, where similartheoretical results are derived. Additionally, iterative unsupervisedmulti-task and transfer learning methods may suffer from an initializationalignment problem, and two alignment algorithms are proposed to resolve theissue. Finally, we demonstrate the effectiveness of our methods throughsimulations and real data examples. To the best of our knowledge, this is thefirst work studying multi-task and transfer learning on GMMs with theoreticalguarantees.</description><author>Ye Tian, Haolei Weng, Lucy Xia, Yang Feng</author><pubDate>Thu, 01 Aug 2024 08:54:39 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2209.15224v3</guid></item><item><title>Large Language Models for Next Point-of-Interest Recommendation</title><link>http://arxiv.org/abs/2404.17591v2</link><description>The next Point of Interest (POI) recommendation task is to predict users'immediate next POI visit given their historical data. Location-Based SocialNetwork (LBSN) data, which is often used for the next POI recommendation task,comes with challenges. One frequently disregarded challenge is how toeffectively use the abundant contextual information present in LBSN data.Previous methods are limited by their numerical nature and fail to address thischallenge. In this paper, we propose a framework that uses pretrained LargeLanguage Models (LLMs) to tackle this challenge. Our framework allows us topreserve heterogeneous LBSN data in its original format, hence avoiding theloss of contextual information. Furthermore, our framework is capable ofcomprehending the inherent meaning of contextual information due to theinclusion of commonsense knowledge. In experiments, we test our framework onthree real-world LBSN datasets. Our results show that the proposed frameworkoutperforms the state-of-the-art models in all three datasets. Our analysisdemonstrates the effectiveness of the proposed framework in using contextualinformation as well as alleviating the commonly encountered cold-start andshort trajectory problems.</description><author>Peibo Li, Maarten de Rijke, Hao Xue, Shuang Ao, Yang Song, Flora D. Salim</author><pubDate>Thu, 01 Aug 2024 08:54:15 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.17591v2</guid></item><item><title>Modeling Latent Selection with Structural Causal Models</title><link>http://arxiv.org/abs/2401.06925v2</link><description>Selection bias is ubiquitous in real-world data, and can lead to misleadingresults if not dealt with properly. We introduce a conditioning operation onStructural Causal Models (SCMs) to model latent selection from a causalperspective. We show that the conditioning operation transforms an SCM with thepresence of an explicit latent selection mechanism into an SCM without suchselection mechanism, which partially encodes the causal semantics of theselected subpopulation according to the original SCM. Furthermore, we show thatthis conditioning operation preserves the simplicity, acyclicity, and linearityof SCMs, and commutes with marginalization. Thanks to these properties,combined with marginalization and intervention, the conditioning operationoffers a valuable tool for conducting causal reasoning tasks within causalmodels where latent details have been abstracted away. We demonstrate byexample how classical results of causal inference can be generalized to includeselection bias and how the conditioning operation helps with modeling ofreal-world problems.</description><author>Leihao Chen, Onno Zoeter, Joris M. Mooij</author><pubDate>Thu, 01 Aug 2024 08:51:46 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.06925v2</guid></item><item><title>Centroid-centered Modeling for Efficient Vision Transformer Pre-training</title><link>http://arxiv.org/abs/2303.04664v2</link><description>Masked Image Modeling (MIM) is a new self-supervised vision pre-trainingparadigm using a Vision Transformer (ViT). Previous works can be pixel-based ortoken-based, using original pixels or discrete visual tokens from parametrictokenizer models, respectively. Our proposed centroid-based approach, CCViT,leverages k-means clustering to obtain centroids for image modeling withoutsupervised training of the tokenizer model, which only takes seconds to create.This non-parametric centroid tokenizer only takes seconds to create and isfaster for token inference. The centroids can represent both patch pixels andindex tokens with the property of local invariance. Specifically, we adoptpatch masking and centroid replacing strategies to construct corrupted inputs,and two stacked encoder blocks to predict corrupted patch tokens andreconstruct original patch pixels. Experiments show that our CCViT achieves84.4% top-1 accuracy on ImageNet-1K classification with ViT-B and 86.0% withViT-L. We also transfer our pre-trained model to other downstream tasks. Ourapproach achieves competitive results with recent baselines without externalsupervision and distillation training from other models.</description><author>Xin Yan, Zuchao Li, Lefei Zhang</author><pubDate>Thu, 01 Aug 2024 08:39:23 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2303.04664v2</guid></item><item><title>OpenUAS: Embeddings of Cities in Japan with Anchor Data for Cross-city Analysis of Area Usage Patterns</title><link>http://arxiv.org/abs/2407.19872v2</link><description>We publicly release OpenUAS, a dataset of area embeddings based on urbanusage patterns, including embeddings for over 1.3 million 50-meter squaremeshes covering a total area of 3,300 square kilometers. This dataset isvaluable for analyzing area functions in fields such as market analysis, urbanplanning, transportation infrastructure, and infection prediction. It capturesthe characteristics of each area in the city, such as office districts andresidential areas, by employing an area embedding technique that utilizeslocation information typically obtained by GPS. Numerous area embeddingtechniques have been proposed, and while the public release of such embeddingdatasets is technically feasible, it has not been realized. One of theobstacles has been the integration of data from different cities and periodsinto a unified space without sharing raw location data. We address this issueby developing an anchoring method that establishes anchors within a sharedembedding space. We publicly release this anchor dataset along with areaembedding datasets from several periods in eight major Japanese cities. Thisdataset allows users to analyze urban usage patterns in Japanese cities andembed their urban dataset into the same embedding space using the anchoringmethod. Our key contributions include the development of the anchoring method,releasing area embedding datasets for Japanese cities, and providing tools foreffective data utilization.</description><author>Naoki Tamura, Kazuyuki Shoji, Shin Katayama, Kenta Urano, Takuro Yonezawa, Nobuo Kawaguchi</author><pubDate>Thu, 01 Aug 2024 08:38:35 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.19872v2</guid></item><item><title>HG-PIPE: Vision Transformer Acceleration with Hybrid-Grained Pipeline</title><link>http://arxiv.org/abs/2407.17879v2</link><description>Vision Transformer (ViT) acceleration with field programmable gate array(FPGA) is promising but challenging. Existing FPGA-based ViT acceleratorsmainly rely on temporal architectures, which process different operators byreusing the same hardware blocks and suffer from extensive memory accessoverhead. Pipelined architectures, either coarse-grained or fine-grained,unroll the ViT computation spatially for memory access efficiency. However,they usually suffer from significant hardware resource constraints and pipelinebubbles induced by the global computation dependency of ViT. In this paper, weintroduce HG-PIPE, a pipelined FPGA accelerator for high-throughput andlow-latency ViT processing. HG-PIPE features a hybrid-grained pipelinearchitecture to reduce on-chip buffer cost and couples the computation dataflowand parallelism design to eliminate the pipeline bubbles. HG-PIPE furtherintroduces careful approximations to implement both linear and non-linearoperators with abundant Lookup Tables (LUTs), thus alleviating resourceconstraints. On a ZCU102 FPGA, HG-PIPE achieves 2.78 times better throughputand 2.52 times better resource efficiency than the prior-art accelerators,e.g., AutoViTAcc. With a VCK190 FPGA, HG-PIPE realizes end-to-end ViTacceleration on a single device and achieves 7118 images/s, which is 2.81 timesfaster than a V100 GPU.</description><author>Qingyu Guo, Jiayong Wan, Songqiang Xu, Meng Li, Yuan Wang</author><pubDate>Thu, 01 Aug 2024 08:18:57 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.17879v2</guid></item><item><title>KeyVideoLLM: Towards Large-scale Video Keyframe Selection</title><link>http://arxiv.org/abs/2407.03104v2</link><description>Recently, with the rise of web videos, managing and understanding large-scalevideo datasets has become increasingly important. Video Large Language Models(VideoLLMs) have emerged in recent years due to their strong videounderstanding capabilities. However, training and inference processes forVideoLLMs demand vast amounts of data, presenting significant challenges todata management, particularly regarding efficiency, robustness, andeffectiveness. In this work, we present KeyVideoLLM, a text-video framesimilarity-based keyframe selection method designed to manage VideoLLM dataefficiently, robustly, and effectively. Specifically, KeyVideoLLM achieves aremarkable data compression rate of up to 60.9 times, substantially loweringdisk space requirements, which proves its high efficiency. Additionally, itmaintains a 100% selection success rate across all video formats and scales,enhances processing speed by up to 200 times compared to existing keyframeselection methods, and does not require hyperparameter tuning. Beyond itsoutstanding efficiency and robustness, KeyVideoLLM further improves modelperformance in video question-answering tasks during both training andinference stages. Notably, it consistently achieved the state-of-the-art (SoTA)experimental results on diverse datasets.</description><author>Hao Liang, Jiapeng Li, Tianyi Bai, Xijie Huang, Linzhuang Sun, Zhengren Wang, Conghui He, Bin Cui, Chong Chen, Wentao Zhang</author><pubDate>Thu, 01 Aug 2024 08:08:43 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.03104v2</guid></item><item><title>M^2ConceptBase: A Fine-Grained Aligned Concept-Centric Multimodal Knowledge Base</title><link>http://arxiv.org/abs/2312.10417v2</link><description>Multimodal knowledge bases (MMKBs) provide cross-modal aligned knowledgecrucial for multimodal tasks. However, the images in existing MMKBs aregenerally collected for entities in encyclopedia knowledge graphs. Therefore,detailed groundings of visual semantics with linguistic concepts are lacking,which are essential for the visual concept cognition ability of multimodalmodels. Addressing this gap, we introduce M^2ConceptBase, the firstconcept-centric MMKB. M^2ConceptBase models concepts as nodes with associatedimages and detailed textual descriptions. We propose a context-aware multimodalsymbol grounding approach to align concept-image and concept-description pairsusing context information from image-text datasets. Comprising 951K images and152K concepts, M^2ConceptBase links each concept to an average of 6.27 imagesand a single description, ensuring comprehensive visual and textual semantics.Human studies confirm more than 95% alignment accuracy, underscoring itsquality. Additionally, our experiments demonstrate that M^2ConceptBasesignificantly enhances VQA model performance on the OK-VQA task. M^2ConceptBasealso substantially improves the fine-grained concept understanding capabilitiesof multimodal large language models through retrieval augmentation in twoconcept-related tasks, highlighting its value.</description><author>Zhiwei Zha, Jiaan Wang, Zhixu Li, Xiangru Zhu, Wei Song, Yanghua Xiao</author><pubDate>Thu, 01 Aug 2024 08:03:48 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.10417v2</guid></item><item><title>GRU-Net: Gaussian Attention Aided Dense Skip Connection Based MultiResUNet for Breast Histopathology Image Segmentation</title><link>http://arxiv.org/abs/2406.08604v2</link><description>Breast cancer is a major global health concern. Pathologists face challengesin analyzing complex features from pathological images, which is atime-consuming and labor-intensive task. Therefore, efficient computer-baseddiagnostic tools are needed for early detection and treatment planning. Thispaper presents a modified version of MultiResU-Net for histopathology imagesegmentation, which is selected as the backbone for its ability to analyze andsegment complex features at multiple scales and ensure effective feature flowvia skip connections. The modified version also utilizes the Gaussiandistribution-based Attention Module (GdAM) to incorporatehistopathology-relevant text information in a Gaussian distribution. Thesampled features from the Gaussian text feature-guided distribution highlightspecific spatial regions based on prior knowledge. Finally, using theControlled Dense Residual Block (CDRB) on skip connections of MultiResU-Net,the information is transferred from the encoder layers to the decoder layers ina controlled manner using a scaling parameter derived from the extractedspatial features. We validate our approach on two diverse breast cancerhistopathology image datasets: TNBC and MonuSeg, demonstrating superiorsegmentation performance compared to state-of-the-art methods. The code for ourproposed model is available on https://github.com/AyushRoy2001/GRU-Net.</description><author>Ayush Roy, Payel Pramanik, Sohom Ghosal, Daria Valenkova, Dmitrii Kaplun, Ram Sarkar</author><pubDate>Thu, 01 Aug 2024 07:55:49 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.08604v2</guid></item><item><title>ChunkAttention: Efficient Self-Attention with Prefix-Aware KV Cache and Two-Phase Partition</title><link>http://arxiv.org/abs/2402.15220v4</link><description>Self-attention is an essential component of large language models (LLM) but asignificant source of inference latency for long sequences. In multi-tenant LLMserving scenarios, the compute and memory operation cost of self-attention canbe optimized by using the probability that multiple LLM requests have sharedsystem prompts in prefixes. In this paper, we introduce ChunkAttention, aprefix-aware self-attention module that can detect matching prompt prefixesacross multiple requests and share their key/value tensors in memory at runtimeto improve the memory utilization of KV cache. This is achieved by breakingmonolithic key/value tensors into smaller chunks and structuring them into theauxiliary prefix tree. Consequently, on top of the prefix-tree based KV cache,we design an efficient self-attention kernel, where a two-phase partitionalgorithm is implemented to improve the data locality during self-attentioncomputation in the presence of shared system prompts. Experiments show thatChunkAttention can speed up the self-attention kernel by 3.2-4.8$\times$compared to the state-of-the-art implementation, with the length of the systemprompt ranging from 1024 to 4096.</description><author>Lu Ye, Ze Tao, Yong Huang, Yang Li</author><pubDate>Thu, 01 Aug 2024 07:51:25 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.15220v4</guid></item><item><title>DefInt: A Default-interventionist Framework for Efficient Reasoning with Hybrid Large Language Models</title><link>http://arxiv.org/abs/2402.02563v3</link><description>Large language models (LLMs) have shown impressive emergent abilities in awide range of tasks, but still face challenges in handling complex reasoningproblems. Previous works like chain-of-thought (CoT) and tree-of-thoughts (ToT)have predominately focused on enhancing accuracy, but overlook the rapidlyincreasing token cost, which could be particularly problematic for open-endedreal-world tasks with huge solution spaces. Motivated by the dual processtheory of human cognition, we propose a Default-Interventionist framework(DefInt) to unleash the synergistic potential of hybrid LLMs. By default,DefInt uses smaller-scale language models to generate low-cost reasoningthoughts, which resembles the fast intuitions produced by System 1. If theintuitions are considered with low confidence, DefInt will invoke thereflective reasoning of scaled-up language models as the intervention of System2, which can override the default thoughts and rectify the reasoning process.Experiments on five representative reasoning tasks show that DefIntconsistently achieves state-of-the-art reasoning accuracy and solutiondiversity. More importantly, it substantially reduces the token cost by 49%-79%compared to the second accurate baselines. Specifically, the open-ended taskshave an average 75% token cost reduction. Code repo with all prompts will bereleased upon publication.</description><author>Yu Shang, Yu Li, Fengli Xu, Yong Li</author><pubDate>Thu, 01 Aug 2024 07:46:54 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.02563v3</guid></item><item><title>Metadata Integration for Spam Reviews Detection on Vietnamese E-commerce Websites</title><link>http://arxiv.org/abs/2405.13292v2</link><description>The problem of detecting spam reviews (opinions) has received significantattention in recent years, especially with the rapid development of e-commerce.Spam reviews are often classified based on comment content, but in some cases,it is insufficient for models to accurately determine the review label. In thiswork, we introduce the ViSpamReviews v2 dataset, which includes metadata ofreviews with the objective of integrating supplementary attributes for spamreview classification. We propose a novel approach to simultaneously integrateboth textual and categorical attributes into the classification model. In ourexperiments, the product category proved effective when combined with deepneural network (DNN) models, while text features performed well on both DNNmodels and the model achieved state-of-the-art performance in the problem ofdetecting spam reviews on Vietnamese e-commerce websites, namely PhoBERT.Specifically, the PhoBERT model achieves the highest accuracy when combinedwith product description features generated from the SPhoBert model, which isthe combination of PhoBERT and SentenceBERT. Using the macro-averaged F1 score,the task of classifying spam reviews achieved 87.22% (an increase of 1.64%compared to the baseline), while the task of identifying the type of spamreviews achieved an accuracy of 73.49% (an increase of 1.93% compared to thebaseline).</description><author>Co Van Dinh, Son T. Luu</author><pubDate>Thu, 01 Aug 2024 07:46:25 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.13292v2</guid></item><item><title>DFE-IANet: A Method for Polyp Image Classification Based on Dual-domain Feature Extraction and Interaction Attention</title><link>http://arxiv.org/abs/2407.20843v2</link><description>It is helpful in preventing colorectal cancer to detect and treat polyps inthe gastrointestinal tract early. However, there have been few studies to dateon designing polyp image classification networks that balance efficiency andaccuracy. This challenge is mainly attributed to the fact that polyps aresimilar to other pathologies and have complex features influenced by texture,color, and morphology. In this paper, we propose a novel network DFE-IANetbased on both spectral transformation and feature interaction. Firstly, toextract detailed features and multi-scale features, the features aretransformed by the multi-scale frequency domain feature extraction (MSFD) blockto extract texture details at the fine-grained level in the frequency domain.Secondly, the multi-scale interaction attention (MSIA) block is designed toenhance the network's capability of extracting critical features. This blockintroduces multi-scale features into self-attention, aiming to adaptively guidethe network to concentrate on vital regions. Finally, with a compact parameterof only 4M, DFE-IANet outperforms the latest and classical networks in terms ofefficiency. Furthermore, DFE-IANet achieves state-of-the-art (SOTA) results onthe challenging Kvasir dataset, demonstrating a remarkable Top-1 accuracy of93.94%. This outstanding accuracy surpasses ViT by 8.94%, ResNet50 by 1.69%,and VMamba by 1.88%. Our code is publicly available athttps://github.com/PURSUETHESUN/DFE-IANet.</description><author>Wei Wang, Jixing He, Xin Wang</author><pubDate>Thu, 01 Aug 2024 07:43:11 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.20843v2</guid></item><item><title>Lite-Mind: Towards Efficient and Robust Brain Representation Network</title><link>http://arxiv.org/abs/2312.03781v4</link><description>The limited data availability and the low signal-to-noise ratio of fMRIsignals lead to the challenging task of fMRI-to-image retrieval.State-of-the-art MindEye remarkably improves fMRI-to-image retrievalperformance by leveraging a large model, i.e., a 996M MLP Backbone per subject,to align fMRI embeddings to the final hidden layer of CLIP's Vision Transformer(ViT). However, significant individual variations exist among subjects, evenunder identical experimental setups, mandating the training of largesubject-specific models. The substantial parameters pose significant challengesin deploying fMRI decoding on practical devices. To this end, we proposeLite-Mind, a lightweight, efficient, and robust brain representation learningparadigm based on Discrete Fourier Transform (DFT), which efficiently alignsfMRI voxels to fine-grained information of CLIP. We elaborately design a DFTbackbone with Spectrum Compression and Frequency Projector modules to learninformative and robust voxel embeddings. Our experiments demonstrate thatLite-Mind achieves an impressive 94.6% fMRI-to-image retrieval accuracy on theNSD dataset for Subject 1, with 98.7% fewer parameters than MindEye. Lite-Mindis also proven to be able to be migrated to smaller fMRI datasets andestablishes a new state-of-the-art for zero-shot classification on the GODdataset.</description><author>Zixuan Gong, Qi Zhang, Guangyin Bao, Lei Zhu, Ke Liu, Liang Hu, Duoqian Miao, Yu Zhang</author><pubDate>Thu, 01 Aug 2024 07:29:47 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.03781v4</guid></item><item><title>Towards Physically Consistent Deep Learning For Climate Model Parameterizations</title><link>http://arxiv.org/abs/2406.03920v2</link><description>Climate models play a critical role in understanding and projecting climatechange. Due to their complexity, their horizontal resolution of about 40-100 kmremains too coarse to resolve processes such as clouds and convection, whichneed to be approximated via parameterizations. These parameterizations are amajor source of systematic errors and large uncertainties in climateprojections. Deep learning (DL)-based parameterizations, trained on data fromcomputationally expensive short, high-resolution simulations, have shown greatpromise for improving climate models in that regard. However, their lack ofinterpretability and tendency to learn spurious non-physical correlationsresult in reduced trust in the climate simulation. We propose an efficientsupervised learning framework for DL-based parameterizations that leads tophysically consistent models with improved interpretability and negligiblecomputational overhead compared to standard supervised training. First, keyfeatures determining the target physical processes are uncovered. Subsequently,the neural network is fine-tuned using only those relevant features. We showempirically that our method robustly identifies a small subset of the inputs asactual physical drivers, therefore, removing spurious non-physicalrelationships. This results in by design physically consistent andinterpretable neural networks while maintaining the predictive performance ofunconstrained black-box DL-based parameterizations.</description><author>Birgit Kühbacher, Fernando Iglesias-Suarez, Niki Kilbertus, Veronika Eyring</author><pubDate>Thu, 01 Aug 2024 07:29:42 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.03920v2</guid></item><item><title>Modelling Assessment Rubrics through Bayesian Networks: a Pragmatic Approach</title><link>http://arxiv.org/abs/2209.05467v2</link><description>Automatic assessment of learner competencies is a fundamental task inintelligent tutoring systems. An assessment rubric typically and effectivelydescribes relevant competencies and competence levels. This paper presents anapproach to deriving a learner model directly from an assessment rubricdefining some (partial) ordering of competence levels. The model is based onBayesian networks and exploits logical gates with uncertainty (often referredto as noisy gates) to reduce the number of parameters of the model, so tosimplify their elicitation by experts and allow real-time inference inintelligent tutoring systems. We illustrate how the approach can be applied toautomatize the human assessment of an activity developed for testingcomputational thinking skills. The simple elicitation of the model startingfrom the assessment rubric opens up the possibility of quickly automating theassessment of several tasks, making them more easily exploitable in the contextof adaptive assessment tools and intelligent tutoring systems.</description><author>Francesca Mangili, Giorgia Adorni, Alberto Piatti, Claudio Bonesana, Alessandro Antonucci</author><pubDate>Thu, 01 Aug 2024 07:12:14 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2209.05467v2</guid></item><item><title>T-Mamba: A unified framework with Long-Range Dependency in dual-domain for 2D &amp; 3D Tooth Segmentation</title><link>http://arxiv.org/abs/2404.01065v2</link><description>Tooth segmentation is a pivotal step in modern digital dentistry, essentialfor applications across orthodontic diagnosis and treatment planning. Despiteits importance, this process is fraught with challenges due to the high noiseand low contrast inherent in 2D and 3D tooth data. Both Convolutional NeuralNetworks (CNNs) and Transformers has shown promise in medical imagesegmentation, yet each method has limitations in handling long-rangedependencies and computational complexity. To address this issue, this paperintroduces T-Mamba, integrating frequency-based features and sharedbi-positional encoding into vision mamba to address limitations in efficientglobal feature modeling. Besides, we design a gate selection unit to integratetwo features in spatial domain and one feature in frequency domain adaptively.T-Mamba is the first work to introduce frequency-based features into visionmamba, and its flexibility allows it to process both 2D and 3D tooth datawithout the need for separate modules. Also, the TED3, a large-scale publictooth 2D dental X-ray dataset, has been presented in this paper. Extensiveexperiments demonstrate that T-Mamba achieves new SOTA results on a publictooth CBCT dataset and outperforms previous SOTA methods on TED3 dataset. Thecode and models are publicly available at: https://github.com/isbrycee/T-Mamba.</description><author>Jing Hao, Yonghui Zhu, Lei He, Moyun Liu, James Kit Hon Tsoi, Kuo Feng Hung</author><pubDate>Thu, 01 Aug 2024 07:01:49 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.01065v2</guid></item><item><title>Pistis-RAG: A Scalable Cascading Framework Towards Trustworthy Retrieval-Augmented Generation</title><link>http://arxiv.org/abs/2407.00072v4</link><description>In Greek mythology, Pistis symbolized good faith, trust, and reliability.Drawing inspiration from these principles, Pistis-RAG is a scalable multi-stageframework designed to address the challenges of large-scale retrieval-augmentedgeneration (RAG) systems. This framework consists of distinct stages: matching,pre-ranking, ranking, reasoning, and aggregating. Each stage contributes tonarrowing the search space, prioritizing semantically relevant documents,aligning with the large language model's (LLM) preferences, supporting complexchain-of-thought (CoT) methods, and combining information from multiplesources. Our ranking stage introduces a significant innovation by recognizing thatsemantic relevance alone may not lead to improved generation quality, due tothe sensitivity of the few-shot prompt order, as noted in previous research.This critical aspect is often overlooked in current RAG frameworks. We argue that the alignment issue between LLMs and external knowledge rankingmethods is tied to the model-centric paradigm dominant in RAG systems. Wepropose a content-centric approach, emphasizing seamless integration betweenLLMs and external information sources to optimize content transformation forspecific tasks. Our novel ranking stage is designed specifically for RAG systems,incorporating principles of information retrieval while considering the uniquebusiness scenarios reflected in LLM preferences and user feedback. We simulatedfeedback signals on the MMLU benchmark, resulting in a 9.3% performanceimprovement. Our model and code will be open-sourced on GitHub. Additionally,experiments on real-world, large-scale data validate the scalability of ourframework.</description><author>Yu Bai, Yukai Miao, Li Chen, Dan Li, Yanyu Ren, Hongtao Xie, Ce Yang, Xuhui Cai</author><pubDate>Thu, 01 Aug 2024 06:56:15 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.00072v4</guid></item><item><title>Open-Set Video-based Facial Expression Recognition with Human Expression-sensitive Prompting</title><link>http://arxiv.org/abs/2404.17100v2</link><description>In Video-based Facial Expression Recognition (V-FER), models are typicallytrained on closed-set datasets with a fixed number of known classes. However,these models struggle with unknown classes common in real-world scenarios. Inthis paper, we introduce a challenging Open-set Video-based Facial ExpressionRecognition (OV-FER) task, aiming to identify both known and new, unseen facialexpressions. While existing approaches use large-scale vision-language modelslike CLIP to identify unseen classes, we argue that these methods may notadequately capture the subtle human expressions needed for OV-FER. To addressthis limitation, we propose a novel Human Expression-Sensitive Prompting (HESP)mechanism to significantly enhance CLIP's ability to model video-based facialexpression details effectively. Our proposed HESP comprises three components:1) a textual prompting module with learnable prompts to enhance CLIP's textualrepresentation of both known and unknown emotions, 2) a visual prompting modulethat encodes temporal emotional information from video frames usingexpression-sensitive attention, equipping CLIP with a new visual modelingability to extract emotion-rich information, and 3) an open-set multi-tasklearning scheme that promotes interaction between the textual and visualmodules, improving the understanding of novel human emotions in videosequences. Extensive experiments conducted on four OV-FER task settingsdemonstrate that HESP can significantly boost CLIP's performance (a relativeimprovement of 17.93% on AUROC and 106.18% on OSCR) and outperform otherstate-of-the-art open-set video understanding methods by a large margin. Codeis available at https://github.com/cosinehuang/HESP.</description><author>Yuanyuan Liu, Yuxuan Huang, Shuyang Liu, Yibing Zhan, Zijing Chen, Zhe Chen</author><pubDate>Thu, 01 Aug 2024 06:46:04 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.17100v2</guid></item><item><title>LLMs as Hackers: Autonomous Linux Privilege Escalation Attacks</title><link>http://arxiv.org/abs/2310.11409v4</link><description>Penetration testing, an essential component of software security testing,allows organizations to identify and remediate vulnerabilities in theirsystems, thus bolstering their defense mechanisms against cyberattacks. Onerecent advancement in the realm of penetration testing is the utilization ofLanguage Models (LLMs). We explore the intersection of LLMs and penetrationtesting to gain insight into their capabilities and challenges in the contextof privilege escalation. We introduce a fully automated privilege-escalationtool designed for evaluating the efficacy of LLMs for (ethical) hacking,executing benchmarks using multiple LLMs, and investigating their respectiveresults. Our results show that GPT-4-turbo is well suited to exploit vulnerabilities(33-83% of vulnerabilities). GPT-3.5-turbo can abuse 16-50% of vulnerabilities,while local models, such as Llama3, can only exploit between 0 and 33% of thevulnerabilities. We analyze the impact of different context sizes, in-context learning,optional high-level guidance mechanisms, and memory management techniques. Wediscuss challenging areas for LLMs, including maintaining focus during testing,coping with errors, and finally comparing LLMs with human hackers. The current version of the LLM-guided privilege-escalation prototype can befound at https://github.com/ipa-labs/hackingBuddyGPT.</description><author>Andreas Happe, Aaron Kaplan, Juergen Cito</author><pubDate>Thu, 01 Aug 2024 06:42:27 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.11409v4</guid></item><item><title>Narrowing the Knowledge Evaluation Gap: Open-Domain Question Answering with Multi-Granularity Answers</title><link>http://arxiv.org/abs/2401.04695v2</link><description>Factual questions typically can be answered correctly at different levels ofgranularity. For example, both ``August 4, 1961'' and ``1961'' are correctanswers to the question ``When was Barack Obama born?''. Standard questionanswering (QA) evaluation protocols, however, do not explicitly take this intoaccount and compare a predicted answer against answers of a single granularitylevel. In this work, we propose GRANOLA QA, a novel evaluation setting where apredicted answer is evaluated in terms of accuracy and informativeness againsta set of multi-granularity answers. We present a simple methodology forenriching existing datasets with multi-granularity answers, and createGRANOLA-EQ, a multi-granularity version of the EntityQuestions dataset. Weevaluate a range of decoding methods on GRANOLA-EQ, including a new algorithm,called Decoding with Response Aggregation (DRAG), that is geared towardsaligning the response granularity with the model's uncertainty. Our experimentsshow that large language models with standard decoding tend to generatespecific answers, which are often incorrect. In contrast, when evaluated onmulti-granularity answers, DRAG yields a nearly 20 point increase in accuracyon average, which further increases for rare entities. Overall, this revealsthat standard evaluation and decoding schemes may significantly underestimatethe knowledge encapsulated in LMs.</description><author>Gal Yona, Roee Aharoni, Mor Geva</author><pubDate>Thu, 01 Aug 2024 06:23:58 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.04695v2</guid></item><item><title>KRF: Keypoint Refinement with Fusion Network for 6D Pose Estimation</title><link>http://arxiv.org/abs/2210.03437v2</link><description>Some robust point cloud registration approaches with controllable poserefinement magnitude, such as ICP and its variants, are commonly used toimprove 6D pose estimation accuracy. However, the effectiveness of thesemethods gradually diminishes with the advancement of deep learning techniquesand the enhancement of initial pose accuracy, primarily due to their lack ofspecific design for pose refinement. In this paper, we propose Point CloudCompletion and Keypoint Refinement with Fusion Data (PCKRF), a new poserefinement pipeline for 6D pose estimation. The pipeline consists of two steps.First, it completes the input point clouds via a novel pose-sensitive pointcompletion network. The network uses both local and global features with poseinformation during point completion. Then, it registers the completed objectpoint cloud with the corresponding target point cloud by our proposed Colorsupported Iterative KeyPoint (CIKP) method. The CIKP method introduces colorinformation into registration and registers a point cloud around each keypointto increase stability. The PCKRF pipeline can be integrated with existingpopular 6D pose estimation methods, such as the full flow bidirectional fusionnetwork, to further improve their pose estimation accuracy. Experimentsdemonstrate that our method exhibits superior stability compared to existingapproaches when optimizing initial poses with relatively high precision.Notably, the results indicate that our method effectively complements mostexisting pose estimation techniques, leading to improved performance in mostcases. Furthermore, our method achieves promising results even in challengingscenarios involving textureless and symmetrical objects. Our source code isavailable at https://github.com/zhanhz/KRF.</description><author>Yiheng Han, Irvin Haozhe Zhan, Long Zeng, Yu-Ping Wang, Ran Yi, Minjing Yu, Matthieu Gaetan Lin, Jenny Sheng, Yong-Jin Liu</author><pubDate>Thu, 01 Aug 2024 06:02:27 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2210.03437v2</guid></item><item><title>Inducing Generalization across Languages and Tasks using Featurized Low-Rank Mixtures</title><link>http://arxiv.org/abs/2402.17934v2</link><description>Adapting pretrained large language models (LLMs) to various downstream tasksin tens or hundreds of human languages is computationally expensive.Parameter-efficient fine-tuning (PEFT) significantly reduces the adaptationcost, by tuning only a small amount of parameters. However, common PEFT methodsLoRA (Hu et al., 2022) suffer from suboptimal performance on diverse datasetmixtures, due to aggressive parameter tying and negative interference amongdifferent datasets. In this work, we propose Featurized Low-rank Mixtures(FLix), a novel PEFT method designed for effective multitask multilingualadaptation. FLix associates each unique dataset feature, such as the dataset'slanguage or task, with its own low-rank weight update parameters. By composingfeature-specific parameters for each dataset, FLix can accommodate diversedataset mixtures and generalize better to unseen datasets. Our experiments showthat FLix leads to significant improvements over a variety of tasks for bothsupervised learning and zero-shot settings with gains of up to $14.2$ inexactmatch points in zero-shot semantic parsing.</description><author>Chu-Cheng Lin, Xinyi Wang, Jonathan H. Clark, Han Lu, Yun Zhu, Chenxi Whitehouse, Hongkun Yu</author><pubDate>Thu, 01 Aug 2024 05:52:51 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.17934v2</guid></item></channel></rss>