<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/"><channel><title>Arxivfresh papers</title><link></link><description>Arxiv paper</description><language>en-US</language><lastBuildDate>Tue, 21 Jan 2025 01:00:04 GMT</lastBuildDate><generator>rfeed v1.0.0</generator><docs>https://github.com/svpino/rfeed/blob/master/README.md</docs><item><title>FaceXBench: Evaluating Multimodal LLMs on Face Understanding</title><link>http://arxiv.org/abs/2501.10360v1</link><description>Multimodal Large Language Models (MLLMs) demonstrate impressiveproblem-solving abilities across a wide range of tasks and domains. However,their capacity for face understanding has not been systematically studied. Toaddress this gap, we introduce FaceXBench, a comprehensive benchmark designedto evaluate MLLMs on complex face understanding tasks. FaceXBench includes5,000 multimodal multiple-choice questions derived from 25 public datasets anda newly created dataset, FaceXAPI. These questions cover 14 tasks across 6broad categories, assessing MLLMs' face understanding abilities in bias andfairness, face authentication, recognition, analysis, localization and toolretrieval. Using FaceXBench, we conduct an extensive evaluation of 26open-source MLLMs alongside 2 proprietary models, revealing the uniquechallenges in complex face understanding tasks. We analyze the models acrossthree evaluation settings: zero-shot, in-context task description, andchain-of-thought prompting. Our detailed analysis reveals that current MLLMs,including advanced models like GPT-4o, and GeminiPro 1.5, show significant roomfor improvement. We believe FaceXBench will be a crucial resource fordeveloping MLLMs equipped to perform sophisticated face understanding. Code:https://github.com/Kartik-3004/facexbench</description><author>Kartik Narayan, Vibashan VS, Vishal M. Patel</author><pubDate>Fri, 17 Jan 2025 18:59:55 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.10360v1</guid></item><item><title>Zero-Shot Monocular Scene Flow Estimation in the Wild</title><link>http://arxiv.org/abs/2501.10357v1</link><description>Large models have shown generalization across datasets for many low-levelvision tasks, like depth estimation, but no such general models exist for sceneflow. Even though scene flow has wide potential use, it is not used in practicebecause current predictive models do not generalize well. We identify three keychallenges and propose solutions for each.First, we create a method thatjointly estimates geometry and motion for accurate prediction. Second, wealleviate scene flow data scarcity with a data recipe that affords us 1Mannotated training samples across diverse synthetic scenes. Third, we evaluatedifferent parameterizations for scene flow prediction and adopt a natural andeffective parameterization. Our resulting model outperforms existing methods aswell as baselines built on large-scale models in terms of 3D end-point error,and shows zero-shot generalization to the casually captured videos from DAVISand the robotic manipulation scenes from RoboTAP. Overall, our approach makesscene flow prediction more practical in-the-wild.</description><author>Yiqing Liang, Abhishek Badki, Hang Su, James Tompkin, Orazio Gallo</author><pubDate>Fri, 17 Jan 2025 18:57:57 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.10357v1</guid></item><item><title>A Fairness-Oriented Reinforcement Learning Approach for the Operation and Control of Shared Micromobility Services</title><link>http://arxiv.org/abs/2403.15780v3</link><description>As Machine Learning grows in popularity across various fields, equity hasbecome a key focus for the AI community. However, fairness-oriented approachesare still underexplored in smart mobility. Addressing this gap, our studyinvestigates the balance between performance optimization and algorithmicfairness in shared micromobility services providing a novel framework based onReinforcement Learning. Exploiting Q-learning, the proposed methodologyachieves equitable outcomes in terms of the Gini index across different areascharacterized by their distance from central hubs. Through vehicle rebalancing,the provided scheme maximizes operator performance while ensuring fairnessprinciples for users, reducing iniquity by up to 85% while only increasingcosts by 30% (w.r.t. applying no equity adjustment). A case study withsynthetic data validates our insights and highlights the importance of fairnessin urban micromobility (source code:https://github.com/mcederle99/FairMSS.git).</description><author>Matteo Cederle, Luca Vittorio Piron, Marina Ceccon, Federico Chiariotti, Alessandro Fabris, Marco Fabris, Gian Antonio Susto</author><pubDate>Fri, 17 Jan 2025 18:42:52 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.15780v3</guid></item><item><title>Credit Risk Identification in Supply Chains Using Generative Adversarial Networks</title><link>http://arxiv.org/abs/2501.10348v1</link><description>Credit risk management within supply chains has emerged as a criticalresearch area due to its significant implications for operational stability andfinancial sustainability. The intricate interdependencies among supply chainparticipants mean that credit risks can propagate across networks, with impactsvarying by industry. This study explores the application of GenerativeAdversarial Networks (GANs) to enhance credit risk identification in supplychains. GANs enable the generation of synthetic credit risk scenarios,addressing challenges related to data scarcity and imbalanced datasets. Byleveraging GAN-generated data, the model improves predictive accuracy whileeffectively capturing dynamic and temporal dependencies in supply chain data.The research focuses on three representative industries-manufacturing (steel),distribution (pharmaceuticals), and services (e-commerce) to assessindustry-specific credit risk contagion. Experimental results demonstrate thatthe GAN-based model outperforms traditional methods, including logisticregression, decision trees, and neural networks, achieving superior accuracy,recall, and F1 scores. The findings underscore the potential of GANs inproactive risk management, offering robust tools for mitigating financialdisruptions in supply chains. Future research could expand the model byincorporating external market factors and supplier relationships to furtherenhance predictive capabilities. Keywords- Generative Adversarial Networks(GANs); Supply Chain Risk; Credit Risk Identification; Machine Learning; DataAugmentation</description><author>Zizhou Zhang, Xinshi Li, Yu Cheng, Zhenrui Chen, Qianying Liu</author><pubDate>Fri, 17 Jan 2025 18:42:46 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.10348v1</guid></item><item><title>ColNet: Collaborative Optimization in Decentralized Federated Multi-task Learning Systems</title><link>http://arxiv.org/abs/2501.10347v1</link><description>The integration of Federated Learning (FL) and Multi-Task Learning (MTL) hasbeen explored to address client heterogeneity, with Federated Multi-TaskLearning (FMTL) treating each client as a distinct task. However, most existingresearch focuses on data heterogeneity (e.g., addressing non-IID data) ratherthan task heterogeneity, where clients solve fundamentally different tasks.Additionally, much of the work relies on centralized settings with a servermanaging the federation, leaving the more challenging domain of decentralizedFMTL largely unexplored. Thus, this work bridges this gap by proposing ColNet,a framework designed for heterogeneous tasks in decentralized federatedenvironments. ColNet divides models into the backbone and task-specific layers,forming groups of similar clients, with group leaders performingconflict-averse cross-group aggregation. A pool of experiments with differentfederations demonstrated ColNet outperforms the compared aggregation schemes indecentralized settings with label and task heterogeneity scenarios.</description><author>Chao Feng, Nicolas Fazli Kohler, Alberto Huertas Celdran, Gerome Bovet, Burkhard Stiller</author><pubDate>Fri, 17 Jan 2025 18:40:38 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.10347v1</guid></item><item><title>3rd Workshop on Maritime Computer Vision (MaCVi) 2025: Challenge Results</title><link>http://arxiv.org/abs/2501.10343v1</link><description>The 3rd Workshop on Maritime Computer Vision (MaCVi) 2025 addresses maritimecomputer vision for Unmanned Surface Vehicles (USV) and underwater. This reportoffers a comprehensive overview of the findings from the challenges. We provideboth statistical and qualitative analyses, evaluating trends from over 700submissions. All datasets, evaluation code, and the leaderboard are availableto the public at https://macvi.org/workshop/macvi25.</description><author>Benjamin Kiefer, Lojze Žust, Jon Muhovič, Matej Kristan, Janez Perš, Matija Teršek, Uma Mudenagudi Chaitra Desai, Arnold Wiliem, Marten Kreis, Nikhil Akalwadi, Yitong Quan, Zhiqiang Zhong, Zhe Zhang, Sujie Liu, Xuran Chen, Yang Yang, Matej Fabijanić, Fausto Ferreira, Seongju Lee, Junseok Lee, Kyoobin Lee, Shanliang Yao, Runwei Guan, Xiaoyu Huang, Yi Ni, Himanshu Kumar, Yuan Feng, Yi-Ching Cheng, Tzu-Yu Lin, Chia-Ming Lee, Chih-Chung Hsu, Jannik Sheikh, Andreas Michel, Wolfgang Gross, Martin Weinmann, Josip Šarić, Yipeng Lin, Xiang Yang, Nan Jiang, Yutang Lu, Fei Feng, Ali Awad, Evan Lucas, Ashraf Saleem, Ching-Heng Cheng, Yu-Fan Lin, Tzu-Yu Lin, Chih-Chung Hsu</author><pubDate>Fri, 17 Jan 2025 18:34:47 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.10343v1</guid></item><item><title>Hybrid Deep Learning Model for epileptic seizure classification by using 1D-CNN with multi-head attention mechanism</title><link>http://arxiv.org/abs/2501.10342v1</link><description>Epilepsy is a prevalent neurological disorder globally, impacting around 50million people \cite{WHO_epilepsy_50million}. Epileptic seizures result fromsudden abnormal electrical activity in the brain, which can be read as suddenand significant changes in the EEG signal of the brain. The signal can vary inseverity and frequency, which results in loss of consciousness and musclecontractions for a short period of time \cite{epilepsyfoundation_myoclonic}.Individuals with epilepsy often face significant employment challenges due tosafety concerns in certain work environments. Many jobs that involve working atheights, operating heavy machinery, or in other potentially hazardous settingsmay be restricted for people with seizure disorders. This certainly limits joboptions and economic opportunities for those living with epilepsy.</description><author>Mohammed Guhdar, Ramadhan J. Mstafa, Abdulhakeem O. Mohammed</author><pubDate>Fri, 17 Jan 2025 18:33:58 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.10342v1</guid></item><item><title>On Learning Informative Trajectory Embeddings for Imitation, Classification and Regression</title><link>http://arxiv.org/abs/2501.09327v2</link><description>In real-world sequential decision making tasks like autonomous driving,robotics, and healthcare, learning from observed state-action trajectories iscritical for tasks like imitation, classification, and clustering. For example,self-driving cars must replicate human driving behaviors, while robots andhealthcare systems benefit from modeling decision sequences, whether or notthey come from expert data. Existing trajectory encoding methods often focus onspecific tasks or rely on reward signals, limiting their ability to generalizeacross domains and tasks. Inspired by the success of embedding models like CLIPand BERT in static domains, we propose a novel method for embeddingstate-action trajectories into a latent space that captures the skills andcompetencies in the dynamic underlying decision-making processes. This methodoperates without the need for reward labels, enabling better generalizationacross diverse domains and tasks. Our contributions are threefold: (1) Weintroduce a trajectory embedding approach that captures multiple abilities fromstate-action data. (2) The learned embeddings exhibit strong representationalpower across downstream tasks, including imitation, classification, clustering,and regression. (3) The embeddings demonstrate unique properties, such ascontrolling agent behaviors in IQ-Learn and an additive structure in the latentspace. Experimental results confirm that our method outperforms traditionalapproaches, offering more flexible and powerful trajectory representations forvarious applications. Our code is available athttps://github.com/Erasmo1015/vte.</description><author>Zichang Ge, Changyu Chen, Arunesh Sinha, Pradeep Varakantham</author><pubDate>Fri, 17 Jan 2025 18:30:04 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.09327v2</guid></item><item><title>Principled model selection for stochastic dynamics</title><link>http://arxiv.org/abs/2501.10339v1</link><description>Complex dynamical systems, from macromolecules to ecosystems, are oftenmodeled by stochastic differential equations (SDEs). To learn such models fromdata, a common approach involves decomposing the SDE into a linear combinationof basis functions. However, this can induce overfitting due to theproliferation of parameters. To address this, we introduce ParsimoniousStochastic Inference (PASTIS), a principled method that removes superfluousparameters from SDE models by combining likelihood-estimation statistics withextreme value theory. We benchmark it against existing methods and show that itreliably selects the exact minimal models from large libraries of functions,even with a low sampling rate or measurement error. We show that it extends tostochastic partial differential equations and demonstrate applications to theinference of ecological networks and reaction-diffusion dynamics.</description><author>Andonis Gerardos, Pierre Ronceray</author><pubDate>Fri, 17 Jan 2025 18:23:16 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.10339v1</guid></item><item><title>MVTamperBench: Evaluating Robustness of Vision-Language Models</title><link>http://arxiv.org/abs/2412.19794v4</link><description>Multimodal Large Language Models (MLLMs) have driven major advances in videounderstanding, yet their vulnerability to adversarial tampering andmanipulations remains underexplored. To address this gap, we introduceMVTamperBench, a benchmark that systematically evaluates MLLM robustnessagainst five prevalent tampering techniques: rotation, masking, substitution,repetition, and dropping. Built from 3.4K original videos-expanded to over 17Ktampered clips spanning 19 video tasks. MVTamperBench challenges models to detect manipulations in spatial andtemporal coherence. We evaluate 45 recent MLLMs from 15+ model families,revealing substantial variability in resilience across tampering types andshowing that larger parameter counts do not necessarily guarantee robustness.MVTamperBench sets a new benchmark for developing tamper-resilient MLLM insafety-critical applications, including detecting clickbait, preventing harmfulcontent distribution, and enforcing policies on media platforms. We release allcode and data to foster open research in trustworthy video understanding. Code: https://amitbcp.github.io/MVTamperBench/ Data:https://huggingface.co/datasets/Srikant86/MVTamperBench</description><author>Amit Agarwal, Srikant Panda, Angeline Charles, Bhargava Kumar, Hitesh Patel, Priyaranjan Pattnayak, Taki Hasan Rafi, Tejaswini Kumar, Dong-Kyu Chae</author><pubDate>Fri, 17 Jan 2025 18:18:21 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.19794v4</guid></item><item><title>Stochastic gradient descent for streaming linear and rectified linear systems with adversarial corruptions</title><link>http://arxiv.org/abs/2403.01204v2</link><description>We propose SGD-exp, a stochastic gradient descent approach for linear andReLU regressions under Massart noise (adversarial semi-random corruption model)for the fully streaming setting. We show novel nearly linear convergenceguarantees of SGD-exp to the true parameter with up to $50\%$ Massartcorruption rate, and with any corruption rate in the case of symmetricoblivious corruptions. This is the first convergence guarantee result forrobust ReLU regression in the streaming setting, and it shows the improvedconvergence rate over previous robust methods for $L_1$ linear regression dueto a choice of an exponentially decaying step size, known for its efficiency inpractice. Our analysis is based on the drift analysis of a discrete stochasticprocess, which could also be interesting on its own.</description><author>Halyun Jeong, Deanna Needell, Elizaveta Rebrova</author><pubDate>Fri, 17 Jan 2025 18:15:40 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.01204v2</guid></item><item><title>Agent4Edu: Generating Learner Response Data by Generative Agents for Intelligent Education Systems</title><link>http://arxiv.org/abs/2501.10332v1</link><description>Personalized learning represents a promising educational strategy withinintelligent educational systems, aiming to enhance learners' practiceefficiency. However, the discrepancy between offline metrics and onlineperformance significantly impedes their progress. To address this challenge, weintroduce Agent4Edu, a novel personalized learning simulator leveraging recentadvancements in human intelligence through large language models (LLMs).Agent4Edu features LLM-powered generative agents equipped with learner profile,memory, and action modules tailored to personalized learning algorithms. Thelearner profiles are initialized using real-world response data, capturingpractice styles and cognitive factors. Inspired by human psychology theory, thememory module records practice facts and high-level summaries, integratingreflection mechanisms. The action module supports various behaviors, includingexercise understanding, analysis, and response generation. Each agent caninteract with personalized learning algorithms, such as computerized adaptivetesting, enabling a multifaceted evaluation and enhancement of customizedservices. Through a comprehensive assessment, we explore the strengths andweaknesses of Agent4Edu, emphasizing the consistency and discrepancies inresponses between agents and human learners. The code, data, and appendix arepublicly available at https://github.com/bigdata-ustc/Agent4Edu.</description><author>Weibo Gao, Qi Liu, Linan Yue, Fangzhou Yao, Rui Lv, Zheng Zhang, Hao Wang, Zhenya Huang</author><pubDate>Fri, 17 Jan 2025 18:05:04 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.10332v1</guid></item><item><title>BoK: Introducing Bag-of-Keywords Loss for Interpretable Dialogue Response Generation</title><link>http://arxiv.org/abs/2501.10328v1</link><description>The standard language modeling (LM) loss by itself has been shown to beinadequate for effective dialogue modeling. As a result, various trainingapproaches, such as auxiliary loss functions and leveraging human feedback, arebeing adopted to enrich open-domain dialogue systems. One such auxiliary lossfunction is Bag-of-Words (BoW) loss, defined as the cross-entropy loss forpredicting all the words/tokens of the next utterance. In this work, we proposea novel auxiliary loss named Bag-of-Keywords (BoK) loss to capture the centralthought of the response through keyword prediction and leverage it to enhancethe generation of meaningful and interpretable responses in open-domaindialogue systems. BoK loss upgrades the BoW loss by predicting only thekeywords or critical words/tokens of the next utterance, intending to estimatethe core idea rather than the entire response. We incorporate BoK loss in bothencoder-decoder (T5) and decoder-only (DialoGPT) architecture and train themodels to minimize the weighted sum of BoK and LM (BoK-LM) loss. We perform ourexperiments on two popular open-domain dialogue datasets, DailyDialog andPersona-Chat. We show that the inclusion of BoK loss improves the dialoguegeneration of backbone models while also enabling post-hoc interpretability. Wealso study the effectiveness of BoK-LM loss as a reference-free metric andobserve comparable performance to the state-of-the-art metrics on variousdialogue evaluation datasets.</description><author>Suvodip Dey, Maunendra Sankar Desarkar</author><pubDate>Fri, 17 Jan 2025 17:57:49 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.10328v1</guid></item><item><title>Large language models for automated scholarly paper review: A survey</title><link>http://arxiv.org/abs/2501.10326v1</link><description>Large language models (LLMs) have significantly impacted human society,influencing various domains. Among them, academia is not simply a domainaffected by LLMs, but it is also the pivotal force in the development of LLMs.In academic publications, this phenomenon is represented during theincorporation of LLMs into the peer review mechanism for reviewing manuscripts.We proposed the concept of automated scholarly paper review (ASPR) in ourprevious paper. As the incorporation grows, it now enters the coexistence phaseof ASPR and peer review, which is described in that paper. LLMs holdtransformative potential for the full-scale implementation of ASPR, but theyalso pose new issues and challenges that need to be addressed. In this surveypaper, we aim to provide a holistic view of ASPR in the era of LLMs. We beginwith a survey to find out which LLMs are used to conduct ASPR. Then, we reviewwhat ASPR-related technological bottlenecks have been solved with theincorporation of LLM technology. After that, we move on to explore new methods,new datasets, new source code, and new online systems that come with LLMs forASPR. Furthermore, we summarize the performance and issues of LLMs in ASPR, andinvestigate the attitudes and reactions of publishers and academia to ASPR.Lastly, we discuss the challenges associated with the development of LLMs forASPR. We hope this survey can serve as an inspirational reference for theresearchers and promote the progress of ASPR for its actual implementation.</description><author>Zhenzhen Zhuang, Jiandong Chen, Hongfeng Xu, Yuwen Jiang, Jialiang Lin</author><pubDate>Fri, 17 Jan 2025 17:56:58 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.10326v1</guid></item><item><title>DiffStereo: High-Frequency Aware Diffusion Model for Stereo Image Restoration</title><link>http://arxiv.org/abs/2501.10325v1</link><description>Diffusion models (DMs) have achieved promising performance in imagerestoration but haven't been explored for stereo images. The application of DMin stereo image restoration is confronted with a series of challenges. The needto reconstruct two images exacerbates DM's computational cost. Additionally,existing latent DMs usually focus on semantic information and removehigh-frequency details as redundancy during latent compression, which isprecisely what matters for image restoration. To address the above problems, wepropose a high-frequency aware diffusion model, DiffStereo for stereo imagerestoration as the first attempt at DM in this domain. Specifically, DiffStereofirst learns latent high-frequency representations (LHFR) of HQ images. DM isthen trained in the learned space to estimate LHFR for stereo images, which arefused into a transformer-based stereo image restoration network providingbeneficial high-frequency information of corresponding HQ images. Theresolution of LHFR is kept the same as input images, which preserves theinherent texture from distortion. And the compression in channels alleviatesthe computational burden of DM. Furthermore, we devise a position encodingscheme when integrating the LHFR into the restoration network, enablingdistinctive guidance in different depths of the restoration network.Comprehensive experiments verify that by combining generative DM andtransformer, DiffStereo achieves both higher reconstruction accuracy and betterperceptual quality on stereo super-resolution, deblurring, and low-lightenhancement compared with state-of-the-art methods.</description><author>Huiyun Cao, Yuan Shi, Bin Xia, Xiaoyu Jin, Wenming Yang</author><pubDate>Fri, 17 Jan 2025 17:56:52 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.10325v1</guid></item><item><title>New Fashion Products Performance Forecasting: A Survey on Evolutions, Models and Emerging Trends</title><link>http://arxiv.org/abs/2501.10324v1</link><description>The fast fashion industry's insatiable demand for new styles and rapidproduction cycles has led to a significant environmental burden.Overproduction, excessive waste, and harmful chemicals have contributed to thenegative environmental impact of the industry. To mitigate these issues, aparadigm shift that prioritizes sustainability and efficiency is urgentlyneeded. Integrating learning-based predictive analytics into the fashionindustry represents a significant opportunity to address environmentalchallenges and drive sustainable practices. By forecasting fashion trends andoptimizing production, brands can reduce their ecological footprint whileremaining competitive in a rapidly changing market. However, one of the keychallenges in forecasting fashion sales is the dynamic nature of consumerpreferences. Fashion is acyclical, with trends constantly evolving andresurfacing. In addition, cultural changes and unexpected events can disruptestablished patterns. This problem is also known as New Fashion ProductsPerformance Forecasting (NFPPF), and it has recently gained more and moreinterest in the global research landscape. Given its multidisciplinary nature,the field of NFPPF has been approached from many different angles. Thiscomprehensive survey wishes to provide an up-to-date overview that focuses onlearning-based NFPPF strategies. The survey is based on the Preferred ReportingItems for Systematic Reviews and Meta-Analyses (PRISMA) methodological flow,allowing for a systematic and complete literature review. In particular, wepropose the first taxonomy that covers the learning panorama for NFPPF,examining in detail the different methodologies used to increase the amount ofmultimodal information, as well as the state-of-the-art available datasets.Finally, we discuss the challenges and future directions.</description><author>Andrea Avogaro, Luigi Capogrosso, Andrea Toaiari, Franco Fummi, Marco Cristani</author><pubDate>Fri, 17 Jan 2025 17:56:27 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.10324v1</guid></item><item><title>Joint Automatic Speech Recognition And Structure Learning For Better Speech Understanding</title><link>http://arxiv.org/abs/2501.07329v2</link><description>Spoken language understanding (SLU) is a structure prediction task in thefield of speech. Recently, many works on SLU that treat it as asequence-to-sequence task have achieved great success. However, This method isnot suitable for simultaneous speech recognition and understanding. In thispaper, we propose a joint speech recognition and structure learning framework(JSRSL), an end-to-end SLU model based on span, which can accurately transcribespeech and extract structured content simultaneously. We conduct experiments onname entity recognition and intent classification using the Chinese datasetAISHELL-NER and the English dataset SLURP. The results show that our proposedmethod not only outperforms the traditional sequence-to-sequence method in bothtranscription and extraction capabilities but also achieves state-of-the-artperformance on the two datasets.</description><author>Jiliang Hu, Zuchao Li, Mengjia Shen, Haojun Ai, Sheng Li, Jun Zhang</author><pubDate>Fri, 17 Jan 2025 17:53:27 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.07329v2</guid></item><item><title>Hierarchical Autoregressive Transformers: Combining Byte-~and Word-Level Processing for Robust, Adaptable Language Models</title><link>http://arxiv.org/abs/2501.10322v1</link><description>Tokenization is a fundamental step in natural language processing, breakingtext into units that computational models can process. While learned subwordtokenizers have become the de-facto standard, they present challenges such aslarge vocabularies, limited adaptability to new domains or languages, andsensitivity to spelling errors and variations. To overcome these limitations,we investigate a hierarchical architecture for autoregressive languagemodelling that combines character-level and word-level processing. It employs alightweight character-level encoder to convert character sequences into wordembeddings, which are then processed by a word-level backbone model and decodedback into characters via a compact character-level decoder. This method retainsthe sequence compression benefits of word-level tokenization without relying ona rigid, predefined vocabulary. We demonstrate, at scales up to 7 billionparameters, that hierarchical transformers match the downstream taskperformance of subword-tokenizer-based models while exhibiting significantlygreater robustness to input perturbations. Additionally, during continuedpretraining on an out-of-domain language, our model trains almost twice asfast, achieves superior performance on the target language, and retains more ofits previously learned knowledge. Hierarchical transformers pave the way forNLP systems that are more robust, flexible, and generalizable across languagesand domains.</description><author>Pit Neitemeier, Björn Deiseroth, Constantin Eichenberg, Lukas Balles</author><pubDate>Fri, 17 Jan 2025 17:51:53 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.10322v1</guid></item><item><title>Towards Human-Guided, Data-Centric LLM Co-Pilots</title><link>http://arxiv.org/abs/2501.10321v1</link><description>Machine learning (ML) has the potential to revolutionize healthcare, but itsadoption is often hindered by the disconnect between the needs of domainexperts and translating these needs into robust and valid ML tools. Despiterecent advances in LLM-based co-pilots to democratize ML for non-technicaldomain experts, these systems remain predominantly focused on model-centricaspects while overlooking critical data-centric challenges. This limitation isproblematic in complex real-world settings where raw data often containscomplex issues, such as missing values, label noise, and domain-specificnuances requiring tailored handling. To address this we introduce CliMB-DC, ahuman-guided, data-centric framework for LLM co-pilots that combines advanceddata-centric tools with LLM-driven reasoning to enable robust, context-awaredata processing. At its core, CliMB-DC introduces a novel, multi-agentreasoning system that combines a strategic coordinator for dynamic planning andadaptation with a specialized worker agent for precise execution. Domainexpertise is then systematically incorporated to guide the reasoning processusing a human-in-the-loop approach. To guide development, we formalize ataxonomy of key data-centric challenges that co-pilots must address.Thereafter, to address the dimensions of the taxonomy, we integratestate-of-the-art data-centric tools into an extensible, open-sourcearchitecture, facilitating the addition of new tools from the researchcommunity. Empirically, using real-world healthcare datasets we demonstrateCliMB-DC's ability to transform uncurated datasets into ML-ready formats,significantly outperforming existing co-pilot baselines for handlingdata-centric challenges. CliMB-DC promises to empower domain experts fromdiverse domains -- healthcare, finance, social sciences and more -- to activelyparticipate in driving real-world impact using ML.</description><author>Evgeny Saveliev, Jiashuo Liu, Nabeel Seedat, Anders Boyd, Mihaela van der Schaar</author><pubDate>Fri, 17 Jan 2025 17:51:22 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.10321v1</guid></item><item><title>Beyond Factual Accuracy: Evaluating Coverage of Diverse Factual Information in Long-form Text Generation</title><link>http://arxiv.org/abs/2501.03545v2</link><description>This paper presents ICAT, an evaluation framework for measuring coverage ofdiverse factual information in long-form text generation. ICAT breaks down along output text into a list of atomic claims and not only verifies each claimthrough retrieval from a (reliable) knowledge source, but also computes thealignment between the atomic factual claims and various aspects expected to bepresented in the output. We study three implementations of the ICAT framework,each with a different assumption on the availability of aspects and alignmentmethod. By adopting data from the diversification task in the TREC Web Trackand the ClueWeb corpus, we evaluate the ICAT framework. We demonstrate strongcorrelation with human judgments and provide comprehensive evaluation acrossmultiple state-of-the-art LLMs. Our framework further offers interpretable andfine-grained analysis of diversity and coverage. Its modular design allows foreasy adaptation to different domains and datasets, making it a valuable toolfor evaluating the qualitative aspects of long-form responses produced by LLMs.</description><author>Chris Samarinas, Alexander Krubner, Alireza Salemi, Youngwoo Kim, Hamed Zamani</author><pubDate>Fri, 17 Jan 2025 17:47:24 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.03545v2</guid></item><item><title>Natural Language Processing of Privacy Policies: A Survey</title><link>http://arxiv.org/abs/2501.10319v1</link><description>Natural Language Processing (NLP) is an essential subset of artificialintelligence. It has become effective in several domains, such as healthcare,finance, and media, to identify perceptions, opinions, and misuse, amongothers. Privacy is no exception, and initiatives have been taken to address thechallenges of usable privacy notifications to users with the help of NLP. Tothis aid, we conduct a literature review by analyzing 109 papers at theintersection of NLP and privacy policies. First, we provide a briefintroduction to privacy policies and discuss various facets of associatedproblems, which necessitate the application of NLP to elevate the current stateof privacy notices and disclosures to users. Subsequently, we a) provide anoverview of the implementation and effectiveness of NLP approaches for betterprivacy policy communication; b) identify the methodologies that can be furtherenhanced to provide robust privacy policies; and c) identify the gaps in thecurrent state-of-the-art research. Our systematic analysis reveals that severalresearch papers focus on annotating and classifying privacy texts for analysisbut need to adequately dwell on other aspects of NLP applications, such assummarization. More specifically, ample research opportunities exist in thisdomain, covering aspects such as corpus generation, summarization vectors,contextualized word embedding, identification of privacy-relevant statementcategories, fine-grained classification, and domain-specific model tuning.</description><author>Andrick Adhikari, Sanchari Das, Rinku Dewri</author><pubDate>Fri, 17 Jan 2025 17:47:15 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.10319v1</guid></item><item><title>HiMix: Reducing Computational Complexity in Large Vision-Language Models</title><link>http://arxiv.org/abs/2501.10318v1</link><description>Benefiting from recent advancements in large language models and modalityalignment techniques, existing Large Vision-Language Models(LVLMs) haveachieved prominent performance across a wide range of scenarios. However, theexcessive computational complexity limits the widespread use of these models inpractical applications. We argue that one main bottleneck in computationalcomplexity is caused by the involvement of redundant vision sequences in modelcomputation. This is inspired by a reassessment of the efficiency of vision andlanguage information transmission in the language decoder of LVLMs. Then, wepropose a novel hierarchical vision-language interaction mechanism calledHierarchical Vision injection for Mixture Attention (HiMix). In HiMix, only thelanguage sequence undergoes full forward propagation, while the vision sequenceinteracts with the language at specific stages within each language decoderlayer. It is striking that our approach significantly reduces computationalcomplexity with minimal performance loss. Specifically, HiMix achieves a 10xreduction in the computational cost of the language decoder across multipleLVLM models while maintaining comparable performance. This highlights theadvantages of our method, and we hope our research brings new perspectives tothe field of vision-language understanding. Project Page:https://xuange923.github.io/HiMix</description><author>Xuange Zhang, Dengjie Li, Bo Liu, Zenghao Bao, Yao Zhou, Baisong Yang, Zhongying Liu, Yujie Zhong, Zheng Zhao, Tongtong Yuan</author><pubDate>Fri, 17 Jan 2025 17:41:47 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.10318v1</guid></item><item><title>Towards Preventing Overreliance on Task-Oriented Conversational AI Through Accountability Modeling</title><link>http://arxiv.org/abs/2501.10316v1</link><description>Recent LLMs have enabled significant advancements for conversational agents.However, they are also well-known to hallucinate, i.e., they often produceresponses that seem plausible but are not factually correct. On the other hand,users tend to over-rely on LLM-based AI agents; they accept the AI's suggestioneven when it is wrong. Adding good friction, such as explanations or gettinguser confirmations, has been proposed as a mitigation in AI-supporteddecision-making systems. In this paper, we propose an accountability model forLLM-based task-oriented dialogue agents to address user overreliance viafriction turns in cases of model uncertainty and errors associated withdialogue state tracking (DST). The accountability model is an augmented LLMwith an additional accountability head, which functions as a binary classifierto predict the slots of the dialogue states. We perform our experiments withthree backbone LLMs (Llama, Mistral, Gemma) on two established task-orienteddatasets (MultiWOZ and Snips). Our empirical findings demonstrate that thisapproach not only enables reliable estimation of AI agent errors but alsoguides the LLM decoder in generating more accurate actions. We observe around3% absolute improvement in joint goal accuracy by incorporating accountabilityheads in modern LLMs for the MultiWOZ dataset. We also show that this methodenables the agent to self-correct its actions, further boosting its performanceby 3%. Finally, we discuss the application of accountability modeling toprevent user overreliance by introducing friction.</description><author>Suvodip Dey, Yi-Jyun Sun, Gokhan Tur, Dilek Hakkani-Tur</author><pubDate>Fri, 17 Jan 2025 17:40:12 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.10316v1</guid></item><item><title>Neuradicon: operational representation learning of neuroimaging reports</title><link>http://arxiv.org/abs/2107.10021v3</link><description>Radiological reports typically summarize the content and interpretation ofimaging studies in unstructured form that precludes quantitative analysis. Thislimits the monitoring of radiological services to throughput undifferentiatedby content, impeding specific, targeted operational optimization. Here wepresent Neuradicon, a natural language processing (NLP) framework forquantitative analysis of neuroradiological reports. Our framework is a hybridof rule-based and artificial intelligence models to represent neurologicalreports in succinct, quantitative form optimally suited to operationalguidance. We demonstrate the application of Neuradicon to operationalphenotyping of a corpus of 336,569 reports, and report excellentgeneralizability across time and two independent healthcare institutions.</description><author>Henry Watkins, Robert Gray, Adam Julius, Yee-Haur Mah, Walter H. L. Pinaya, Paul Wright, Ashwani Jha, Holger Engleitner, Jorge Cardoso, Sebastien Ourselin, Geraint Rees, Rolf Jaeger, Parashkev Nachev</author><pubDate>Fri, 17 Jan 2025 17:37:42 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2107.10021v3</guid></item><item><title>On the Hypomonotone Class of Variational Inequalities</title><link>http://arxiv.org/abs/2410.09182v2</link><description>This paper studies the behavior of the extragradient algorithm [Korpelevich,1976] when applied to hypomonotone operators, a class of problems that extendsbeyond the classical monotone setting. To support the understanding of thisvariational inequality problem class, we focus on a subclass of hypomonotonelinear operators, characterizing them based on their eigenvalues and providingconcrete examples. While the extragradient method is widely recognized for itsefficiency in solving variational inequalities involving monotone and Lipschitzcontinuous operators, we demonstrate that it does not guarantee convergence inthe hypomonotone case. In particular, we construct a counterexample where theextragradient method diverges regardless of the step size. A numericalexperiment is presented to support this result.</description><author>Khaled Alomar, Tatjana Chavdarova</author><pubDate>Fri, 17 Jan 2025 17:30:13 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.09182v2</guid></item><item><title>Mesh2SLAM in VR: A Fast Geometry-Based SLAM Framework for Rapid Prototyping in Virtual Reality Applications</title><link>http://arxiv.org/abs/2501.09600v2</link><description>SLAM is a foundational technique with broad applications in robotics andAR/VR. SLAM simulations evaluate new concepts, but testing onresource-constrained devices, such as VR HMDs, faces challenges: highcomputational cost and restricted sensor data access. This work proposes asparse framework using mesh geometry projections as features, which improvesefficiency and circumvents direct sensor data access, advancing SLAM researchas we demonstrate in VR and through numerical evaluation.</description><author>Carlos Augusto Pinheiro de Sousa, Heiko Hamann, Oliver Deussen</author><pubDate>Fri, 17 Jan 2025 17:07:31 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.09600v2</guid></item><item><title>Improved Paraphrase Generation via Controllable Latent Diffusion</title><link>http://arxiv.org/abs/2404.08938v2</link><description>Paraphrase generation strives to generate high-quality and diverseexpressions of a given text, a domain where diffusion models excel. Though SOTAdiffusion generation reconciles generation quality and diversity, textualdiffusion suffers from a truncation issue that hinders efficiency and qualitycontrol. In this work, we propose \textit{L}atent \textit{D}iffusion\textit{P}araphraser~(LDP), a novel paraphrase generation by modeling acontrollable diffusion process given a learned latent space. LDP achievessuperior generation efficiency compared to its diffusion counterparts. It canfacilitate only input segments to ensure paraphrase semantics, improving theresults without external features. Experiments show that LDP better reconcilesparaphrase generation quality and diversity than baselines. Further analysisshows that our method is also helpful to other similar text generations anddomain adaptations</description><author>Wei Zou, Ziyuan Zhuang, Xiang Geng, Shujian Huang, Jia Liu, Jiajun Chen</author><pubDate>Fri, 17 Jan 2025 17:05:41 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.08938v2</guid></item><item><title>STPOTR: Simultaneous Human Trajectory and Pose Prediction Using a Non-Autoregressive Transformer for Robot Following Ahead</title><link>http://arxiv.org/abs/2209.07600v4</link><description>In this paper, we develop a neural network model to predict future humanmotion from an observed human motion history. We propose a non-autoregressivetransformer architecture to leverage its parallel nature for easier trainingand fast, accurate predictions at test time. The proposed architecture divideshuman motion prediction into two parts: 1) the human trajectory, which is thehip joint 3D position over time and 2) the human pose which is the all otherjoints 3D positions over time with respect to a fixed hip joint. We propose tomake the two predictions simultaneously, as the shared representation canimprove the model performance. Therefore, the model consists of two sets ofencoders and decoders. First, a multi-head attention module applied to encoderoutputs improves human trajectory. Second, another multi-head self-attentionmodule applied to encoder outputs concatenated with decoder outputs facilitateslearning of temporal dependencies. Our model is well-suited for roboticapplications in terms of test accuracy and speed, and compares favorably withrespect to state-of-the-art methods. We demonstrate the real-worldapplicability of our work via the Robot Follow-Ahead task, a challenging yetpractical case study for our proposed model.</description><author>Mohammad Mahdavian, Payam Nikdel, Mahdi TaherAhmadi, Mo Chen</author><pubDate>Fri, 17 Jan 2025 16:52:03 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2209.07600v4</guid></item><item><title>An Ontology for Social Determinants of Education (SDoEd) based on Human-AI Collaborative Approach</title><link>http://arxiv.org/abs/2501.10300v1</link><description>The use of computational ontologies is well-established in the field ofMedical Informatics. The topic of Social Determinants of Health (SDoH) has alsoreceived extensive attention. Work at the intersection of ontologies and SDoHhas been published. However, a standardized framework for Social Determinantsof Education (SDoEd) is lacking. In this paper, we are closing the gap byintroducing an SDoEd ontology for creating a precise conceptualization of theinterplay between life circumstances of students and their possible educationalachievements. The ontology was developed utilizing suggestions fromChatGPT-3.5-010422 and validated using peer-reviewed research articles. Thefirst version of developed ontology was evaluated by human experts in the fieldof education and validated using standard ontology evaluation software. Thisversion of the SDoEd ontology contains 231 domain concepts, 10 objectproperties, and 24 data properties</description><author>Navya Martin Kollapally, James Geller, Patricia Morreale, Daehan Kwak</author><pubDate>Fri, 17 Jan 2025 16:51:03 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.10300v1</guid></item><item><title>The Effect of Similarity Measures on Accurate Stability Estimates for Local Surrogate Models in Text-based Explainable AI</title><link>http://arxiv.org/abs/2406.15839v2</link><description>Recent work has investigated the vulnerability of local surrogate methods toadversarial perturbations on a machine learning (ML) model's inputs, where theexplanation is manipulated while the meaning and structure of the originalinput remains similar under the complex model. Although weaknesses across manymethods have been shown to exist, the reasons behind why remain littleexplored. Central to the concept of adversarial attacks on explainable AI (XAI)is the similarity measure used to calculate how one explanation differs fromanother. A poor choice of similarity measure can lead to erroneous conclusionson the efficacy of an XAI method. Too sensitive a measure results inexaggerated vulnerability, while too coarse understates its weakness. Weinvestigate a variety of similarity measures designed for text-based rankedlists, including Kendall's Tau, Spearman's Footrule, and Rank-biased Overlap todetermine how substantial changes in the type of measure or threshold ofsuccess affect the conclusions generated from common adversarial attackprocesses. Certain measures are found to be overly sensitive, resulting inerroneous estimates of stability.</description><author>Christopher Burger, Charles Walter, Thai Le</author><pubDate>Fri, 17 Jan 2025 16:49:25 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.15839v2</guid></item><item><title>Moonshine: Distilling Game Content Generators into Steerable Generative Models</title><link>http://arxiv.org/abs/2408.09594v2</link><description>Procedural Content Generation via Machine Learning (PCGML) has enhanced gamecontent creation, yet challenges in controllability and limited training datapersist. This study addresses these issues by distilling a constructive PCGalgorithm into a controllable PCGML model. We first generate a large amount ofcontent with a constructive algorithm and label it using a Large Language Model(LLM). We use these synthetic labels to condition two PCGML models forcontent-specific generation, a diffusion model and the five-dollar model. Thisneural network distillation process ensures that the generation aligns with theoriginal algorithm while introducing controllability through plain text. Wedefine this text-conditioned PCGML as a Text-to-game-Map (T2M) task, offeringan alternative to prevalent text-to-image multi-modal tasks. We compare ourdistilled models with the baseline constructive algorithm. Our analysis of thevariety, accuracy, and quality of our generation demonstrates the efficacy ofdistilling constructive methods into controllable text-conditioned PCGMLmodels.</description><author>Yuhe Nie, Michael Middleton, Tim Merino, Nidhushan Kanagaraja, Ashutosh Kumar, Zhan Zhuang, Julian Togelius</author><pubDate>Fri, 17 Jan 2025 16:44:35 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.09594v2</guid></item><item><title>High-Rank Irreducible Cartesian Tensor Decomposition and Bases of Equivariant Spaces</title><link>http://arxiv.org/abs/2412.18263v4</link><description>Irreducible Cartesian tensors (ICTs) play a crucial role in the design ofequivariant graph neural networks, as well as in theoretical chemistry andchemical physics. Meanwhile, the design space of available linear operations ontensors that preserve symmetry presents a significant challenge. The ICTdecomposition and a basis of this equivariant space are difficult to obtain forhigh-rank tensors. After decades of research, Bonvicini (2024) recentlyachieves an explicit ICT decomposition for $n=5$ with factorial time/spacecomplexity. In this work we, for the first time, obtains decomposition matricesfor ICTs up to rank $n=9$ with reduced and affordable complexity, byconstructing what we call path matrices. The path matrices are obtained viaperforming chain-like contractions with Clebsch-Gordan matrices following theparentage scheme. We prove and leverage that the concatenation of path matricesis an orthonormal change-of-basis matrix between the Cartesian tensor productspace and the spherical direct sum spaces. Furthermore, we identify a completeorthogonal basis for the equivariant space, rather than a spanning set(Pearce-Crump, 2023), through this path matrices technique. To the best of ourknowledge, this is also the first analytic, rather than numerical, method fortheoretically obtaining arbitrary rank orthogonal ICT decomposition matricesand orthogonal equivariant bases. We further extend our result to the arbitrarytensor product and direct sum spaces, enabling free design between differentspaces while keeping symmetry. The Python code is available athttps://github.com/ShihaoShao-GH/ICT-decomposition-and-equivariant-bases, wherethe $n=6,\dots,9$ ICT decomposition matrices are obtained in 1s, 3s, 11s, and4m32s on 28-cores Intel(R) Xeon(R) Gold 6330 CPU @ 2.00GHz, respectively.</description><author>Shihao Shao, Yikang Li, Zhouchen Lin, Qinghua Cui</author><pubDate>Fri, 17 Jan 2025 16:40:21 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.18263v4</guid></item><item><title>Generalized Multi-hop Traffic Pressure for Heterogeneous Traffic Perimeter Control</title><link>http://arxiv.org/abs/2409.00753v2</link><description>Perimeter control (PC) prevents loss of traffic network capacity due tocongestion in urban areas. Homogeneous PC allows all access points to aprotected region to have identical permitted inflow. However, homogeneous PCperforms poorly when the congestion in the protected region is heterogeneous(e.g., imbalanced demand) since the homogeneous PC does not consider specifictraffic conditions around each perimeter intersection. When the protectedregion has spatially heterogeneous congestion, one needs to modulate theperimeter inflow rate to be higher near low-density regions and vice versa forhigh-density regions. A na\"ive approach is to leverage 1-hop traffic pressureto measure traffic condition around perimeter intersections, but such metric istoo spatially myopic for PC. To address this issue, we formulate multi-hopdownstream pressure grounded on Markov chain theory, which ``looks deeper''into the protected region beyond perimeter intersections. In addition, weformulate a two-stage hierarchical control scheme that can leverage this novelmulti-hop pressure to redistribute the total permitted inflow provided by apre-trained deep reinforcement learning homogeneous control policy.Experimental results show that our heterogeneous PC approaches leveragingmulti-hop pressure significantly outperform homogeneous PC in scenarios wherethe origin-destination flows are highly imbalanced with high spatialheterogeneity. Moveover, our approach is shown to be robust against turningratio uncertainties by a sensitivity analysis.</description><author>Xiaocan Li, Xiaoyu Wang, Ilia Smirnov, Scott Sanner, Baher Abdulhai</author><pubDate>Fri, 17 Jan 2025 16:37:23 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2409.00753v2</guid></item><item><title>Two Types of AI Existential Risk: Decisive and Accumulative</title><link>http://arxiv.org/abs/2401.07836v3</link><description>The conventional discourse on existential risks (x-risks) from AI typicallyfocuses on abrupt, dire events caused by advanced AI systems, particularlythose that might achieve or surpass human-level intelligence. These events havesevere consequences that either lead to human extinction or irreversiblycripple human civilization to a point beyond recovery. This discourse, however,often neglects the serious possibility of AI x-risks manifesting incrementallythrough a series of smaller yet interconnected disruptions, gradually crossingcritical thresholds over time. This paper contrasts the conventional "decisiveAI x-risk hypothesis" with an "accumulative AI x-risk hypothesis." While theformer envisions an overt AI takeover pathway, characterized by scenarios likeuncontrollable superintelligence, the latter suggests a different causalpathway to existential catastrophes. This involves a gradual accumulation ofcritical AI-induced threats such as severe vulnerabilities and systemic erosionof economic and political structures. The accumulative hypothesis suggests aboiling frog scenario where incremental AI risks slowly converge, underminingsocietal resilience until a triggering event results in irreversible collapse.Through systems analysis, this paper examines the distinct assumptionsdifferentiating these two hypotheses. It is then argued that the accumulativeview can reconcile seemingly incompatible perspectives on AI risks. Theimplications of differentiating between these causal pathways -- the decisiveand the accumulative -- for the governance of AI as well as long-term AI safetyare discussed.</description><author>Atoosa Kasirzadeh</author><pubDate>Fri, 17 Jan 2025 16:35:27 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.07836v3</guid></item><item><title>Pairwise Elimination with Instance-Dependent Guarantees for Bandits with Cost Subsidy</title><link>http://arxiv.org/abs/2501.10290v1</link><description>Multi-armed bandits (MAB) are commonly used in sequential onlinedecision-making when the reward of each decision is an unknown random variable.In practice however, the typical goal of maximizing total reward may be lessimportant than minimizing the total cost of the decisions taken, subject to areward constraint. For example, we may seek to make decisions that have atleast the reward of a reference ``default'' decision, with as low a cost aspossible. This problem was recently introduced in the Multi-Armed Bandits withCost Subsidy (MAB-CS) framework. MAB-CS is broadly applicable to problemdomains where a primary metric (cost) is constrained by a secondary metric(reward), and the rewards are unknown. In our work, we address variants ofMAB-CS including ones with reward constrained by the reward of a knownreference arm or by the subsidized best reward. We introduce thePairwise-Elimination (PE) algorithm for the known reference arm variant andgeneralize PE to PE-CS for the subsidized best reward variant. Ourinstance-dependent analysis of PE and PE-CS reveals that both algorithms havean order-wise logarithmic upper bound on Cost and Quality Regret, making ourpolicies the first with such a guarantee. Moreover, by comparing our upper andlower bound results we establish that PE is order-optimal for all knownreference arm problem instances. Finally, experiments are conducted using theMovieLens 25M and Goodreads datasets for both PE and PE-CS revealing theeffectiveness of PE and the superior balance between performance andreliability offered by PE-CS compared to baselines from the literature.</description><author>Ishank Juneja, Carlee Joe-Wong, Osman Yağan</author><pubDate>Fri, 17 Jan 2025 16:34:45 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.10290v1</guid></item><item><title>GSTAR: Gaussian Surface Tracking and Reconstruction</title><link>http://arxiv.org/abs/2501.10283v1</link><description>3D Gaussian Splatting techniques have enabled efficient photo-realisticrendering of static scenes. Recent works have extended these approaches tosupport surface reconstruction and tracking. However, tracking dynamic surfaceswith 3D Gaussians remains challenging due to complex topology changes, such assurfaces appearing, disappearing, or splitting. To address these challenges, wepropose GSTAR, a novel method that achieves photo-realistic rendering, accuratesurface reconstruction, and reliable 3D tracking for general dynamic sceneswith changing topology. Given multi-view captures as input, GSTAR bindsGaussians to mesh faces to represent dynamic objects. For surfaces withconsistent topology, GSTAR maintains the mesh topology and tracks the meshesusing Gaussians. In regions where topology changes, GSTAR adaptively unbindsGaussians from the mesh, enabling accurate registration and the generation ofnew surfaces based on these optimized Gaussians. Additionally, we introduce asurface-based scene flow method that provides robust initialization fortracking between frames. Experiments demonstrate that our method effectivelytracks and reconstructs dynamic surfaces, enabling a range of applications. Ourproject page with the code release is available athttps://chengwei-zheng.github.io/GSTAR/.</description><author>Chengwei Zheng, Lixin Xue, Juan Zarate, Jie Song</author><pubDate>Fri, 17 Jan 2025 16:26:24 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.10283v1</guid></item><item><title>Computational Protein Science in the Era of Large Language Models (LLMs)</title><link>http://arxiv.org/abs/2501.10282v1</link><description>Considering the significance of proteins, computational protein science hasalways been a critical scientific field, dedicated to revealing knowledge anddeveloping applications within the protein sequence-structure-functionparadigm. In the last few decades, Artificial Intelligence (AI) has madesignificant impacts in computational protein science, leading to notablesuccesses in specific protein modeling tasks. However, those previous AI modelsstill meet limitations, such as the difficulty in comprehending the semanticsof protein sequences, and the inability to generalize across a wide range ofprotein modeling tasks. Recently, LLMs have emerged as a milestone in AI due totheir unprecedented language processing &amp; generalization capability. They canpromote comprehensive progress in fields rather than solving individual tasks.As a result, researchers have actively introduced LLM techniques incomputational protein science, developing protein Language Models (pLMs) thatskillfully grasp the foundational knowledge of proteins and can be effectivelygeneralized to solve a diversity of sequence-structure-function reasoningproblems. While witnessing prosperous developments, it's necessary to present asystematic overview of computational protein science empowered by LLMtechniques. First, we summarize existing pLMs into categories based on theirmastered protein knowledge, i.e., underlying sequence patterns, explicitstructural and functional information, and external scientific languages.Second, we introduce the utilization and adaptation of pLMs, highlighting theirremarkable achievements in promoting protein structure prediction, proteinfunction prediction, and protein design studies. Then, we describe thepractical application of pLMs in antibody design, enzyme design, and drugdiscovery. Finally, we specifically discuss the promising future directions inthis fast-growing field.</description><author>Wenqi Fan, Yi Zhou, Shijie Wang, Yuyao Yan, Hui Liu, Qian Zhao, Le Song, Qing Li</author><pubDate>Fri, 17 Jan 2025 16:21:18 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.10282v1</guid></item><item><title>Counterfactual Uncertainty Quantification of Factual Estimand of Efficacy from Before-and-After Treatment Repeated Measures Randomized Controlled Trials</title><link>http://arxiv.org/abs/2411.09635v3</link><description>The ideal estimand for comparing treatment $Rx$ with a control $C$ is the$\textit{counterfactual}$ efficacy $Rx:C$, the expected differential outcomebetween $Rx$ and $C$ if each patient were given $\textit{both}$. One hundredyears ago, Neyman (1923a) proved unbiased $\textit{point estimation}$ ofcounterfactual efficacy from designed $\textit{factual}$ experiments isachievable. But he left the determination of how much might the counterfactualvariance of this estimate be smaller than the factual variance as an openchallenge. This article shows $\textit{counterfactual}$ uncertaintyquantification (CUQ), quantifying uncertainty for factual point estimates butin a counterfactual setting, is achievable for Randomized Controlled Trials(RCTs) with Before-and-After treatment Repeated Measures which are common inmany therapeutic areas. We achieve CUQ whose variability is typically smallerthan factual UQ by creating a new statistical modeling principle called ETZ. We urge caution in using predictors with measurement error which violatesstandard regression assumption and can cause $\textit{attenuation}$ inestimating treatment effects. Fortunately, we prove that, for traditionalmedicine in general, and for targeted therapy with efficacy defined as averagedover the population, counterfactual point estimation is unbiased. However, forboth Real Human and Digital Twins approaches, predicting treatment effect in$\textit{subgroups}$ may have attenuation bias.</description><author>Xingya Wang, Yang Han, Yushi Liu, Szu-Yu Tang, Jason C. Hsu</author><pubDate>Fri, 17 Jan 2025 16:11:42 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2411.09635v3</guid></item><item><title>Automated Machine Learning for Remaining Useful Life Predictions</title><link>http://arxiv.org/abs/2306.12215v2</link><description>Being able to predict the remaining useful life (RUL) of an engineeringsystem is an important task in prognostics and health management. Recently,data-driven approaches to RUL predictions are becoming prevalent overmodel-based approaches since no underlying physical knowledge of theengineering system is required. Yet, this just replaces required expertise ofthe underlying physics with machine learning (ML) expertise, which is oftenalso not available. Automated machine learning (AutoML) promises to buildend-to-end ML pipelines automatically enabling domain experts without MLexpertise to create their own models. This paper introduces AutoRUL, anAutoML-driven end-to-end approach for automatic RUL predictions. AutoRULcombines fine-tuned standard regression methods to an ensemble with highpredictive power. By evaluating the proposed method on eight real-world andsynthetic datasets against state-of-the-art hand-crafted models, we show thatAutoML provides a viable alternative to hand-crafted data-driven RULpredictions. Consequently, creating RUL predictions can be made more accessiblefor domain experts using AutoML by eliminating ML expertise from data-drivenmodel construction.</description><author>Marc-André Zöller, Fabian Mauthe, Peter Zeiler, Marius Lindauer, Marco F. Huber</author><pubDate>Fri, 17 Jan 2025 16:04:05 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.12215v2</guid></item><item><title>SEANN: A Domain-Informed Neural Network for Epidemiological Insights</title><link>http://arxiv.org/abs/2501.10273v1</link><description>In epidemiology, traditional statistical methods such as logistic regression,linear regression, and other parametric models are commonly employed toinvestigate associations between predictors and health outcomes. However,non-parametric machine learning techniques, such as deep neural networks(DNNs), coupled with explainable AI (XAI) tools, offer new opportunities forthis task. Despite their potential, these methods face challenges due to thelimited availability of high-quality, high-quantity data in this field. Toaddress these challenges, we introduce SEANN, a novel approach for informedDNNs that leverages a prevalent form of domain-specific knowledge: PooledEffect Sizes (PES). PESs are commonly found in published Meta-Analysis studies,in different forms, and represent a quantitative form of a scientificconsensus. By direct integration within the learning procedure using a customloss, we experimentally demonstrate significant improvements in thegeneralizability of predictive performances and the scientific plausibility ofextracted relationships compared to a domain-knowledge agnostic neural networkin a scarce and noisy data setting.</description><author>Jean-Baptiste Guimbaud, Marc Plantevit, Léa Maître, Rémy Cazabet</author><pubDate>Fri, 17 Jan 2025 16:01:05 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.10273v1</guid></item><item><title>Enhancing reliability in prediction intervals using point forecasters: Heteroscedastic Quantile Regression and Width-Adaptive Conformal Inference</title><link>http://arxiv.org/abs/2406.14904v2</link><description>Constructing prediction intervals for time series forecasting is challenging,particularly when practitioners rely solely on point forecasts. While previousresearch has focused on creating increasingly efficient intervals, we arguethat standard measures alone are inadequate. Beyond efficiency, predictionintervals must adapt their width based on the difficulty of the predictionwhile preserving coverage regardless of complexity. To address these issues, wepropose combining Heteroscedastic Quantile Regression (HQR) with Width-AdaptiveConformal Inference (WACI). This integrated procedure guarantees theoreticalcoverage and enables interval widths to vary with predictive uncertainty. Weassess its performance using both a synthetic example and a real worldElectricity Price Forecasting scenario. Our results show that this combinedapproach meets or surpasses typical benchmarks for validity and efficiency,while also fulfilling important yet often overlooked practical requirements.</description><author>Carlos Sebastián, Carlos E. González-Guillén, Jesús Juan</author><pubDate>Fri, 17 Jan 2025 15:59:34 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.14904v2</guid></item><item><title>Can machine learning unlock new insights into high-frequency trading?</title><link>http://arxiv.org/abs/2405.08101v2</link><description>We design and train machine learning models to capture the nonlinearinteractions between financial market dynamics and high-frequency trading (HFT)activity. In doing so, we introduce new metrics to identify liquidity-demandingand -supplying HFT strategies. Both types of HFT strategies increase activityin response to information events and decrease it when trading speed isrestricted, with liquidity-supplying strategies demonstrating greaterresponsiveness. Liquidity-demanding HFT is positively linked with latencyarbitrage opportunities, whereas liquidity-supplying HFT is negatively related,aligning with theoretical expectations. Our metrics have implications forunderstanding the information production process in financial markets.</description><author>G. Ibikunle, B. Moews, D. Muravyev, K. Rzayev</author><pubDate>Fri, 17 Jan 2025 15:57:52 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.08101v2</guid></item><item><title>ESVO2: Direct Visual-Inertial Odometry with Stereo Event Cameras</title><link>http://arxiv.org/abs/2410.09374v2</link><description>Event-based visual odometry is a specific branch of visual SimultaneousLocalization and Mapping (SLAM) techniques, which aims at solving tracking andmapping subproblems (typically in parallel), by exploiting the special workingprinciples of neuromorphic (i.e., event-based) cameras. Due to themotion-dependent nature of event data, explicit data association (i.e., featurematching) under large-baseline view-point changes is difficult to establish,making direct methods a more rational choice. However, state-of-the-art directmethods are limited by the high computational complexity of the mappingsub-problem and the degeneracy of camera pose tracking in certain degrees offreedom (DoF) in rotation. In this paper, we tackle these issues by building anevent-based stereo visual-inertial odometry system on top of a direct pipeline.Specifically, to speed up the mapping operation, we propose an efficientstrategy for sampling contour points according to the local dynamics of events.The mapping performance is also improved in terms of structure completeness andlocal smoothness by merging the temporal stereo and static stereo results. Tocircumvent the degeneracy of camera pose tracking in recovering the pitch andyaw components of general 6-DoF motion, we introduce IMU measurements as motionpriors via pre-integration. To this end, a compact back-end is proposed forcontinuously updating the IMU bias and predicting the linear velocity, enablingan accurate motion prediction for camera pose tracking. The resulting systemscales well with modern high-resolution event cameras and leads to betterglobal positioning accuracy in large-scale outdoor environments. Extensiveevaluations on five publicly available datasets featuring different resolutionsand scenarios justify the superior performance of the proposed system againstfive state-of-the-art methods.</description><author>Junkai Niu, Sheng Zhong, Xiuyuan Lu, Shaojie Shen, Guillermo Gallego, Yi Zhou</author><pubDate>Fri, 17 Jan 2025 15:52:06 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.09374v2</guid></item><item><title>MutualForce: Mutual-Aware Enhancement for 4D Radar-LiDAR 3D Object Detection</title><link>http://arxiv.org/abs/2501.10266v1</link><description>Radar and LiDAR have been widely used in autonomous driving as LiDAR providesrich structure information, and radar demonstrates high robustness underadverse weather. Recent studies highlight the effectiveness of fusing radar andLiDAR point clouds. However, challenges remain due to the modality misalignmentand information loss during feature extractions. To address these issues, wepropose a 4D radar-LiDAR framework to mutually enhance their representations.Initially, the indicative features from radar are utilized to guide both radarand LiDAR geometric feature learning. Subsequently, to mitigate their sparsitygap, the shape information from LiDAR is used to enrich radar BEV features.Extensive experiments on the View-of-Delft (VoD) dataset demonstrate ourapproach's superiority over existing methods, achieving the highest mAP of71.76% across the entire area and 86.36\% within the driving corridor.Especially for cars, we improve the AP by 4.17% and 4.20% due to the strongindicative features and symmetric shapes.</description><author>Xiangyuan Peng, Huawei Sun, Kay Bierzynski, Anton Fischbacher, Lorenzo Servadei, Robert Wille</author><pubDate>Fri, 17 Jan 2025 15:48:37 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.10266v1</guid></item><item><title>Logarithmic Regret for Nonlinear Control</title><link>http://arxiv.org/abs/2501.10261v1</link><description>We address the problem of learning to control an unknown nonlinear dynamicalsystem through sequential interactions. Motivated by high-stakes applicationsin which mistakes can be catastrophic, such as robotics and healthcare, westudy situations where it is possible for fast sequential learning to occur.Fast sequential learning is characterized by the ability of the learning agentto incur logarithmic regret relative to a fully-informed baseline. Wedemonstrate that fast sequential learning is achievable in a diverse class ofcontinuous control problems where the system dynamics depend smoothly onunknown parameters, provided the optimal control policy is persistentlyexciting. Additionally, we derive a regret bound which grows with the squareroot of the number of interactions for cases where the optimal policy is notpersistently exciting. Our results provide the first regret bounds forcontrolling nonlinear dynamical systems depending nonlinearly on unknownparameters. We validate the trends our theory predicts in simulation on asimple dynamical system.</description><author>James Wang, Bruce D. Lee, Ingvar Ziemann, Nikolai Matni</author><pubDate>Fri, 17 Jan 2025 15:42:42 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.10261v1</guid></item><item><title>DADA: Dual Averaging with Distance Adaptation</title><link>http://arxiv.org/abs/2501.10258v1</link><description>We present a novel universal gradient method for solving convex optimizationproblems. Our algorithm -- Dual Averaging with Distance Adaptation (DADA) -- isbased on the classical scheme of dual averaging and dynamically adjusts itscoefficients based on observed gradients and the distance between iterates andthe starting point, eliminating the need for problem-specific parameters. DADAis a universal algorithm that simultaneously works for a broad spectrum ofproblem classes, provided the local growth of the objective function around itsminimizer can be bounded. Particular examples of such problem classes arenonsmooth Lipschitz functions, Lipschitz-smooth functions, H\"older-smoothfunctions, functions with high-order Lipschitz derivative,quasi-self-concordant functions, and $(L_0,L_1)$-smooth functions. Crucially,DADA is applicable to both unconstrained and constrained problems, even whenthe domain is unbounded, without requiring prior knowledge of the number ofiterations or desired accuracy.</description><author>Mohammad Moshtaghifar, Anton Rodomanov, Daniil Vankov, Sebastian Stich</author><pubDate>Fri, 17 Jan 2025 15:40:03 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.10258v1</guid></item><item><title>Unsupervised Rhythm and Voice Conversion of Dysarthric to Healthy Speech for ASR</title><link>http://arxiv.org/abs/2501.10256v1</link><description>Automatic speech recognition (ASR) systems are well known to perform poorlyon dysarthric speech. Previous works have addressed this by speaking ratemodification to reduce the mismatch with typical speech. Unfortunately, theseapproaches rely on transcribed speech data to estimate speaking rates andphoneme durations, which might not be available for unseen speakers. Therefore,we combine unsupervised rhythm and voice conversion methods based onself-supervised speech representations to map dysarthric to typical speech. Weevaluate the outputs with a large ASR model pre-trained on healthy speechwithout further fine-tuning and find that the proposed rhythm conversionespecially improves performance for speakers of the Torgo corpus with moresevere cases of dysarthria. Code and audio samples are available athttps://idiap.github.io/RnV .</description><author>Karl El Hajal, Enno Hermann, Ajinkya Kulkarni, Mathew Magimai. -Doss</author><pubDate>Fri, 17 Jan 2025 15:39:21 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.10256v1</guid></item><item><title>Towards Large Reasoning Models: A Survey on Scaling LLM Reasoning Capabilities</title><link>http://arxiv.org/abs/2501.09686v2</link><description>Language has long been conceived as an essential tool for human reasoning.The breakthrough of Large Language Models (LLMs) has sparked significantresearch interest in leveraging these models to tackle complex reasoning tasks.Researchers have moved beyond simple autoregressive token generation byintroducing the concept of "thought" -- a sequence of tokens representingintermediate steps in the reasoning process. This innovative paradigm enablesLLMs' to mimic complex human reasoning processes, such as tree search andreflective thinking. Recently, an emerging trend of learning to reason hasapplied reinforcement learning (RL) to train LLMs to master reasoningprocesses. This approach enables the automatic generation of high-qualityreasoning trajectories through trial-and-error search algorithms, significantlyexpanding LLMs' reasoning capacity by providing substantially more trainingdata. Furthermore, recent studies demonstrate that encouraging LLMs to "think"with more tokens during test-time inference can further significantly boostreasoning accuracy. Therefore, the train-time and test-time scaling combined toshow a new research frontier -- a path toward Large Reasoning Model. Theintroduction of OpenAI's o1 series marks a significant milestone in thisresearch direction. In this survey, we present a comprehensive review of recentprogress in LLM reasoning. We begin by introducing the foundational backgroundof LLMs and then explore the key technical components driving the developmentof large reasoning models, with a focus on automated data construction,learning-to-reason techniques, and test-time scaling. We also analyze popularopen-source projects at building large reasoning models, and conclude with openchallenges and future research directions.</description><author>Fengli Xu, Qianyue Hao, Zefang Zong, Jingwei Wang, Yunke Zhang, Jingyi Wang, Xiaochong Lan, Jiahui Gong, Tianjian Ouyang, Fanjin Meng, Chenyang Shao, Yuwei Yan, Qinglong Yang, Yiwen Song, Sijian Ren, Xinyuan Hu, Yu Li, Jie Feng, Chen Gao, Yong Li</author><pubDate>Fri, 17 Jan 2025 15:24:53 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.09686v2</guid></item><item><title>Large Language Model is Secretly a Protein Sequence Optimizer</title><link>http://arxiv.org/abs/2501.09274v2</link><description>We consider the protein sequence engineering problem, which aims to findprotein sequences with high fitness levels, starting from a given wild-typesequence. Directed evolution has been a dominating paradigm in this field whichhas an iterative process to generate variants and select via experimentalfeedback. We demonstrate large language models (LLMs), despite being trained onmassive texts, are secretly protein sequence optimizers. With a directedevolutionary method, LLM can perform protein engineering through Pareto andexperiment-budget constrained optimization, demonstrating success on bothsynthetic and experimental fitness landscapes.</description><author>Yinkai Wang, Jiaxing He, Yuanqi Du, Xiaohui Chen, Jianan Canal Li, Li-Ping Liu, Xiaolin Xu, Soha Hassoun</author><pubDate>Fri, 17 Jan 2025 15:22:00 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.09274v2</guid></item><item><title>BILTS: A Bi-Invariant Similarity Measure for Robust Object Trajectory Recognition under Reference Frame Variations</title><link>http://arxiv.org/abs/2405.04392v2</link><description>When similar object motions are performed in diverse contexts but are meantto be recognized under a single classification, these contextual variations actas disturbances that negatively affect accurate motion recognition. In thispaper, we focus on contextual variations caused by reference frame variations.To robustly deal with these variations, similarity measures have beenintroduced that compare object motion trajectories in a context-invariantmanner. However, most are highly sensitive to noise near singularities, wherethe measure is not uniquely defined, and lack bi-invariance (invariance to bothworld and body frame variations). To address these issues, we propose the novel\textit{Bi-Invariant Local Trajectory-Shape Similarity} (BILTS) measure.Compared to other measures, the BILTS measure uniquely offers bi-invariance,boundedness, and third-order shape identity. Aimed at practicalimplementations, we devised a discretized and regularized version of the BILTSmeasure which shows exceptional robustness to singularities. This isdemonstrated through rigorous recognition experiments using multiple datasets.On average, BILTS attained the highest recognition ratio and least sensitivityto contextual variations compared to other invariant object motion similaritymeasures. We believe that the BILTS measure is a valuable tool for recognizingmotions performed in diverse contexts and has potential in other applications,including the recognition, segmentation, and adaptation of both motion andforce trajectories.</description><author>Arno Verduyn, Erwin Aertbeliën, Glenn Maes, Joris De Schutter, Maxim Vochten</author><pubDate>Fri, 17 Jan 2025 15:21:52 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.04392v2</guid></item><item><title>Bridging Diversity and Uncertainty in Active learning with Self-Supervised Pre-Training</title><link>http://arxiv.org/abs/2403.03728v2</link><description>This study addresses the integration of diversity-based and uncertainty-basedsampling strategies in active learning, particularly within the context ofself-supervised pre-trained models. We introduce a straightforward heuristiccalled TCM that mitigates the cold start problem while maintaining strongperformance across various data levels. By initially applying TypiClust fordiversity sampling and subsequently transitioning to uncertainty sampling withMargin, our approach effectively combines the strengths of both strategies. Ourexperiments demonstrate that TCM consistently outperforms existing methodsacross various datasets in both low and high data regimes.</description><author>Paul Doucet, Benjamin Estermann, Till Aczel, Roger Wattenhofer</author><pubDate>Fri, 17 Jan 2025 15:15:15 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.03728v2</guid></item><item><title>Over-the-Air Multi-Sensor Inference with Neural Networks Using Memristor-Based Analog Computing</title><link>http://arxiv.org/abs/2501.10245v1</link><description>Deep neural networks provide reliable solutions for many classification andregression tasks; however, their application in real-time wireless systems withsimple sensor networks is limited due to high energy consumption andsignificant bandwidth needs. This study proposes a multi-sensor wirelessinference system with memristor-based analog computing. Given the sensors'limited computational capabilities, the features from the network's front endare transmitted to a central device where an $L_p$-norm inspired approximationof the maximum operation is employed to achieve transformation-invariantfeatures, enabling efficient over-the-air transmission. We also introduce atrainable over-the-air sensor fusion method based on $L_p$-norm inspiredcombining function that customizes sensor fusion to match the network andsensor distribution characteristics, enhancing adaptability. To address theenergy constraints of sensors, we utilize memristors, known for theirenergy-efficient in-memory computing, enabling analog-domain computations thatreduce energy use and computational overhead in edge computing. This dualapproach of memristors and $L_p$-norm inspired sensor fusion fostersenergy-efficient computational and transmission paradigms and serves as apractical energy-efficient solution with minimal performance loss.</description><author>Busra Tegin, Muhammad Atif Ali, Tolga M Duman</author><pubDate>Fri, 17 Jan 2025 15:14:58 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.10245v1</guid></item><item><title>Random-Key Algorithms for Optimizing Integrated Operating Room Scheduling</title><link>http://arxiv.org/abs/2501.10243v1</link><description>Efficient surgery room scheduling is essential for hospital efficiency,patient satisfaction, and resource utilization. This study addresses thischallenge by introducing a novel concept of Random-Key Optimizer (RKO),rigorously tested on literature and new, real-world inspired instances. Ourcombinatorial optimization problem incorporates multi-room scheduling,equipment scheduling, and complex availability constraints for rooms, patients,and surgeons, facilitating rescheduling and enhancing operational flexibility.The RKO approach represents solutions as points in a continuous space, whichare then mapped in the problem solution space via a deterministic functionknown as a decoder. The core idea is to operate metaheuristics and heuristicsin the random-key space, unaware of the original solution space. We design theBiased Random-Key Genetic Algorithm with $Q$-Learning, Simulated Annealing, andIterated Local Search for use within an RKO framework, employing a singledecoder function. The proposed metaheuristics are complemented by lower-boundformulations, providing optimal gaps for evaluating the effectiveness of theheuristic results. Our results demonstrate significant lower and upper boundsimprovements for the literature instances, notably proving one optimal result.Furthermore, the best-proposed metaheuristic efficiently generates schedulesfor the newly introduced instances, even in highly constrained scenarios. Thisresearch offers valuable insights and practical solutions for improving surgeryscheduling processes, offering tangible benefits to hospitals by optimisingresource allocation, reducing patient wait times, and enhancing overalloperational efficiency.</description><author>Bruno Salezze Vieira, Eduardo Machado Silva, Antonio Augusto Chaves</author><pubDate>Fri, 17 Jan 2025 15:11:30 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.10243v1</guid></item><item><title>Challenges and recommendations for Electronic Health Records data extraction and preparation for dynamic prediction modelling in hospitalized patients -- a practical guide</title><link>http://arxiv.org/abs/2501.10240v1</link><description>Dynamic predictive modeling using electronic health record (EHR) data hasgained significant attention in recent years. The reliability andtrustworthiness of such models depend heavily on the quality of the underlyingdata, which is largely determined by the stages preceding the modeldevelopment: data extraction from EHR systems and data preparation. We listover forty challenges encountered during these stages and provide actionablerecommendations for addressing them. These challenges are organized into fourcategories: cohort definition, outcome definition, feature engineering, anddata cleaning. This list is designed to serve as a practical guide for dataextraction engineers and researchers, supporting better practices and improvingthe quality and real-world applicability of dynamic prediction models inclinical settings.</description><author>Elena Albu, Shan Gao, Pieter Stijnen, Frank E. Rademakers, Bas C T van Bussel, Taya Collyer, Tina Hernandez-Boussard, Laure Wynants, Ben Van Calster</author><pubDate>Fri, 17 Jan 2025 15:09:57 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.10240v1</guid></item><item><title>The Animal-AI Environment: A Virtual Laboratory For Comparative Cognition and Artificial Intelligence Research</title><link>http://arxiv.org/abs/2312.11414v3</link><description>The Animal-AI Environment is a unique game-based research platform designedto facilitate collaboration between the artificial intelligence and comparativecognition research communities. In this paper, we present the latest version ofthe Animal-AI Environment, outlining several major features that make the gamemore engaging for humans and more complex for AI systems. These featuresinclude interactive buttons, reward dispensers, and player notifications, aswell as an overhaul of the environment's graphics and processing forsignificant improvements in agent training time and quality of the human playerexperience. We provide detailed guidance on how to build computational andbehavioural experiments with the Animal-AI Environment. We present results froma series of agents, including the state-of-the-art deep reinforcement learningagent Dreamer-v3, on newly designed tests and the Animal-AI Testbed of 900tasks inspired by research in the field of comparative cognition. The Animal-AIEnvironment offers a new approach for modelling cognition in humans andnon-human animals, and for building biologically inspired artificialintelligence.</description><author>Konstantinos Voudouris, Ibrahim Alhas, Wout Schellaert, Matteo G. Mecattaf, Ben Slater, Matthew Crosby, Joel Holmes, John Burden, Niharika Chaubey, Niall Donnelly, Matishalin Patel, Marta Halina, José Hernández-Orallo, Lucy G. Cheke</author><pubDate>Fri, 17 Jan 2025 15:08:47 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.11414v3</guid></item><item><title>Improving Zero-Shot Chinese-English Code-Switching ASR with kNN-CTC and Gated Monolingual Datastores</title><link>http://arxiv.org/abs/2406.03814v5</link><description>The kNN-CTC model has proven to be effective for monolingual automatic speechrecognition (ASR). However, its direct application to multilingual scenarioslike code-switching, presents challenges. Although there is potential forperformance improvement, a kNN-CTC model utilizing a single bilingual datastorecan inadvertently introduce undesirable noise from the alternative language. Toaddress this, we propose a novel kNN-CTC-based code-switching ASR (CS-ASR)framework that employs dual monolingual datastores and a gated datastoreselection mechanism to reduce noise interference. Our method selects theappropriate datastore for decoding each frame, ensuring the injection oflanguage-specific information into the ASR process. We apply this framework tocutting-edge CTC-based models, developing an advanced CS-ASR system. Extensiveexperiments demonstrate the remarkable effectiveness of our gated datastoremechanism in enhancing the performance of zero-shot Chinese-English CS-ASR.</description><author>Jiaming Zhou, Shiwan Zhao, Hui Wang, Tian-Hao Zhang, Haoqin Sun, Xuechen Wang, Yong Qin</author><pubDate>Fri, 17 Jan 2025 15:02:08 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.03814v5</guid></item><item><title>SpaceTime: Causal Discovery from Non-Stationary Time Series</title><link>http://arxiv.org/abs/2501.10235v1</link><description>Understanding causality is challenging and often complicated by changingcausal relationships over time and across environments. Climate patterns, forexample, shift over time with recurring seasonal trends, while also dependingon geographical characteristics such as ecosystem variability. Existing methodsfor discovering causal graphs from time series either assume stationarity, donot permit both temporal and spatial distribution changes, or are unaware oflocations with the same causal relationships. In this work, we therefore unifythe three tasks of causal graph discovery in the non-stationary multi-contextsetting, of reconstructing temporal regimes, and of partitioning datasets andtime intervals into those where invariant causal relationships hold. Toconstruct a consistent score that forms the basis of our method, we employ theMinimum Description Length principle. Our resulting algorithm SPACETIMEsimultaneously accounts for heterogeneity across space and non-stationarityover time. Given multiple time series, it discovers regime changepoints and atemporal causal graph using non-parametric functional modeling and kernelizeddiscrepancy testing. We also show that our method provides insights intoreal-world phenomena such as river-runoff measured at different catchments andbiosphere-atmosphere interactions across ecosystems.</description><author>Sarah Mameche, Lénaïg Cornanguer, Urmi Ninad, Jilles Vreeken</author><pubDate>Fri, 17 Jan 2025 15:00:20 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.10235v1</guid></item><item><title>Counterfactual Explanations for k-means and Gaussian Clustering</title><link>http://arxiv.org/abs/2501.10234v1</link><description>Counterfactuals have been recognized as an effective approach to explainclassifier decisions. Nevertheless, they have not yet been considered in thecontext of clustering. In this work, we propose the use of counterfactuals toexplain clustering solutions. First, we present a general definition forcounterfactuals for model-based clustering that includes plausibility andfeasibility constraints. Then we consider the counterfactual generation problemfor k-means and Gaussian clustering assuming Euclidean distance. Our approachtakes as input the factual, the target cluster, a binary mask indicatingactionable or immutable features and a plausibility factor specifying how farfrom the cluster boundary the counterfactual should be placed. In the k-meansclustering case, analytical mathematical formulas are presented for computingthe optimal solution, while in the Gaussian clustering case (assuming full,diagonal, or spherical covariances) our method requires the numerical solutionof a nonlinear equation with a single parameter only. We demonstrate theadvantages of our approach through illustrative examples and quantitativeexperimental comparisons.</description><author>Georgios Vardakas, Antonia Karra, Evaggelia Pitoura, Aristidis Likas</author><pubDate>Fri, 17 Jan 2025 14:56:20 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.10234v1</guid></item><item><title>Amortized Bayesian Mixture Models</title><link>http://arxiv.org/abs/2501.10229v1</link><description>Finite mixtures are a broad class of models useful in scenarios whereobserved data is generated by multiple distinct processes but without explicitinformation about the responsible process for each data point. EstimatingBayesian mixture models is computationally challenging due to issues such ashigh-dimensional posterior inference and label switching. Furthermore,traditional methods such as MCMC are applicable only if the likelihoods foreach mixture component are analytically tractable. Amortized Bayesian Inference (ABI) is a simulation-based framework forestimating Bayesian models using generative neural networks. This allows thefitting of models without explicit likelihoods, and provides fast inference.ABI is therefore an attractive framework for estimating mixture models. Thispaper introduces a novel extension of ABI tailored to mixture models. Wefactorize the posterior into a distribution of the parameters and adistribution of (categorical) mixture indicators, which allows us to use acombination of generative neural networks for parameter inference, andclassification networks for mixture membership identification. The proposedframework accommodates both independent and dependent mixture models, enablingfiltering and smoothing. We validate and demonstrate our approach throughsynthetic and real-world datasets.</description><author>Šimon Kucharský, Paul Christian Bürkner</author><pubDate>Fri, 17 Jan 2025 14:51:03 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.10229v1</guid></item><item><title>Modelling Activity Scheduling Behaviour with Deep Generative Machine Learning</title><link>http://arxiv.org/abs/2501.10221v1</link><description>We model human activity scheduling behaviour using a deep generative machinelearning approach. Activity schedules, which represent the activities andassociated travel behaviours of individuals, are a core component of manyapplied models in the transport, energy and epidemiology domains. Our datadriven approach learns human preferences and scheduling logic without the needfor complex interacting combinations of sub-models and custom-rules, this makesour approach significantly faster and simpler to operate that existingapproaches. We find activity schedule data combines aspects of both continuousimage data and also discrete text data, requiring novel approaches. Weadditionally contribute a novel schedule representation and comprehensiveevaluation framework for generated schedules. Evaluation shows our approach isable to rapidly generate large, diverse and realistic synthetic samples ofactivity schedules.</description><author>Fred Shone, Tim Hillel</author><pubDate>Fri, 17 Jan 2025 14:37:54 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.10221v1</guid></item><item><title>Robust Egoistic Rigid Body Localization</title><link>http://arxiv.org/abs/2501.10219v1</link><description>We consider a robust and self-reliant (or "egoistic") variation of the rigidbody localization (RBL) problem, in which a primary rigid body seeks toestimate the pose (i.e., location and orientation) of another rigid body (or"target"), relative to its own, without the assistance of externalinfrastructure, without prior knowledge of the shape of the target, and takinginto account the possibility that the available observations are incomplete.Three complementary contributions are then offered for such a scenario. Thefirst is a method to estimate the translation vector between the center pointof both rigid bodies, which unlike existing techniques does not require thatboth objects have the same shape or even the same number of landmark points.This technique is shown to significantly outperform the state-of-the-art (SotA)under complete information, but to be sensitive to data erasures, even whenenhanced by matrix completion methods. The second contribution, designed tooffer improved performance in the presence of incomplete information, offers arobust alternative to the latter, at the expense of a slight relative lossunder complete information. Finally, the third contribution is a scheme for theestimation of the rotation matrix describing the relative orientation of thetarget rigid body with respect to the primary. Comparisons of the proposedschemes and SotA techniques demonstrate the advantage of the contributedmethods in terms of root mean square error (RMSE) performance under fullycomplete information and incomplete conditions.</description><author>Niclas Führling, Giuseppe Thadeu Freitas de Abreu, David González G., Osvaldo Gonsa</author><pubDate>Fri, 17 Jan 2025 14:33:05 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.10219v1</guid></item><item><title>Optimal Quantization for Matrix Multiplication</title><link>http://arxiv.org/abs/2410.13780v2</link><description>Recent work in machine learning community proposed multiple methods forperforming lossy compression (quantization) of large matrices. Thisquantization is important for accelerating matrix multiplication (maincomponent of large language models), which is often bottlenecked by the speedof loading these matrices from memory. Unlike classical vector quantization andrate-distortion theory, the goal of these new compression algorithms is to beable to approximate not the matrices themselves, but their matrix product.Specifically, given a pair of real matrices $A,B$ an encoder (compressor) isapplied to each of them independently producing descriptions with $R$ bits perentry. These representations subsequently are used by the decoder to estimatematrix product $A^\top B$. In this work, we provide a non-asymptotic lowerbound on the mean squared error of this approximation (as a function of rate$R$) for the case of matrices $A,B$ with iid Gaussian entries. Algorithmically,we construct a universal quantizer based on nested lattices with an explicitguarantee of approximation error for any (non-random) pair of matrices $A$, $B$in terms of only Frobenius norms $\|\bar{A}\|_F, \|\bar{B}\|_F$ and$\|\bar{A}^\top \bar{B}\|_F$, where $\bar{A},\bar{B}$ are versions of $A,B$with zero-centered columns, respectively. For iid Gaussian matrices ourquantizer achieves the lower bound and is, thus, asymptotically optimal. Apractical low-complexity version of our quantizer achieves performance quiteclose to optimal. In addition, we derive rate-distortion function for matrixmultiplication of iid Gaussian matrices, which exhibits an interestingphase-transition at $R\approx 0.906$ bit/entry.</description><author>Or Ordentlich, Yury Polyanskiy</author><pubDate>Fri, 17 Jan 2025 14:26:37 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.13780v2</guid></item><item><title>The Relevance of AWS Chronos: An Evaluation of Standard Methods for Time Series Forecasting with Limited Tuning</title><link>http://arxiv.org/abs/2501.10216v1</link><description>A systematic comparison of Chronos, a transformer-based time seriesforecasting framework, against traditional approaches including ARIMA andProphet. We evaluate these models across multiple time horizons and usercategories, with a focus on the impact of historical context length. Ouranalysis reveals that while Chronos demonstrates superior performance forlonger-term predictions and maintains accuracy with increased context,traditional models show significant degradation as context length increases. Wefind that prediction quality varies systematically between user classes,suggesting that underlying behavior patterns always influence modelperformance. This study provides a case for deploying Chronos in real-worldapplications where limited model tuning is feasible, especially in scenariosrequiring longer prediction.</description><author>Matthew Baron, Alex Karpinski</author><pubDate>Fri, 17 Jan 2025 14:23:54 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.10216v1</guid></item><item><title>Deep Compression Autoencoder for Efficient High-Resolution Diffusion Models</title><link>http://arxiv.org/abs/2410.10733v5</link><description>We present Deep Compression Autoencoder (DC-AE), a new family of autoencodermodels for accelerating high-resolution diffusion models. Existing autoencodermodels have demonstrated impressive results at a moderate spatial compressionratio (e.g., 8x), but fail to maintain satisfactory reconstruction accuracy forhigh spatial compression ratios (e.g., 64x). We address this challenge byintroducing two key techniques: (1) Residual Autoencoding, where we design ourmodels to learn residuals based on the space-to-channel transformed features toalleviate the optimization difficulty of high spatial-compression autoencoders;(2) Decoupled High-Resolution Adaptation, an efficient decoupled three-phasestraining strategy for mitigating the generalization penalty of highspatial-compression autoencoders. With these designs, we improve theautoencoder's spatial compression ratio up to 128 while maintaining thereconstruction quality. Applying our DC-AE to latent diffusion models, weachieve significant speedup without accuracy drop. For example, on ImageNet512x512, our DC-AE provides 19.1x inference speedup and 17.9x training speedupon H100 GPU for UViT-H while achieving a better FID, compared with the widelyused SD-VAE-f8 autoencoder. Our code is available athttps://github.com/mit-han-lab/efficientvit.</description><author>Junyu Chen, Han Cai, Junsong Chen, Enze Xie, Shang Yang, Haotian Tang, Muyang Li, Yao Lu, Song Han</author><pubDate>Fri, 17 Jan 2025 14:22:06 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.10733v5</guid></item><item><title>Temporal Graph MLP Mixer for Spatio-Temporal Forecasting</title><link>http://arxiv.org/abs/2501.10214v1</link><description>Spatiotemporal forecasting is critical in applications such as trafficprediction, climate modeling, and environmental monitoring. However, theprevalence of missing data in real-world sensor networks significantlycomplicates this task. In this paper, we introduce the Temporal Graph MLP-Mixer(T-GMM), a novel architecture designed to address these challenges. The modelcombines node-level processing with patch-level subgraph encoding to capturelocalized spatial dependencies while leveraging a three-dimensional MLP-Mixerto handle temporal, spatial, and feature-based dependencies. Experiments on theAQI, ENGRAD, PV-US and METR-LA datasets demonstrate the model's ability toeffectively forecast even in the presence of significant missing data. Whilenot surpassing state-of-the-art models in all scenarios, the T-GMM exhibitsstrong learning capabilities, particularly in capturing long-rangedependencies. These results highlight its potential for robust, scalablespatiotemporal forecasting.</description><author>Muhammad Bilal, Luis Carretero Lopez</author><pubDate>Fri, 17 Jan 2025 14:13:48 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.10214v1</guid></item><item><title>Disharmony: Forensics using Reverse Lighting Harmonization</title><link>http://arxiv.org/abs/2501.10212v1</link><description>Content generation and manipulation approaches based on deep learning methodshave seen significant advancements, leading to an increased need for techniquesto detect whether an image has been generated or edited. Another area ofresearch focuses on the insertion and harmonization of objects within images.In this study, we explore the potential of using harmonization data inconjunction with a segmentation model to enhance the detection of edited imageregions. These edits can be either manually crafted or generated using deeplearning methods. Our findings demonstrate that this approach can effectivelyidentify such edits. Existing forensic models often overlook the detection ofharmonized objects in relation to the background, but our proposed DisharmonyNetwork addresses this gap. By utilizing an aggregated dataset of harmonizationtechniques, our model outperforms existing forensic networks in identifyingharmonized objects integrated into their backgrounds, and shows potential fordetecting various forms of edits, including virtual try-on tasks.</description><author>Philip Wootaek Shin, Jack Sampson, Vijaykrishnan Narayanan, Andres Marquez, Mahantesh Halappanavar</author><pubDate>Fri, 17 Jan 2025 14:12:52 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.10212v1</guid></item><item><title>DPCL-Diff: The Temporal Knowledge Graph Reasoning Based on Graph Node Diffusion Model with Dual-Domain Periodic Contrastive Learning</title><link>http://arxiv.org/abs/2411.01477v2</link><description>Temporal knowledge graph (TKG) reasoning that infers future missing facts isan essential and challenging task. Predicting future events typically relies onclosely related historical facts, yielding more accurate results for repetitiveor periodic events. However, for future events with sparse historicalinteractions, the effectiveness of this method, which focuses on leveraginghigh-frequency historical information, diminishes. Recently, the capabilitiesof diffusion models in image generation have opened new opportunities for TKGreasoning. Therefore, we propose a graph node diffusion model with dual-domainperiodic contrastive learning (DPCL-Diff). Graph node diffusion model (GNDiff)introduces noise into sparsely related events to simulate new events,generating high-quality data that better conforms to the actual distribution.This generative mechanism significantly enhances the model's ability to reasonabout new events. Additionally, the dual-domain periodic contrastive learning(DPCL) maps periodic and non-periodic event entities to Poincar\'e andEuclidean spaces, leveraging their characteristics to distinguish similarperiodic events effectively. Experimental results on four public datasetsdemonstrate that DPCL-Diff significantly outperforms state-of-the-art TKGmodels in event prediction, demonstrating our approach's effectiveness. Thisstudy also investigates the combined effectiveness of GNDiff and DPCL in TKGtasks.</description><author>Yukun Cao, Lisheng Wang, Luobin Huang</author><pubDate>Fri, 17 Jan 2025 14:10:15 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2411.01477v2</guid></item><item><title>Hypercone Assisted Contour Generation for Out-of-Distribution Detection</title><link>http://arxiv.org/abs/2501.10209v1</link><description>Recent advances in the field of out-of-distribution (OOD) detection haveplaced great emphasis on learning better representations suited to this task.While there are distance-based approaches, distributional awareness has seldombeen exploited for better performance. We present HAC$_k$-OOD, a novel OODdetection method that makes no distributional assumption about the data, butautomatically adapts to its distribution. Specifically, HAC$_k$-OOD constructsa set of hypercones by maximizing the angular distance to neighbors in a givendata-point's vicinity to approximate the contour within which in-distribution(ID) data-points lie. Experimental results show state-of-the-art FPR@95 andAUROC performance on Near-OOD detection and on Far-OOD detection on thechallenging CIFAR-100 benchmark without explicitly training for OODperformance.</description><author>Annita Vapsi, Andrés Muñoz, Nancy Thomas, Keshav Ramani, Daniel Borrajo</author><pubDate>Fri, 17 Jan 2025 14:08:32 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.10209v1</guid></item><item><title>Jailbreaking as a Reward Misspecification Problem</title><link>http://arxiv.org/abs/2406.14393v4</link><description>The widespread adoption of large language models (LLMs) has raised concernsabout their safety and reliability, particularly regarding their vulnerabilityto adversarial attacks. In this paper, we propose a novel perspective thatattributes this vulnerability to reward misspecification during the alignmentprocess. This misspecification occurs when the reward function fails toaccurately capture the intended behavior, leading to misaligned model outputs.We introduce a metric ReGap to quantify the extent of reward misspecificationand demonstrate its effectiveness and robustness in detecting harmful backdoorprompts. Building upon these insights, we present ReMiss, a system forautomated red teaming that generates adversarial prompts in areward-misspecified space. ReMiss achieves state-of-the-art attack successrates on the AdvBench benchmark against various target aligned LLMs whilepreserving the human readability of the generated prompts. Furthermore, theseattacks on open-source models demonstrate high transferability to closed-sourcemodels like GPT-4o and out-of-distribution tasks from HarmBench. Detailedanalysis highlights the unique advantages of the proposed rewardmisspecification objective compared to previous methods, offering new insightsfor improving LLM safety and robustness.</description><author>Zhihui Xie, Jiahui Gao, Lei Li, Zhenguo Li, Qi Liu, Lingpeng Kong</author><pubDate>Fri, 17 Jan 2025 13:56:50 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.14393v4</guid></item><item><title>Provably Safeguarding a Classifier from OOD and Adversarial Samples: an Extreme Value Theory Approach</title><link>http://arxiv.org/abs/2501.10202v1</link><description>This paper introduces a novel method, Sample-efficient ProbabilisticDetection using Extreme Value Theory (SPADE), which transforms a classifierinto an abstaining classifier, offering provable protection againstout-of-distribution and adversarial samples. The approach is based on aGeneralized Extreme Value (GEV) model of the training distribution in theclassifier's latent space, enabling the formal characterization of OOD samples.Interestingly, under mild assumptions, the GEV model also allows for formallycharacterizing adversarial samples. The abstaining classifier, which rejectssamples based on their assessment by the GEV model, provably avoids OOD andadversarial samples. The empirical validation of the approach, conducted onvarious neural architectures (ResNet, VGG, and Vision Transformer) and mediumand large-sized datasets (CIFAR-10, CIFAR-100, and ImageNet), demonstrates itsfrugality, stability, and efficiency compared to the state of the art.</description><author>Nicolas Atienza, Christophe Labreuche, Johanne Cohen, Michele Sebag</author><pubDate>Fri, 17 Jan 2025 13:51:14 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.10202v1</guid></item><item><title>Adaptive Clustering for Efficient Phenotype Segmentation of UAV Hyperspectral Data</title><link>http://arxiv.org/abs/2501.10199v1</link><description>Unmanned Aerial Vehicles (UAVs) combined with Hyperspectral imaging (HSI)offer potential for environmental and agricultural applications by capturingdetailed spectral information that enables the prediction of invisible featureslike biochemical leaf properties. However, the data-intensive nature of HSIposes challenges for remote devices, which have limited computational resourcesand storage. This paper introduces an Online Hyperspectral Simple LinearIterative Clustering algorithm (OHSLIC) framework for real-time tree phenotypesegmentation. OHSLIC reduces inherent noise and computational demands throughadaptive incremental clustering and a lightweight neural network, whichphenotypes trees using leaf contents such as chlorophyll, carotenoids, andanthocyanins. A hyperspectral dataset is created using a custom simulator thatincorporates realistic leaf parameters, and light interactions. Resultsdemonstrate that OHSLIC achieves superior regression accuracy and segmentationperformance compared to pixel- or window-based methods while significantlyreducing inference time. The method`s adaptive clustering enables dynamictrade-offs between computational efficiency and accuracy, paving the way forscalable edge-device deployment in HSI applications.</description><author>Ciem Cornelissen, Sam Leroux, Pieter Simoens</author><pubDate>Fri, 17 Jan 2025 13:48:04 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.10199v1</guid></item><item><title>CSHNet: A Novel Information Asymmetric Image Translation Method</title><link>http://arxiv.org/abs/2501.10197v1</link><description>Despite advancements in cross-domain image translation, challenges persist inasymmetric tasks such as SAR-to-Optical and Sketch-to-Instance conversions,which involve transforming data from a less detailed domain into one withricher content. Traditional CNN-based methods are effective at capturing finedetails but struggle with global structure, leading to unwanted merging ofimage regions. To address this, we propose the CNN-Swin Hybrid Network(CSHNet), which combines two key modules: Swin Embedded CNN (SEC) and CNNEmbedded Swin (CES), forming the SEC-CES-Bottleneck (SCB). SEC leverages CNN'sdetailed feature extraction while integrating the Swin Transformer's structuralbias. CES, in turn, preserves the Swin Transformer's global integrity,compensating for CNN's lack of focus on structure. Additionally, CSHNetincludes two components designed to enhance cross-domain information retention:the Interactive Guided Connection (IGC), which enables dynamic informationexchange between SEC and CES, and Adaptive Edge Perception Loss (AEPL), whichmaintains structural boundaries during translation. Experimental results showthat CSHNet outperforms existing methods in both visual quality and performancemetrics across scene-level and instance-level datasets. Our code is availableat: https://github.com/XduShi/CSHNet.</description><author>Xi Yang, Haoyuan Shi, Zihan Wang, Nannan Wang, Xinbo Gao</author><pubDate>Fri, 17 Jan 2025 13:44:54 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.10197v1</guid></item><item><title>Boosting drug-disease association prediction for drug repositioning via dual-feature extraction and cross-dual-domain decoding</title><link>http://arxiv.org/abs/2407.11812v4</link><description>The extraction of biomedical data has significant academic and practicalvalue in contemporary biomedical sciences. In recent years, drug repositioning,a cost-effective strategy for drug development by discovering new indicationsfor approved drugs, has gained increasing attention. However, many existingdrug repositioning methods focus on mining information from adjacent nodes inbiomedical networks without considering the potential inter-relationshipsbetween the feature spaces of drugs and diseases. This can lead to inaccurateencoding, resulting in biased mined drug-disease association information. Toaddress this limitation, we propose a new model called Dual-Feature DrugRepurposing Neural Network (DFDRNN). DFDRNN allows the mining of two features(similarity and association) from the drug-disease biomedical networks toencode drugs and diseases. A self-attention mechanism is utilized to extractneighbor feature information. It incorporates two dual-feature extractionmodules: the single-domain dual-feature extraction (SDDFE) module forextracting features within a single domain (drugs or diseases) and thecross-domain dual-feature extraction (CDDFE) module for extracting featuresacross domains. By utilizing these modules, we ensure more appropriate encodingof drugs and diseases. A cross-dual-domain decoder is also designed to predictdrug-disease associations in both domains. Our proposed DFDRNN modeloutperforms six state-of-the-art methods on four benchmark datasets, achievingan average AUROC of 0.946 and an average AUPR of 0.597. Case studies on twodiseases show that the proposed DFDRNN model can be applied in real-worldscenarios, demonstrating its significant potential in drug repositioning.</description><author>Enqiang Zhu, Xiang Li, Chanjuan Liu, Nikhil R. Pal</author><pubDate>Fri, 17 Jan 2025 13:42:32 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.11812v4</guid></item><item><title>Contributions to the Decision Theoretic Foundations of Machine Learning and Robust Statistics under Weakly Structured Information</title><link>http://arxiv.org/abs/2501.10195v1</link><description>This habilitation thesis is cumulative and, therefore, is collecting andconnecting research that I (together with several co-authors) have conductedover the last few years. Thus, the absolute core of the work is formed by theten publications listed on page 5 under the name Contributions 1 to 10. Thereferences to the complete versions of these articles are also found in thislist, making them as easily accessible as possible for readers wishing to divedeep into the different research projects. The chapters following this thesis,namely Parts A to C and the concluding remarks, serve to place the articles ina larger scientific context, to (briefly) explain their respective content on aless formal level, and to highlight some interesting perspectives for futureresearch in their respective contexts. Naturally, therefore, the followingpresentation has neither the level of detail nor the formal rigor that can(hopefully) be found in the papers. The purpose of the following text is toprovide the reader an easy and high-level access to this interesting andimportant research field as a whole, thereby, advertising it to a broaderaudience.</description><author>Christoph Jansen</author><pubDate>Fri, 17 Jan 2025 13:39:51 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.10195v1</guid></item><item><title>Surrogate-based multiscale analysis of experiments on thermoplastic composites under off-axis loading</title><link>http://arxiv.org/abs/2501.10193v1</link><description>In this paper, we present a surrogate-based multiscale approach to modelconstant strain-rate and creep experiments on unidirectional thermoplasticcomposites under off-axis loading. In previous contributions, these experimentswere modeled through a single-scale micromechanical simulation under theassumption of macroscopic homogeneity. Although efficient and accurate in manyscenarios, simulations with low-off axis angles showed significantdiscrepancies with the experiments. It was hypothesized that the mismatch wascaused by macroscopic inhomogeneity, which would require a multiscale approachto capture it. However, full-field multiscale simulations remaincomputationally prohibitive. To address this issue, we replace the micromodelwith a Physically Recurrent Neural Network (PRNN), a surrogate model thatcombines data-driven components with embedded constitutive models to capturehistory-dependent behavior naturally. The explainability of the latent space ofthis network is also explored in a transfer learning strategy that requires nore-training. With the surrogate-based simulations, we confirm the hypothesisraised on the inhomogeneity of the macroscopic strain field and gain insightsinto the influence of adjustment of the experimental setup with obliqueend-tabs. Results from the surrogate-based multiscale approach show betteragreement with experiments than the single-scale micromechanical approach overa wide range of settings, although with limited accuracy on the creepexperiments, where macroscopic test effects were implicitly taken into accountin the material properties calibration.</description><author>M. A. Maia, I. B. C. M. Rocha, D. Kovačević, F. P. van der Meer</author><pubDate>Fri, 17 Jan 2025 13:39:10 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.10193v1</guid></item><item><title>Temporal Causal Reasoning with (Non-Recursive) Structural Equation Models</title><link>http://arxiv.org/abs/2501.10190v1</link><description>Structural Equation Models (SEM) are the standard approach to representingcausal dependencies between variables in causal models. In this paper wepropose a new interpretation of SEMs when reasoning about Actual Causality, inwhich SEMs are viewed as mechanisms transforming the dynamics of exogenousvariables into the dynamics of endogenous variables. This allows us to combinecounterfactual causal reasoning with existing temporal logic formalisms, and tointroduce a temporal logic, CPLTL, for causal reasoning about such structures.We show that the standard restriction to so-called \textit{recursive} models(with no cycles in the dependency graph) is not necessary in our approach,allowing us to reason about mutually dependent processes and feedback loops.Finally, we introduce new notions of model equivalence for temporal causalmodels, and show that CPLTL has an efficient model-checking procedure.</description><author>Maksim Gladyshev, Natasha Alechina, Mehdi Dastani, Dragan Doder, Brian Logan</author><pubDate>Fri, 17 Jan 2025 13:37:58 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.10190v1</guid></item><item><title>Bandit on the Hunt: Dynamic Crawling for Cyber Threat Intelligence</title><link>http://arxiv.org/abs/2304.11960v3</link><description>Public information contains valuable Cyber Threat Intelligence (CTI) that isused to prevent attacks in the future. Ideally, the learnings from previousattacks help to mitigate all those that follow. While there are standards forsharing this information, much of it is shared in non-standardized newsarticles or blog posts. It is a time-consuming task to monitor online sourcesfor threats and even then, one can never be sure, to use the right sources.Current research propose extractors of Indicators of Compromise from knownsources, while the identification of new sources is rarely considered. Thispaper proposes a focused crawler focused on the CTI domain based on multi-armedbandit ( MAB) and different crawling strategies. It uses SBERT to identifyrelevant documents, while dynamically adapt its crawling path. We propose asystem called ThreatCrawl, which achieve a harvest rate of over 25% and is ableto expand its used seed by over 300%, while retaining focus on the topic athand. In addition, this crawler identified previously unknown but highlyrelevant overview pages, datasets, and domains.</description><author>Philipp Kuehn, Dilara Nadermahmoodi, Markus Bayer, Christian Reuter</author><pubDate>Fri, 17 Jan 2025 13:34:49 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2304.11960v3</guid></item><item><title>Good things come in small packages: Should we adopt Lite-GPUs in AI infrastructure?</title><link>http://arxiv.org/abs/2501.10187v1</link><description>To match the blooming demand of generative AI workloads, GPU designers haveso far been trying to pack more and more compute and memory into single complexand expensive packages. However, there is growing uncertainty about thescalability of individual GPUs and thus AI clusters, as state-of-the-art GPUsare already displaying packaging, yield, and cooling limitations. We propose torethink the design and scaling of AI clusters through efficiently-connectedlarge clusters of Lite-GPUs, GPUs with single, small dies and a fraction of thecapabilities of larger GPUs. We think recent advances in co-packaged optics canbe key in overcoming the communication challenges of distributing AI workloadsonto more Lite-GPUs. In this paper, we present the key benefits of Lite-GPUs onmanufacturing cost, blast radius, yield, and power efficiency; and discusssystems opportunities and challenges around resource, workload, memory, andnetwork management.</description><author>Burcu Canakci, Junyi Liu, Xingbo Wu, Nathanaël Cheriere, Paolo Costa, Sergey Legtchenko, Dushyanth Narayanan, Ant Rowstron</author><pubDate>Fri, 17 Jan 2025 13:32:28 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.10187v1</guid></item><item><title>Generative Artificial Intelligence: Implications for Biomedical and Health Professions Education</title><link>http://arxiv.org/abs/2501.10186v1</link><description>Generative AI has had a profound impact on biomedicine and health, both inprofessional work and in education. Based on large language models (LLMs),generative AI has been found to perform as well as humans in simulatedsituations taking medical board exams, answering clinical questions, solvingclinical cases, applying clinical reasoning, and summarizing information.Generative AI is also being used widely in education, performing well inacademic courses and their assessments. This review summarizes the successes ofLLMs and highlights some of their challenges in the context of education, mostnotably aspects that may undermines the acquisition of knowledge and skills forprofessional work. It then provides recommendations for best practicesovercoming shortcomings for LLM use in education. Although there are challengesfor use of generative AI in education, all students and faculty, in biomedicineand health and beyond, must have understanding and be competent in its use.</description><author>William Hersh</author><pubDate>Fri, 17 Jan 2025 13:32:19 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.10186v1</guid></item><item><title>Generate E-commerce Product Background by Integrating Category Commonality and Personalized Style</title><link>http://arxiv.org/abs/2312.13309v2</link><description>The state-of-the-art methods for e-commerce product background generationsuffer from the inefficiency of designing product-wise prompts when scaling upthe production, as well as the ineffectiveness of describing fine-grainedstyles when customizing personalized backgrounds for some specific brands. Toaddress these obstacles, we integrate the category commonality and personalizedstyle into diffusion models. Concretely, we propose a Category-Wise Generatorto enable large-scale background generation with only one model for the firsttime. A unique identifier in the prompt is assigned to each category, whoseattention is located on the background by a mask-guided cross attention layerto learn the category-wise style. Furthermore, for products with specific andfine-grained requirements in layout, elements, etc, a Personality-WiseGenerator is devised to learn such personalized style directly from a referenceimage to resolve textual ambiguities, and is trained in a self-supervisedmanner for more efficient training data usage. To advance research in thisfield, the first large-scale e-commerce product background generation datasetBG60k is constructed, which covers more than 60k product images from over 2kcategories. Experiments demonstrate that our method could generate high-qualitybackgrounds for different categories, and maintain the personalized backgroundstyle of reference images. BG60k will be available at\url{https://github.com/Whileherham/BG60k}.</description><author>Haohan Wang, Wei Feng, Yaoyu Li, Zheng Zhang, Jingjing Lv, Junjie Shen, Zhangang Lin, Jingping Shao</author><pubDate>Fri, 17 Jan 2025 13:28:01 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.13309v2</guid></item><item><title>Improved learning rates in multi-unit uniform price auctions</title><link>http://arxiv.org/abs/2501.10181v1</link><description>Motivated by the strategic participation of electricity producers inelectricity day-ahead market, we study the problem of online learning inrepeated multi-unit uniform price auctions focusing on the adversarial opposingbid setting. The main contribution of this paper is the introduction of a newmodeling of the bid space. Indeed, we prove that a learning algorithmleveraging the structure of this problem achieves a regret of$\tilde{O}(K^{4/3}T^{2/3})$ under bandit feedback, improving over the bound of$\tilde{O}(K^{7/4}T^{3/4})$ previously obtained in the literature. Thisimproved regret rate is tight up to logarithmic terms. Inspired by electricityreserve markets, we further introduce a different feedback model under whichall winning bids are revealed. This feedback interpolates between thefull-information and bandit scenarios depending on the auctions' results. Weprove that, under this feedback, the algorithm that we propose achieves regret$\tilde{O}(K^{5/2}\sqrt{T})$.</description><author>Marius Potfer, Dorian Baudry, Hugo Richard, Vianney Perchet, Cheng Wan</author><pubDate>Fri, 17 Jan 2025 13:26:12 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.10181v1</guid></item><item><title>A Simple but Effective Closed-form Solution for Extreme Multi-label Learning</title><link>http://arxiv.org/abs/2501.10179v1</link><description>Extreme multi-label learning (XML) is a task of assigning multiple labelsfrom an extremely large set of labels to each data instance. Many currenthigh-performance XML models are composed of a lot of hyperparameters, whichcomplicates the tuning process. Additionally, the models themselves are adaptedspecifically to XML, which complicates their reimplementation. To remedy thisproblem, we propose a simple method based on ridge regression for XML. Theproposed method not only has a closed-form solution but also is composed of asingle hyperparameter. Since there are no precedents on applying ridgeregression to XML, this paper verified the performance of the method by usingvarious XML benchmark datasets. Furthermore, we enhanced the prediction oflow-frequency labels in XML, which hold informative content. This prediction isessential yet challenging because of the limited amount of data. Here, weemployed a simple frequency-based weighting. This approach greatly simplifiesthe process compared with existing techniques. Experimental results revealedthat it can achieve levels of performance comparable to, or even exceeding,those of models with numerous hyperparameters. Additionally, we found that thefrequency-based weighting significantly improved the predictive performance forlow-frequency labels, while requiring almost no changes in implementation. Thesource code for the proposed method is available on github athttps://github.com/cars1015/XML-ridge.</description><author>Kazuma Onishi, Katsuhiko Hayashi</author><pubDate>Fri, 17 Jan 2025 13:24:13 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.10179v1</guid></item><item><title>LayerAnimate: Layer-specific Control for Animation</title><link>http://arxiv.org/abs/2501.08295v2</link><description>Animated video separates foreground and background elements into layers, withdistinct processes for sketching, refining, coloring, and in-betweening.Existing video generation methods typically treat animation as a monolithicdata domain, lacking fine-grained control over individual layers. In thispaper, we introduce LayerAnimate, a novel architectural approach that enhancesfine-grained control over individual animation layers within a video diffusionmodel, allowing users to independently manipulate foreground and backgroundelements in distinct layers. To address the challenge of limited layer-specificdata, we propose a data curation pipeline that features automated elementsegmentation, motion-state hierarchical merging, and motion coherencerefinement. Through quantitative and qualitative comparisons, and user study,we demonstrate that LayerAnimate outperforms current methods in terms ofanimation quality, control precision, and usability, making it an ideal toolfor both professional animators and amateur enthusiasts. This framework opensup new possibilities for layer-specific animation applications and creativeflexibility. Our code is available at https://layeranimate.github.io.</description><author>Yuxue Yang, Lue Fan, Zuzeng Lin, Feng Wang, Zhaoxiang Zhang</author><pubDate>Fri, 17 Jan 2025 13:22:51 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.08295v2</guid></item><item><title>Multi-stage Training of Bilingual Islamic LLM for Neural Passage Retrieval</title><link>http://arxiv.org/abs/2501.10175v1</link><description>This study examines the use of Natural Language Processing (NLP) technologywithin the Islamic domain, focusing on developing an Islamic neural retrievalmodel. By leveraging the robust XLM-R model, the research employs a languagereduction technique to create a lightweight bilingual large language model(LLM). Our approach for domain adaptation addresses the unique challenges facedin the Islamic domain, where substantial in-domain corpora exist only in Arabicwhile limited in other languages, including English. The work utilizes a multi-stage training process for retrieval models,incorporating large retrieval datasets, such as MS MARCO, and smaller,in-domain datasets to improve retrieval performance. Additionally, we havecurated an in-domain retrieval dataset in English by employing dataaugmentation techniques and involving a reliable Islamic source. This approachenhances the domain-specific dataset for retrieval, leading to furtherperformance gains. The findings suggest that combining domain adaptation and a multi-stagetraining method for the bilingual Islamic neural retrieval model enables it tooutperform monolingual models on downstream retrieval tasks.</description><author>Vera Pavlova</author><pubDate>Fri, 17 Jan 2025 13:17:42 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.10175v1</guid></item><item><title>Optimal Restart Strategies for Parameter-dependent Optimization Algorithms</title><link>http://arxiv.org/abs/2501.10173v1</link><description>This paper examines restart strategies for algorithms whose successfultermination depends on an unknown parameter $\lambda$. After each restart,$\lambda$ is increased, until the algorithm terminates successfully. It isassumed that there is a unique, unknown, optimal value for $\lambda$. For thealgorithm to run successfully, this value must be reached or surpassed. The keyquestion is whether there exists an optimal strategy for selecting $\lambda$after each restart taking into account that the computational costs (runtime)increases with $\lambda$. In this work, potential restart strategies areclassified into parameter-dependent strategy types. A loss function isintroduced to quantify the wasted computational cost relative to the optimalstrategy. A crucial requirement for any efficient restart strategy is that itsloss, relative to the optimal $\lambda$, remains bounded. To this end, upperand lower bounds of the loss are derived. Using these bounds it will be shownthat not all strategy types are bounded. However, for a particular strategytype, where $\lambda$ is increased multiplicatively by a constant factor$\lambda$, the relative loss function is bounded. Furthermore, it will bedemonstrated that within this strategy type, there exists an optimal value for$\lambda$ that minimizes the maximum relative loss. In the asymptotic limit,this optimal choice of $\lambda$ does not depend on the unknown optimal$\lambda$.</description><author>Lisa Schönenberger, Hans-Georg Beyer</author><pubDate>Fri, 17 Jan 2025 13:14:53 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.10173v1</guid></item><item><title>Mean and Variance Estimation Complexity in Arbitrary Distributions via Wasserstein Minimization</title><link>http://arxiv.org/abs/2501.10172v1</link><description>Parameter estimation is a fundamental challenge in machine learning, crucialfor tasks such as neural network weight fitting and Bayesian inference. Thispaper focuses on the complexity of estimating translation $\boldsymbol{\mu} \in\mathbb{R}^l$ and shrinkage $\sigma \in \mathbb{R}_{++}$ parameters for adistribution of the form $\frac{1}{\sigma^l} f_0 \left( \frac{\boldsymbol{x} -\boldsymbol{\mu}}{\sigma} \right)$, where $f_0$ is a known density in$\mathbb{R}^l$ given $n$ samples. We highlight that while the problem isNP-hard for Maximum Likelihood Estimation (MLE), it is possible to obtain$\varepsilon$-approximations for arbitrary $\varepsilon &gt; 0$ within$\text{poly} \left( \frac{1}{\varepsilon} \right)$ time using the Wassersteindistance.</description><author>Valentio Iverson, Stephen Vavasis</author><pubDate>Fri, 17 Jan 2025 13:07:52 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.10172v1</guid></item><item><title>Convex Physics Informed Neural Networks for the Monge-Ampère Optimal Transport Problem</title><link>http://arxiv.org/abs/2501.10162v1</link><description>Optimal transportation of raw material from suppliers to customers is anissue arising in logistics that is addressed here with a continuous modelrelying on optimal transport theory. A physics informed neuralnetwork method isadvocated here for the solution of the corresponding generalized Monge-Amp`ereequation. Convex neural networks are advocated to enforce the convexity of thesolution to the Monge-Amp\`ere equation and obtain a suitable approximation ofthe optimal transport map. A particular focus is set on the enforcement oftransport boundary conditions in the loss function. Numerical experimentsillustrate the solution to the optimal transport problem in severalconfigurations, and sensitivity analyses are performed.</description><author>Alexandre Caboussat, Anna Peruso</author><pubDate>Fri, 17 Jan 2025 12:51:25 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.10162v1</guid></item><item><title>CSSDM Ontology to Enable Continuity of Care Data Interoperability</title><link>http://arxiv.org/abs/2501.10160v1</link><description>The rapid advancement of digital technologies and recent global pandemicscenarios have led to a growing focus on how these technologies can enhancehealthcare service delivery and workflow to address crises. Action plans thatconsolidate existing digital transformation programs are being reviewed toestablish core infrastructure and foundations for sustainable healthcaresolutions. Reforming health and social care to personalize home care, forexample, can help avoid treatment in overcrowded acute hospital settings andimprove the experiences and outcomes for both healthcare professionals andservice users. In this information-intensive domain, addressing theinteroperability challenge through standards-based roadmaps is crucial forenabling effective connections between health and social care services. Thisapproach facilitates safe and trustworthy data workflows between differenthealthcare system providers. In this paper, we present a methodology forextracting, transforming, and loading data through a semi-automated processusing a Common Semantic Standardized Data Model (CSSDM) to create personalizedhealthcare knowledge graph (KG). The CSSDM is grounded in the formal ontologyof ISO 13940 ContSys and incorporates FHIR-based specifications to supportstructural attributes for generating KGs. We propose that the CSSDM facilitatesdata harmonization and linking, offering an alternative approach tointeroperability. This approach promotes a novel form of collaboration betweencompanies developing health information systems and cloud-enabled healthservices. Consequently, it provides multiple stakeholders with access tohigh-quality data and information sharing.</description><author>Subhashis Das, Debashis Naskar, Sara Rodriguez Gonzalez, Pamela Hussey</author><pubDate>Fri, 17 Jan 2025 12:48:48 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.10160v1</guid></item><item><title>Structure-guided Deep Multi-View Clustering</title><link>http://arxiv.org/abs/2501.10157v1</link><description>Deep multi-view clustering seeks to utilize the abundant information frommultiple views to improve clustering performance. However, most of the existingclustering methods often neglect to fully mine multi-view structuralinformation and fail to explore the distribution of multi-view data, limitingclustering performance. To address these limitations, we propose astructure-guided deep multi-view clustering model. Specifically, we introduce apositive sample selection strategy based on neighborhood relationships, coupledwith a corresponding loss function. This strategy constructs multi-view nearestneighbor graphs to dynamically redefine positive sample pairs, enabling themining of local structural information within multi-view data and enhancing thereliability of positive sample selection. Additionally, we introduce a Gaussiandistribution model to uncover latent structural information and introduce aloss function to reduce discrepancies between view embeddings. These twostrategies explore multi-view structural information and data distribution fromdifferent perspectives, enhancing consistency across views and increasingintra-cluster compactness. Experimental evaluations demonstrate the efficacy ofour method, showing significant improvements in clustering performance onmultiple benchmark datasets compared to state-of-the-art multi-view clusteringapproaches.</description><author>Jinrong Cui, Xiaohuang Wu, Haitao Zhang, Chongjie Dong, Jie Wen</author><pubDate>Fri, 17 Jan 2025 12:42:30 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.10157v1</guid></item><item><title>How Redundant Is the Transformer Stack in Speech Representation Models?</title><link>http://arxiv.org/abs/2409.16302v2</link><description>Self-supervised speech representation models, particularly those leveragingtransformer architectures, have demonstrated remarkable performance acrossvarious tasks such as speech recognition, speaker identification, and emotiondetection. Recent studies on transformer models revealed a high redundancybetween layers and the potential for significant pruning, which we willinvestigate here for transformer-based speech representation models. We performa detailed analysis of layer similarity in speech representation models usingthree similarity metrics: cosine similarity, centered kernel alignment, andmutual nearest-neighbor alignment. Our findings reveal a block-like structureof high similarity, suggesting two main processing steps and significantredundancy of layers. We demonstrate the effectiveness of pruningtransformer-based speech representation models without the need forpost-training, achieving up to 40% reduction in transformer layers whilemaintaining over 95% of the model's predictive capacity. Furthermore, we employa knowledge distillation method to substitute the entire transformer stack withmimicking layers, reducing the network size 95-98% and the inference time by upto 94%. This substantial decrease in computational load occurs withoutconsiderable performance loss, suggesting that the transformer stack is almostcompletely redundant for downstream applications of speech representationmodels.</description><author>Teresa Dorszewski, Albert Kjøller Jacobsen, Lenka Tětková, Lars Kai Hansen</author><pubDate>Fri, 17 Jan 2025 12:27:40 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2409.16302v2</guid></item><item><title>Region-wise stacking ensembles for estimating brain-age using MRI</title><link>http://arxiv.org/abs/2501.10153v1</link><description>Predictive modeling using structural magnetic resonance imaging (MRI) data isa prominent approach to study brain-aging. Machine learning algorithms andfeature extraction methods have been employed to improve predictions andexplore healthy and accelerated aging e.g. neurodegenerative and psychiatricdisorders. The high-dimensional MRI data pose challenges to buildinggeneralizable and interpretable models as well as for data privacy. Commonpractices are resampling or averaging voxels within predefined parcels, whichreduces anatomical specificity and biological interpretability as voxels withina region may differently relate to aging. Effectively, naive fusion byaveraging can result in information loss and reduced accuracy. We present aconceptually novel two-level stacking ensemble (SE) approach. The first levelcomprises regional models for predicting individuals' age based on voxel-wiseinformation, fused by a second-level model yielding final predictions. Eightdata fusion scenarios were explored using as input Gray matter volume (GMV)estimates from four datasets covering the adult lifespan. Performance, measuredusing mean absolute error (MAE), R2, correlation and prediction bias, showedthat SE outperformed the region-wise averages. The best performance wasobtained when first-level regional predictions were obtained as out-of-samplepredictions on the application site with second-level models trained onindependent and site-specific data (MAE=4.75 vs baseline regional mean GMVMAE=5.68). Performance improved as more datasets were used for training.First-level predictions showed improved and more robust aging signal providingnew biological insights and enhanced data privacy. Overall, the SE improvesaccuracy compared to the baseline while preserving or enhancing data privacy.</description><author>Georgios Antonopoulos, Shammi More, Simon B. Eickhoff, Federico Raimondo, Kaustubh R. Patil</author><pubDate>Fri, 17 Jan 2025 12:24:28 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.10153v1</guid></item><item><title>Topology-Driven Attribute Recovery for Attribute Missing Graph Learning in Social Internet of Things</title><link>http://arxiv.org/abs/2501.10151v1</link><description>With the advancement of information technology, the Social Internet of Things(SIoT) has fostered the integration of physical devices and social networks,deepening the study of complex interaction patterns. Text Attribute Graphs(TAGs) capture both topological structures and semantic attributes, enhancingthe analysis of complex interactions within the SIoT. However, existing graphlearning methods are typically designed for complete attributed graphs, and thecommon issue of missing attributes in Attribute Missing Graphs (AMGs) increasesthe difficulty of analysis tasks. To address this, we propose theTopology-Driven Attribute Recovery (TDAR) framework, which leveragestopological data for AMG learning. TDAR introduces an improved pre-fillingmethod for initial attribute recovery using native graph topology.Additionally, it dynamically adjusts propagation weights and incorporateshomogeneity strategies within the embedding space to suit AMGs' uniquetopological structures, effectively reducing noise during informationpropagation. Extensive experiments on public datasets demonstrate that TDARsignificantly outperforms state-of-the-art methods in attribute reconstructionand downstream tasks, offering a robust solution to the challenges posed byAMGs. The code is available at https://github.com/limengran98/TDAR.</description><author>Mengran Li, Junzhou Chen, Chenyun Yu, Guanying Jiang, Ronghui Zhang, Yanming Shen, Houbing Herbert Song</author><pubDate>Fri, 17 Jan 2025 12:23:42 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.10151v1</guid></item><item><title>Dual Debiasing: Remove Stereotypes and Keep Factual Gender for Fair Language Modeling and Translation</title><link>http://arxiv.org/abs/2501.10150v1</link><description>Mitigation of biases, such as language models' reliance on genderstereotypes, is a crucial endeavor required for the creation of reliable anduseful language technology. The crucial aspect of debiasing is to ensure thatthe models preserve their versatile capabilities, including their ability tosolve language tasks and equitably represent various genders. To address thisissue, we introduce a streamlined Dual Dabiasing Algorithm through ModelAdaptation (2DAMA). Novel Dual Debiasing enables robust reduction ofstereotypical bias while preserving desired factual gender information encodedby language models. We show that 2DAMA effectively reduces gender bias inEnglish and is one of the first approaches facilitating the mitigation ofstereotypical tendencies in translation. The proposed method's key advantage isthe preservation of factual gender cues, which are useful in a wide range ofnatural language processing tasks.</description><author>Tomasz Limisiewicz, David Mareček, Tomáš Musil</author><pubDate>Fri, 17 Jan 2025 12:23:30 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.10150v1</guid></item><item><title>News Without Borders: Domain Adaptation of Multilingual Sentence Embeddings for Cross-lingual News Recommendation</title><link>http://arxiv.org/abs/2406.12634v2</link><description>Rapidly growing numbers of multilingual news consumers pose an increasingchallenge to news recommender systems in terms of providing customizedrecommendations. First, existing neural news recommenders, even when powered bymultilingual language models (LMs), suffer substantial performance losses inzero-shot cross-lingual transfer (ZS-XLT). Second, the current paradigm offine-tuning the backbone LM of a neural recommender on task-specific data iscomputationally expensive and infeasible in few-shot recommendation andcold-start setups, where data is scarce or completely unavailable. In thiswork, we propose a news-adapted sentence encoder (NaSE), domain-specializedfrom a pretrained massively multilingual sentence encoder (SE). To this end, weconstruct and leverage PolyNews and PolyNewsParallel, two multilingualnews-specific corpora. With the news-adapted multilingual SE in place, we testthe effectiveness of (i.e., question the need for) supervised fine-tuning fornews recommendation, and propose a simple and strong baseline based on (i)frozen NaSE embeddings and (ii) late click-behavior fusion. We show that NaSEachieves state-of-the-art performance in ZS-XLT in true cold-start and few-shotnews recommendation.</description><author>Andreea Iana, Fabian David Schmidt, Goran Glavaš, Heiko Paulheim</author><pubDate>Fri, 17 Jan 2025 12:19:05 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.12634v2</guid></item><item><title>MRI2Speech: Speech Synthesis from Articulatory Movements Recorded by Real-time MRI</title><link>http://arxiv.org/abs/2412.18836v2</link><description>Previous real-time MRI (rtMRI)-based speech synthesis models depend heavilyon noisy ground-truth speech. Applying loss directly over ground truthmel-spectrograms entangles speech content with MRI noise, resulting in poorintelligibility. We introduce a novel approach that adapts the multi-modalself-supervised AV-HuBERT model for text prediction from rtMRI and incorporatesa new flow-based duration predictor for speaker-specific alignment. Thepredicted text and durations are then used by a speech decoder to synthesizealigned speech in any novel voice. We conduct thorough experiments on twodatasets and demonstrate our method's generalization ability to unseenspeakers. We assess our framework's performance by masking parts of the rtMRIvideo to evaluate the impact of different articulators on text prediction. Ourmethod achieves a $15.18\%$ Word Error Rate (WER) on the USC-TIMIT MRI corpus,marking a huge improvement over the current state-of-the-art. Speech samplesare available at https://mri2speech.github.io/MRI2Speech/</description><author>Neil Shah, Ayan Kashyap, Shirish Karande, Vineet Gandhi</author><pubDate>Fri, 17 Jan 2025 12:18:44 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.18836v2</guid></item><item><title>A Vision-Language Framework for Multispectral Scene Representation Using Language-Grounded Features</title><link>http://arxiv.org/abs/2501.10144v1</link><description>Scene understanding in remote sensing often faces challenges in generatingaccurate representations for complex environments such as various land useareas or coastal regions, which may also include snow, clouds, or haze. Toaddress this, we present a vision-language framework named Spectral LLaVA,which integrates multispectral data with vision-language alignment techniquesto enhance scene representation and description. Using the BigEarthNet v2dataset from Sentinel-2, we establish a baseline with RGB-based scenedescriptions and further demonstrate substantial improvements through theincorporation of multispectral information. Our framework optimizes alightweight linear projection layer for alignment while keeping the visionbackbone of SpectralGPT frozen. Our experiments encompass scene classificationusing linear probing and language modeling for jointly performing sceneclassification and description generation. Our results highlight SpectralLLaVA's ability to produce detailed and accurate descriptions, particularly forscenarios where RGB data alone proves inadequate, while also enhancingclassification performance by refining SpectralGPT features into semanticallymeaningful representations.</description><author>Enes Karanfil, Nevrez Imamoglu, Erkut Erdem, Aykut Erdem</author><pubDate>Fri, 17 Jan 2025 12:12:33 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.10144v1</guid></item><item><title>Audio-Driven Reinforcement Learning for Head-Orientation in Naturalistic Environments</title><link>http://arxiv.org/abs/2409.10048v2</link><description>Although deep reinforcement learning (DRL) approaches in audio signalprocessing have seen substantial progress in recent years, audio-driven DRL fortasks such as navigation, gaze control and head-orientation control in thecontext of human-robot interaction have received little attention. Here, wepropose an audio-driven DRL framework in which we utilise deep Q-learning todevelop an autonomous agent that orients towards a talker in the acousticenvironment based on stereo speech recordings. Our results show that the agentlearned to perform the task at a near perfect level when trained on speechsegments in anechoic environments (that is, without reverberation). Thepresence of reverberation in naturalistic acoustic environments affected theagent's performance, although the agent still substantially outperformed abaseline, randomly acting agent. Finally, we quantified the degree ofgeneralization of the proposed DRL approach across naturalistic acousticenvironments. Our experiments revealed that policies learned by agents trainedon medium or high reverb environments generalized to low reverb environments,but policies learned by agents trained on anechoic or low reverb environmentsdid not generalize to medium or high reverb environments. Taken together, thisstudy demonstrates the potential of audio-driven DRL for tasks such ashead-orientation control and highlights the need for training strategies thatenable robust generalization across environments for real-world audio-drivenDRL applications.</description><author>Wessel Ledder, Yuzhen Qin, Kiki van der Heijden</author><pubDate>Fri, 17 Jan 2025 12:12:28 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2409.10048v2</guid></item><item><title>Enhancing UAV Path Planning Efficiency Through Accelerated Learning</title><link>http://arxiv.org/abs/2501.10141v1</link><description>Unmanned Aerial Vehicles (UAVs) are increasingly essential in various fieldssuch as surveillance, reconnaissance, and telecommunications. This study aimsto develop a learning algorithm for the path planning of UAV wirelesscommunication relays, which can reduce storage requirements and accelerate DeepReinforcement Learning (DRL) convergence. Assuming the system possesses terrainmaps of the area and can estimate user locations using localization algorithmsor direct GPS reporting, it can input these parameters into the learningalgorithms to achieve optimized path planning performance. However, higherresolution terrain maps are necessary to extract topological information suchas terrain height, object distances, and signal blockages. This requirementincreases memory and storage demands on UAVs while also lengthening convergencetimes in DRL algorithms. Similarly, defining the telecommunication coverage mapin UAV wireless communication relays using these terrain maps and user positionestimations demands higher memory and storage utilization for the learning pathplanning algorithms. Our approach reduces path planning training time byapplying a dimensionality reduction technique based on Principal ComponentAnalysis (PCA), sample combination, Prioritized Experience Replay (PER), andthe combination of Mean Squared Error (MSE) and Mean Absolute Error (MAE) losscalculations in the coverage map estimates, thereby enhancing a Twin DelayedDeep Deterministic Policy Gradient (TD3) algorithm. The proposed solutionreduces the convergence episodes needed for basic training by approximatelyfour times compared to the traditional TD3.</description><author>Joseanne Viana, Boris Galkin, Lester Ho, Holger Claussen</author><pubDate>Fri, 17 Jan 2025 12:05:24 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.10141v1</guid></item><item><title>Conformal Prediction Sets with Improved Conditional Coverage using Trust Scores</title><link>http://arxiv.org/abs/2501.10139v1</link><description>Standard conformal prediction offers a marginal guarantee on coverage, butfor prediction sets to be truly useful, they should ideally ensure coverageconditional on each test point. Unfortunately, it is impossible to achieveexact, distribution-free conditional coverage in finite samples. In this work,we propose an alternative conformal prediction algorithm that targets coveragewhere it matters most--in instances where a classifier is overconfident in itsincorrect predictions. We start by dissecting miscoverage events inmarginally-valid conformal prediction, and show that miscoverage rates varybased on the classifier's confidence and its deviation from the Bayes optimalclassifier. Motivated by this insight, we develop a variant of conformalprediction that targets coverage conditional on a reduced set of two variables:the classifier's confidence in a prediction and a nonparametric trust scorethat measures its deviation from the Bayes classifier. Empirical evaluation onmultiple image datasets shows that our method generally improves conditionalcoverage properties compared to standard conformal prediction, includingclass-conditional coverage, coverage over arbitrary subgroups, and coverageover demographic groups.</description><author>Jivat Neet Kaur, Michael I. Jordan, Ahmed Alaa</author><pubDate>Fri, 17 Jan 2025 12:01:56 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.10139v1</guid></item><item><title>Visual Exploration of Stopword Probabilities in Topic Models</title><link>http://arxiv.org/abs/2501.10137v1</link><description>Stopword removal is a critical stage in many Machine Learning methods butoften receives little consideration, it interferes with the modelvisualizations and disrupts user confidence. Inappropriately chosen or hastilyomitted stopwords not only lead to suboptimal performance but alsosignificantly affect the quality of models, thus reducing the willingness ofpractitioners and stakeholders to rely on the output visualizations. This paperproposes a novel extraction method that provides a corpus-specificprobabilistic estimation of stopword likelihood and an interactivevisualization system to support their analysis. We evaluated our approach andinterface using real-world data, a commonly used Machine Learning method (TopicModelling), and a comprehensive qualitative experiment probing user confidence.The results of our work show that our system increases user confidence in thecredibility of topic models by (1) returning reasonable probabilities, (2)generating an appropriate and representative extension of common stopwordlists, and (3) providing an adjustable threshold for estimating and analyzingstopwords visually. Finally, we discuss insights, recommendations, and bestpractices to support practitioners while improving the output of MachineLearning methods and topic model visualizations with robust stopword analysisand removal.</description><author>Shuangjiang Xue, Pierre Le Bras, David A. Robb, Mike J. Chantler, Stefano Padilla</author><pubDate>Fri, 17 Jan 2025 11:59:56 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.10137v1</guid></item></channel></rss>