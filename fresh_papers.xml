<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/"><channel><title>Arxivfresh papers</title><link></link><description>Arxiv paper</description><language>en-US</language><lastBuildDate>Wed, 20 Dec 2023 14:00:05 GMT</lastBuildDate><generator>rfeed v1.0.0</generator><docs>https://github.com/svpino/rfeed/blob/master/README.md</docs><item><title>Weakly Supervised Open-Vocabulary Object Detection</title><link>http://arxiv.org/abs/2312.12437v1</link><description>Despite weakly supervised object detection (WSOD) being a promising steptoward evading strong instance-level annotations, its capability is confined toclosed-set categories within a single training dataset. In this paper, wepropose a novel weakly supervised open-vocabulary object detection framework,namely WSOVOD, to extend traditional WSOD to detect novel concepts and utilizediverse datasets with only image-level annotations. To achieve this, we explorethree vital strategies, including dataset-level feature adaptation, image-levelsalient object localization, and region-level vision-language alignment. First,we perform data-aware feature extraction to produce an input-conditionalcoefficient, which is leveraged into dataset attribute prototypes to identifydataset bias and help achieve cross-dataset generalization. Second, acustomized location-oriented weakly supervised region proposal network isproposed to utilize high-level semantic layouts from the category-agnosticsegment anything model to distinguish object boundaries. Lastly, we introduce aproposal-concept synchronized multiple-instance network, i.e., object miningand refinement with visual-semantic alignment, to discover objects matched tothe text embeddings of concepts. Extensive experiments on Pascal VOC and MSCOCO demonstrate that the proposed WSOVOD achieves new state-of-the-artcompared with previous WSOD methods in both close-set object localization anddetection tasks. Meanwhile, WSOVOD enables cross-dataset and open-vocabularylearning to achieve on-par or even better performance than well-establishedfully-supervised open-vocabulary object detection (FSOVOD).</description><author>Jianghang Lin, Yunhang Shen, Bingquan Wang, Shaohui Lin, Ke Li, Liujuan Cao</author><pubDate>Tue, 19 Dec 2023 18:59:53 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.12437v1</guid></item><item><title>Geometry-Aware Normalizing Wasserstein Flows for Optimal Causal Inference</title><link>http://arxiv.org/abs/2311.18826v3</link><description>This manuscript enriches the framework of continuous normalizing flows (CNFs)within causal inference, primarily to augment the geometric properties ofparametric submodels used in targeted maximum likelihood estimation (TMLE). Byintroducing an innovative application of CNFs, we construct a refined series ofparametric submodels that enable a directed interpolation between the priordistribution $p_0$ and the empirical distribution $p_1$. This proposedmethodology serves to optimize the semiparametric efficiency bound in causalinference by orchestrating CNFs to align with Wasserstein gradient flows. Ourapproach not only endeavors to minimize the mean squared error in theestimation but also imbues the estimators with geometric sophistication,thereby enhancing robustness against misspecification. This robustness iscrucial, as it alleviates the dependence on the standard $n^{\frac{1}{4}}$ ratefor a doubly-robust perturbation direction in TMLE. By incorporating robustoptimization principles and differential geometry into the estimators, thedeveloped geometry-aware CNFs represent a significant advancement in thepursuit of doubly robust causal inference.</description><author>Kaiwen Hou</author><pubDate>Tue, 19 Dec 2023 18:59:34 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.18826v3</guid></item><item><title>A Challenger to GPT-4V? Early Explorations of Gemini in Visual Expertise</title><link>http://arxiv.org/abs/2312.12436v1</link><description>The surge of interest towards Multi-modal Large Language Models (MLLMs),e.g., GPT-4V(ision) from OpenAI, has marked a significant trend in bothacademia and industry. They endow Large Language Models (LLMs) with powerfulcapabilities in visual understanding, enabling them to tackle diversemulti-modal tasks. Very recently, Google released Gemini, its newest and mostcapable MLLM built from the ground up for multi-modality. In light of thesuperior reasoning capabilities, can Gemini challenge GPT-4V's leading positionin multi-modal learning? In this paper, we present a preliminary exploration ofGemini Pro's visual understanding proficiency, which comprehensively coversfour domains: fundamental perception, advanced cognition, challenging visiontasks, and various expert capacities. We compare Gemini Pro with thestate-of-the-art GPT-4V to evaluate its upper limits, along with the latestopen-sourced MLLM, Sphinx, which reveals the gap between manual efforts andblack-box systems. The qualitative samples indicate that, while GPT-4V andGemini showcase different answering styles and preferences, they can exhibitcomparable visual reasoning capabilities, and Sphinx still trails behind themconcerning domain generalizability. Specifically, GPT-4V tends to elaboratedetailed explanations and intermediate steps, and Gemini prefers to output adirect and concise answer. The quantitative evaluation on the popular MMEbenchmark also demonstrates the potential of Gemini to be a strong challengerto GPT-4V. Our early investigation of Gemini also observes some common issuesof MLLMs, indicating that there still remains a considerable distance towardsartificial general intelligence. Our project for tracking the progress of MLLMis released athttps://github.com/BradyFU/Awesome-Multimodal-Large-Language-Models.</description><author>Chaoyou Fu, Renrui Zhang, Haojia Lin, Zihan Wang, Timin Gao, Yongdong Luo, Yubo Huang, Zhengye Zhang, Longtian Qiu, Gaoxiang Ye, Yunhang Shen, Mengdan Zhang, Peixian Chen, Sirui Zhao, Xiawu Zheng, Shaohui Lin, Deqiang Jiang, Di Yin, Peng Gao, Ke Li, Xing Sun, Rongrong Ji</author><pubDate>Tue, 19 Dec 2023 18:59:22 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.12436v1</guid></item><item><title>Tracking Any Object Amodally</title><link>http://arxiv.org/abs/2312.12433v1</link><description>Amodal perception, the ability to comprehend complete object structures frompartial visibility, is a fundamental skill, even for infants. Its significanceextends to applications like autonomous driving, where a clear understanding ofheavily occluded objects is essential. However, modern detection and trackingalgorithms often overlook this critical capability, perhaps due to theprevalence of modal annotations in most datasets. To address the scarcity ofamodal data, we introduce the TAO-Amodal benchmark, featuring 880 diversecategories in thousands of video sequences. Our dataset includes amodal andmodal bounding boxes for visible and occluded objects, including objects thatare partially out-of-frame. To enhance amodal tracking with object permanence,we leverage a lightweight plug-in module, the amodal expander, to transformstandard, modal trackers into amodal ones through fine-tuning on a few hundredvideo sequences with data augmentation. We achieve a 3.3\% and 1.6\%improvement on the detection and tracking of occluded objects on TAO-Amodal.When evaluated on people, our method produces dramatic improvements of 2xcompared to state-of-the-art modal baselines.</description><author>Cheng-Yen Hsieh, Tarasha Khurana, Achal Dave, Deva Ramanan</author><pubDate>Tue, 19 Dec 2023 18:58:40 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.12433v1</guid></item><item><title>On Inference Stability for Diffusion Models</title><link>http://arxiv.org/abs/2312.12431v1</link><description>Denoising Probabilistic Models (DPMs) represent an emerging domain ofgenerative models that excel in generating diverse and high-quality images.However, most current training methods for DPMs often neglect the correlationbetween timesteps, limiting the model's performance in generating imageseffectively. Notably, we theoretically point out that this issue can be causedby the cumulative estimation gap between the predicted and the actualtrajectory. To minimize that gap, we propose a novel \textit{sequence-aware}loss that aims to reduce the estimation gap to enhance the sampling quality.Furthermore, we theoretically show that our proposed loss function is a tighterupper bound of the estimation loss in comparison with the conventional loss inDPMs. Experimental results on several benchmark datasets including CIFAR10,CelebA, and CelebA-HQ consistently show a remarkable improvement of ourproposed method regarding the image generalization quality measured by FID andInception Score compared to several DPM baselines. Our code and pre-trainedcheckpoints are available at \url{https://github.com/viettmab/SA-DPM}.</description><author>Viet Nguyen, Giang Vu, Tung Nguyen Thanh, Khoat Than, Toan Tran</author><pubDate>Tue, 19 Dec 2023 18:57:34 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.12431v1</guid></item><item><title>Efficient Title Reranker for Fast and Improved Knowledge-Intense NLP</title><link>http://arxiv.org/abs/2312.12430v1</link><description>We introduce Efficient Title Reranker via Broadcasting Query Encoder, a noveltitle reranking technique to achieve efficient title reranking 20x-40x fasterthan vanilla passage reranker. However, one of the challenges with the trainingof Efficient Title Reranker is the instability. Analyzing the issue, we foundsome very difficult ground truths might act as noisy labels causing accuracy todrop as well as some extreme values in model probability output causing nan. Toaddress these issues, we introduce the Sigmoid Trick, a novel technique thatreduces the gradient update of both cases resulting in better retrievalefficacy. Experiments showed the effectiveness of ETR and sigmoid trick as weachieved four state-of-the-art positions on the kilt knowledge benchmark.</description><author>Ziyi Chen, Heyi Tao, Daqian Zuo, Jize Jiang, Yang Jun, Yuxiang Wei</author><pubDate>Tue, 19 Dec 2023 18:56:52 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.12430v1</guid></item><item><title>The Endoscapes Dataset for Surgical Scene Segmentation, Object Detection, and Critical View of Safety Assessment: Official Splits and Benchmark</title><link>http://arxiv.org/abs/2312.12429v1</link><description>This technical report provides a detailed overview of Endoscapes, a datasetof laparoscopic cholecystectomy (LC) videos with highly intricate annotationstargeted at automated assessment of the Critical View of Safety (CVS).Endoscapes comprises 201 LC videos with frames annotated sparsely but regularlywith segmentation masks, bounding boxes, and CVS assessment by three differentclinical experts. Altogether, there are 11090 frames annotated with CVS and1933 frames annotated with tool and anatomy bounding boxes from the 201 videos,as well as an additional 422 frames from 50 of the 201 videos annotated withtool and anatomy segmentation masks. In this report, we provide detaileddataset statistics (size, class distribution, dataset splits, etc.) and acomprehensive performance benchmark for instance segmentation, objectdetection, and CVS prediction. The dataset and model checkpoints are publicallyavailable at https://github.com/CAMMA-public/Endoscapes.</description><author>Aditya Murali, Deepak Alapatt, Pietro Mascagni, Armine Vardazaryan, Alain Garcia, Nariaki Okamoto, Guido Costamagna, Didier Mutter, Jacques Marescaux, Bernard Dallemagne, Nicolas Padoy</author><pubDate>Tue, 19 Dec 2023 18:56:44 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.12429v1</guid></item><item><title>SegRefiner: Towards Model-Agnostic Segmentation Refinement with Discrete Diffusion Process</title><link>http://arxiv.org/abs/2312.12425v1</link><description>In this paper, we explore a principal way to enhance the quality of objectmasks produced by different segmentation models. We propose a model-agnosticsolution called SegRefiner, which offers a novel perspective on this problem byinterpreting segmentation refinement as a data generation process. As a result,the refinement process can be smoothly implemented through a series ofdenoising diffusion steps. Specifically, SegRefiner takes coarse masks asinputs and refines them using a discrete diffusion process. By predicting thelabel and corresponding states-transition probabilities for each pixel,SegRefiner progressively refines the noisy masks in a conditional denoisingmanner. To assess the effectiveness of SegRefiner, we conduct comprehensiveexperiments on various segmentation tasks, including semantic segmentation,instance segmentation, and dichotomous image segmentation. The resultsdemonstrate the superiority of our SegRefiner from multiple aspects. Firstly,it consistently improves both the segmentation metrics and boundary metricsacross different types of coarse masks. Secondly, it outperforms previousmodel-agnostic refinement methods by a significant margin. Lastly, it exhibitsa strong capability to capture extremely fine details when refininghigh-resolution images. The source code and trained models are available athttps://github.com/MengyuWang826/SegRefiner.</description><author>Mengyu Wang, Henghui Ding, Jun Hao Liew, Jiajun Liu, Yao Zhao, Yunchao Wei</author><pubDate>Tue, 19 Dec 2023 18:53:47 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.12425v1</guid></item><item><title>Jack of All Tasks, Master of Many: Designing General-purpose Coarse-to-Fine Vision-Language Model</title><link>http://arxiv.org/abs/2312.12423v1</link><description>The ability of large language models (LLMs) to process visual inputs hasgiven rise to general-purpose vision systems, unifying various vision-language(VL) tasks by instruction tuning. However, due to the enormous diversity ininput-output formats in the vision domain, existing general-purpose models failto successfully integrate segmentation and multi-image inputs with coarse-leveltasks into a single framework. In this work, we introduce VistaLLM, a powerfulvisual system that addresses coarse- and fine-grained VL tasks over single andmultiple input images using a unified framework. VistaLLM utilizes aninstruction-guided image tokenizer that filters global embeddings using taskdescriptions to extract compressed and refined features from numerous images.Moreover, VistaLLM employs a gradient-aware adaptive sampling technique torepresent binary segmentation masks as sequences, significantly improving overpreviously used uniform sampling. To bolster the desired capability ofVistaLLM, we curate CoinIt, a comprehensive coarse-to-fine instruction tuningdataset with 6.8M samples. We also address the lack of multi-image groundingdatasets by introducing a novel task, AttCoSeg (Attribute-levelCo-Segmentation), which boosts the model's reasoning and grounding capabilityover multiple input images. Extensive experiments on a wide range of V- and VLtasks demonstrate the effectiveness of VistaLLM by achieving consistentstate-of-the-art performance over strong baselines across all downstream tasks.Our project page can be found at https://shramanpramanick.github.io/VistaLLM/.</description><author>Shraman Pramanick, Guangxing Han, Rui Hou, Sayan Nag, Ser-Nam Lim, Nicolas Ballas, Qifan Wang, Rama Chellappa, Amjad Almahairi</author><pubDate>Tue, 19 Dec 2023 18:53:01 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.12423v1</guid></item><item><title>Scene-Conditional 3D Object Stylization and Composition</title><link>http://arxiv.org/abs/2312.12419v1</link><description>Recently, 3D generative models have made impressive progress, enabling thegeneration of almost arbitrary 3D assets from text or image inputs. However,these approaches generate objects in isolation without any consideration forthe scene where they will eventually be placed. In this paper, we propose aframework that allows for the stylization of an existing 3D asset to fit into agiven 2D scene, and additionally produce a photorealistic composition as if theasset was placed within the environment. This not only opens up a new level ofcontrol for object stylization, for example, the same assets can be stylized toreflect changes in the environment, such as summer to winter or fantasy versusfuturistic settings-but also makes the object-scene composition morecontrollable. We achieve this by combining modeling and optimizing the object'stexture and environmental lighting through differentiable ray tracing withimage priors from pre-trained text-to-image diffusion models. We demonstratethat our method is applicable to a wide variety of indoor and outdoor scenesand arbitrary objects.</description><author>Jinghao Zhou, Tomas Jakab, Philip Torr, Christian Rupprecht</author><pubDate>Tue, 19 Dec 2023 18:50:33 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.12419v1</guid></item><item><title>LASA: Instance Reconstruction from Real Scans using A Large-scale Aligned Shape Annotation Dataset</title><link>http://arxiv.org/abs/2312.12418v1</link><description>Instance shape reconstruction from a 3D scene involves recovering the fullgeometries of multiple objects at the semantic instance level. Many methodsleverage data-driven learning due to the intricacies of scene complexity andsignificant indoor occlusions. Training these methods often requires alarge-scale, high-quality dataset with aligned and paired shape annotationswith real-world scans. Existing datasets are either synthetic or misaligned,restricting the performance of data-driven methods on real data. To this end,we introduce LASA, a Large-scale Aligned Shape Annotation Dataset comprising10,412 high-quality CAD annotations aligned with 920 real-world scene scansfrom ArkitScenes, created manually by professional artists. On this top, wepropose a novel Diffusion-based Cross-Modal Shape Reconstruction (DisCo)method. It is empowered by a hybrid feature aggregation design to fusemulti-modal inputs and recover high-fidelity object geometries. Besides, wepresent an Occupancy-Guided 3D Object Detection (OccGOD) method and demonstratethat our shape annotations provide scene occupancy clues that can furtherimprove 3D object detection. Supported by LASA, extensive experiments show thatour methods achieve state-of-the-art performance in both instance-level scenereconstruction and 3D object detection tasks.</description><author>Haolin Liu, Chongjie Ye, Yinyu Nie, Yingfan He, Xiaoguang Han</author><pubDate>Tue, 19 Dec 2023 18:50:10 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.12418v1</guid></item><item><title>Prompting Hard or Hardly Prompting: Prompt Inversion for Text-to-Image Diffusion Models</title><link>http://arxiv.org/abs/2312.12416v1</link><description>The quality of the prompts provided to text-to-image diffusion modelsdetermines how faithful the generated content is to the user's intent, oftenrequiring `prompt engineering'. To harness visual concepts from target imageswithout prompt engineering, current approaches largely rely on embeddinginversion by optimizing and then mapping them to pseudo-tokens. However,working with such high-dimensional vector representations is challengingbecause they lack semantics and interpretability, and only allow simple vectoroperations when using them. Instead, this work focuses on inverting thediffusion model to obtain interpretable language prompts directly. Thechallenge of doing this lies in the fact that the resulting optimizationproblem is fundamentally discrete and the space of prompts is exponentiallylarge; this makes using standard optimization techniques, such as stochasticgradient descent, difficult. To this end, we utilize a delayed projectionscheme to optimize for prompts representative of the vocabulary space in themodel. Further, we leverage the findings that different timesteps of thediffusion process cater to different levels of detail in an image. The later,noisy, timesteps of the forward diffusion process correspond to the semanticinformation, and therefore, prompt inversion in this range provides tokensrepresentative of the image semantics. We show that our approach can identifysemantically interpretable and meaningful prompts for a target image which canbe used to synthesize diverse images with similar content. We furtherillustrate the application of the optimized prompts in evolutionary imagegeneration and concept removal.</description><author>Shweta Mahajan, Tanzila Rahman, Kwang Moo Yi, Leonid Sigal</author><pubDate>Tue, 19 Dec 2023 18:47:30 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.12416v1</guid></item><item><title>Efficient Conditionally Invariant Representation Learning</title><link>http://arxiv.org/abs/2212.08645v2</link><description>We introduce the Conditional Independence Regression CovariancE (CIRCE), ameasure of conditional independence for multivariate continuous-valuedvariables. CIRCE applies as a regularizer in settings where we wish to learnneural features $\varphi(X)$ of data $X$ to estimate a target $Y$, while beingconditionally independent of a distractor $Z$ given $Y$. Both $Z$ and $Y$ areassumed to be continuous-valued but relatively low dimensional, whereas $X$ andits features may be complex and high dimensional. Relevant settings includedomain-invariant learning, fairness, and causal learning. The procedurerequires just a single ridge regression from $Y$ to kernelized features of $Z$,which can be done in advance. It is then only necessary to enforce independenceof $\varphi(X)$ from residuals of this regression, which is possible withattractive estimation properties and consistency guarantees. By contrast,earlier measures of conditional feature dependence require multiple regressionsfor each step of feature learning, resulting in more severe bias and variance,and greater computational cost. When sufficiently rich features are used, weestablish that CIRCE is zero if and only if $\varphi(X) \perp \!\!\! \perp Z\mid Y$. In experiments, we show superior performance to previous methods onchallenging benchmarks, including learning conditionally invariant imagefeatures.</description><author>Roman Pogodin, Namrata Deka, Yazhe Li, Danica J. Sutherland, Victor Veitch, Arthur Gretton</author><pubDate>Tue, 19 Dec 2023 18:46:19 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2212.08645v2</guid></item><item><title>Rapid Artefact Removal and H&amp;E-Stained Tissue Segmentation</title><link>http://arxiv.org/abs/2308.13304v2</link><description>We present an innovative method for rapidly segmenting hematoxylin and eosin(H&amp;E)-stained tissue in whole-slide images (WSIs) that eliminates a wide rangeof undesirable artefacts such as pen marks and scanning artefacts. Our methodinvolves taking a single-channel representation of a lowmagnification RGBoverview of the WSI in which the pixel values are bimodally distributed suchthat H&amp;E-stained tissue is easily distinguished from both background and a widevariety of artefacts. We demonstrate our method on 30 WSIs prepared from a widerange of institutions and WSI digital scanners, each containing substantialartefacts, and compare it to segmentations provided by Otsu thresholding andHistolab tissue segmentation and pen filtering tools. We found that our methodsegmented the tissue and fully removed all artefacts in 29 out of 30 WSIs,whereas Otsu thresholding failed to remove any artefacts, and the Histolab penfiltering tools only partially removed the pen marks. The beauty of ourapproach lies in its simplicity: manipulating RGB colour space and using Otsuthresholding allows for the segmentation of H&amp;E-stained tissue and the rapidremoval of artefacts without the need for machine learning or parameter tuning.</description><author>B. A. Schreiber, J. Denholm, F. Jaeckle, M. J. Arends, K. M. Branson, C. -B. Schönlieb, E. J. Soilleux</author><pubDate>Tue, 19 Dec 2023 18:45:10 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2308.13304v2</guid></item><item><title>Towards Automatic Support of Software Model Evolution with Large Language~Models</title><link>http://arxiv.org/abs/2312.12404v1</link><description>Modeling structure and behavior of software systems plays a crucial role, invarious areas of software engineering. As with other software engineeringartifacts, software models are subject to evolution. Supporting modelers inevolving models by model completion facilities and providing high-level editoperations such as frequently occurring editing patterns is still an openproblem. Recently, large language models (i.e., generative neural networks)have garnered significant attention in various research areas, includingsoftware engineering. In this paper, we explore the potential of large languagemodels in supporting the evolution of software models in software engineering.We propose an approach that utilizes large language models for model completionand discovering editing patterns in model histories of software systems.Through controlled experiments using simulated model repositories, we conductan evaluation of the potential of large language models for these two tasks. Wehave found that large language models are indeed a promising technology forsupporting software model evolution, and that it is worth investigating furtherin the area of software model evolution.</description><author>Christof Tinnes, Thomas Fuchß, Uwe Hohenstein, Sven Apel</author><pubDate>Tue, 19 Dec 2023 18:38:01 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.12404v1</guid></item><item><title>On Alternating-time Temporal Logic, Hyperproperties, and Strategy Sharing</title><link>http://arxiv.org/abs/2312.12403v1</link><description>Alternating-time temporal logic (ATL$^*$) is a well-established framework forformal reasoning about multi-agent systems. However, while ATL$^*$ can reasonabout the strategic ability of agents (e.g., some coalition $A$ can ensure thata goal is reached eventually), we cannot compare multiple strategicinteractions, nor can we require multiple agents to follow the same strategy.For example, we cannot state that coalition $A$ can reach a goal sooner (ormore often) than some other coalition $A'$. In this paper, we proposeHyperATLS$^*_S$, an extension of ATL$^*$ in which we can (1) compare theoutcome of multiple strategic interactions w.r.t. a hyperproperty, i.e., aproperty that refers to multiple paths at the same time, and (2) enforce thatsome agents share the same strategy. We show that HyperATL$^*_S$ is a richspecification language that captures important AI-related properties that wereout of reach of existing logics. We prove that model checking of HyperATL$^*_S$on concurrent game structures is decidable. We implement our model-checkingalgorithm in a tool we call HyMASMC and evaluate it on a range of benchmarks.</description><author>Raven Beutner, Bernd Finkbeiner</author><pubDate>Tue, 19 Dec 2023 18:37:39 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.12403v1</guid></item><item><title>New classes of the greedy-applicable arm feature distributions in the sparse linear bandit problem</title><link>http://arxiv.org/abs/2312.12400v1</link><description>We consider the sparse contextual bandit problem where arm feature affectsreward through the inner product of sparse parameters. Recent studies havedeveloped sparsity-agnostic algorithms based on the greedy arm selectionpolicy. However, the analysis of these algorithms requires strong assumptionson the arm feature distribution to ensure that the greedily selected samplesare sufficiently diverse; One of the most common assumptions, relaxed symmetry,imposes approximate origin-symmetry on the distribution, which cannot allowdistributions that has origin-asymmetric support. In this paper, we show thatthe greedy algorithm is applicable to a wider range of the arm featuredistributions from two aspects. Firstly, we show that a mixture distributionthat has a greedy-applicable component is also greedy-applicable. Second, wepropose new distribution classes, related to Gaussian mixture, discrete, andradial distribution, for which the sample diversity is guaranteed. The proposedclasses can describe distributions with origin-asymmetric support and, inconjunction with the first claim, provide theoretical guarantees of the greedypolicy for a very wide range of the arm feature distributions.</description><author>Koji Ichikawa, Shinji Ito, Daisuke Hatano, Hanna Sumita, Takuro Fukunaga, Naonori Kakimura, Ken-ichi Kawarabayashi</author><pubDate>Tue, 19 Dec 2023 18:35:33 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.12400v1</guid></item><item><title>Finding Nash equilibria by minimizing approximate exploitability with learned best responses</title><link>http://arxiv.org/abs/2301.08830v2</link><description>There has been substantial progress on finding game-theoretic equilibria.Most of that work has focused on games with finite, discrete action spaces.However, many games involving space, time, money, and other fine-grainedquantities have continuous action spaces (or are best modeled as such). Westudy the problem of finding an approximate Nash equilibrium of games withcontinuous action sets. The standard measure of closeness to Nash equilibriumis exploitability, which measures how much players can benefit fromunilaterally changing their strategy. We propose two new methods that minimizean approximation of the exploitability with respect to the strategy profile.The first method uses a learned best-response function, which takes the currentstrategy profile as input and returns candidate best responses for each player.The strategy profile and best-response functions are trained simultaneously,with the former trying to minimize exploitability while the latter tries tomaximize it. The second method maintains an ensemble of candidate bestresponses for each player. In each iteration, the best-performing elements ofeach ensemble are used to update the current strategy profile. The strategyprofile and best-response ensembles are simultaneously trained to minimize andmaximize the approximate exploitability, respectively. We evaluate our methodson various continuous games, showing that they outperform prior methods.</description><author>Carlos Martin, Tuomas Sandholm</author><pubDate>Tue, 19 Dec 2023 18:31:20 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2301.08830v2</guid></item><item><title>ICML 2023 Topological Deep Learning Challenge : Design and Results</title><link>http://arxiv.org/abs/2309.15188v3</link><description>This paper presents the computational challenge on topological deep learningthat was hosted within the ICML 2023 Workshop on Topology and Geometry inMachine Learning. The competition asked participants to provide open-sourceimplementations of topological neural networks from the literature bycontributing to the python packages TopoNetX (data processing) and TopoModelX(deep learning). The challenge attracted twenty-eight qualifying submissions inits two-month duration. This paper describes the design of the challenge andsummarizes its main findings.</description><author>Mathilde Papillon, Mustafa Hajij, Helen Jenne, Johan Mathe, Audun Myers, Theodore Papamarkou, Ghada Zamzmi, Tolga Birdal, Tamal Dey, Tim Doster, Tegan Emerson, Gurusankar Gopalakrishnan, Devendra Govil, Aldo Guzmán-Sáenz, Henry Kvinge, Neal Livesay, Soham Mukherjee, Shreyas N. Samaga, Karthikeyan Natesan Ramamurthy, Maneel Reddy Karri, Paul Rosen, Sophia Sanborn, Robin Walters, Jens Agerberg, Sadrodin Barikbin, Claudio Battiloro, Gleb Bazhenov, Guillermo Bernardez, Aiden Brent, Sergio Escalera, Simone Fiorellino, Dmitrii Gavrilev, Mohammed Hassanin, Paul Häusner, Odin Hoff Gardaa, Abdelwahed Khamis, Manuel Lecha, German Magai, Tatiana Malygina, Rubén Ballester, Kalyan Nadimpalli, Alexander Nikitin, Abraham Rabinowitz, Alessandro Salatiello, Simone Scardapane, Luca Scofano, Suraj Singh, Jen</author><pubDate>Tue, 19 Dec 2023 18:25:08 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2309.15188v3</guid></item><item><title>Mixture of Cluster-conditional LoRA Experts for Vision-language Instruction Tuning</title><link>http://arxiv.org/abs/2312.12379v1</link><description>Instruction tuning of the Large Vision-language Models (LVLMs) hasrevolutionized the development of versatile models with zero-shotgeneralization across a wide range of downstream vision-language tasks.However, diversity of training tasks of different sources and formats wouldlead to inevitable task conflicts, where different tasks conflicts for the sameset of model parameters, resulting in sub-optimal instruction-followingabilities. To address that, we propose the Mixture of Cluster-conditional LoRAExperts (MoCLE), a novel Mixture of Experts (MoE) architecture designed toactivate the task-customized model parameters based on the instructionclusters. A separate universal expert is further incorporated to improve thegeneralization capabilities of MoCLE for novel instructions. Extensiveexperiments on 10 zero-shot tasks demonstrate the effectiveness of MoCLE.</description><author>Yunhao Gou, Zhili Liu, Kai Chen, Lanqing Hong, Hang Xu, Aoxue Li, Dit-Yan Yeung, James T. Kwok, Yu Zhang</author><pubDate>Tue, 19 Dec 2023 18:11:19 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.12379v1</guid></item><item><title>Chasing Fairness in Graphs: A GNN Architecture Perspective</title><link>http://arxiv.org/abs/2312.12369v1</link><description>There has been significant progress in improving the performance of graphneural networks (GNNs) through enhancements in graph data, model architecturedesign, and training strategies. For fairness in graphs, recent studies achievefair representations and predictions through either graph data pre-processing(e.g., node feature masking, and topology rewiring) or fair training strategies(e.g., regularization, adversarial debiasing, and fair contrastive learning).How to achieve fairness in graphs from the model architecture perspective isless explored. More importantly, GNNs exhibit worse fairness performancecompared to multilayer perception since their model architecture (i.e.,neighbor aggregation) amplifies biases. To this end, we aim to achieve fairnessvia a new GNN architecture. We propose \textsf{F}air \textsf{M}essage\textsf{P}assing (FMP) designed within a unified optimization framework forGNNs. Notably, FMP \textit{explicitly} renders sensitive attribute usage in\textit{forward propagation} for node classification task using cross-entropyloss without data pre-processing. In FMP, the aggregation is first adopted toutilize neighbors' information and then the bias mitigation step explicitlypushes demographic group node presentation centers together. In this way, FMPscheme can aggregate useful information from neighbors and mitigate bias toachieve better fairness and prediction tradeoff performance. Experiments onnode classification tasks demonstrate that the proposed FMP outperforms severalbaselines in terms of fairness and accuracy on three real-world datasets. Thecode is available in {\url{https://github.com/zhimengj0326/FMP}}.</description><author>Zhimeng Jiang, Xiaotian Han, Chao Fan, Zirui Liu, Na Zou, Ali Mostafavi, Xia Hu</author><pubDate>Tue, 19 Dec 2023 18:00:15 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.12369v1</guid></item><item><title>SpokesBiz -- an Open Corpus of Conversational Polish</title><link>http://arxiv.org/abs/2312.12364v1</link><description>This paper announces the early release of SpokesBiz, a freely availablecorpus of conversational Polish developed within the CLARIN-BIZ project andcomprising over 650 hours of recordings. The transcribed recordings have beendiarized and manually annotated for punctuation and casing. We outline thegeneral structure and content of the corpus, showcasing selected applicationsin linguistic research, evaluation and improvement of automatic speechrecognition (ASR) systems</description><author>Piotr Pęzik, Sylwia Karasińska, Anna Cichosz, Łukasz Jałowiecki, Konrad Kaczyński, Małgorzata Krawentek, Karolina Walkusz, Paweł Wilk, Mariusz Kleć, Krzysztof Szklanny, Szymon Marszałkowski</author><pubDate>Tue, 19 Dec 2023 17:48:26 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.12364v1</guid></item><item><title>Frugal LMs Trained to Invoke Symbolic Solvers Achieve Parameter-Efficient Arithmetic Reasoning</title><link>http://arxiv.org/abs/2312.05571v2</link><description>Large Language Models (LLM) exhibit zero-shot mathematical reasoning capacityas a behavior emergent with scale, commonly manifesting as chain-of-thoughts(CoT) reasoning. However, multiple empirical findings suggest that this prowessis exclusive to LLMs with exorbitant sizes (beyond 50 billion parameters).Meanwhile, educational neuroscientists suggest that symbolic algebraicmanipulation be introduced around the same time as arithmetic word problems tomodularize language-to-formulation, symbolic manipulation of the formulation,and endgame arithmetic. In this paper, we start with the hypothesis that muchsmaller LMs, which are weak at multi-step reasoning, can achieve reasonablearithmetic reasoning if arithmetic word problems are posed as aformalize-then-solve task. In our architecture, which we call SYRELM, the LMserves the role of a translator to map natural language arithmetic questionsinto a formal language (FL) description. A symbolic solver then evaluates theFL expression to obtain the answer. A small frozen LM, equipped with anefficient low-rank adapter, is capable of generating FL expressions thatincorporate natural language descriptions of the arithmetic problem (e.g.,variable names and their purposes, formal expressions combining variables,etc.). We adopt policy-gradient reinforcement learning to train the adapted LM,informed by the non-differentiable symbolic solver. This marks a sharpdeparture from the recent development in tool-augmented LLMs, in which theexternal tools (e.g., calculator, Web search, etc.) are essentially detachedfrom the learning phase of the LM. SYRELM shows massive improvements (e.g.,+30.65 absolute point improvement in accuracy on the SVAMP dataset using GPT-J6B model) over base LMs, while keeping our testbed easy to diagnose, interpretand within reach of most researchers.</description><author>Subhabrata Dutta, Joykirat Singh, Ishan Pandey, Sunny Manchanda, Soumen Chakrabarti, Tanmoy Chakraborty</author><pubDate>Tue, 19 Dec 2023 17:48:20 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.05571v2</guid></item><item><title>Auditable Algorithms for Approximate Model Counting</title><link>http://arxiv.org/abs/2312.12362v1</link><description>Model counting, or counting the satisfying assignments of a Boolean formula,is a fundamental problem with diverse applications. Given #P-hardness of theproblem, developing algorithms for approximate counting is an importantresearch area. Building on the practical success of SAT-solvers, the focus hasrecently shifted from theory to practical implementations of approximatecounting algorithms. This has brought to focus new challenges, such as thedesign of auditable approximate counters that not only provide an approximationof the model count, but also a certificate that a verifier with limitedcomputational power can use to check if the count is indeed within the promisedbounds of approximation. Towards generating certificates, we start by examining the best-knowndeterministic approximate counting algorithm that uses polynomially many callsto a $\Sigma_2^P$ oracle. We show that this can be audited via a $\Sigma_2^P$oracle with the query constructed over $n^2 \log^2 n$ variables, where theoriginal formula has $n$ variables. Since $n$ is often large, we ask if thecount of variables in the certificate can be reduced -- a crucial question forpotential implementation. We show that this is indeed possible with a tradeoffin the counting algorithm's complexity. Specifically, we develop newdeterministic approximate counting algorithms that invoke a $\Sigma_3^P$oracle, but can be certified using a $\Sigma_2^P$ oracle using certificates onfar fewer variables: our final algorithm uses only $n \log n$ variables. Ourstudy demonstrates that one can simplify auditing significantly if we allow thecounting algorithm to access a slightly more powerful oracle. This shows forthe first time how audit complexity can be traded for complexity of approximatecounting.</description><author>Kuldeep S. Meel, Supratik Chakraborty, S. Akshay</author><pubDate>Tue, 19 Dec 2023 17:47:18 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.12362v1</guid></item><item><title>Augmentation-Aware Self-Supervision for Data-Efficient GAN Training</title><link>http://arxiv.org/abs/2205.15677v4</link><description>Training generative adversarial networks (GANs) with limited data ischallenging because the discriminator is prone to overfitting. Previouslyproposed differentiable augmentation demonstrates improved data efficiency oftraining GANs. However, the augmentation implicitly introduces undesiredinvariance to augmentation for the discriminator since it ignores the change ofsemantics in the label space caused by data transformation, which may limit therepresentation learning ability of the discriminator and ultimately affect thegenerative modeling performance of the generator. To mitigate the negativeimpact of invariance while inheriting the benefits of data augmentation, wepropose a novel augmentation-aware self-supervised discriminator that predictsthe augmentation parameter of the augmented data. Particularly, the predictiontargets of real data and generated data are required to be distinguished sincethey are different during training. We further encourage the generator toadversarially learn from the self-supervised discriminator by generatingaugmentation-predictable real and not fake data. This formulation connects thelearning objective of the generator and the arithmetic $-$ harmonic meandivergence under certain assumptions. We compare our method withstate-of-the-art (SOTA) methods using the class-conditional BigGAN andunconditional StyleGAN2 architectures on data-limited CIFAR-10, CIFAR-100,FFHQ, LSUN-Cat, and five low-shot datasets. Experimental results demonstratesignificant improvements of our method over SOTA methods in trainingdata-efficient GANs.</description><author>Liang Hou, Qi Cao, Yige Yuan, Songtao Zhao, Chongyang Ma, Siyuan Pan, Pengfei Wan, Zhongyuan Wang, Huawei Shen, Xueqi Cheng</author><pubDate>Tue, 19 Dec 2023 17:42:05 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2205.15677v4</guid></item><item><title>PoetryDiffusion: Towards Joint Semantic and Metrical Manipulation in Poetry Generation</title><link>http://arxiv.org/abs/2306.08456v3</link><description>Controllable text generation is a challenging and meaningful field in naturallanguage generation (NLG). Especially, poetry generation is a typical one withwell-defined and strict conditions for text generation which is an idealplayground for the assessment of current methodologies. While prior workssucceeded in controlling either semantic or metrical aspects of poetrygeneration, simultaneously addressing both remains a challenge. In this paper,we pioneer the use of the Diffusion model for generating sonnets and ChineseSongCi poetry to tackle such challenges. In terms of semantics, ourPoetryDiffusion model, built upon the Diffusion model, generates entiresentences or poetry by comprehensively considering the entirety of sentenceinformation. This approach enhances semantic expression, distinguishing it fromautoregressive and large language models (LLMs). For metrical control, theseparation feature of diffusion generation and its constraint control moduleenable us to flexibly incorporate a novel metrical controller to manipulate andevaluate metrics (format and rhythm). The denoising process in PoetryDiffusionallows for gradual enhancement of semantics and flexible integration of themetrical controller which can calculate and impose penalties on states thatstray significantly from the target control distribution. Experimental resultson two datasets demonstrate that our model outperforms existing models inautomatic evaluation of semantic, metrical, and overall performance as well ashuman evaluation.</description><author>Zhiyuan Hu, Chumin Liu, Yue Feng, Anh Tuan Luu, Bryan Hooi</author><pubDate>Tue, 19 Dec 2023 17:42:02 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.08456v3</guid></item><item><title>CLIP-DINOiser: Teaching CLIP a few DINO tricks</title><link>http://arxiv.org/abs/2312.12359v1</link><description>The popular CLIP model displays impressive zero-shot capabilities thanks toits seamless interaction with arbitrary text prompts. However, its lack ofspatial awareness makes it unsuitable for dense computer vision tasks, e.g.,semantic segmentation, without an additional fine-tuning step that often usesannotations and can potentially suppress its original open-vocabularyproperties. Meanwhile, self-supervised representation methods have demonstratedgood localization properties without human-made annotations nor explicitsupervision. In this work, we take the best of both worlds and propose azero-shot open-vocabulary semantic segmentation method, which does not requireany annotations. We propose to locally improve dense MaskCLIP features,computed with a simple modification of CLIP's last pooling layer, byintegrating localization priors extracted from self-supervised features. Bydoing so, we greatly improve the performance of MaskCLIP and produce smoothoutputs. Moreover, we show that the used self-supervised feature properties candirectly be learnt from CLIP features therefore allowing us to obtain the bestresults with a single pass through CLIP model. Our method CLIP-DINOiser needsonly a single forward pass of CLIP and two light convolutional layers atinference, no extra supervision nor extra memory and reaches state-of-the-artresults on challenging and fine-grained benchmarks such as COCO, PascalContext, Cityscapes and ADE20k. The code to reproduce our results is availableat https://github.com/wysoczanska/clip_dinoiser.</description><author>Monika Wysoczańska, Oriane Siméoni, Michaël Ramamonjisoa, Andrei Bursuc, Tomasz Trzciński, Patrick Pérez</author><pubDate>Tue, 19 Dec 2023 17:40:27 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.12359v1</guid></item><item><title>Modeling non-linear Effects with Neural Networks in Relational Event Models</title><link>http://arxiv.org/abs/2312.12357v1</link><description>Dynamic networks offer an insight of how relational systems evolve. However,modeling these networks efficiently remains a challenge, primarily due tocomputational constraints, especially as the number of observed events grows.This paper addresses this issue by introducing the Deep Relational EventAdditive Model (DREAM) as a solution to the computational challenges presentedby modeling non-linear effects in Relational Event Models (REMs). DREAM relieson Neural Additive Models to model non-linear effects, allowing each effect tobe captured by an independent neural network. By strategically tradingcomputational complexity for improved memory management and leveraging thecomputational capabilities of Graphic Processor Units (GPUs), DREAM efficientlycaptures complex non-linear relationships within data. This approachdemonstrates the capability of DREAM in modeling dynamic networks and scalingto larger networks. Comparisons with traditional REM approaches showcase DREAMsuperior computational efficiency. The model potential is further demonstratedby an examination of the patent citation network, which contains nearly 8million nodes and 100 million events.</description><author>Edoardo Filippi-Mazzola, Ernst C. Wit</author><pubDate>Tue, 19 Dec 2023 17:38:26 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.12357v1</guid></item><item><title>SMC-NCA: Semantic-guided Multi-level Contrast for Semi-supervised Action Segmentation</title><link>http://arxiv.org/abs/2312.12347v1</link><description>Semi-supervised action segmentation aims to perform frame-wise classificationin long untrimmed videos, where only a fraction of videos in the training sethave labels. Recent studies have shown the potential of contrastive learning inunsupervised representation learning using unlabelled data. However, learningthe representation of each frame by unsupervised contrastive learning foraction segmentation remains an open and challenging problem. In this paper, wepropose a novel Semantic-guided Multi-level Contrast scheme with aNeighbourhood-Consistency-Aware unit (SMC-NCA) to extract strong frame-wiserepresentations for semi-supervised action segmentation. Specifically, forrepresentation learning, SMC is firstly used to explore intra- andinter-information variations in a unified and contrastive way, based on dynamicclustering process of the original input, encoded semantic and temporalfeatures. Then, the NCA module, which is responsible for enforcing spatialconsistency between neighbourhoods centered at different frames to alleviateover-segmentation issues, works alongside SMC for semi-supervised learning. OurSMC outperforms the other state-of-the-art methods on three benchmarks,offering improvements of up to 17.8% and 12.6% in terms of edit distance andaccuracy, respectively. Additionally, the NCA unit results in significantbetter segmentation performance against the others in the presence of only 5%labelled videos. We also demonstrate the effectiveness of the proposed methodon our Parkinson's Disease Mouse Behaviour (PDMB) dataset. The code anddatasets will be made publicly available.</description><author>Feixiang Zhou, Zheheng Jiang, Huiyu Zhou, Xuelong Li</author><pubDate>Tue, 19 Dec 2023 17:26:44 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.12347v1</guid></item><item><title>Improving Lipschitz-Constrained Neural Networks by Learning Activation Functions</title><link>http://arxiv.org/abs/2210.16222v2</link><description>Lipschitz-constrained neural networks have several advantages overunconstrained ones and can be applied to a variety of problems, making them atopic of attention in the deep learning community. Unfortunately, it has beenshown both theoretically and empirically that they perform poorly when equippedwith ReLU activation functions. By contrast, neural networks with learnable1-Lipschitz linear splines are known to be more expressive. In this paper, weshow that such networks correspond to global optima of a constrained functionaloptimization problem that consists of the training of a neural network composedof 1-Lipschitz linear layers and 1-Lipschitz freeform activation functions withsecond-order total-variation regularization. Further, we propose an efficientmethod to train these neural networks. Our numerical experiments show that ourtrained networks compare favorably with existing 1-Lipschitz neuralarchitectures.</description><author>Stanislas Ducotterd, Alexis Goujon, Pakshal Bohra, Dimitris Perdios, Sebastian Neumayer, Michael Unser</author><pubDate>Tue, 19 Dec 2023 17:19:49 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2210.16222v2</guid></item><item><title>On the Effectiveness of Retrieval, Alignment, and Replay in Manipulation</title><link>http://arxiv.org/abs/2312.12345v1</link><description>Imitation learning with visual observations is notoriously inefficient whenaddressed with end-to-end behavioural cloning methods. In this paper, weexplore an alternative paradigm which decomposes reasoning into three phases.First, a retrieval phase, which informs the robot what it can do with anobject. Second, an alignment phase, which informs the robot where to interactwith the object. And third, a replay phase, which informs the robot how tointeract with the object. Through a series of real-world experiments oneveryday tasks, such as grasping, pouring, and inserting objects, we show thatthis decomposition brings unprecedented learning efficiency, and effectiveinter- and intra-class generalisation. Videos are available athttps://www.robot-learning.uk/retrieval-alignment-replay.</description><author>Norman Di Palo, Edward Johns</author><pubDate>Tue, 19 Dec 2023 17:17:52 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.12345v1</guid></item><item><title>Avoiding Data Contamination in Language Model Evaluation: Dynamic Test Construction with Latest Materials</title><link>http://arxiv.org/abs/2312.12343v1</link><description>Data contamination in evaluation is getting increasingly prevalent with theemerge of language models pre-trained on super large, automatically-crawledcorpora. This problem leads to significant challenges in accurate assessment ofmodel capabilities and generalisations. In this paper, we propose LatestEval,an automatic method leverages the most recent texts to create uncontaminatedreading comprehension evaluations. LatestEval avoids data contamination by onlyusing texts published within a recent time window, ensuring no overlap with thetraining corpora of pre-trained language models. We develop LatestEvalautomated pipeline to 1) gather latest texts; 2) identify key information, and3) construct questions targeting the information while removing the existinganswers from the context. This encourages models to infer the answersthemselves based on the remaining context, rather than just copy-paste. Ourexperiments demonstrate that language models exhibit negligible memorisationbehaviours on LatestEval as opposed to previous benchmarks, suggesting asignificantly reduced risk of data contamination and leading to a more robustevaluation. Data and code are publicly available at:https://github.com/liyucheng09/LatestEval.</description><author>Yucheng Li, Frank Geurin, Chenghua Lin</author><pubDate>Tue, 19 Dec 2023 17:16:43 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.12343v1</guid></item><item><title>Engineering an Exact Pseudo-Boolean Model Counter</title><link>http://arxiv.org/abs/2312.12341v1</link><description>Model counting, a fundamental task in computer science, involves determiningthe number of satisfying assignments to a Boolean formula, typicallyrepresented in conjunctive normal form (CNF). While model counting for CNFformulas has received extensive attention with a broad range of applications,the study of model counting for Pseudo-Boolean (PB) formulas has beenrelatively overlooked. Pseudo-Boolean formulas, being more succinct thanpropositional Boolean formulas, offer greater flexibility in representingreal-world problems. Consequently, there is a crucial need to investigateefficient techniques for model counting for PB formulas. In this work, we propose the first exact Pseudo-Boolean model counter,PBCount, that relies on knowledge compilation approach via algebraic decisiondiagrams. Our extensive empirical evaluation shows that PBCount can computecounts for 1513 instances while the current state-of-the-art approach couldonly handle 1013 instances. Our work opens up several avenues for future workin the context of model counting for PB formulas, such as the development ofpreprocessing techniques and exploration of approaches other than knowledgecompilation.</description><author>Suwei Yang, Kuldeep S. Meel</author><pubDate>Tue, 19 Dec 2023 17:14:06 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.12341v1</guid></item><item><title>Scalable Geometric Fracture Assembly via Co-creation Space among Assemblers</title><link>http://arxiv.org/abs/2312.12340v1</link><description>Geometric fracture assembly presents a challenging practical task inarchaeology and 3D computer vision. Previous methods have focused solely onassembling fragments based on semantic information, which has limited thequantity of objects that can be effectively assembled. Therefore, there is aneed to develop a scalable framework for geometric fracture assembly withoutrelying on semantic information. To improve the effectiveness of assemblinggeometric fractures without semantic information, we propose a co-creationspace comprising several assemblers capable of gradually and unambiguouslyassembling fractures. Additionally, we introduce a novel loss function, i.e.,the geometric-based collision loss, to address collision issues during thefracture assembly process and enhance the results. Our framework exhibitsbetter performance on both PartNet and Breaking Bad datasets compared toexisting state-of-the-art frameworks. Extensive experiments and quantitativecomparisons demonstrate the effectiveness of our proposed framework, whichfeatures linear computational complexity, enhanced abstraction, and improvedgeneralization. Our code is publicly available athttps://github.com/Ruiyuan-Zhang/CCS.</description><author>Ruiyuan Zhang, Jiaxiang Liu, Zexi Li, Hao Dong, Jie Fu, Chao Wu</author><pubDate>Tue, 19 Dec 2023 17:13:51 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.12340v1</guid></item><item><title>Value Explicit Pretraining for Goal-Based Transfer Learning</title><link>http://arxiv.org/abs/2312.12339v1</link><description>We propose a method that allows for learning task-agnostic representationsbased on value function estimates from a sequence of observations where thelast frame corresponds to a goal. These representations would learn to relatestates across different tasks, based on the temporal distance to the goalstate, irrespective of the appearance changes and dynamics. This method couldbe used to transfer learnt policies/skills to unseen related tasks.</description><author>Kiran Lekkala, Henghui Bao, Sumedh Sontakke, Laurent Itti</author><pubDate>Tue, 19 Dec 2023 17:12:35 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.12339v1</guid></item><item><title>Learning from Mistakes: Self-Regularizing Hierarchical Representations in Point Cloud Semantic Segmentation</title><link>http://arxiv.org/abs/2301.11145v2</link><description>Recent advances in autonomous robotic technologies have highlighted thegrowing need for precise environmental analysis. LiDAR semantic segmentationhas gained attention to accomplish fine-grained scene understanding by actingdirectly on raw content provided by sensors. Recent solutions showed howdifferent learning techniques can be used to improve the performance of themodel, without any architectural or dataset change. Following this trend, wepresent a coarse-to-fine setup that LEArns from classification mistaKes (LEAK)derived from a standard model. First, classes are clustered into macro groupsaccording to mutual prediction errors; then, the learning process isregularized by: (1) aligning class-conditional prototypical featurerepresentation for both fine and coarse classes, (2) weighting instances with aper-class fairness index. Our LEAK approach is very general and can beseamlessly applied on top of any segmentation architecture; indeed,experimental results showed that it enables state-of-the-art performances ondifferent architectures, datasets and tasks, while ensuring more balancedclass-wise results and faster convergence.</description><author>Elena Camuffo, Umberto Michieli, Simone Milani</author><pubDate>Tue, 19 Dec 2023 17:09:04 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2301.11145v2</guid></item><item><title>Bayesian Methods for Media Mix Modelling with shape and funnel effects</title><link>http://arxiv.org/abs/2311.05587v4</link><description>In recent years, significant progress in generative AI has highlighted theimportant role of physics-inspired models that utilize advanced mathematicalconcepts based on fundamental physics principles to enhance artificialintelligence capabilities. Among these models, those based on diffusionequations have greatly improved image quality. This study aims to explore thepotential uses of Maxwell-Boltzmann equation, which forms the basis of thekinetic theory of gases, and the Michaelis-Menten model in Marketing MixModelling (MMM) applications. We propose incorporating these equations intoHierarchical Bayesian models to analyse consumer behaviour in the context ofadvertising. These equation sets excel in accurately describing the randomdynamics in complex systems like social interactions and consumer-advertisinginteractions.</description><author>Javier Marin</author><pubDate>Tue, 19 Dec 2023 17:07:19 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.05587v4</guid></item><item><title>auto-sktime: Automated Time Series Forecasting</title><link>http://arxiv.org/abs/2312.08528v2</link><description>In today's data-driven landscape, time series forecasting is pivotal indecision-making across various sectors. Yet, the proliferation of more diversetime series data, coupled with the expanding landscape of available forecastingmethods, poses significant challenges for forecasters. To meet the growingdemand for efficient forecasting, we introduce auto-sktime, a novel frameworkfor automated time series forecasting. The proposed framework uses the power ofautomated machine learning (AutoML) techniques to automate the creation of theentire forecasting pipeline. The framework employs Bayesian optimization, toautomatically construct pipelines from statistical, machine learning (ML) anddeep neural network (DNN) models. Furthermore, we propose three essentialimprovements to adapt AutoML to time series data: First, pipeline templates toaccount for the different supported forecasting models. Second, a novelwarm-starting technique to start the optimization from prior optimization runs.Third, we adapt multi-fidelity optimizations to make them applicable to asearch space containing statistical, ML and DNN models. Experimental results on64 diverse real-world time series datasets demonstrate the effectiveness andefficiency of the framework, outperforming traditional methods while requiringminimal human involvement.</description><author>Marc-André Zöller, Marius Lindauer, Marco F. Huber</author><pubDate>Tue, 19 Dec 2023 17:07:02 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.08528v2</guid></item><item><title>Who Reviews The Reviewers? A Multi-Level Jury Problem</title><link>http://arxiv.org/abs/2211.08494v2</link><description>We consider the problem of determining a binary ground truth using advicefrom a group of independent reviewers (experts) who express their guess about aground truth correctly with some independent probability (competence). In thissetting, when all reviewers are competent (competence greater than one-half),the Condorcet Jury Theorem tells us that adding more reviewers increases theoverall accuracy, and if all competences are known, then there exists anoptimal weighting of the reviewers. However, in practical settings, reviewersmay be noisy or incompetent, i.e., competence below half, and the number ofexperts may be small, so the asymptotic Condorcet Jury Theorem is notpractically relevant. In such cases we explore appointing one or more chairs(judges) who determine the weight of each reviewer for aggregation, creatingmultiple levels. However, these chairs may be unable to correctly identify thecompetence of the reviewers they oversee, and therefore unable to compute theoptimal weighting. We give conditions when a set of chairs is able to weightthe reviewers optimally, and depending on the competence distribution of theagents, give results about when it is better to have more chairs or morereviewers. Through numerical simulations we show that in some cases it isbetter to have more chairs, but in many cases it is better to have morereviewers.</description><author>Ben Abramowitz, Omer Lev, Nicholas Mattei</author><pubDate>Tue, 19 Dec 2023 17:04:59 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2211.08494v2</guid></item><item><title>pixelSplat: 3D Gaussian Splats from Image Pairs for Scalable Generalizable 3D Reconstruction</title><link>http://arxiv.org/abs/2312.12337v1</link><description>We introduce pixelSplat, a feed-forward model that learns to reconstruct 3Dradiance fields parameterized by 3D Gaussian primitives from pairs of images.Our model features real-time and memory-efficient rendering for scalabletraining as well as fast 3D reconstruction at inference time. To overcome localminima inherent to sparse and locally supported representations, we predict adense probability distribution over 3D and sample Gaussian means from thatprobability distribution. We make this sampling operation differentiable via areparameterization trick, allowing us to back-propagate gradients through theGaussian splatting representation. We benchmark our method on wide-baselinenovel view synthesis on the real-world RealEstate10k and ACID datasets, wherewe outperform state-of-the-art light field transformers and acceleraterendering by 2.5 orders of magnitude while reconstructing an interpretable andeditable 3D radiance field.</description><author>David Charatan, Sizhe Li, Andrea Tagliasacchi, Vincent Sitzmann</author><pubDate>Tue, 19 Dec 2023 17:03:50 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.12337v1</guid></item><item><title>PowMix: A Versatile Regularizer for Multimodal Sentiment Analysis</title><link>http://arxiv.org/abs/2312.12334v1</link><description>Multimodal sentiment analysis (MSA) leverages heterogeneous data sources tointerpret the complex nature of human sentiments. Despite significant progressin multimodal architecture design, the field lacks comprehensive regularizationmethods. This paper introduces PowMix, a versatile embedding space regularizerthat builds upon the strengths of unimodal mixing-based regularizationapproaches and introduces novel algorithmic components that are specificallytailored to multimodal tasks. PowMix is integrated before the fusion stage ofmultimodal architectures and facilitates intra-modal mixing, such as mixingtext with text, to act as a regularizer. PowMix consists of five components: 1)a varying number of generated mixed examples, 2) mixing factor reweighting, 3)anisotropic mixing, 4) dynamic mixing, and 5) cross-modal label mixing.Extensive experimentation across benchmark MSA datasets and a broad spectrum ofdiverse architectural designs demonstrate the efficacy of PowMix, as evidencedby consistent performance improvements over baselines and existing mixingmethods. An in-depth ablation study highlights the critical contribution ofeach PowMix component and how they synergistically enhance performance.Furthermore, algorithmic analysis demonstrates how PowMix behaves in differentscenarios, particularly comparing early versus late fusion architectures.Notably, PowMix enhances overall performance without sacrificing modelrobustness or magnifying text dominance. It also retains its strong performancein situations of limited data. Our findings position PowMix as a promisingversatile regularization strategy for MSA. Code will be made available.</description><author>Efthymios Georgiou, Yannis Avrithis, Alexandros Potamianos</author><pubDate>Tue, 19 Dec 2023 17:01:58 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.12334v1</guid></item><item><title>Topological complexity of spiked random polynomials and finite-rank spherical integrals</title><link>http://arxiv.org/abs/2312.12323v1</link><description>We study the annealed complexity of a random Gaussian homogeneous polynomialon the $N$-dimensional unit sphere in the presence of deterministic polynomialsthat depend on fixed unit vectors and external parameters. In particular, weestablish variational formulas for the exponential asymptotics of the averagenumber of total critical points and of local maxima. This is obtained throughthe Kac-Rice formula and the determinant asymptotics of a finite-rankperturbation of a Gaussian Wigner matrix. More precisely, the determinantanalysis is based on recent advances on finite-rank spherical integrals by[Guionnet, Husson 2022] to study the large deviations of multi-rank spikedGaussian Wigner matrices. The analysis of the variational problem identifies atopological phase transition. There is an exact threshold for the externalparameters such that, once exceeded, the complexity function vanishes into newregions in which the critical points are close to the given vectors.Interestingly, these regions also include those where critical points are closeto multiple vectors.</description><author>Vanessa Piccolo</author><pubDate>Tue, 19 Dec 2023 16:52:01 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.12323v1</guid></item><item><title>Bypassing the Safety Training of Open-Source LLMs with Priming Attacks</title><link>http://arxiv.org/abs/2312.12321v1</link><description>With the recent surge in popularity of LLMs has come an ever-increasing needfor LLM safety training. In this paper, we show that SOTA open-source LLMs arevulnerable to simple, optimization-free attacks we refer to as $\textit{primingattacks}$, which are easy to execute and effectively bypass alignment fromsafety training. Our proposed attack improves the Attack Success Rate onHarmful Behaviors, as measured by Llama Guard, by up to $3.3\times$ compared tobaselines. Source code and data are available athttps://github.com/uiuc-focal-lab/llm-priming-attacks .</description><author>Jason Vega, Isha Chaudhary, Changming Xu, Gagandeep Singh</author><pubDate>Tue, 19 Dec 2023 16:47:12 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.12321v1</guid></item><item><title>MoConVQ: Unified Physics-Based Motion Control via Scalable Discrete Representations</title><link>http://arxiv.org/abs/2310.10198v3</link><description>In this work, we present MoConVQ, a novel unified framework for physics-basedmotion control leveraging scalable discrete representations. Building uponvector quantized variational autoencoders (VQ-VAE) and model-basedreinforcement learning, our approach effectively learns motion embeddings froma large, unstructured dataset spanning tens of hours of motion examples. Theresultant motion representation not only captures diverse motion skills butalso offers a robust and intuitive interface for various applications. Wedemonstrate the versatility of MoConVQ through several applications: universaltracking control from various motion sources, interactive character controlwith latent motion representations using supervised learning, physics-basedmotion generation from natural language descriptions using the GPT framework,and, most interestingly, seamless integration with large language models (LLMs)with in-context learning to tackle complex and abstract tasks.</description><author>Heyuan Yao, Zhenhua Song, Yuyang Zhou, Tenglong Ao, Baoquan Chen, Libin Liu</author><pubDate>Tue, 19 Dec 2023 16:44:46 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.10198v3</guid></item><item><title>An Alternate View on Optimal Filtering in an RKHS</title><link>http://arxiv.org/abs/2312.12318v1</link><description>Kernel Adaptive Filtering (KAF) are mathematically principled methods whichsearch for a function in a Reproducing Kernel Hilbert Space. While they workwell for tasks such as time series prediction and system identification theyare plagued by a linear relationship between number of training samples andmodel size, hampering their use on the very large data sets common in today'sdata saturated world. Previous methods try to solve this issue bysparsification. We describe a novel view of optimal filtering which may providea route towards solutions in a RKHS which do not necessarily have this lineargrowth in model size. We do this by defining a RKHS in which the time structureof a stochastic process is still present. Using correntropy [11], an extensionof the idea of a covariance function, we create a time based functional whichdescribes some potentially nonlinear desired mapping function. This form of asolution may provide a fruitful line of research for creating more efficientrepresentations of functionals in a RKHS, while theoretically providingcomputational complexity in the test set similar to Wiener solution.</description><author>Benjamin Colburn, Jose C. Principe, Luis G. Sanchez Giraldo</author><pubDate>Tue, 19 Dec 2023 16:43:17 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.12318v1</guid></item><item><title>Celestial Machine Learning: Discovering the Planarity, Heliocentricity, and Orbital Equation of Mars with AI Feynman</title><link>http://arxiv.org/abs/2312.12315v1</link><description>Can a machine or algorithm discover or learn the elliptical orbit of Marsfrom astronomical sightings alone? Johannes Kepler required two paradigm shiftsto discover his First Law regarding the elliptical orbit of Mars. Firstly, ashift from the geocentric to the heliocentric frame of reference. Secondly, thereduction of the orbit of Mars from a three- to a two-dimensional space. Weextend AI Feynman, a physics-inspired tool for symbolic regression, to discoverthe heliocentricity and planarity of Mars' orbit and emulate his discovery ofKepler's first law.</description><author>Zi-Yu Khoo, Gokul Rajiv, Abel Yang, Jonathan Sze Choong Low, Stéphane Bressan</author><pubDate>Tue, 19 Dec 2023 16:39:32 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.12315v1</guid></item><item><title>First qualitative observations on deep learning vision model YOLO and DETR for automated driving in Austria</title><link>http://arxiv.org/abs/2312.12314v1</link><description>This study investigates the application of single and two-stage 2D-objectdetection algorithms like You Only Look Once (YOLO), Real-Time DEtectionTRansformer (RT-DETR) algorithm for automated object detection to enhance roadsafety for autonomous driving on Austrian roads. The YOLO algorithm is astate-of-the-art real-time object detection system known for its efficiency andaccuracy. In the context of driving, its potential to rapidly identify andtrack objects is crucial for advanced driver assistance systems (ADAS) andautonomous vehicles. The research focuses on the unique challenges posed by theroad conditions and traffic scenarios in Austria. The country's diverselandscape, varying weather conditions, and specific traffic regulationsnecessitate a tailored approach for reliable object detection. The studyutilizes a selective dataset comprising images and videos captured on Austrianroads, encompassing urban, rural, and alpine environments.</description><author>Stefan Schoder</author><pubDate>Tue, 19 Dec 2023 16:39:02 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.12314v1</guid></item><item><title>A Comparative Evaluation of Additive Separability Tests for Physics-Informed Machine Learning</title><link>http://arxiv.org/abs/2312.09775v2</link><description>Many functions characterising physical systems are additively separable. Thisis the case, for instance, of mechanical Hamiltonian functions in physics,population growth equations in biology, and consumer preference and utilityfunctions in economics. We consider the scenario in which a surrogate of afunction is to be tested for additive separability. The detection that thesurrogate is additively separable can be leveraged to improve further learning.Hence, it is beneficial to have the ability to test for such separability insurrogates. The mathematical approach is to test if the mixed partialderivative of the surrogate is zero; or empirically, lower than a threshold. Wepresent and comparatively and empirically evaluate the eight methods to computethe mixed partial derivative of a surrogate function.</description><author>Zi-Yu Khoo, Jonathan Sze Choong Low, Stéphane Bressan</author><pubDate>Tue, 19 Dec 2023 16:35:56 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.09775v2</guid></item><item><title>Anonymizing Speech: Evaluating and Designing Speaker Anonymization Techniques</title><link>http://arxiv.org/abs/2308.04455v3</link><description>The growing use of voice user interfaces has led to a surge in the collectionand storage of speech data. While data collection allows for the development ofefficient tools powering most speech services, it also poses serious privacyissues for users as centralized storage makes private personal speech datavulnerable to cyber threats. With the increasing use of voice-based digitalassistants like Amazon's Alexa, Google's Home, and Apple's Siri, and with theincreasing ease with which personal speech data can be collected, the risk ofmalicious use of voice-cloning and speaker/gender/pathological/etc. recognitionhas increased. This thesis proposes solutions for anonymizing speech and evaluating thedegree of the anonymization. In this work, anonymization refers to makingpersonal speech data unlinkable to an identity while maintaining the usefulness(utility) of the speech signal (e.g., access to linguistic content). We startby identifying several challenges that evaluation protocols need to consider toevaluate the degree of privacy protection properly. We clarify howanonymization systems must be configured for evaluation purposes and highlightthat many practical deployment configurations do not permit privacy evaluation.Furthermore, we study and examine the most common voice conversion-basedanonymization system and identify its weak points before suggesting new methodsto overcome some limitations. We isolate all components of the anonymizationsystem to evaluate the degree of speaker PPI associated with each of them.Then, we propose several transformation methods for each component to reduce asmuch as possible speaker PPI while maintaining utility. We promoteanonymization algorithms based on quantization-based transformation as analternative to the most-used and well-known noise-based approach. Finally, weendeavor a new attack method to invert anonymization.</description><author>Pierre Champion</author><pubDate>Tue, 19 Dec 2023 16:33:03 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2308.04455v3</guid></item><item><title>Instruct-SCTG: Guiding Sequential Controlled Text Generation through Instructions</title><link>http://arxiv.org/abs/2312.12299v1</link><description>Instruction-tuned large language models have shown remarkable performance inaligning generated text with user intentions across various tasks. However,maintaining human-like discourse structure in the generated text remains achallenging research question. In this paper, we propose Instruct-SCTG, aflexible and effective sequential framework that harnesses instruction-tunedlanguage models to generate structurally coherent text in both fine-tuned andzero-shot setups. Our framework generates articles in a section-by-sectionmanner, aligned with the desired human structure using natural languageinstructions. Furthermore, we introduce a new automatic metric that measuresdiscourse divergence in a fuzzy manner. Extensive experiments on three datasetsfrom representative domains of news and recipes demonstrate thestate-of-the-art performance of our framework in imposing discourse structureduring text generation, as verified by both automatic and human evaluation. Ourcode will be available on Github.</description><author>Yinhong Liu, Yixuan Su, Ehsan Shareghi, Nigel Collier</author><pubDate>Tue, 19 Dec 2023 16:20:49 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.12299v1</guid></item><item><title>Weak Kerr Nonlinearity Boosts the Performance of Frequency-Multiplexed Photonic Extreme Learning Machines: A Multifaceted Approach</title><link>http://arxiv.org/abs/2312.12296v1</link><description>We provide a theoretical, numerical, and experimental investigation of theKerr nonlinearity impact on the performance of a frequency-multiplexed ExtremeLearning Machine (ELM). In such ELM, the neuron signals are encoded in thelines of a frequency comb. The Kerr nonlinearity facilitates the randomizedneuron connections allowing for efficient information mixing. A programmablespectral filter applies the output weights. The system operates in acontinuous-wave regime. Even at low input peak powers, the resulting weak Kerrnonlinearity is sufficient to significantly boost the performance on severaltasks. This boost already arises when one uses only the very small Kerrnonlinearity present in a 20-meter long erbium-doped fiber amplifier. Incontrast, a subsequent propagation in 540 meters of a single-mode fiberimproves the performance only slightly, whereas additional information mixingwith a phase modulator does not result in a further improvement at all. Weintroduce a model to show that, in frequency-multiplexed ELMs, the Kerrnonlinearity mixes information via four-wave mixing, rather than via self- orcross-phase modulation. At low powers, this effect is quartic in the comb-lineamplitudes. Numerical simulations validate our experimental results andinterpretation.</description><author>Marina Zajnulina, Alessandro Lupo, Serge Massar</author><pubDate>Tue, 19 Dec 2023 16:18:59 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.12296v1</guid></item><item><title>FAL-CUR: Fair Active Learning using Uncertainty and Representativeness on Fair Clustering</title><link>http://arxiv.org/abs/2209.12756v2</link><description>Active Learning (AL) techniques have proven to be highly effective inreducing data labeling costs across a range of machine learning tasks.Nevertheless, one known challenge of these methods is their potential tointroduce unfairness towards sensitive attributes. Although recent approacheshave focused on enhancing fairness in AL, they tend to reduce the model'saccuracy. To address this issue, we propose a novel strategy, named Fair ActiveLearning using fair Clustering, Uncertainty, and Representativeness (FAL-CUR),to improve fairness in AL. FAL-CUR tackles the fairness problem in AL bycombining fair clustering with an acquisition function that determines whichsamples to query based on their uncertainty and representativeness scores. Weevaluate the performance of FAL-CUR on four real-world datasets, and theresults demonstrate that FAL-CUR achieves a 15% - 20% improvement in fairnesscompared to the best state-of-the-art method in terms of equalized odds whilemaintaining stable accuracy scores. Furthermore, an ablation study highlightsthe crucial roles of fair clustering in preserving fairness and the acquisitionfunction in stabilizing the accuracy performance.</description><author>Ricky Fajri, Akrati Saxena, Yulong Pei, Mykola Pechenizkiy</author><pubDate>Tue, 19 Dec 2023 16:17:04 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2209.12756v2</guid></item><item><title>Toward enriched Cognitive Learning with XAI</title><link>http://arxiv.org/abs/2312.12290v1</link><description>As computational systems supported by artificial intelligence (AI) techniquescontinue to play an increasingly pivotal role in making high-stakesrecommendations and decisions across various domains, the demand forexplainable AI (XAI) has grown significantly, extending its impact intocognitive learning research. Providing explanations for novel concepts isrecognised as a fundamental aid in the learning process, particularly whenaddressing challenges stemming from knowledge deficiencies and skillapplication. Addressing these difficulties involves timely explanations andguidance throughout the learning process, prompting the interest of AI expertsin developing explainer models. In this paper, we introduce an intelligentsystem (CL-XAI) for Cognitive Learning which is supported by XAI, focusing ontwo key research objectives: exploring how human learners comprehend theinternal mechanisms of AI models using XAI tools and evaluating theeffectiveness of such tools through human feedback. The use of CL-XAI isillustrated with a game-inspired virtual use case where learners tacklecombinatorial problems to enhance problem-solving skills and deepen theirunderstanding of complex concepts, highlighting the potential fortransformative advances in cognitive learning and co-learning.</description><author>Muhammad Suffian, Ulrike Kuhl, Jose M. Alonso-Moral, Alessandro Bogliolo</author><pubDate>Tue, 19 Dec 2023 16:13:47 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.12290v1</guid></item><item><title>Optimised Storage for Datalog Reasoning</title><link>http://arxiv.org/abs/2312.11297v2</link><description>Materialisation facilitates Datalog reasoning by precomputing allconsequences of the facts and the rules so that queries can be directlyanswered over the materialised facts. However, storing all materialised factsmay be infeasible in practice, especially when the rules are complex and thegiven set of facts is large. We observe that for certain combinations of rules,there exist data structures that compactly represent the reasoning result andcan be efficiently queried when necessary. In this paper, we present a generalframework that allows for the integration of such optimised storage schemeswith standard materialisation algorithms. Moreover, we devise optimised storageschemes targeting at transitive rules and union rules, two types of(combination of) rules that commonly occur in practice. Our experimentalevaluation shows that our approach significantly improves memory consumption,sometimes by orders of magnitude, while remaining competitive in terms of queryanswering time.</description><author>Xinyue Zhang, Pan Hu, Yavor Nenov, Ian Horrocks</author><pubDate>Tue, 19 Dec 2023 16:11:33 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.11297v2</guid></item><item><title>Designing Behavior Trees from Goal-Oriented LTLf Formulas</title><link>http://arxiv.org/abs/2307.06399v2</link><description>Temporal logic can be used to formally specify autonomous agent goals, butsynthesizing planners that guarantee goal satisfaction can be computationallyprohibitive. This paper shows how to turn goals specified using a subset offinite trace Linear Temporal Logic (LTL) into a behavior tree (BT) thatguarantees that successful traces satisfy the LTL goal. Useful LTL formulas forachievement goals can be derived using achievement-oriented task missiongrammars, leading to missions made up of tasks combined using LTL operators.Constructing BTs from LTL formulas leads to a relaxed behavior synthesisproblem in which a wide range of planners can implement the action nodes in theBT. Importantly, any successful trace induced by the planners satisfies thecorresponding LTL formula. The usefulness of the approach is demonstrated intwo ways: a) exploring the alignment between two planners and LTL goals, and b)solving a sequential key-door problem for a Fetch robot.</description><author>Aadesh Neupane, Eric G Mercer, Michael A. Goodrich</author><pubDate>Tue, 19 Dec 2023 16:11:05 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.06399v2</guid></item><item><title>A Baseline Analysis of Reward Models' Ability To Accurately Analyze Foundation Models Under Distribution Shift</title><link>http://arxiv.org/abs/2311.14743v5</link><description>Foundation models, specifically Large Language Models (LLM's), have latelygained wide-spread attention and adoption. Reinforcement Learning with HumanFeedback (RLHF) involves training a reward model to capture desired behaviors,which is then used to align LLM's. These reward models are additionally used atinference-time to estimate LLM responses' adherence to those desired behaviors.However, there is little work measuring how robust these reward models are todistribution shifts. In this work, we evaluate how reward model performance -measured via accuracy and calibration (i.e. alignment between accuracy andconfidence) - is affected by distribution shift. We show novel calibrationpatterns and accuracy drops due to OOD prompts and responses, and that thereward model is more sensitive to shifts in responses than prompts.Additionally, we adapt an OOD detection technique commonly used inclassification to the reward model setting to detect these distribution shiftsin prompts and responses.</description><author>Will LeVine, Ben Pikus, Tony Chen, Sean Hendryx</author><pubDate>Tue, 19 Dec 2023 16:05:51 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.14743v5</guid></item><item><title>Prompt-based Domain Discrimination for Multi-source Time Series Domain Adaptation</title><link>http://arxiv.org/abs/2312.12276v1</link><description>Time series domain adaptation stands as a pivotal and intricate challengewith diverse applications, including but not limited to human activityrecognition, sleep stage classification, and machine fault diagnosis. Despitethe numerous domain adaptation techniques proposed to tackle this complexproblem, their primary focus has been on the common representations of timeseries data. This concentration might inadvertently lead to the oversight ofvaluable domain-specific information originating from different source domains.To bridge this gap, we introduce POND, a novel prompt-based deep learning modeldesigned explicitly for multi-source time series domain adaptation. POND istailored to address significant challenges, notably: 1) The unavailability of aquantitative relationship between meta-data information and time seriesdistributions, and 2) The dearth of exploration into extracting domain-specificmeta-data information. In this paper, we present an instance-level promptgenerator and a fidelity loss mechanism to facilitate the faithful learning ofmeta-data information. Additionally, we propose a domain discriminationtechnique to discern domain-specific meta-data information from multiple sourcedomains. Our approach involves a simple yet effective meta-learning algorithmto optimize the objective efficiently. Furthermore, we augment the model'sperformance by incorporating the Mixture of Expert (MoE) technique. Theefficacy and robustness of our proposed POND model are extensively validatedthrough experiments across 50 scenarios encompassing five datasets, whichdemonstrates that our proposed POND model outperforms the state-of-the-artmethods by up to $66\%$ on the F1-score.</description><author>Junxiang Wang, Guangji Bai, Wei Cheng, Zhengzhang Chen, Liang Zhao, Haifeng Chen</author><pubDate>Tue, 19 Dec 2023 15:57:37 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.12276v1</guid></item><item><title>Emergence of In-Context Reinforcement Learning from Noise Distillation</title><link>http://arxiv.org/abs/2312.12275v1</link><description>In-Context Reinforcement Learning is an emerging field with great potentialfor advancing Artificial Intelligence. Its core capability lies in generalizingto unseen tasks through interaction with the environment. To master thesecapabilities, an agent must be trained on specifically curated data thatincludes a policy improvement that an algorithm seeks to extract and then applyin context in the environment. However, for numerous tasks, training RL agentsmay be unfeasible, while obtaining human demonstrations can be relatively easy.Additionally, it is rare to be given the optimal policy, typically, onlysuboptimal demonstrations are available. We propose $AD^{\epsilon}$, a methodthat leverages demonstrations without policy improvement and enables multi-taskin-context learning in the presence of a suboptimal demonstrator. This isachieved by artificially creating a history of incremental improvement, whereinnoise is systematically introduced into the demonstrator's policy.Consequently, each successive transition illustrates a marginally bettertrajectory than the previous one. Our approach was tested on the Dark Room andDark Key-to-Door environments, resulting in over a $\textbf{2}$x improvementcompared to the best available policy in the data.</description><author>Ilya Zisman, Vladislav Kurenkov, Alexander Nikulin, Viacheslav Sinii, Sergey Kolesnikov</author><pubDate>Tue, 19 Dec 2023 15:56:30 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.12275v1</guid></item><item><title>Intrinsic Image Diffusion for Single-view Material Estimation</title><link>http://arxiv.org/abs/2312.12274v1</link><description>We present Intrinsic Image Diffusion, a generative model for appearancedecomposition of indoor scenes. Given a single input view, we sample multiplepossible material explanations represented as albedo, roughness, and metallicmaps. Appearance decomposition poses a considerable challenge in computervision due to the inherent ambiguity between lighting and material propertiesand the lack of real datasets. To address this issue, we advocate for aprobabilistic formulation, where instead of attempting to directly predict thetrue material properties, we employ a conditional generative model to samplefrom the solution space. Furthermore, we show that utilizing the strong learnedprior of recent diffusion models trained on large-scale real-world images canbe adapted to material estimation and highly improves the generalization toreal images. Our method produces significantly sharper, more consistent, andmore detailed materials, outperforming state-of-the-art methods by $1.5dB$ onPSNR and by $45\%$ better FID score on albedo prediction. We demonstrate theeffectiveness of our approach through experiments on both synthetic andreal-world datasets.</description><author>Peter Kocsis, Vincent Sitzmann, Matthias Nießner</author><pubDate>Tue, 19 Dec 2023 15:56:19 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.12274v1</guid></item><item><title>VQA4CIR: Boosting Composed Image Retrieval with Visual Question Answering</title><link>http://arxiv.org/abs/2312.12273v1</link><description>Albeit progress has been made in Composed Image Retrieval (CIR), weempirically find that a certain percentage of failure retrieval results are notconsistent with their relative captions. To address this issue, this workprovides a Visual Question Answering (VQA) perspective to boost the performanceof CIR. The resulting VQA4CIR is a post-processing approach and can be directlyplugged into existing CIR methods. Given the top-C retrieved images by a CIRmethod, VQA4CIR aims to decrease the adverse effect of the failure retrievalresults being inconsistent with the relative caption. To find the retrievedimages inconsistent with the relative caption, we resort to the "QA generationto VQA" self-verification pipeline. For QA generation, we suggest fine-tuningLLM (e.g., LLaMA) to generate several pairs of questions and answers from eachrelative caption. We then fine-tune LVLM (e.g., LLaVA) to obtain the VQA model.By feeding the retrieved image and question to the VQA model, one can find theimages inconsistent with relative caption when the answer by VQA isinconsistent with the answer in the QA pair. Consequently, the CIR performancecan be boosted by modifying the ranks of inconsistently retrieved images.Experimental results show that our proposed method outperforms state-of-the-artCIR methods on the CIRR and Fashion-IQ datasets.</description><author>Chun-Mei Feng, Yang Bai, Tao Luo, Zhen Li, Salman Khan, Wangmeng Zuo, Xinxing Xu, Rick Siow Mong Goh, Yong Liu</author><pubDate>Tue, 19 Dec 2023 15:56:08 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.12273v1</guid></item><item><title>Debiasing Multimodal Sarcasm Detection with Contrastive Learning</title><link>http://arxiv.org/abs/2312.10493v2</link><description>Despite commendable achievements made by existing work, prevailing multimodalsarcasm detection studies rely more on textual content over visual information.It unavoidably induces spurious correlations between textual words and labels,thereby significantly hindering the models' generalization capability. Toaddress this problem, we define the task of out-of-distribution (OOD)multimodal sarcasm detection, which aims to evaluate models' generalizabilitywhen the word distribution is different in training and testing settings.Moreover, we propose a novel debiasing multimodal sarcasm detection frameworkwith contrastive learning, which aims to mitigate the harmful effect of biasedtextual factors for robust OOD generalization. In particular, we first designcounterfactual data augmentation to construct the positive samples withdissimilar word biases and negative samples with similar word biases.Subsequently, we devise an adapted debiasing contrastive learning mechanism toempower the model to learn robust task-relevant features and alleviate theadverse effect of biased words. Extensive experiments show the superiority ofthe proposed framework.</description><author>Mengzhao Jia, Can Xie, Liqiang Jing</author><pubDate>Tue, 19 Dec 2023 15:55:23 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.10493v2</guid></item><item><title>Automated speech audiometry: Can it work using open-source pre-trained Kaldi-NL automatic speech recognition?</title><link>http://arxiv.org/abs/2312.12269v1</link><description>A practical speech audiometry tool is the digits-in-noise (DIN) test forhearing screening of populations of varying ages and hearing status. The testis usually conducted by a human supervisor (e.g., clinician), who scores theresponses spoken by the listener, or online, where a software scores theresponses entered by the listener. The test has 24 digit-triplets presented inan adaptive staircase procedure, resulting in a speech reception threshold(SRT). We propose an alternative automated DIN test setup that can evaluatespoken responses whilst conducted without a human supervisor, using theopen-source automatic speech recognition toolkit, Kaldi-NL. Thirtyself-reported normal-hearing Dutch adults (19-64 years) completed oneDIN+Kaldi-NL test. Their spoken responses were recorded, and used forevaluating the transcript of decoded responses by Kaldi-NL. Study 1 evaluatedthe Kaldi-NL performance through its word error rate (WER), percentage ofsummed decoding errors regarding only digits found in the transcript comparedto the total number of digits present in the spoken responses. Average WERacross participants was 5.0% (range 0 - 48%, SD = 8.8%), with average decodingerrors in three triplets per participant. Study 2 analysed the effect thattriplets with decoding errors from Kaldi-NL had on the DIN test output (SRT),using bootstrapping simulations. Previous research indicated 0.70 dB as thetypical within-subject SRT variability for normal-hearing adults. Study 2showed that up to four triplets with decoding errors produce SRT variationswithin this range, suggesting that our proposed setup could be feasible forclinical applications.</description><author>Gloria Araiza-Illan, Luke Meyer, Khiet P. Truong, Deniz Baskent</author><pubDate>Tue, 19 Dec 2023 15:51:49 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.12269v1</guid></item><item><title>FedDiv: Collaborative Noise Filtering for Federated Learning with Noisy Labels</title><link>http://arxiv.org/abs/2312.12263v1</link><description>Federated learning with noisy labels (F-LNL) aims at seeking an optimalserver model via collaborative distributed learning by aggregating multipleclient models trained with local noisy or clean samples. On the basis of afederated learning framework, recent advances primarily adopt label noisefiltering to separate clean samples from noisy ones on each client, therebymitigating the negative impact of label noise. However, these prior methods donot learn noise filters by exploiting knowledge across all clients, leading tosub-optimal and inferior noise filtering performance and thus damaging trainingstability. In this paper, we present FedDiv to tackle the challenges of F-LNL.Specifically, we propose a global noise filter called Federated Noise Filterfor effectively identifying samples with noisy labels on every client, therebyraising stability during local training sessions. Without sacrificing dataprivacy, this is achieved by modeling the global distribution of label noiseacross all clients. Then, in an effort to make the global model achieve higherperformance, we introduce a Predictive Consistency based Sampler to identifymore credible local data for local model training, thus preventing noisememorization and further boosting the training stability. Extensive experimentson CIFAR-10, CIFAR-100, and Clothing1M demonstrate that \texttt{FedDiv}achieves superior performance over state-of-the-art F-LNL methods underdifferent label noise settings for both IID and non-IID data partitions. Sourcecode is publicly available at https://github.com/lijichang/FLNL-FedDiv.</description><author>Jichang Li, Guanbin Li, Hui Cheng, Zicheng Liao, Yizhou Yu</author><pubDate>Tue, 19 Dec 2023 15:46:47 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.12263v1</guid></item><item><title>Vertical Federated Alzheimer's Detection on Multimodal Data</title><link>http://arxiv.org/abs/2312.10237v2</link><description>In the era of rapidly advancing medical technologies, the segmentation ofmedical data has become inevitable, necessitating the development of privacypreserving machine learning algorithms that can train on distributed data.Consolidating sensitive medical data is not always an option particularly dueto the stringent privacy regulations imposed by the Health InsurancePortability and Accountability Act (HIPAA). In this paper, we introduce a HIPAAcompliant framework that can train from distributed data. We then propose amultimodal vertical federated model for Alzheimer's Disease (AD) detection, aserious neurodegenerative condition that can cause dementia, severely impairingbrain function and hindering simple tasks, especially without preventativecare. This vertical federated model offers a distributed architecture thatenables collaborative learning across diverse sources of medical data whilerespecting privacy constraints imposed by HIPAA. It is also able to leveragemultiple modalities of data, enhancing the robustness and accuracy of ADdetection. Our proposed model not only contributes to the advancement offederated learning techniques but also holds promise for overcoming the hurdlesposed by data segmentation in medical research. By using vertical federatedlearning, this research strives to provide a framework that enables healthcareinstitutions to harness the collective intelligence embedded in theirdistributed datasets without compromising patient privacy.</description><author>Paul K. Mandal</author><pubDate>Tue, 19 Dec 2023 15:44:40 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.10237v2</guid></item><item><title>PPFM: Image denoising in photon-counting CT using single-step posterior sampling Poisson flow generative models</title><link>http://arxiv.org/abs/2312.09754v2</link><description>Diffusion and Poisson flow models have shown impressive performance in a widerange of generative tasks, including low-dose CT image denoising. However, onelimitation in general, and for clinical applications in particular, is slowsampling. Due to their iterative nature, the number of function evaluations(NFE) required is usually on the order of $10-10^3$, both for conditional andunconditional generation. In this paper, we present posterior sampling Poissonflow generative models (PPFM), a novel image denoising technique for low-doseand photon-counting CT that produces excellent image quality whilst keepingNFE=1. Updating the training and sampling processes of Poisson flow generativemodels (PFGM)++, we learn a conditional generator which defines a trajectorybetween the prior noise distribution and the posterior distribution ofinterest. We additionally hijack and regularize the sampling process to achieveNFE=1. Our results shed light on the benefits of the PFGM++ framework comparedto diffusion models. In addition, PPFM is shown to perform favorably comparedto current state-of-the-art diffusion-style models with NFE=1, consistencymodels, as well as popular deep learning and non-deep learning-based imagedenoising techniques, on clinical low-dose CT images and clinical images from aprototype photon-counting CT system.</description><author>Dennis Hein, Staffan Holmin, Timothy Szczykutowicz, Jonathan S Maltz, Mats Danielsson, Ge Wang, Mats Persson</author><pubDate>Tue, 19 Dec 2023 15:44:15 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.09754v2</guid></item><item><title>Inferring the relationship between soil temperature and the normalized difference vegetation index with machine learning</title><link>http://arxiv.org/abs/2312.12258v1</link><description>Changes in climate can greatly affect the phenology of plants, which can haveimportant feedback effects, such as altering the carbon cycle. Thesephenological feedback effects are often induced by a shift in the start or enddates of the growing season of plants. The normalized difference vegetationindex (NDVI) serves as a straightforward indicator for assessing the presenceof green vegetation and can also provide an estimation of the plants' growingseason. In this study, we investigated the effect of soil temperature on thetiming of the start of the season (SOS), timing of the peak of the season(POS), and the maximum annual NDVI value (PEAK) in subarctic grasslandecosystems between 2014 and 2019. We also explored the impact of othermeteorological variables, including air temperature, precipitation, andirradiance, on the inter-annual variation in vegetation phenology. Usingmachine learning (ML) techniques and SHapley Additive exPlanations (SHAP)values, we analyzed the relative importance and contribution of each variableto the phenological predictions. Our results reveal a significant relationshipbetween soil temperature and SOS and POS, indicating that higher soiltemperatures lead to an earlier start and peak of the growing season. However,the Peak NDVI values showed just a slight increase with higher soiltemperatures. The analysis of other meteorological variables demonstrated theirimpacts on the inter-annual variation of the vegetation phenology. Ultimately,this study contributes to our knowledge of the relationships between soiltemperature, meteorological variables, and vegetation phenology, providingvaluable insights for predicting vegetation phenology characteristics andmanaging subarctic grasslands in the face of climate change. Additionally, thiswork provides a solid foundation for future ML-based vegetation phenologystudies.</description><author>Steven Mortier, Amir Hamedpour, Bart Bussmann, Ruth Phoebe Tchana Wandji, Steven Latré, Bjarni D. Sigurdsson, Tom De Schepper, Tim Verdonck</author><pubDate>Tue, 19 Dec 2023 15:43:50 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.12258v1</guid></item><item><title>TaskFlex Solver for Multi-Agent Pursuit via Automatic Curriculum Learning</title><link>http://arxiv.org/abs/2312.12255v1</link><description>This paper addresses the problem of multi-agent pursuit, where slow pursuerscooperate to capture fast evaders in a confined environment with obstacles.Existing heuristic algorithms often lack expressive coordination strategies andare highly sensitive to task conditions, requiring extensive hyperparametertuning. In contrast, reinforcement learning (RL) has been applied to thisproblem and is capable of obtaining cooperative pursuit strategies. However,RL-based methods face challenges in training for complex scenarios due to thevast amount of training data and limited adaptability to varying taskconditions, such as different scene sizes, varying numbers and speeds ofobstacles, and flexible speed ratios of the evader to the pursuer. In thiswork, we combine RL and curriculum learning to introduce a flexible solver formultiagent pursuit problems, named TaskFlex Solver (TFS), which is capable ofsolving multi-agent pursuit problems with diverse and dynamically changing taskconditions in both 2-dimensional and 3-dimensional scenarios. TFS utilizes acurriculum learning method that constructs task distributions based on trainingprogress, enhancing training efficiency and final performance. Our algorithmconsists of two main components: the Task Evaluator, which evaluates tasksuccess rates and selects tasks of moderate difficulty to maintain a curriculumarchive, and the Task Sampler, which constructs training distributions bysampling tasks from the curriculum archive to maximize policy improvement.Experiments show that TFS produces much stronger performance than baselines andachieves close to 100% capture rates in both 2-dimensional and 3-dimensionalmulti-agent pursuit problems with diverse and dynamically changing scenes. Theproject website is at https://sites.google.com/view/tfs-2023.</description><author>Jiayu Chen, Guosheng Li, Chao Yu, Xinyi Yang, Botian Xu, Huazhong Yang, Yu Wang</author><pubDate>Tue, 19 Dec 2023 15:39:09 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.12255v1</guid></item><item><title>Geo-located Aspect Based Sentiment Analysis (ABSA) for Crowdsourced Evaluation of Urban Environments</title><link>http://arxiv.org/abs/2312.12253v1</link><description>Sentiment analysis methods are rapidly being adopted by the field of UrbanDesign and Planning, for the crowdsourced evaluation of urban environments.However, most models used within this domain are able to identify positive ornegative sentiment associated with a textual appraisal as a whole, withoutinferring information about specific urban aspects contained within it, or thesentiment associated with them. While Aspect Based Sentiment Analysis (ABSA) isbecoming increasingly popular, most existing ABSA models are trained onnon-urban themes such as restaurants, electronics, consumer goods and the like.This body of research develops an ABSA model capable of extracting urbanaspects contained within geo-located textual urban appraisals, along withcorresponding aspect sentiment classification. We annotate a dataset of 2500crowdsourced reviews of public parks, and train a Bidirectional EncoderRepresentations from Transformers (BERT) model with Local Context Focus (LCF)on this data. Our model achieves significant improvement in prediction accuracyon urban reviews, for both Aspect Term Extraction (ATE) and Aspect SentimentClassification (ASC) tasks. For demonstrative analysis, positive and negativeurban aspects across Boston are spatially visualized. We hope that this modelis useful for designers and planners for fine-grained urban sentimentevaluation.</description><author>Demircan Tas, Rohit Priyadarshi Sanatani</author><pubDate>Tue, 19 Dec 2023 15:37:27 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.12253v1</guid></item><item><title>HypLL: The Hyperbolic Learning Library</title><link>http://arxiv.org/abs/2306.06154v3</link><description>Deep learning in hyperbolic space is quickly gaining traction in the fieldsof machine learning, multimedia, and computer vision. Deep networks commonlyoperate in Euclidean space, implicitly assuming that data lies on regulargrids. Recent advances have shown that hyperbolic geometry provides a viablealternative foundation for deep learning, especially when data is hierarchicalin nature and when working with few embedding dimensions. Currently however, noaccessible open-source library exists to build hyperbolic network modules akinto well-known deep learning libraries. We present HypLL, the HyperbolicLearning Library to bring the progress on hyperbolic deep learning together.HypLL is built on top of PyTorch, with an emphasis in its design forease-of-use, in order to attract a broad audience towards this new andopen-ended research direction. The code is available at:https://github.com/maxvanspengler/hyperbolic_learning_library.</description><author>Max van Spengler, Philipp Wirth, Pascal Mettes</author><pubDate>Tue, 19 Dec 2023 15:37:22 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.06154v3</guid></item><item><title>ST(OR)2: Spatio-Temporal Object Level Reasoning for Activity Recognition in the Operating Room</title><link>http://arxiv.org/abs/2312.12250v1</link><description>Surgical robotics holds much promise for improving patient safety andclinician experience in the Operating Room (OR). However, it also comes withnew challenges, requiring strong team coordination and effective OR management.Automatic detection of surgical activities is a key requirement for developingAI-based intelligent tools to tackle these challenges. The currentstate-of-the-art surgical activity recognition methods however operate onimage-based representations and depend on large-scale labeled datasets whosecollection is time-consuming and resource-expensive. This work proposes a newsample-efficient and object-based approach for surgical activity recognition inthe OR. Our method focuses on the geometric arrangements between clinicians andsurgical devices, thus utilizing the significant object interaction dynamics inthe OR. We conduct experiments in a low-data regime study for long videoactivity recognition. We also benchmark our method againstother object-centricapproaches on clip-level action classification and show superior performance.</description><author>Idris Hamoud, Muhammad Abdullah Jamal, Vinkle Srivastav, Didier Mutter, Nicolas Padoy, Omid Mohareri</author><pubDate>Tue, 19 Dec 2023 15:33:57 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.12250v1</guid></item><item><title>MDD-UNet: Domain Adaptation for Medical Image Segmentation with Theoretical Guarantees, a Proof of Concept</title><link>http://arxiv.org/abs/2312.12246v1</link><description>The current state-of-the art techniques for image segmentation are oftenbased on U-Net architectures, a U-shaped encoder-decoder networks with skipconnections. Despite the powerful performance, the architecture often does notperform well when used on data which has different characteristics than thedata it was trained on. Many techniques for improving performance in thepresence of domain shift have been developed, however typically only have looseconnections to the theory of domain adaption. In this work, we propose anunsupervised domain adaptation framework for U-Nets with theoretical guaranteesbased on the Margin Disparity Discrepancy [1] called the MDD-UNet. We evaluatethe proposed technique on the task of hippocampus segmentation, and find thatthe MDD-UNet is able to learn features which are domain-invariant with noknowledge about the labels in the target domain. The MDD-UNet improvesperformance over the standard U-Net on 11 out of 12 combinations of datasets.This work serves as a proof of concept by demonstrating an improvement on theU-Net in it's standard form without modern enhancements, which opens up a newavenue of studying domain adaptation for models with very large hypothesisspaces from both methodological and practical perspectives. Code is availableat https://github.com/asbjrnmunk/mdd-unet.</description><author>Asbjørn Munk, Ao Ma, Mads Nielsen</author><pubDate>Tue, 19 Dec 2023 15:30:10 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.12246v1</guid></item><item><title>Optimization Theory Based Deep Reinforcement Learning for Resource Allocation in Ultra-Reliable Wireless Networked Control Systems</title><link>http://arxiv.org/abs/2311.16895v2</link><description>The design of Wireless Networked Control System (WNCS) requires addressingcritical interactions between control and communication systems with minimalcomplexity and communication overhead while providing ultra-high reliability.This paper introduces a novel optimization theory based deep reinforcementlearning (DRL) framework for the joint design of controller and communicationsystems. The objective of minimum power consumption is targeted whilesatisfying the schedulability and rate constraints of the communication systemin the finite blocklength regime and stability constraint of the controlsystem. Decision variables include the sampling period in the control system,and blocklength and packet error probability in the communication system. Theproposed framework contains two stages: optimization theory and DRL. In theoptimization theory stage, following the formulation of the joint optimizationproblem, optimality conditions are derived to find the mathematical relationsbetween the optimal values of the decision variables. These relations allow thedecomposition of the problem into multiple building blocks. In the DRL stage,the blocks that are simplified but not tractable are replaced by DRL. Viaextensive simulations, the proposed optimization theory based DRL approach isdemonstrated to outperform the optimization theory and pure DRL basedapproaches, with close to optimal performance and much lower complexity.</description><author>Hamida Qumber Ali, Amirhassan Babazadeh Darabi, Sinem Coleri</author><pubDate>Tue, 19 Dec 2023 15:26:36 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.16895v2</guid></item><item><title>Mathematical Foundations for a Compositional Account of the Bayesian Brain</title><link>http://arxiv.org/abs/2212.12538v3</link><description>This dissertation reports some first steps towards a compositional account ofactive inference and the Bayesian brain. Specifically, we use the tools ofcontemporary applied category theory to supply functorial semantics forapproximate inference. To do so, we define on the `syntactic' side the newnotion of Bayesian lens and show that Bayesian updating composes according tothe compositional lens pattern. Using Bayesian lenses, and inspired bycompositional game theory, we define fibrations of statistical games andclassify various problems of statistical inference as corresponding sections:the chain rule of the relative entropy is formalized as a strict section, whilemaximum likelihood estimation and the free energy give lax sections. In theprocess, we introduce a new notion of `copy-composition'. On the `semantic' side, we present a new formalization of general opendynamical systems (particularly: deterministic, stochastic, and random; anddiscrete- and continuous-time) as certain coalgebras of polynomial functors,which we show collect into monoidal opindexed categories (or, alternatively,into algebras for multicategories of generalized polynomial functors). We usethese opindexed categories to define monoidal bicategories of cilia: dynamicalsystems which control lenses, and which supply the target for our functorialsemantics. Accordingly, we construct functors which explain the bidirectionalcompositional structure of predictive coding neural circuits under the freeenergy principle, thereby giving a formal mathematical underpinning to thebidirectionality observed in the cortex. Along the way, we explain how tocompose rate-coded neural circuits using an algebra for a multicategory oflinear circuit diagrams, showing subsequently that this is subsumed by lensesand polynomial functors.</description><author>Toby St Clere Smithe</author><pubDate>Tue, 19 Dec 2023 15:25:42 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2212.12538v3</guid></item><item><title>GeomVerse: A Systematic Evaluation of Large Models for Geometric Reasoning</title><link>http://arxiv.org/abs/2312.12241v1</link><description>Large language models have shown impressive results for multi-hopmathematical reasoning when the input question is only textual. Manymathematical reasoning problems, however, contain both text and image. With theever-increasing adoption of vision language models (VLMs), understanding theirreasoning abilities for such problems is crucial. In this paper, we evaluatethe reasoning capabilities of VLMs along various axes through the lens ofgeometry problems. We procedurally create a synthetic dataset of geometryquestions with controllable difficulty levels along multiple axes, thusenabling a systematic evaluation. The empirical results obtained using ourbenchmark for state-of-the-art VLMs indicate that these models are not ascapable in subjects like geometry (and, by generalization, other topicsrequiring similar reasoning) as suggested by previous benchmarks. This is madeespecially clear by the construction of our benchmark at various depth levels,since solving higher-depth problems requires long chains of reasoning ratherthan additional memorized knowledge. We release the dataset for furtherresearch in this area.</description><author>Mehran Kazemi, Hamidreza Alvari, Ankit Anand, Jialin Wu, Xi Chen, Radu Soricut</author><pubDate>Tue, 19 Dec 2023 15:25:39 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.12241v1</guid></item><item><title>Fast Neural Network Inference on FPGAs for Triggering on Long-Lived Particles at Colliders</title><link>http://arxiv.org/abs/2307.05152v2</link><description>Experimental particle physics demands a sophisticated trigger and acquisitionsystem capable to efficiently retain the collisions of interest for furtherinvestigation. Heterogeneous computing with the employment of FPGA cards mayemerge as a trending technology for the triggering strategy of the upcominghigh-luminosity program of the Large Hadron Collider at CERN. In this context,we present two machine-learning algorithms for selecting events where neutrallong-lived particles decay within the detector volume studying their accuracyand inference time when accelerated on commercially available Xilinx FPGAaccelerator cards. The inference time is also confronted with a CPU- andGPU-based hardware setup. The proposed new algorithms are proven efficient forthe considered benchmark physics scenario and their accuracy is found to notdegrade when accelerated on the FPGA cards. The results indicate that alltested architectures fit within the latency requirements of a second-leveltrigger farm and that exploiting accelerator technologies for real-timeprocessing of particle-physics collisions is a promising research field thatdeserves additional investigations, in particular with machine-learning modelswith a large number of trainable parameters.</description><author>Andrea Coccaro, Francesco Armando Di Bello, Stefano Giagu, Lucrezia Rambelli, Nicola Stocchetti</author><pubDate>Tue, 19 Dec 2023 15:24:58 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.05152v2</guid></item><item><title>Roll With the Punches: Expansion and Shrinkage of Soft Label Selection for Semi-supervised Fine-Grained Learning</title><link>http://arxiv.org/abs/2312.12237v1</link><description>While semi-supervised learning (SSL) has yielded promising results, the morerealistic SSL scenario remains to be explored, in which the unlabeled dataexhibits extremely high recognition difficulty, e.g., fine-grained visualclassification in the context of SSL (SS-FGVC). The increased recognitiondifficulty on fine-grained unlabeled data spells disaster for pseudo-labelingaccuracy, resulting in poor performance of the SSL model. To tackle thischallenge, we propose Soft Label Selection with Confidence-Aware Clusteringbased on Class Transition Tracking (SoC) by reconstructing the pseudo-labelselection process by jointly optimizing Expansion Objective and ShrinkageObjective, which is based on a soft label manner. Respectively, the formerobjective encourages soft labels to absorb more candidate classes to ensure theattendance of ground-truth class, while the latter encourages soft labels toreject more noisy classes, which is theoretically proved to be equivalent toentropy minimization. In comparisons with various state-of-the-art methods, ourapproach demonstrates its superior performance in SS-FGVC. Checkpoints andsource code are available at https://github.com/NJUyued/SoC4SS-FGVC.</description><author>Yue Duan, Zhen Zhao, Lei Qi, Luping Zhou, Lei Wang, Yinghuan Shi</author><pubDate>Tue, 19 Dec 2023 15:22:37 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.12237v1</guid></item><item><title>Probabilistic Exponential Integrators</title><link>http://arxiv.org/abs/2305.14978v2</link><description>Probabilistic solvers provide a flexible and efficient framework forsimulation, uncertainty quantification, and inference in dynamical systems.However, like standard solvers, they suffer performance penalties for certainstiff systems, where small steps are required not for reasons of numericalaccuracy but for the sake of stability. This issue is greatly alleviated insemi-linear problems by the probabilistic exponential integrators developed inthis paper. By including the fast, linear dynamics in the prior, we arrive at aclass of probabilistic integrators with favorable properties. Namely, they areproven to be L-stable, and in a certain case reduce to a classic exponentialintegrator -- with the added benefit of providing a probabilistic account ofthe numerical error. The method is also generalized to arbitrary non-linearsystems by imposing piece-wise semi-linearity on the prior via Jacobians of thevector field at the previous estimates, resulting in probabilistic exponentialRosenbrock methods. We evaluate the proposed methods on multiple stiffdifferential equations and demonstrate their improved stability and efficiencyover established probabilistic solvers. The present contribution thus expandsthe range of problems that can be effectively tackled within probabilisticnumerics.</description><author>Nathanael Bosch, Philipp Hennig, Filip Tronarp</author><pubDate>Tue, 19 Dec 2023 15:21:24 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.14978v2</guid></item><item><title>Generalization Analysis of Machine Learning Algorithms via the Worst-Case Data-Generating Probability Measure</title><link>http://arxiv.org/abs/2312.12236v1</link><description>In this paper, the worst-case probability measure over the data is introducedas a tool for characterizing the generalization capabilities of machinelearning algorithms. More specifically, the worst-case probability measure is aGibbs probability measure and the unique solution to the maximization of theexpected loss under a relative entropy constraint with respect to a referenceprobability measure. Fundamental generalization metrics, such as thesensitivity of the expected loss, the sensitivity of the empirical risk, andthe generalization gap are shown to have closed-form expressions involving theworst-case data-generating probability measure. Existing results for the Gibbsalgorithm, such as characterizing the generalization gap as a sum of mutualinformation and lautum information, up to a constant factor, are recovered. Anovel parallel is established between the worst-case data-generatingprobability measure and the Gibbs algorithm. Specifically, the Gibbsprobability measure is identified as a fundamental commonality of the modelspace and the data space for machine learning algorithms.</description><author>Xinying Zou, Samir M. Perlaza, Iñaki Esnaola, Eitan Altman</author><pubDate>Tue, 19 Dec 2023 15:20:27 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.12236v1</guid></item><item><title>Brush Your Text: Synthesize Any Scene Text on Images via Diffusion Model</title><link>http://arxiv.org/abs/2312.12232v1</link><description>Recently, diffusion-based image generation methods are credited for theirremarkable text-to-image generation capabilities, while still facing challengesin accurately generating multilingual scene text images. To tackle thisproblem, we propose Diff-Text, which is a training-free scene text generationframework for any language. Our model outputs a photo-realistic image given atext of any language along with a textual description of a scene. The modelleverages rendered sketch images as priors, thus arousing the potentialmultilingual-generation ability of the pre-trained Stable Diffusion. Based onthe observation from the influence of the cross-attention map on objectplacement in generated images, we propose a localized attention constraint intothe cross-attention layer to address the unreasonable positioning problem ofscene text. Additionally, we introduce contrastive image-level prompts tofurther refine the position of the textual region and achieve more accuratescene text generation. Experiments demonstrate that our method outperforms theexisting method in both the accuracy of text recognition and the naturalness offoreground-background blending.</description><author>Lingjun Zhang, Xinyuan Chen, Yaohui Wang, Yue Lu, Yu Qiao</author><pubDate>Tue, 19 Dec 2023 15:18:40 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.12232v1</guid></item><item><title>It's All in the Mix: Wasserstein Machine Learning with Mixed Features</title><link>http://arxiv.org/abs/2312.12230v1</link><description>Problem definition: The recent advent of data-driven and end-to-enddecision-making across different areas of operations management has led to anever closer integration of prediction models from machine learning andoptimization models from operations research. A key challenge in this contextis the presence of estimation errors in the prediction models, which tend to beamplified by the subsequent optimization model -- a phenomenon that is oftenreferred to as the Optimizer's Curse or the Error-Maximization Effect ofOptimization. Methodology/results: A contemporary approach to combat such estimation errorsis offered by distributionally robust problem formulations that consider alldata-generating distributions close to the empirical distribution derived fromhistorical samples, where `closeness' is determined by the Wassersteindistance. While those techniques show significant promise in problems where allinput features are continuous, they scale exponentially when binary and/orcategorical features are present. This paper demonstrates that suchmixed-feature problems can indeed be solved in polynomial time. We present apractically efficient algorithm to solve mixed-feature problems, and we compareour method against alternative techniques both theoretically and empirically onstandard benchmark instances. Managerial implications: Data-driven operations management problems ofteninvolve prediction models with discrete features. We develop and analyze amethodology that faithfully accounts for the presence of discrete features, andwe demonstrate that our approach can significantly outperform existing methodsthat are agnostic to the presence of discrete features, both theoretically andacross standard benchmark instances.</description><author>Reza Belbasi, Aras Selvi, Wolfram Wiesemann</author><pubDate>Tue, 19 Dec 2023 15:15:52 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.12230v1</guid></item><item><title>Poincaré ResNet</title><link>http://arxiv.org/abs/2303.14027v3</link><description>This paper introduces an end-to-end residual network that operates entirelyon the Poincar\'e ball model of hyperbolic space. Hyperbolic learning hasrecently shown great potential for visual understanding, but is currently onlyperformed in the penultimate layer(s) of deep networks. All visualrepresentations are still learned through standard Euclidean networks. In thispaper we investigate how to learn hyperbolic representations of visual datadirectly from the pixel-level. We propose Poincar\'e ResNet, a hyperboliccounterpart of the celebrated residual network, starting from Poincar\'e 2Dconvolutions up to Poincar\'e residual connections. We identify threeroadblocks for training convolutional networks entirely in hyperbolic space andpropose a solution for each: (i) Current hyperbolic network initializationscollapse to the origin, limiting their applicability in deeper networks. Weprovide an identity-based initialization that preserves norms over many layers.(ii) Residual networks rely heavily on batch normalization, which comes withexpensive Fr\'echet mean calculations in hyperbolic space. We introducePoincar\'e midpoint batch normalization as a faster and equally effectivealternative. (iii) Due to the many intermediate operations in Poincar\'elayers, we lastly find that the computation graphs of deep learning librariesblow up, limiting our ability to train on deep hyperbolic networks. We providemanual backward derivations of core hyperbolic operations to maintainmanageable computation graphs.</description><author>Max van Spengler, Erwin Berkhout, Pascal Mettes</author><pubDate>Tue, 19 Dec 2023 15:15:50 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2303.14027v3</guid></item><item><title>Label Words are Anchors: An Information Flow Perspective for Understanding In-Context Learning</title><link>http://arxiv.org/abs/2305.14160v4</link><description>In-context learning (ICL) emerges as a promising capability of large languagemodels (LLMs) by providing them with demonstration examples to perform diversetasks. However, the underlying mechanism of how LLMs learn from the providedcontext remains under-explored. In this paper, we investigate the workingmechanism of ICL through an information flow lens. Our findings reveal thatlabel words in the demonstration examples function as anchors: (1) semanticinformation aggregates into label word representations during the shallowcomputation layers' processing; (2) the consolidated information in label wordsserves as a reference for LLMs' final predictions. Based on these insights, weintroduce an anchor re-weighting method to improve ICL performance, ademonstration compression technique to expedite inference, and an analysisframework for diagnosing ICL errors in GPT2-XL. The promising applications ofour findings again validate the uncovered ICL working mechanism and pave theway for future studies.</description><author>Lean Wang, Lei Li, Damai Dai, Deli Chen, Hao Zhou, Fandong Meng, Jie Zhou, Xu Sun</author><pubDate>Tue, 19 Dec 2023 15:13:52 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.14160v4</guid></item><item><title>HuTuMotion: Human-Tuned Navigation of Latent Motion Diffusion Models with Minimal Feedback</title><link>http://arxiv.org/abs/2312.12227v1</link><description>We introduce HuTuMotion, an innovative approach for generating natural humanmotions that navigates latent motion diffusion models by leveraging few-shothuman feedback. Unlike existing approaches that sample latent variables from astandard normal prior distribution, our method adapts the prior distribution tobetter suit the characteristics of the data, as indicated by human feedback,thus enhancing the quality of motion generation. Furthermore, our findingsreveal that utilizing few-shot feedback can yield performance levels on parwith those attained through extensive human feedback. This discovery emphasizesthe potential and efficiency of incorporating few-shot human-guidedoptimization within latent diffusion models for personalized and style-awarehuman motion generation applications. The experimental results show thesignificantly superior performance of our method over existing state-of-the-artapproaches.</description><author>Gaoge Han, Shaoli Huang, Mingming Gong, Jinglei Tang</author><pubDate>Tue, 19 Dec 2023 15:13:08 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.12227v1</guid></item><item><title>On the Parameterization of Second-Order Optimization Effective Towards the Infinite Width</title><link>http://arxiv.org/abs/2312.12226v1</link><description>Second-order optimization has been developed to accelerate the training ofdeep neural networks and it is being applied to increasingly larger-scalemodels. In this study, towards training on further larger scales, we identify aspecific parameterization for second-order optimization that promotes featurelearning in a stable manner even if the network width increases significantly.Inspired by a maximal update parameterization, we consider a one-step update ofthe gradient and reveal the appropriate scales of hyperparameters includingrandom initialization, learning rates, and damping terms. Our approach coverstwo major second-order optimization algorithms, K-FAC and Shampoo, and wedemonstrate that our parameterization achieves higher generalizationperformance in feature learning. In particular, it enables us to transfer thehyperparameters across models with different widths.</description><author>Satoki Ishikawa, Ryo Karakida</author><pubDate>Tue, 19 Dec 2023 15:12:39 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.12226v1</guid></item><item><title>Ghost Noise for Regularizing Deep Neural Networks</title><link>http://arxiv.org/abs/2305.17205v2</link><description>Batch Normalization (BN) is widely used to stabilize the optimization processand improve the test performance of deep neural networks. The regularizationeffect of BN depends on the batch size and explicitly using smaller batch sizeswith Batch Normalization, a method known as Ghost Batch Normalization (GBN),has been found to improve generalization in many settings. We investigate theeffectiveness of GBN by disentangling the induced ``Ghost Noise'' fromnormalization and quantitatively analyzing the distribution of noise as well asits impact on model performance. Inspired by our analysis, we propose a newregularization technique called Ghost Noise Injection (GNI) that imitates thenoise in GBN without incurring the detrimental train-test discrepancy effectsof small batch training. We experimentally show that GNI can provide a greatergeneralization benefit than GBN. Ghost Noise Injection can also be beneficialin otherwise non-noisy settings such as layer-normalized networks, providingadditional evidence of the usefulness of Ghost Noise in Batch Normalization asa regularizer.</description><author>Atli Kosson, Dongyang Fan, Martin Jaggi</author><pubDate>Tue, 19 Dec 2023 15:12:37 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.17205v2</guid></item><item><title>Self-Supervised Detection of Perfect and Partial Input-Dependent Symmetries</title><link>http://arxiv.org/abs/2312.12223v1</link><description>Group equivariance ensures consistent responses to group transformations ofthe input, leading to more robust models and enhanced generalizationcapabilities. However, this property can lead to overly constrained models ifthe symmetries considered in the group differ from those observed in data.While common methods address this by determining the appropriate level ofsymmetry at the dataset level, they are limited to supervised settings andignore scenarios in which multiple levels of symmetry co-exist in the samedataset. For instance, pictures of cars and planes exhibit different levels ofrotation, yet both are included in the CIFAR-10 dataset. In this paper, wepropose a method able to detect the level of symmetry of each input without theneed for labels. To this end, we derive a sufficient and necessary condition tolearn the distribution of symmetries in the data. Using the learneddistribution, we generate pseudo-labels that allow us to learn the levels ofsymmetry of each input in a self-supervised manner. We validate theeffectiveness of our approach on synthetic datasets with different per-classlevels of symmetries e.g. MNISTMultiple, in which digits are uniformly rotatedwithin a class-dependent interval. We demonstrate that our method can be usedfor practical applications such as the generation of standardized datasets inwhich the symmetries are not present, as well as the detection ofout-of-distribution symmetries during inference. By doing so, both thegeneralization and robustness of non-equivariant models can be improved. Ourcode is publicly available at https://github.com/aurban0/ssl-sym.</description><author>Alonso Urbano, David W. Romero</author><pubDate>Tue, 19 Dec 2023 15:11:46 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.12223v1</guid></item><item><title>EarthVQA: Towards Queryable Earth via Relational Reasoning-Based Remote Sensing Visual Question Answering</title><link>http://arxiv.org/abs/2312.12222v1</link><description>Earth vision research typically focuses on extracting geospatial objectlocations and categories but neglects the exploration of relations betweenobjects and comprehensive reasoning. Based on city planning needs, we develop amulti-modal multi-task VQA dataset (EarthVQA) to advance relationalreasoning-based judging, counting, and comprehensive analysis. The EarthVQAdataset contains 6000 images, corresponding semantic masks, and 208,593 QApairs with urban and rural governance requirements embedded. As objects are thebasis for complex relational reasoning, we propose a Semantic OBject Awarenessframework (SOBA) to advance VQA in an object-centric way. To preserve refinedspatial locations and semantics, SOBA leverages a segmentation network forobject semantics generation. The object-guided attention aggregates objectinterior features via pseudo masks, and bidirectional cross-attention furthermodels object external relations hierarchically. To optimize object counting,we propose a numerical difference loss that dynamically adds differencepenalties, unifying the classification and regression tasks. Experimentalresults show that SOBA outperforms both advanced general and remote sensingmethods. We believe this dataset and framework provide a strong benchmark forEarth vision's complex analysis. The project page is athttps://Junjue-Wang.github.io/homepage/EarthVQA.</description><author>Junjue Wang, Zhuo Zheng, Zihang Chen, Ailong Ma, Yanfei Zhong</author><pubDate>Tue, 19 Dec 2023 15:11:32 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.12222v1</guid></item><item><title>Sharing is CAIRing: Characterizing Principles and Assessing Properties of Universal Privacy Evaluation for Synthetic Tabular Data</title><link>http://arxiv.org/abs/2312.12216v1</link><description>Data sharing is a necessity for innovative progress in many domains,especially in healthcare. However, the ability to share data is hindered byregulations protecting the privacy of natural persons. Synthetic tabular dataprovide a promising solution to address data sharing difficulties but does notinherently guarantee privacy. Still, there is a lack of agreement onappropriate methods for assessing the privacy-preserving capabilities ofsynthetic data, making it difficult to compare results across studies. To thebest of our knowledge, this is the first work to identify properties thatconstitute good universal privacy evaluation metrics for synthetic tabulardata. The goal of such metrics is to enable comparability across studies and toallow non-technical stakeholders to understand how privacy is protected. Weidentify four principles for the assessment of metrics: Comparability,Applicability, Interpretability, and Representativeness (CAIR). To quantify andrank the degree to which evaluation metrics conform to the CAIR principles, wedesign a rubric using a scale of 1-4. Each of the four properties is scored onfour parameters, yielding 16 total dimensions. We study the applicability andusefulness of the CAIR principles and rubric by assessing a selection ofmetrics popular in other studies. The results provide granular insights intothe strengths and weaknesses of existing metrics that not only rank the metricsbut highlight areas of potential improvements. We expect that the CAIRprinciples will foster agreement among researchers and organizations on whichuniversal privacy evaluation metrics are appropriate for synthetic tabulardata.</description><author>Tobias Hyrup, Anton Danholt Lautrup, Arthur Zimek, Peter Schneider-Kamp</author><pubDate>Tue, 19 Dec 2023 15:05:52 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.12216v1</guid></item><item><title>JaxMARL: Multi-Agent RL Environments in JAX</title><link>http://arxiv.org/abs/2311.10090v4</link><description>Benchmarks play an important role in the development of machine learningalgorithms. For example, research in reinforcement learning (RL) has beenheavily influenced by available environments and benchmarks. However, RLenvironments are traditionally run on the CPU, limiting their scalability withtypical academic compute. Recent advancements in JAX have enabled the wider useof hardware acceleration to overcome these computational hurdles, enablingmassively parallel RL training pipelines and environments. This is particularlyuseful for multi-agent reinforcement learning (MARL) research. First of all,multiple agents must be considered at each environment step, addingcomputational burden, and secondly, the sample complexity is increased due tonon-stationarity, decentralised partial observability, or other MARLchallenges. In this paper, we present JaxMARL, the first open-source code basethat combines ease-of-use with GPU enabled efficiency, and supports a largenumber of commonly used MARL environments as well as popular baselinealgorithms. When considering wall clock time, our experiments show that per-runour JAX-based training pipeline is up to 12500x faster than existingapproaches. This enables efficient and thorough evaluations, with the potentialto alleviate the evaluation crisis of the field. We also introduce andbenchmark SMAX, a vectorised, simplified version of the popular StarCraftMulti-Agent Challenge, which removes the need to run the StarCraft II gameengine. This not only enables GPU acceleration, but also provides a moreflexible MARL environment, unlocking the potential for self-play,meta-learning, and other future applications in MARL. We provide code athttps://github.com/flairox/jaxmarl.</description><author>Alexander Rutherford, Benjamin Ellis, Matteo Gallici, Jonathan Cook, Andrei Lupu, Gardar Ingvarsson, Timon Willi, Akbir Khan, Christian Schroeder de Witt, Alexandra Souly, Saptarashmi Bandyopadhyay, Mikayel Samvelyan, Minqi Jiang, Robert Tjarko Lange, Shimon Whiteson, Bruno Lacerda, Nick Hawes, Tim Rocktaschel, Chris Lu, Jakob Nicolaus Foerster</author><pubDate>Tue, 19 Dec 2023 14:55:15 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.10090v4</guid></item><item><title>Identification of Causal Structure in the Presence of Missing Data with Additive Noise Model</title><link>http://arxiv.org/abs/2312.12206v1</link><description>Missing data are an unavoidable complication frequently encountered in manycausal discovery tasks. When a missing process depends on the missing valuesthemselves (known as self-masking missingness), the recovery of the jointdistribution becomes unattainable, and detecting the presence of suchself-masking missingness remains a perplexing challenge. Consequently, due tothe inability to reconstruct the original distribution and to discern theunderlying missingness mechanism, simply applying existing causal discoverymethods would lead to wrong conclusions. In this work, we found that the recentadvances additive noise model has the potential for learning causal structureunder the existence of the self-masking missingness. With this observation, weaim to investigate the identification problem of learning causal structure frommissing data under an additive noise model with different missingnessmechanisms, where the `no self-masking missingness' assumption can beeliminated appropriately. Specifically, we first elegantly extend the scope ofidentifiability of causal skeleton to the case with weak self-maskingmissingness (i.e., no other variable could be the cause of self-maskingindicators except itself). We further provide the sufficient and necessaryidentification conditions of the causal direction under additive noise modeland show that the causal structure can be identified up to an IN-equivalentpattern. We finally propose a practical algorithm based on the abovetheoretical results on learning the causal skeleton and causal direction.Extensive experiments on synthetic and real data demonstrate the efficiency andeffectiveness of the proposed algorithms.</description><author>Jie Qiao, Zhengming Chen, Jianhua Yu, Ruichu Cai, Zhifeng Hao</author><pubDate>Tue, 19 Dec 2023 14:44:26 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.12206v1</guid></item><item><title>Polar Encoding: A Simple Baseline Approach for Classification with Missing Values</title><link>http://arxiv.org/abs/2210.01905v3</link><description>We propose polar encoding, a representation of categorical and numerical$[0,1]$-valued attributes with missing values to be used in a classificationcontext. We argue that this is a good baseline approach, because it can be usedwith any classification algorithm, preserves missingness information, is verysimple to apply and offers good performance. In particular, unlike the existingmissing-indicator approach, it does not require imputation, ensures thatmissing values are equidistant from non-missing values, and lets decision treealgorithms choose how to split missing values, thereby providing a practicalrealisation of the "missingness incorporated in attributes" (MIA) proposal.Furthermore, we show that categorical and $[0,1]$-valued attributes can beviewed as special cases of a single attribute type, corresponding to theclassical concept of barycentric coordinates, and that this offers a naturalinterpretation of polar encoding as a fuzzified form of one-hot encoding. Withan experiment based on twenty real-life datasets with missing values, we showthat, in terms of the resulting classification performance, polar encodingperforms better than the state-of-the-art strategies \e{multiple imputation bychained equations} (MICE) and \e{multiple imputation with denoisingautoencoders} (MIDAS) and -- depending on the classifier -- about as well orbetter than mean/mode imputation with missing-indicators.</description><author>Oliver Urs Lenz, Daniel Peralta, Chris Cornelis</author><pubDate>Tue, 19 Dec 2023 14:39:40 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2210.01905v3</guid></item><item><title>Mask Grounding for Referring Image Segmentation</title><link>http://arxiv.org/abs/2312.12198v1</link><description>Referring Image Segmentation (RIS) is a challenging task that requires analgorithm to segment objects referred by free-form language expressions.Despite significant progress in recent years, most state-of-the-art (SOTA)methods still suffer from considerable language-image modality gap at the pixeland word level. These methods generally 1) rely on sentence-level languagefeatures for language-image alignment and 2) lack explicit training supervisionfor fine-grained visual grounding. Consequently, they exhibit weak object-levelcorrespondence between visual and language features. Without well-groundedfeatures, prior methods struggle to understand complex expressions that requirestrong reasoning over relationships among multiple objects, especially whendealing with rarely used or ambiguous clauses. To tackle this challenge, weintroduce a novel Mask Grounding auxiliary task that significantly improvesvisual grounding within language features, by explicitly teaching the model tolearn fine-grained correspondence between masked textual tokens and theirmatching visual objects. Mask Grounding can be directly used on prior RISmethods and consistently bring improvements. Furthermore, to holisticallyaddress the modality gap, we also design a cross-modal alignment loss and anaccompanying alignment module. These additions work synergistically with MaskGrounding. With all these techniques, our comprehensive approach culminates inMagNet Mask-grounded Network), an architecture that significantly outperformsprior arts on three key benchmarks (RefCOCO, RefCOCO+ and G-Ref), demonstratingour method's effectiveness in addressing current limitations of RIS algorithms.Our code and pre-trained weights will be released.</description><author>Yong Xien Chng, Henry Zheng, Yizeng Han, Xuchong Qiu, Gao Huang</author><pubDate>Tue, 19 Dec 2023 14:34:36 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.12198v1</guid></item><item><title>Conformal Temporal Logic Planning using Large Language Models: Knowing When to Do What and When to Ask for Help</title><link>http://arxiv.org/abs/2309.10092v2</link><description>This paper addresses a new motion planning problem for mobile robots taskedwith accomplishing multiple high-level sub-tasks, expressed using naturallanguage (NL). These sub-tasks should be accomplished in a temporal and logicalorder. To formally define the overarching mission, we leverage Linear TemporalLogic (LTL) defined over atomic predicates modeling these NL-based sub-tasks.This is in contrast to related planning approaches that define LTL tasks overatomic predicates capturing desired low-level system configurations. Our goalis to design robot plans that satisfy LTL tasks defined over NL-based atomicpropositions. A novel technical challenge arising in this setup lies inreasoning about correctness of a robot plan with respect to such LTL-encodedtasks. To address this problem, we propose HERACLEs, a hierarchical conformalnatural language planner, that relies on (i) automata theory to determine whatNL-specified sub-tasks should be accomplished next to make mission progress;(ii) Large Language Models to design robot plans satisfying these sub-tasks;and (iii) conformal prediction to reason probabilistically about correctness ofthe designed plans and to determine if external assistance is required. Weprovide theoretical probabilistic mission satisfaction guarantees as well asextensive comparative experiments on mobile manipulation tasks.</description><author>Jun Wang, Jiaming Tong, Kaiyuan Tan, Yevgeniy Vorobeychik, Yiannis Kantaros</author><pubDate>Tue, 19 Dec 2023 14:34:19 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2309.10092v2</guid></item><item><title>Color-NeuS: Reconstructing Neural Implicit Surfaces with Color</title><link>http://arxiv.org/abs/2308.06962v2</link><description>The reconstruction of object surfaces from multi-view images or monocularvideo is a fundamental issue in computer vision. However, much of the recentresearch concentrates on reconstructing geometry through implicit or explicitmethods. In this paper, we shift our focus towards reconstructing mesh inconjunction with color. We remove the view-dependent color from neural volumerendering while retaining volume rendering performance through a relightingnetwork. Mesh is extracted from the signed distance function (SDF) network forthe surface, and color for each surface vertex is drawn from the global colornetwork. To evaluate our approach, we conceived a in hand object scanning taskfeaturing numerous occlusions and dramatic shifts in lighting conditions. We'vegathered several videos for this task, and the results surpass those of anyexisting methods capable of reconstructing mesh alongside color. Additionally,our method's performance was assessed using public datasets, including DTU,BlendedMVS, and OmniObject3D. The results indicated that our method performswell across all these datasets. Project page:https://colmar-zlicheng.github.io/color_neus.</description><author>Licheng Zhong, Lixin Yang, Kailin Li, Haoyu Zhen, Mei Han, Cewu Lu</author><pubDate>Tue, 19 Dec 2023 14:29:58 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2308.06962v2</guid></item><item><title>Relative Policy-Transition Optimization for Fast Policy Transfer</title><link>http://arxiv.org/abs/2206.06009v2</link><description>We consider the problem of policy transfer between two Markov DecisionProcesses (MDPs). We introduce a lemma based on existing theoretical results inreinforcement learning to measure the relativity gap between two arbitraryMDPs, that is the difference between any two cumulative expected returnsdefined on different policies and environment dynamics. Based on this lemma, wepropose two new algorithms referred to as Relative Policy Optimization (RPO)and Relative Transition Optimization (RTO), which offer fast policy transferand dynamics modelling, respectively. RPO transfers the policy evaluated in oneenvironment to maximize the return in another, while RTO updates theparameterized dynamics model to reduce the gap between the dynamics of the twoenvironments. Integrating the two algorithms results in the complete RelativePolicy-Transition Optimization (RPTO) algorithm, in which the policy interactswith the two environments simultaneously, such that data collections from twoenvironments, policy and transition updates are completed in one closed loop toform a principled learning framework for policy transfer. We demonstrate theeffectiveness of RPTO on a set of MuJoCo continuous control tasks by creatingpolicy transfer problems via variant dynamics.</description><author>Jiawei Xu, Cheng Zhou, Yizheng Zhang, Baoxiang Wang, Lei Han</author><pubDate>Tue, 19 Dec 2023 14:29:53 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2206.06009v2</guid></item><item><title>Gaussian process learning of nonlinear dynamics</title><link>http://arxiv.org/abs/2312.12193v1</link><description>One of the pivotal tasks in scientific machine learning is to representunderlying dynamical systems from time series data. Many methods for suchdynamics learning explicitly require the derivatives of state data, which arenot directly available and can be approximated conventionally by finitedifferences. However, the discrete approximations of time derivatives mayresult in a poor estimation when state data are scarce and/or corrupted bynoise, thus compromising the predictiveness of the learned dynamical models. Toovercome this technical hurdle, we propose a new method that learns nonlineardynamics through a Bayesian inference of characterizing model parameters. Thismethod leverages a Gaussian process representation of states, and constructs alikelihood function using the correlation between state data and theirderivatives, yet prevents explicit evaluations of time derivatives. Through aBayesian scheme, a probabilistic estimate of the model parameters is given bythe posterior distribution, and thus a quantification is facilitated foruncertainties from noisy state data and the learning process. Specifically, wewill discuss the applicability of the proposed method to two typical scenariosfor dynamical systems: parameter identification and estimation with an affinestructure of the system, and nonlinear parametric approximation without priorknowledge.</description><author>Dongwei Ye, Mengwu Guo</author><pubDate>Tue, 19 Dec 2023 14:27:26 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.12193v1</guid></item><item><title>Conductivity Imaging from Internal Measurements with Mixed Least-Squares Deep Neural Networks</title><link>http://arxiv.org/abs/2303.16454v3</link><description>In this work we develop a novel approach using deep neural networks toreconstruct the conductivity distribution in elliptic problems from onemeasurement of the solution over the whole domain. The approach is based on amixed reformulation of the governing equation and utilizes the standardleast-squares objective, with deep neural networks as ansatz functions toapproximate the conductivity and flux simultaneously. We provide a thoroughanalysis of the deep neural network approximations of the conductivity for bothcontinuous and empirical losses, including rigorous error estimates that areexplicit in terms of the noise level, various penalty parameters and neuralnetwork architectural parameters (depth, width and parameter bound). We alsoprovide multiple numerical experiments in two- and multi-dimensions toillustrate distinct features of the approach, e.g., excellent stability withrespect to data noise and capability of solving high-dimensional problems.</description><author>Bangti Jin, Xiyao Li, Qimeng Quan, Zhi Zhou</author><pubDate>Tue, 19 Dec 2023 14:27:21 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2303.16454v3</guid></item><item><title>CUDC: A Curiosity-Driven Unsupervised Data Collection Method with Adaptive Temporal Distances for Offline Reinforcement Learning</title><link>http://arxiv.org/abs/2312.12191v1</link><description>Offline reinforcement learning (RL) aims to learn an effective policy from apre-collected dataset. Most existing works are to develop sophisticatedlearning algorithms, with less emphasis on improving the data collectionprocess. Moreover, it is even challenging to extend the single-task setting andcollect a task-agnostic dataset that allows an agent to perform multipledownstream tasks. In this paper, we propose a Curiosity-driven UnsupervisedData Collection (CUDC) method to expand feature space using adaptive temporaldistances for task-agnostic data collection and ultimately improve learningefficiency and capabilities for multi-task offline RL. To achieve this, CUDCestimates the probability of the k-step future states being reachable from thecurrent states, and adapts how many steps into the future that the dynamicsmodel should predict. With this adaptive reachability mechanism in place, thefeature representation can be diversified, and the agent can navigate itself tocollect higher-quality data with curiosity. Empirically, CUDC surpassesexisting unsupervised methods in efficiency and learning performance in variousdownstream offline RL tasks of the DeepMind control suite.</description><author>Chenyu Sun, Hangwei Qian, Chunyan Miao</author><pubDate>Tue, 19 Dec 2023 14:26:23 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.12191v1</guid></item><item><title>Decentralised and collaborative machine learning framework for IoT</title><link>http://arxiv.org/abs/2312.12190v1</link><description>Decentralised machine learning has recently been proposed as a potentialsolution to the security issues of the canonical federated learning approach.In this paper, we propose a decentralised and collaborative machine learningframework specially oriented to resource-constrained devices, usual in IoTdeployments. With this aim we propose the following construction blocks. First,an incremental learning algorithm based on prototypes that was specificallyimplemented to work in low-performance computing elements. Second, tworandom-based protocols to exchange the local models among the computingelements in the network. Finally, two algorithmics approaches for predictionand prototype creation. This proposal was compared to a typical centralizedincremental learning approach in terms of accuracy, training time androbustness with very promising results.</description><author>Martín González-Soto, Rebeca P. Díaz-Redondo, Manuel Fernández-Veiga, Bruno Rodríguez-Castro, Ana Fernández-Vilas</author><pubDate>Tue, 19 Dec 2023 14:25:41 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.12190v1</guid></item><item><title>Teeth Localization and Lesion Segmentation in CBCT Images using SpatialConfiguration-Net and U-Net</title><link>http://arxiv.org/abs/2312.12189v1</link><description>The localization of teeth and segmentation of periapical lesions in cone-beamcomputed tomography (CBCT) images are crucial tasks for clinical diagnosis andtreatment planning, which are often time-consuming and require a high level ofexpertise. However, automating these tasks is challenging due to variations inshape, size, and orientation of lesions, as well as similar topologies amongteeth. Moreover, the small volumes occupied by lesions in CBCT images pose aclass imbalance problem that needs to be addressed. In this study, we propose adeep learning-based method utilizing two convolutional neural networks: theSpatialConfiguration-Net (SCN) and a modified version of the U-Net. The SCNaccurately predicts the coordinates of all teeth present in an image, enablingprecise cropping of teeth volumes that are then fed into the U-Net whichdetects lesions via segmentation. To address class imbalance, we compare theperformance of three reweighting loss functions. After evaluation on 144 CBCTimages, our method achieves a 97.3% accuracy for teeth localization, along witha promising sensitivity and specificity of 0.97 and 0.88, respectively, forsubsequent lesion detection.</description><author>Arnela Hadzic, Barbara Kirnbauer, Darko Stern, Martin Urschler</author><pubDate>Tue, 19 Dec 2023 14:23:47 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.12189v1</guid></item></channel></rss>