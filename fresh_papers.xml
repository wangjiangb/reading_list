<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/"><channel><title>Arxivfresh papers</title><link></link><description>Arxiv paper</description><language>en-US</language><lastBuildDate>Thu, 17 Oct 2024 01:00:08 GMT</lastBuildDate><generator>rfeed v1.0.0</generator><docs>https://github.com/svpino/rfeed/blob/master/README.md</docs><item><title>Light-Weight Fault Tolerant Attention for Large Language Model Training</title><link>http://arxiv.org/abs/2410.11720v2</link><description>Large Language Models (LLMs) have demonstrated remarkable performance invarious natural language processing tasks. However, the training of thesemodels is computationally intensive and susceptible to faults, particularly inthe attention mechanism, which is a critical component of transformer-basedLLMs. In this paper, we investigate the impact of faults on LLM training,focusing on INF, NaN, and near-INF values in the computation results withsystematic fault injection experiments. We observe the propagation patterns ofthese errors, which can trigger non-trainable states in the model and disrupttraining, forcing the procedure to load from checkpoints. To mitigate theimpact of these faults, we propose ATTNChecker, the first Algorithm-Based FaultTolerance (ABFT) technique tailored for the attention mechanism in LLMs.ATTNChecker is designed based on fault propagation patterns of LLM andincorporates performance optimization to adapt to both system reliability andmodel vulnerability while providing lightweight protection for fast LLMtraining. Evaluations on four LLMs show that ATTNChecker on average incurs onaverage 7% overhead on training while detecting and correcting all extremeerrors. Compared with the state-of-the-art checkpoint/restore approach,ATTNChecker reduces recovery overhead by up to 49x.</description><author>Yuhang Liang, Xinyi Li, Jie Ren, Ang Li, Bo Fang, Jieyang Chen</author><pubDate>Wed, 16 Oct 2024 15:10:58 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.11720v2</guid></item><item><title>Efficient Diffusion Models: A Comprehensive Survey from Principles to Practices</title><link>http://arxiv.org/abs/2410.11795v2</link><description>As one of the most popular and sought-after generative models in the recentyears, diffusion models have sparked the interests of many researchers andsteadily shown excellent advantage in various generative tasks such as imagesynthesis, video generation, molecule design, 3D scene rendering and multimodalgeneration, relying on their dense theoretical principles and reliableapplication practices. The remarkable success of these recent efforts ondiffusion models comes largely from progressive design principles and efficientarchitecture, training, inference, and deployment methodologies. However, therehas not been a comprehensive and in-depth review to summarize these principlesand practices to help the rapid understanding and application of diffusionmodels. In this survey, we provide a new efficiency-oriented perspective onthese existing efforts, which mainly focuses on the profound principles andefficient practices in architecture designs, model training, fast inference andreliable deployment, to guide further theoretical research, algorithm migrationand model application for new scenarios in a reader-friendly way.\url{https://github.com/ponyzym/Efficient-DMs-Survey}</description><author>Zhiyuan Ma, Yuzhu Zhang, Guoli Jia, Liangliang Zhao, Yichao Ma, Mingjie Ma, Gaofeng Liu, Kaiyan Zhang, Jianjun Li, Bowen Zhou</author><pubDate>Wed, 16 Oct 2024 13:10:32 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.11795v2</guid></item><item><title>Can Search-Based Testing with Pareto Optimization Effectively Cover Failure-Revealing Test Inputs?</title><link>http://arxiv.org/abs/2410.11769v2</link><description>Search-based software testing (SBST) is a widely adopted technique fortesting complex systems with large input spaces, such as Deep Learning-enabled(DL-enabled) systems. Many SBST techniques focus on Pareto-based optimization,where multiple objectives are optimized in parallel to reveal failures.However, it is important to ensure that identified failures are spreadthroughout the entire failure-inducing area of a search domain and notclustered in a sub-region. This ensures that identified failures aresemantically diverse and reveal a wide range of underlying causes. In thispaper, we present a theoretical argument explaining why testing based on Paretooptimization is inadequate for covering failure-inducing areas within a searchdomain. We support our argument with empirical results obtained by applying twowidely used types of Pareto-based optimization techniques, namely NSGA-II (anevolutionary algorithm) and OMOPSO (a swarm-based Pareto-optimizationalgorithm), to two DL-enabled systems: an industrial Automated Valet Parking(AVP) system and a system for classifying handwritten digits. We measure thecoverage of failure-revealing test inputs in the input space using a metricthat we refer to as the Coverage Inverted Distance quality indicator. Ourresults show that NSGA-II-based search and OMOPSO are not more effective than ana\"ive random search baseline in covering test inputs that reveal failures.The replication package for this study is available in a GitHub repository.</description><author>Lev Sorokin, Damir Safin, Shiva Nejati</author><pubDate>Wed, 16 Oct 2024 08:30:57 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.11769v2</guid></item><item><title>MoH: Multi-Head Attention as Mixture-of-Head Attention</title><link>http://arxiv.org/abs/2410.11842v1</link><description>In this work, we upgrade the multi-head attention mechanism, the core of theTransformer model, to improve efficiency while maintaining or surpassing theprevious accuracy level. We show that multi-head attention can be expressed inthe summation form. Drawing on the insight that not all attention heads holdequal significance, we propose Mixture-of-Head attention (MoH), a newarchitecture that treats attention heads as experts in the Mixture-of-Experts(MoE) mechanism. MoH has two significant advantages: First, MoH enables eachtoken to select the appropriate attention heads, enhancing inference efficiencywithout compromising accuracy or increasing the number of parameters. Second,MoH replaces the standard summation in multi-head attention with a weightedsummation, introducing flexibility to the attention mechanism and unlockingextra performance potential. Extensive experiments on ViT, DiT, and LLMsdemonstrate that MoH outperforms multi-head attention by using only 50%-90% ofthe attention heads. Moreover, we demonstrate that pre-trained multi-headattention models, such as LLaMA3-8B, can be further continue-tuned into our MoHmodels. Notably, MoH-LLaMA3-8B achieves an average accuracy of 64.0% across 14benchmarks, outperforming LLaMA3-8B by 2.4% by utilizing only 75% of theattention heads. We believe the proposed MoH is a promising alternative tomulti-head attention and provides a strong foundation for developing advancedand efficient attention-based models.</description><author>Peng Jin, Bo Zhu, Li Yuan, Shuicheng Yan</author><pubDate>Tue, 15 Oct 2024 17:59:44 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.11842v1</guid></item><item><title>GaVaMoE: Gaussian-Variational Gated Mixture of Experts for Explainable Recommendation</title><link>http://arxiv.org/abs/2410.11841v1</link><description>Large language model-based explainable recommendation (LLM-based ER) systemsshow promise in generating human-like explanations for recommendations.However, they face challenges in modeling user-item collaborative preferences,personalizing explanations, and handling sparse user-item interactions. Toaddress these issues, we propose GaVaMoE, a novel Gaussian-Variational GatedMixture of Experts framework for explainable recommendation. GaVaMoE introducestwo key components: (1) a rating reconstruction module that employs VariationalAutoencoder (VAE) with a Gaussian Mixture Model (GMM) to capture complexuser-item collaborative preferences, serving as a pre-trained multi-gatingmechanism; and (2) a set of fine-grained expert models coupled with themulti-gating mechanism for generating highly personalized explanations. The VAEcomponent models latent factors in user-item interactions, while the GMMclusters users with similar behaviors. Each cluster corresponds to a gate inthe multi-gating mechanism, routing user-item pairs to appropriate expertmodels. This architecture enables GaVaMoE to generate tailored explanations forspecific user types and preferences, mitigating data sparsity by leveraginguser similarities. Extensive experiments on three real-world datasetsdemonstrate that GaVaMoE significantly outperforms existing methods inexplanation quality, personalization, and consistency. Notably, GaVaMoEexhibits robust performance in scenarios with sparse user-item interactions,maintaining high-quality explanations even for users with limited historicaldata.</description><author>Fei Tang, Yongliang Shen, Hang Zhang, Zeqi Tan, Wenqi Zhang, Guiyang Hou, Kaitao Song, Weiming Lu, Yueting Zhuang</author><pubDate>Tue, 15 Oct 2024 17:59:30 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.11841v1</guid></item><item><title>A Hitchhiker's Guide to Scaling Law Estimation</title><link>http://arxiv.org/abs/2410.11840v1</link><description>Scaling laws predict the loss of a target machine learning model byextrapolating from easier-to-train models with fewer parameters or smallertraining sets. This provides an efficient way for practitioners and researchersalike to compare pretraining decisions involving optimizers, datasets, andmodel architectures. Despite the widespread use of scaling laws to model thedynamics of language model training, there has been little work onunderstanding how to best estimate and interpret them. We collect (and release)a large-scale dataset containing losses and downstream evaluations for 485previously published pretrained models. We use these to estimate more than 1000scaling laws, then derive a set of best practices for estimating scaling lawsin new model families. We find that fitting scaling laws to intermediatecheckpoints of training runs (and not just their final losses) substantiallyimproves accuracy, and that -- all else equal -- estimates of performance aregenerally most accurate when derived from other models of similar sizes.However, because there is a significant degree of variability across modelseeds, training multiple small models is sometimes more useful than training asingle large one. Moreover, while different model families differ scalingbehavior, they are often similar enough that a target model's behavior can bepredicted from a single model with the same architecture, along with scalingparameter estimates derived from other model families.</description><author>Leshem Choshen, Yang Zhang, Jacob Andreas</author><pubDate>Tue, 15 Oct 2024 17:59:10 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.11840v1</guid></item><item><title>High-Resolution Frame Interpolation with Patch-based Cascaded Diffusion</title><link>http://arxiv.org/abs/2410.11838v1</link><description>Despite the recent progress, existing frame interpolation methods stillstruggle with processing extremely high resolution input and handlingchallenging cases such as repetitive textures, thin objects, and large motion.To address these issues, we introduce a patch-based cascaded pixel diffusionmodel for frame interpolation, HiFI, that excels in these scenarios whileachieving competitive performance on standard benchmarks. Cascades, whichgenerate a series of images from low- to high-resolution, can helpsignificantly with large or complex motion that require both global context fora coarse solution and detailed context for high resolution output. However,contrary to prior work on cascaded diffusion models which perform diffusion onincreasingly large resolutions, we use a single model that always performsdiffusion at the same resolution and upsamples by processing patches of theinputs and the prior solution. We show that this technique drastically reducesmemory usage at inference time and also allows us to use a single model at testtime, solving both frame interpolation and spatial up-sampling, saving trainingcost. We show that HiFI helps significantly with high resolution and complexrepeated textures that require global context. HiFI demonstrates comparable orbeyond state-of-the-art performance on multiple benchmarks (Vimeo, Xiph,X-Test, SEPE-8K). On our newly introduced dataset that focuses on particularlychallenging cases, HiFI also significantly outperforms other baselines on thesecases. Please visit our project page for video results:https://hifi-diffusion.github.io</description><author>Junhwa Hur, Charles Herrmann, Saurabh Saxena, Janne Kontkanen, Wei-Sheng Lai, Yichang Shih, Michael Rubinstein, David J. Fleet, Deqing Sun</author><pubDate>Tue, 15 Oct 2024 17:59:04 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.11838v1</guid></item><item><title>LoRA-Pro: Are Low-Rank Adapters Properly Optimized?</title><link>http://arxiv.org/abs/2407.18242v2</link><description>Low-rank adaptation, also known as LoRA, has emerged as a prominent methodfor parameter-efficient fine-tuning of foundation models. Despite itscomputational efficiency, LoRA still yields inferior performance compared tofull fine-tuning. In this paper, we first uncover a fundamental connectionbetween the optimization processes of LoRA and full fine-tuning: using LoRA foroptimization is mathematically equivalent to full fine-tuning using a low-rankgradient for parameter updates. And this low-rank gradient can be expressed interms of the gradients of the two low-rank matrices in LoRA. Leveraging thisinsight, we introduce LoRA-Pro, a method that enhances LoRA's performance bystrategically adjusting the gradients of these low-rank matrices. Thisadjustment allows the low-rank gradient to more accurately approximate the fullfine-tuning gradient, thereby narrowing the performance gap between LoRA andfull fine-tuning. Furthermore, we theoretically derive the optimal solutionsfor adjusting the gradients of the low-rank matrices, applying them duringfine-tuning in LoRA-Pro. We conduct extensive experiments across naturallanguage understanding, dialogue generation, mathematical reasoning, codegeneration, and image classification tasks, demonstrating that LoRA-Prosubstantially improves LoRA's performance, effectively narrowing the gap withfull fine-tuning. Code is publicly available at\url{https://github.com/mrflogs/LoRA-Pro}.</description><author>Zhengbo Wang, Jian Liang, Ran He, Zilei Wang, Tieniu Tan</author><pubDate>Tue, 15 Oct 2024 17:58:24 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.18242v2</guid></item><item><title>On the Effectiveness of Dataset Alignment for Fake Image Detection</title><link>http://arxiv.org/abs/2410.11835v1</link><description>As latent diffusion models (LDMs) democratize image generation capabilities,there is a growing need to detect fake images. A good detector should focus onthe generative models fingerprints while ignoring image properties such assemantic content, resolution, file format, etc. Fake image detectors areusually built in a data driven way, where a model is trained to separate realfrom fake images. Existing works primarily investigate network architecturechoices and training recipes. In this work, we argue that in addition to thesealgorithmic choices, we also require a well aligned dataset of real/fake imagesto train a robust detector. For the family of LDMs, we propose a very simpleway to achieve this: we reconstruct all the real images using the LDMsautoencoder, without any denoising operation. We then train a model to separatethese real images from their reconstructions. The fakes created this way areextremely similar to the real ones in almost every aspect (e.g., size, aspectratio, semantic content), which forces the model to look for the LDM decodersartifacts. We empirically show that this way of creating aligned real/fakedatasets, which also sidesteps the computationally expensive denoising process,helps in building a detector that focuses less on spurious correlations,something that a very popular existing method is susceptible to. Finally, todemonstrate just how effective the alignment in a dataset can be, we build adetector using images that are not natural objects, and present promisingresults. Overall, our work identifies the subtle but significant issues thatarise when training a fake image detector and proposes a simple and inexpensivesolution to address these problems.</description><author>Anirudh Sundara Rajan, Utkarsh Ojha, Jedidiah Schloesser, Yong Jae Lee</author><pubDate>Tue, 15 Oct 2024 17:58:07 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.11835v1</guid></item><item><title>Mitigating Suboptimality of Deterministic Policy Gradients in Complex Q-functions</title><link>http://arxiv.org/abs/2410.11833v1</link><description>In reinforcement learning, off-policy actor-critic approaches like DDPG andTD3 are based on the deterministic policy gradient. Herein, the Q-function istrained from off-policy environment data and the actor (policy) is trained tomaximize the Q-function via gradient ascent. We observe that in complex taskslike dexterous manipulation and restricted locomotion, the Q-value is a complexfunction of action, having several local optima or discontinuities. This posesa challenge for gradient ascent to traverse and makes the actor prone to getstuck at local optima. To address this, we introduce a new actor architecturethat combines two simple insights: (i) use multiple actors and evaluate theQ-value maximizing action, and (ii) learn surrogates to the Q-function that aresimpler to optimize with gradient-based methods. We evaluate tasks such asrestricted locomotion, dexterous manipulation, and large discrete-action spacerecommender systems and show that our actor finds optimal actions morefrequently and outperforms alternate actor architectures.</description><author>Ayush Jain, Norio Kosaka, Xinhu Li, Kyung-Min Kim, Erdem Bıyık, Joseph J. Lim</author><pubDate>Tue, 15 Oct 2024 17:58:03 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.11833v1</guid></item><item><title>CoTracker3: Simpler and Better Point Tracking by Pseudo-Labelling Real Videos</title><link>http://arxiv.org/abs/2410.11831v1</link><description>Most state-of-the-art point trackers are trained on synthetic data due to thedifficulty of annotating real videos for this task. However, this can result insuboptimal performance due to the statistical gap between synthetic and realvideos. In order to understand these issues better, we introduce CoTracker3,comprising a new tracking model and a new semi-supervised training recipe. Thisallows real videos without annotations to be used during training by generatingpseudo-labels using off-the-shelf teachers. The new model eliminates orsimplifies components from previous trackers, resulting in a simpler and oftensmaller architecture. This training scheme is much simpler than prior work andachieves better results using 1,000 times less data. We further study thescaling behaviour to understand the impact of using more real unsupervised datain point tracking. The model is available in online and offline variants andreliably tracks visible and occluded points.</description><author>Nikita Karaev, Iurii Makarov, Jianyuan Wang, Natalia Neverova, Andrea Vedaldi, Christian Rupprecht</author><pubDate>Tue, 15 Oct 2024 17:56:32 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.11831v1</guid></item><item><title>TemporalBench: Benchmarking Fine-grained Temporal Understanding for Multimodal Video Models</title><link>http://arxiv.org/abs/2410.10818v2</link><description>Understanding fine-grained temporal dynamics is crucial for multimodal videocomprehension and generation. Due to the lack of fine-grained temporalannotations, existing video benchmarks mostly resemble static image benchmarksand are incompetent at evaluating models for temporal understanding. In thispaper, we introduce TemporalBench, a new benchmark dedicated to evaluatingfine-grained temporal understanding in videos. TemporalBench consists of ~10Kvideo question-answer pairs, derived from ~2K high-quality human annotationsdetailing the temporal dynamics in video clips. As a result, our benchmarkprovides a unique testbed for evaluating various temporal understanding andreasoning abilities such as action frequency, motion magnitude, event order,etc. Moreover, it enables evaluations on various tasks like both video questionanswering and captioning, both short and long video understanding, as well asdifferent models such as multimodal video embedding models and text generationmodels. Results show that state-of-the-art models like GPT-4o achieve only38.5% question answering accuracy on TemporalBench, demonstrating a significantgap (~30%) between humans and AI in temporal understanding. Furthermore, wenotice a critical pitfall for multi-choice QA where LLMs can detect the subtlechanges in negative captions and find a centralized description as a cue forits prediction, where we propose Multiple Binary Accuracy (MBA) to correct suchbias. We hope that TemporalBench can foster research on improving models'temporal reasoning capabilities. Both dataset and evaluation code will be madeavailable.</description><author>Mu Cai, Reuben Tan, Jianrui Zhang, Bocheng Zou, Kai Zhang, Feng Yao, Fangrui Zhu, Jing Gu, Yiwu Zhong, Yuzhang Shang, Yao Dou, Jaden Park, Jianfeng Gao, Yong Jae Lee, Jianwei Yang</author><pubDate>Tue, 15 Oct 2024 17:55:46 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.10818v2</guid></item><item><title>MMFuser: Multimodal Multi-Layer Feature Fuser for Fine-Grained Vision-Language Understanding</title><link>http://arxiv.org/abs/2410.11829v1</link><description>Despite significant advancements in Multimodal Large Language Models (MLLMs)for understanding complex human intentions through cross-modal interactions,capturing intricate image details remains challenging. Previous methodsintegrating multiple vision encoders to enhance visual detail introduceredundancy and computational overhead. We observe that most MLLMs utilize onlythe last-layer feature map of the vision encoder for visual representation,neglecting the rich fine-grained information in shallow feature maps. Toaddress this issue, we propose \modelname, a simple yet effective multi-layerfeature fuser that efficiently integrates deep and shallow features from VisionTransformers (ViTs). Specifically, it leverages semantically aligned deepfeatures as queries to dynamically extract missing details from shallowfeatures, thus preserving semantic alignment while enriching the representationwith fine-grained information. Applied to the LLaVA-1.5 model,\modelname~achieves significant improvements in visual representation andbenchmark performance, providing a more flexible and lightweight solutioncompared to multi-encoder ensemble methods. The code and model have beenreleased at https://github.com/yuecao0119/MMFuser.</description><author>Yue Cao, Yangzhou Liu, Zhe Chen, Guangchen Shi, Wenhai Wang, Danhuai Zhao, Tong Lu</author><pubDate>Tue, 15 Oct 2024 17:55:22 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.11829v1</guid></item><item><title>Autonomous Improvement of Instruction Following Skills via Foundation Models</title><link>http://arxiv.org/abs/2407.20635v2</link><description>Intelligent instruction-following robots capable of improving fromautonomously collected experience have the potential to transform robotlearning: instead of collecting costly teleoperated demonstration data,large-scale deployment of fleets of robots can quickly collect largerquantities of autonomous data that can collectively improve their performance.However, autonomous improvement requires solving two key problems: (i) fullyautomating a scalable data collection procedure that can collect diverse andsemantically meaningful robot data and (ii) learning from non-optimal,autonomous data with no human annotations. To this end, we propose a novelapproach that addresses these challenges, allowing instruction-followingpolicies to improve from autonomously collected data without human supervision.Our framework leverages vision-language models to collect and evaluatesemantically meaningful experiences in new environments, and then utilizes adecomposition of instruction following tasks into (semantic)language-conditioned image generation and (non-semantic) goal reaching, whichmakes it significantly more practical to improve from this autonomouslycollected data without any human annotations. We carry out extensiveexperiments in the real world to demonstrate the effectiveness of our approach,and find that in a suite of unseen environments, the robot policy can beimproved 2x with autonomously collected data. We open-source the code for oursemantic autonomous improvement pipeline, as well as our autonomous dataset of30.5K trajectories collected across five tabletop environments.</description><author>Zhiyuan Zhou, Pranav Atreya, Abraham Lee, Homer Walke, Oier Mees, Sergey Levine</author><pubDate>Tue, 15 Oct 2024 17:54:17 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.20635v2</guid></item><item><title>Analysis and Benchmarking of Extending Blind Face Image Restoration to Videos</title><link>http://arxiv.org/abs/2410.11828v1</link><description>Recent progress in blind face restoration has resulted in producinghigh-quality restored results for static images. However, efforts to extendthese advancements to video scenarios have been minimal, partly because of theabsence of benchmarks that allow for a comprehensive and fair comparison. Inthis work, we first present a fair evaluation benchmark, in which we firstintroduce a Real-world Low-Quality Face Video benchmark (RFV-LQ), evaluateseveral leading image-based face restoration algorithms, and conduct a thoroughsystematical analysis of the benefits and challenges associated with extendingblind face image restoration algorithms to degraded face videos. Our analysisidentifies several key issues, primarily categorized into two aspects:significant jitters in facial components and noise-shape flickering betweenframes. To address these issues, we propose a Temporal Consistency Network(TCN) cooperated with alignment smoothing to reduce jitters and flickers inrestored videos. TCN is a flexible component that can be seamlessly pluggedinto the most advanced face image restoration algorithms, ensuring the qualityof image-based restoration is maintained as closely as possible. Extensiveexperiments have been conducted to evaluate the effectiveness and efficiency ofour proposed TCN and alignment smoothing operation. Project page:https://wzhouxiff.github.io/projects/FIR2FVR/FIR2FVR.</description><author>Zhouxia Wang, Jiawei Zhang, Xintao Wang, Tianshui Chen, Ying Shan, Wenping Wang, Ping Luo</author><pubDate>Tue, 15 Oct 2024 17:53:25 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.11828v1</guid></item><item><title>Bayesian Experimental Design via Contrastive Diffusions</title><link>http://arxiv.org/abs/2410.11826v1</link><description>Bayesian Optimal Experimental Design (BOED) is a powerful tool to reduce thecost of running a sequence of experiments. When based on the ExpectedInformation Gain (EIG), design optimization corresponds to the maximization ofsome intractable expected {\it contrast} between prior and posteriordistributions. Scaling this maximization to high dimensional and complexsettings has been an issue due to BOED inherent computational complexity. Inthis work, we introduce an {\it expected posterior} distribution withcost-effective sampling properties and provide a tractable access to the EIGcontrast maximization via a new EIG gradient expression. Diffusion-basedsamplers are used to compute the dynamics of the expected posterior and ideasfrom bi-level optimization are leveraged to derive an efficient jointsampling-optimization loop, without resorting to lower bound approximations ofthe EIG. The resulting efficiency gain allows to extend BOED to the well-testedgenerative capabilities of diffusion models. By incorporating generative modelsinto the BOED framework, we expand its scope and its use in scenarios that werepreviously impractical. Numerical experiments and comparison withstate-of-the-art methods show the potential of the approach.</description><author>Jacopo Iollo, Christophe Heinkelé, Pierre Alliez, Florence Forbes</author><pubDate>Tue, 15 Oct 2024 17:53:07 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.11826v1</guid></item><item><title>Learning Smooth Humanoid Locomotion through Lipschitz-Constrained Policies</title><link>http://arxiv.org/abs/2410.11825v1</link><description>Reinforcement learning combined with sim-to-real transfer offers a generalframework for developing locomotion controllers for legged robots. Tofacilitate successful deployment in the real world, smoothing techniques, suchas low-pass filters and smoothness rewards, are often employed to developpolicies with smooth behaviors. However, because these techniques arenon-differentiable and usually require tedious tuning of a large set ofhyperparameters, they tend to require extensive manual tuning for each roboticplatform. To address this challenge and establish a general technique forenforcing smooth behaviors, we propose a simple and effective method thatimposes a Lipschitz constraint on a learned policy, which we refer to asLipschitz-Constrained Policies (LCP). We show that the Lipschitz constraint canbe implemented in the form of a gradient penalty, which provides adifferentiable objective that can be easily incorporated with automaticdifferentiation frameworks. We demonstrate that LCP effectively replaces theneed for smoothing rewards or low-pass filters and can be easily integratedinto training frameworks for many distinct humanoid robots. We extensivelyevaluate LCP in both simulation and real-world humanoid robots, producingsmooth and robust locomotion controllers. All simulation and deployment code,along with complete checkpoints, is available on our project page:https://lipschitz-constrained-policy.github.io.</description><author>Zixuan Chen, Xialin He, Yen-Jen Wang, Qiayuan Liao, Yanjie Ze, Zhongyu Li, S. Shankar Sastry, Jiajun Wu, Koushil Sreenath, Saurabh Gupta, Xue Bin Peng</author><pubDate>Tue, 15 Oct 2024 17:52:20 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.11825v1</guid></item><item><title>KITTEN: A Knowledge-Intensive Evaluation of Image Generation on Visual Entities</title><link>http://arxiv.org/abs/2410.11824v1</link><description>Recent advancements in text-to-image generation have significantly enhancedthe quality of synthesized images. Despite this progress, evaluationspredominantly focus on aesthetic appeal or alignment with text prompts.Consequently, there is limited understanding of whether these models canaccurately represent a wide variety of realistic visual entities - a taskrequiring real-world knowledge. To address this gap, we propose a benchmarkfocused on evaluating Knowledge-InTensive image generaTion on real-worldENtities (i.e., KITTEN). Using KITTEN, we conduct a systematic study on thefidelity of entities in text-to-image generation models, focusing on theirability to generate a wide range of real-world visual entities, such aslandmark buildings, aircraft, plants, and animals. We evaluate the latesttext-to-image models and retrieval-augmented customization models using bothautomatic metrics and carefully-designed human evaluations, with an emphasis onthe fidelity of entities in the generated images. Our findings reveal that eventhe most advanced text-to-image models often fail to generate entities withaccurate visual details. Although retrieval-augmented models can enhance thefidelity of entity by incorporating reference images during testing, they oftenover-rely on these references and struggle to produce novel configurations ofthe entity as requested in creative text prompts.</description><author>Hsin-Ping Huang, Xinyi Wang, Yonatan Bitton, Hagai Taitelbaum, Gaurav Singh Tomar, Ming-Wei Chang, Xuhui Jia, Kelvin C. K. Chan, Hexiang Hu, Yu-Chuan Su, Ming-Hsuan Yang</author><pubDate>Tue, 15 Oct 2024 17:50:37 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.11824v1</guid></item><item><title>Adaptive Data Optimization: Dynamic Sample Selection with Scaling Laws</title><link>http://arxiv.org/abs/2410.11820v1</link><description>The composition of pretraining data is a key determinant of foundationmodels' performance, but there is no standard guideline for allocating alimited computational budget across different data sources. Most currentapproaches either rely on extensive experiments with smaller models or dynamicdata adjustments that also require proxy models, both of which significantlyincrease the workflow complexity and computational overhead. In this paper, weintroduce Adaptive Data Optimization (ADO), an algorithm that optimizes datadistributions in an online fashion, concurrent with model training. Unlikeexisting techniques, ADO does not require external knowledge, proxy models, ormodifications to the model update. Instead, ADO uses per-domain scaling laws toestimate the learning potential of each domain during training and adjusts thedata mixture accordingly, making it more scalable and easier to integrate.Experiments demonstrate that ADO can achieve comparable or better performancethan prior methods while maintaining computational efficiency across differentcomputation scales, offering a practical solution for dynamically adjustingdata distribution without sacrificing flexibility or increasing costs. Beyondits practical benefits, ADO also provides a new perspective on data collectionstrategies via scaling laws.</description><author>Yiding Jiang, Allan Zhou, Zhili Feng, Sadhika Malladi, J. Zico Kolter</author><pubDate>Tue, 15 Oct 2024 17:47:44 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.11820v1</guid></item><item><title>Improving Long-Text Alignment for Text-to-Image Diffusion Models</title><link>http://arxiv.org/abs/2410.11817v1</link><description>The rapid advancement of text-to-image (T2I) diffusion models has enabledthem to generate unprecedented results from given texts. However, as textinputs become longer, existing encoding methods like CLIP face limitations, andaligning the generated images with long texts becomes challenging. To tacklethese issues, we propose LongAlign, which includes a segment-level encodingmethod for processing long texts and a decomposed preference optimizationmethod for effective alignment training. For segment-level encoding, long textsare divided into multiple segments and processed separately. This methodovercomes the maximum input length limits of pretrained encoding models. Forpreference optimization, we provide decomposed CLIP-based preference models tofine-tune diffusion models. Specifically, to utilize CLIP-based preferencemodels for T2I alignment, we delve into their scoring mechanisms and find thatthe preference scores can be decomposed into two components: a text-relevantpart that measures T2I alignment and a text-irrelevant part that assesses othervisual aspects of human preference. Additionally, we find that thetext-irrelevant part contributes to a common overfitting problem duringfine-tuning. To address this, we propose a reweighting strategy that assignsdifferent weights to these two components, thereby reducing overfitting andenhancing alignment. After fine-tuning $512 \times 512$ Stable Diffusion (SD)v1.5 for about 20 hours using our method, the fine-tuned SD outperformsstronger foundation models in T2I alignment, such as PixArt-$\alpha$ andKandinsky v2.2. The code is available athttps://github.com/luping-liu/LongAlign.</description><author>Luping Liu, Chao Du, Tianyu Pang, Zehan Wang, Chongxuan Li, Dong Xu</author><pubDate>Tue, 15 Oct 2024 17:46:31 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.11817v1</guid></item><item><title>Jigsaw++: Imagining Complete Shape Priors for Object Reassembly</title><link>http://arxiv.org/abs/2410.11816v1</link><description>The automatic assembly problem has attracted increasing interest due to itscomplex challenges that involve 3D representation. This paper introducesJigsaw++, a novel generative method designed to tackle the multifacetedchallenges of reconstruction for the reassembly problem. Existing approachfocusing primarily on piecewise information for both part and fractureassembly, often overlooking the integration of complete object prior. Jigsaw++distinguishes itself by learning a category-agnostic shape prior of completeobjects. It employs the proposed "retargeting" strategy that effectivelyleverages the output of any existing assembly method to generate complete shapereconstructions. This capability allows it to function orthogonally to thecurrent methods. Through extensive evaluations on Breaking Bad dataset andPartNet, Jigsaw++ has demonstrated its effectiveness, reducing reconstructionerrors and enhancing the precision of shape reconstruction, which sets a newdirection for future reassembly model developments.</description><author>Jiaxin Lu, Gang Hua, Qixing Huang</author><pubDate>Tue, 15 Oct 2024 17:45:37 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.11816v1</guid></item><item><title>A Novel Gaussian Min-Max Theorem and its Applications</title><link>http://arxiv.org/abs/2402.07356v3</link><description>A celebrated result by Gordon allows one to compare the min-max behavior oftwo Gaussian processes if certain inequality conditions are met. Theconsequences of this result include the Gaussian min-max (GMT) and convexGaussian min-max (CGMT) theorems which have had far-reaching implications inhigh-dimensional statistics, machine learning, non-smooth optimization, andsignal processing. Both theorems rely on a pair of Gaussian processes, firstidentified by Slepian, that satisfy Gordon's comparison inequalities. In thispaper, we identify such a new pair. The resulting theorems extend the classicalGMT and CGMT Theorems from the case where the underlying Gaussian matrix in theprimary process has iid rows to where it has independent butnon-identically-distributed ones. The new CGMT is applied to the problems ofmulti-source Gaussian regression, as well as to binary classification ofgeneral Gaussian mixture models.</description><author>Danil Akhtiamov, David Bosch, Reza Ghane, K Nithin Varma, Babak Hassibi</author><pubDate>Tue, 15 Oct 2024 17:43:51 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.07356v3</guid></item><item><title>SGEdit: Bridging LLM with Text2Image Generative Model for Scene Graph-based Image Editing</title><link>http://arxiv.org/abs/2410.11815v1</link><description>Scene graphs offer a structured, hierarchical representation of images, withnodes and edges symbolizing objects and the relationships among them. It canserve as a natural interface for image editing, dramatically improvingprecision and flexibility. Leveraging this benefit, we introduce a newframework that integrates large language model (LLM) with Text2Image generativemodel for scene graph-based image editing. This integration enables precisemodifications at the object level and creative recomposition of scenes withoutcompromising overall image integrity. Our approach involves two primary stages:1) Utilizing a LLM-driven scene parser, we construct an image's scene graph,capturing key objects and their interrelationships, as well as parsingfine-grained attributes such as object masks and descriptions. Theseannotations facilitate concept learning with a fine-tuned diffusion model,representing each object with an optimized token and detailed descriptionprompt. 2) During the image editing phase, a LLM editing controller guides theedits towards specific areas. These edits are then implemented by anattention-modulated diffusion editor, utilizing the fine-tuned model to performobject additions, deletions, replacements, and adjustments. Through extensiveexperiments, we demonstrate that our framework significantly outperformsexisting image editing methods in terms of editing precision and sceneaesthetics.</description><author>Zhiyuan Zhang, DongDong Chen, Jing Liao</author><pubDate>Tue, 15 Oct 2024 17:40:48 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.11815v1</guid></item><item><title>LoRD: Adapting Differentiable Driving Policies to Distribution Shifts</title><link>http://arxiv.org/abs/2410.09681v2</link><description>Distribution shifts between operational domains can severely affect theperformance of learned models in self-driving vehicles (SDVs). While this is awell-established problem, prior work has mostly explored naive solutions suchas fine-tuning, focusing on the motion prediction task. In this work, weexplore novel adaptation strategies for differentiable autonomy stacksconsisting of prediction, planning, and control, perform evaluation inclosed-loop, and investigate the often-overlooked issue of catastrophicforgetting. Specifically, we introduce two simple yet effective techniques: alow-rank residual decoder (LoRD) and multi-task fine-tuning. Throughexperiments across three models conducted on two real-world autonomous drivingdatasets (nuPlan, exiD), we demonstrate the effectiveness of our methods andhighlight a significant performance gap between open-loop and closed-loopevaluation in prior approaches. Our approach improves forgetting by up to23.33% and the closed-loop OOD driving score by 8.83% in comparison to standardfine-tuning.</description><author>Christopher Diehl, Peter Karkus, Sushant Veer, Marco Pavone, Torsten Bertram</author><pubDate>Tue, 15 Oct 2024 17:38:26 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.09681v2</guid></item><item><title>Advancements in Road Lane Mapping: Comparative Fine-Tuning Analysis of Deep Learning-based Semantic Segmentation Methods Using Aerial Imagery</title><link>http://arxiv.org/abs/2410.05717v2</link><description>This research addresses the need for high-definition (HD) maps for autonomousvehicles (AVs), focusing on road lane information derived from aerial imagery.While Earth observation data offers valuable resources for map creation,specialized models for road lane extraction are still underdeveloped in remotesensing. In this study, we perform an extensive comparison of twelvefoundational deep learning-based semantic segmentation models for road lanemarking extraction from high-definition remote sensing images, assessing theirperformance under transfer learning with partially labeled datasets. Thesemodels were fine-tuned on the partially labeled Waterloo Urban Scene dataset,and pre-trained on the SkyScapes dataset, simulating a likely scenario ofreal-life model deployment under partial labeling. We observed and assessed thefine-tuning performance and overall performance. Models showed significantperformance improvements after fine-tuning, with mean IoU scores ranging from33.56% to 76.11%, and recall ranging from 66.0% to 98.96%. Transformer-basedmodels outperformed convolutional neural networks, emphasizing the importanceof model pre-training and fine-tuning in enhancing HD map development for AVnavigation.</description><author>Willow Liu, Shuxin Qiao, Kyle Gao, Hongjie He, Michael A. Chapman, Linlin Xu, Jonathan Li</author><pubDate>Tue, 15 Oct 2024 17:37:45 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.05717v2</guid></item><item><title>What We Talk About When We Talk About LMs: Implicit Paradigm Shifts and the Ship of Language Models</title><link>http://arxiv.org/abs/2407.01929v2</link><description>The term Language Models (LMs), as a time-specific collection of models ofinterest, is constantly reinvented, with its referents updated much like the$\textit{Ship of Theseus}$ replaces its parts but remains the same ship inessence. In this paper, we investigate this $\textit{Ship of Language Models}$problem, wherein scientific evolution takes the form of continuous, implicitretrofits of key existing terms. We seek to initiate a novel perspective ofscientific progress, in addition to the more well-studied emergence of newterms. To this end, we construct the data infrastructure based on recent NLPpublications. Then, we perform a series of text-based analyses toward adetailed, quantitative understanding of the use of Language Models as a term ofart. Our work highlights how systems and theories influence each other inscientific discourse, and we call for attention to the transformation of thisShip that we all are contributing to.</description><author>Shengqi Zhu, Jeffrey M. Rzeszotarski</author><pubDate>Tue, 15 Oct 2024 17:36:59 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.01929v2</guid></item><item><title>Regional Ocean Forecasting with Hierarchical Graph Neural Networks</title><link>http://arxiv.org/abs/2410.11807v1</link><description>Accurate ocean forecasting systems are vital for understanding marinedynamics, which play a crucial role in environmental management and climateadaptation strategies. Traditional numerical solvers, while effective, arecomputationally expensive and time-consuming. Recent advancements in machinelearning have revolutionized weather forecasting, offering fast andenergy-efficient alternatives. Building on these advancements, we introduceSeaCast, a neural network designed for high-resolution, medium-range oceanforecasting. SeaCast employs a graph-based framework to effectively handle thecomplex geometry of ocean grids and integrates external forcing data tailoredto the regional ocean context. Our approach is validated through experiments ata high spatial resolution using the operational numerical model of theMediterranean Sea provided by the Copernicus Marine Service, along with bothnumerical and data-driven atmospheric forcings.</description><author>Daniel Holmberg, Emanuela Clementi, Teemu Roos</author><pubDate>Tue, 15 Oct 2024 17:34:50 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.11807v1</guid></item><item><title>NesTools: A Dataset for Evaluating Nested Tool Learning Abilities of Large Language Models</title><link>http://arxiv.org/abs/2410.11805v1</link><description>Large language models (LLMs) combined with tool learning have gainedimpressive results in real-world applications. During tool learning, LLMs maycall multiple tools in nested orders, where the latter tool call may take theformer response as its input parameters. However, current research on thenested tool learning capabilities is still under-explored, since the existingbenchmarks lack of relevant data instances. To address this problem, weintroduce NesTools to bridge the current gap in comprehensive nested toollearning evaluations. NesTools comprises a novel automatic data generationmethod to construct large-scale nested tool calls with different nestingstructures. With manual review and refinement, the dataset is in high qualityand closely aligned with real-world scenarios. Therefore, NesTools can serve asa new benchmark to evaluate the nested tool learning abilities of LLMs. Weconduct extensive experiments on 22 LLMs, and provide in-depth analyses withNesTools, which shows that current LLMs still suffer from the complex nestedtool learning task.</description><author>Han Han, Tong Zhu, Xiang Zhang, Mengsong Wu, Hao Xiong, Wenliang Chen</author><pubDate>Tue, 15 Oct 2024 17:33:43 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.11805v1</guid></item><item><title>VIA: Unified Spatiotemporal Video Adaptation Framework for Global and Local Video Editing</title><link>http://arxiv.org/abs/2406.12831v2</link><description>Video editing is a cornerstone of digital media, from entertainment andeducation to professional communication. However, previous methods oftenoverlook the necessity of comprehensively understanding both global and localcontexts, leading to inaccurate and inconsistent edits in the spatiotemporaldimension, especially for long videos. In this paper, we introduce VIA, aunified spatiotemporal Video Adaptation framework for global and local videoediting, pushing the limits of consistently editing minute-long videos. First,to ensure local consistency within individual frames, we designed test-timeediting adaptation to adapt a pre-trained image editing model for improvingconsistency between potential editing directions and the text instruction, andadapt masked latent variables for precise local control. Furthermore, tomaintain global consistency over the video sequence, we introducespatiotemporal adaptation that recursively gather consistent attentionvariables in key frames and strategically applies them across the wholesequence to realize the editing effects. Extensive experiments demonstratethat, compared to baseline methods, our VIA approach produces edits that aremore faithful to the source videos, more coherent in the spatiotemporalcontext, and more precise in local control. More importantly, we show that VIAcan achieve consistent long video editing in minutes, unlocking the potentialfor advanced video editing tasks over long video sequences.</description><author>Jing Gu, Yuwei Fang, Ivan Skorokhodov, Peter Wonka, Xinya Du, Sergey Tulyakov, Xin Eric Wang</author><pubDate>Tue, 15 Oct 2024 17:31:56 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.12831v2</guid></item><item><title>Curriculum effects and compositionality emerge with in-context learning in neural networks</title><link>http://arxiv.org/abs/2402.08674v3</link><description>Human learning embodies a striking duality: sometimes, we appear capable offollowing logical, compositional rules and benefit from structured curricula(e.g., in formal education), while other times, we rely on an incrementalapproach or trial-and-error, learning better from curricula that areunstructured or randomly interleaved. Influential psychological theoriesexplain this seemingly disparate behavioral evidence by positing twoqualitatively different learning systems -- one for rapid, rule-basedinferences and another for slow, incremental adaptation. It remains unclear howto reconcile such theories with neural networks, which learn via incrementalweight updates and are thus a natural model for the latter type of learning,but are not obviously compatible with the former. However, recent evidencesuggests that both metalearning neural networks and large language models arecapable of "in-context learning" (ICL) -- the ability to flexibly grasp thestructure of a new task from a few examples given at inference time. Here, weshow that networks capable of ICL can reproduce human-like learning andcompositional behavior on rule-governed tasks, while at the same timereplicating human behavioral phenomena in tasks lacking rule-like structure viatheir usual in-weight learning (IWL). Our work shows how emergent ICL can equipneural networks with fundamentally different learning properties than thosetraditionally attributed to them, and that these can coexist with theproperties of their native IWL, thus offering a novel perspective ondual-process theories and human cognitive flexibility.</description><author>Jacob Russin, Ellie Pavlick, Michael J. Frank</author><pubDate>Tue, 15 Oct 2024 17:29:13 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.08674v3</guid></item><item><title>FoundTS: Comprehensive and Unified Benchmarking of Foundation Models for Time Series Forecasting</title><link>http://arxiv.org/abs/2410.11802v1</link><description>Time Series Forecasting (TSF) is key functionality in numerous fields,including in finance, weather services, and energy management. While TSFmethods are emerging these days, many of them require domain-specific datacollection and model training and struggle with poor generalization performanceon new domains. Foundation models aim to overcome this limitation. Pre-trainedon large-scale language or time series data, they exhibit promising inferencingcapabilities in new or unseen data. This has spurred a surge in new TSFfoundation models. We propose a new benchmark, FoundTS, to enable thorough andfair evaluation and comparison of such models. FoundTS covers a variety of TSFfoundation models, including those based on large language models and thosepretrained on time series. Next, FoundTS supports different forecastingstrategies, including zero-shot, few-shot, and full-shot, thereby facilitatingmore thorough evaluations. Finally, FoundTS offers a pipeline that standardizesevaluation processes such as dataset splitting, loading, normalization, andfew-shot sampling, thereby facilitating fair evaluations. Building on this, wereport on an extensive evaluation of TSF foundation models on a broad range ofdatasets from diverse domains and with different statistical characteristics.Specifically, we identify pros and cons and inherent limitations of existingfoundation models, and we identify directions for future model design. We makeour code and datasets available athttps://anonymous.4open.science/r/FoundTS-C2B0.</description><author>Zhe Li, Xiangfei Qiu, Peng Chen, Yihang Wang, Hanyin Cheng, Yang Shu, Jilin Hu, Chenjuan Guo, Aoying Zhou, Qingsong Wen, Christian S. Jensen, Bin Yang</author><pubDate>Tue, 15 Oct 2024 17:23:49 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.11802v1</guid></item><item><title>Predicting from Strings: Language Model Embeddings for Bayesian Optimization</title><link>http://arxiv.org/abs/2410.10190v2</link><description>Bayesian Optimization is ubiquitous in the field of experimental design andblackbox optimization for improving search efficiency, but has beentraditionally restricted to regression models which are only applicable tofixed search spaces and tabular input features. We propose Embed-then-Regress,a paradigm for applying in-context regression over string inputs, through theuse of string embedding capabilities of pretrained language models. Byexpressing all inputs as strings, we are able to perform general-purposeregression for Bayesian Optimization over various domains including synthetic,combinatorial, and hyperparameter optimization, obtaining comparable results tostate-of-the-art Gaussian Process-based algorithms. Code can be found athttps://github.com/google-research/optformer/tree/main/optformer/embed_then_regress.</description><author>Tung Nguyen, Qiuyi Zhang, Bangding Yang, Chansoo Lee, Jorg Bornschein, Yingjie Miao, Sagi Perel, Yutian Chen, Xingyou Song</author><pubDate>Tue, 15 Oct 2024 17:23:08 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.10190v2</guid></item><item><title>Active Label Refinement for Robust Training of Imbalanced Medical Image Classification Tasks in the Presence of High Label Noise</title><link>http://arxiv.org/abs/2407.05973v2</link><description>The robustness of supervised deep learning-based medical image classificationis significantly undermined by label noise. Although several methods have beenproposed to enhance classification performance in the presence of noisy labels,they face some challenges: 1) a struggle with class-imbalanced datasets,leading to the frequent overlooking of minority classes as noisy samples; 2) asingular focus on maximizing performance using noisy datasets, withoutincorporating experts-in-the-loop for actively cleaning the noisy labels. Tomitigate these challenges, we propose a two-phase approach that combinesLearning with Noisy Labels (LNL) and active learning. This approach not onlyimproves the robustness of medical image classification in the presence ofnoisy labels, but also iteratively improves the quality of the dataset byrelabeling the important incorrect labels, under a limited annotation budget.Furthermore, we introduce a novel Variance of Gradients approach in LNL phase,which complements the loss-based sample selection by also samplingunder-represented samples. Using two imbalanced noisy medical classificationdatasets, we demonstrate that that our proposed technique is superior to itspredecessors at handling class imbalance by not misidentifying clean samplesfrom minority classes as mostly noisy samples.</description><author>Bidur Khanal, Tianhong Dai, Binod Bhattarai, Cristian Linte</author><pubDate>Tue, 15 Oct 2024 17:22:12 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.05973v2</guid></item><item><title>Efficient Diffusion Models: A Comprehensive Survey from Principles to Practices</title><link>http://arxiv.org/abs/2410.11795v1</link><description>As one of the most popular and sought-after generative models in the recentyears, diffusion models have sparked the interests of many researchers andsteadily shown excellent advantage in various generative tasks such as imagesynthesis, video generation, molecule design, 3D scene rendering and multimodalgeneration, relying on their dense theoretical principles and reliableapplication practices. The remarkable success of these recent efforts ondiffusion models comes largely from progressive design principles and efficientarchitecture, training, inference, and deployment methodologies. However, therehas not been a comprehensive and in-depth review to summarize these principlesand practices to help the rapid understanding and application of diffusionmodels. In this survey, we provide a new efficiency-oriented perspective onthese existing efforts, which mainly focuses on the profound principles andefficient practices in architecture designs, model training, fast inference andreliable deployment, to guide further theoretical research, algorithm migrationand model application for new scenarios in a reader-friendly way.\url{https://github.com/ponyzym/Efficient-DMs-Survey}</description><author>Zhiyuan Ma, Yuzhu Zhang, Guoli Jia, Liangliang Zhao, Yichao Ma, Mingjie Ma, Gaofeng Liu, Kaiyan Zhang, Jianjun Li, Bowen Zhou</author><pubDate>Tue, 15 Oct 2024 17:19:46 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.11795v1</guid></item><item><title>OKAMI: Teaching Humanoid Robots Manipulation Skills through Single Video Imitation</title><link>http://arxiv.org/abs/2410.11792v1</link><description>We study the problem of teaching humanoid robots manipulation skills byimitating from single video demonstrations. We introduce OKAMI, a method thatgenerates a manipulation plan from a single RGB-D video and derives a policyfor execution. At the heart of our approach is object-aware retargeting, whichenables the humanoid robot to mimic the human motions in an RGB-D video whileadjusting to different object locations during deployment. OKAMI usesopen-world vision models to identify task-relevant objects and retarget thebody motions and hand poses separately. Our experiments show that OKAMIachieves strong generalizations across varying visual and spatial conditions,outperforming the state-of-the-art baseline on open-world imitation fromobservation. Furthermore, OKAMI rollout trajectories are leveraged to trainclosed-loop visuomotor policies, which achieve an average success rate of 79.2%without the need for labor-intensive teleoperation. More videos can be found onour website https://ut-austin-rpl.github.io/OKAMI/.</description><author>Jinhan Li, Yifeng Zhu, Yuqi Xie, Zhenyu Jiang, Mingyo Seo, Georgios Pavlakos, Yuke Zhu</author><pubDate>Tue, 15 Oct 2024 17:17:54 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.11792v1</guid></item><item><title>Need of AI in Modern Education: in the Eyes of Explainable AI (xAI)</title><link>http://arxiv.org/abs/2408.00025v2</link><description>Modern Education is not \textit{Modern} without AI. However, AI's complexnature makes understanding and fixing problems challenging. Research worldwideshows that a parent's income greatly influences a child's education. This ledus to explore how AI, especially complex models, makes important decisionsusing Explainable AI tools. Our research uncovered many complexities linked toparental income and offered reasonable explanations for these decisions.However, we also found biases in AI that go against what we want from AI ineducation: clear transparency and equal access for everyone. These biases canimpact families and children's schooling, highlighting the need for better AIsolutions that offer fair opportunities to all. This chapter tries to shedlight on the complex ways AI operates, especially concerning biases. These arethe foundational steps towards better educational policies, which include usingAI in ways that are more reliable, accountable, and beneficial for everyoneinvolved.</description><author>Supriya Manna, Niladri Sett</author><pubDate>Tue, 15 Oct 2024 17:15:31 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.00025v2</guid></item><item><title>AGaLiTe: Approximate Gated Linear Transformers for Online Reinforcement Learning</title><link>http://arxiv.org/abs/2310.15719v2</link><description>In this paper we investigate transformer architectures designed for partiallyobservable online reinforcement learning. The self-attention mechanism in thetransformer architecture is capable of capturing long-range dependencies and itis the main reason behind its effectiveness in processing sequential data.Nevertheless, despite their success, transformers have two significantdrawbacks that still limit their applicability in online reinforcementlearning: (1) in order to remember all past information, the self-attentionmechanism requires access to the whole history to be provided as context. (2)The inference cost in transformers is expensive. In this paper, we introducerecurrent alternatives to the transformer self-attention mechanism that offercontext-independent inference cost, leverage long-range dependencieseffectively, and performs well in online reinforcement learning task. Wequantify the impact of the different components of our architecture in adiagnostic environment and assess performance gains in 2D and 3D pixel-basedpartially-observable environments (e.g. T-Maze, Mystery Path, Craftax, andMemory Maze). Compared with a state-of-the-art architecture, GTrXL, inferencein our approach is at least 40% cheaper while reducing memory use more than50%. Our approach either performs similarly or better than GTrXL, improvingmore than 37% upon GTrXL performance in harder tasks.</description><author>Subhojeet Pramanik, Esraa Elelimy, Marlos C. Machado, Adam White</author><pubDate>Tue, 15 Oct 2024 17:14:26 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.15719v2</guid></item><item><title>Solving The Dynamic Volatility Fitting Problem: A Deep Reinforcement Learning Approach</title><link>http://arxiv.org/abs/2410.11789v1</link><description>The volatility fitting is one of the core problems in the equity derivativesbusiness. Through a set of deterministic rules, the degrees of freedom in theimplied volatility surface encoding (parametrization, density, diffusion) aredefined. Whilst very effective, this approach widespread in the industry is notnatively tailored to learn from shifts in market regimes and discoverunsuspected optimal behaviors. In this paper, we change the classical paradigmand apply the latest advances in Deep Reinforcement Learning(DRL) to solve thefitting problem. In particular, we show that variants of Deep DeterministicPolicy Gradient (DDPG) and Soft Actor Critic (SAC) can achieve at least as goodas standard fitting algorithms. Furthermore, we explain why the reinforcementlearning framework is appropriate to handle complex objective functions and isnatively adapted for online learning.</description><author>Emmanuel Gnabeyeu, Omar Karkar, Imad Idboufous</author><pubDate>Tue, 15 Oct 2024 17:10:54 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.11789v1</guid></item><item><title>Teuken-7B-Base &amp; Teuken-7B-Instruct: Towards European LLMs</title><link>http://arxiv.org/abs/2410.03730v2</link><description>We present two multilingual LLMs designed to embrace Europe's linguisticdiversity by supporting all 24 official languages of the European Union.Trained on a dataset comprising around 60% non-English data and utilizing acustom multilingual tokenizer, our models address the limitations of existingLLMs that predominantly focus on English or a few high-resource languages. Wedetail the models' development principles, i.e., data composition, tokenizeroptimization, and training methodologies. The models demonstrate competitiveperformance across multilingual benchmarks, as evidenced by their performanceon European versions of ARC, HellaSwag, MMLU, and TruthfulQA.</description><author>Mehdi Ali, Michael Fromm, Klaudia Thellmann, Jan Ebert, Alexander Arno Weber, Richard Rutmann, Charvi Jain, Max Lübbering, Daniel Steinigen, Johannes Leveling, Katrin Klug, Jasper Schulze Buschhoff, Lena Jurkschat, Hammam Abdelwahab, Benny Jörg Stein, Karl-Heinz Sylla, Pavel Denisov, Nicolo' Brandizzi, Qasid Saleem, Anirban Bhowmick, Lennard Helmer, Chelsea John, Pedro Ortiz Suarez, Malte Ostendorff, Alex Jude, Lalith Manjunath, Samuel Weinbach, Carolin Penke, Oleg Filatov, Shima Asaadi, Fabio Barth, Rafet Sifa, Fabian Küch, Andreas Herten, René Jäkel, Georg Rehm, Stefan Kesselheim, Joachim Köhler, Nicolas Flores-Herr</author><pubDate>Tue, 15 Oct 2024 17:09:40 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.03730v2</guid></item><item><title>ImageFolder: Autoregressive Image Generation with Folded Tokens</title><link>http://arxiv.org/abs/2410.01756v2</link><description>Image tokenizers are crucial for visual generative models, e.g., diffusionmodels (DMs) and autoregressive (AR) models, as they construct the latentrepresentation for modeling. Increasing token length is a common approach toimprove the image reconstruction quality. However, tokenizers with longer tokenlengths are not guaranteed to achieve better generation quality. There exists atrade-off between reconstruction and generation quality regarding token length.In this paper, we investigate the impact of token length on both imagereconstruction and generation and provide a flexible solution to the tradeoff.We propose ImageFolder, a semantic tokenizer that provides spatially alignedimage tokens that can be folded during autoregressive modeling to improve bothgeneration efficiency and quality. To enhance the representative capabilitywithout increasing token length, we leverage dual-branch product quantizationto capture different contexts of images. Specifically, semantic regularizationis introduced in one branch to encourage compacted semantic information whileanother branch is designed to capture the remaining pixel-level details.Extensive experiments demonstrate the superior quality of image generation andshorter token length with ImageFolder tokenizer.</description><author>Xiang Li, Kai Qiu, Hao Chen, Jason Kuen, Jiuxiang Gu, Bhiksha Raj, Zhe Lin</author><pubDate>Tue, 15 Oct 2024 17:07:45 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.01756v2</guid></item><item><title>Divide And Conquer: Learning Chaotic Dynamical Systems With Multistep Penalty Neural Ordinary Differential Equations</title><link>http://arxiv.org/abs/2407.00568v5</link><description>Forecasting high-dimensional dynamical systems is a fundamental challenge invarious fields, such as geosciences and engineering. Neural OrdinaryDifferential Equations (NODEs), which combine the power of neural networks andnumerical solvers, have emerged as a promising algorithm for forecastingcomplex nonlinear dynamical systems. However, classical techniques used forNODE training are ineffective for learning chaotic dynamical systems. In thiswork, we propose a novel NODE-training approach that allows for robust learningof chaotic dynamical systems. Our method addresses the challenges ofnon-convexity and exploding gradients associated with underlying chaoticdynamics. Training data trajectories from such systems are split into multiple,non-overlapping time windows. In addition to the deviation from the trainingdata, the optimization loss term further penalizes the discontinuities of thepredicted trajectory between the time windows. The window size is selectedbased on the fastest Lyapunov time scale of the system. Multi-step penalty(MP)method is first demonstrated on Lorenz equation, to illustrate how it improvesthe loss landscape and thereby accelerates the optimization convergence. MPmethod can optimize chaotic systems in a manner similar to least-squaresshadowing with significantly lower computational costs. Our proposed algorithm,denoted the Multistep Penalty NODE, is applied to chaotic systems such as theKuramoto-Sivashinsky equation, the two-dimensional Kolmogorov flow, and ERA5reanalysis data for the atmosphere. It is observed that MP-NODE provide viableperformance for such chaotic systems, not only for short-term trajectorypredictions but also for invariant statistics that are hallmarks of the chaoticnature of these dynamics.</description><author>Dibyajyoti Chakraborty, Seung Whan Chung, Troy Arcomano, Romit Maulik</author><pubDate>Tue, 15 Oct 2024 17:07:25 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.00568v5</guid></item><item><title>Selection-p: Self-Supervised Task-Agnostic Prompt Compression for Faithfulness and Transferability</title><link>http://arxiv.org/abs/2410.11786v1</link><description>Large Language Models (LLMs) have demonstrated impressive capabilities in awide range of natural language processing tasks when leveraging in-contextlearning. To mitigate the additional computational and financial costsassociated with in-context learning, several prompt compression methods havebeen proposed to compress the in-context learning prompts. Despite theirsuccess, these methods face challenges with transferability due tomodel-specific compression, or rely on external training data, such as GPT-4.In this paper, we investigate the ability of LLMs to develop a unifiedcompression method that discretizes uninformative tokens, utilizing aself-supervised pre-training technique. By introducing a small number ofparameters during the continual pre-training, the proposed Selection-p producesa probability for each input token, indicating whether to preserve or discardit. Experiments show Selection-p achieves state-of-the-art performance acrossnumerous classification tasks, achieving compression rates of up to 10 timeswhile experiencing only a marginal 0.8% decrease in performance. Moreover, itexhibits superior transferability to different models compared to prior work.Additionally, we further analyze how Selection-p helps maintain performance onin-context learning with long contexts.</description><author>Tsz Ting Chung, Leyang Cui, Lemao Liu, Xinting Huang, Shuming Shi, Dit-Yan Yeung</author><pubDate>Tue, 15 Oct 2024 17:05:25 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.11786v1</guid></item><item><title>Socialized Learning: A Survey of the Paradigm Shift for Edge Intelligence in Networked Systems</title><link>http://arxiv.org/abs/2404.13348v3</link><description>Amidst the robust impetus from artificial intelligence (AI) and big data,edge intelligence (EI) has emerged as a nascent computing paradigm,synthesizing AI with edge computing (EC) to become an exemplary solution forunleashing the full potential of AI services. Nonetheless, challenges incommunication costs, resource allocation, privacy, and security continue toconstrain its proficiency in supporting services with diverse requirements. Inresponse to these issues, this paper introduces socialized learning (SL) as apromising solution, further propelling the advancement of EI. SL is a learningparadigm predicated on social principles and behaviors, aimed at amplifying thecollaborative capacity and collective intelligence of agents within the EIsystem. SL not only enhances the system's adaptability but also optimizescommunication, and networking processes, essential for distributed intelligenceacross diverse devices and platforms. Therefore, a combination of SL and EI maygreatly facilitate the development of collaborative intelligence in the futurenetwork. This paper presents the findings of a literature review on theintegration of EI and SL, summarizing the latest achievements in existingresearch on EI and SL. Subsequently, we delve comprehensively into thelimitations of EI and how it could benefit from SL. Special emphasis is placedon the communication challenges and networking strategies and other aspectswithin these systems, underlining the role of optimized network solutions inimproving system efficiency. Based on these discussions, we elaborate in detailon three integrated components: socialized architecture, socialized training,and socialized inference, analyzing their strengths and weaknesses. Finally, weidentify some possible future applications of combining SL and EI, discuss openproblems and suggest some future research.</description><author>Xiaofei Wang, Yunfeng Zhao, Chao Qiu, Qinghua Hu, Victor C. M. Leung</author><pubDate>Tue, 15 Oct 2024 17:04:51 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.13348v3</guid></item><item><title>Prompt a Robot to Walk with Large Language Models</title><link>http://arxiv.org/abs/2309.09969v3</link><description>Large language models (LLMs) pre-trained on vast internet-scale data haveshowcased remarkable capabilities across diverse domains. Recently, there hasbeen escalating interest in deploying LLMs for robotics, aiming to harness thepower of foundation models in real-world settings. However, this approach facessignificant challenges, particularly in grounding these models in the physicalworld and in generating dynamic robot motions. To address these issues, weintroduce a novel paradigm in which we use few-shot prompts collected from thephysical environment, enabling the LLM to autoregressively generate low-levelcontrol commands for robots without task-specific fine-tuning. Experimentsacross various robots and environments validate that our method can effectivelyprompt a robot to walk. We thus illustrate how LLMs can proficiently functionas low-level feedback controllers for dynamic motion control even inhigh-dimensional robotic systems. The project website and source code can befound at: https://prompt2walk.github.io/ .</description><author>Yen-Jen Wang, Bike Zhang, Jianyu Chen, Koushil Sreenath</author><pubDate>Tue, 15 Oct 2024 17:04:20 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2309.09969v3</guid></item><item><title>How social reinforcement learning can lead to metastable polarisation and the voter model</title><link>http://arxiv.org/abs/2406.07993v2</link><description>Previous explanations for the persistence of polarization of opinions havetypically included modelling assumptions that predispose the possibility ofpolarization (i.e., assumptions allowing a pair of agents to drift apart intheir opinion such as repulsive interactions or bounded confidence). Anexception is a recent simulation study showing that polarization is persistentwhen agents form their opinions using social reinforcement learning. Our goal is to highlight the usefulness of reinforcement learning in thecontext of modeling opinion dynamics, but that caution is required whenselecting the tools used to study such a model. We show that the polarizationobserved in the model of the simulation study cannot persist indefinitely, andexhibits consensus asymptotically with probability one. By constructing a linkbetween the reinforcement learning model and the voter model, we argue that theobserved polarization is metastable. Finally, we show that a slightmodification in the learning process of the agents changes the model from beingnon-ergodic to being ergodic. Our results show that reinforcement learning may be a powerful method formodelling polarization in opinion dynamics, but that the tools (objects tostudy such as the stationary distribution, or time to absorption for example)appropriate for analysing such models crucially depend on their properties(such as ergodicity, or transience). These properties are determined by thedetails of the learning process and may be difficult to identify based solelyon simulations.</description><author>Benedikt V. Meylahn, Janusz M. Meylahn</author><pubDate>Tue, 15 Oct 2024 17:02:38 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.07993v2</guid></item><item><title>Latent BKI: Open-Dictionary Continuous Mapping in Visual-Language Latent Spaces with Quantifiable Uncertainty</title><link>http://arxiv.org/abs/2410.11783v1</link><description>This paper introduces a novel probabilistic mapping algorithm, Latent BKI,which enables open-vocabulary mapping with quantifiable uncertainty.Traditionally, semantic mapping algorithms focus on a fixed set of semanticcategories which limits their applicability for complex robotic tasks.Vision-Language (VL) models have recently emerged as a technique to jointlymodel language and visual features in a latent space, enabling semanticrecognition beyond a predefined, fixed set of semantic classes. Latent BKIrecurrently incorporates neural embeddings from VL models into a voxel map withquantifiable uncertainty, leveraging the spatial correlations of nearbyobservations through Bayesian Kernel Inference (BKI). Latent BKI is evaluatedagainst similar explicit semantic mapping and VL mapping frameworks on thepopular MatterPort-3D and Semantic KITTI data sets, demonstrating that LatentBKI maintains the probabilistic benefits of continuous mapping with theadditional benefit of open-dictionary queries. Real-world experimentsdemonstrate applicability to challenging indoor environments.</description><author>Joey Wilson, Ruihan Xu, Yile Sun, Parker Ewen, Minghan Zhu, Kira Barton, Maani Ghaffari</author><pubDate>Tue, 15 Oct 2024 17:02:32 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.11783v1</guid></item><item><title>G-Designer: Architecting Multi-agent Communication Topologies via Graph Neural Networks</title><link>http://arxiv.org/abs/2410.11782v1</link><description>Recent advancements in large language model (LLM)-based agents havedemonstrated that collective intelligence can significantly surpass thecapabilities of individual agents, primarily due to well-crafted inter-agentcommunication topologies. Despite the diverse and high-performing designsavailable, practitioners often face confusion when selecting the most effectivepipeline for their specific task: \textit{Which topology is the best choice formy task, avoiding unnecessary communication token overhead while ensuringhigh-quality solution?} In response to this dilemma, we introduce G-Designer,an adaptive, efficient, and robust solution for multi-agent deployment, whichdynamically designs task-aware, customized communication topologies.Specifically, G-Designer models the multi-agent system as a multi-agentnetwork, leveraging a variational graph auto-encoder to encode both the nodes(agents) and a task-specific virtual node, and decodes a task-adaptive andhigh-performing communication topology. Extensive experiments on six benchmarksshowcase that G-Designer is: \textbf{(1) high-performing}, achieving superiorresults on MMLU with accuracy at $84.50\%$ and on HumanEval with pass@1 at$89.90\%$; \textbf{(2) task-adaptive}, architecting communication protocolstailored to task difficulty, reducing token consumption by up to $95.33\%$ onHumanEval; and \textbf{(3) adversarially robust}, defending against agentadversarial attacks with merely $0.3\%$ accuracy drop.</description><author>Guibin Zhang, Yanwei Yue, Xiangguo Sun, Guancheng Wan, Miao Yu, Junfeng Fang, Kun Wang, Dawei Cheng</author><pubDate>Tue, 15 Oct 2024 17:01:21 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.11782v1</guid></item><item><title>Language Models Encode Numbers Using Digit Representations in Base 10</title><link>http://arxiv.org/abs/2410.11781v1</link><description>Large language models (LLMs) frequently make errors when handling even simplenumerical problems, such as comparing two small numbers. A natural hypothesisis that these errors stem from how LLMs represent numbers, and specifically,whether their representations of numbers capture their numeric values. Wetackle this question from the observation that LLM errors on numerical tasksare often distributed across \textit{the digits} of the answer rather thannormally around \textit{its numeric value}. Through a series of probingexperiments and causal interventions, we show that LLMs internally representnumbers with individual circular representations per-digit in base 10. Thisdigit-wise representation, as opposed to a value representation, sheds light onthe error patterns of models on tasks involving numerical reasoning and couldserve as a basis for future studies on analyzing numerical mechanisms in LLMs.</description><author>Amit Arnold Levy, Mor Geva</author><pubDate>Tue, 15 Oct 2024 17:00:15 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.11781v1</guid></item><item><title>MLLM can see? Dynamic Correction Decoding for Hallucination Mitigation</title><link>http://arxiv.org/abs/2410.11779v1</link><description>Multimodal Large Language Models (MLLMs) frequently exhibit hallucinationphenomena, but the underlying reasons remain poorly understood. In this paper,we present an empirical analysis and find that, although MLLMs incorrectlygenerate the objects in the final output, they are actually able to recognizevisual objects in the preceding layers. We speculate that this may be due tothe strong knowledge priors of the language model suppressing the visualinformation, leading to hallucinations. Motivated by this, we propose a noveldynamic correction decoding method for MLLMs (DeCo), which adaptively selectsthe appropriate preceding layers and proportionally integrates knowledge intothe final layer to adjust the output logits. Note that DeCo is model agnosticand can be seamlessly incorporated with various classic decoding strategies andapplied to different MLLMs. We evaluate DeCo on widely-used benchmarks,demonstrating that it can reduce hallucination rates by a large margin comparedto baselines, highlighting its potential to mitigate hallucinations. Code isavailable at https://github.com/zjunlp/DeCo.</description><author>Chenxi Wang, Xiang Chen, Ningyu Zhang, Bozhong Tian, Haoming Xu, Shumin Deng, Huajun Chen</author><pubDate>Tue, 15 Oct 2024 16:57:44 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.11779v1</guid></item><item><title>Self-Data Distillation for Recovering Quality in Pruned Large Language Models</title><link>http://arxiv.org/abs/2410.09982v2</link><description>Large language models have driven significant progress in natural languageprocessing, but their deployment requires substantial compute and memoryresources. As models scale, compression techniques become essential forbalancing model quality with computational efficiency. Structured pruning,which removes less critical components of the model, is a promising strategyfor reducing complexity. However, one-shot pruning often results in significantquality degradation, particularly in tasks requiring multi-step reasoning. Torecover lost quality, supervised fine-tuning (SFT) is commonly applied, but itcan lead to catastrophic forgetting by shifting the model's learned datadistribution. Therefore, addressing the degradation from both pruning and SFTis essential to preserve the original model's quality. In this work, we proposeself-data distilled fine-tuning to address these challenges. Our approachleverages the original, unpruned model to generate a distilled dataset thatpreserves semantic richness and mitigates catastrophic forgetting bymaintaining alignment with the base model's knowledge. Empirically, wedemonstrate that self-data distillation consistently outperforms standard SFT,improving average accuracy by up to 8% on the HuggingFace OpenLLM Leaderboardv1. Specifically, when pruning 6 decoder blocks on Llama3.1-8B Instruct (i.e.,32 to 26 layers, reducing the model size from 8.03B to 6.72B parameters), ourmethod retains 91.2% of the original model's accuracy compared to 81.7% withSFT, while reducing real-world FLOPs by 16.30%. Furthermore, our approachscales effectively across datasets, with the quality improving as the datasetsize increases.</description><author>Vithursan Thangarasa, Ganesh Venkatesh, Nish Sinnadurai, Sean Lie</author><pubDate>Tue, 15 Oct 2024 16:57:41 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.09982v2</guid></item><item><title>On the Training Convergence of Transformers for In-Context Classification</title><link>http://arxiv.org/abs/2410.11778v1</link><description>While transformers have demonstrated impressive capacities for in-contextlearning (ICL) in practice, theoretical understanding of the underlyingmechanism enabling transformers to perform ICL is still in its infant stage.This work aims to theoretically study the training dynamics of transformers forin-context classification tasks. We demonstrate that, for in-contextclassification of Gaussian mixtures under certain assumptions, a single-layertransformer trained via gradient descent converges to a globally optimal modelat a linear rate. We further quantify the impact of the training and testingprompt lengths on the ICL inference error of the trained transformer. We showthat when the lengths of training and testing prompts are sufficiently large,the prediction of the trained transformer approaches the Bayes-optimalclassifier. Experimental results corroborate the theoretical findings.</description><author>Wei Shen, Ruida Zhou, Jing Yang, Cong Shen</author><pubDate>Tue, 15 Oct 2024 16:57:14 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.11778v1</guid></item><item><title>Encoding architecture algebra</title><link>http://arxiv.org/abs/2410.11776v1</link><description>Despite the wide variety of input types in machine learning, this diversityis often not fully reflected in their representations or model architectures,leading to inefficiencies throughout a model's lifecycle. This paper introducesan algebraic approach to constructing input-encoding architectures thatproperly account for the data's structure, providing a step toward achievingmore typeful machine learning.</description><author>Stephane Bersier, Xinyi Chen-Lin</author><pubDate>Tue, 15 Oct 2024 16:56:34 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.11776v1</guid></item><item><title>Fractal Calibration for long-tailed object detection</title><link>http://arxiv.org/abs/2410.11774v1</link><description>Real-world datasets follow an imbalanced distribution, which posessignificant challenges in rare-category object detection. Recent studies tacklethis problem by developing re-weighting and re-sampling methods, that utilisethe class frequencies of the dataset. However, these techniques focus solely onthe frequency statistics and ignore the distribution of the classes in imagespace, missing important information. In contrast to them, we propose FRActalCALibration (FRACAL): a novel post-calibration method for long-tailed objectdetection. FRACAL devises a logit adjustment method that utilises the fractaldimension to estimate how uniformly classes are distributed in image space.During inference, it uses the fractal dimension to inversely downweight theprobabilities of uniformly spaced class predictions achieving balance in twoaxes: between frequent and rare categories, and between uniformly spaced andsparsely spaced classes. FRACAL is a post-processing method and it does notrequire any training, also it can be combined with many off-the-shelf modelssuch as one-stage sigmoid detectors and two-stage instance segmentation models.FRACAL boosts the rare class performance by up to 8.6% and surpasses allprevious methods on LVIS dataset, while showing good generalisation to otherdatasets such as COCO, V3Det and OpenImages. The code will be released.</description><author>Konstantinos Panagiotis Alexandridis, Ismail Elezi, Jiankang Deng, Anh Nguyen, Shan Luo</author><pubDate>Tue, 15 Oct 2024 16:55:10 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.11774v1</guid></item><item><title>U-MedSAM: Uncertainty-aware MedSAM for Medical Image Segmentation</title><link>http://arxiv.org/abs/2408.08881v2</link><description>Medical Image Foundation Models have proven to be powerful tools for maskprediction across various datasets. However, accurately assessing theuncertainty of their predictions remains a significant challenge. To addressthis, we propose a new model, U-MedSAM, which integrates the MedSAM model withan uncertainty-aware loss function and the Sharpness-Aware Minimization(SharpMin) optimizer. The uncertainty-aware loss function automaticallycombines region-based, distribution-based, and pixel-based loss designs toenhance segmentation accuracy and robustness. SharpMin improves generalizationby finding flat minima in the loss landscape, thereby reducing overfitting. Ourmethod was evaluated in the CVPR24 MedSAM on Laptop challenge, where U-MedSAMdemonstrated promising performance.</description><author>Xin Wang, Xiaoyu Liu, Peng Huang, Pu Huang, Shu Hu, Hongtu Zhu</author><pubDate>Tue, 15 Oct 2024 16:54:44 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.08881v2</guid></item><item><title>Time-Series Foundation Model for Value-at-Risk</title><link>http://arxiv.org/abs/2410.11773v1</link><description>This study is the first to explore the application of a time-seriesfoundation model for VaR estimation. Foundation models, pre-trained on vast andvaried datasets, can be used in a zero-shot setting with relatively minimaldata or further improved through finetuning. We compare the performance ofGoogle's model, called TimesFM, against conventional parametric andnon-parametric models, including GARCH, Generalized Autoregressive Score (GAS),and empirical quantile estimates, using daily returns from the S\&amp;P 100 indexand its constituents over 19 years. Our backtesting results indicate that, interms of the actual-over-expected ratio, the fine-tuned TimesFM modelconsistently outperforms traditional methods. Regarding the quantile score lossfunction, it achieves performance comparable to the best econometric approach,the GAS model. Overall, the foundation model is either the best or among thetop performers in forecasting VaR across the 0.01, 0.025, 0.05, and 0.1 VaRlevels. We also found that fine-tuning significantly improves the results, andthe model should not be used in zero-shot settings. Overall, foundation modelscan provide completely alternative approaches to traditional econometricmethods, yet there are challenges to be tackled.</description><author>Anubha Goel, Puneet Pasricha, Juho Kanniainen</author><pubDate>Tue, 15 Oct 2024 16:53:44 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.11773v1</guid></item><item><title>Layer-wise Importance Matters: Less Memory for Better Performance in Parameter-efficient Fine-tuning of Large Language Models</title><link>http://arxiv.org/abs/2410.11772v1</link><description>Parameter-Efficient Fine-Tuning (PEFT) methods have gained significantpopularity for adapting pre-trained Large Language Models (LLMs) to downstreamtasks, primarily due to their potential to significantly reduce memory andcomputational overheads. However, a common limitation in most PEFT approachesis their application of a uniform architectural design across all layers. Thisuniformity involves identical trainable modules and ignores the varyingimportance of each layer, leading to sub-optimal fine-tuning results. Toovercome the above limitation and obtain better performance, we develop a novelapproach, Importance-aware Sparse Tuning (IST), to fully utilize the inherentsparsity and select the most important subset of full layers with effectivelayer-wise importance scoring. The proposed IST is a versatile andplug-and-play technique compatible with various PEFT methods that operate on aper-layer basis. By leveraging the estimated importance scores, IST dynamicallyupdates these selected layers in PEFT modules, leading to reduced memorydemands. We further provide theoretical proof of convergence and empiricalevidence of superior performance to demonstrate the advantages of IST overuniform updating strategies. Extensive experiments on a range of LLMs, PEFTs,and downstream tasks substantiate the effectiveness of our proposed method,showcasing IST's capacity to enhance existing layer-based PEFT methods. Ourcode is available at https://github.com/Kaiseem/IST.</description><author>Kai Yao, Penlei Gao, Lichun Li, Yuan Zhao, Xiaofeng Wang, Wei Wang, Jianke Zhu</author><pubDate>Tue, 15 Oct 2024 16:53:26 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.11772v1</guid></item><item><title>l_inf-approximation of localized distributions</title><link>http://arxiv.org/abs/2410.11771v1</link><description>Distributions in spatial model often exhibit localized features. Intuitively,this locality implies a low intrinsic dimensionality, which can be exploitedfor efficient approximation and computation of complex distributions. However,existing approximation theory mainly considers the joint distributions, whichdoes not guarantee that the marginal errors are small. In this work, weestablish a dimension independent error bound for the marginals of approximatedistributions. This $\ell_\infty$-approximation error is obtained using Stein'smethod, and we propose a $\delta$-locality condition that quantifies the degreeof localization in a distribution. We also show how $\delta$-locality can bederived from different conditions that characterize the distribution'slocality. Our $\ell_\infty$ bound motivates the localization of existingapproximation methods to respect the locality. As examples, we show how to uselocalized likelihood-informed subspace method and localized score matching,which not only avoid dimension dependence in the approximation error, but alsosignificantly reduce the computational cost due to the local and parallelimplementation based on the localized structure.</description><author>Tiangang Cui, Shuigen Liu, Xin Tong</author><pubDate>Tue, 15 Oct 2024 16:47:05 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.11771v1</guid></item><item><title>Can Search-Based Testing with Pareto Optimization Effectively Cover Failure-Revealing Test Inputs?</title><link>http://arxiv.org/abs/2410.11769v1</link><description>Search-based software testing (SBST) is a widely adopted technique fortesting complex systems with large input spaces, such as Deep Learning-enabled(DL-enabled) systems. Many SBST techniques focus on Pareto-based optimization,where multiple objectives are optimized in parallel to reveal failures.However, it is important to ensure that identified failures are spreadthroughout the entire failure-inducing area of a search domain and notclustered in a sub-region. This ensures that identified failures aresemantically diverse and reveal a wide range of underlying causes. In thispaper, we present a theoretical argument explaining why testing based on Paretooptimization is inadequate for covering failure-inducing areas within a searchdomain. We support our argument with empirical results obtained by applying twowidely used types of Pareto-based optimization techniques, namely NSGA-II (anevolutionary algorithm) and MOPSO (a swarm-based algorithm), to two DL-enabledsystems: an industrial Automated Valet Parking (AVP) system and a system forclassifying handwritten digits. We measure the coverage of failure-revealingtest inputs in the input space using a metric that we refer to as the CoverageInverted Distance quality indicator. Our results show that NSGA-II and MOPSOare not more effective than a na\"ive random search baseline in covering testinputs that reveal failures. The replication package for this study isavailable in a GitHub repository.</description><author>Lev Sorokin, Damir Safin, Shiva Nejati</author><pubDate>Tue, 15 Oct 2024 16:44:40 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.11769v1</guid></item><item><title>Analyzing (In)Abilities of SAEs via Formal Languages</title><link>http://arxiv.org/abs/2410.11767v1</link><description>Autoencoders have been used for finding interpretable and disentangledfeatures underlying neural network representations in both image and textdomains. While the efficacy and pitfalls of such methods are well-studied invision, there is a lack of corresponding results, both qualitative andquantitative, for the text domain. We aim to address this gap by trainingsparse autoencoders (SAEs) on a synthetic testbed of formal languages.Specifically, we train SAEs on the hidden representations of models trained onformal languages (Dyck-2, Expr, and English PCFG) under a wide variety ofhyperparameter settings, finding interpretable latents often emerge in thefeatures learned by our SAEs. However, similar to vision, we find performanceturns out to be highly sensitive to inductive biases of the training pipeline.Moreover, we show latents correlating to certain features of the input do notalways induce a causal impact on model's computation. We thus argue thatcausality has to become a central target in SAE training: learning of causalfeatures should be incentivized from the ground-up. Motivated by this, wepropose and perform preliminary investigations for an approach that promoteslearning of causally relevant features in our formal language setting.</description><author>Abhinav Menon, Manish Shrivastava, David Krueger, Ekdeep Singh Lubana</author><pubDate>Tue, 15 Oct 2024 16:42:13 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.11767v1</guid></item><item><title>DPD-NeuralEngine: A 22-nm 6.6-TOPS/W/mm$^2$ Recurrent Neural Network Accelerator for Wideband Power Amplifier Digital Pre-Distortion</title><link>http://arxiv.org/abs/2410.11766v1</link><description>The increasing adoption of Deep Neural Network (DNN)-based DigitalPre-distortion (DPD) in modern communication systems necessitates efficienthardware implementations. This paper presents DPD-NeuralEngine, an ultra-fast,tiny-area, and power-efficient DPD accelerator based on a Gated Recurrent Unit(GRU) neural network (NN). Leveraging a co-designed software and hardwareapproach, our 22 nm CMOS implementation operates at 2 GHz, capable ofprocessing I/Q signals up to 250 MSps. Experimental results demonstrate athroughput of 256.5 GOPS and power efficiency of 1.32 TOPS/W with DPDlinearization performance measured in Adjacent Channel Power Ratio (ACPR) of-45.3 dBc and Error Vector Magnitude (EVM) of -39.8 dB. To our knowledge, thiswork represents the first AI-based DPD application-specific integrated circuit(ASIC) accelerator, achieving a power-area efficiency (PAE) of 6.6TOPS/W/mm$^2$.</description><author>Ang Li, Haolin Wu, Yizhuo Wu, Qinyu Chen, Leo C. N. de Vreede, Chang Gao</author><pubDate>Tue, 15 Oct 2024 16:39:50 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.11766v1</guid></item><item><title>ECGN: A Cluster-Aware Approach to Graph Neural Networks for Imbalanced Classification</title><link>http://arxiv.org/abs/2410.11765v1</link><description>Classifying nodes in a graph is a common problem. The ideal classifier mustadapt to any imbalances in the class distribution. It must also use informationin the clustering structure of real-world graphs. Existing Graph NeuralNetworks (GNNs) have not addressed both problems together. We propose theEnhanced Cluster-aware Graph Network (ECGN), a novel method that addressesthese issues by integrating cluster-specific training with synthetic nodegeneration. Unlike traditional GNNs that apply the same node update process forall nodes, ECGN learns different aggregations for different clusters. We alsouse the clusters to generate new minority-class nodes in a way that helpsclarify the inter-class decision boundary. By combining cluster-awareembeddings with a global integration step, ECGN enhances the quality of theresulting node embeddings. Our method works with any underlying GNN and anycluster generation technique. Experimental results show that ECGN consistentlyoutperforms its closest competitors by up to 11% on some widely studiedbenchmark datasets.</description><author>Bishal Thapaliya, Anh Nguyen, Yao Lu, Tian Xie, Igor Grudetskyi, Fudong Lin, Antonios Valkanas, Jingyu Liu, Deepayan Chakraborty, Bilel Fehri</author><pubDate>Tue, 15 Oct 2024 16:39:38 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.11765v1</guid></item><item><title>Improving semantic understanding in speech language models via brain-tuning</title><link>http://arxiv.org/abs/2410.09230v2</link><description>Speech language models align with human brain responses to natural languageto an impressive degree. However, current models rely heavily on low-levelspeech features, indicating they lack brain-relevant semantics which limitstheir utility as model organisms of semantic processing in the brain. In thiswork, we address this limitation by inducing brain-relevant bias directly intothe models via fine-tuning with fMRI recordings of people listening to naturalstories, a process we name brain-tuning. After testing it on 3 differentpretrained model families, we show that brain-tuning not only improves overallalignment with new brain recordings in semantic language regions, but alsoreduces the reliance on low-level speech features for this alignment.Excitingly, we further show that brain-tuning leads to 1) consistentimprovements in performance on a range of downstream tasks and 2) arepresentational space with increased semantic preference. Our results provideconverging evidence, for the first time, that incorporating brain signals intothe training of language models improves the models' semantic understanding.</description><author>Omer Moussa, Dietrich Klakow, Mariya Toneva</author><pubDate>Tue, 15 Oct 2024 16:39:10 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.09230v2</guid></item><item><title>TAMS: Translation-Assisted Morphological Segmentation</title><link>http://arxiv.org/abs/2403.14840v2</link><description>Canonical morphological segmentation is the process of analyzing words intothe standard (aka underlying) forms of their constituent morphemes. This is acore task in language documentation, and NLP systems have the potential todramatically speed up this process. But in typical language documentationsettings, training data for canonical morpheme segmentation is scarce, makingit difficult to train high quality models. However, translation data is oftenmuch more abundant, and, in this work, we present a method that attempts toleverage this data in the canonical segmentation task. We propose acharacter-level sequence-to-sequence model that incorporates representations oftranslations obtained from pretrained high-resource monolingual language modelsas an additional signal. Our model outperforms the baseline in a super-lowresource setting but yields mixed results on training splits with more data.While further work is needed to make translations useful in higher-resourcesettings, our model shows promise in severely resource-constrained settings.</description><author>Enora Rice, Ali Marashian, Luke Gessler, Alexis Palmer, Katharina von der Wense</author><pubDate>Tue, 15 Oct 2024 16:34:51 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.14840v2</guid></item><item><title>SlideChat: A Large Vision-Language Assistant for Whole-Slide Pathology Image Understanding</title><link>http://arxiv.org/abs/2410.11761v1</link><description>Despite the progress made by multimodal large language models (MLLMs) incomputational pathology, they remain limited by a predominant focus onpatch-level analysis, missing essential contextual information at thewhole-slide level. The lack of large-scale instruction datasets and thegigapixel scale of whole slide images (WSIs) pose significant developmentalchallenges. In this paper, we present SlideChat, the first vision-languageassistant capable of understanding gigapixel whole-slide images, exhibitingexcellent multimodal conversational capability and response complex instructionacross diverse pathology scenarios. To support its development, we createdSlideInstruction, the largest instruction-following dataset for WSIs consistingof 4.2K WSI captions and 176K VQA pairs with multiple categories. Furthermore,we propose SlideBench, a multimodal benchmark that incorporates captioning andVQA tasks to assess SlideChat's capabilities in varied clinical settings suchas microscopy, diagnosis. Compared to both general and specialized MLLMs,SlideChat exhibits exceptional capabilities achieving state-of-the-artperformance on 18 of 22 tasks. For example, it achieved an overall accuracy of81.17% on SlideBench-VQA (TCGA), and 54.15% on SlideBench-VQA (BCNB). We willfully release SlideChat, SlideInstruction and SlideBench as open-sourceresources to facilitate research and development in computational pathology.</description><author>Ying Chen, Guoan Wang, Yuanfeng Ji, Yanjun Li, Jin Ye, Tianbin Li, Bin Zhang, Nana Pei, Rongshan Yu, Yu Qiao, Junjun He</author><pubDate>Tue, 15 Oct 2024 16:33:33 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.11761v1</guid></item><item><title>Augmentation-aware Self-supervised Learning with Conditioned Projector</title><link>http://arxiv.org/abs/2306.06082v3</link><description>Self-supervised learning (SSL) is a powerful technique for learning fromunlabeled data. By learning to remain invariant to applied data augmentations,methods such as SimCLR and MoCo can reach quality on par with supervisedapproaches. However, this invariance may be detrimental for solving downstreamtasks that depend on traits affected by augmentations used during pretraining,such as color. In this paper, we propose to foster sensitivity to suchcharacteristics in the representation space by modifying the projector network,a common component of self-supervised architectures. Specifically, wesupplement the projector with information about augmentations applied toimages. For the projector to take advantage of this auxiliary conditioning whensolving the SSL task, the feature extractor learns to preserve the augmentationinformation in its representations. Our approach, coined ConditionalAugmentation-aware Self-supervised Learning (CASSLE), is directly applicable totypical joint-embedding SSL methods regardless of their objective functions.Moreover, it does not require major changes in the network architecture orprior knowledge of downstream tasks. In addition to an analysis of sensitivitytowards different data augmentations, we conduct a series of experiments, whichshow that CASSLE improves over various SSL methods, reaching state-of-the-artperformance in multiple downstream tasks.</description><author>Marcin Przewięźlikowski, Mateusz Pyla, Bartosz Zieliński, Bartłomiej Twardowski, Jacek Tabor, Marek Śmieja</author><pubDate>Tue, 15 Oct 2024 16:31:41 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.06082v3</guid></item><item><title>Transforming In-Vehicle Network Intrusion Detection: VAE-based Knowledge Distillation Meets Explainable AI</title><link>http://arxiv.org/abs/2410.09043v2</link><description>In the evolving landscape of autonomous vehicles, ensuring robust in-vehiclenetwork (IVN) security is paramount. This paper introduces an advancedintrusion detection system (IDS) called KD-XVAE that uses a VariationalAutoencoder (VAE)-based knowledge distillation approach to enhance bothperformance and efficiency. Our model significantly reduces complexity,operating with just 1669 parameters and achieving an inference time of 0.3 msper batch, making it highly suitable for resource-constrained automotiveenvironments. Evaluations in the HCRL Car-Hacking dataset demonstrateexceptional capabilities, attaining perfect scores (Recall, Precision, F1 Scoreof 100%, and FNR of 0%) under multiple attack types, including DoS, Fuzzing,Gear Spoofing, and RPM Spoofing. Comparative analysis on the CICIoV2024 datasetfurther underscores its superiority over traditional machine learning models,achieving perfect detection metrics. We furthermore integrate Explainable AI(XAI) techniques to ensure transparency in the model's decisions. The VAEcompresses the original feature space into a latent space, on which thedistilled model is trained. SHAP(SHapley Additive exPlanations) values provideinsights into the importance of each latent dimension, mapped back to originalfeatures for intuitive understanding. Our paper advances the field byintegrating state-of-the-art techniques, addressing critical challenges in thedeployment of efficient, trustworthy, and reliable IDSes for autonomousvehicles, ensuring enhanced protection against emerging cyber threats.</description><author>Muhammet Anil Yagiz, Pedram MohajerAnsari, Mert D. Pese, Polat Goktas</author><pubDate>Tue, 15 Oct 2024 16:29:55 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.09043v2</guid></item><item><title>LoSAM: Local Search in Additive Noise Models with Unmeasured Confounders, a Top-Down Global Discovery Approach</title><link>http://arxiv.org/abs/2410.11759v1</link><description>We address the challenge of causal discovery in structural equation modelswith additive noise without imposing additional assumptions on the underlyingdata-generating process. We introduce local search in additive noise model(LoSAM), which generalizes an existing nonlinear method that leverages localcausal substructures to the general additive noise setting, allowing for bothlinear and nonlinear causal mechanisms. We show that LoSAM achieves polynomialruntime, and improves runtime and efficiency by exploiting new substructures tominimize the conditioning set at each step. Further, we introduce a variant ofLoSAM, LoSAM-UC, that is robust to unmeasured confounding among roots, aproperty that is often not satisfied by functional-causal-model-based methods.We numerically demonstrate the utility of LoSAM, showing that it outperformsexisting benchmarks.</description><author>Sujai Hiremath, Kyra Gan, Promit Ghosal</author><pubDate>Tue, 15 Oct 2024 16:28:55 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.11759v1</guid></item><item><title>Latent Action Pretraining from Videos</title><link>http://arxiv.org/abs/2410.11758v1</link><description>We introduce Latent Action Pretraining for general Action models (LAPA), anunsupervised method for pretraining Vision-Language-Action (VLA) models withoutground-truth robot action labels. Existing Vision-Language-Action modelsrequire action labels typically collected by human teleoperators duringpretraining, which significantly limits possible data sources and scale. Inthis work, we propose a method to learn from internet-scale videos that do nothave robot action labels. We first train an action quantization modelleveraging VQ-VAE-based objective to learn discrete latent actions betweenimage frames, then pretrain a latent VLA model to predict these latent actionsfrom observations and task descriptions, and finally finetune the VLA onsmall-scale robot manipulation data to map from latent to robot actions.Experimental results demonstrate that our method significantly outperformsexisting techniques that train robot manipulation policies from large-scalevideos. Furthermore, it outperforms the state-of-the-art VLA model trained withrobotic action labels on real-world manipulation tasks that require languageconditioning, generalization to unseen objects, and semantic generalization tounseen instructions. Training only on human manipulation videos also showspositive transfer, opening up the potential for leveraging web-scale data forrobotics foundation model.</description><author>Seonghyeon Ye, Joel Jang, Byeongguk Jeon, Sejune Joo, Jianwei Yang, Baolin Peng, Ajay Mandlekar, Reuben Tan, Yu-Wei Chao, Bill Yuchen Lin, Lars Liden, Kimin Lee, Jianfeng Gao, Luke Zettlemoyer, Dieter Fox, Minjoon Seo</author><pubDate>Tue, 15 Oct 2024 16:28:09 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.11758v1</guid></item><item><title>Evidence of Cognitive Deficits andDevelopmental Advances in Generative AI: A Clock Drawing Test Analysis</title><link>http://arxiv.org/abs/2410.11756v1</link><description>Generative AI's rapid advancement sparks interest in its cognitive abilities,especially given its capacity for tasks like language understanding and codegeneration. This study explores how several recent GenAI models perform on theClock Drawing Test (CDT), a neuropsychological assessment of visuospatialplanning and organization. While models create clock-like drawings, theystruggle with accurate time representation, showing deficits similar tomild-severe cognitive impairment (Wechsler, 2009). Errors include numericalsequencing issues, incorrect clock times, and irrelevant additions, despiteaccurate rendering of clock features. Only GPT 4 Turbo and Gemini Pro 1.5produced the correct time, scoring like healthy individuals (4/4). A follow-upclock-reading test revealed only Sonnet 3.5 succeeded, suggesting drawingdeficits stem from difficulty with numerical concepts. These findings mayreflect weaknesses in visual-spatial understanding, working memory, orcalculation, highlighting strengths in learned knowledge but weaknesses inreasoning. Comparing human and machine performance is crucial for understandingAI's cognitive capabilities and guiding development toward human-like cognitivefunctions.</description><author>Isaac R. Galatzer-Levy, Jed McGiffin, David Munday, Xin Liu, Danny Karmon, Ilia Labzovsky, Rivka Moroshko, Amir Zait, Daniel McDuff</author><pubDate>Tue, 15 Oct 2024 16:27:22 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.11756v1</guid></item><item><title>The Fragility of Fairness: Causal Sensitivity Analysis for Fair Machine Learning</title><link>http://arxiv.org/abs/2410.09600v2</link><description>Fairness metrics are a core tool in the fair machine learning literature(FairML), used to determine that ML models are, in some sense, "fair".Real-world data, however, are typically plagued by various measurement biasesand other violated assumptions, which can render fairness assessmentsmeaningless. We adapt tools from causal sensitivity analysis to the FairMLcontext, providing a general framework which (1) accommodates effectively anycombination of fairness metric and bias that can be posed in the "oblivioussetting"; (2) allows researchers to investigate combinations of biases,resulting in non-linear sensitivity; and (3) enables flexible encoding ofdomain-specific constraints and assumptions. Employing this framework, weanalyze the sensitivity of the most common parity metrics under 3 varieties ofclassifier across 14 canonical fairness datasets. Our analysis reveals thestriking fragility of fairness assessments to even minor dataset biases. Weshow that causal sensitivity analysis provides a powerful and necessary toolkitfor gauging the informativeness of parity metric evaluations. Our repository isavailable here: https://github.com/Jakefawkes/fragile_fair.</description><author>Jake Fawkes, Nic Fishman, Mel Andrews, Zachary C. Lipton</author><pubDate>Tue, 15 Oct 2024 16:26:55 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.09600v2</guid></item><item><title>Toward Universal and Interpretable World Models for Open-ended Learning Agents</title><link>http://arxiv.org/abs/2409.18676v2</link><description>We introduce a generic, compositional and interpretable class of generativeworld models that supports open-ended learning agents. This is a sparse classof Bayesian networks capable of approximating a broad range of stochasticprocesses, which provide agents with the ability to learn world models in amanner that may be both interpretable and computationally scalable. Thisapproach integrating Bayesian structure learning and intrinsically motivated(model-based) planning enables agents to actively develop and refine theirworld models, which may lead to developmental learning and more robust,adaptive behavior.</description><author>Lancelot Da Costa</author><pubDate>Tue, 15 Oct 2024 16:23:51 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2409.18676v2</guid></item><item><title>Personas with Attitudes: Controlling LLMs for Diverse Data Annotation</title><link>http://arxiv.org/abs/2410.11745v1</link><description>We present a novel approach for enhancing diversity and control in dataannotation tasks by personalizing large language models (LLMs). We investigatethe impact of injecting diverse persona descriptions into LLM prompts acrosstwo studies, exploring whether personas increase annotation diversity andwhether the impacts of individual personas on the resulting annotations areconsistent and controllable. Our results show that persona-prompted LLMsproduce more diverse annotations than LLMs prompted without personas and thatthese effects are both controllable and repeatable, making our approach asuitable tool for improving data annotation in subjective NLP tasks liketoxicity detection.</description><author>Leon Fröhling, Gianluca Demartini, Dennis Assenmacher</author><pubDate>Tue, 15 Oct 2024 16:22:49 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.11745v1</guid></item><item><title>DySpec: Faster Speculative Decoding with Dynamic Token Tree Structure</title><link>http://arxiv.org/abs/2410.11744v1</link><description>While speculative decoding has recently appeared as a promising direction foraccelerating the inference of large language models (LLMs), the speedup andscalability are strongly bounded by the token acceptance rate. Prevalentmethods usually organize predicted tokens as independent chains or fixed tokentrees, which fails to generalize to diverse query distributions. In this paper,we propose DySpec, a faster speculative decoding algorithm with a novel dynamictoken tree structure. We begin by bridging the draft distribution andacceptance rate from intuitive and empirical clues, and successfully show thatthe two variables are strongly correlated. Based on this, we employ a greedystrategy to dynamically expand the token tree at run time. Theoretically, weshow that our method can achieve optimal results under mild assumptions.Empirically, DySpec yields a higher acceptance rate and speedup than fixedtrees. DySpec can drastically improve the throughput and reduce the latency oftoken generation across various data distribution and model sizes, whichsignificantly outperforms strong competitors, including Specinfer and Sequoia.Under low temperature setting, DySpec can improve the throughput up to9.1$\times$ and reduce the latency up to 9.4$\times$ on Llama2-70B. Under hightemperature setting, DySpec can also improve the throughput up to 6.21$\times$,despite the increasing difficulty of speculating more than one token per stepfor draft model.</description><author>Yunfan Xiong, Ruoyu Zhang, Yanzeng Li, Tianhao Wu, Lei Zou</author><pubDate>Tue, 15 Oct 2024 16:21:15 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.11744v1</guid></item><item><title>LLM-Based Robust Product Classification in Commerce and Compliance</title><link>http://arxiv.org/abs/2408.05874v2</link><description>Product classification is a crucial task in international trade, ascompliance regulations are verified and taxes and duties are applied based onproduct categories. Manual classification of products is time-consuming anderror-prone, and the sheer volume of products imported and exported renders themanual process infeasible. Consequently, e-commerce platforms and enterprisesinvolved in international trade have turned to automatic product classificationusing machine learning. However, current approaches do not consider thereal-world challenges associated with product classification, such as veryabbreviated and incomplete product descriptions. In addition, recentadvancements in generative Large Language Models (LLMs) and their reasoningcapabilities are mainly untapped in product classification and e-commerce. Inthis research, we explore the real-life challenges of industrial classificationand we propose data perturbations that allow for realistic data simulation.Furthermore, we employ LLM-based product classification to improve therobustness of the prediction in presence of incomplete data. Our research showsthat LLMs with in-context learning outperform the supervised approaches in theclean-data scenario. Additionally, we illustrate that LLMs are significantlymore robust than the supervised approaches when data attacks are present.</description><author>Sina Gholamian, Gianfranco Romani, Bartosz Rudnikowicz, Stavroula Skylaki</author><pubDate>Tue, 15 Oct 2024 16:18:10 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.05874v2</guid></item><item><title>POLO -- Point-based, multi-class animal detection</title><link>http://arxiv.org/abs/2410.11741v1</link><description>Automated wildlife surveys based on drone imagery and object detectiontechnology are a powerful and increasingly popular tool in conservationbiology. Most detectors require training images with annotated bounding boxes,which are tedious, expensive, and not always unambiguous to create. To reducethe annotation load associated with this practice, we develop POLO, amulti-class object detection model that can be trained entirely on pointlabels. POLO is based on simple, yet effective modifications to the YOLOv8architecture, including alterations to the prediction process, training losses,and post-processing. We test POLO on drone recordings of waterfowl containingup to multiple thousands of individual birds in one image and compare it to aregular YOLOv8. Our experiments show that at the same annotation cost, POLOachieves improved accuracy in counting animals in aerial imagery.</description><author>Giacomo May, Emanuele Dalsasso, Benjamin Kellenberger, Devis Tuia</author><pubDate>Tue, 15 Oct 2024 16:17:16 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.11741v1</guid></item><item><title>LongHalQA: Long-Context Hallucination Evaluation for MultiModal Large Language Models</title><link>http://arxiv.org/abs/2410.09962v2</link><description>Hallucination, a phenomenon where multimodal large language models~(MLLMs)tend to generate textual responses that are plausible but unaligned with theimage, has become one major hurdle in various MLLM-related applications.Several benchmarks have been created to gauge the hallucination levels ofMLLMs, by either raising discriminative questions about the existence ofobjects or introducing LLM evaluators to score the generated text from MLLMs.However, the discriminative data largely involve simple questions that are notaligned with real-world text, while the generative data involve LLM evaluatorsthat are computationally intensive and unstable due to their inherentrandomness. We propose LongHalQA, an LLM-free hallucination benchmark thatcomprises 6K long and complex hallucination text. LongHalQA is featured byGPT4V-generated hallucinatory data that are well aligned with real-worldscenarios, including object/image descriptions and multi-round conversationswith 14/130 words and 189 words, respectively, on average. It introduces twonew tasks, hallucination discrimination and hallucination completion, unifyingboth discriminative and generative evaluations in a singlemultiple-choice-question form and leading to more reliable and efficientevaluations without the need for LLM evaluators. Further, we propose anadvanced pipeline that greatly facilitates the construction of futurehallucination benchmarks with long and complex questions and descriptions.Extensive experiments over multiple recent MLLMs reveal various new challengeswhen they are handling hallucinations with long and complex textual data.Dataset and evaluation code are available athttps://github.com/hanqiu-hq/LongHalQA.</description><author>Han Qiu, Jiaxing Huang, Peng Gao, Qin Qi, Xiaoqin Zhang, Ling Shao, Shijian Lu</author><pubDate>Tue, 15 Oct 2024 16:10:26 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.09962v2</guid></item><item><title>NeuroSEM: A hybrid framework for simulating multiphysics problems by coupling PINNs and spectral elements</title><link>http://arxiv.org/abs/2407.21217v2</link><description>Multiphysics problems that are characterized by complex interactions amongfluid dynamics, heat transfer, structural mechanics, and electromagnetics, areinherently challenging due to their coupled nature. While experimental data oncertain state variables may be available, integrating these data with numericalsolvers remains a significant challenge. Physics-informed neural networks(PINNs) have shown promising results in various engineering disciplines,particularly in handling noisy data and solving inverse problems in partialdifferential equations (PDEs). However, their effectiveness in forecastingnonlinear phenomena in multiphysics regimes, particularly involving turbulence,is yet to be fully established. This study introduces NeuroSEM, a hybridframework integrating PINNs with the high-fidelity Spectral Element Method(SEM) solver, Nektar++. NeuroSEM leverages the strengths of both PINNs and SEM,providing robust solutions for multiphysics problems. PINNs are trained toassimilate data and model physical phenomena in specific subdomains, which arethen integrated into the Nektar++ solver. We demonstrate the efficiency andaccuracy of NeuroSEM for thermal convection in cavity flow and flow past acylinder. We applied NeuroSEM to the Rayleigh-B\'enard convection system,including cases with missing thermal boundary conditions and noisy datasets,and to real particle image velocimetry (PIV) data to capture flow patternscharacterized by horseshoe vortical structures. The framework's plug-and-playnature facilitates its extension to other multiphysics or multiscale problems.Furthermore, NeuroSEM is optimized for efficient execution on emergingintegrated GPU-CPU architectures. This hybrid approach enhances the accuracyand efficiency of simulations, making it a powerful tool for tackling complexengineering challenges in various scientific domains.</description><author>Khemraj Shukla, Zongren Zou, Chi Hin Chan, Additi Pandey, Zhicheng Wang, George Em Karniadakis</author><pubDate>Tue, 15 Oct 2024 16:08:30 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.21217v2</guid></item><item><title>THaMES: An End-to-End Tool for Hallucination Mitigation and Evaluation in Large Language Models</title><link>http://arxiv.org/abs/2409.11353v2</link><description>Hallucination, the generation of factually incorrect content, is a growingchallenge in Large Language Models (LLMs). Existing detection and mitigationmethods are often isolated and insufficient for domain-specific needs, lackinga standardized pipeline. This paper introduces THaMES (Tool for HallucinationMitigations and EvaluationS), an integrated framework and library addressingthis gap. THaMES offers an end-to-end solution for evaluating and mitigatinghallucinations in LLMs, featuring automated test set generation, multifacetedbenchmarking, and adaptable mitigation strategies. It automates test setcreation from any corpus, ensuring high data quality, diversity, andcost-efficiency through techniques like batch processing, weighted sampling,and counterfactual validation. THaMES assesses a model's ability to detect andreduce hallucinations across various tasks, including text generation andbinary classification, applying optimal mitigation strategies like In-ContextLearning (ICL), Retrieval Augmented Generation (RAG), and Parameter-EfficientFine-tuning (PEFT). Evaluations of state-of-the-art LLMs using a knowledge baseof academic papers, political news, and Wikipedia reveal that commercial modelslike GPT-4o benefit more from RAG than ICL, while open-weight models likeLlama-3.1-8B-Instruct and Mistral-Nemo gain more from ICL. Additionally, PEFTsignificantly enhances the performance of Llama-3.1-8B-Instruct in bothevaluation tasks.</description><author>Mengfei Liang, Archish Arun, Zekun Wu, Cristian Munoz, Jonathan Lutch, Emre Kazim, Adriano Koshiyama, Philip Treleaven</author><pubDate>Tue, 15 Oct 2024 16:05:27 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2409.11353v2</guid></item><item><title>LoRTA: Low Rank Tensor Adaptation of Large Language Models</title><link>http://arxiv.org/abs/2410.04060v2</link><description>Low Rank Adaptation (LoRA) is a popular Parameter Efficient Fine Tuning(PEFT) method that effectively adapts large pre-trained models for downstreamtasks. LoRA parameterizes model updates using low-rank matrices at each layer,significantly reducing the number of trainable parameters and, consequently,resource requirements during fine-tuning. However, the lower bound on thenumber of trainable parameters remains high due to the use of the low-rankmatrix model. In this paper, we address this limitation by proposing a novelapproach that employs a low rank tensor parametrization for model updates. Theproposed low rank tensor model can significantly reduce the number of trainableparameters, while also allowing for finer-grained control over adapter size.Our experiments on Natural Language Understanding, Instruction Tuning,Preference Optimization and Protein Folding benchmarks demonstrate that ourmethod is both efficient and effective for fine-tuning large language models,achieving a substantial reduction in the number of parameters while maintainingcomparable performance.</description><author>Ignacio Hounie, Charilaos Kanatsoulis, Arnuv Tandon, Alejandro Ribeiro</author><pubDate>Tue, 15 Oct 2024 16:03:20 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.04060v2</guid></item><item><title>Dash: Accelerating Distributed Private Convolutional Neural Network Inference with Arithmetic Garbled Circuits</title><link>http://arxiv.org/abs/2302.06361v2</link><description>The adoption of machine learning solutions is rapidly increasing across allparts of society. As the models grow larger, both training and inference ofmachine learning models is increasingly outsourced, e.g. to cloud serviceproviders. This means that potentially sensitive data is processed on untrustedplatforms, which bears inherent data security and privacy risks. In this work,we investigate how to protect distributed machine learning systems, focusing ondeep convolutional neural networks. The most common and best-performing mixedMPC approaches are based on HE, secret sharing, and garbled circuits. Theycommonly suffer from large performance overheads, big accuracy losses, andcommunication overheads that grow linearly in the depth of the neural network.To improve on these problems, we present Dash, a fast and distributed privateconvolutional neural network inference scheme secure against maliciousattackers. Building on arithmetic garbling gadgets [BMR16] and fancy-garbling[BCM+19], Dash is based purely on arithmetic garbled circuits. We introduceLabelTensors that allow us to leverage the massive parallelity of modern GPUs.Combined with state-of-the-art garbling optimizations, Dash outperformsprevious garbling approaches up to a factor of about 100. Furthermore, weintroduce an efficient scaling operation over the residues of the Chineseremainder theorem representation to arithmetic garbled circuits, which allowsus to garble larger networks and achieve much higher accuracy than previousapproaches. Finally, Dash requires only a single communication round perinference step, regardless of the depth of the neural network, and a very smallconstant online communication volume.</description><author>Jonas Sander, Sebastian Berndt, Ida Bruhns, Thomas Eisenbarth</author><pubDate>Tue, 15 Oct 2024 16:02:47 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2302.06361v2</guid></item><item><title>Patch-Based Diffusion Models Beat Whole-Image Models for Mismatched Distribution Inverse Problems</title><link>http://arxiv.org/abs/2410.11730v1</link><description>Diffusion models have achieved excellent success in solving inverse problemsdue to their ability to learn strong image priors, but existing approachesrequire a large training dataset of images that should come from the samedistribution as the test dataset. When the training and test distributions aremismatched, artifacts and hallucinations can occur in reconstructed images dueto the incorrect priors. In this work, we systematically study out ofdistribution (OOD) problems where a known training distribution is firstprovided. We first study the setting where only a single measurement obtainedfrom the unknown test distribution is available. Next we study the settingwhere a very small sample of data belonging to the test distribution isavailable, and our goal is still to reconstruct an image from a measurementthat came from the test distribution. In both settings, we use a patch-baseddiffusion prior that learns the image distribution solely from patches.Furthermore, in the first setting, we include a self-supervised loss that helpsthe network output maintain consistency with the measurement. Extensiveexperiments show that in both settings, the patch-based method can obtain highquality image reconstructions that can outperform whole-image models and cancompete with methods that have access to large in-distribution trainingdatasets. Furthermore, we show how whole-image models are prone to memorizationand overfitting, leading to artifacts in the reconstructions, while apatch-based model can resolve these issues.</description><author>Jason Hu, Bowen Song, Jeffrey A. Fessler, Liyue Shen</author><pubDate>Tue, 15 Oct 2024 16:02:08 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.11730v1</guid></item><item><title>MimicTalk: Mimicking a personalized and expressive 3D talking face in minutes</title><link>http://arxiv.org/abs/2410.06734v2</link><description>Talking face generation (TFG) aims to animate a target identity's face tocreate realistic talking videos. Personalized TFG is a variant that emphasizesthe perceptual identity similarity of the synthesized result (from theperspective of appearance and talking style). While previous works typicallysolve this problem by learning an individual neural radiance field (NeRF) foreach identity to implicitly store its static and dynamic information, we findit inefficient and non-generalized due to the per-identity-per-trainingframework and the limited training data. To this end, we propose MimicTalk, thefirst attempt that exploits the rich knowledge from a NeRF-basedperson-agnostic generic model for improving the efficiency and robustness ofpersonalized TFG. To be specific, (1) we first come up with a person-agnostic3D TFG model as the base model and propose to adapt it into a specificidentity; (2) we propose a static-dynamic-hybrid adaptation pipeline to helpthe model learn the personalized static appearance and facial dynamic features;(3) To generate the facial motion of the personalized talking style, we proposean in-context stylized audio-to-motion model that mimics the implicit talkingstyle provided in the reference video without information loss by an explicitstyle representation. The adaptation process to an unseen identity can beperformed in 15 minutes, which is 47 times faster than previousperson-dependent methods. Experiments show that our MimicTalk surpassesprevious baselines regarding video quality, efficiency, and expressiveness.Source code and video samples are available at https://mimictalk.github.io .</description><author>Zhenhui Ye, Tianyun Zhong, Yi Ren, Ziyue Jiang, Jiawei Huang, Rongjie Huang, Jinglin Liu, Jinzheng He, Chen Zhang, Zehan Wang, Xize Chen, Xiang Yin, Zhou Zhao</author><pubDate>Tue, 15 Oct 2024 16:01:57 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.06734v2</guid></item><item><title>GOVERN: Gradient Orientation Vote Ensemble for Multi-Teacher Reinforced Distillation</title><link>http://arxiv.org/abs/2405.03764v2</link><description>Pre-trained language models have become an integral component ofquestion-answering systems, achieving remarkable performance. However, forpractical deployment, it is crucial to perform knowledge distillation tomaintain high performance while operating under computational constraints. Inthis paper, we address a key question: given the importance of unsuperviseddistillation for student model performance, how can knowledge from multipleteacher models be effectively ensemble during this stage without the guidanceof labels? We propose a novel algorithm, GOVERN, to tackle this issue. GOVERNhas demonstrated significant improvements in both offline and onlineexperiments, enabling the student model to achieve results comparable to thatof teacher ensembles. Our experiments show that GOVERN remarkably requires amere 1\% of the ensemble method's inference budget to achieve 99.5\% ofperformance. The proposed algorithm has been successfully deployed in areal-world commercial question-answering system, demonstrating its real-worldapplicability.</description><author>Wenjie Zhou, Zhenxin Ding, Xiaodong Zhang, Haibo Shi, Junfeng Wang, Dawei Yin</author><pubDate>Tue, 15 Oct 2024 16:01:11 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.03764v2</guid></item><item><title>YOLO-ELA: Efficient Local Attention Modeling for High-Performance Real-Time Insulator Defect Detection</title><link>http://arxiv.org/abs/2410.11727v1</link><description>Existing detection methods for insulator defect identification from unmannedaerial vehicles (UAV) struggle with complex background scenes and smallobjects, leading to suboptimal accuracy and a high number of false positivesdetection. Using the concept of local attention modeling, this paper proposes anew attention-based foundation architecture, YOLO-ELA, to address this issue.The Efficient Local Attention (ELA) blocks were added into the neck part of theone-stage YOLOv8 architecture to shift the model's attention from backgroundfeatures towards features of insulators with defects. The SCYLLAIntersection-Over-Union (SIoU) criterion function was used to reduce detectionloss, accelerate model convergence, and increase the model's sensitivitytowards small insulator defects, yielding higher true positive outcomes. Due toa limited dataset, data augmentation techniques were utilized to increase thediversity of the dataset. In addition, we leveraged the transfer learningstrategy to improve the model's performance. Experimental results onhigh-resolution UAV images show that our method achieved a state-of-the-artperformance of 96.9% mAP0.5 and a real-time detection speed of 74.63 frames persecond, outperforming the baseline model. This further demonstrates theeffectiveness of attention-based convolutional neural networks (CNN) in objectdetection tasks.</description><author>Olalekan Akindele, Joshua Atolagbe</author><pubDate>Tue, 15 Oct 2024 16:00:01 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.11727v1</guid></item><item><title>Towards Supporting Legal Argumentation with NLP: Is More Data Really All You Need?</title><link>http://arxiv.org/abs/2406.10974v3</link><description>Modeling legal reasoning and argumentation justifying decisions in cases hasalways been central to AI &amp; Law, yet contemporary developments in legal NLPhave increasingly focused on statistically classifying legal conclusions fromtext. While conceptually simpler, these approaches often fall short inproviding usable justifications connecting to appropriate legal concepts. Thispaper reviews both traditional symbolic works in AI &amp; Law and recent advancesin legal NLP, and distills possibilities of integrating expert-informedknowledge to strike a balance between scalability and explanation in symbolicvs. data-driven approaches. We identify open challenges and discuss thepotential of modern NLP models and methods that integrate</description><author>T. Y. S. S Santosh, Kevin D. Ashley, Katie Atkinson, Matthias Grabmair</author><pubDate>Tue, 15 Oct 2024 15:59:34 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.10974v3</guid></item><item><title>Machine Learning for K-adaptability in Two-stage Robust Optimization</title><link>http://arxiv.org/abs/2210.11152v3</link><description>Two-stage robust optimization problems constitute one of the hardestoptimization problem classes. One of the solution approaches to this class ofproblems is K-adaptability. This approach simultaneously seeks the bestpartitioning of the uncertainty set of scenarios into K subsets, and optimizesdecisions corresponding to each of these subsets. In general case, it is solvedusing the K-adaptability branch-and-bound algorithm, which requires explorationof exponentially-growing solution trees. To accelerate finding high-qualitysolutions in such trees, we propose a machine learning-based node selectionstrategy. In particular, we construct a feature engineering scheme based ongeneral two-stage robust optimization insights that allows us to train ourmachine learning tool on a database of resolved B&amp;B trees, and to apply itas-is to problems of different sizes and/or types. We experimentally show thatusing our learned node selection strategy outperforms a vanilla, random nodeselection strategy when tested on problems of the same type as the trainingproblems, also in case the K-value or the problem size differs from thetraining ones.</description><author>Esther Julien, Krzysztof Postek, Ş. İlker Birbil</author><pubDate>Tue, 15 Oct 2024 15:59:22 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2210.11152v3</guid></item><item><title>Subgraph-Aware Training of Language Models for Knowledge Graph Completion Using Structure-Aware Contrastive Learning</title><link>http://arxiv.org/abs/2407.12703v4</link><description>Fine-tuning pre-trained language models (PLMs) has recently shown a potentialto improve knowledge graph completion (KGC). However, most PLM-based methodsfocus solely on encoding textual information, neglecting the long-tailed natureof knowledge graphs and their various topological structures, e.g., subgraphs,shortest paths, and degrees. We claim that this is a major obstacle toachieving higher accuracy of PLMs for KGC. To this end, we propose aSubgraph-Aware Training framework for KGC (SATKGC) with two ideas: (i)subgraph-aware mini-batching to encourage hard negative sampling and tomitigate an imbalance in the frequency of entity occurrences during training,and (ii) new contrastive learning to focus more on harder in-batch negativetriples and harder positive triples in terms of the structural properties ofthe knowledge graph. To the best of our knowledge, this is the first study tocomprehensively incorporate the structural inductive bias of the knowledgegraph into fine-tuning PLMs. Extensive experiments on three KGC benchmarksdemonstrate the superiority of SATKGC. Our code is available.</description><author>Youmin Ko, Hyemin Yang, Taeuk Kim, Hyunjoon Kim</author><pubDate>Tue, 15 Oct 2024 15:59:09 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.12703v4</guid></item><item><title>Mitigate Position Bias in Large Language Models via Scaling a Single Dimension</title><link>http://arxiv.org/abs/2406.02536v2</link><description>Large Language Models (LLMs) are increasingly applied in various real-worldscenarios due to their excellent generalization capabilities and robustgenerative abilities. However, they exhibit position bias, also known as "lostin the middle", a phenomenon that is especially pronounced in long-contextscenarios, which indicates the placement of the key information in differentpositions of a prompt can significantly affect accuracy. This paper firstexplores the micro-level manifestations of position bias, concluding thatattention weights are a micro-level expression of position bias. It furtheridentifies that, in addition to position embeddings, causal attention mask alsocontributes to position bias by creating position-specific hidden states. Basedon these insights, we propose a method to mitigate position bias by scalingthis positional hidden states. Experiments on the NaturalQuestionsMulti-document QA, KV retrieval, LongBench and timeline reorder tasks, usingvarious models including RoPE models, context windowextended models, and Alibimodels, demonstrate the effectiveness and generalizability of our approach. Ourmethod can improve performance by up to 15.2% by modifying just one dimensionof hidden states. Our code is available at https://aka.ms/PositionalHidden.</description><author>Yijiong Yu, Huiqiang Jiang, Xufang Luo, Qianhui Wu, Chin-Yew Lin, Dongsheng Li, Yuqing Yang, Yongfeng Huang, Lili Qiu</author><pubDate>Tue, 15 Oct 2024 15:58:07 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.02536v2</guid></item><item><title>Learning Truncated Causal History Model for Video Restoration</title><link>http://arxiv.org/abs/2410.03936v2</link><description>One key challenge to video restoration is to model the transition dynamics ofvideo frames governed by motion. In this work, we propose TURTLE to learn thetruncated causal history model for efficient and high-performing videorestoration. Unlike traditional methods that process a range of contextualframes in parallel, TURTLE enhances efficiency by storing and summarizing atruncated history of the input frame latent representation into an evolvinghistorical state. This is achieved through a sophisticated similarity-basedretrieval mechanism that implicitly accounts for inter-frame motion andalignment. The causal design in TURTLE enables recurrence in inference throughstate-memorized historical features while allowing parallel training bysampling truncated video clips. We report new state-of-the-art results on amultitude of video restoration benchmark tasks, including video desnowing,nighttime video deraining, video raindrops and rain streak removal, videosuper-resolution, real-world and synthetic video deblurring, and blind videodenoising while reducing the computational cost compared to existing bestcontextual methods on all these tasks.</description><author>Amirhosein Ghasemabadi, Muhammad Kamran Janjua, Mohammad Salameh, Di Niu</author><pubDate>Tue, 15 Oct 2024 15:57:10 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.03936v2</guid></item><item><title>Phantom: General Trigger Attacks on Retrieval Augmented Language Generation</title><link>http://arxiv.org/abs/2405.20485v2</link><description>Retrieval Augmented Generation (RAG) expands the capabilities of modern largelanguage models (LLMs), by anchoring, adapting, and personalizing theirresponses to the most relevant knowledge sources. It is particularly useful inchatbot applications, allowing developers to customize LLM output withoutexpensive retraining. Despite their significant utility in variousapplications, RAG systems present new security risks. In this work, we proposenew attack vectors that allow an adversary to inject a single maliciousdocument into a RAG system's knowledge base, and mount a backdoor poisoningattack. We design Phantom, a general two-stage optimization framework againstRAG systems, that crafts a malicious poisoned document leading to an integrityviolation in the model's output. First, the document is constructed to beretrieved only when a specific trigger sequence of tokens appears in thevictim's queries. Second, the document is further optimized with craftedadversarial text that induces various adversarial objectives on the LLM output,including refusal to answer, reputation damage, privacy violations, and harmfulbehaviors. We demonstrate our attacks on multiple LLM architectures, includingGemma, Vicuna, and Llama, and show that they transfer to GPT-3.5 Turbo andGPT-4. Finally, we successfully conducted a Phantom attack on NVIDIA'sblack-box production RAG system, "Chat with RTX".</description><author>Harsh Chaudhari, Giorgio Severi, John Abascal, Matthew Jagielski, Christopher A. Choquette-Choo, Milad Nasr, Cristina Nita-Rotaru, Alina Oprea</author><pubDate>Tue, 15 Oct 2024 15:56:58 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.20485v2</guid></item><item><title>MedSyn: Text-guided Anatomy-aware Synthesis of High-Fidelity 3D CT Images</title><link>http://arxiv.org/abs/2310.03559v6</link><description>This paper introduces an innovative methodology for producing high-quality 3Dlung CT images guided by textual information. While diffusion-based generativemodels are increasingly used in medical imaging, current state-of-the-artapproaches are limited to low-resolution outputs and underutilize radiologyreports' abundant information. The radiology reports can enhance the generationprocess by providing additional guidance and offering fine-grained control overthe synthesis of images. Nevertheless, expanding text-guided generation tohigh-resolution 3D images poses significant memory and anatomicaldetail-preserving challenges. Addressing the memory issue, we introduce ahierarchical scheme that uses a modified UNet architecture. We start bysynthesizing low-resolution images conditioned on the text, serving as afoundation for subsequent generators for complete volumetric data. To ensurethe anatomical plausibility of the generated samples, we provide furtherguidance by generating vascular, airway, and lobular segmentation masks inconjunction with the CT images. The model demonstrates the capability to usetextual input and segmentation tasks to generate synthesized images. Theresults of comparative assessments indicate that our approach exhibits superiorperformance compared to the most advanced models based on GAN and diffusiontechniques, especially in accurately retaining crucial anatomical features suchas fissure lines, airways, and vascular structures. This innovation introducesnovel possibilities. This study focuses on two main objectives: (1) thedevelopment of a method for creating images based on textual prompts andanatomical components, and (2) the capability to generate new imagesconditioning on anatomical elements. The advancements in image generation canbe applied to enhance numerous downstream tasks.</description><author>Yanwu Xu, Li Sun, Wei Peng, Shuyue Jia, Katelyn Morrison, Adam Perer, Afrooz Zandifar, Shyam Visweswaran, Motahhare Eslami, Kayhan Batmanghelich</author><pubDate>Tue, 15 Oct 2024 15:56:57 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.03559v6</guid></item><item><title>Generalizable Spacecraft Trajectory Generation via Multimodal Learning with Transformers</title><link>http://arxiv.org/abs/2410.11723v1</link><description>Effective trajectory generation is essential for reliable on-board spacecraftautonomy. Among other approaches, learning-based warm-starting represents anappealing paradigm for solving the trajectory generation problem, effectivelycombining the benefits of optimization- and data-driven methods. Currentapproaches for learning-based trajectory generation often focus on fixed,single-scenario environments, where key scene characteristics, such as obstaclepositions or final-time requirements, remain constant across problem instances.However, practical trajectory generation requires the scenario to be frequentlyreconfigured, making the single-scenario approach a potentially impracticalsolution. To address this challenge, we present a novel trajectory generationframework that generalizes across diverse problem configurations, by leveraginghigh-capacity transformer neural networks capable of learning from multimodaldata sources. Specifically, our approach integrates transformer-based neuralnetwork models into the trajectory optimization process, encoding bothscene-level information (e.g., obstacle locations, initial and goal states) andtrajectory-level constraints (e.g., time bounds, fuel consumption targets) viamultimodal representations. The transformer network then generates near-optimalinitial guesses for non-convex optimization problems, significantly enhancingconvergence speed and performance. The framework is validated through extensivesimulations and real-world experiments on a free-flyer platform, achieving upto 30% cost improvement and 80% reduction in infeasible cases with respect totraditional approaches, and demonstrating robust generalization across diversescenario variations.</description><author>Davide Celestini, Amirhossein Afsharrad, Daniele Gammelli, Tommaso Guffanti, Gioele Zardini, Sanjay Lall, Elisa Capello, Simone D'Amico, Marco Pavone</author><pubDate>Tue, 15 Oct 2024 15:55:42 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.11723v1</guid></item><item><title>RClicks: Realistic Click Simulation for Benchmarking Interactive Segmentation</title><link>http://arxiv.org/abs/2410.11722v1</link><description>The emergence of Segment Anything (SAM) sparked research interest in thefield of interactive segmentation, especially in the context of image editingtasks and speeding up data annotation. Unlike common semantic segmentation,interactive segmentation methods allow users to directly influence their outputthrough prompts (e.g. clicks). However, click patterns in real-worldinteractive segmentation scenarios remain largely unexplored. Most methods relyon the assumption that users would click in the center of the largest erroneousarea. Nevertheless, recent studies show that this is not always the case. Thus,methods may have poor performance in real-world deployment despite high metricsin a baseline benchmark. To accurately simulate real-user clicks, we conducteda large crowdsourcing study of click patterns in an interactive segmentationscenario and collected 475K real-user clicks. Drawing on ideas from saliencytasks, we develop a clickability model that enables sampling clicks, whichclosely resemble actual user inputs. Using our model and dataset, we proposeRClicks benchmark for a comprehensive comparison of existing interactivesegmentation methods on realistic clicks. Specifically, we evaluate not onlythe average quality of methods, but also the robustness w.r.t. click patterns.According to our benchmark, in real-world usage interactive segmentation modelsmay perform worse than it has been reported in the baseline benchmark, and mostof the methods are not robust. We believe that RClicks is a significant steptowards creating interactive segmentation methods that provide the best userexperience in real-world cases.</description><author>Anton Antonov, Andrey Moskalenko, Denis Shepelev, Alexander Krapukhin, Konstantin Soshin, Anton Konushin, Vlad Shakhuro</author><pubDate>Tue, 15 Oct 2024 15:55:00 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.11722v1</guid></item><item><title>Federated Continual Learning Goes Online: Uncertainty-Aware Memory Management for Vision Tasks and Beyond</title><link>http://arxiv.org/abs/2405.18925v3</link><description>Given the ability to model more realistic and dynamic problems, FederatedContinual Learning (FCL) has been increasingly investigated recently. Awell-known problem encountered in this setting is the so-called catastrophicforgetting, for which the learning model is inclined to focus on more recenttasks while forgetting the previously learned knowledge. The majority of thecurrent approaches in FCL propose generative-based solutions to solve saidproblem. However, this setting requires multiple training epochs over the data,implying an offline setting where datasets are stored locally and remainunchanged over time. Furthermore, the proposed solutions are tailored forvision tasks solely. To overcome these limitations, we propose a new approachto deal with different modalities in the online scenario where new data arrivein streams of mini-batches that can only be processed once. To solvecatastrophic forgetting, we propose an uncertainty-aware memory-based approach.Specifically, we suggest using an estimator based on the Bregman Information(BI) to compute the model's variance at the sample level. Through measures ofpredictive uncertainty, we retrieve samples with specific characteristics, and- by retraining the model on such samples - we demonstrate the potential ofthis approach to reduce the forgetting effect in realistic settings whilemaintaining data confidentiality and competitive communication efficiencycompared to state-of-the-art approaches.</description><author>Giuseppe Serra, Florian Buettner</author><pubDate>Tue, 15 Oct 2024 15:53:12 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.18925v3</guid></item><item><title>Data Interpreter: An LLM Agent For Data Science</title><link>http://arxiv.org/abs/2402.18679v4</link><description>Large Language Model (LLM)-based agents have shown effectiveness across manyapplications. However, their use in data science scenarios requiring solvinglong-term interconnected tasks, dynamic data adjustments and domain expertiseremains challenging. Previous approaches primarily focus on individual tasks,making it difficult to assess the complete data science workflow. Moreover,they struggle to handle real-time changes in intermediate data and fail toadapt dynamically to evolving task dependencies inherent to data scienceproblems. In this paper, we present Data Interpreter, an LLM-based agentdesigned to automatically solve various data science problems end-to-end. OurData Interpreter incorporates two key modules: 1) Hierarchical Graph Modeling,which breaks down complex problems into manageable subproblems, enablingdynamic node generation and graph optimization; and 2) Programmable NodeGeneration, a technique that refines and verifies each subproblem toiteratively improve code generation results and robustness. Extensiveexperiments consistently demonstrate the superiority of Data Interpreter. OnInfiAgent-DABench, it achieves a 25% performance boost, raising accuracy from75.9% to 94.9%. For machine learning and open-ended tasks, it improvesperformance from 88% to 95%, and from 60% to 97%, respectively. Moreover, onthe MATH dataset, Data Interpreter achieves remarkable performance with a 26%improvement compared to state-of-the-art baselines. The code is available athttps://github.com/geekan/MetaGPT.</description><author>Sirui Hong, Yizhang Lin, Bang Liu, Bangbang Liu, Binhao Wu, Ceyao Zhang, Chenxing Wei, Danyang Li, Jiaqi Chen, Jiayi Zhang, Jinlin Wang, Li Zhang, Lingyao Zhang, Min Yang, Mingchen Zhuge, Taicheng Guo, Tuo Zhou, Wei Tao, Xiangru Tang, Xiangtao Lu, Xiawu Zheng, Xinbing Liang, Yaying Fei, Yuheng Cheng, Zhibin Gou, Zongze Xu, Chenglin Wu</author><pubDate>Tue, 15 Oct 2024 15:52:57 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.18679v4</guid></item><item><title>Light-Weight Fault Tolerant Attention for Large Language Model Training</title><link>http://arxiv.org/abs/2410.11720v1</link><description>Large Language Models (LLMs) have demonstrated remarkable performance invarious natural language processing tasks. However, the training of thesemodels is computationally intensive and susceptible to faults, particularly inthe attention mechanism, which is a critical component of transformer-basedLLMs. In this paper, we investigate the impact of faults on LLM training,focusing on INF, NaN, and near-INF values in the computation results withsystematic fault injection experiments. We observe the propagation patterns ofthese errors, which can trigger non-trainable states in the model and disrupttraining, forcing the procedure to load from checkpoints.To mitigate the impactof these faults, we propose ATTNChecker, the first Algorithm-Based FaultTolerance (ABFT) technique tailored for the attention mechanism in LLMs.ATTNChecker is designed based on fault propagation patterns of LLM andincorporates performance optimization to adapt to both system reliability andmodel vulnerability while providing lightweight protection for fast LLMtraining. Evaluations on four LLMs show that ATTNChecker on average incurs onaverage 7% overhead on training while detecting and correcting all extremeerrors. Compared with the state-of-the-art checkpoint/restore approach,ATTNChecker reduces recovery overhead by up to 49x.</description><author>Yuhang Liang, Xinyi Li, Jie Ren, Ang Li, Bo Fang, Jieyang Chen</author><pubDate>Tue, 15 Oct 2024 15:52:45 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.11720v1</guid></item><item><title>LeOCLR: Leveraging Original Images for Contrastive Learning of Visual Representations</title><link>http://arxiv.org/abs/2403.06813v3</link><description>Contrastive instance discrimination methods outperform supervised learning indownstream tasks such as image classification and object detection. However,these methods rely heavily on data augmentation during representation learning,which can lead to suboptimal results if not implemented carefully. A commonaugmentation technique in contrastive learning is random cropping followed byresizing. This can degrade the quality of representation learning when the tworandom crops contain distinct semantic content. To tackle this issue, weintroduce LeOCLR (Leveraging Original Images for Contrastive Learning of VisualRepresentations), a framework that employs a novel instance discriminationapproach and an adapted loss function. This method prevents the loss ofimportant semantic features caused by mapping different object parts duringrepresentation learning. Our experiments demonstrate that LeOCLR consistentlyimproves representation learning across various datasets, outperformingbaseline models. For instance, LeOCLR surpasses MoCo-v2 by 5.1% on ImageNet-1Kin linear evaluation and outperforms several other methods on transfer learningand object detection tasks.</description><author>Mohammad Alkhalefi, Georgios Leontidis, Mingjun Zhong</author><pubDate>Tue, 15 Oct 2024 15:52:15 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.06813v3</guid></item><item><title>Converging to a Lingua Franca: Evolution of Linguistic Regions and Semantics Alignment in Multilingual Large Language Models</title><link>http://arxiv.org/abs/2410.11718v1</link><description>Large language models (LLMs) have demonstrated remarkable performance,particularly in multilingual contexts. While recent studies suggest that LLMscan transfer skills learned in one language to others, the internal mechanismsbehind this ability remain unclear. We observed that the neuron activationpatterns of LLMs exhibit similarities when processing the same language,revealing the existence and location of key linguistic regions. Additionally,we found that neuron activation patterns are similar when processing sentenceswith the same semantic meaning in different languages. This indicates that LLMsmap semantically identical inputs from different languages into a "LinguaFranca", a common semantic latent space that allows for consistent processingacross languages. This semantic alignment becomes more pronounced with trainingand increased model size, resulting in a more language-agnostic activationpattern. Moreover, we found that key linguistic neurons are concentrated in thefirst and last layers of LLMs, becoming denser in the first layers as trainingprogresses. Experiments on BLOOM and LLaMA2 support these findings,highlighting the structural evolution of multilingual LLMs during training andscaling up. This paper provides insights into the internal workings of LLMs,offering a foundation for future improvements in their cross-lingualcapabilities.</description><author>Hongchuan Zeng, Senyu Han, Lu Chen, Kai Yu</author><pubDate>Tue, 15 Oct 2024 15:49:15 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.11718v1</guid></item><item><title>Enhancing Agent Learning through World Dynamics Modeling</title><link>http://arxiv.org/abs/2407.17695v2</link><description>Large language models (LLMs) have been increasingly applied to tasks inlanguage understanding and interactive decision-making, with their impressiveperformance largely attributed to the extensive domain knowledge embeddedwithin them. However, the depth and breadth of this knowledge can vary acrossdomains. Many existing approaches assume that LLMs possess a comprehensiveunderstanding of their environment, often overlooking potential gaps in theirgrasp of actual world dynamics. To address this, we introduce Discover, Verify,and Evolve (DiVE), a framework that discovers world dynamics from a smallnumber of demonstrations, verifies the accuracy of these dynamics, and evolvesnew, advanced dynamics tailored to the current situation. Through extensiveevaluations, we assess the impact of each component on performance and comparethe dynamics generated by DiVE to human-annotated dynamics. Our results showthat LLMs guided by DiVE make more informed decisions, achieving rewardscomparable to human players in the Crafter environment and surpassing methodsthat require prior task-specific training in the MiniHack environment.</description><author>Zhiyuan Sun, Haochen Shi, Marc-Alexandre Côté, Glen Berseth, Xingdi Yuan, Bang Liu</author><pubDate>Tue, 15 Oct 2024 15:48:04 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.17695v2</guid></item><item><title>Zero-shot Model-based Reinforcement Learning using Large Language Models</title><link>http://arxiv.org/abs/2410.11711v1</link><description>The emerging zero-shot capabilities of Large Language Models (LLMs) have ledto their applications in areas extending well beyond natural languageprocessing tasks. In reinforcement learning, while LLMs have been extensivelyused in text-based environments, their integration with continuous state spacesremains understudied. In this paper, we investigate how pre-trained LLMs can beleveraged to predict in context the dynamics of continuous Markov decisionprocesses. We identify handling multivariate data and incorporating the controlsignal as key challenges that limit the potential of LLMs' deployment in thissetup and propose Disentangled In-Context Learning (DICL) to address them. Wepresent proof-of-concept applications in two reinforcement learning settings:model-based policy evaluation and data-augmented off-policy reinforcementlearning, supported by theoretical analysis of the proposed methods. Ourexperiments further demonstrate that our approach produces well-calibrateduncertainty estimates. We release the code athttps://github.com/abenechehab/dicl.</description><author>Abdelhakim Benechehab, Youssef Attia El Hili, Ambroise Odonnat, Oussama Zekri, Albert Thomas, Giuseppe Paolo, Maurizio Filippone, Ievgen Redko, Balázs Kégl</author><pubDate>Tue, 15 Oct 2024 15:46:53 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.11711v1</guid></item></channel></rss>