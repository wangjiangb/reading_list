<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/"><channel><title>Arxivfresh papers</title><link></link><description>Arxiv paper</description><language>en-US</language><lastBuildDate>Tue, 13 Aug 2024 13:01:00 GMT</lastBuildDate><generator>rfeed v1.0.0</generator><docs>https://github.com/svpino/rfeed/blob/master/README.md</docs><item><title>On the Impact of Calibration Data in Post-training Quantization and Pruning</title><link>http://arxiv.org/abs/2311.09755v2</link><description>Quantization and pruning form the foundation of compression for neuralnetworks, enabling efficient inference for large language models (LLMs).Recently, various quantization and pruning techniques have demonstratedremarkable performance in a post-training setting. They rely upon calibrationdata, a small set of unlabeled examples that are used to generate layeractivations. However, no prior work has systematically investigated how thecalibration data impacts the effectiveness of model compression methods. Inthis paper, we present the first extensive empirical study on the effect ofcalibration data upon LLM performance. We trial a variety of quantization andpruning methods, datasets, tasks, and models. Surprisingly, we find substantialvariations in downstream task performance, contrasting existing work thatsuggests a greater level of robustness to the calibration data. Finally, wemake a series of recommendations for the effective use of calibration data inLLM quantization and pruning.</description><author>Miles Williams, Nikolaos Aletras</author><pubDate>Mon, 12 Aug 2024 17:57:00 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.09755v2</guid></item><item><title>Formal-LLM: Integrating Formal Language and Natural Language for Controllable LLM-based Agents</title><link>http://arxiv.org/abs/2402.00798v4</link><description>Recent advancements on Large Language Models (LLMs) enable AI Agents toautomatically generate and execute multi-step plans to solve complex tasks.However, since LLM's content generation process is hardly controllable, currentLLM-based agents frequently generate invalid or non-executable plans, whichjeopardizes the performance of the generated plans and corrupts users' trust inLLM-based agents. In response, this paper proposes a novel "Formal-LLM"framework for LLM-based agents by integrating the expressiveness of naturallanguage and the precision of formal language. Specifically, the frameworkallows agent developers to express their requirements or constraints for theplanning process as an automaton. A stack-based LLM plan generation process isthen conducted under the supervision of the automaton to ensure that thegenerated plan satisfies the constraints, making the planning processcontrollable. We conduct experiments on both benchmark tasks and practicalreal-life tasks, and our framework achieves over 50% overall performanceincrease, which validates the feasibility and effectiveness of employingFormal-LLM to guide the plan generation of agents, preventing the agents fromgenerating invalid and unsuccessful plans. Further, more controllable LLM-basedagents can facilitate the broader utilization of LLM in application scenarioswhere high validity of planning is essential. The source code of this work isavailable at https://github.com/agiresearch/Formal-LLM.</description><author>Zelong Li, Wenyue Hua, Hao Wang, He Zhu, Yongfeng Zhang</author><pubDate>Mon, 12 Aug 2024 17:54:32 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.00798v4</guid></item><item><title>Benchmarking Cognitive Biases in Large Language Models as Evaluators</title><link>http://arxiv.org/abs/2309.17012v2</link><description>Large Language Models (LLMs) have recently been shown to be effective asautomatic evaluators with simple prompting and in-context learning. In thiswork, we assemble 15 LLMs of four different size ranges and evaluate theiroutput responses by preference ranking from the other LLMs as evaluators, suchas System Star is better than System Square. We then evaluate the quality ofranking outputs introducing the Cognitive Bias Benchmark for LLMs as Evaluators(CoBBLEr), a benchmark to measure six different cognitive biases in LLMevaluation outputs, such as the Egocentric bias where a model prefers to rankits own outputs highly in evaluation. We find that LLMs are biased text qualityevaluators, exhibiting strong indications on our bias benchmark (average of 40%of comparisons across all models) within each of their evaluations thatquestion their robustness as evaluators. Furthermore, we examine thecorrelation between human and machine preferences and calculate the averageRank-Biased Overlap (RBO) score to be 49.6%, indicating that machinepreferences are misaligned with humans. According to our findings, LLMs maystill be unable to be utilized for automatic annotation aligned with humanpreferences. Our project page is at: https://minnesotanlp.github.io/cobbler.</description><author>Ryan Koo, Minhwa Lee, Vipul Raheja, Jong Inn Park, Zae Myung Kim, Dongyeop Kang</author><pubDate>Mon, 12 Aug 2024 17:53:13 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2309.17012v2</guid></item><item><title>Moo-ving Beyond Tradition: Revolutionizing Cattle Behavioural Phenotyping with Pose Estimation Techniques</title><link>http://arxiv.org/abs/2408.06336v1</link><description>The cattle industry has been a major contributor to the economy of manycountries, including the US and Canada. The integration of ArtificialIntelligence (AI) has revolutionized this sector, mirroring its transformativeimpact across all industries by enabling scalable and automated monitoring andintervention practices. AI has also introduced tools and methods that automatemany tasks previously performed by human labor with the help of computervision, including health inspections. Among these methods, pose estimation hasa special place; pose estimation is the process of finding the position ofjoints in an image of animals. Analyzing the pose of animal subjects enablesprecise identification and tracking of the animal's movement and the movementsof its body parts. By summarizing the video and imagery data into movement andjoint location using pose estimation and then analyzing this information, wecan address the scalability challenge in cattle management, focusing on healthmonitoring, behavioural phenotyping and welfare concerns. Our study reviewsrecent advancements in pose estimation methodologies, their applicability inimproving the cattle industry, existing challenges, and gaps in this field.Furthermore, we propose an initiative to enhance open science frameworks withinthis field of study by launching a platform designed to connect industry andacademia.</description><author>Navid Ghassemi, Ali Goldani, Ian Q. Whishaw, Majid H. Mohajerani</author><pubDate>Mon, 12 Aug 2024 17:52:29 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.06336v1</guid></item><item><title>LOLgorithm: Integrating Semantic,Syntactic and Contextual Elements for Humor Classification</title><link>http://arxiv.org/abs/2408.06335v1</link><description>This paper explores humor detection through a linguistic lens, prioritizingsyntactic, semantic, and contextual features over computational methods inNatural Language Processing. We categorize features into syntactic, semantic,and contextual dimensions, including lexicons, structural statistics, Word2Vec,WordNet, and phonetic style. Our proposed model, Colbert, utilizes BERTembeddings and parallel hidden layers to capture sentence congruity. Bycombining syntactic, semantic, and contextual features, we train Colbert forhumor detection. Feature engineering examines essential syntactic and semanticfeatures alongside BERT embeddings. SHAP interpretations and decision treesidentify influential features, revealing that a holistic approach improveshumor detection accuracy on unseen data. Integrating linguistic cues fromdifferent dimensions enhances the model's ability to understand humorcomplexity beyond traditional computational methods.</description><author>Tanisha Khurana, Kaushik Pillalamarri, Vikram Pande, Munindar Singh</author><pubDate>Mon, 12 Aug 2024 17:52:11 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.06335v1</guid></item><item><title>FastFiD: Improve Inference Efficiency of Open Domain Question Answering via Sentence Selection</title><link>http://arxiv.org/abs/2408.06333v1</link><description>Open Domain Question Answering (ODQA) has been advancing rapidly in recenttimes, driven by significant developments in dense passage retrieval andpretrained language models. Current models typically incorporate the FiDframework, which is composed by a neural retriever alongside an encoder-decoderneural reader. In the answer generation process, the retriever will retrievenumerous passages (around 100 for instance), each of which is then individuallyencoded by the encoder. Subsequently, the decoder makes predictions based onthese encoded passages. Nevertheless, this framework can be relativelytime-consuming, particularly due to the extensive length of the gatheredpassages. To address this, we introduce FastFiD in this paper, a novel approachthat executes sentence selection on the encoded passages. This aids inretaining valuable sentences while reducing the context length required forgenerating answers. Experiments on three commonly used datasets (NaturalQuestions, TriviaQA and ASQA) demonstrate that our method can enhance theinference speed by 2.3X-5.7X, while simultaneously maintaining the model'sperformance. Moreover, an in-depth analysis of the model's attention revealsthat the selected sentences indeed hold a substantial contribution towards thefinal answer. The codes are publicly available athttps://github.com/thunlp/FastFiD.</description><author>Yufei Huang, Xu Han, Maosong Sun</author><pubDate>Mon, 12 Aug 2024 17:50:02 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.06333v1</guid></item><item><title>Animate, or Inanimate, That is the Question for Large Language Models</title><link>http://arxiv.org/abs/2408.06332v1</link><description>The cognitive essence of humans is deeply intertwined with the concept ofanimacy, which plays an essential role in shaping their memory, vision, andmulti-layered language understanding. Although animacy appears in language vianuanced constraints on verbs and adjectives, it is also learned and refinedthrough extralinguistic information. Similarly, we assume that the LLMs'limited abilities to understand natural language when processing animacy aremotivated by the fact that these models are trained exclusively on text. Hence, the question this paper aims to answer arises: can LLMs, in theirdigital wisdom, process animacy in a similar way to what humans would do? Wethen propose a systematic analysis via prompting approaches. In particular, weprobe different LLMs by prompting them using animate, inanimate, usual, andstranger contexts. Results reveal that, although LLMs have been trainedpredominantly on textual data, they exhibit human-like behavior when faced withtypical animate and inanimate entities in alignment with earlier studies.Hence, LLMs can adapt to understand unconventional situations by recognizingoddities as animated without needing to interface with unspoken cognitivetriggers humans rely on to break down animations.</description><author>Leonardo Ranaldi, Giulia Pucci, Fabio Massimo Zanzotto</author><pubDate>Mon, 12 Aug 2024 17:48:55 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.06332v1</guid></item><item><title>HeLiMOS: A Dataset for Moving Object Segmentation in 3D Point Clouds From Heterogeneous LiDAR Sensors</title><link>http://arxiv.org/abs/2408.06328v1</link><description>Moving object segmentation (MOS) using a 3D light detection and ranging(LiDAR) sensor is crucial for scene understanding and identification of movingobjects. Despite the availability of various types of 3D LiDAR sensors in themarket, MOS research still predominantly focuses on 3D point clouds frommechanically spinning omnidirectional LiDAR sensors. Thus, we are, for example,lacking a dataset with MOS labels for point clouds from solid-state LiDARsensors which have irregular scanning patterns. In this paper, we present alabeled dataset, called \textit{HeLiMOS}, that enables to test MOS approacheson four heterogeneous LiDAR sensors, including two solid-state LiDAR sensors.Furthermore, we introduce a novel automatic labeling method to substantiallyreduce the labeling effort required from human annotators. To this end, ourframework exploits an instance-aware static map building approach andtracking-based false label filtering. Finally, we provide experimental resultsregarding the performance of commonly used state-of-the-art MOS approaches onHeLiMOS that suggest a new direction for a sensor-agnostic MOS, which generallyworks regardless of the type of LiDAR sensors used to capture 3D point clouds.Our dataset is available at https://sites.google.com/view/helimos.</description><author>Hyungtae Lim, Seoyeon Jang, Benedikt Mersch, Jens Behley, Hyun Myung, Cyrill Stachniss</author><pubDate>Mon, 12 Aug 2024 17:44:33 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.06328v1</guid></item><item><title>VisualAgentBench: Towards Large Multimodal Models as Visual Foundation Agents</title><link>http://arxiv.org/abs/2408.06327v1</link><description>Large Multimodal Models (LMMs) have ushered in a new era in artificialintelligence, merging capabilities in both language and vision to form highlycapable Visual Foundation Agents. These agents are postulated to excel across amyriad of tasks, potentially approaching general artificial intelligence.However, existing benchmarks fail to sufficiently challenge or showcase thefull potential of LMMs in complex, real-world environments. To address thisgap, we introduce VisualAgentBench (VAB), a comprehensive and pioneeringbenchmark specifically designed to train and evaluate LMMs as visual foundationagents across diverse scenarios, including Embodied, Graphical User Interface,and Visual Design, with tasks formulated to probe the depth of LMMs'understanding and interaction capabilities. Through rigorous testing acrossnine proprietary LMM APIs and eight open models, we demonstrate theconsiderable yet still developing agent capabilities of these models.Additionally, VAB constructs a trajectory training set constructed throughhybrid methods including Program-based Solvers, LMM Agent Bootstrapping, andHuman Demonstrations, promoting substantial performance improvements in LMMsthrough behavior cloning. Our work not only aims to benchmark existing modelsbut also provides a solid foundation for future development into visualfoundation agents. Code, train \&amp; test data, and part of fine-tuned open LMMsare available at \url{https://github.com/THUDM/VisualAgentBench}.</description><author>Xiao Liu, Tianjie Zhang, Yu Gu, Iat Long Iong, Yifan Xu, Xixuan Song, Shudan Zhang, Hanyu Lai, Xinyi Liu, Hanlin Zhao, Jiadai Sun, Xinyue Yang, Yu Yang, Zehan Qi, Shuntian Yao, Xueqiao Sun, Siyi Cheng, Qinkai Zheng, Hao Yu, Hanchen Zhang, Wenyi Hong, Ming Ding, Lihang Pan, Xiaotao Gu, Aohan Zeng, Zhengxiao Du, Chan Hee Song, Yu Su, Yuxiao Dong, Jie Tang</author><pubDate>Mon, 12 Aug 2024 17:44:17 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.06327v1</guid></item><item><title>EqNIO: Subequivariant Neural Inertial Odometry</title><link>http://arxiv.org/abs/2408.06321v1</link><description>Presently, neural networks are widely employed to accurately estimate 2Ddisplacements and associated uncertainties from Inertial Measurement Unit (IMU)data that can be integrated into stochastic filter networks like the ExtendedKalman Filter (EKF) as measurements and uncertainties for the update step inthe filter. However, such neural approaches overlook symmetry which is acrucial inductive bias for model generalization. This oversight is notablebecause (i) physical laws adhere to symmetry principles when considering thegravity axis, meaning there exists the same transformation for both thephysical entity and the resulting trajectory, and (ii) displacements shouldremain equivariant to frame transformations when the inertial frame changes. Toaddress this, we propose a subequivariant framework by: (i) derivingfundamental layers such as linear and nonlinear layers for a subequivariantnetwork, designed to handle sequences of vectors and scalars, (ii) employingthe subequivariant network to predict an equivariant frame for the sequence ofinertial measurements. This predicted frame can then be utilized for extractinginvariant features through projection, which are integrated with arbitrarynetwork architectures, (iii) transforming the invariant output by frametransformation to obtain equivariant displacements and covariances. Wedemonstrate the effectiveness and generalization of our Equivariant Frameworkon a filter-based approach with TLIO architecture for TLIO and Aria datasets,and an end-to-end deep learning approach with RONIN architecture for RONIN,RIDI and OxIOD datasets.</description><author>Royina Karegoudra Jayanth, Yinshuang Xu, Ziyun Wang, Evangelos Chatzipantazis, Daniel Gehrig, Kostas Daniilidis</author><pubDate>Mon, 12 Aug 2024 17:42:46 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.06321v1</guid></item><item><title>Can We Rely on LLM Agents to Draft Long-Horizon Plans? Let's Take TravelPlanner as an Example</title><link>http://arxiv.org/abs/2408.06318v1</link><description>Large language models (LLMs) have brought autonomous agents closer toartificial general intelligence (AGI) due to their promising generalization andemergent capabilities. There is, however, a lack of studies on how LLM-basedagents behave, why they could potentially fail, and how to improve them,particularly in demanding real-world planning tasks. In this paper, as aneffort to fill the gap, we present our study using a realistic benchmark,TravelPlanner, where an agent must meet multiple constraints to generateaccurate plans. We leverage this benchmark to address four key researchquestions: (1) are LLM agents robust enough to lengthy and noisy contexts whenit comes to reasoning and planning? (2) can few-shot prompting adversely impactthe performance of LLM agents in scenarios with long context? (3) can we relyon refinement to improve plans, and (4) can fine-tuning LLMs with both positiveand negative feedback lead to further improvement? Our comprehensiveexperiments indicate that, firstly, LLMs often fail to attend to crucial partsof a long context, despite their ability to handle extensive referenceinformation and few-shot examples; secondly, they still struggle with analyzingthe long plans and cannot provide accurate feedback for refinement; thirdly, wepropose Feedback-Aware Fine-Tuning (FAFT), which leverages both positive andnegative feedback, resulting in substantial gains over Supervised Fine-Tuning(SFT). Our findings offer in-depth insights to the community on various aspectsrelated to real-world planning applications.</description><author>Yanan Chen, Ali Pesaranghader, Tanmana Sadhu, Dong Hoon Yi</author><pubDate>Mon, 12 Aug 2024 17:39:01 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.06318v1</guid></item><item><title>Body Transformer: Leveraging Robot Embodiment for Policy Learning</title><link>http://arxiv.org/abs/2408.06316v1</link><description>In recent years, the transformer architecture has become the de factostandard for machine learning algorithms applied to natural language processingand computer vision. Despite notable evidence of successful deployment of thisarchitecture in the context of robot learning, we claim that vanillatransformers do not fully exploit the structure of the robot learning problem.Therefore, we propose Body Transformer (BoT), an architecture that leveragesthe robot embodiment by providing an inductive bias that guides the learningprocess. We represent the robot body as a graph of sensors and actuators, andrely on masked attention to pool information throughout the architecture. Theresulting architecture outperforms the vanilla transformer, as well as theclassical multilayer perceptron, in terms of task completion, scalingproperties, and computational efficiency when representing either imitation orreinforcement learning policies. Additional material including the open-sourcecode is available at https://sferrazza.cc/bot_site.</description><author>Carmelo Sferrazza, Dun-Ming Huang, Fangchen Liu, Jongmin Lee, Pieter Abbeel</author><pubDate>Mon, 12 Aug 2024 17:31:28 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.06316v1</guid></item><item><title>OWL2Vec4OA: Tailoring Knowledge Graph Embeddings for Ontology Alignment</title><link>http://arxiv.org/abs/2408.06310v1</link><description>Ontology alignment is integral to achieving semantic interoperability as thenumber of available ontologies covering intersecting domains is increasing.This paper proposes OWL2Vec4OA, an extension of the ontology embedding systemOWL2Vec*. While OWL2Vec* has emerged as a powerful technique for ontologyembedding, it currently lacks a mechanism to tailor the embedding to theontology alignment task. OWL2Vec4OA incorporates edge confidence values fromseed mappings to guide the random walk strategy. We present the theoreticalfoundations, implementation details, and experimental evaluation of ourproposed extension, demonstrating its potential effectiveness for ontologyalignment tasks.</description><author>Sevinj Teymurova, Ernesto Jiménez-Ruiz, Tillman Weyde, Jiaoyan Chen</author><pubDate>Mon, 12 Aug 2024 17:24:19 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.06310v1</guid></item><item><title>Moderating Illicit Online Image Promotion for Unsafe User-Generated Content Games Using Large Vision-Language Models</title><link>http://arxiv.org/abs/2403.18957v2</link><description>Online user generated content games (UGCGs) are increasingly popular amongchildren and adolescents for social interaction and more creative onlineentertainment. However, they pose a heightened risk of exposure to explicitcontent, raising growing concerns for the online safety of children andadolescents. Despite these concerns, few studies have addressed the issue ofillicit image-based promotions of unsafe UGCGs on social media, which caninadvertently attract young users. This challenge arises from the difficulty ofobtaining comprehensive training data for UGCG images and the unique nature ofthese images, which differ from traditional unsafe content. In this work, wetake the first step towards studying the threat of illicit promotions of unsafeUGCGs. We collect a real-world dataset comprising 2,924 images that displaydiverse sexually explicit and violent content used to promote UGCGs by theirgame creators. Our in-depth studies reveal a new understanding of this problemand the urgent need for automatically flagging illicit UGCG promotions. Weadditionally create a cutting-edge system, UGCG-Guard, designed to aid socialmedia platforms in effectively identifying images used for illicit UGCGpromotions. This system leverages recently introduced large vision-languagemodels (VLMs) and employs a novel conditional prompting strategy for zero-shotdomain adaptation, along with chain-of-thought (CoT) reasoning for contextualidentification. UGCG-Guard achieves outstanding results, with an accuracy rateof 94% in detecting these images used for the illicit promotion of such gamesin real-world scenarios.</description><author>Keyan Guo, Ayush Utkarsh, Wenbo Ding, Isabelle Ondracek, Ziming Zhao, Guo Freeman, Nishant Vishwamitra, Hongxin Hu</author><pubDate>Mon, 12 Aug 2024 17:20:35 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.18957v2</guid></item><item><title>KIX: A Knowledge and Interaction-Centric Metacognitive Framework for Task Generalization</title><link>http://arxiv.org/abs/2402.05346v2</link><description>People aptly exhibit general intelligence behaviors in solving a variety oftasks with flexibility and ability to adapt to novel situations by reusing andapplying high-level knowledge acquired over time. But artificial agents aremore like specialists, lacking such generalist behaviors. Artificial agentswill require understanding and exploiting critical structured knowledgerepresentations. We present a metacognitive generalization framework,Knowledge-Interaction-eXecution (KIX), and argue that interactions with objectsleveraging type space facilitate the learning of transferable interactionconcepts and generalization. It is a natural way of integrating knowledge intoreinforcement learning and is promising to act as an enabler for autonomous andgeneralist behaviors in artificial intelligence systems.</description><author>Arun Kumar, Paul Schrater</author><pubDate>Mon, 12 Aug 2024 17:19:06 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.05346v2</guid></item><item><title>From SAM to SAM 2: Exploring Improvements in Meta's Segment Anything Model</title><link>http://arxiv.org/abs/2408.06305v1</link><description>The Segment Anything Model (SAM), introduced to the computer vision communityby Meta in April 2023, is a groundbreaking tool that allows automatedsegmentation of objects in images based on prompts such as text, clicks, orbounding boxes. SAM excels in zero-shot performance, segmenting unseen objectswithout additional training, stimulated by a large dataset of over one billionimage masks. SAM 2 expands this functionality to video, leveraging memory frompreceding and subsequent frames to generate accurate segmentation across entirevideos, enabling near real-time performance. This comparison shows how SAM hasevolved to meet the growing need for precise and efficient segmentation invarious applications. The study suggests that future advancements in modelslike SAM will be crucial for improving computer vision technology.</description><author>Athulya Sundaresan Geetha, Muhammad Hussain</author><pubDate>Mon, 12 Aug 2024 17:17:35 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.06305v1</guid></item><item><title>ReLU-KAN: New Kolmogorov-Arnold Networks that Only Need Matrix Addition, Dot Multiplication, and ReLU</title><link>http://arxiv.org/abs/2406.02075v2</link><description>Limited by the complexity of basis function (B-spline) calculations,Kolmogorov-Arnold Networks (KAN) suffer from restricted parallel computingcapability on GPUs. This paper proposes a novel ReLU-KAN implementation thatinherits the core idea of KAN. By adopting ReLU (Rectified Linear Unit) andpoint-wise multiplication, we simplify the design of KAN's basis function andoptimize the computation process for efficient CUDA computing. The proposedReLU-KAN architecture can be readily implemented on existing deep learningframeworks (e.g., PyTorch) for both inference and training. Experimentalresults demonstrate that ReLU-KAN achieves a 20x speedup compared totraditional KAN with 4-layer networks. Furthermore, ReLU-KAN exhibits a morestable training process with superior fitting ability while preserving the"catastrophic forgetting avoidance" property of KAN. You can get the code inhttps://github.com/quiqi/relu_kan</description><author>Qi Qiu, Tao Zhu, Helin Gong, Liming Chen, Huansheng Ning</author><pubDate>Mon, 12 Aug 2024 17:17:00 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.02075v2</guid></item><item><title>Long-Form Answers to Visual Questions from Blind and Low Vision People</title><link>http://arxiv.org/abs/2408.06303v1</link><description>Vision language models can now generate long-form answers to questions aboutimages - long-form visual question answers (LFVQA). We contribute VizWiz-LF, adataset of long-form answers to visual questions posed by blind and low vision(BLV) users. VizWiz-LF contains 4.2k long-form answers to 600 visual questions,collected from human expert describers and six VQA models. We develop andannotate functional roles of sentences of LFVQA and demonstrate that long-formanswers contain information beyond the question answer such as explanations andsuggestions. We further conduct automatic and human evaluations with BLV andsighted people to evaluate long-form answers. BLV people perceive bothhuman-written and generated long-form answers to be plausible, but generatedanswers often hallucinate incorrect visual details, especially for unanswerablevisual questions (e.g., blurry or irrelevant images). To reduce hallucinations,we evaluate the ability of VQA models to abstain from answering unanswerablequestions across multiple prompting strategies.</description><author>Mina Huh, Fangyuan Xu, Yi-Hao Peng, Chongyan Chen, Hansika Murugu, Danna Gurari, Eunsol Choi, Amy Pavel</author><pubDate>Mon, 12 Aug 2024 17:15:02 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.06303v1</guid></item><item><title>Finding Patterns in Ambiguity: Interpretable Stress Testing in the Decision~Boundary</title><link>http://arxiv.org/abs/2408.06302v1</link><description>The increasing use of deep learning across various domains highlights theimportance of understanding the decision-making processes of these black-boxmodels. Recent research focusing on the decision boundaries of deepclassifiers, relies on generated synthetic instances in areas of lowconfidence, uncovering samples that challenge both models and humans. Wepropose a novel approach to enhance the interpretability of deep binaryclassifiers by selecting representative samples from the decision boundary -prototypes - and applying post-model explanation algorithms. We evaluate theeffectiveness of our approach through 2D visualizations and GradientSHAPanalysis. Our experiments demonstrate the potential of the proposed method,revealing distinct and compact clusters and diverse prototypes that captureessential features that lead to low-confidence decisions. By offering a moreaggregated view of deep classifiers' decision boundaries, our work contributesto the responsible development and deployment of reliable machine learningsystems.</description><author>Inês Gomes, Luís F. Teixeira, Jan N. van Rijn, Carlos Soares, André Restivo, Luís Cunha, Moisés Santos</author><pubDate>Mon, 12 Aug 2024 17:14:41 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.06302v1</guid></item><item><title>RAGGED: Towards Informed Design of Retrieval Augmented Generation Systems</title><link>http://arxiv.org/abs/2403.09040v2</link><description>Retrieval-augmented generation (RAG) can significantly improve theperformance of language models (LMs) by providing additional context for taskssuch as document-based question answering (DBQA). However, the effectiveness ofRAG is highly dependent on its configuration. To systematically find theoptimal configuration, we introduce RAGGED, a framework for analyzing RAGconfigurations across various DBQA tasks. Using the framework, we discoverdistinct LM behaviors in response to varying context quantities, contextqualities, and retrievers. For instance, while some models are robust to noisycontexts, monotonically performing better with more contexts, others are morenoise-sensitive and can effectively use only a few contexts before declining inperformance. This framework also provides a deeper analysis of thesedifferences by evaluating the LMs' sensitivity to signal and noise underspecific context quality conditions. Using RAGGED, researchers andpractitioners can derive actionable insights about how to optimally configuretheir RAG systems for their specific question-answering tasks.</description><author>Jennifer Hsia, Afreen Shaikh, Zhiruo Wang, Graham Neubig</author><pubDate>Mon, 12 Aug 2024 17:12:04 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.09040v2</guid></item><item><title>Inverse designing metamaterials with programmable nonlinear functional responses in graph space</title><link>http://arxiv.org/abs/2408.06300v1</link><description>Material responses to static and dynamic stimuli, represented as nonlinearcurves, are design targets for engineering functionalities like structuralsupport, impact protection, and acoustic and photonic bandgaps.Three-dimensional metamaterials offer significant tunability due to theirinternal structure, yet existing methods struggle to capture their complexbehavior-to-structure relationships. We present GraphMetaMat, a graph-basedframework capable of designing three-dimensional metamaterials withprogrammable responses and arbitrary manufacturing constraints. Integratinggraph networks, physics biases, reinforcement learning, and tree search,GraphMetaMat can target stress-strain curves spanning four orders of magnitudeand complex behaviors, as well as viscoelastic transmission responses withvarying attenuation gaps. GraphMetaMat can create cushioning materials forprotective equipment and vibration-damping panels for electric vehicles,outperforming commercial materials, and enabling the automatic design ofmaterials with on-demand functionalities.</description><author>Marco Maurizi, Derek Xu, Yu-Tong Wang, Desheng Yao, David Hahn, Mourad Oudich, Anish Satpati, Mathieu Bauchy, Wei Wang, Yizhou Sun, Yun Jing, Xiaoyu Rayne Zheng</author><pubDate>Mon, 12 Aug 2024 17:09:28 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.06300v1</guid></item><item><title>LEARN: An Invex Loss for Outlier Oblivious Robust Online Optimization</title><link>http://arxiv.org/abs/2408.06297v1</link><description>We study a robust online convex optimization framework, where an adversarycan introduce outliers by corrupting loss functions in an arbitrary number ofrounds k, unknown to the learner. Our focus is on a novel setting allowingunbounded domains and large gradients for the losses without relying on aLipschitz assumption. We introduce the Log Exponential Adjusted Robust andiNvex (LEARN) loss, a non-convex (invex) robust loss function to mitigate theeffects of outliers and develop a robust variant of the online gradient descentalgorithm by leveraging the LEARN loss. We establish tight regret guarantees(up to constants), in a dynamic setting, with respect to the uncorrupted roundsand conduct experiments to validate our theory. Furthermore, we present aunified analysis framework for developing online optimization algorithms fornon-convex (invex) losses, utilizing it to provide regret bounds with respectto the LEARN loss, which may be of independent interest.</description><author>Adarsh Barik, Anand Krishna, Vincent Y. F. Tan</author><pubDate>Mon, 12 Aug 2024 17:08:31 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.06297v1</guid></item><item><title>An Experimental Comparison of Partitioning Strategies for Distributed Graph Neural Network Training</title><link>http://arxiv.org/abs/2308.15602v2</link><description>Recently, graph neural networks (GNNs) have gained much attention as agrowing area of deep learning capable of learning on graph-structured data.However, the computational and memory requirements for training GNNs onlarge-scale graphs make it necessary to distribute the training. A prerequisitefor distributed GNN training is to partition the input graph into smaller partsthat are distributed among multiple machines of a compute cluster. Althoughgraph partitioning has been studied with regard to graph analytics and graphdatabases, its effect on GNN training performance is largely unexplored. As aconsequence, it is unclear whether investing computational efforts intohigh-quality graph partitioning would pay off in GNN training scenarios. In this paper, we study the effectiveness of graph partitioning fordistributed GNN training. Our study aims to understand how different factorssuch as GNN parameters, mini-batch size, graph type, features size, andscale-out factor influence the effectiveness of graph partitioning. We conductexperiments with two different GNN systems using vertex and edge partitioning.We found that high-quality graph partitioning is a very effective optimizationto speed up GNN training and to reduce memory consumption. Furthermore, ourresults show that invested partitioning time can quickly be amortized byreduced GNN training time, making it a relevant optimization for most GNNscenarios. Compared to research on distributed graph processing, our studyreveals that graph partitioning plays an even more significant role indistributed GNN training, which motivates further research on the graphpartitioning problem.</description><author>Nikolai Merkel, Daniel Stoll, Ruben Mayer, Hans-Arno Jacobsen</author><pubDate>Mon, 12 Aug 2024 17:02:48 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2308.15602v2</guid></item><item><title>Non-Stationary Latent Auto-Regressive Bandits</title><link>http://arxiv.org/abs/2402.03110v2</link><description>We consider the stochastic multi-armed bandit problem with non-stationaryrewards. We present a novel formulation of non-stationarity in the environmentwhere changes in the mean reward of the arms over time are due to some unknown,latent, auto-regressive (AR) state of order $k$. We call this new environmentthe latent AR bandit. Different forms of the latent AR bandit appear in manyreal-world settings, especially in emerging scientific fields such asbehavioral health or education where there are few mechanistic models of theenvironment. If the AR order $k$ is known, we propose an algorithm thatachieves $\tilde{O}(k\sqrt{T})$ regret in this setting. Empirically, ouralgorithm outperforms standard UCB across multiple non-stationary environments,even if $k$ is mis-specified.</description><author>Anna L. Trella, Walter Dempsey, Finale Doshi-Velez, Susan A. Murphy</author><pubDate>Mon, 12 Aug 2024 16:58:54 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.03110v2</guid></item><item><title>OpenIns3D: Snap and Lookup for 3D Open-vocabulary Instance Segmentation</title><link>http://arxiv.org/abs/2309.00616v5</link><description>In this work, we introduce OpenIns3D, a new 3D-input-only framework for 3Dopen-vocabulary scene understanding. The OpenIns3D framework employs a"Mask-Snap-Lookup" scheme. The "Mask" module learns class-agnostic maskproposals in 3D point clouds, the "Snap" module generates synthetic scene-levelimages at multiple scales and leverages 2D vision-language models to extractinteresting objects, and the "Lookup" module searches through the outcomes of"Snap" to assign category names to the proposed masks. This approach, yetsimple, achieves state-of-the-art performance across a wide range of 3Dopen-vocabulary tasks, including recognition, object detection, and instancesegmentation, on both indoor and outdoor datasets. Moreover, OpenIns3Dfacilitates effortless switching between different 2D detectors withoutrequiring retraining. When integrated with powerful 2D open-world models, itachieves excellent results in scene understanding tasks. Furthermore, whencombined with LLM-powered 2D models, OpenIns3D exhibits an impressivecapability to comprehend and process highly complex text queries that demandintricate reasoning and real-world knowledge. Project page:https://zheninghuang.github.io/OpenIns3D/</description><author>Zhening Huang, Xiaoyang Wu, Xi Chen, Hengshuang Zhao, Lei Zhu, Joan Lasenby</author><pubDate>Mon, 12 Aug 2024 16:58:33 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2309.00616v5</guid></item><item><title>The AI Scientist: Towards Fully Automated Open-Ended Scientific Discovery</title><link>http://arxiv.org/abs/2408.06292v1</link><description>One of the grand challenges of artificial general intelligence is developingagents capable of conducting scientific research and discovering new knowledge.While frontier models have already been used as aids to human scientists, e.g.for brainstorming ideas, writing code, or prediction tasks, they still conductonly a small part of the scientific process. This paper presents the firstcomprehensive framework for fully automatic scientific discovery, enablingfrontier large language models to perform research independently andcommunicate their findings. We introduce The AI Scientist, which generatesnovel research ideas, writes code, executes experiments, visualizes results,describes its findings by writing a full scientific paper, and then runs asimulated review process for evaluation. In principle, this process can berepeated to iteratively develop ideas in an open-ended fashion, acting like thehuman scientific community. We demonstrate its versatility by applying it tothree distinct subfields of machine learning: diffusion modeling,transformer-based language modeling, and learning dynamics. Each idea isimplemented and developed into a full paper at a cost of less than $15 perpaper. To evaluate the generated papers, we design and validate an automatedreviewer, which we show achieves near-human performance in evaluating paperscores. The AI Scientist can produce papers that exceed the acceptancethreshold at a top machine learning conference as judged by our automatedreviewer. This approach signifies the beginning of a new era in scientificdiscovery in machine learning: bringing the transformative benefits of AIagents to the entire research process of AI itself, and taking us closer to aworld where endless affordable creativity and innovation can be unleashed onthe world's most challenging problems. Our code is open-sourced athttps://github.com/SakanaAI/AI-Scientist</description><author>Chris Lu, Cong Lu, Robert Tjarko Lange, Jakob Foerster, Jeff Clune, David Ha</author><pubDate>Mon, 12 Aug 2024 16:58:11 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.06292v1</guid></item><item><title>Mambular: A Sequential Model for Tabular Deep Learning</title><link>http://arxiv.org/abs/2408.06291v1</link><description>The analysis of tabular data has traditionally been dominated bygradient-boosted decision trees (GBDTs), known for their proficiency with mixedcategorical and numerical features. However, recent deep learning innovationsare challenging this dominance. We introduce Mambular, an adaptation of theMamba architecture optimized for tabular data. We extensively benchmarkMambular against state-of-the-art models, including neural networks andtree-based methods, and demonstrate its competitive performance across diversedatasets. Additionally, we explore various adaptations of Mambular tounderstand its effectiveness for tabular data. We investigate different poolingstrategies, feature interaction mechanisms, and bi-directional processing. Ouranalysis shows that interpreting features as a sequence and passing themthrough Mamba layers results in surprisingly performant models. The resultshighlight Mambulars potential as a versatile and powerful architecture fortabular data analysis, expanding the scope of deep learning applications inthis domain. The source code is available at https://github.com/basf/mamba-tabular.</description><author>Anton Frederik Thielmann, Manish Kumar, Christoph Weisser, Arik Reuter, Benjamin Säfken, Soheila Samiee</author><pubDate>Mon, 12 Aug 2024 16:57:57 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.06291v1</guid></item><item><title>Monitoring Fidelity of Online Reinforcement Learning Algorithms in Clinical Trials</title><link>http://arxiv.org/abs/2402.17003v2</link><description>Online reinforcement learning (RL) algorithms offer great potential forpersonalizing treatment for participants in clinical trials. However, deployingan online, autonomous algorithm in the high-stakes healthcare setting makesquality control and data quality especially difficult to achieve. This paperproposes algorithm fidelity as a critical requirement for deploying online RLalgorithms in clinical trials. It emphasizes the responsibility of thealgorithm to (1) safeguard participants and (2) preserve the scientific utilityof the data for post-trial analyses. We also present a framework forpre-deployment planning and real-time monitoring to help algorithm developersand clinical researchers ensure algorithm fidelity. To illustrate ourframework's practical application, we present real-world examples from theOralytics clinical trial. Since Spring 2023, this trial successfully deployedan autonomous, online RL algorithm to personalize behavioral interventions forparticipants at risk for dental disease.</description><author>Anna L. Trella, Kelly W. Zhang, Inbal Nahum-Shani, Vivek Shetty, Iris Yan, Finale Doshi-Velez, Susan A. Murphy</author><pubDate>Mon, 12 Aug 2024 16:56:11 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.17003v2</guid></item><item><title>Fair Column Subset Selection</title><link>http://arxiv.org/abs/2306.04489v4</link><description>The problem of column subset selection asks for a subset of columns from aninput matrix such that the matrix can be reconstructed as accurately aspossible within the span of the selected columns. A natural extension is toconsider a setting where the matrix rows are partitioned into two groups, andthe goal is to choose a subset of columns that minimizes the maximumreconstruction error of both groups, relative to their respective best rank-kapproximation. Extending the known results of column subset selection to thisfair setting is not straightforward: in certain scenarios it is unavoidable tochoose columns separately for each group, resulting in double the expectedcolumn count. We propose a deterministic leverage-score sampling strategy forthe fair setting and show that sampling a column subset of minimum size becomesNP-hard in the presence of two groups. Despite these negative results, we givean approximation algorithm that guarantees a solution within 1.5 times theoptimal solution size. We also present practical heuristic algorithms based onrank-revealing QR factorization. Finally, we validate our methods through anextensive set of experiments using real-world data.</description><author>Antonis Matakos, Bruno Ordozgoiti, Suhas Thejaswi</author><pubDate>Mon, 12 Aug 2024 16:54:55 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.04489v4</guid></item><item><title>Toward a Surgeon-in-the-Loop Ophthalmic Robotic Apprentice using Reinforcement and Imitation Learning</title><link>http://arxiv.org/abs/2311.17693v3</link><description>Robot-assisted surgical systems have demonstrated significant potential inenhancing surgical precision and minimizing human errors. However, existingsystems cannot accommodate individual surgeons' unique preferences andrequirements. Additionally, they primarily focus on general surgeries (e.g.,laparoscopy) and are unsuitable for highly precise microsurgeries, such asophthalmic procedures. Thus, we propose an image-guided approach forsurgeon-centered autonomous agents that can adapt to the individual surgeon'sskill level and preferred surgical techniques during ophthalmic cataractsurgery. Our approach trains reinforcement and imitation learning agentssimultaneously using curriculum learning approaches guided by image data toperform all tasks of the incision phase of cataract surgery. By integrating thesurgeon's actions and preferences into the training process, our approachenables the robot to implicitly learn and adapt to the individual surgeon'sunique techniques through surgeon-in-the-loop demonstrations. This results in amore intuitive and personalized surgical experience for the surgeon whileensuring consistent performance for the autonomous robotic apprentice. Wedefine and evaluate the effectiveness of our approach in a simulatedenvironment using our proposed metrics and highlight the trade-off between ageneric agent and a surgeon-centered adapted agent. Finally, our approach hasthe potential to extend to other ophthalmic and microsurgical procedures,opening the door to a new generation of surgeon-in-the-loop autonomous surgicalrobots. We provide an open-source simulation framework for future developmentand reproducibility athttps://github.com/amrgomaaelhady/CataractAdaptSurgRobot.</description><author>Amr Gomaa, Bilal Mahdy, Niko Kleer, Antonio Krüger</author><pubDate>Mon, 12 Aug 2024 16:52:09 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.17693v3</guid></item><item><title>Reinforcement Learning in High-frequency Market Making</title><link>http://arxiv.org/abs/2407.21025v2</link><description>This paper establishes a new and comprehensive theoretical analysis for theapplication of reinforcement learning (RL) in high-frequency market making. Webridge the modern RL theory and the continuous-time statistical models inhigh-frequency financial economics. Different with most existing literature onmethodological research about developing various RL methods for market makingproblem, our work is a pilot to provide the theoretical analysis. We target theeffects of sampling frequency, and find an interesting tradeoff between errorand complexity of RL algorithm when tweaking the values of the time increment$\Delta$ $-$ as $\Delta$ becomes smaller, the error will be smaller but thecomplexity will be larger. We also study the two-player case under thegeneral-sum game framework and establish the convergence of Nash equilibrium tothe continuous-time game equilibrium as $\Delta\rightarrow0$. The NashQ-learning algorithm, which is an online multi-agent RL method, is applied tosolve the equilibrium. Our theories are not only useful for practitioners tochoose the sampling frequency, but also very general and applicable to otherhigh-frequency financial decision making problems, e.g., optimal executions, aslong as the time-discretization of a continuous-time markov decision process isadopted. Monte Carlo simulation evidence support all of our theories.</description><author>Yuheng Zheng, Zihan Ding</author><pubDate>Mon, 12 Aug 2024 16:51:02 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.21025v2</guid></item><item><title>Mipmap-GS: Let Gaussians Deform with Scale-specific Mipmap for Anti-aliasing Rendering</title><link>http://arxiv.org/abs/2408.06286v1</link><description>3D Gaussian Splatting (3DGS) has attracted great attention in novel viewsynthesis because of its superior rendering efficiency and high fidelity.However, the trained Gaussians suffer from severe zooming degradation due tonon-adjustable representation derived from single-scale training. Though somemethods attempt to tackle this problem via post-processing techniques such asselective rendering or filtering techniques towards primitives, thescale-specific information is not involved in Gaussians. In this paper, wepropose a unified optimization method to make Gaussians adaptive for arbitraryscales by self-adjusting the primitive properties (e.g., color, shape and size)and distribution (e.g., position). Inspired by the mipmap technique, we designpseudo ground-truth for the target scale and propose a scale-consistencyguidance loss to inject scale information into 3D Gaussians. Our method is aplug-in module, applicable for any 3DGS models to solve the zoom-in andzoom-out aliasing. Extensive experiments demonstrate the effectiveness of ourmethod. Notably, our method outperforms 3DGS in PSNR by an average of 9.25 dBfor zoom-in and 10.40 dB for zoom-out on the NeRF Synthetic dataset.</description><author>Jiameng Li, Yue Shi, Jiezhang Cao, Bingbing Ni, Wenjun Zhang, Kai Zhang, Luc Van Gool</author><pubDate>Mon, 12 Aug 2024 16:49:22 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.06286v1</guid></item><item><title>Synthetic Patient-Physician Dialogue Generation from Clinical Notes Using LLM</title><link>http://arxiv.org/abs/2408.06285v1</link><description>Medical dialogue systems (MDS) enhance patient-physician communication,improve healthcare accessibility, and reduce costs. However, acquiring suitabledata to train these systems poses significant challenges. Privacy concernsprevent the use of real conversations, necessitating synthetic alternatives.Synthetic dialogue generation from publicly available clinical notes offers apromising solution to this issue, providing realistic data while safeguardingprivacy. Our approach, SynDial, uses a single LLM iteratively with zero-shotprompting and a feedback loop to generate and refine high-quality syntheticdialogues. The feedback consists of weighted evaluation scores for similarityand extractiveness. The iterative process ensures dialogues meet predefinedthresholds, achieving superior extractiveness as a result of the feedback loop.Additionally, evaluation shows that the generated dialogues excel in factualitymetric compared to the baselines and has comparable diversity scores with GPT4.</description><author>Trisha Das, Dina Albassam, Jimeng Sun</author><pubDate>Mon, 12 Aug 2024 16:49:22 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.06285v1</guid></item><item><title>MovieSum: An Abstractive Summarization Dataset for Movie Screenplays</title><link>http://arxiv.org/abs/2408.06281v1</link><description>Movie screenplay summarization is challenging, as it requires anunderstanding of long input contexts and various elements unique to movies.Large language models have shown significant advancements in documentsummarization, but they often struggle with processing long input contexts.Furthermore, while television transcripts have received attention in recentstudies, movie screenplay summarization remains underexplored. To stimulateresearch in this area, we present a new dataset, MovieSum, for abstractivesummarization of movie screenplays. This dataset comprises 2200 moviescreenplays accompanied by their Wikipedia plot summaries. We manuallyformatted the movie screenplays to represent their structural elements.Compared to existing datasets, MovieSum possesses several distinctive features:(1) It includes movie screenplays, which are longer than scripts of TVepisodes. (2) It is twice the size of previous movie screenplay datasets. (3)It provides metadata with IMDb IDs to facilitate access to additional externalknowledge. We also show the results of recently released large language modelsapplied to summarization on our dataset to provide a detailed baseline.</description><author>Rohit Saxena, Frank Keller</author><pubDate>Mon, 12 Aug 2024 16:43:09 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.06281v1</guid></item><item><title>Multi-marginal Schrödinger Bridges with Iterative Reference</title><link>http://arxiv.org/abs/2408.06277v1</link><description>Practitioners frequently aim to infer an unobserved population trajectoryusing sample snapshots at multiple time points. For instance, in single-cellsequencing, scientists would like to learn how gene expression evolves overtime. But sequencing any cell destroys that cell. So we cannot access anycell's full trajectory, but we can access snapshot samples from many cells.Stochastic differential equations are commonly used to analyze systems withfull individual-trajectory access; since here we have only sample snapshots,these methods are inapplicable. The deep learning community has recentlyexplored using Schr\"odinger bridges (SBs) and their extensions to estimatethese dynamics. However, these methods either (1) interpolate between just twotime points or (2) require a single fixed reference dynamic within the SB,which is often just set to be Brownian motion. But learning piecewise fromadjacent time points can fail to capture long-term dependencies. Andpractitioners are typically able to specify a model class for the referencedynamic but not the exact values of the parameters within it. So we propose anew method that (1) learns the unobserved trajectories from sample snapshotsacross multiple time points and (2) requires specification only of a class ofreference dynamics, not a single fixed one. In particular, we suggest aniterative projection method inspired by Schr\"odinger bridges; we alternatebetween learning a piecewise SB on the unobserved trajectories and using thelearned SB to refine our best guess for the dynamics within the referenceclass. We demonstrate the advantages of our method via a well-known simulatedparametric model from ecology, simulated and real data from systems biology,and real motion-capture data.</description><author>Yunyi Shen, Renato Berlinghieri, Tamara Broderick</author><pubDate>Mon, 12 Aug 2024 16:39:18 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.06277v1</guid></item><item><title>Review-driven Personalized Preference Reasoning with Large Language Models for Recommendation</title><link>http://arxiv.org/abs/2408.06276v1</link><description>Recent advancements in Large Language Models (LLMs) have demonstratedexceptional performance across a wide range of tasks, generating significantinterest in their application to recommendation systems. However, existingmethods have not fully capitalized on the potential of LLMs, often constrainedby limited input information or failing to fully utilize their advancedreasoning capabilities. To address these limitations, we introduce EXP3RT, anovel LLM-based recommender designed to leverage rich preference informationcontained in user and item reviews. EXP3RT is basically fine-tuned throughdistillation from a teacher LLM to perform three key tasks in order: EXP3RTfirst extracts and encapsulates essential subjective preferences from rawreviews, aggregates and summarizes them according to specific criteria tocreate user and item profiles. It then generates detailed step-by-stepreasoning followed by predicted rating, i.e., reasoning-enhanced ratingprediction, by considering both subjective and objective information fromuser/item profiles and item descriptions. This personalized preferencereasoning from EXP3RT enhances rating prediction accuracy and also providesfaithful and reasonable explanations for recommendation. Extensive experimentsshow that EXP3RT outperforms existing methods on both rating prediction andcandidate item reranking for top-k recommendation, while significantlyenhancing the explainability of recommendation systems.</description><author>Jieyong Kim, Hyunseo Kim, Hyunjin Cho, SeongKu Kang, Buru Chang, Jinyoung Yeo, Dongha Lee</author><pubDate>Mon, 12 Aug 2024 16:39:03 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.06276v1</guid></item><item><title>CT evaluation of 2D and 3D holistic deep learning methods for the volumetric segmentation of airway lesions</title><link>http://arxiv.org/abs/2403.08042v2</link><description>This research embarked on a comparative exploration of the holisticsegmentation capabilities of Convolutional Neural Networks (CNNs) in both 2Dand 3D formats, focusing on cystic fibrosis (CF) lesions. The study utilizeddata from two CF reference centers, covering five major CF structural changes.Initially, it compared the 2D and 3D models, highlighting the 3D model'ssuperior capability in capturing complex features like mucus plugs andconsolidations. To improve the 2D model's performance, a loss adapted to finestructures segmentation was implemented and evaluated, significantly enhancingits accuracy, though not surpassing the 3D model's performance. The modelsunderwent further validation through external evaluation against pulmonaryfunction tests (PFTs), confirming the robustness of the findings. Moreover,this study went beyond comparing metrics; it also included comprehensiveassessments of the models' interpretability and reliability, providing valuableinsights for their clinical application.</description><author>Amel Imene Hadj Bouzid, Baudouin Denis de Senneville, Fabien Baldacci, Pascal Desbarats, Patrick Berger, Ilyes Benlala, Gaël Dournes</author><pubDate>Mon, 12 Aug 2024 16:37:31 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.08042v2</guid></item><item><title>FuxiTranyu: A Multilingual Large Language Model Trained with Balanced Data</title><link>http://arxiv.org/abs/2408.06273v1</link><description>Large language models (LLMs) have demonstrated prowess in a wide range oftasks. However, many LLMs exhibit significant performance discrepancies betweenhigh- and low-resource languages. To mitigate this challenge, we presentFuxiTranyu, an open-source multilingual LLM, which is designed to satisfy theneed of the research community for balanced and high-performing multilingualcapabilities. FuxiTranyu-8B, the base model with 8 billion parameters, istrained from scratch on a meticulously balanced multilingual data repositorythat contains 600 billion tokens covering 43 natural languages and 16programming languages. In addition to the base model, we also develop twoinstruction-tuned models: FuxiTranyu-8B-SFT that is fine-tuned on a diversemultilingual instruction dataset, and FuxiTranyu-8B-DPO that is further refinedwith DPO on a preference dataset for enhanced alignment ability. Extensiveexperiments on a wide range of multilingual benchmarks demonstrate thecompetitive performance of FuxiTranyu against existing multilingual LLMs, e.g.,BLOOM-7B, PolyLM-13B, Llama-2-Chat-7B and Mistral-7B-Instruct. Interpretabilityanalyses at both the neuron and representation level suggest that FuxiTranyu isable to learn consistent multilingual representations across differentlanguages. To promote further research into multilingual LLMs and their workingmechanisms, we release both the base and instruction-tuned FuxiTranyu modelstogether with 58 pretraining checkpoints at HuggingFace and Github.</description><author>Haoran Sun, Renren Jin, Shaoyang Xu, Leiyu Pan, Supryadi, Menglong Cui, Jiangcun Dui, Yikun Lei, Lei Yang, Ling Shi, Juesi Xiao, Shaolin Zhu, Deyi Xiong</author><pubDate>Mon, 12 Aug 2024 16:34:56 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.06273v1</guid></item><item><title>Anchored Preference Optimization and Contrastive Revisions: Addressing Underspecification in Alignment</title><link>http://arxiv.org/abs/2408.06266v1</link><description>Large Language Models (LLMs) are often aligned using contrastive alignmentobjectives and preference pair datasets. The interaction between model, paireddata, and objective makes alignment a complicated procedure, sometimesproducing subpar results. We study this and find that (i) preference data givesa better learning signal when the underlying responses are contrastive, and(ii) alignment objectives lead to better performance when they specify morecontrol over the model during training. Based on these insights, we introduceContrastive Learning from AI Revisions (CLAIR), a data-creation method whichleads to more contrastive preference pairs, and Anchored PreferenceOptimization (APO), a controllable and more stable alignment objective. Wealign Llama-3-8B-Instruct using various comparable datasets and alignmentobjectives and measure MixEval-Hard scores, which correlate highly with humanjudgments. The CLAIR preferences lead to the strongest performance out of alldatasets, and APO consistently outperforms less controllable objectives. Ourbest model, trained on 32K CLAIR preferences with APO, improvesLlama-3-8B-Instruct by 7.65%, closing the gap with GPT4-turbo by 45%. Our codeis available at https://github.com/ContextualAI/CLAIR_and_APO.</description><author>Karel D'Oosterlinck, Winnie Xu, Chris Develder, Thomas Demeester, Amanpreet Singh, Christopher Potts, Douwe Kiela, Shikib Mehri</author><pubDate>Mon, 12 Aug 2024 16:24:51 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.06266v1</guid></item><item><title>Audio Enhancement for Computer Audition -- An Iterative Training Paradigm Using Sample Importance</title><link>http://arxiv.org/abs/2408.06264v1</link><description>Neural network models for audio tasks, such as automatic speech recognition(ASR) and acoustic scene classification (ASC), are susceptible to noisecontamination for real-life applications. To improve audio quality, anenhancement module, which can be developed independently, is explicitly used atthe front-end of the target audio applications. In this paper, we present anend-to-end learning solution to jointly optimise the models for audioenhancement (AE) and the subsequent applications. To guide the optimisation ofthe AE module towards a target application, and especially to overcomedifficult samples, we make use of the sample-wise performance measure as anindication of sample importance. In experiments, we consider fourrepresentative applications to evaluate our training paradigm, i.e., ASR,speech command recognition (SCR), speech emotion recognition (SER), and ASC.These applications are associated with speech and non-speech tasks concerningsemantic and non-semantic features, transient and global information, and theexperimental results indicate that our proposed approach can considerably boostthe noise robustness of the models, especially at low signal-to-noise ratios(SNRs), for a wide range of computer audition tasks in everyday-life noisyenvironments.</description><author>Manuel Milling, Shuo Liu, Andreas Triantafyllopoulos, Ilhan Aslan, Björn W. Schuller</author><pubDate>Mon, 12 Aug 2024 16:23:58 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.06264v1</guid></item><item><title>Unified Discrete Diffusion for Categorical Data</title><link>http://arxiv.org/abs/2402.03701v2</link><description>Discrete diffusion models have seen a surge of attention with applications onnaturally discrete data such as language and graphs. Although discrete-timediscrete diffusion has been established for a while, only recently Campbell etal. (2022) introduced the first framework for continuous-time discretediffusion. However, their training and sampling processes differ significantlyfrom the discrete-time version, necessitating nontrivial approximations fortractability. In this paper, we first present a series of mathematicalsimplifications of the variational lower bound that enable more accurate andeasy-to-optimize training for discrete diffusion. In addition, we derive asimple formulation for backward denoising that enables exact and acceleratedsampling, and importantly, an elegant unification of discrete-time andcontinuous-time discrete diffusion. Thanks to simpler analytical formulations,both forward and now also backward probabilities can flexibly accommodate anynoise distribution, including different noise distributions for multi-elementobjects. Experiments show that our proposed USD3 (for Unified SimplifiedDiscrete Denoising Diffusion) outperform all SOTA baselines on establisheddatasets. We open-source our unified code athttps://github.com/LingxiaoShawn/USD3.</description><author>Lingxiao Zhao, Xueying Ding, Lijun Yu, Leman Akoglu</author><pubDate>Mon, 12 Aug 2024 16:22:38 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.03701v2</guid></item><item><title>DUNE: A Machine Learning Deep UNet++ based Ensemble Approach to Monthly, Seasonal and Annual Climate Forecasting</title><link>http://arxiv.org/abs/2408.06262v1</link><description>Capitalizing on the recent availability of ERA5 monthly averaged long-termdata records of mean atmospheric and climate fields based on high-resolutionreanalysis, deep-learning architectures offer an alternative to physics-baseddaily numerical weather predictions for subseasonal to seasonal (S2S) andannual means. A novel Deep UNet++-based Ensemble (DUNE) neural architecture isintroduced, employing multi-encoder-decoder structures with residual blocks.When initialized from a prior month or year, this architecture produced thefirst AI-based global monthly, seasonal, or annual mean forecast of 2-metertemperatures (T2m) and sea surface temperatures (SST). ERA5 monthly mean datais used as input for T2m over land, SST over oceans, and solar radiation at thetop of the atmosphere for each month of 40 years to train the model. Validationforecasts are performed for an additional two years, followed by five years offorecast evaluations to account for natural annual variability. AI-trainedinference forecast weights generate forecasts in seconds, enabling ensembleseasonal forecasts. Root Mean Squared Error (RMSE), Anomaly CorrelationCoefficient (ACC), and Heidke Skill Score (HSS) statistics are presentedglobally and over specific regions. These forecasts outperform persistence,climatology, and multiple linear regression for all domains. DUNE forecastsdemonstrate comparable statistical accuracy to NOAA's operational monthly andseasonal probabilistic outlook forecasts over the US but at significantlyhigher resolutions. RMSE and ACC error statistics for other recent AI-baseddaily forecasts also show superior performance for DUNE-based forecasts. TheDUNE model's application to an ensemble data assimilation cycle showscomparable forecast accuracy with a single high-resolution model, potentiallyeliminating the need for retraining on extrapolated datasets.</description><author>Pratik Shukla, Milton Halem</author><pubDate>Mon, 12 Aug 2024 16:22:30 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.06262v1</guid></item><item><title>Open-Source Molecular Processing Pipeline for Generating Molecules</title><link>http://arxiv.org/abs/2408.06261v1</link><description>Generative models for molecules have shown considerable promise for use incomputational chemistry, but remain difficult to use for non-experts. For thisreason, we introduce open-source infrastructure for easily building generativemolecular models into the widely used DeepChem [Ramsundar et al., 2019] librarywith the aim of creating a robust and reusable molecular generation pipeline.In particular, we add high quality PyTorch [Paszke et al., 2019]implementations of the Molecular Generative Adversarial Networks (MolGAN) [Caoand Kipf, 2022] and Normalizing Flows [Papamakarios et al., 2021]. Ourimplementations show strong performance comparable with past work [Kuznetsovand Polykovskiy, 2021, Cao and Kipf, 2022].</description><author>Shreyas V, Jose Siguenza, Karan Bania, Bharath Ramsundar</author><pubDate>Mon, 12 Aug 2024 16:21:29 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.06261v1</guid></item><item><title>MoMa: Efficient Early-Fusion Pre-training with Mixture of Modality-Aware Experts</title><link>http://arxiv.org/abs/2407.21770v3</link><description>We introduce MoMa, a novel modality-aware mixture-of-experts (MoE)architecture designed for pre-training mixed-modal, early-fusion languagemodels. MoMa processes images and text in arbitrary sequences by dividingexpert modules into modality-specific groups. These groups exclusively processdesignated tokens while employing learned routing within each group to maintainsemantically informed adaptivity. Our empirical results reveal substantialpre-training efficiency gains through this modality-specific parameterallocation. Under a 1-trillion-token training budget, the MoMa 1.4B model,featuring 4 text experts and 4 image experts, achieves impressive FLOPssavings: 3.7x overall, with 2.6x for text and 5.2x for image processingcompared to a compute-equivalent dense baseline, measured by pre-training loss.This outperforms the standard expert-choice MoE with 8 mixed-modal experts,which achieves 3x overall FLOPs savings (3x for text, 2.8x for image).Combining MoMa with mixture-of-depths (MoD) further improves pre-training FLOPssavings to 4.2x overall (text: 3.4x, image: 5.3x), although this combinationhurts performance in causal inference due to increased sensitivity to routeraccuracy. These results demonstrate MoMa's potential to significantly advancethe efficiency of mixed-modal, early-fusion language model pre-training, pavingthe way for more resource-efficient and capable multimodal AI systems.</description><author>Xi Victoria Lin, Akshat Shrivastava, Liang Luo, Srinivasan Iyer, Mike Lewis, Gargi Ghosh, Luke Zettlemoyer, Armen Aghajanyan</author><pubDate>Mon, 12 Aug 2024 16:20:37 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.21770v3</guid></item><item><title>Context-aware Visual Storytelling with Visual Prefix Tuning and Contrastive Learning</title><link>http://arxiv.org/abs/2408.06259v1</link><description>Visual storytelling systems generate multi-sentence stories from imagesequences. In this task, capturing contextual information and bridging visualvariation bring additional challenges. We propose a simple yet effectiveframework that leverages the generalization capabilities of pretrainedfoundation models, only training a lightweight vision-language mapping networkto connect modalities, while incorporating context to enhance coherence. Weintroduce a multimodal contrastive objective that also improves visualrelevance and story informativeness. Extensive experimental results, acrossboth automatic metrics and human evaluations, demonstrate that the storiesgenerated by our framework are diverse, coherent, informative, and interesting.</description><author>Yingjin Song, Denis Paperno, Albert Gatt</author><pubDate>Mon, 12 Aug 2024 16:15:32 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.06259v1</guid></item><item><title>Deep Learning System Boundary Testing through Latent Space Style Mixing</title><link>http://arxiv.org/abs/2408.06258v1</link><description>Evaluating the behavioral frontier of deep learning (DL) systems is crucialfor understanding their generalizability and robustness. However, boundarytesting is challenging due to their high-dimensional input space. Generativeartificial intelligence offers a promising solution by modeling datadistribution within compact latent space representations, thereby facilitatingfiner-grained explorations. In this work, we introduce MIMICRY, a novelblack-box system-agnostic test generator that leverages these latentrepresentations to generate frontier inputs for the DL systems under test.Specifically, MIMICRY uses style-based generative adversarial networks trainedto learn the representation of inputs with disentangled features. Thisrepresentation enables embedding style-mixing operations between a source and atarget input, combining their features to explore the boundary between them. Weevaluated the effectiveness of different MIMICRY configurations in generatingboundary inputs for four popular DL image classification systems. Our resultsshow that manipulating the latent space allows for effective and efficientexploration of behavioral frontiers. As opposed to a model-based baseline,MIMICRY generates a higher quality frontier of behaviors which includes moreand closer inputs. Additionally, we assessed the validity of these inputs,revealing a high validity rate according to human assessors.</description><author>Amr Abdellatif, Xingcheng Chen, Vincenzo Riccio, Andrea Stocco</author><pubDate>Mon, 12 Aug 2024 16:14:55 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.06258v1</guid></item><item><title>Reciprocal Learning</title><link>http://arxiv.org/abs/2408.06257v1</link><description>We demonstrate that a wide array of machine learning algorithms are specificinstances of one single paradigm: reciprocal learning. These instances rangefrom active learning over multi-armed bandits to self-training. We show thatall these algorithms do not only learn parameters from data but also viceversa: They iteratively alter training data in a way that depends on thecurrent model fit. We introduce reciprocal learning as a generalization ofthese algorithms using the language of decision theory. This allows us to studyunder what conditions they converge. The key is to guarantee that reciprocallearning contracts such that the Banach fixed-point theorem applies. In thisway, we find that reciprocal learning algorithms converge at linear rates to anapproximately optimal model under relatively mild assumptions on the lossfunction, if their predictions are probabilistic and the sample adaption isboth non-greedy and either randomized or regularized. We interpret thesefindings and provide corollaries that relate them to specific active learning,self-training, and bandit algorithms.</description><author>Julian Rodemann, Christoph Jansen, Georg Schollmeyer</author><pubDate>Mon, 12 Aug 2024 16:14:52 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.06257v1</guid></item><item><title>A Text-guided Protein Design Framework</title><link>http://arxiv.org/abs/2302.04611v3</link><description>Current AI-assisted protein design mainly utilizes protein sequential andstructural information. Meanwhile, there exists tremendous knowledge curated byhumans in the text format describing proteins' high-level functionalities. Yet,whether the incorporation of such text data can help protein design tasks hasnot been explored. To bridge this gap, we propose ProteinDT, a multi-modalframework that leverages textual descriptions for protein design. ProteinDTconsists of three subsequent steps: ProteinCLAP which aligns the representationof two modalities, a facilitator that generates the protein representation fromthe text modality, and a decoder that creates the protein sequences from therepresentation. To train ProteinDT, we construct a large dataset,SwissProtCLAP, with 441K text and protein pairs. We quantitatively verify theeffectiveness of ProteinDT on three challenging tasks: (1) over 90\% accuracyfor text-guided protein generation; (2) best hit ratio on 12 zero-shottext-guided protein editing tasks; (3) superior performance on four out of sixprotein property prediction benchmarks.</description><author>Shengchao Liu, Yanjing Li, Zhuoxinran Li, Anthony Gitter, Yutao Zhu, Jiarui Lu, Zhao Xu, Weili Nie, Arvind Ramanathan, Chaowei Xiao, Jian Tang, Hongyu Guo, Anima Anandkumar</author><pubDate>Mon, 12 Aug 2024 16:05:43 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2302.04611v3</guid></item><item><title>Rethinking Video with a Universal Event-Based Representation</title><link>http://arxiv.org/abs/2408.06248v1</link><description>Traditionally, video is structured as a sequence of discrete image frames.Recently, however, a novel video sensing paradigm has emerged which eschewsvideo frames entirely. These "event" sensors aim to mimic the human visionsystem with asynchronous sensing, where each pixel has an independent, sparsedata stream. While these cameras enable high-speed and high-dynamic-rangesensing, researchers often revert to a framed representation of the event datafor existing applications, or build bespoke applications for a particularcamera's event data type. At the same time, classical video systems havesignificant computational redundancy at the application layer, since pixelsamples are repeated across frames in the uncompressed domain. To address the shortcomings of existing systems, I introduce Address,Decimation, {\Delta}t Event Representation (AD{\Delta}ER, pronounced "adder"),a novel intermediate video representation and system framework. The frameworktranscodes a variety of framed and event camera sources into a singleevent-based representation, which supports source-modeled lossy compression andbackward compatibility with traditional frame-based applications. I demonstratethat AD{\Delta}ER achieves state-of-the-art application speed and compressionperformance for scenes with high temporal redundancy. Crucially, I describe howAD{\Delta}ER unlocks an entirely new control mechanism for computer vision:application speed can correlate with both the scene content and the level oflossy compression. Finally, I discuss the implications for event-based video onlarge-scale video surveillance and resource-constrained sensing.</description><author>Andrew Freeman</author><pubDate>Mon, 12 Aug 2024 16:00:17 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.06248v1</guid></item><item><title>Latent Disentanglement for Low Light Image Enhancement</title><link>http://arxiv.org/abs/2408.06245v1</link><description>Many learning-based low-light image enhancement (LLIE) algorithms are basedon the Retinex theory. However, the Retinex-based decomposition techniques insuch models introduce corruptions which limit their enhancement performance. Inthis paper, we propose a Latent Disentangle-based Enhancement Network (LDE-Net)for low light vision tasks. The latent disentanglement module disentangles theinput image in latent space such that no corruption remains in the disentangledContent and Illumination components. For LLIE task, we design a Content-AwareEmbedding (CAE) module that utilizes Content features to direct the enhancementof the Illumination component. For downstream tasks (e.g. nighttime UAVtracking and low-light object detection), we develop an effective light-weightenhancer based on the latent disentanglement framework. Comprehensivequantitative and qualitative experiments demonstrate that our LDE-Netsignificantly outperforms state-of-the-art methods on various LLIE benchmarks.In addition, the great results obtained by applying our framework on thedownstream tasks also demonstrate the usefulness of our latent disentanglementdesign.</description><author>Zhihao Zheng, Mooi Choo Chuah</author><pubDate>Mon, 12 Aug 2024 15:54:46 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.06245v1</guid></item><item><title>Decentralized Intelligence Network (DIN)</title><link>http://arxiv.org/abs/2407.02461v3</link><description>Decentralized Intelligence Network (DIN) is a theoretical frameworkaddressing data fragmentation and siloing challenges, enabling scalable AIthrough data sovereignty. It facilitates effective AI utilization withinsovereign networks by overcoming barriers to accessing diverse data sources,leveraging: 1) personal data stores to ensure data sovereignty, where dataremains securely within Participants' control; 2) a scalable federated learningprotocol implemented on a public blockchain for decentralized AI training,where only model parameter updates are shared, keeping data within the personaldata stores; and 3) a scalable, trustless cryptographic rewards mechanism on apublic blockchain to incentivize participation and ensure fair rewarddistribution through a decentralized auditing protocol. This approachguarantees that no entity can prevent or control access to training data orinfluence financial benefits, as coordination and reward distribution aremanaged on the public blockchain with an immutable record. The frameworksupports effective AI training by allowing Participants to maintain controlover their data, benefit financially, and contribute to a decentralized,scalable ecosystem that leverages collective AI to develop beneficialalgorithms.</description><author>Abraham Nash</author><pubDate>Mon, 12 Aug 2024 15:54:14 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.02461v3</guid></item><item><title>3D Reconstruction of Protein Structures from Multi-view AFM Images using Neural Radiance Fields (NeRFs)</title><link>http://arxiv.org/abs/2408.06244v1</link><description>Recent advancements in deep learning for predicting 3D protein structureshave shown promise, particularly when leveraging inputs like protein sequencesand Cryo-Electron microscopy (Cryo-EM) images. However, these techniques oftenfall short when predicting the structures of protein complexes (PCs), whichinvolve multiple proteins. In our study, we investigate using atomic forcemicroscopy (AFM) combined with deep learning to predict the 3D structures ofPCs. AFM generates height maps that depict the PCs in various randomorientations, providing a rich information for training a neural network topredict the 3D structures. We then employ the pre-trained UpFusion model (whichutilizes a conditional diffusion model for synthesizing novel views) to trainan instance-specific NeRF model for 3D reconstruction. The performance ofUpFusion is evaluated through zero-shot predictions of 3D protein structuresusing AFM images. The challenge, however, lies in the time-intensive andimpractical nature of collecting actual AFM images. To address this, we use avirtual AFM imaging process that transforms a `PDB' protein file intomulti-view 2D virtual AFM images via volume rendering techniques. Weextensively validate the UpFusion architecture using both virtual and actualmulti-view AFM images. Our results include a comparison of structures predictedwith varying numbers of views and different sets of views. This novel approachholds significant potential for enhancing the accuracy of protein complexstructure predictions with further fine-tuning of the UpFusion network.</description><author>Jaydeep Rade, Ethan Herron, Soumik Sarkar, Anwesha Sarkar, Adarsh Krishnamurthy</author><pubDate>Mon, 12 Aug 2024 15:53:24 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.06244v1</guid></item><item><title>Decentralized Intelligence Health Network (DIHN)</title><link>http://arxiv.org/abs/2408.06240v1</link><description>Decentralized Intelligence Health Network (DIHN) is a theoretical frameworkaddressing significant challenges of health data sovereignty and AI utilizationin healthcare caused by data fragmentation across providers and institutions.It establishes a sovereign architecture for healthcare provision as aprerequisite to a sovereign health network, then facilitates effective AIutilization by overcoming barriers to accessing diverse medical data sources.This comprehensive framework leverages: 1) self-sovereign identity architecturecoupled with a personal health record (PHR) as a prerequisite for health datasovereignty; 2) a scalable federated learning (FL) protocol implemented on apublic blockchain for decentralized AI training in healthcare, where healthdata remains with participants and only model parameter updates are shared; and3) a scalable, trustless rewards mechanism to incentivize participation andensure fair reward distribution. This framework ensures that no entity canprevent or control access to training on health data offered by participants ordetermine financial benefits, as these processes operate on a public blockchainwith an immutable record and without a third party. It supports effective AItraining in healthcare, allowing patients to maintain control over their healthdata, benefit financially, and contribute to a decentralized, scalableecosystem that leverages collective AI to develop beneficial healthcarealgorithms. Patients receive rewards into their digital wallets as an incentiveto opt-in to the FL protocol, with a long-term roadmap to funding decentralizedinsurance solutions. This approach introduces a novel, self-financed healthcaremodel that adapts to individual needs, complements existing systems, andredefines universal coverage. It highlights the potential to transformhealthcare data management and AI utilization while empowering patients.</description><author>Abraham Nash</author><pubDate>Mon, 12 Aug 2024 15:47:26 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.06240v1</guid></item><item><title>Across Platforms and Languages: Dutch Influencers and Legal Disclosures on Instagram, YouTube and TikTok</title><link>http://arxiv.org/abs/2407.12451v2</link><description>Content monetization on social media fuels a growing influencer economy.Influencer marketing remains largely undisclosed or inappropriately disclosedon social media. Non-disclosure issues have become a priority for national andsupranational authorities worldwide, who are starting to impose increasinglyharsher sanctions on them. This paper proposes a transparent methodology formeasuring whether and how influencers comply with disclosures based on legalstandards. We introduce a novel distinction between disclosures that arelegally sufficient (green) and legally insufficient (yellow). We apply thismethodology to an original dataset reflecting the content of 150 Dutchinfluencers publicly registered with the Dutch Media Authority based onrecently introduced registration obligations. The dataset consists of 292,315posts and is multi-language (English and Dutch) and cross-platform (Instagram,YouTube and TikTok). We find that influencer marketing remains generallyunderdisclosed on social media, and that bigger influencers are not necessarilymore compliant with disclosure standards.</description><author>Haoyang Gui, Thales Bertaglia, Catalina Goanta, Sybe de Vries, Gerasimos Spanakis</author><pubDate>Mon, 12 Aug 2024 15:44:26 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.12451v2</guid></item><item><title>Correlation Weighted Prototype-based Self-Supervised One-Shot Segmentation of Medical Images</title><link>http://arxiv.org/abs/2408.06235v1</link><description>Medical image segmentation is one of the domains where sufficient annotateddata is not available. This necessitates the application of low-data frameworkslike few-shot learning. Contemporary prototype-based frameworks often do notaccount for the variation in features within the support and query images,giving rise to a large variance in prototype alignment. In this work, we adopta prototype-based self-supervised one-way one-shot learning framework usingpseudo-labels generated from superpixels to learn the semantic segmentationtask itself. We use a correlation-based probability score to generate a dynamicprototype for each query pixel from the bag of prototypes obtained from thesupport feature map. This weighting scheme helps to give a higher weightage tocontextually related prototypes. We also propose a quadrant masking strategy inthe downstream segmentation task by utilizing prior domain information todiscard unwanted false positives. We present extensive experimentations andevaluations on abdominal CT and MR datasets to show that the proposed simplebut potent framework performs at par with the state-of-the-art methods.</description><author>Siladittya Manna, Saumik Bhattacharya, Umapada Pal</author><pubDate>Mon, 12 Aug 2024 15:38:51 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.06235v1</guid></item><item><title>A Comprehensive Case Study on the Performance of Machine Learning Methods on the Classification of Solar Panel Electroluminescence Images</title><link>http://arxiv.org/abs/2408.06229v1</link><description>Photovoltaics (PV) are widely used to harvest solar energy, an important formof renewable energy. Photovoltaic arrays consist of multiple solar panelsconstructed from solar cells. Solar cells in the field are vulnerable tovarious defects, and electroluminescence (EL) imaging provides effective andnon-destructive diagnostics to detect those defects. We use multipletraditional machine learning and modern deep learning models to classify ELsolar cell images into different functional/defective categories. Because ofthe asymmetry in the number of functional vs. defective cells, an imbalancedlabel problem arises in the EL image data. The current literature lacksinsights on which methods and metrics to use for model training and prediction.In this paper, we comprehensively compare different machine learning and deeplearning methods under different performance metrics on the classification ofsolar cell EL images from monocrystalline and polycrystalline modules. Weprovide a comprehensive discussion on different metrics. Our results provideinsights and guidelines for practitioners in selecting prediction methods andperformance metrics.</description><author>Xinyi Song, Kennedy Odongo, Francis G. Pascual, Yili Hong</author><pubDate>Mon, 12 Aug 2024 15:29:32 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.06229v1</guid></item><item><title>FLEURS-R: A Restored Multilingual Speech Corpus for Generation Tasks</title><link>http://arxiv.org/abs/2408.06227v1</link><description>This paper introduces FLEURS-R, a speech restoration applied version of theFew-shot Learning Evaluation of Universal Representations of Speech (FLEURS)corpus. FLEURS-R maintains an N-way parallel speech corpus in 102 languages asFLEURS, with improved audio quality and fidelity by applying the speechrestoration model Miipher. The aim of FLEURS-R is to advance speech technologyin more languages and catalyze research including text-to-speech (TTS) andother speech generation tasks in low-resource languages. Comprehensiveevaluations with the restored speech and TTS baseline models trained from thenew corpus show that the new corpus obtained significantly improved speechquality while maintaining the semantic contents of the speech. The corpus ispublicly released via Hugging Face.</description><author>Min Ma, Yuma Koizumi, Shigeki Karita, Heiga Zen, Jason Riesa, Haruko Ishikawa, Michiel Bacchiani</author><pubDate>Mon, 12 Aug 2024 15:28:51 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.06227v1</guid></item><item><title>A Large-Scale Study of Model Integration in ML-Enabled Software Systems</title><link>http://arxiv.org/abs/2408.06226v1</link><description>The rise of machine learning (ML) and its embedding in systems hasdrastically changed the engineering of software-intensive systems.Traditionally, software engineering focuses on manually created artifacts suchas source code and the process of creating them, as well as best practices forintegrating them, i.e., software architectures. In contrast, the development ofML artifacts, i.e. ML models, comes from data science and focuses on the MLmodels and their training data. However, to deliver value to end users, theseML models must be embedded in traditional software, often forming complextopologies. In fact, ML-enabled software can easily incorporate many differentML models. While the challenges and practices of building ML-enabled systemshave been studied to some extent, beyond isolated examples, little is knownabout the characteristics of real-world ML-enabled systems. Properly embeddingML models in systems so that they can be easily maintained or reused is farfrom trivial. We need to improve our empirical understanding of such systems,which we address by presenting the first large-scale study of real ML-enabledsoftware systems, covering over 2,928 open source systems on GitHub. Weclassified and analyzed them to determine their characteristics, as well astheir practices for reusing ML models and related code, and the architecture ofthese systems. Our findings provide practitioners and researchers with insightinto practices for embedding and integrating ML models, bringing data scienceand software engineering closer together.</description><author>Yorick Sens, Henriette Knopp, Sven Peldszus, Thorsten Berger</author><pubDate>Mon, 12 Aug 2024 15:28:40 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.06226v1</guid></item><item><title>On Effects of Steering Latent Representation for Large Language Model Unlearning</title><link>http://arxiv.org/abs/2408.06223v1</link><description>Representation Misdirection for Unlearning (RMU), which steers modelrepresentation in the intermediate layer to a target random representation, isan effective method for large language model (LLM) unlearning. Despite its highperformance, the underlying cause and explanation remain underexplored. In thispaper, we first theoretically demonstrate that steering forget representationsin the intermediate layer reduces token confidence, causing LLMs to generatewrong or nonsense responses. Second, we investigate how the coefficientinfluences the alignment of forget-sample representations with the randomdirection and hint at the optimal coefficient values for effective unlearningacross different network layers. Third, we show that RMU unlearned models arerobust against adversarial jailbreak attacks. Last, our empirical analysisshows that RMU is less effective when applied to the middle and later layers inLLMs. To resolve this drawback, we propose Adaptive RMU -- a simple yeteffective alternative method that makes unlearning effective with most layers.Extensive experiments demonstrate that Adaptive RMU significantly improves theunlearning performance compared to prior art while incurring no additionalcomputational cost.</description><author>Dang Huu-Tien, Trung-Tin Pham, Hoang Thanh-Tung, Naoya Inoue</author><pubDate>Mon, 12 Aug 2024 15:24:50 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.06223v1</guid></item><item><title>A Digital Twin Framework Utilizing Machine Learning for Robust Predictive Maintenance: Enhancing Tire Health Monitoring</title><link>http://arxiv.org/abs/2408.06220v1</link><description>We introduce a novel digital twin framework for predictive maintenance oflong-term physical systems. Using monitoring tire health as an application, weshow how the digital twin framework can be used to enhance automotive safetyand efficiency, and how the technical challenges can be overcome using athree-step approach. Firstly, for managing the data complexity over a longoperation span, we employ data reduction techniques to concisely representphysical tires using historical performance and usage data. Relying on thesedata, for fast real-time prediction, we train a transformer-based model offlineon our concise dataset to predict future tire health over time, represented asRemaining Casing Potential (RCP). Based on our architecture, our modelquantifies both epistemic and aleatoric uncertainty, providing reliableconfidence intervals around predicted RCP. Secondly, to incorporate real-timedata, we update the predictive model in the digital twin framework, ensuringits accuracy throughout its life span with the aid of hybrid modeling and theuse of discrepancy function. Thirdly, to assist decision making in predictivemaintenance, we implement a Tire State Decision Algorithm, which strategicallydetermines the optimal timing for tire replacement based on RCP forecasted byour transformer model. This approach ensures our digital twin accuratelypredicts system health, continually refines its digital representation, andsupports predictive maintenance decisions. Our framework effectively embodies aphysical system, leveraging big data and machine learning for predictivemaintenance, model updates, and decision-making.</description><author>Vispi Karkaria, Jie Chen, Christopher Luey, Chase Siuta, Damien Lim, Robert Radulescu, Wei Chen</author><pubDate>Mon, 12 Aug 2024 15:21:35 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.06220v1</guid></item><item><title>Detecting Android Malware: From Neural Embeddings to Hands-On Validation with BERTroid</title><link>http://arxiv.org/abs/2405.03620v2</link><description>As cyber threats and malware attacks increasingly alarm both individuals andbusinesses, the urgency for proactive malware countermeasures intensifies. Thishas driven a rising interest in automated machine learning solutions.Transformers, a cutting-edge category of attention-based deep learning methods,have demonstrated remarkable success. In this paper, we present BERTroid, aninnovative malware detection model built on the BERT architecture. Overall,BERTroid emerged as a promising solution for combating Android malware. Itsability to outperform state-of-the-art solutions demonstrates its potential asa proactive defense mechanism against malicious software attacks. Additionally,we evaluate BERTroid on multiple datasets to assess its performance acrossdiverse scenarios. In the dynamic landscape of cybersecurity, our approach hasdemonstrated promising resilience against the rapid evolution of malware onAndroid systems. While the machine learning model captures broad patterns, weemphasize the role of manual validation for deeper comprehension and insightinto these behaviors. This human intervention is critical for discerningintricate and context-specific behaviors, thereby validating and reinforcingthe model's findings.</description><author>Meryam Chaieb, Mostafa Anouar Ghorab, Mohamed Aymen Saied</author><pubDate>Mon, 12 Aug 2024 15:16:15 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.03620v2</guid></item><item><title>Semisupervised Neural Proto-Language Reconstruction</title><link>http://arxiv.org/abs/2406.05930v2</link><description>Existing work implementing comparative reconstruction of ancestral languages(proto-languages) has usually required full supervision. However, historicalreconstruction models are only of practical value if they can be trained with alimited amount of labeled data. We propose a semisupervised historicalreconstruction task in which the model is trained on only a small amount oflabeled data (cognate sets with proto-forms) and a large amount of unlabeleddata (cognate sets without proto-forms). We propose a neural architecture forcomparative reconstruction (DPD-BiReconstructor) incorporating an essentialinsight from linguists' comparative method: that reconstructed words should notonly be reconstructable from their daughter words, but also deterministicallytransformable back into their daughter words. We show that this architecture isable to leverage unlabeled cognate sets to outperform strong semisupervisedbaselines on this novel task.</description><author>Liang Lu, Peirong Xie, David R. Mortensen</author><pubDate>Mon, 12 Aug 2024 15:10:00 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.05930v2</guid></item><item><title>Private Fine-tuning of Large Language Models with Zeroth-order Optimization</title><link>http://arxiv.org/abs/2401.04343v2</link><description>Differentially private stochastic gradient descent (DP-SGD) allows models tobe trained in a privacy-preserving manner, but has proven difficult to scale tothe era of foundation models. We introduce DP-ZO, a private fine-tuningframework for large language models by privatizing zeroth order optimizationmethods. A key insight into the design of our method is that the direction ofthe gradient in the zeroth-order optimization we use is random and the onlyinformation from training data is the step size, i.e., a scalar. Therefore, weonly need to privatize the scalar step size, which is memory-efficient. DP-ZOprovides a strong privacy-utility trade-off across different tasks, and modelsizes that are comparable to DP-SGD in $(\varepsilon,\delta)$-DP. Notably,DP-ZO possesses significant advantages over DP-SGD in memory efficiency, andobtains higher utility in $\varepsilon$-DP when using the Laplace mechanism.</description><author>Xinyu Tang, Ashwinee Panda, Milad Nasr, Saeed Mahloujifar, Prateek Mittal</author><pubDate>Mon, 12 Aug 2024 15:07:50 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.04343v2</guid></item><item><title>Leveraging KANs For Enhanced Deep Koopman Operator Discovery</title><link>http://arxiv.org/abs/2406.02875v3</link><description>Multi-layer perceptrons (MLP's) have been extensively utilized in discoveringDeep Koopman operators for linearizing nonlinear dynamics. With the emergenceof Kolmogorov-Arnold Networks (KANs) as a more efficient and accuratealternative to the MLP Neural Network, we propose a comparison of theperformance of each network type in the context of learning Koopman operatorswith control. In this work, we propose a KANs-based deep Koopman framework withapplications to an orbital Two-Body Problem (2BP) and the pendulum fordata-driven discovery of linear system dynamics. KANs were found to be superiorin nearly all aspects of training; learning 31 times faster, being 15 timesmore parameter efficiency, and predicting 1.25 times more accurately ascompared to the MLP Deep Neural Networks (DNNs) in the case of the 2BP. Thus,KANs shows potential for being an efficient tool in the development of DeepKoopman Theory.</description><author>George Nehma, Madhur Tiwari</author><pubDate>Mon, 12 Aug 2024 15:07:04 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.02875v3</guid></item><item><title>Computability of Classification and Deep Learning: From Theoretical Limits to Practical Feasibility through Quantization</title><link>http://arxiv.org/abs/2408.06212v1</link><description>The unwavering success of deep learning in the past decade led to theincreasing prevalence of deep learning methods in various application fields.However, the downsides of deep learning, most prominently its lack oftrustworthiness, may not be compatible with safety-critical orhigh-responsibility applications requiring stricter performance guarantees.Recently, several instances of deep learning applications have been shown to besubject to theoretical limitations of computability, undermining thefeasibility of performance guarantees when employed on real-world computers. Weextend the findings by studying computability in the deep learning frameworkfrom two perspectives: From an application viewpoint in the context ofclassification problems and a general limitation viewpoint in the context oftraining neural networks. In particular, we show restrictions on thealgorithmic solvability of classification problems that also render thealgorithmic detection of failure in computations in a general settinginfeasible. Subsequently, we prove algorithmic limitations in training deepneural networks even in cases where the underlying problem is well-behaved.Finally, we end with a positive observation, showing that in quantized versionsof classification and deep network training, computability restrictions do notarise or can be overcome to a certain degree.</description><author>Holger Boche, Vit Fojtik, Adalbert Fono, Gitta Kutyniok</author><pubDate>Mon, 12 Aug 2024 15:02:26 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.06212v1</guid></item><item><title>A mathematical perspective on Transformers</title><link>http://arxiv.org/abs/2312.10794v4</link><description>Transformers play a central role in the inner workings of large languagemodels. We develop a mathematical framework for analyzing Transformers based ontheir interpretation as interacting particle systems, which reveals thatclusters emerge in long time. Our study explores the underlying theory andoffers new perspectives for mathematicians as well as computer scientists.</description><author>Borjan Geshkovski, Cyril Letrouit, Yury Polyanskiy, Philippe Rigollet</author><pubDate>Mon, 12 Aug 2024 14:56:43 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.10794v4</guid></item><item><title>ControlNet-XS: Rethinking the Control of Text-to-Image Diffusion Models as Feedback-Control Systems</title><link>http://arxiv.org/abs/2312.06573v2</link><description>The field of image synthesis has made tremendous strides forward in the lastyears. Besides defining the desired output image with text-prompts, anintuitive approach is to additionally use spatial guidance in form of an image,such as a depth map. In state-of-the-art approaches, this guidance is realizedby a separate controlling model that controls a pre-trained image generationnetwork, such as a latent diffusion model. Understanding this process from acontrol system perspective shows that it forms a feedback-control system, wherethe control module receives a feedback signal from the generation process andsends a corrective signal back. When analysing existing systems, we observethat the feedback signals are timely sparse and have a small number of bits. Asa consequence, there can be long delays between newly generated features andthe respective corrective signals for these features. It is known that thisdelay is the most unwanted aspect of any control system. In this work, we takean existing controlling network (ControlNet) and change the communicationbetween the controlling network and the generation process to be ofhigh-frequency and with large-bandwidth. By doing so, we are able toconsiderably improve the quality of the generated images, as well as thefidelity of the control. Also, the controlling network needs noticeably fewerparameters and hence is about twice as fast during inference and training time.Another benefit of small-sized models is that they help to democratise ourfield and are likely easier to understand. We call our proposed networkControlNet-XS. When comparing with the state-of-the-art approaches, weoutperform them for pixel-level guidance, such as depth, canny-edges, andsemantic segmentation, and are on a par for loose keypoint-guidance of humanposes. All code and pre-trained models will be made publicly available.</description><author>Denis Zavadski, Johann-Friedrich Feiden, Carsten Rother</author><pubDate>Mon, 12 Aug 2024 14:52:49 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.06573v2</guid></item><item><title>Strategy Game-Playing with Size-Constrained State Abstraction</title><link>http://arxiv.org/abs/2408.06202v1</link><description>Playing strategy games is a challenging problem for artificial intelligence(AI). One of the major challenges is the large search space due to a diverseset of game components. In recent works, state abstraction has been applied tosearch-based game AI and has brought significant performance improvements.State abstraction techniques rely on reducing the search space, e.g., byaggregating similar states. However, the application of these abstractions ishindered because the quality of an abstraction is difficult to evaluate.Previous works hence abandon the abstraction in the middle of the search to notbias the search to a local optimum. This mechanism introduces a hyper-parameterto decide the time to abandon the current state abstraction. In this work, wepropose a size-constrained state abstraction (SCSA), an approach that limitsthe maximum number of nodes being grouped together. We found that with SCSA,the abstraction is not required to be abandoned. Our empirical results on $3$strategy games show that the SCSA agent outperforms the previous methods andyields robust performance over different games. Codes are open-sourced at\url{https://github.com/GAIGResearch/Stratega}.</description><author>Linjie Xu, Diego Perez-Liebana, Alexander Dockhorn</author><pubDate>Mon, 12 Aug 2024 14:50:18 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.06202v1</guid></item><item><title>Discover-then-Name: Task-Agnostic Concept Bottlenecks via Automated Concept Discovery</title><link>http://arxiv.org/abs/2407.14499v2</link><description>Concept Bottleneck Models (CBMs) have recently been proposed to address the'black-box' problem of deep neural networks, by first mapping images to ahuman-understandable concept space and then linearly combining concepts forclassification. Such models typically require first coming up with a set ofconcepts relevant to the task and then aligning the representations of afeature extractor to map to these concepts. However, even with powerfulfoundational feature extractors like CLIP, there are no guarantees that thespecified concepts are detectable. In this work, we leverage recent advances inmechanistic interpretability and propose a novel CBM approach -- calledDiscover-then-Name-CBM (DN-CBM) -- that inverts the typical paradigm: insteadof pre-selecting concepts based on the downstream classification task, we usesparse autoencoders to first discover concepts learnt by the model, and thenname them and train linear probes for classification. Our concept extractionstrategy is efficient, since it is agnostic to the downstream task, and usesconcepts already known to the model. We perform a comprehensive evaluationacross multiple datasets and CLIP architectures and show that our method yieldssemantically meaningful concepts, assigns appropriate names to them that makethem easy to interpret, and yields performant and interpretable CBMs. Codeavailable at https://github.com/neuroexplicit-saar/discover-then-name.</description><author>Sukrut Rao, Sweta Mahajan, Moritz Böhle, Bernt Schiele</author><pubDate>Mon, 12 Aug 2024 14:50:01 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.14499v2</guid></item><item><title>Dynamic Blocked Clause Elimination for Projected Model Counting</title><link>http://arxiv.org/abs/2408.06199v1</link><description>In this paper, we explore the application of blocked clause elimination forprojected model counting. This is the problem of determining the number ofmodels ||\exists X.{\Sigma}|| of a propositional formula {\Sigma} aftereliminating a given set X of variables existentially. Although blocked clauseelimination is a well-known technique for SAT solving, its direct applicationto model counting is challenging as in general it changes the number of models.However, we demonstrate, by focusing on projected variables during the blockedclause search, that blocked clause elimination can be leveraged whilepreserving the correct model count. To take advantage of blocked clauseelimination in an efficient way during model counting, a novel data structureand associated algorithms are introduced. Our proposed approach is implementedin the model counter d4. Our experiments demonstrate the computational benefitsof our new method of blocked clause elimination for projected model counting.</description><author>Jean-Marie Lagniez, Pierre Marquis, Armin Biere</author><pubDate>Mon, 12 Aug 2024 14:49:12 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.06199v1</guid></item><item><title>On the Generalization of Preference Learning with DPO</title><link>http://arxiv.org/abs/2408.03459v2</link><description>Large language models (LLMs) have demonstrated remarkable capabilities butoften struggle to align with human preferences, leading to harmful orundesirable outputs. Preference learning, which trains models to distinguishbetween preferred and non-preferred responses based on human feedback, hasbecome a crucial component for ensuring that LLMs align with human values.Despite the widespread adoption in real-world systems, a thorough theoreticalunderstanding of the generalization guarantees for these models remain lacking.This paper bridges that gap by introducing a new theoretical framework toanalyze the generalization guarantees of models trained with direct preferenceoptimization (DPO). While existing generalization theory often focuses onoverparameterized models achieving near-optimal loss or models independent ofthe training process, our framework rigorously assesses how well modelsgeneralize after a finite number of gradient steps, reflecting real-world LLMtraining practices. By analyzing the reward margin associated with each sampleand its trajectory throughout training, we can effectively bound thegeneralization error. We derive learning guarantees showing that, underspecific conditions, models trained with DPO can correctly discern preferredresponses on unseen data with high probability. These insights are empiricallyvalidated on contemporary LLMs, underscoring the practical relevance of ourtheoretical findings.</description><author>Shawn Im, Yixuan Li</author><pubDate>Mon, 12 Aug 2024 14:45:34 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.03459v2</guid></item><item><title>A secure and private ensemble matcher using multi-vault obfuscated templates</title><link>http://arxiv.org/abs/2404.05205v2</link><description>Generative AI has revolutionized modern machine learning by providingunprecedented realism, diversity, and efficiency in data generation. Thistechnology holds immense potential for biometrics, including for securingsensitive and personally identifiable information. Given the irrevocability ofbiometric samples and mounting privacy concerns, biometric template securityand secure matching are among the most sought-after features of modernbiometric systems. This paper proposes a novel obfuscation method usingGenerative AI to enhance biometric template security. Our approach utilizessynthetic facial images generated by a Generative Adversarial Network (GAN) as"random chaff points" within a secure vault system. Our method creates nsub-templates from the original template, each obfuscated with m GAN chaffpoints. During verification, s closest vectors to the biometric query areretrieved from each vault and combined to generate hash values, which are thencompared with the stored hash value. Thus, our method safeguards useridentities during the training and deployment phases by employing theGAN-generated synthetic images. Our protocol was tested using the AT&amp;T, GT, andLFW face datasets, achieving ROC areas under the curve of 0.99, 0.99, and 0.90,respectively. Our results demonstrate that the proposed method can maintainhigh accuracy and reasonable computational complexity comparable to thoseunprotected template methods while significantly enhancing security andprivacy, underscoring the potential of Generative AI in developing proactivedefensive strategies for biometric systems.</description><author>Babak Poorebrahim Gilkalaye, Shubhabrata Mukherjee, Reza Derakhshani</author><pubDate>Mon, 12 Aug 2024 14:42:48 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.05205v2</guid></item><item><title>Mutual Reasoning Makes Smaller LLMs Stronger Problem-Solvers</title><link>http://arxiv.org/abs/2408.06195v1</link><description>This paper introduces rStar, a self-play mutual reasoning approach thatsignificantly improves reasoning capabilities of small language models (SLMs)without fine-tuning or superior models. rStar decouples reasoning into aself-play mutual generation-discrimination process. First, a target SLMaugments the Monte Carlo Tree Search (MCTS) with a rich set of human-likereasoning actions to construct higher quality reasoning trajectories. Next,another SLM, with capabilities similar to the target SLM, acts as adiscriminator to verify each trajectory generated by the target SLM. Themutually agreed reasoning trajectories are considered mutual consistent, thusare more likely to be correct. Extensive experiments across five SLMsdemonstrate rStar can effectively solve diverse reasoning problems, includingGSM8K, GSM-Hard, MATH, SVAMP, and StrategyQA. Remarkably, rStar boosts GSM8Kaccuracy from 12.51% to 63.91% for LLaMA2-7B, from 36.46% to 81.88% forMistral-7B, from 74.53% to 91.13% for LLaMA3-8B-Instruct. Code will beavailable at https://github.com/zhentingqi/rStar.</description><author>Zhenting Qi, Mingyuan Ma, Jiahang Xu, Li Lyna Zhang, Fan Yang, Mao Yang</author><pubDate>Mon, 12 Aug 2024 14:42:13 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.06195v1</guid></item><item><title>FruitNeRF: A Unified Neural Radiance Field based Fruit Counting Framework</title><link>http://arxiv.org/abs/2408.06190v1</link><description>We introduce FruitNeRF, a unified novel fruit counting framework thatleverages state-of-the-art view synthesis methods to count any fruit typedirectly in 3D. Our framework takes an unordered set of posed images capturedby a monocular camera and segments fruit in each image. To make our systemindependent of the fruit type, we employ a foundation model that generatesbinary segmentation masks for any fruit. Utilizing both modalities, RGB andsemantic, we train a semantic neural radiance field. Through uniform volumesampling of the implicit Fruit Field, we obtain fruit-only point clouds. Byapplying cascaded clustering on the extracted point cloud, our approachachieves precise fruit count.The use of neural radiance fields providessignificant advantages over conventional methods such as object tracking oroptical flow, as the counting itself is lifted into 3D. Our method preventsdouble counting fruit and avoids counting irrelevant fruit.We evaluate ourmethodology using both real-world and synthetic datasets. The real-worlddataset consists of three apple trees with manually counted ground truths, abenchmark apple dataset with one row and ground truth fruit location, while thesynthetic dataset comprises various fruit types including apple, plum, lemon,pear, peach, and mango.Additionally, we assess the performance of fruitcounting using the foundation model compared to a U-Net.</description><author>Lukas Meyer, Andreas Gilson, Ute Schmidt, Marc Stamminger</author><pubDate>Mon, 12 Aug 2024 14:40:38 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.06190v1</guid></item><item><title>Time is Not Enough: Time-Frequency based Explanation for Time-Series Black-Box Models</title><link>http://arxiv.org/abs/2408.03636v2</link><description>Despite the massive attention given to time-series explanations due to theirextensive applications, a notable limitation in existing approaches is theirprimary reliance on the time-domain. This overlooks the inherent characteristicof time-series data containing both time and frequency features. In this work,we present Spectral eXplanation (SpectralX), an XAI framework that providestime-frequency explanations for time-series black-box classifiers. This easilyadaptable framework enables users to "plug-in" various perturbation-based XAImethods for any pre-trained time-series classification models to assess theirimpact on the explanation quality without having to modify the frameworkarchitecture. Additionally, we introduce Feature Importance Approximations(FIA), a new perturbation-based XAI method. These methods consist of featureinsertion, deletion, and combination techniques to enhance computationalefficiency and class-specific explanations in time-series classification tasks.We conduct extensive experiments in the generated synthetic dataset and variousUCR Time-Series datasets to first compare the explanation performance of FIAand other existing perturbation-based XAI methods in both time-domain andtime-frequency domain, and then show the superiority of our FIA in thetime-frequency domain with the SpectralX framework. Finally, we conduct a userstudy to confirm the practicality of our FIA in SpectralX framework forclass-specific time-frequency based time-series explanations. The source codeis available in https://github.com/gustmd0121/Time_is_not_Enough</description><author>Hyunseung Chung, Sumin Jo, Yeonsu Kwon, Edward Choi</author><pubDate>Mon, 12 Aug 2024 14:39:56 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.03636v2</guid></item><item><title>Improving the Evaluation and Actionability of Explanation Methods for Multivariate Time Series Classification</title><link>http://arxiv.org/abs/2406.12507v2</link><description>Explanation for Multivariate Time Series Classification (MTSC) is animportant topic that is under explored. There are very few quantitativeevaluation methodologies and even fewer examples of actionable explanation,where the explanation methods are shown to objectively improve specificcomputational tasks on time series data. In this paper we focus on analyzingInterpretTime, a recent evaluation methodology for attribution methods appliedto MTSC. We showcase some significant weaknesses of the original methodologyand propose ideas to improve both its accuracy and efficiency. Unlike relatedwork, we go beyond evaluation and also showcase the actionability of theproduced explainer ranking, by using the best attribution methods for the taskof channel selection in MTSC. We find that perturbation-based methods such asSHAP and Feature Ablation work well across a set of datasets, classifiers andtasks and outperform gradient-based methods. We apply the best rankedexplainers to channel selection for MTSC and show significant data sizereduction and improved classifier accuracy.</description><author>Davide Italo Serramazza, Thach Le Nguyen, Georgiana Ifrim</author><pubDate>Mon, 12 Aug 2024 14:38:18 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.12507v2</guid></item><item><title>Insights from the Usage of the Ansible Lightspeed Code Completion Service</title><link>http://arxiv.org/abs/2402.17442v2</link><description>The availability of Large Language Models (LLMs) which can generate code, hasmade it possible to create tools that improve developer productivity.Integrated development environments or IDEs which developers use to writesoftware are often used as an interface to interact with LLMs. Although manysuch tools have been released, almost all of them focus on general-purposeprogramming languages. Domain-specific languages, such as those crucial forInformation Technology (IT) automation, have not received much attention.Ansible is one such YAML-based IT automation-specific language. AnsibleLightspeed is an LLM-based service designed explicitly to generate Ansible YAMLgiven natural language prompt. This paper first presents the design and implementation of the AnsibleLightspeed service. We then evaluate its utility to developers using diverseindicators, including extended utilization, analysis of user rejectedsuggestions, as well as analysis of user sentiments. The analysis is based ondata collected for 10,696 real users including 3,910 returning users. The codefor Ansible Lightspeed service and the analysis framework is made available forothers to use. To our knowledge, our study is the first to involve thousands of users inevaluating code assistants for domain-specific languages. We propose animproved version of user acceptance rate and we are the first code completiontool to present N-Day user retention figures. With our findings we provideinsights into the effectiveness of small, dedicated models in a domain-specificcontext. We hope this work serves as a reference for software engineering andmachine learning researchers exploring code completion services fordomain-specific languages in particular and programming languages in general.</description><author>Priyam Sahoo, Saurabh Pujar, Ganesh Nalawade, Richard Gebhardt, Louis Mandel, Luca Buratti</author><pubDate>Mon, 12 Aug 2024 14:36:32 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.17442v2</guid></item><item><title>Improving Structural Diversity of Blackbox LLMs via Chain-of-Specification Prompting</title><link>http://arxiv.org/abs/2408.06186v1</link><description>The capability to generate diverse text is a key challenge facing largelanguage models (LLMs). Thus far, diversity has been studied via metrics suchas $n$-gram diversity or diversity of BERT embeddings. However, for these kindsof diversity, the user has little control over the dimensions along whichdiversity is considered. For example, in the poetry domain, one might desirediversity in terms of rhyme and meter, whereas in the code domain, one mightdesire diversity in terms of the kinds of expressions used to solve a problem.We propose a diversity metric called structural diversity, where the userprovides a mapping from generated text to features capturing the kinds ofdiversity that they care about. In addition, we propose a novel strategy calledchain-of-specification (CoS) prompting for improving diversity by first havingthe LLM generate a specification encoding one instance of structural features,and then prompting the LLM to generate text that satisfies these features;notably, our strategy works with blackbox LLMs. In our experiments, we showthat for structural diversity in the poetry and code domains, CoS significantlyimproves diversity compared to several baselines.</description><author>Halley Young, Yimeng Zeng, Jacob Gardner, Osbert Bastani</author><pubDate>Mon, 12 Aug 2024 14:34:06 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.06186v1</guid></item><item><title>Centralized and Federated Heart Disease Classification Models Using UCI Dataset and their Shapley-value Based Interpretability</title><link>http://arxiv.org/abs/2408.06183v1</link><description>Cardiovascular diseases are a leading cause of mortality worldwide,highlighting the need for accurate diagnostic methods. This study benchmarkscentralized and federated machine learning algorithms for heart diseaseclassification using the UCI dataset which includes 920 patient records fromfour hospitals in the USA, Hungary and Switzerland. Our benchmark is supportedby Shapley-value interpretability analysis to quantify features' importance forclassification. In the centralized setup, various binary classificationalgorithms are trained on pooled data, with a support vector machine (SVM)achieving the highest testing accuracy of 83.3\%, surpassing the establishedbenchmark of 78.7\% with logistic regression. Additionally, federated learningalgorithms with four clients (hospitals) are explored, leveraging the dataset'snatural partition to enhance privacy without sacrificing accuracy. FederatedSVM, an uncommon approach in the literature, achieves a top testing accuracy of73.8\%. Our interpretability analysis aligns with existing medical knowledge ofheart disease indicators. Overall, this study establishes a benchmark forefficient and interpretable pre-screening tools for heart disease whilemaintaining patients' privacy.</description><author>Mario Padilla Rodriguez, Mohamed Nafea</author><pubDate>Mon, 12 Aug 2024 14:29:54 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.06183v1</guid></item><item><title>LPGen: Enhancing High-Fidelity Landscape Painting Generation through Diffusion Model</title><link>http://arxiv.org/abs/2407.17229v3</link><description>Generating landscape paintings expands the possibilities of artisticcreativity and imagination. Traditional landscape painting methods involveusing ink or colored ink on rice paper, which requires substantial time andeffort. These methods are susceptible to errors and inconsistencies and lackprecise control over lines and colors. This paper presents LPGen, ahigh-fidelity, controllable model for landscape painting generation,introducing a novel multi-modal framework that integrates image prompts intothe diffusion model. We extract its edges and contours by computing canny edgesfrom the target landscape image. These, along with natural language textprompts and drawing style references, are fed into the latent diffusion modelas conditions. We implement a decoupled cross-attention strategy to ensurecompatibility between image and text prompts, facilitating multi-modal imagegeneration. A decoder generates the final image. Quantitative and qualitativeanalyses demonstrate that our method outperforms existing approaches inlandscape painting generation and exceeds the current state-of-the-art. TheLPGen network effectively controls the composition and color of landscapepaintings, generates more accurate images, and supports further research indeep learning-based landscape painting generation.</description><author>Wanggong Yang, Xiaona Wang, Yingrui Qiu, Yifei Zhao</author><pubDate>Mon, 12 Aug 2024 14:28:42 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.17229v3</guid></item><item><title>Investigating the ability of deep learning to predict Welding Depth and Pore Volume in Hairpin Welding</title><link>http://arxiv.org/abs/2312.01606v4</link><description>To advance quality assurance in the welding process, this study presents adeep learning DL model that enables the prediction of two critical welds' KeyPerformance Characteristics (KPCs): welding depth and average pore volume. Inthe proposed approach, a wide range of laser welding Key Input Characteristics(KICs) is utilized, including welding beam geometries, welding feed rates, pathrepetitions for weld beam geometries, and bright light weld ratios for allpaths, all of which were obtained from hairpin welding experiments. Two DLnetworks are employed with multiple hidden dense layers and linear activationfunctions to investigate the capabilities of deep neural networks in capturingthe complex nonlinear relationships between the welding input and outputvariables (KPCs and KICs). Applying DL networks to the small numericalexperimental hairpin welding dataset has shown promising results, achievingMean Absolute Error (MAE) values 0.1079 for predicting welding depth and 0.0641for average pore volume. This, in turn, promises significant advantages incontrolling welding outcomes, moving beyond the current trend of relying onlyon defect classification in weld monitoring, to capture the correlation betweenthe weld parameters and weld geometries.</description><author>Amena Darwish, Stefan Ericson, Rohollah Ghasemi, Tobias Andersson, Dan Lönn, Andreas Andersson Lassila, Kent Salomonsson</author><pubDate>Mon, 12 Aug 2024 14:26:38 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.01606v4</guid></item><item><title>Localising the Seizure Onset Zone from Single-Pulse Electrical Stimulation Responses with a CNN Transformer</title><link>http://arxiv.org/abs/2403.20324v2</link><description>Epilepsy is one of the most common neurological disorders, often requiringsurgical intervention when medication fails to control seizures. For effectivesurgical outcomes, precise localisation of the epileptogenic focus - oftenapproximated through the Seizure Onset Zone (SOZ) - is critical yet remains achallenge. Active probing through electrical stimulation is already standardclinical practice for identifying epileptogenic areas. Our study advances theapplication of deep learning for SOZ localisation using Single-Pulse ElectricalStimulation (SPES) responses, with two key contributions. Firstly, we implementan existing deep learning model to compare two SPES analysis paradigms:divergent and convergent. These paradigms evaluate outward and inward effectiveconnections, respectively. We assess the generalisability of these models tounseen patients and electrode placements using held-out test sets. Our findingsreveal a notable improvement in moving from a divergent (AUROC: 0.574) to aconvergent approach (AUROC: 0.666), marking the first application of the latterin this context. Secondly, we demonstrate the efficacy of CNN Transformers withcross-channel attention in handling heterogeneous electrode placements,increasing the AUROC to 0.730. These findings represent a significant step inmodelling patient-specific intracranial EEG electrode placements in SPES.Future work will explore integrating these models into clinical decision-makingprocesses to bridge the gap between deep learning research and practicalhealthcare applications.</description><author>Jamie Norris, Aswin Chari, Dorien van Blooijs, Gerald Cooray, Karl Friston, Martin Tisdall, Richard Rosch</author><pubDate>Mon, 12 Aug 2024 14:19:44 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.20324v2</guid></item><item><title>Zero-shot 3D Segmentation of Abdominal Organs in CT Scans Using Segment Anything Model 2: Adapting Video Tracking Capabilities for 3D Medical Imaging</title><link>http://arxiv.org/abs/2408.06170v1</link><description>Purpose: This study aimed to evaluate the zero-shot performance of SegmentAnything Model 2 (SAM 2) in 3D segmentation of abdominal organs in CT scans,leveraging its video tracking capabilities for volumetric medical imaging.Materials and Methods: Using a subset of the TotalSegmentator CT dataset(n=123) from 8 different institutions, we assessed SAM 2's ability to segment 8abdominal organs. Segmentation was initiated from three different Z-coordinatelevels (caudal, mid, and cranial levels) of each organ. Performance wasmeasured using the Dice similarity coefficient (DSC). We also analyzed organvolumes to contextualize the results. Results: As a zero-shot approach, largerorgans with clear boundaries demonstrated high segmentation performance, withmean(median) DSCs as follows: liver 0.821(0.898), left kidney 0.870(0.921),right kidney 0.862(0.935), and spleen 0.891(0.932). Smaller or less definedstructures showed lower performance: gallbladder 0.531(0.590), pancreas0.361(0.359), and adrenal glands 0.203-0.308(0.109-0.231). Significantdifferences in DSC were observed depending on the starting initial slice ofsegmentation for different organs. A moderate positive correlation was observedbetween volume size and DSCs (Spearman's rs = 0.731, P &lt;.001 at caudal-level).DSCs exhibited high variability within organs, ranging from near 0 to almost1.0, indicating substantial inconsistency in segmentation performance betweenscans. Conclusion: SAM 2 demonstrated promising zero-shot performance insegmenting certain abdominal organs in CT scans, particularly larger organswith clear boundaries. The model's ability to segment previously unseen targetswithout additional training highlights its potential for cross-domaingeneralization in medical imaging. However, improvements are needed for smallerand less defined structures.</description><author>Yosuke Yamagishi, Shouhei Hanaoka, Tomohiro Kikuchi, Takahiro Nakao, Yuta Nakamura, Yukihiro Nomura, Soichiro Miki, Takeharu Yoshikawa, Osamu Abe</author><pubDate>Mon, 12 Aug 2024 14:16:10 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.06170v1</guid></item><item><title>Fakes of Varying Shades: How Warning Affects Human Perception and Engagement Regarding LLM Hallucinations</title><link>http://arxiv.org/abs/2404.03745v3</link><description>The widespread adoption and transformative effects of large language models(LLMs) have sparked concerns regarding their capacity to produce inaccurate andfictitious content, referred to as `hallucinations'. Given the potential risksassociated with hallucinations, humans should be able to identify them. Thisresearch aims to understand the human perception of LLM hallucinations bysystematically varying the degree of hallucination (genuine, minorhallucination, major hallucination) and examining its interaction with warning(i.e., a warning of potential inaccuracies: absent vs. present). Participants(N=419) from Prolific rated the perceived accuracy and engaged with content(e.g., like, dislike, share) in a Q/A format. Participants ranked content astruthful in the order of genuine, minor hallucination, and major hallucination,and user engagement behaviors mirrored this pattern. More importantly, weobserved that warning improved the detection of hallucination withoutsignificantly affecting the perceived truthfulness of genuine content. Weconclude by offering insights for future tools to aid human detection ofhallucinations. All survey materials, demographic questions, and post-sessionquestions are available at:https://github.com/MahjabinNahar/fakes-of-varying-shades-survey-materials</description><author>Mahjabin Nahar, Haeseung Seo, Eun-Ju Lee, Aiping Xiong, Dongwon Lee</author><pubDate>Mon, 12 Aug 2024 14:13:15 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.03745v3</guid></item><item><title>Blind-Match: Efficient Homomorphic Encryption-Based 1:N Matching for Privacy-Preserving Biometric Identification</title><link>http://arxiv.org/abs/2408.06167v1</link><description>We present Blind-Match, a novel biometric identification system thatleverages homomorphic encryption (HE) for efficient and privacy-preserving 1:Nmatching. Blind-Match introduces a HE-optimized cosine similarity computationmethod, where the key idea is to divide the feature vector into smaller partsfor processing rather than computing the entire vector at once. By optimizingthe number of these parts, Blind-Match minimizes execution time while ensuringdata privacy through HE. Blind-Match achieves superior performance compared tostate-of-the-art methods across various biometric datasets. On the LFW facedataset, Blind-Match attains a 99.63% Rank-1 accuracy with a 128-dimensionalfeature vector, demonstrating its robustness in face recognition tasks. Forfingerprint identification, Blind-Match achieves a remarkable 99.55% Rank-1accuracy on the PolyU dataset, even with a compact 16-dimensional featurevector, significantly outperforming the state-of-the-art method, Blind-Touch,which achieves only 59.17%. Furthermore, Blind-Match showcases practicalefficiency in large-scale biometric identification scenarios, such as NaverCloud's FaceSign, by processing 6,144 biometric samples in 0.74 seconds using a128-dimensional feature vector.</description><author>Hyunmin Choi, Jiwon Kim, Chiyoung Song, Simon S. Woo, Hyoungshick Kim</author><pubDate>Mon, 12 Aug 2024 14:13:08 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.06167v1</guid></item><item><title>XMainframe: A Large Language Model for Mainframe Modernization</title><link>http://arxiv.org/abs/2408.04660v2</link><description>Mainframe operating systems, despite their inception in the 1940s, continueto support critical sectors like finance and government. However, these systemsare often viewed as outdated, requiring extensive maintenance andmodernization. Addressing this challenge necessitates innovative tools that canunderstand and interact with legacy codebases. To this end, we introduceXMainframe, a state-of-the-art large language model (LLM) specifically designedwith knowledge of mainframe legacy systems and COBOL codebases. Our solutioninvolves the creation of an extensive data collection pipeline to producehigh-quality training datasets, enhancing XMainframe's performance in thisspecialized domain. Additionally, we present MainframeBench, a comprehensivebenchmark for assessing mainframe knowledge, including multiple-choicequestions, question answering, and COBOL code summarization. Our empiricalevaluations demonstrate that XMainframe consistently outperforms existingstate-of-the-art LLMs across these tasks. Specifically, XMainframe achieves 30%higher accuracy than DeepSeek-Coder on multiple-choice questions, doubles theBLEU score of Mixtral-Instruct 8x7B on question answering, and scores six timeshigher than GPT-3.5 on COBOL summarization. Our work highlights the potentialof XMainframe to drive significant advancements in managing and modernizinglegacy systems, thereby enhancing productivity and saving time for softwaredevelopers.</description><author>Anh T. V. Dau, Hieu Trung Dao, Anh Tuan Nguyen, Hieu Trung Tran, Phong X. Nguyen, Nghi D. Q. Bui</author><pubDate>Mon, 12 Aug 2024 14:12:23 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.04660v2</guid></item><item><title>MC-GPT: Empowering Vision-and-Language Navigation with Memory Map and Reasoning Chains</title><link>http://arxiv.org/abs/2405.10620v2</link><description>In the Vision-and-Language Navigation (VLN) task, the agent is required tonavigate to a destination following a natural language instruction. Whilelearning-based approaches have been a major solution to the task, they sufferfrom high training costs and lack of interpretability. Recently, Large LanguageModels (LLMs) have emerged as a promising tool for VLN due to their stronggeneralization capabilities. However, existing LLM-based methods facelimitations in memory construction and diversity of navigation strategies. Toaddress these challenges, we propose a suite of techniques. Firstly, weintroduce a method to maintain a topological map that stores navigationhistory, retaining information about viewpoints, objects, and their spatialrelationships. This map also serves as a global action space. Additionally, wepresent a Navigation Chain of Thoughts module, leveraging human navigationexamples to enrich navigation strategy diversity. Finally, we establish apipeline that integrates navigational memory and strategies with perception andaction prediction modules. Experimental results on the REVERIE and R2R datasetsshow that our method effectively enhances the navigation ability of the LLM andimproves the interpretability of navigation reasoning.</description><author>Zhaohuan Zhan, Lisha Yu, Sijie Yu, Guang Tan</author><pubDate>Mon, 12 Aug 2024 14:07:32 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.10620v2</guid></item><item><title>It's Morphing Time: Unleashing the Potential of Multiple LLMs via Multi-objective Optimization</title><link>http://arxiv.org/abs/2407.00487v2</link><description>In this paper, we introduce a novel approach for large language model mergingvia black-box multi-objective optimization algorithms. The goal of modelmerging is to combine multiple models, each excelling in different tasks, intoa single model that outperforms any of the individual source models. However,model merging faces two significant challenges: First, existing methods relyheavily on human intuition and customized strategies to tackle multiple tasks.Second, it's difficult to search for the great model merging configuration inlimited evaluations. To address these challenges, we propose a multi-objectiveoptimization based model merging method named MM-MO. The proposed method canautomatically search merging configurations for multiple tasks withmulti-objective optimization algorithms. Moreover, to obtain high-quality modelmerging configurations within a limited number of evaluation iterations, wehave made several improvements to multi-objective Bayesian optimizationspecifically for model merging scenarios. First, we introduced a weak-to-strongmethod to improve the acquisition strategy. Second, we employed Fisherinformation to select configurations, further increasing the chances ofdiscovering superior model merging configurations. Third, we designed asparsity metric as an additional optimization objective to enhance the model'sgeneralization performance across different tasks. We conducted comprehensiveexperiments with other mainstream model merging methods, demonstrating that ourmethod consistently outperforms them. Moreover, performance improvements areobserved even on the tasks not explicitly targeted as optimization objectives,indicating that our method enhances the overall potential of the model. ...</description><author>Bingdong Li, Zixiang Di, Yanting Yang, Hong Qian, Peng Yang, Hao Hao, Ke Tang, Aimin Zhou</author><pubDate>Mon, 12 Aug 2024 14:06:48 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.00487v2</guid></item><item><title>ACCELERATION: Sequentially-scanning DECT Imaging Using High Temporal Resolution Image Reconstruction And Temporal Extrapolation</title><link>http://arxiv.org/abs/2408.06163v1</link><description>Dual-energy computed tomography (DECT) has been widely used to obtainquantitative elemental composition of imaged subjects for personalized andprecise medical diagnosis. Compared with existing high-end DECT leveragingadvanced X-ray source and/or detector technologies, the use of thesequentially-scanning data acquisition scheme to implement DECT may makebroader impact on clinical practice because this scheme requires no specializedhardware designs. However, since the concentration of iodinated contrast agentin the imaged subject varies over time, sequentially-scanned data sets acquiredat two tube potentials are temporally inconsistent. As existing materialdecomposition approaches for DECT assume that the data sets acquired at twotube potentials are temporally consistent, the violation of this assumptionresults in inaccurate quantification accuracy of iodine concentration. In thiswork, we developed a technique to achieve sequentially-scanning DECT imagingusing high temporal resolution image reconstruction and temporal extrapolation,ACCELERATION in short, to address the technical challenge induced by temporalinconsistency of sequentially-scanned data sets and improve iodinequantification accuracy in sequentially-scanning DECT. ACCELERATION has beenvalidated and evaluated using numerical simulation data sets generated fromclinical human subject exams. Results demonstrated the improvement of iodinequantification accuracy using ACCELERATION.</description><author>Qiaoxin Li, Dong Liang, Yinsheng Li</author><pubDate>Mon, 12 Aug 2024 14:03:17 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.06163v1</guid></item><item><title>Rag and Roll: An End-to-End Evaluation of Indirect Prompt Manipulations in LLM-based Application Frameworks</title><link>http://arxiv.org/abs/2408.05025v2</link><description>Retrieval Augmented Generation (RAG) is a technique commonly used to equipmodels with out of distribution knowledge. This process involves collecting,indexing, retrieving, and providing information to an LLM for generatingresponses. Despite its growing popularity due to its flexibility and low cost,the security implications of RAG have not been extensively studied. The datafor such systems are often collected from public sources, providing an attackera gateway for indirect prompt injections to manipulate the responses of themodel. In this paper, we investigate the security of RAG systems againstend-to-end indirect prompt manipulations. First, we review existing RAGframework pipelines, deriving a prototypical architecture and identifyingcritical parameters. We then examine prior works searching for techniques thatattackers can use to perform indirect prompt manipulations. Finally, weimplemented Rag 'n Roll, a framework to determine the effectiveness of attacksagainst end-to-end RAG applications. Our results show that existing attacks aremostly optimized to boost the ranking of malicious documents during theretrieval phase. However, a higher rank does not immediately translate into areliable attack. Most attacks, against various configurations, settle around a40% success rate, which could rise to 60% when considering ambiguous answers assuccessful attacks (those that include the expected benign one as well).Additionally, when using unoptimized documents, attackers deploying two of them(or more) for a target query can achieve similar results as those usingoptimized ones. Finally, exploration of the configuration space of a RAG showedlimited impact in thwarting the attacks, where the most successful combinationseverely undermines functionality.</description><author>Gianluca De Stefano, Lea Schönherr, Giancarlo Pellegrino</author><pubDate>Mon, 12 Aug 2024 13:57:42 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.05025v2</guid></item><item><title>OmniCLIP: Adapting CLIP for Video Recognition with Spatial-Temporal Omni-Scale Feature Learning</title><link>http://arxiv.org/abs/2408.06158v1</link><description>Recent Vision-Language Models (VLMs) \textit{e.g.} CLIP have made greatprogress in video recognition. Despite the improvement brought by the strongvisual backbone in extracting spatial features, CLIP still falls short incapturing and integrating spatial-temporal features which is essential forvideo recognition. In this paper, we propose OmniCLIP, a framework that adaptsCLIP for video recognition by focusing on learning comprehensive featuresencompassing spatial, temporal, and dynamic spatial-temporal scales, which werefer to as omni-scale features. This is achieved through the design ofspatial-temporal blocks that include parallel temporal adapters (PTA), enablingefficient temporal modeling. Additionally, we introduce a self-prompt generator(SPG) module to capture dynamic object spatial features. The synergy betweenPTA and SPG allows OmniCLIP to discern varying spatial information acrossframes and assess object scales over time. We have conducted extensiveexperiments in supervised video recognition, few-shot video recognition, andzero-shot recognition tasks. The results demonstrate the effectiveness of ourmethod, especially with OmniCLIP achieving a top-1 accuracy of 74.30\% onHMDB51 in a 16-shot setting, surpassing the recent MotionPrompt approach evenwith full training data. The code is available at\url{https://github.com/XiaoBuL/OmniCLIP}.</description><author>Mushui Liu, Bozheng Li, Yunlong Yu</author><pubDate>Mon, 12 Aug 2024 13:55:46 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.06158v1</guid></item><item><title>Novel View Synthesis from a Single Image with Pretrained Diffusion Guidance</title><link>http://arxiv.org/abs/2408.06157v1</link><description>Recent 3D novel view synthesis (NVS) methods are limited tosingle-object-centric scenes generated from new viewpoints and struggle withcomplex environments. They often require extensive 3D data for training,lacking generalization beyond training distribution. Conversely, 3D-freemethods can generate text-controlled views of complex, in-the-wild scenes usinga pretrained stable diffusion model without tedious fine-tuning, but lackcamera control. In this paper, we introduce HawkI++, a method capable ofgenerating camera-controlled viewpoints from a single input image. HawkI++excels in handling complex and diverse scenes without additional 3D data orextensive training. It leverages widely available pretrained NVS models forweak guidance, integrating this knowledge into a 3D-free view synthesisapproach to achieve the desired results efficiently. Our experimental resultsdemonstrate that HawkI++ outperforms existing models in both qualitative andquantitative evaluations, providing high-fidelity and consistent novel viewsynthesis at desired camera angles across a wide variety of scenes.</description><author>Taewon Kang, Divya Kothandaraman, Dinesh Manocha, Ming C. Lin</author><pubDate>Mon, 12 Aug 2024 13:53:40 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.06157v1</guid></item><item><title>ViscoNet: Bridging and Harmonizing Visual and Textual Conditioning for ControlNet</title><link>http://arxiv.org/abs/2312.03154v2</link><description>This paper introduces ViscoNet, a novel one-branch-adapter architecture forconcurrent spatial and visual conditioning. Our lightweight model requirestrainable parameters and dataset size multiple orders of magnitude smaller thanthe current state-of-the-art IP-Adapter. However, our method successfullypreserves the generative power of the frozen text-to-image (T2I) backbone.Notably, it excels in addressing mode collapse, a pervasive issue previouslyoverlooked. Our novel architecture demonstrates outstanding capabilities inachieving a harmonious visual-text balance, unlocking unparalleled versatilityin various human image generation tasks, including pose re-targeting, virtualtry-on, stylization, person re-identification, and textile transfer.Demo andcode are available from project page https://soon-yau.github.io/visconet/ .</description><author>Soon Yau Cheong, Armin Mustafa, Andrew Gilbert</author><pubDate>Mon, 12 Aug 2024 13:53:17 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.03154v2</guid></item><item><title>Palantir: Towards Efficient Super Resolution for Ultra-high-definition Live Streaming</title><link>http://arxiv.org/abs/2408.06152v1</link><description>Neural enhancement through super-resolution deep neural networks opens up newpossibilities for ultra-high-definition live streaming over existing encodingand networking infrastructure. Yet, the heavy SR DNN inference overhead leadsto severe deployment challenges. To reduce the overhead, existing systemspropose to apply DNN-based SR only on selected anchor frames while upscalingnon-anchor frames via the lightweight reusing-based SR approach. However,frame-level scheduling is coarse-grained and fails to deliver optimalefficiency. In this work, we propose Palantir, the first neural-enhanced UHDlive streaming system with fine-grained patch-level scheduling. In thepresented solutions, two novel techniques are incorporated to make goodscheduling decisions for inference overhead optimization and reduce thescheduling latency. Firstly, under the guidance of our pioneering andtheoretical analysis, Palantir constructs a directed acyclic graph (DAG) forlightweight yet accurate quality estimation under any possible anchor patchset. Secondly, to further optimize the scheduling latency, Palantir improvesparallelizability by refactoring the computation subprocedure of the estimationprocess into a sparse matrix-matrix multiplication operation. The evaluationresults suggest that Palantir incurs a negligible scheduling latency accountingfor less than 5.7% of the end-to-end latency requirement. When compared to thestate-of-the-art real-time frame-level scheduling strategy, Palantir reducesthe energy overhead of SR-integrated mobile clients by 38.1% at most (and 22.4%on average) and the monetary costs of cloud-based SR by 80.1% at most (and38.4% on average).</description><author>Xinqi Jin, Zhui Zhu, Xikai Sun, Fan Dang, Jiangchuan Liu, Jingao Xu, Kebin Liu, Xinlei Chen, Yunhao Liu</author><pubDate>Mon, 12 Aug 2024 13:48:06 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.06152v1</guid></item><item><title>LipidBERT: A Lipid Language Model Pre-trained on METiS de novo Lipid Library</title><link>http://arxiv.org/abs/2408.06150v1</link><description>In this study, we generate and maintain a database of 10 million virtuallipids through METiS's in-house de novo lipid generation algorithms and lipidvirtual screening techniques. These virtual lipids serve as a corpus forpre-training, lipid representation learning, and downstream task knowledgetransfer, culminating in state-of-the-art LNP property prediction performance.We propose LipidBERT, a BERT-like model pre-trained with the Masked LanguageModel (MLM) and various secondary tasks. Additionally, we compare theperformance of embeddings generated by LipidBERT and PhatGPT, our GPT-likelipid generation model, on downstream tasks. The proposed bilingual LipidBERTmodel operates in two languages: the language of ionizable lipid pre-training,using in-house dry-lab lipid structures, and the language of LNP fine-tuning,utilizing in-house LNP wet-lab data. This dual capability positions LipidBERTas a key AI-based filter for future screening tasks, including new versions ofMETiS de novo lipid libraries and, more importantly, candidates for in vivotesting for orgran-targeting LNPs. To the best of our knowledge, this is thefirst successful demonstration of the capability of a pre-trained languagemodel on virtual lipids and its effectiveness in downstream tasks using web-labdata. This work showcases the clever utilization of METiS's in-house de novolipid library as well as the power of dry-wet lab integration.</description><author>Tianhao Yu, Cai Yao, Zhuorui Sun, Feng Shi, Lin Zhang, Kangjie Lyu, Xuan Bai, Andong Liu, Xicheng Zhang, Jiali Zou, Wenshou Wang, Chris Lai, Kai Wang</author><pubDate>Mon, 12 Aug 2024 13:44:24 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.06150v1</guid></item><item><title>Efficient and Scalable Point Cloud Generation with Sparse Point-Voxel Diffusion Models</title><link>http://arxiv.org/abs/2408.06145v1</link><description>We propose a novel point cloud U-Net diffusion architecture for 3D generativemodeling capable of generating high-quality and diverse 3D shapes whilemaintaining fast generation times. Our network employs a dual-brancharchitecture, combining the high-resolution representations of points with thecomputational efficiency of sparse voxels. Our fastest variant outperforms allnon-diffusion generative approaches on unconditional shape generation, the mostpopular benchmark for evaluating point cloud generative models, while ourlargest model achieves state-of-the-art results among diffusion methods, with aruntime approximately 70% of the previously state-of-the-art PVD. Beyondunconditional generation, we perform extensive evaluations, includingconditional generation on all categories of ShapeNet, demonstrating thescalability of our model to larger datasets, and implicit generation whichallows our network to produce high quality point clouds on fewer timesteps,further decreasing the generation time. Finally, we evaluate the architecture'sperformance in point cloud completion and super-resolution. Our model excels inall tasks, establishing it as a state-of-the-art diffusion U-Net for pointcloud generative modeling. The code is publicly available athttps://github.com/JohnRomanelis/SPVD.git.</description><author>Ioannis Romanelis, Vlassios Fotis, Athanasios Kalogeras, Christos Alexakos, Konstantinos Moustakas, Adrian Munteanu</author><pubDate>Mon, 12 Aug 2024 13:41:47 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.06145v1</guid></item><item><title>Med42-v2: A Suite of Clinical LLMs</title><link>http://arxiv.org/abs/2408.06142v1</link><description>Med42-v2 introduces a suite of clinical large language models (LLMs) designedto address the limitations of generic models in healthcare settings. Thesemodels are built on Llama3 architecture and fine-tuned using specializedclinical data. They underwent multi-stage preference alignment to effectivelyrespond to natural prompts. While generic models are often preference-alignedto avoid answering clinical queries as a precaution, Med42-v2 is specificallytrained to overcome this limitation, enabling its use in clinical settings.Med42-v2 models demonstrate superior performance compared to the originalLlama3 models in both 8B and 70B parameter configurations and GPT-4 acrossvarious medical benchmarks. These LLMs are developed to understand clinicalqueries, perform reasoning tasks, and provide valuable assistance in clinicalenvironments. The models are now publicly available at\href{https://huggingface.co/m42-health}{https://huggingface.co/m42-health}.</description><author>Clément Christophe, Praveen K Kanithi, Tathagata Raha, Shadab Khan, Marco AF Pimentel</author><pubDate>Mon, 12 Aug 2024 13:37:31 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.06142v1</guid></item><item><title>MR3D-Net: Dynamic Multi-Resolution 3D Sparse Voxel Grid Fusion for LiDAR-Based Collective Perception</title><link>http://arxiv.org/abs/2408.06137v1</link><description>The safe operation of automated vehicles depends on their ability to perceivethe environment comprehensively. However, occlusion, sensor range, andenvironmental factors limit their perception capabilities. To overcome theselimitations, collective perception enables vehicles to exchange information.However, fusing this exchanged information is a challenging task. Early fusionapproaches require large amounts of bandwidth, while intermediate fusionapproaches face interchangeability issues. Late fusion of shared detections iscurrently the only feasible approach. However, it often results in inferiorperformance due to information loss. To address this issue, we proposeMR3D-Net, a dynamic multi-resolution 3D sparse voxel grid fusion backbonearchitecture for LiDAR-based collective perception. We show that sparse voxelgrids at varying resolutions provide a meaningful and compact environmentrepresentation that can adapt to the communication bandwidth. MR3D-Net achievesstate-of-the-art performance on the OPV2V 3D object detection benchmark whilereducing the required bandwidth by up to 94% compared to early fusion. Code isavailable at https://github.com/ekut-es/MR3D-Net</description><author>Sven Teufel, Jörg Gamerdinger, Georg Volk, Oliver Bringmann</author><pubDate>Mon, 12 Aug 2024 13:27:11 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.06137v1</guid></item><item><title>Strong and weak alignment of large language models with human values</title><link>http://arxiv.org/abs/2408.04655v2</link><description>Minimizing negative impacts of Artificial Intelligent (AI) systems on humansocieties without human supervision requires them to be able to align withhuman values. However, most current work only addresses this issue from atechnical point of view, e.g., improving current methods relying onreinforcement learning from human feedback, neglecting what it means and isrequired for alignment to occur. Here, we propose to distinguish strong andweak value alignment. Strong alignment requires cognitive abilities (eitherhuman-like or different from humans) such as understanding and reasoning aboutagents' intentions and their ability to causally produce desired effects. Weargue that this is required for AI systems like large language models (LLMs) tobe able to recognize situations presenting a risk that human values may beflouted. To illustrate this distinction, we present a series of prompts showingChatGPT's, Gemini's and Copilot's failures to recognize some of thesesituations. We moreover analyze word embeddings to show that the nearestneighbors of some human values in LLMs differ from humans' semanticrepresentations. We then propose a new thought experiment that we call "theChinese room with a word transition dictionary", in extension of John Searle'sfamous proposal. We finally mention current promising research directionstowards a weak alignment, which could produce statistically satisfying answersin a number of common situations, however so far without ensuring any truthvalue.</description><author>Mehdi Khamassi, Marceau Nahon, Raja Chatila</author><pubDate>Mon, 12 Aug 2024 13:20:36 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.04655v2</guid></item><item><title>XLAVS-R: Cross-Lingual Audio-Visual Speech Representation Learning for Noise-Robust Speech Perception</title><link>http://arxiv.org/abs/2403.14402v2</link><description>Speech recognition and translation systems perform poorly on noisy inputs,which are frequent in realistic environments. Augmenting these systems withvisual signals has the potential to improve robustness to noise. However,audio-visual (AV) data is only available in limited amounts and for fewerlanguages than audio-only resources. To address this gap, we present XLAVS-R, across-lingual audio-visual speech representation model for noise-robust speechrecognition and translation in over 100 languages. It is designed to maximizethe benefits of limited multilingual AV pre-training data, by building on topof audio-only multilingual pre-training and simplifying existing pre-trainingschemes. Extensive evaluation on the MuAViC benchmark shows the strength ofXLAVS-R on downstream audio-visual speech recognition and translation tasks,where it outperforms the previous state of the art by up to 18.5% WER and 4.7BLEU given noisy AV inputs, and enables strong zero-shot audio-visual abilitywith audio-only fine-tuning.</description><author>HyoJung Han, Mohamed Anwar, Juan Pino, Wei-Ning Hsu, Marine Carpuat, Bowen Shi, Changhan Wang</author><pubDate>Mon, 12 Aug 2024 13:16:48 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.14402v2</guid></item></channel></rss>