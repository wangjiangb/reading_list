<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/"><channel><title>Arxivfresh papers</title><link></link><description>Arxiv paper</description><language>en-US</language><lastBuildDate>Thu, 18 Jan 2024 14:00:05 GMT</lastBuildDate><generator>rfeed v1.0.0</generator><docs>https://github.com/svpino/rfeed/blob/master/README.md</docs><item><title>GARField: Group Anything with Radiance Fields</title><link>http://arxiv.org/abs/2401.09419v1</link><description>Grouping is inherently ambiguous due to the multiple levels of granularity inwhich one can decompose a scene -- should the wheels of an excavator beconsidered separate or part of the whole? We present Group Anything withRadiance Fields (GARField), an approach for decomposing 3D scenes into ahierarchy of semantically meaningful groups from posed image inputs. To do thiswe embrace group ambiguity through physical scale: by optimizing ascale-conditioned 3D affinity feature field, a point in the world can belong todifferent groups of different sizes. We optimize this field from a set of 2Dmasks provided by Segment Anything (SAM) in a way that respects coarse-to-finehierarchy, using scale to consistently fuse conflicting masks from differentviewpoints. From this field we can derive a hierarchy of possible groupings viaautomatic tree construction or user interaction. We evaluate GARField on avariety of in-the-wild scenes and find it effectively extracts groups at manylevels: clusters of objects, objects, and various subparts. GARField inherentlyrepresents multi-view consistent groupings and produces higher fidelity groupsthan the input SAM masks. GARField's hierarchical grouping could have excitingdownstream applications such as 3D asset extraction or dynamic sceneunderstanding. See the project website at https://www.garfield.studio/</description><author>Chung Min Kim, Mingxuan Wu, Justin Kerr, Ken Goldberg, Matthew Tancik, Angjoo Kanazawa</author><pubDate>Wed, 17 Jan 2024 18:57:53 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.09419v1</guid></item><item><title>Vision Mamba: Efficient Visual Representation Learning with Bidirectional State Space Model</title><link>http://arxiv.org/abs/2401.09417v1</link><description>Recently the state space models (SSMs) with efficient hardware-aware designs,i.e., Mamba, have shown great potential for long sequence modeling. Buildingefficient and generic vision backbones purely upon SSMs is an appealingdirection. However, representing visual data is challenging for SSMs due to theposition-sensitivity of visual data and the requirement of global context forvisual understanding. In this paper, we show that the reliance of visualrepresentation learning on self-attention is not necessary and propose a newgeneric vision backbone with bidirectional Mamba blocks (Vim), which marks theimage sequences with position embeddings and compresses the visualrepresentation with bidirectional state space models. On ImageNetclassification, COCO object detection, and ADE20k semantic segmentation tasks,Vim achieves higher performance compared to well-established visiontransformers like DeiT, while also demonstrating significantly improvedcomputation &amp; memory efficiency. For example, Vim is 2.8$\times$ faster thanDeiT and saves 86.8% GPU memory when performing batch inference to extractfeatures on images with a resolution of 1248$\times$1248. The resultsdemonstrate that Vim is capable of overcoming the computation &amp; memoryconstraints on performing Transformer-style understanding for high-resolutionimages and it has great potential to become the next-generation backbone forvision foundation models. Code is available at https://github.com/hustvl/Vim.</description><author>Lianghui Zhu, Bencheng Liao, Qian Zhang, Xinlong Wang, Wenyu Liu, Xinggang Wang</author><pubDate>Wed, 17 Jan 2024 18:56:18 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.09417v1</guid></item><item><title>TextureDreamer: Image-guided Texture Synthesis through Geometry-aware Diffusion</title><link>http://arxiv.org/abs/2401.09416v1</link><description>We present TextureDreamer, a novel image-guided texture synthesis method totransfer relightable textures from a small number of input images (3 to 5) totarget 3D shapes across arbitrary categories. Texture creation is a pivotalchallenge in vision and graphics. Industrial companies hire experienced artiststo manually craft textures for 3D assets. Classical methods require denselysampled views and accurately aligned geometry, while learning-based methods areconfined to category-specific shapes within the dataset. In contrast,TextureDreamer can transfer highly detailed, intricate textures from real-worldenvironments to arbitrary objects with only a few casually captured images,potentially significantly democratizing texture creation. Our core idea,personalized geometry-aware score distillation (PGSD), draws inspiration fromrecent advancements in diffuse models, including personalized modeling fortexture information extraction, variational score distillation for detailedappearance synthesis, and explicit geometry guidance with ControlNet. Ourintegration and several essential modifications substantially improve thetexture quality. Experiments on real images spanning different categories showthat TextureDreamer can successfully transfer highly realistic, semanticmeaningful texture to arbitrary objects, surpassing the visual quality ofprevious state-of-the-art.</description><author>Yu-Ying Yeh, Jia-Bin Huang, Changil Kim, Lei Xiao, Thu Nguyen-Phuoc, Numair Khan, Cheng Zhang, Manmohan Chandraker, Carl S Marshall, Zhao Dong, Zhengqin Li</author><pubDate>Wed, 17 Jan 2024 18:55:49 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.09416v1</guid></item><item><title>Randomized Kaczmarz with geometrically smoothed momentum</title><link>http://arxiv.org/abs/2401.09415v1</link><description>This paper studies the effect of adding geometrically smoothed momentum tothe randomized Kaczmarz algorithm, which is an instance of stochastic gradientdescent on a linear least squares loss function. We prove a result about theexpected error in the direction of singular vectors of the matrix defining theleast squares loss. We present several numerical examples illustrating theutility of our result and pose several questions.</description><author>Seth J. Alderman, Roan W. Luikart, Nicholas F. Marshall</author><pubDate>Wed, 17 Jan 2024 18:55:24 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.09415v1</guid></item><item><title>Vlogger: Make Your Dream A Vlog</title><link>http://arxiv.org/abs/2401.09414v1</link><description>In this work, we present Vlogger, a generic AI system for generating aminute-level video blog (i.e., vlog) of user descriptions. Different from shortvideos with a few seconds, vlog often contains a complex storyline withdiversified scenes, which is challenging for most existing video generationapproaches. To break through this bottleneck, our Vlogger smartly leveragesLarge Language Model (LLM) as Director and decomposes a long video generationtask of vlog into four key stages, where we invoke various foundation models toplay the critical roles of vlog professionals, including (1) Script, (2) Actor,(3) ShowMaker, and (4) Voicer. With such a design of mimicking human beings,our Vlogger can generate vlogs through explainable cooperation of top-downplanning and bottom-up shooting. Moreover, we introduce a novel video diffusionmodel, ShowMaker, which serves as a videographer in our Vlogger for generatingthe video snippet of each shooting scene. By incorporating Script and Actorattentively as textual and visual prompts, it can effectively enhancespatial-temporal coherence in the snippet. Besides, we design a concise mixedtraining paradigm for ShowMaker, boosting its capacity for both T2V generationand prediction. Finally, the extensive experiments show that our methodachieves state-of-the-art performance on zero-shot T2V generation andprediction tasks. More importantly, Vlogger can generate over 5-minute vlogsfrom open-world descriptions, without loss of video coherence on script andactor. The code and model is all available athttps://github.com/zhuangshaobin/Vlogger.</description><author>Shaobin Zhuang, Kunchang Li, Xinyuan Chen, Yaohui Wang, Ziwei Liu, Yu Qiao, Yali Wang</author><pubDate>Wed, 17 Jan 2024 18:55:12 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.09414v1</guid></item><item><title>POP-3D: Open-Vocabulary 3D Occupancy Prediction from Images</title><link>http://arxiv.org/abs/2401.09413v1</link><description>We describe an approach to predict open-vocabulary 3D semantic voxeloccupancy map from input 2D images with the objective of enabling 3D grounding,segmentation and retrieval of free-form language queries. This is a challengingproblem because of the 2D-3D ambiguity and the open-vocabulary nature of thetarget tasks, where obtaining annotated training data in 3D is difficult. Thecontributions of this work are three-fold. First, we design a new modelarchitecture for open-vocabulary 3D semantic occupancy prediction. Thearchitecture consists of a 2D-3D encoder together with occupancy prediction and3D-language heads. The output is a dense voxel map of 3D grounded languageembeddings enabling a range of open-vocabulary tasks. Second, we develop atri-modal self-supervised learning algorithm that leverages three modalities:(i) images, (ii) language and (iii) LiDAR point clouds, and enables trainingthe proposed architecture using a strong pre-trained vision-language modelwithout the need for any 3D manual language annotations. Finally, wedemonstrate quantitatively the strengths of the proposed model on severalopen-vocabulary tasks: Zero-shot 3D semantic segmentation using existingdatasets; 3D grounding and retrieval of free-form language queries, using asmall dataset that we propose as an extension of nuScenes. You can find theproject page here https://vobecant.github.io/POP3D.</description><author>Antonin Vobecky, Oriane Siméoni, David Hurych, Spyros Gidaris, Andrei Bursuc, Patrick Pérez, Josef Sivic</author><pubDate>Wed, 17 Jan 2024 18:51:53 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.09413v1</guid></item><item><title>Through the Looking-Glass: Transparency Implications and Challenges in Enterprise AI Knowledge Systems</title><link>http://arxiv.org/abs/2401.09410v1</link><description>Knowledge can't be disentangled from people. As AI knowledge systems minevast volumes of work-related data, the knowledge that's being extracted andsurfaced is intrinsically linked to the people who create and use it. Whenthese systems get embedded in organizational settings, the information that isbrought to the foreground and the information that's pushed to the peripherycan influence how individuals see each other and how they see themselves atwork. In this paper, we present the looking-glass metaphor and use it toconceptualize AI knowledge systems as systems that reflect and distort,expanding our view on transparency requirements, implications and challenges.We formulate transparency as a key mediator in shaping different ways ofseeing, including seeing into the system, which unveils its capabilities,limitations and behavior, and seeing through the system, which shapes workers'perceptions of their own contributions and others within the organization.Recognizing the sociotechnical nature of these systems, we identify threetransparency dimensions necessary to realize the value of AI knowledge systems,namely system transparency, procedural transparency and transparency ofoutcomes. We discuss key challenges hindering the implementation of these formsof transparency, bringing to light the wider sociotechnical gap andhighlighting directions for future Computer-supported Cooperative Work (CSCW)research.</description><author>Karina Cortiñas-Lorenzo, Siân Lindley, Ida Larsen-Ledet, Bhaskar Mitra</author><pubDate>Wed, 17 Jan 2024 18:47:30 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.09410v1</guid></item><item><title>Theory of Mind abilities of Large Language Models in Human-Robot Interaction : An Illusion?</title><link>http://arxiv.org/abs/2401.05302v2</link><description>Large Language Models have shown exceptional generative abilities in variousnatural language and generation tasks. However, possible anthropomorphizationand leniency towards failure cases have propelled discussions on emergentabilities of Large Language Models especially on Theory of Mind (ToM) abilitiesin Large Language Models. While several false-belief tests exists to verify theability to infer and maintain mental models of another entity, we study aspecial application of ToM abilities that has higher stakes and possiblyirreversible consequences : Human Robot Interaction. In this work, we explorethe task of Perceived Behavior Recognition, where a robot employs a LargeLanguage Model (LLM) to assess the robot's generated behavior in a mannersimilar to human observer. We focus on four behavior types, namely -explicable, legible, predictable, and obfuscatory behavior which have beenextensively used to synthesize interpretable robot behaviors. The LLMs goal is,therefore to be a human proxy to the agent, and to answer how a certain agentbehavior would be perceived by the human in the loop, for example "Given arobot's behavior X, would the human observer find it explicable?". We conduct ahuman subject study to verify that the users are able to correctly answer sucha question in the curated situations (robot setting and plan) across fivedomains. A first analysis of the belief test yields extremely positive resultsinflating ones expectations of LLMs possessing ToM abilities. We then proposeand perform a suite of perturbation tests which breaks this illusion, i.e.Inconsistent Belief, Uninformative Context and Conviction Test. We concludethat, the high score of LLMs on vanilla prompts showcases its potential use inHRI settings, however to possess ToM demands invariance to trivial orirrelevant perturbations in the context which LLMs lack.</description><author>Mudit Verma, Siddhant Bhambri, Subbarao Kambhampati</author><pubDate>Wed, 17 Jan 2024 18:45:39 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.05302v2</guid></item><item><title>Deciphering Textual Authenticity: A Generalized Strategy through the Lens of Large Language Semantics for Detecting Human vs. Machine-Generated Text</title><link>http://arxiv.org/abs/2401.09407v1</link><description>With the recent proliferation of Large Language Models (LLMs), there has beenan increasing demand for tools to detect machine-generated text. The effectivedetection of machine-generated text face two pertinent problems: First, theyare severely limited in generalizing against real-world scenarios, wheremachine-generated text is produced by a variety of generators, including butnot limited to GPT-4 and Dolly, and spans diverse domains, ranging fromacademic manuscripts to social media posts. Second, existing detectionmethodologies treat texts produced by LLMs through a restrictive binaryclassification lens, neglecting the nuanced diversity of artifacts generated bydifferent LLMs. In this work, we undertake a systematic study on the detectionof machine-generated text in real-world scenarios. We first study theeffectiveness of state-of-the-art approaches and find that they are severelylimited against text produced by diverse generators and domains in the realworld. Furthermore, t-SNE visualizations of the embeddings from a pretrainedLLM's encoder show that they cannot reliably distinguish between human andmachine-generated text. Based on our findings, we introduce a novel system,T5LLMCipher, for detecting machine-generated text using a pretrained T5 encodercombined with LLM embedding sub-clustering to address the text produced bydiverse generators and domains in the real world. We evaluate our approachacross 9 machine-generated text systems and 9 domains and find that ourapproach provides state-of-the-art generalization ability, with an averageincrease in F1 score on machine-generated text of 19.6\% on unseen generatorsand domains compared to the top performing existing approaches and correctlyattributes the generator of text with an accuracy of 93.6\%.</description><author>Mazal Bethany, Brandon Wherry, Emet Bethany, Nishant Vishwamitra, Peyman Najafirad</author><pubDate>Wed, 17 Jan 2024 18:45:13 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.09407v1</guid></item><item><title>HomPINNs: homotopy physics-informed neural networks for solving the inverse problems of nonlinear differential equations with multiple solutions</title><link>http://arxiv.org/abs/2304.02811v2</link><description>Due to the complex behavior arising from non-uniqueness, symmetry, andbifurcations in the solution space, solving inverse problems of nonlineardifferential equations (DEs) with multiple solutions is a challenging task. Toaddress this, we propose homotopy physics-informed neural networks (HomPINNs),a novel framework that leverages homotopy continuation and neural networks(NNs) to solve inverse problems. The proposed framework begins with the use ofNNs to simultaneously approximate unlabeled observations across diversesolutions while adhering to DE constraints. Through homotopy continuation, theproposed method solves the inverse problem by tracing the observations andidentifying multiple solutions. The experiments involve testing the performanceof the proposed method on one-dimensional DEs and applying it to solve atwo-dimensional Gray-Scott simulation. Our findings demonstrate that theproposed method is scalable and adaptable, providing an effective solution forsolving DEs with multiple solutions and unknown parameters. Moreover, it hassignificant potential for various applications in scientific computing, such asmodeling complex systems and solving inverse problems in physics, chemistry,biology, etc.</description><author>Haoyang Zheng, Yao Huang, Ziyang Huang, Wenrui Hao, Guang Lin</author><pubDate>Wed, 17 Jan 2024 18:14:20 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2304.02811v2</guid></item><item><title>Stuck in the Quicksand of Numeracy, Far from AGI Summit: Evaluating LLMs' Mathematical Competency through Ontology-guided Perturbations</title><link>http://arxiv.org/abs/2401.09395v1</link><description>Recent advancements in Large Language Models (LLMs) have showcased strikingresults on existing logical reasoning benchmarks, with some models evensurpassing human performance. However, the true depth of their competencies androbustness, in mathematical reasoning tasks, remains an open question. Inresponse, we develop (i) an ontology of perturbations of maths questions, (ii)a semi-automatic method of perturbation, and (iii) a dataset of perturbed mathsquestions to probe the limits of LLM capabilities in mathematical reasoningtasks. These controlled perturbations span across multiple fine dimensions ofthe structural and representational aspects of maths questions. Using GPT-4, wegenerated the MORE dataset by perturbing randomly selected five seed questionsfrom GSM8K. This process was guided by our ontology and involved a thoroughautomatic and manual filtering process, yielding a set of 216 maths problems.We conducted comprehensive evaluation of both closed-source and open-sourceLLMs on MORE. The results show a significant performance drop across all themodels against the perturbed questions. This strongly suggests that currentLLMs lack robust mathematical skills and deep reasoning abilities. Thisresearch not only identifies multiple gaps in the capabilities of currentmodels, but also highlights multiple potential directions for futuredevelopment. Our dataset will be made publicly available athttps://huggingface.co/datasets/declare-lab/GSM8k_MORE.</description><author>Pengfei Hong, Deepanway Ghosal, Navonil Majumder, Somak Aditya, Rada Mihalcea, Soujanya Poria</author><pubDate>Wed, 17 Jan 2024 18:13:07 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.09395v1</guid></item><item><title>Élivágar: Efficient Quantum Circuit Search for Classification</title><link>http://arxiv.org/abs/2401.09393v1</link><description>Designing performant and noise-robust circuits for Quantum Machine Learning(QML) is challenging -- the design space scales exponentially with circuitsize, and there are few well-supported guiding principles for QML circuitdesign. Although recent Quantum Circuit Search (QCS) methods attempt to searchfor performant QML circuits that are also robust to hardware noise, theydirectly adopt designs from classical Neural Architecture Search (NAS) that aremisaligned with the unique constraints of quantum hardware, resulting in highsearch overheads and severe performance bottlenecks. We present \'Eliv\'agar, a novel resource-efficient, noise-guided QCSframework. \'Eliv\'agar innovates in all three major aspects of QCS -- searchspace, search algorithm and candidate evaluation strategy -- to address thedesign flaws in current classically-inspired QCS methods. \'Eliv\'agar achieveshardware-efficiency and avoids an expensive circuit-mapping co-search vianoise- and device topology-aware candidate generation. By introducing twocheap-to-compute predictors, Clifford noise resilience and Representationalcapacity, \'Eliv\'agar decouples the evaluation of noise robustness andperformance, enabling early rejection of low-fidelity circuits and reducingcircuit evaluation costs. Due to its resource-efficiency, \'Eliv\'agar canfurther search for data embeddings, significantly improving performance. Based on a comprehensive evaluation of \'Eliv\'agar on 12 real quantumdevices and 9 QML applications, \'Eliv\'agar achieves 5.3% higher accuracy anda 271$\times$ speedup compared to state-of-the-art QCS methods.</description><author>Sashwat Anagolum, Narges Alavisamani, Poulami Das, Moinuddin Qureshi, Eric Kessler, Yunong Shi</author><pubDate>Wed, 17 Jan 2024 18:09:26 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.09393v1</guid></item><item><title>Tri$^{2}$-plane: Volumetric Avatar Reconstruction with Feature Pyramid</title><link>http://arxiv.org/abs/2401.09386v1</link><description>Recent years have witnessed considerable achievements in facial avatarreconstruction with neural volume rendering. Despite notable advancements, thereconstruction of complex and dynamic head movements from monocular videosstill suffers from capturing and restoring fine-grained details. In this work,we propose a novel approach, named Tri$^2$-plane, for monocular photo-realisticvolumetric head avatar reconstructions. Distinct from the existing works thatrely on a single tri-plane deformation field for dynamic facial modeling, theproposed Tri$^2$-plane leverages the principle of feature pyramids and threetop-to-down lateral connections tri-planes for details improvement. It samplesand renders facial details at multiple scales, transitioning from the entireface to specific local regions and then to even more refined sub-regions.Moreover, we incorporate a camera-based geometry-aware sliding window method asan augmentation in training, which improves the robustness beyond the canonicalspace, with a particular improvement in cross-identity generation capabilities.Experimental outcomes indicate that the Tri$^2$-plane not only surpassesexisting methodologies but also achieves superior performance across bothquantitative metrics and qualitative assessments through experiments.</description><author>Luchuan Song, Pinxin Liu, Lele Chen, Celong Liu, Chenliang Xu</author><pubDate>Wed, 17 Jan 2024 17:59:03 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.09386v1</guid></item><item><title>AUTOACT: Automatic Agent Learning from Scratch via Self-Planning</title><link>http://arxiv.org/abs/2401.05268v2</link><description>Language agents have achieved considerable performance on various complextasks. Despite the incessant exploration in this field, existing language agentsystems still struggle with costly, non-reproducible data reliance and face thechallenge of compelling a single model for multiple functions. To this end, weintroduce AutoAct, an automatic agent learning framework that does not rely onlarge-scale annotated data and synthetic trajectories from closed-source models(e.g., GPT-4). Given limited data with a tool library, AutoAct firstautomatically synthesizes planning trajectories without any assistance fromhumans or strong closed-source models. Then, AutoAct leverages adivision-of-labor strategy to automatically differentiate based on the targettask information and synthesized trajectories, producing a sub-agent group tocomplete the task. We conduct comprehensive experiments with different LLMs,which demonstrates that AutoAct yields better or parallel performance comparedto various strong baselines. We even notice that AutoAct, when using theLlama-2-13b model, can achieve performance comparable to that of the zero-shotGPT-3.5-Turbo agent. Code will be available athttps://github.com/zjunlp/AutoAct.</description><author>Shuofei Qiao, Ningyu Zhang, Runnan Fang, Yujie Luo, Wangchunshu Zhou, Yuchen Eleanor Jiang, Chengfei Lv, Huajun Chen</author><pubDate>Wed, 17 Jan 2024 17:57:24 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.05268v2</guid></item><item><title>Diverse Part Synthesis for 3D Shape Creation</title><link>http://arxiv.org/abs/2401.09384v1</link><description>Methods that use neural networks for synthesizing 3D shapes in the form of apart-based representation have been introduced over the last few years. Thesemethods represent shapes as a graph or hierarchy of parts and enable a varietyof applications such as shape sampling and reconstruction. However, currentmethods do not allow easily regenerating individual shape parts according touser preferences. In this paper, we investigate techniques that allow the userto generate multiple, diverse suggestions for individual parts. Specifically,we experiment with multimodal deep generative models that allow samplingdiverse suggestions for shape parts and focus on models which have not beenconsidered in previous work on shape synthesis. To provide a comparative studyof these techniques, we introduce a method for synthesizing 3D shapes in apart-based representation and evaluate all the part suggestion techniqueswithin this synthesis method. In our method, which is inspired by previouswork, shapes are represented as a set of parts in the form of implicitfunctions which are then positioned in space to form the final shape. Synthesisin this representation is enabled by a neural network architecture based on animplicit decoder and a spatial transformer. We compare the various multimodalgenerative models by evaluating their performance in generating partsuggestions. Our contribution is to show with qualitative and quantitativeevaluations which of the new techniques for multimodal part generation performthe best and that a synthesis method based on the top-performing techniquesallows the user to more finely control the parts that are generated in the 3Dshapes while maintaining high shape fidelity when reconstructing shapes.</description><author>Yanran Guan, Oliver van Kaick</author><pubDate>Wed, 17 Jan 2024 17:55:06 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.09384v1</guid></item><item><title>Unlocking Unlabeled Data: Ensemble Learning with the Hui- Walter Paradigm for Performance Estimation in Online and Static Settings</title><link>http://arxiv.org/abs/2401.09376v1</link><description>In the realm of machine learning and statistical modeling, practitionersoften work under the assumption of accessible, static, labeled data forevaluation and training. However, this assumption often deviates from realitywhere data may be private, encrypted, difficult- to-measure, or unlabeled. Inthis paper, we bridge this gap by adapting the Hui-Walter paradigm, a methodtraditionally applied in epidemiology and medicine, to the field of machinelearning. This approach enables us to estimate key performance metrics such asfalse positive rate, false negative rate, and priors in scenarios where noground truth is available. We further extend this paradigm for handling onlinedata, opening up new possibilities for dynamic data environments. Ourmethodology involves partitioning data into latent classes to simulate multipledata populations (if natural populations are unavailable) and independentlytraining models to replicate multiple tests. By cross-tabulating binaryoutcomes across ensemble categorizers and multiple populations, we are able toestimate unknown parameters through Gibbs sampling, eliminating the need forground-truth or labeled data. This paper showcases the potential of ourmethodology to transform machine learning practices by allowing for accuratemodel assessment under dynamic and uncertain data conditions.</description><author>Kevin Slote, Elaine Lee</author><pubDate>Wed, 17 Jan 2024 17:46:10 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.09376v1</guid></item><item><title>Watch Your Language: Investigating Content Moderation with Large Language Models</title><link>http://arxiv.org/abs/2309.14517v2</link><description>Large language models (LLMs) have exploded in popularity due to their abilityto perform a wide array of natural language tasks. Text-based contentmoderation is one LLM use case that has received recent enthusiasm, however,there is little research investigating how LLMs perform in content moderationsettings. In this work, we evaluate a suite of commodity LLMs on two commoncontent moderation tasks: rule-based community moderation and toxic contentdetection. For rule-based community moderation, we instantiate 95 subcommunityspecific LLMs by prompting GPT-3.5 with rules from 95 Reddit subcommunities. Wefind that GPT-3.5 is effective at rule-based moderation for many communities,achieving a median accuracy of 64% and a median precision of 83%. For toxicitydetection, we evaluate a suite of commodity LLMs (GPT-3, GPT-3.5, GPT-4, GeminiPro, LLAMA 2) and show that LLMs significantly outperform currently widespreadtoxicity classifiers. However, recent increases in model size add only marginalbenefit to toxicity detection, suggesting a potential performance plateau forLLMs on toxicity detection tasks. We conclude by outlining avenues for futurework in studying LLMs and content moderation.</description><author>Deepak Kumar, Yousef AbuHashem, Zakir Durumeric</author><pubDate>Wed, 17 Jan 2024 17:41:18 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2309.14517v2</guid></item><item><title>Flame: Simplifying Topology Extension in Federated Learning</title><link>http://arxiv.org/abs/2305.05118v2</link><description>Distributed machine learning approaches, including a broad class of federatedlearning (FL) techniques, present a number of benefits when deploying machinelearning applications over widely distributed infrastructures. The benefits arehighly dependent on the details of the underlying machine learning topology,which specifies the functionality executed by the participating nodes, theirdependencies and interconnections. Current systems lack the flexibility andextensibility necessary to customize the topology of a machine learningdeployment. We present Flame, a new system that provides flexibility of thetopology configuration of distributed FL applications around the specifics of aparticular deployment context, and is easily extensible to support new FLarchitectures. Flame achieves this via a new high-level abstraction TopologyAbstraction Graphs (TAGs). TAGs decouple the ML application logic from theunderlying deployment details, making it possible to specialize the applicationdeployment with reduced development effort. Flame is released as an open sourceproject, and its flexibility and extensibility support a variety of topologiesand mechanisms, and can facilitate the development of new FL methodologies.</description><author>Harshit Daga, Jaemin Shin, Dhruv Garg, Ada Gavrilovska, Myungjin Lee, Ramana Rao Kompella</author><pubDate>Wed, 17 Jan 2024 17:27:10 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.05118v2</guid></item><item><title>Swing: Short-cutting Rings for Higher Bandwidth Allreduce</title><link>http://arxiv.org/abs/2401.09356v1</link><description>The allreduce collective operation accounts for a significant fraction of theruntime of workloads running on distributed systems. One factor determining itsperformance is the distance between communicating nodes, especially on networkslike torus, where a higher distance implies multiple messages being forwardedon the same link, thus reducing the allreduce bandwidth. Torus networks arewidely used on systems optimized for machine learning workloads (e.g., GoogleTPUs and Amazon Trainium devices), as well as on some of the Top500supercomputers. To improve allreduce performance on torus networks we introduceSwing, a new algorithm that keeps a low distance between communicating nodes byswinging between torus directions. Our analysis and experimental evaluationshow that Swing outperforms by up to 3x existing allreduce algorithms forvectors ranging from 32B to 128MiB, on different types of torus and torus-liketopologies, regardless of their shape and size.</description><author>Daniele De Sensi, Tommaso Bonato, David Saam, Torsten Hoefler</author><pubDate>Wed, 17 Jan 2024 17:24:36 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.09356v1</guid></item><item><title>Fine-grained Hallucination Detection and Editing for Language Models</title><link>http://arxiv.org/abs/2401.06855v2</link><description>Large language models (LMs) are prone to generate diverse factually incorrectstatements, which are widely called hallucinations. Current approachespredominantly focus on coarse-grained automatic hallucination detection orediting, overlooking nuanced error levels. In this paper, we propose a noveltask -- automatic fine-grained hallucination detection -- and present acomprehensive taxonomy encompassing six hierarchically defined types ofhallucination. To facilitate evaluation, we introduce a new benchmark thatincludes fine-grained human judgments on two LM outputs across various domains.Our analysis reveals that ChatGPT and Llama 2-Chat exhibit hallucinations in60% and 75% of their outputs, respectively, and a majority of thesehallucinations fall into categories that have been underexplored. As an initialstep to address this, we train FAVA, a retrieval-augmented LM by carefullydesigning synthetic data generations to detect and correct fine-grainedhallucinations. On our benchmark, our automatic and human evaluations show thatFAVA significantly outperforms ChatGPT on fine-grained hallucination detectionby a large margin though a large room for future improvement still exists.FAVA's suggested edits also improve the factuality of LM-generated text,resulting in 5-10% FActScore improvements.</description><author>Abhika Mishra, Akari Asai, Vidhisha Balachandran, Yizhong Wang, Graham Neubig, Yulia Tsvetkov, Hannaneh Hajishirzi</author><pubDate>Wed, 17 Jan 2024 17:23:20 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.06855v2</guid></item><item><title>Neural Contractive Dynamical Systems</title><link>http://arxiv.org/abs/2401.09352v1</link><description>Stability guarantees are crucial when ensuring a fully autonomous robot doesnot take undesirable or potentially harmful actions. Unfortunately, globalstability guarantees are hard to provide in dynamical systems learned fromdata, especially when the learned dynamics are governed by neural networks. Wepropose a novel methodology to learn neural contractive dynamical systems,where our neural architecture ensures contraction, and hence, global stability.To efficiently scale the method to high-dimensional dynamical systems, wedevelop a variant of the variational autoencoder that learns dynamics in alow-dimensional latent representation space while retaining contractivestability after decoding. We further extend our approach to learningcontractive systems on the Lie group of rotations to account for full-poseend-effector dynamic motions. The result is the first highly flexible learningarchitecture that provides contractive stability guarantees with capability toperform obstacle avoidance. Empirically, we demonstrate that our approachencodes the desired dynamics more accurately than the current state-of-the-art,which provides less strong stability guarantees.</description><author>Hadi Beik-Mohammadi, Søren Hauberg, Georgios Arvanitidis, Nadia Figueroa, Gerhard Neumann, Leonel Rozo</author><pubDate>Wed, 17 Jan 2024 17:18:21 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.09352v1</guid></item><item><title>Intensity Profile Projection: A Framework for Continuous-Time Representation Learning for Dynamic Networks</title><link>http://arxiv.org/abs/2306.06155v3</link><description>We present a new representation learning framework, Intensity ProfileProjection, for continuous-time dynamic network data. Given triples $(i,j,t)$,each representing a time-stamped ($t$) interaction between two entities($i,j$), our procedure returns a continuous-time trajectory for each node,representing its behaviour over time. The framework consists of three stages:estimating pairwise intensity functions, e.g. via kernel smoothing; learning aprojection which minimises a notion of intensity reconstruction error; andconstructing evolving node representations via the learned projection. Thetrajectories satisfy two properties, known as structural and temporalcoherence, which we see as fundamental for reliable inference. Moreoever, wedevelop estimation theory providing tight control on the error of any estimatedtrajectory, indicating that the representations could even be used in quitenoise-sensitive follow-on analyses. The theory also elucidates the role ofsmoothing as a bias-variance trade-off, and shows how we can reduce the levelof smoothing as the signal-to-noise ratio increases on account of the algorithm`borrowing strength' across the network.</description><author>Alexander Modell, Ian Gallagher, Emma Ceccherini, Nick Whiteley, Patrick Rubin-Delanchy</author><pubDate>Wed, 17 Jan 2024 17:13:59 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.06155v3</guid></item><item><title>High Confidence Level Inference is Almost Free using Parallel Stochastic Optimization</title><link>http://arxiv.org/abs/2401.09346v1</link><description>Uncertainty quantification for estimation through stochastic optimizationsolutions in an online setting has gained popularity recently. This paperintroduces a novel inference method focused on constructing confidenceintervals with efficient computation and fast convergence to the nominal level.Specifically, we propose to use a small number of independent multi-runs toacquire distribution information and construct a t-based confidence interval.Our method requires minimal additional computation and memory beyond thestandard updating of estimates, making the inference process almost cost-free.We provide a rigorous theoretical guarantee for the confidence interval,demonstrating that the coverage is approximately exact with an explicitconvergence rate and allowing for high confidence level inference. Inparticular, a new Gaussian approximation result is developed for the onlineestimators to characterize the coverage properties of our confidence intervalsin terms of relative errors. Additionally, our method also allows forleveraging parallel computing to further accelerate calculations using multiplecores. It is easy to implement and can be integrated with existing stochasticalgorithms without the need for complicated modifications.</description><author>Wanrong Zhu, Zhipeng Lou, Ziyang Wei, Wei Biao Wu</author><pubDate>Wed, 17 Jan 2024 17:11:45 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.09346v1</guid></item><item><title>Analyzing Emissions and Energy Efficiency at Unsignalized Real-world Intersections Under Mixed Traffic Control</title><link>http://arxiv.org/abs/2311.11866v2</link><description>Greenhouse gas emissions have dramatically risen since the early 1900s withU.S. transportation generating 28% of U.S. emissions. As such, there isinterest in reducing transportation-related emissions. Specifically,sustainability research has sprouted around signalized intersections asintersections allow different streams of traffic to cross and changedirections. Recent research has developed mixed traffic control eco-drivingstrategies at signalized intersections to decrease emissions. However, theinherent structure of a signalized intersection generates increased emissionsby creating frequent acceleration/deceleration events, excessive idling fromtraffic congestion, and stop-and-go waves. Thus, we believe unsignalizedintersections hold potential for further sustainability improvements. In thiswork, we provide an emissions analysis on unsignalized intersections withcomplex, real-world topologies and traffic demands where mixed traffic controlstrategies are employed by robot vehicles (RVs) to reduce wait times andcongestion. We find with at least 10% RV penetration rate, RVs generate lessfuel consumption, CO2 emissions, and NOx emissions than signalizedintersections by up to 27%, 27% and 28%, respectively. With at least 30% RVs,CO and HC emissions are reduced by up to 42% and 43%, respectively.Additionally, RVs can reduce network-wide emissions despite only employingtheir strategies at intersections.</description><author>Michael Villarreal, Dawei Wang, Jia Pan, Weizi Li</author><pubDate>Wed, 17 Jan 2024 17:10:31 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.11866v2</guid></item><item><title>Efficient slot labelling</title><link>http://arxiv.org/abs/2401.09343v1</link><description>Slot labelling is an essential component of any dialogue system, aiming tofind important arguments in every user turn. Common approaches involve largepre-trained language models (PLMs) like BERT or RoBERTa, but they facechallenges such as high computational requirements and dependence onpre-training data. In this work, we propose a lightweight method which performson par or better than the state-of-the-art PLM-based methods, while havingalmost 10x less trainable parameters. This makes it especially applicable forreal-life industry scenarios.</description><author>Vladimir Vlasov</author><pubDate>Wed, 17 Jan 2024 17:08:36 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.09343v1</guid></item><item><title>Paralinguistics-Enhanced Large Language Modeling of Spoken Dialogue</title><link>http://arxiv.org/abs/2312.15316v2</link><description>Large Language Models (LLMs) have demonstrated superior abilities in taskssuch as chatting, reasoning, and question-answering. However, standard LLMs mayignore crucial paralinguistic information, such as sentiment, emotion, andspeaking style, which are essential for achieving natural, human-like spokenconversation, especially when such information is conveyed by acoustic cues. Wetherefore propose Paralinguistics-enhanced Generative Pretrained Transformer(ParalinGPT), an LLM that utilizes text and speech modalities to better modelthe linguistic content and paralinguistic attributes of spoken dialogue. Themodel takes the conversational context of text, speech embeddings, andparalinguistic attributes as input prompts within a serialized multitaskingmultimodal framework. Specifically, our framework serializes tasks in the orderof current paralinguistic attribute prediction, response paralinguisticattribute prediction, and response text generation with autoregressiveconditioning. We utilize the Switchboard-1 corpus, including its sentimentlabels as the paralinguistic attribute, as our spoken dialogue dataset.Experimental results indicate the proposed serialized multitasking methodoutperforms typical sequence classification techniques on current and responsesentiment classification. Furthermore, leveraging conversational context andspeech embeddings significantly improves both response text generation andsentiment prediction. Our proposed framework achieves relative improvements of6.7%, 12.0%, and 3.5% in current sentiment accuracy, response sentimentaccuracy, and response text BLEU score, respectively.</description><author>Guan-Ting Lin, Prashanth Gurunath Shivakumar, Ankur Gandhe, Chao-Han Huck Yang, Yile Gu, Shalini Ghosh, Andreas Stolcke, Hung-yi Lee, Ivan Bulyko</author><pubDate>Wed, 17 Jan 2024 17:07:37 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.15316v2</guid></item><item><title>SceneVerse: Scaling 3D Vision-Language Learning for Grounded Scene Understanding</title><link>http://arxiv.org/abs/2401.09340v1</link><description>3D vision-language grounding, which focuses on aligning language with the 3Dphysical environment, stands as a cornerstone in the development of embodiedagents. In comparison to recent advancements in the 2D domain, groundinglanguage in 3D scenes faces several significant challenges: (i) the inherentcomplexity of 3D scenes due to the diverse object configurations, their richattributes, and intricate relationships; (ii) the scarcity of paired 3Dvision-language data to support grounded learning; and (iii) the absence of aunified learning framework to distill knowledge from grounded 3D data. In thiswork, we aim to address these three major challenges in 3D vision-language byexamining the potential of systematically upscaling 3D vision-language learningin indoor environments. We introduce the first million-scale 3D vision-languagedataset, SceneVerse, encompassing about 68K 3D indoor scenes and comprising2.5M vision-language pairs derived from both human annotations and our scalablescene-graph-based generation approach. We demonstrate that this scaling allowsfor a unified pre-training framework, Grounded Pre-training for Scenes (GPS),for 3D vision-language learning. Through extensive experiments, we showcase theeffectiveness of GPS by achieving state-of-the-art performance on all existing3D visual grounding benchmarks. The vast potential of SceneVerse and GPS isunveiled through zero-shot transfer experiments in the challenging 3Dvision-language tasks. Project website: https://scene-verse.github.io .</description><author>Baoxiong Jia, Yixin Chen, Huangyue Yu, Yan Wang, Xuesong Niu, Tengyu Liu, Qing Li, Siyuan Huang</author><pubDate>Wed, 17 Jan 2024 17:04:35 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.09340v1</guid></item><item><title>LQ-LoRA: Low-rank Plus Quantized Matrix Decomposition for Efficient Language Model Finetuning</title><link>http://arxiv.org/abs/2311.12023v2</link><description>We propose a simple approach for memory-efficient adaptation of pretrainedlanguage models. Our approach uses an iterative algorithm to decompose eachpretrained matrix into a high-precision low-rank component and amemory-efficient quantized component. During finetuning, the quantizedcomponent remains fixed and only the low-rank component is updated. We presentan integer linear programming formulation of the quantization component whichenables dynamic configuration of quantization parameters (e.g., bit-width,block size) for each matrix given an overall target memory budget. We furtherexplore a data-aware version of the algorithm which uses an approximation ofthe Fisher information matrix to weight the reconstruction objective duringmatrix decomposition. Experiments on finetuning RoBERTa and LLaMA-2 (7B and70B) demonstrate that our low-rank plus quantized matrix decomposition approach(LQ-LoRA) outperforms strong QLoRA and GPTQ-LoRA baselines and enablesaggressive quantization to sub-3 bits with only minor performance degradations.When finetuned on a language modeling calibration dataset, LQ-LoRA can also beused for model compression; in this setting our 2.75-bit LLaMA-2-70B model(which has 2.85 bits on average when including the low-rank components andrequires 27GB of GPU memory) performs respectably compared to the 16-bitbaseline.</description><author>Han Guo, Philip Greengard, Eric P. Xing, Yoon Kim</author><pubDate>Wed, 17 Jan 2024 17:01:57 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.12023v2</guid></item><item><title>Central Limit Theorem for Two-Timescale Stochastic Approximation with Markovian Noise: Theory and Applications</title><link>http://arxiv.org/abs/2401.09339v1</link><description>Two-timescale stochastic approximation (TTSA) is among the most generalframeworks for iterative stochastic algorithms. This includes well-knownstochastic optimization methods such as SGD variants and those designed forbilevel or minimax problems, as well as reinforcement learning like the familyof gradient-based temporal difference (GTD) algorithms. In this paper, weconduct an in-depth asymptotic analysis of TTSA under controlled Markoviannoise via central limit theorem (CLT), uncovering the coupled dynamics of TTSAinfluenced by the underlying Markov chain, which has not been addressed byprevious CLT results of TTSA only with Martingale difference noise. Buildingupon our CLT, we expand its application horizon of efficient samplingstrategies from vanilla SGD to a wider TTSA context in distributed learning,thus broadening the scope of Hu et al. (2022). In addition, we leverage our CLTresult to deduce the statistical properties of GTD algorithms with nonlinearfunction approximation using Markovian samples and show their identicalasymptotic performance, a perspective not evident from current finite-timebounds.</description><author>Jie Hu, Vishwaraj Doshi, Do Young Eun</author><pubDate>Wed, 17 Jan 2024 17:01:08 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.09339v1</guid></item><item><title>To deform or not: treatment-aware longitudinal registration for breast DCE-MRI during neoadjuvant chemotherapy via unsupervised keypoints detection</title><link>http://arxiv.org/abs/2401.09336v1</link><description>Clinicians compare breast DCE-MRI after neoadjuvant chemotherapy (NAC) withpre-treatment scans to evaluate the response to NAC. Clinical evidence supportsthat accurate longitudinal deformable registration without deforming treatedtumor regions is key to quantifying tumor changes. We propose a conditionalpyramid registration network based on unsupervised keypoint detection andselective volume-preserving to quantify changes over time. In this approach, weextract the structural and the abnormal keypoints from DCE-MRI, apply thestructural keypoints for the registration algorithm to restrict largedeformation, and employ volume-preserving loss based on abnormal keypoints tokeep the volume of the tumor unchanged after registration. We use a clinicaldataset with 1630 MRI scans from 314 patients treated with NAC. The resultsdemonstrate that our method registers with better performance and better volumepreservation of the tumors. Furthermore, a local-global-combining biomarkerbased on the proposed method achieves high accuracy in pathological completeresponse (pCR) prediction, indicating that predictive information existsoutside tumor regions. The biomarkers could potentially be used to avoidunnecessary surgeries for certain patients. It may be valuable for cliniciansand/or computer systems to conduct follow-up tumor segmentation and responseprediction on images registered by our method. Our code is available on\url{https://github.com/fiy2W/Treatment-aware-Longitudinal-Registration}.</description><author>Luyi Han, Tao Tan, Tianyu Zhang, Yuan Gao, Xin Wang, Valentina Longo, Sofía Ventura-Díaz, Anna D'Angelo, Jonas Teuwen, Ritse Mann</author><pubDate>Wed, 17 Jan 2024 16:58:10 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.09336v1</guid></item><item><title>Large Language Models Are Neurosymbolic Reasoners</title><link>http://arxiv.org/abs/2401.09334v1</link><description>A wide range of real-world applications is characterized by their symbolicnature, necessitating a strong capability for symbolic reasoning. This paperinvestigates the potential application of Large Language Models (LLMs) assymbolic reasoners. We focus on text-based games, significant benchmarks foragents with natural language capabilities, particularly in symbolic tasks likemath, map reading, sorting, and applying common sense in text-based worlds. Tofacilitate these agents, we propose an LLM agent designed to tackle symbolicchallenges and achieve in-game objectives. We begin by initializing the LLMagent and informing it of its role. The agent then receives observations and aset of valid actions from the text-based games, along with a specific symbolicmodule. With these inputs, the LLM agent chooses an action and interacts withthe game environments. Our experimental results demonstrate that our methodsignificantly enhances the capability of LLMs as automated agents for symbolicreasoning, and our LLM agent is effective in text-based games involvingsymbolic tasks, achieving an average performance of 88% across all tasks.</description><author>Meng Fang, Shilong Deng, Yudi Zhang, Zijing Shi, Ling Chen, Mykola Pechenizkiy, Jun Wang</author><pubDate>Wed, 17 Jan 2024 16:57:19 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.09334v1</guid></item><item><title>Machines Do See Color: A Guideline to Classify Different Forms of Racist Discourse in Large Corpora</title><link>http://arxiv.org/abs/2401.09333v1</link><description>Current methods to identify and classify racist language in text rely onsmall-n qualitative approaches or large-n approaches focusing exclusively onovert forms of racist discourse. This article provides a step-by-stepgeneralizable guideline to identify and classify different forms of racistdiscourse in large corpora. In our approach, we start by conceptualizing racismand its different manifestations. We then contextualize these racistmanifestations to the time and place of interest, which allows researchers toidentify their discursive form. Finally, we apply XLM-RoBERTa (XLM-R), across-lingual model for supervised text classification with a cutting-edgecontextual understanding of text. We show that XLM-R and XLM-R-Racismo, ourpretrained model, outperform other state-of-the-art approaches in classifyingracism in large corpora. We illustrate our approach using a corpus of tweetsrelating to the Ecuadorian ind\'igena community between 2018 and 2021.</description><author>Diana Davila Gordillo, Joan Timoneda, Sebastian Vallejo Vera</author><pubDate>Wed, 17 Jan 2024 16:57:18 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.09333v1</guid></item><item><title>AIRI: Predicting Retention Indices and their Uncertainties using Artificial Intelligence</title><link>http://arxiv.org/abs/2401.01506v2</link><description>The Kov\'ats Retention index (RI) is a quantity measured using gaschromatography and commonly used in the identification of chemical structures.Creating libraries of observed RI values is a laborious task, so we explore theuse of a deep neural network for predicting RI values from structure forstandard semipolar columns. This network generated predictions with a meanabsolute error of 15.1 and, in a quantification of the tail of the errordistribution, a 95th percentile absolute error of 46.5. Because of theArtificial Intelligence Retention Indices (AIRI) network's accuracy, it wasused to predict RI values for the NIST EI-MS spectral libraries. These RIvalues are used to improve chemical identification methods and the quality ofthe library. Estimating uncertainty is an important practical need when usingprediction models. To quantify the uncertainty of our network for eachindividual prediction, we used the outputs of an ensemble of 8 networks tocalculate a predicted standard deviation for each RI value prediction. Thispredicted standard deviation was corrected to follow the error between observedand predicted RI values. The Z scores using these predicted standard deviationshad a standard deviation of 1.52 and a 95th percentile absolute Z scorecorresponding to a mean RI value of 42.6.</description><author>Lewis Y. Geer, Stephen E. Stein, William Gary Mallard, Douglas J. Slotta</author><pubDate>Wed, 17 Jan 2024 16:53:09 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.01506v2</guid></item><item><title>Event-Based Visual Odometry on Non-Holonomic Ground Vehicles</title><link>http://arxiv.org/abs/2401.09331v1</link><description>Despite the promise of superior performance under challenging conditions,event-based motion estimation remains a hard problem owing to the difficulty ofextracting and tracking stable features from event streams. In order torobustify the estimation, it is generally believed that fusion with othersensors is a requirement. In this work, we demonstrate reliable, purelyevent-based visual odometry on planar ground vehicles by employing theconstrained non-holonomic motion model of Ackermann steering platforms. Weextend single feature n-linearities for regular frame-based cameras to the caseof quasi time-continuous event-tracks, and achieve a polynomial form viavariable degree Taylor expansions. Robust averaging over multiple event tracksis simply achieved via histogram voting. As demonstrated on both simulated andreal data, our algorithm achieves accurate and robust estimates of thevehicle's instantaneous rotational velocity, and thus results that arecomparable to the delta rotations obtained by frame-based sensors under normalconditions. We furthermore significantly outperform the more traditionalalternatives in challenging illumination scenarios. The code is available at\url{https://github.com/gowanting/NHEVO}.</description><author>Wanting Xu, Si'ao Zhang, Li Cui, Xin Peng, Laurent Kneip</author><pubDate>Wed, 17 Jan 2024 16:52:20 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.09331v1</guid></item><item><title>Online Stability Improvement of Groebner Basis Solvers using Deep Learning</title><link>http://arxiv.org/abs/2401.09328v1</link><description>Over the past decade, the Gr\"obner basis theory and automatic solvergeneration have lead to a large number of solutions to geometric visionproblems. In practically all cases, the derived solvers apply a fixedelimination template to calculate the Gr\"obner basis and thereby identify thezero-dimensional variety of the original polynomial constraints. However, it isclear that different variable or monomial orderings lead to differentelimination templates, and we show that they may present a large variability inaccuracy for a certain instance of a problem. The present paper has twocontributions. We first show that for a common class of problems in geometricvision, variable reordering simply translates into a permutation of the columnsof the initial coefficient matrix, and that -- as a result -- one and the sameelimination template can be reused in different ways, each one leading topotentially different accuracy. We then prove that the original set ofcoefficients may contain sufficient information to train a classifier foronline selection of a good solver, most notably at the cost of only a smallcomputational overhead. We demonstrate wide applicability at the hand ofgeneric dense polynomial problem solvers, as well as a concrete solver fromgeometric vision.</description><author>Wanting Xu, Lan Hu, Manolis C. Tsakiris, Laurent Kneip</author><pubDate>Wed, 17 Jan 2024 16:51:28 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.09328v1</guid></item><item><title>Siamese Meets Diffusion Network: SMDNet for Enhanced Change Detection in High-Resolution RS Imagery</title><link>http://arxiv.org/abs/2401.09325v1</link><description>Recently, the application of deep learning to change detection (CD) hassignificantly progressed in remote sensing images. In recent years, CD taskshave mostly used architectures such as CNN and Transformer to identify thesechanges. However, these architectures have shortcomings in representingboundary details and are prone to false alarms and missed detections undercomplex lighting and weather conditions. For that, we propose a new network,Siamese Meets Diffusion Network (SMDNet). This network combines the Siam-U2NetFeature Differential Encoder (SU-FDE) and the denoising diffusion implicitmodel to improve the accuracy of image edge change detection and enhance themodel's robustness under environmental changes. First, we propose an innovativeSU-FDE module that utilizes shared weight features to capture differencesbetween time series images and identify similarities between features toenhance edge detail detection. Furthermore, we add an attention mechanism toidentify key coarse features to improve the model's sensitivity and accuracy.Finally, the diffusion model of progressive sampling is used to fuse key coarsefeatures, and the noise reduction ability of the diffusion model and theadvantages of capturing the probability distribution of image data are used toenhance the adaptability of the model in different environments. Our method'scombination of feature extraction and diffusion models demonstrateseffectiveness in change detection in remote sensing images. The performanceevaluation of SMDNet on LEVIR-CD, DSIFN-CD, and CDD datasets yields validatedF1 scores of 90.99%, 88.40%, and 88.47%, respectively. This substantiates theadvanced capabilities of our model in accurately identifying variations andintricate details.</description><author>Jia Jia, Geunho Lee, Zhibo Wang, Lyu Zhi, Yuchu He</author><pubDate>Wed, 17 Jan 2024 16:48:55 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.09325v1</guid></item><item><title>BENO: Boundary-embedded Neural Operators for Elliptic PDEs</title><link>http://arxiv.org/abs/2401.09323v1</link><description>Elliptic partial differential equations (PDEs) are a major class oftime-independent PDEs that play a key role in many scientific and engineeringdomains such as fluid dynamics, plasma physics, and solid mechanics. Recently,neural operators have emerged as a promising technique to solve elliptic PDEsmore efficiently by directly mapping the input to solutions. However, existingnetworks typically cannot handle complex geometries and inhomogeneous boundaryvalues present in the real world. Here we introduce Boundary-Embedded NeuralOperators (BENO), a novel neural operator architecture that embeds the complexgeometries and inhomogeneous boundary values into the solving of elliptic PDEs.Inspired by classical Green's function, BENO consists of two branches of GraphNeural Networks (GNNs) for interior source term and boundary values,respectively. Furthermore, a Transformer encoder maps the global boundarygeometry into a latent vector which influences each message passing layer ofthe GNNs. We test our model extensively in elliptic PDEs with various boundaryconditions. We show that all existing baseline methods fail to learn thesolution operator. In contrast, our model, endowed with boundary-embeddedarchitecture, outperforms state-of-the-art neural operators and strongbaselines by an average of 60.96\%. Our source code can be foundhttps://github.com/AI4Science-WestlakeU/beno.git.</description><author>Haixin Wang, Jiaxin Li, Anubhav Dwivedi, Kentaro Hara, Tailin Wu</author><pubDate>Wed, 17 Jan 2024 16:47:39 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.09323v1</guid></item><item><title>FIT-SLAM -- Fisher Information and Traversability estimation-based Active SLAM for exploration in 3D environments</title><link>http://arxiv.org/abs/2401.09322v1</link><description>Active visual SLAM finds a wide array of applications in GNSS-Deniedsub-terrain environments and outdoor environments for ground robots. To achieverobust localization and mapping accuracy, it is imperative to incorporate theperception considerations in the goal selection and path planning towards thegoal during an exploration mission. Through this work, we propose FIT-SLAM(Fisher Information and Traversability estimation-based Active SLAM), a newexploration method tailored for unmanned ground vehicles (UGVs) to explore 3Denvironments. This approach is devised with the dual objectives of sustainingan efficient exploration rate while optimizing SLAM accuracy. Initially, anestimation of a global traversability map is conducted, which accounts for theenvironmental constraints pertaining to traversability. Subsequently, wepropose a goal candidate selection approach along with a path planning methodtowards this goal that takes into account the information provided by thelandmarks used by the SLAM backend to achieve robust localization andsuccessful path execution . The entire algorithm is tested and evaluated firstin a simulated 3D world, followed by a real-world environment and is comparedto pre-existing exploration methods. The results obtained during thisevaluation demonstrate a significant increase in the exploration rate whileeffectively minimizing the localization covariance.</description><author>Suchetan Saravanan, Corentin Chauffaut, Caroline Chanel, Damien Vivet</author><pubDate>Wed, 17 Jan 2024 16:46:38 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.09322v1</guid></item><item><title>Enhancing image quality prediction with self-supervised visual masking</title><link>http://arxiv.org/abs/2305.19858v2</link><description>Full-reference image quality metrics (FR-IQMs) aim to measure the visualdifferences between a pair of reference and distorted images, with the goal ofaccurately predicting human judgments. However, existing FR-IQMs, includingtraditional ones like PSNR and SSIM and even perceptual ones such as HDR-VDP,LPIPS, and DISTS, still fall short in capturing the complexities and nuances ofhuman perception. In this work, rather than devising a novel IQM model, we seekto improve upon the perceptual quality of existing FR-IQM methods. We achievethis by considering visual masking, an important characteristic of the humanvisual system that changes its sensitivity to distortions as a function oflocal image content. Specifically, for a given FR-IQM metric, we propose topredict a visual masking model that modulates reference and distorted images ina way that penalizes the visual errors based on their visibility. Since theground truth visual masks are difficult to obtain, we demonstrate how they canbe derived in a self-supervised manner solely based on mean opinion scores(MOS) collected from an FR-IQM dataset. Our approach results in enhanced FR-IQMmetrics that are more in line with human prediction both visually andquantitatively.</description><author>Uğur Çoğalan, Mojtaba Bemana, Hans-Peter Seidel, Karol Myszkowski</author><pubDate>Wed, 17 Jan 2024 16:41:01 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.19858v2</guid></item><item><title>Improved Probabilistic Image-Text Representations</title><link>http://arxiv.org/abs/2305.18171v3</link><description>Image-Text Matching (ITM) task, a fundamental vision-language (VL) task,suffers from the inherent ambiguity arising from multiplicity and imperfectannotations. Deterministic functions are not sufficiently powerful to captureambiguity, prompting the exploration of probabilistic embeddings to tackle thechallenge. However, the existing probabilistic ITM approach encounters two keyshortcomings; the burden of heavy computations due to the Monte Carloapproximation, and the loss saturation issue in the face of abundant falsenegatives. To overcome the issues, this paper presents an improvedProbabilistic Cross-Modal Embeddings (named PCME++) by introducing a newprobabilistic distance with a closed-form solution. In addition, twooptimization techniques are proposed to enhance PCME++ further: first, theincorporation of pseudo-positives to prevent the loss saturation problem undermassive false negatives; second, mixed sample data augmentation forprobabilistic matching. Experimental results on MS-COCO Caption and twoextended benchmarks, CxC and ECCV Caption, demonstrate the effectiveness ofPCME++ compared to state-of-the-art ITM methods. The robustness of PCME++ isalso evaluated under noisy image-text correspondences. In addition, thepotential applicability of PCME++ in automatic prompt tuning for zero-shotclassification is shown. The code is available athttps://github.com/naver-ai/pcmepp.</description><author>Sanghyuk Chun</author><pubDate>Wed, 17 Jan 2024 16:38:47 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.18171v3</guid></item><item><title>A Chat About Boring Problems: Studying GPT-based text normalization</title><link>http://arxiv.org/abs/2309.13426v2</link><description>Text normalization - the conversion of text from written to spoken form - istraditionally assumed to be an ill-formed task for language models. In thiswork, we argue otherwise. We empirically show the capacity of Large-LanguageModels (LLM) for text normalization in few-shot scenarios. Combiningself-consistency reasoning with linguistic-informed prompt engineering, we findLLM based text normalization to achieve error rates around 40\% lower than topnormalization systems. Further, upon error analysis, we note key limitations inthe conventional design of text normalization tasks. We create a new taxonomyof text normalization errors and apply it to results from GPT-3.5-Turbo andGPT-4.0. Through this new framework, we can identify strengths and weaknessesof GPT-based TN, opening opportunities for future work.</description><author>Yang Zhang, Travis M. Bartley, Mariana Graterol-Fuenmayor, Vitaly Lavrukhin, Evelina Bakhturina, Boris Ginsburg</author><pubDate>Wed, 17 Jan 2024 16:36:58 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2309.13426v2</guid></item><item><title>ID-MixGCL: Identity Mixup for Graph Contrastive Learning</title><link>http://arxiv.org/abs/2304.10045v2</link><description>Graph contrastive learning (GCL) has recently achieved substantialadvancements. Existing GCL approaches compare two different ``views'' of thesame graph in order to learn node/graph representations. The underlyingassumption of these studies is that the graph augmentation strategy is capableof generating several different graph views such that the graph views arestructurally different but semantically similar to the original graphs, andthus the ground-truth labels of the original and augmented graph/nodes can beregarded identical in contrastive learning. However, we observe that thisassumption does not always hold. For instance, the deletion of a super-nodewithin a social network can exert a substantial influence on the partitioningof communities for other nodes. Similarly, any perturbation to nodes or edgesin a molecular graph will change the labels of the graph. Therefore, we believethat augmenting the graph, accompanied by an adaptation of the labels used forthe contrastive loss, will facilitate the encoder to learn a betterrepresentation. Based on this idea, we propose ID-MixGCL, which allows thesimultaneous interpolation of input nodes and corresponding identity labels toobtain soft-confidence samples, with a controllable degree of change, leadingto the capture of fine-grained representations from self-supervised training onunlabeled graphs. Experimental results demonstrate that ID-MixGCL improvesperformance on graph classification and node classification tasks, asdemonstrated by significant improvements on the Cora, IMDB-B, IMDB-M, andPROTEINS datasets compared to state-of-the-art techniques, by 3-29% absolutepoints.</description><author>Gehang Zhang, Bowen Yu, Jiangxia Cao, Xinghua Zhang, Jiawei Sheng, Chuan Zhou, Tingwen Liu</author><pubDate>Wed, 17 Jan 2024 16:28:51 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2304.10045v2</guid></item><item><title>Tiny Time Mixers (TTMs): Fast Pre-trained Models for Enhanced Zero/Few-Shot Forecasting of Multivariate Time Series</title><link>http://arxiv.org/abs/2401.03955v3</link><description>Large pre-trained models for zero/few-shot learning excel in language andvision domains but encounter challenges in multivariate time series (TS) due tothe diverse nature and scarcity of publicly available pre-training data.Consequently, there has been a recent surge in utilizing pre-trained largelanguage models (LLMs) with token adaptations for TS forecasting. Theseapproaches employ cross-domain transfer learning and surprisingly yieldimpressive results. However, these models are typically very slow and large(~billion parameters) and do not consider cross-channel correlations. Toaddress this, we present Tiny Time Mixers (TTM), a significantly small modelbased on the lightweight TSMixer architecture. TTM marks the first success indeveloping fast and tiny general pre-trained models (&lt;1M parameters),exclusively trained on public TS datasets, with effective transfer learningcapabilities for forecasting. To tackle the complexity of pre-training onmultiple datasets with varied temporal resolutions, we introduce several novelenhancements such as adaptive patching, dataset augmentation via downsampling,and resolution prefix tuning. Moreover, we employ a multi-level modelingstrategy to effectively model channel correlations and infuse exogenous signalsduring fine-tuning, a crucial capability lacking in existing benchmarks. TTMshows significant accuracy gains (12-38\%) over popular benchmarks infew/zero-shot forecasting. It also drastically reduces the compute needs ascompared to LLM-TS methods, with a 14X cut in learnable parameters, 106X lesstotal parameters, and substantial reductions in fine-tuning (65X) and inferencetime (54X). In fact, TTM's zero-shot often surpasses the few-shot results inmany popular benchmarks, highlighting the efficacy of our approach. Code andpre-trained models will be open-sourced.</description><author>Vijay Ekambaram, Arindam Jati, Nam H. Nguyen, Pankaj Dayama, Chandra Reddy, Wesley M. Gifford, Jayant Kalagnanam</author><pubDate>Wed, 17 Jan 2024 16:27:24 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.03955v3</guid></item><item><title>In the realm of hybrid Brain: Human Brain and AI</title><link>http://arxiv.org/abs/2210.01461v4</link><description>With the recent developments in neuroscience and engineering, it is nowpossible to record brain signals and decode them. Also, a growing number ofstimulation methods have emerged to modulate and influence brain activity.Current brain-computer interface (BCI) technology is mainly on therapeuticoutcomes, it already demonstrated its efficiency as assistive andrehabilitative technology for patients with severe motor impairments. Recently,artificial intelligence (AI) and machine learning (ML) technologies have beenused to decode brain signals. Beyond this progress, combining AI with advancedBCIs in the form of implantable neurotechnologies grants new possibilities forthe diagnosis, prediction, and treatment of neurological and psychiatricdisorders. In this context, we envision the development of closed loop,intelligent, low-power, and miniaturized neural interfaces that will use braininspired AI techniques with neuromorphic hardware to process the data from thebrain. This will be referred to as Brain Inspired Brain Computer Interfaces(BI-BCIs). Such neural interfaces would offer access to deeper brain regionsand better understanding for brain's functions and working mechanism, whichimproves BCIs operative stability and system's efficiency. On one hand, braininspired AI algorithms represented by spiking neural networks (SNNs) would beused to interpret the multimodal neural signals in the BCI system. On the otherhand, due to the ability of SNNs to capture rich dynamics of biological neuronsand to represent and integrate different information dimensions such as time,frequency, and phase, it would be used to model and encode complex informationprocessing in the brain and to provide feedback to the users. This paperprovides an overview of the different methods to interface with the brain,presents future applications and discusses the merger of AI and BCIs.</description><author>Hoda Fares, Margherita Ronchini, Milad Zamani, Hooman Farkhani, Farshad Moradi</author><pubDate>Wed, 17 Jan 2024 16:15:10 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2210.01461v4</guid></item><item><title>SummaryMixing: A Linear-Complexity Alternative to Self-Attention for Speech Recognition and Understanding</title><link>http://arxiv.org/abs/2307.07421v2</link><description>Modern speech processing systems rely on self-attention. Unfortunately, tokenmixing with self-attention takes quadratic time in the length of the speechutterance, slowing down inference as well as training and increasing memoryconsumption. Cheaper alternatives to self-attention for ASR have beendeveloped, but they fail to consistently reach the same level of accuracy. Thispaper, therefore, proposes a novel linear-time alternative to self-attention.It summarises an utterance with the mean over vectors for all time steps. Thissingle summary is then combined with time-specific information. We call thismethod "SummaryMixing". Introducing SummaryMixing in state-of-the-art ASRmodels makes it feasible to preserve or exceed previous speech recognitionperformance while lowering the training and inference times by up to 28$\%$ andreducing the memory budget by a factor of two. The benefits of SummaryMixingcan also be generalized to other speech-processing tasks, such as speechunderstanding.</description><author>Titouan Parcollet, Rogier van Dalen, Shucong Zhang, Sourav Bhattacharya</author><pubDate>Wed, 17 Jan 2024 16:12:38 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.07421v2</guid></item><item><title>The dynamics of belief: continuously monitoring and visualising complex systems</title><link>http://arxiv.org/abs/2208.05764v2</link><description>The rise of AI in human contexts places new demands on automated systems tobe transparent and explainable. We examine some anthropomorphic ideas andprinciples relevant to such accountablity in order to develop a theoreticalframework for thinking about digital systems in complex human contexts and theproblem of explaining their behaviour. Structurally, systems are made ofmodular and hierachical components, which we abstract in a new system modelusing notions of modes and mode transitions. A mode is an independent componentof the system with its own objectives, monitoring data, and algorithms. Thebehaviour of a mode, including its transitions to other modes, is determined byfunctions that interpret each mode's monitoring data in the light of itsobjectives and algorithms. We show how these belief functions can help explainsystem behaviour by visualising their evaluation as trajectories inhigher-dimensional geometric spaces. These ideas are formalised mathematicallyby abstract and concrete simplicial complexes. We offer three techniques: aframework for design heuristics, a general system theory based on modes, and ageometric visualisation, and apply them in three types of human-centredsystems.</description><author>Edwin J. Beggs, John V. Tucker</author><pubDate>Wed, 17 Jan 2024 16:04:03 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2208.05764v2</guid></item><item><title>Carrying over algorithm in transformers</title><link>http://arxiv.org/abs/2401.07993v2</link><description>Addition is perhaps one of the simplest arithmetic tasks one can think of andis usually performed using the carrying over algorithm. This algorithm consistsof two tasks: adding digits in the same position and carrying over a onewhenever necessary. We study how transformer models implement this algorithmand how the two aforementioned tasks are allocated to different parts of thenetwork. We first focus on two-layer encoder-only models and show that thecarrying over algorithm is implemented in a modular fashion. The first layer ismostly responsible for adding digits in the same position. The second layerfirst decides, in the attention, which positions need a carried one or not, andthen performs the carrying of the one in the final MLP. We provide a simple wayof precisely identifying which neurons are responsible for that task. Thisimplementation of the carrying over algorithm occurs across a range ofhyperparameters for two as well as three-layer models. For small decoder-onlymodels, we observe the same implementation and provide suggestive evidence forits existence in three 7B large language models.</description><author>Jorrit Kruthoff</author><pubDate>Wed, 17 Jan 2024 16:02:27 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.07993v2</guid></item><item><title>Tight Fusion of Events and Inertial Measurements for Direct Velocity Estimation</title><link>http://arxiv.org/abs/2401.09296v1</link><description>Traditional visual-inertial state estimation targets absolute camera posesand spatial landmark locations while first-order kinematics are typicallyresolved as an implicitly estimated sub-state. However, this poses a risk invelocity-based control scenarios, as the quality of the estimation ofkinematics depends on the stability of absolute camera and landmark coordinatesestimation. To address this issue, we propose a novel solution to tightvisual-inertial fusion directly at the level of first-order kinematics byemploying a dynamic vision sensor instead of a normal camera. Morespecifically, we leverage trifocal tensor geometry to establish an incidencerelation that directly depends on events and camera velocity, and demonstratehow velocity estimates in highly dynamic situations can be obtained over shorttime intervals. Noise and outliers are dealt with using a nested two-layerRANSAC scheme. Additionally, smooth velocity signals are obtained from a tightfusion with pre-integrated inertial signals using a sliding window optimizer.Experiments on both simulated and real data demonstrate that the proposed tightevent-inertial fusion leads to continuous and reliable velocity estimation inhighly dynamic scenarios independently of absolute coordinates. Furthermore, inextreme cases, it achieves more stable and more accurate estimation ofkinematics than traditional, point-position-based visual-inertial odometry.</description><author>Wanting Xu, Xin Peng, Laurent Kneip</author><pubDate>Wed, 17 Jan 2024 15:56:57 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.09296v1</guid></item><item><title>T-FOLEY: A Controllable Waveform-Domain Diffusion Model for Temporal-Event-Guided Foley Sound Synthesis</title><link>http://arxiv.org/abs/2401.09294v1</link><description>Foley sound, audio content inserted synchronously with videos, plays acritical role in the user experience of multimedia content. Recently, there hasbeen active research in Foley sound synthesis, leveraging the advancements indeep generative models. However, such works mainly focus on replicating asingle sound class or a textual sound description, neglecting temporalinformation, which is crucial in the practical applications of Foley sound. Wepresent T-Foley, a Temporal-event-guided waveform generation model for Foleysound synthesis. T-Foley generates high-quality audio using two conditions: thesound class and temporal event feature. For temporal conditioning, we devise atemporal event feature and a novel conditioning technique named Block-FiLM.T-Foley achieves superior performance in both objective and subjectiveevaluation metrics and generates Foley sound well-synchronized with thetemporal events. Additionally, we showcase T-Foley's practical applications,particularly in scenarios involving vocal mimicry for temporal event control.We show the demo on our companion website.</description><author>Yoonjin Chung, Junwon Lee, Juhan Nam</author><pubDate>Wed, 17 Jan 2024 15:54:36 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.09294v1</guid></item><item><title>Mean-field underdamped Langevin dynamics and its spacetime discretization</title><link>http://arxiv.org/abs/2312.16360v3</link><description>We propose a new method called the N-particle underdamped Langevin algorithmfor optimizing a special class of non-linear functionals defined over the spaceof probability measures. Examples of problems with this formulation includetraining mean-field neural networks, maximum mean discrepancy minimization andkernel Stein discrepancy minimization. Our algorithm is based on a novelspacetime discretization of the mean-field underdamped Langevin dynamics, forwhich we provide a new, fast mixing guarantee. In addition, we demonstrate thatour algorithm converges globally in total variation distance, bridging thetheoretical gap between the dynamics and its practical implementation.</description><author>Qiang Fu, Ashia Wilson</author><pubDate>Wed, 17 Jan 2024 15:48:20 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.16360v3</guid></item><item><title>Supporting Safety Analysis of Image-processing DNNs through Clustering-based Approaches</title><link>http://arxiv.org/abs/2301.13506v3</link><description>The adoption of deep neural networks (DNNs) in safety-critical contexts isoften prevented by the lack of effective means to explain their results,especially when they are erroneous. In our previous work, we proposed awhite-box approach (HUDD) and a black-box approach (SAFE) to automaticallycharacterize DNN failures. They both identify clusters of similar images from apotentially large set of images leading to DNN failures. However, the analysispipelines for HUDD and SAFE were instantiated in specific ways according tocommon practices, deferring the analysis of other pipelines to future work. Inthis paper, we report on an empirical evaluation of 99 different pipelines forroot cause analysis of DNN failures. They combine transfer learning,autoencoders, heatmaps of neuron relevance, dimensionality reductiontechniques, and different clustering algorithms. Our results show that the bestpipeline combines transfer learning, DBSCAN, and UMAP. It leads to clustersalmost exclusively capturing images of the same failure scenario, thusfacilitating root cause analysis. Further, it generates distinct clusters foreach root cause of failure, thus enabling engineers to detect all the unsafescenarios. Interestingly, these results hold even for failure scenarios thatare only observed in a small percentage of the failing images.</description><author>Mohammed Oualid Attaoui, Hazem Fahmy, Fabrizio Pastore, Lionel Briand</author><pubDate>Wed, 17 Jan 2024 15:45:54 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2301.13506v3</guid></item><item><title>Deployable Reinforcement Learning with Variable Control Rate</title><link>http://arxiv.org/abs/2401.09286v1</link><description>Deploying controllers trained with Reinforcement Learning (RL) on real robotscan be challenging: RL relies on agents' policies being modeled as MarkovDecision Processes (MDPs), which assume an inherently discrete passage of time.The use of MDPs results in that nearly all RL-based control systems employ afixed-rate control strategy with a period (or time step) typically chosen basedon the developer's experience or specific characteristics of the applicationenvironment. Unfortunately, the system should be controlled at the highest,worst-case frequency to ensure stability, which can demand significantcomputational and energy resources and hinder the deployability of thecontroller on onboard hardware. Adhering to the principles of reactiveprogramming, we surmise that applying control actions only when necessaryenables the use of simpler hardware and helps reduce energy consumption. Wechallenge the fixed frequency assumption by proposing a variant of RL withvariable control rate. In this approach, the policy decides the action theagent should take as well as the duration of the time step associated with thataction. In our new setting, we expand Soft Actor-Critic (SAC) to compute theoptimal policy with a variable control rate, introducing the Soft ElasticActor-Critic (SEAC) algorithm. We show the efficacy of SEAC through aproof-of-concept simulation driving an agent with Newtonian kinematics. Ourexperiments show higher average returns, shorter task completion times, andreduced computational resources when compared to fixed rate policies.</description><author>Dong Wang, Giovanni Beltrame</author><pubDate>Wed, 17 Jan 2024 15:40:11 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.09286v1</guid></item><item><title>Diffusion-Based Adversarial Sample Generation for Improved Stealthiness and Controllability</title><link>http://arxiv.org/abs/2305.16494v3</link><description>Neural networks are known to be susceptible to adversarial samples: smallvariations of natural examples crafted to deliberately mislead the models.While they can be easily generated using gradient-based techniques in digitaland physical scenarios, they often differ greatly from the actual datadistribution of natural images, resulting in a trade-off between strength andstealthiness. In this paper, we propose a novel framework dubbedDiffusion-Based Projected Gradient Descent (Diff-PGD) for generating realisticadversarial samples. By exploiting a gradient guided by a diffusion model,Diff-PGD ensures that adversarial samples remain close to the original datadistribution while maintaining their effectiveness. Moreover, our framework canbe easily customized for specific tasks such as digital attacks, physical-worldattacks, and style-based attacks. Compared with existing methods for generatingnatural-style adversarial samples, our framework enables the separation ofoptimizing adversarial loss from other surrogate losses (e.g.,content/smoothness/style loss), making it more stable and controllable.Finally, we demonstrate that the samples generated using Diff-PGD have bettertransferability and anti-purification power than traditional gradient-basedmethods. Code will be released in https://github.com/xavihart/Diff-PGD</description><author>Haotian Xue, Alexandre Araujo, Bin Hu, Yongxin Chen</author><pubDate>Wed, 17 Jan 2024 15:38:27 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.16494v3</guid></item><item><title>A gradient-based approach to fast and accurate head motion compensation in cone-beam CT</title><link>http://arxiv.org/abs/2401.09283v1</link><description>Cone-beam computed tomography (CBCT) systems, with their portability, presenta promising avenue for direct point-of-care medical imaging, particularly incritical scenarios such as acute stroke assessment. However, the integration ofCBCT into clinical workflows faces challenges, primarily linked to long scanduration resulting in patient motion during scanning and leading to imagequality degradation in the reconstructed volumes. This paper introduces a novelapproach to CBCT motion estimation using a gradient-based optimizationalgorithm, which leverages generalized derivatives of the backprojectionoperator for cone-beam CT geometries. Building on that, a fully differentiabletarget function is formulated which grades the quality of the current motionestimate in reconstruction space. We drastically accelerate motion estimationyielding a 19-fold speed-up compared to existing methods. Additionally, weinvestigate the architecture of networks used for quality metric regression andpropose predicting voxel-wise quality maps, favoring autoencoder-likearchitectures over contracting ones. This modification improves gradient flow,leading to more accurate motion estimation. The presented method is evaluatedthrough realistic experiments on head anatomy. It achieves a reduction inreprojection error from an initial average of 3mm to 0.61mm after motioncompensation and consistently demonstrates superior performance compared toexisting approaches. The analytic Jacobian for the backprojection operation,which is at the core of the proposed method, is made publicly available. Insummary, this paper contributes to the advancement of CBCT integration intoclinical workflows by proposing a robust motion estimation approach thatenhances efficiency and accuracy, addressing critical challenges intime-sensitive scenarios.</description><author>Mareike Thies, Fabian Wagner, Noah Maul, Haijun Yu, Manuela Meier, Linda-Sophie Schneider, Mingxuan Gu, Siyuan Mei, Lukas Folle, Andreas Maier</author><pubDate>Wed, 17 Jan 2024 15:37:00 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.09283v1</guid></item><item><title>Adaptive Regret for Bandits Made Possible: Two Queries Suffice</title><link>http://arxiv.org/abs/2401.09278v1</link><description>Fast changing states or volatile environments pose a significant challenge toonline optimization, which needs to perform rapid adaptation under limitedobservation. In this paper, we give query and regret optimal bandit algorithmsunder the strict notion of strongly adaptive regret, which measures the maximumregret over any contiguous interval $I$. Due to its worst-case nature, there isan almost-linear $\Omega(|I|^{1-\epsilon})$ regret lower bound, when only onequery per round is allowed [Daniely el al, ICML 2015]. Surprisingly, with justtwo queries per round, we give Strongly Adaptive Bandit Learner (StABL) thatachieves $\tilde{O}(\sqrt{n|I|})$ adaptive regret for multi-armed bandits with$n$ arms. The bound is tight and cannot be improved in general. Our algorithmleverages a multiplicative update scheme of varying stepsizes and a carefullychosen observation distribution to control the variance. Furthermore, we extendour results and provide optimal algorithms in the bandit convex optimizationsetting. Finally, we empirically demonstrate the superior performance of ouralgorithms under volatile environments and for downstream tasks, such asalgorithm selection for hyperparameter optimization.</description><author>Zhou Lu, Qiuyi Zhang, Xinyi Chen, Fred Zhang, David Woodruff, Elad Hazan</author><pubDate>Wed, 17 Jan 2024 15:32:04 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.09278v1</guid></item><item><title>Avoiding strict saddle points of nonconvex regularized problems</title><link>http://arxiv.org/abs/2401.09274v1</link><description>We introduce a strict saddle property for $\ell_p$ regularized functions, andpropose an iterative reweighted $\ell_1$ algorithm to solve the $\ell_p$regularized problems. The algorithm is guaranteed to converge only to localminimizers when randomly initialized. The strict saddle property is showngeneric on these sparse optimization problems. Those analyses as well as theproposed algorithm can be easily extended to general nonconvex regularizedproblems.</description><author>Luwei Bai</author><pubDate>Wed, 17 Jan 2024 15:25:50 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.09274v1</guid></item><item><title>A Probabilistic Fluctuation based Membership Inference Attack for Diffusion Models</title><link>http://arxiv.org/abs/2308.12143v3</link><description>Membership Inference Attack (MIA) identifies whether a record exists in amachine learning model's training set by querying the model. MIAs on theclassic classification models have been well-studied, and recent works havestarted to explore how to transplant MIA onto generative models. Ourinvestigation indicates that existing MIAs designed for generative modelsmainly depend on the overfitting in target models. However, overfitting can beavoided by employing various regularization techniques, whereas existing MIAsdemonstrate poor performance in practice. Unlike overfitting, memorization isessential for deep learning models to attain optimal performance, making it amore prevalent phenomenon. Memorization in generative models leads to anincreasing trend in the probability distribution of generating records aroundthe member record. Therefore, we propose a Probabilistic Fluctuation AssessingMembership Inference Attack (PFAMI), a black-box MIA that infers memberships bydetecting these trends via analyzing the overall probabilistic fluctuationsaround given records. We conduct extensive experiments across multiplegenerative models and datasets, which demonstrate PFAMI can improve the attacksuccess rate (ASR) by about 27.9% when compared with the best baseline.</description><author>Wenjie Fu, Huandong Wang, Chen Gao, Guanghua Liu, Yong Li, Tao Jiang</author><pubDate>Wed, 17 Jan 2024 15:25:22 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2308.12143v3</guid></item><item><title>Phenotyping calcification in vascular tissues using artificial intelligence</title><link>http://arxiv.org/abs/2401.07825v2</link><description>Vascular calcification is implicated as an important factor in major adversecardiovascular events (MACE), including heart attack and stroke. A controversyremains over how to integrate the diverse forms of vascular calcification intoclinical risk assessment tools. Even the commonly used calcium score forcoronary arteries, which assumes risk scales positively with totalcalcification, has important inconsistencies. Fundamental studies are needed todetermine how risk is influenced by the diverse calcification phenotypes.However, studies of these kinds are hindered by the lack of high-throughput,objective, and non-destructive tools for classifying calcification in imagingdata sets. Here, we introduce a new classification system for phenotypingcalcification along with a semi-automated, non-destructive pipeline that candistinguish these phenotypes in even atherosclerotic tissues. The pipelineincludes a deep-learning-based framework for segmenting lipid pools in noisymicro-CT images and an unsupervised clustering framework for categorizingcalcification based on size, clustering, and topology. This approach isillustrated for five vascular specimens, providing phenotyping for thousands ofcalcification particles across as many as 3200 images in less than seven hours.Average Dice Similarity Coefficients of 0.96 and 0.87 could be achieved fortissue and lipid pool, respectively, with training and validation needed ononly 13 images despite the high heterogeneity in these tissues. By introducingan efficient and comprehensive approach to phenotyping calcification, this workenables large-scale studies to identify a more reliable indicator of the riskof cardiovascular events, a leading cause of global mortality and morbidity.</description><author>Mehdi Ramezanpour, Anne M. Robertson, Yasutaka Tobe, Xiaowei Jia, Juan R. Cebral</author><pubDate>Wed, 17 Jan 2024 15:23:00 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.07825v2</guid></item><item><title>PixelDINO: Semi-Supervised Semantic Segmentation for Detecting Permafrost Disturbances</title><link>http://arxiv.org/abs/2401.09271v1</link><description>Arctic Permafrost is facing significant changes due to global climate change.As these regions are largely inaccessible, remote sensing plays a crucial rulein better understanding the underlying processes not just on a local scale, butacross the Arctic. In this study, we focus on the remote detection ofretrogressive thaw slumps (RTS), a permafrost disturbance comparable tolandslides induced by thawing. For such analyses from space, deep learning hasbecome an indispensable tool, but limited labelled training data remains achallenge for training accurate models. To improve model generalization acrossthe Arctic without the need for additional labelled data, we present asemi-supervised learning approach to train semantic segmentation models todetect RTS. Our framework called PixelDINO is trained in parallel on labelleddata as well as unlabelled data. For the unlabelled data, the model segmentsthe imagery into self-taught pseudo-classes and the training procedure ensuresconsistency of these pseudo-classes across strong augmentations of the inputdata. Our experimental results demonstrate that PixelDINO can improve modelperformance both over supervised baseline methods as well as existingsemi-supervised semantic segmentation approaches, highlighting its potentialfor training robust models that generalize well to regions that were notincluded in the training data. The project page containing code and othermaterials for this study can be found at\url{https://khdlr.github.io/PixelDINO/}.</description><author>Konrad Heidler, Ingmar Nitze, Guido Grosse, Xiao Xiang Zhu</author><pubDate>Wed, 17 Jan 2024 15:20:10 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.09271v1</guid></item><item><title>Risk-Aware Accelerated Wireless Federated Learning with Heterogeneous Clients</title><link>http://arxiv.org/abs/2401.09267v1</link><description>Wireless Federated Learning (FL) is an emerging distributed machine learningparadigm, particularly gaining momentum in domains with confidential andprivate data on mobile clients. However, the location-dependent performance, interms of transmission rates and susceptibility to transmission errors, posesmajor challenges for wireless FL's convergence speed and accuracy. Thechallenge is more acute for hostile environments without a metric thatauthenticates the data quality and security profile of the clients. In thiscontext, this paper proposes a novel risk-aware accelerated FL framework thataccounts for the clients heterogeneity in the amount of possessed data,transmission rates, transmission errors, and trustworthiness. Classifyingclients according to their location-dependent performance and trustworthinessprofiles, we propose a dynamic risk-aware global model aggregation scheme thatallows clients to participate in descending order of their transmission ratesand an ascending trustworthiness constraint. In particular, the transmissionrate is the dominant participation criterion for initial rounds to acceleratethe convergence speed. Our model then progressively relaxes the transmissionrate restriction to explore more training data at cell-edge clients. Theaggregation rounds incorporate a debiasing factor that accounts fortransmission errors. Risk-awareness is enabled by a validation set, where thebase station eliminates non-trustworthy clients at the fine-tuning stage. Theproposed scheme is benchmarked against a conservative scheme (i.e., onlyallowing trustworthy devices) and an aggressive scheme (i.e., oblivious to thetrust metric). The numerical results highlight the superiority of the proposedscheme in terms of accuracy and convergence speed when compared to bothbenchmarks.</description><author>Mohamed Ads, Hesham ElSawy, Hossam S. Hassanein</author><pubDate>Wed, 17 Jan 2024 15:15:52 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.09267v1</guid></item><item><title>P$^2$OT: Progressive Partial Optimal Transport for Deep Imbalanced Clustering</title><link>http://arxiv.org/abs/2401.09266v1</link><description>Deep clustering, which learns representation and semantic clustering withoutlabels information, poses a great challenge for deep learning-based approaches.Despite significant progress in recent years, most existing methods focus onuniformly distributed datasets, significantly limiting the practicalapplicability of their methods. In this paper, we first introduce a morepractical problem setting named deep imbalanced clustering, where theunderlying classes exhibit an imbalance distribution. To tackle this problem,we propose a novel pseudo-labeling-based learning framework. Our frameworkformulates pseudo-label generation as a progressive partial optimal transportproblem, which progressively transports each sample to imbalanced clustersunder prior distribution constraints, thus generating imbalance-awarepseudo-labels and learning from high-confident samples. In addition, wetransform the initial formulation into an unbalanced optimal transport problemwith augmented constraints, which can be solved efficiently by a fast matrixscaling algorithm. Experiments on various datasets, including a human-curatedlong-tailed CIFAR100, challenging ImageNet-R, and large-scale subsets offine-grained iNaturalist2018 datasets, demonstrate the superiority of ourmethod.</description><author>Chuyu Zhang, Hui Ren, Xuming He</author><pubDate>Wed, 17 Jan 2024 15:15:46 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.09266v1</guid></item><item><title>Generalizing Medical Image Representations via Quaternion Wavelet Networks</title><link>http://arxiv.org/abs/2310.10224v3</link><description>Neural network generalizability is becoming a broad research field due to theincreasing availability of datasets from different sources and for varioustasks. This issue is even wider when processing medical data, where a lack ofmethodological standards causes large variations being provided by differentimaging centers or acquired with various devices and cofactors. To overcomethese limitations, we introduce a novel, generalizable, data- and task-agnosticframework able to extract salient features from medical images. The proposedquaternion wavelet network (QUAVE) can be easily integrated with anypre-existing medical image analysis or synthesis task, and it can be involvedwith real, quaternion, or hypercomplex-valued models, generalizing theiradoption to single-channel data. QUAVE first extracts different sub-bandsthrough the quaternion wavelet transform, resulting in bothlow-frequency/approximation bands and high-frequency/fine-grained features.Then, it weighs the most representative set of sub-bands to be involved asinput to any other neural model for image processing, replacing standard datasamples. We conduct an extensive experimental evaluation comprising differentdatasets, diverse image analysis, and synthesis tasks including reconstruction,segmentation, and modality translation. We also evaluate QUAVE in combinationwith both real and quaternion-valued models. Results demonstrate theeffectiveness and the generalizability of the proposed framework that improvesnetwork performance while being flexible to be adopted in manifold scenariosand robust to domain shifts. The full code is available at:https://github.com/ispamm/QWT.</description><author>Luigi Sigillo, Eleonora Grassucci, Aurelio Uncini, Danilo Comminiello</author><pubDate>Wed, 17 Jan 2024 15:13:37 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.10224v3</guid></item><item><title>MSHyper: Multi-Scale Hypergraph Transformer for Long-Range Time Series Forecasting</title><link>http://arxiv.org/abs/2401.09261v1</link><description>Demystifying interactions between temporal patterns of different scales isfundamental to precise long-range time series forecasting. However, previousworks lack the ability to model high-order interactions. To promote morecomprehensive pattern interaction modeling for long-range time seriesforecasting, we propose a Multi-Scale Hypergraph Transformer (MSHyper)framework. Specifically, a multi-scale hypergraph is introduced to providefoundations for modeling high-order pattern interactions. Then by treatinghyperedges as nodes, we also build a hyperedge graph to enhance hypergraphmodeling. In addition, a tri-stage message passing mechanism is introduced toaggregate pattern information and learn the interaction strength betweentemporal patterns of different scales. Extensive experiments on five real-worlddatasets demonstrate that MSHyper achieves state-of-the-art performance,reducing prediction errors by an average of 8.73% and 7.15% over the bestbaseline in MSE and MAE, respectively.</description><author>Zongjiang Shang, Ling Chen</author><pubDate>Wed, 17 Jan 2024 15:12:11 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.09261v1</guid></item><item><title>Balancing stability and plasticity in continual learning: the readout-decomposition of activation change (RDAC) framework</title><link>http://arxiv.org/abs/2310.04741v4</link><description>Continual learning (CL) algorithms strive to acquire new knowledge whilepreserving prior information. However, this stability-plasticity trade-offremains a central challenge. This paper introduces a framework that dissectsthis trade-off, offering valuable insights into CL algorithms. TheReadout-Decomposition of Activation Change (RDAC) framework first addresses thestability-plasticity dilemma and its relation to catastrophic forgetting. Itrelates learning-induced activation changes in the range of prior readouts tothe degree of stability and changes in the null space to the degree ofplasticity. In deep non-linear networks tackling split-CIFAR-110 tasks, theframework clarifies the stability-plasticity trade-offs of the popularregularization algorithms Synaptic intelligence (SI), Elastic-weightconsolidation (EWC), and learning without Forgetting (LwF), and replay-basedalgorithms Gradient episodic memory (GEM), and data replay. GEM and data replaypreserved stability and plasticity, while SI, EWC, and LwF traded offplasticity for stability. The inability of the regularization algorithms tomaintain plasticity was linked to them restricting the change of activations inthe null space of the prior readout. Additionally, for one-hidden-layer linearneural networks, we derived a gradient decomposition algorithm to restrictactivation change only in the range of the prior readouts, to maintain highstability while not further sacrificing plasticity. Results demonstrate thatthe algorithm maintained stability without significant plasticity loss. TheRDAC framework informs the behavior of existing CL algorithms and paves the wayfor novel CL approaches. Finally, it sheds light on the connection betweenlearning-induced activation/representation changes and the stability-plasticitydilemma, also offering insights into representational drift in biologicalsystems.</description><author>Daniel Anthes, Sushrut Thorat, Peter König, Tim C. Kietzmann</author><pubDate>Wed, 17 Jan 2024 15:10:26 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.04741v4</guid></item><item><title>Mitigating distribution shift in machine learning-augmented hybrid simulation</title><link>http://arxiv.org/abs/2401.09259v1</link><description>We study the problem of distribution shift generally arising inmachine-learning augmented hybrid simulation, where parts of simulationalgorithms are replaced by data-driven surrogates. We first establish amathematical framework to understand the structure of machine-learningaugmented hybrid simulation problems, and the cause and effect of theassociated distribution shift. We show correlations between distribution shiftand simulation error both numerically and theoretically. Then, we propose asimple methodology based on tangent-space regularized estimator to control thedistribution shift, thereby improving the long-term accuracy of the simulationresults. In the linear dynamics case, we provide a thorough theoreticalanalysis to quantify the effectiveness of the proposed method. Moreover, weconduct several numerical experiments, including simulating a partially knownreaction-diffusion equation and solving Navier-Stokes equations using theprojection method with a data-driven pressure solver. In all cases, we observemarked improvements in simulation accuracy under the proposed method,especially for systems with high degrees of distribution shift, such as thosewith relatively strong non-linear reaction mechanisms, or flows at largeReynolds numbers.</description><author>Jiaxi Zhao, Qianxiao Li</author><pubDate>Wed, 17 Jan 2024 15:05:39 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.09259v1</guid></item><item><title>An Efficient Generalizable Framework for Visuomotor Policies via Control-aware Augmentation and Privilege-guided Distillation</title><link>http://arxiv.org/abs/2401.09258v1</link><description>Visuomotor policies, which learn control mechanisms directly fromhigh-dimensional visual observations, confront challenges in adapting to newenvironments with intricate visual variations. Data augmentation emerges as apromising method for bridging these generalization gaps by enriching datavariety. However, straightforwardly augmenting the entire observation shallimpose excessive burdens on policy learning and may even result in performancedegradation. In this paper, we propose to improve the generalization ability ofvisuomotor policies as well as preserve training stability from two aspects: 1)We learn a control-aware mask through a self-supervised reconstruction taskwith three auxiliary losses and then apply strong augmentation only to thosecontrol-irrelevant regions based on the mask to reduce the generalization gaps.2) To address training instability issues prevalent in visual reinforcementlearning (RL), we distill the knowledge from a pretrained RL expert processinglow-level environment states, to the student visuomotor policy. The policy issubsequently deployed to unseen environments without any further finetuning. Weconducted comparison and ablation studies across various benchmarks: theDMControl Generalization Benchmark (DMC-GB), the enhanced Robot ManipulationDistraction Benchmark (RMDB), and a specialized long-horizontal drawer-openingrobotic task. The extensive experimental results well demonstrate theeffectiveness of our method, e.g., showing a 17\% improvement over previousmethods in the video-hard setting of DMC-GB.</description><author>Yinuo Zhao, Kun Wu, Tianjiao Yi, Zhiyuan Xu, Xiaozhu Ju, Zhengping Che, Qinru Qiu, Chi Harold Liu, Jian Tang</author><pubDate>Wed, 17 Jan 2024 15:05:00 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.09258v1</guid></item><item><title>A First-Order Multi-Gradient Algorithm for Multi-Objective Bi-Level Optimization</title><link>http://arxiv.org/abs/2401.09257v1</link><description>In this paper, we study the Multi-Objective Bi-Level Optimization (MOBLO)problem, where the upper-level subproblem is a multi-objective optimizationproblem and the lower-level subproblem is for scalar optimization. Existinggradient-based MOBLO algorithms need to compute the Hessian matrix, causing thecomputational inefficient problem. To address this, we propose an efficientfirst-order multi-gradient method for MOBLO, called FORUM. Specifically, wereformulate MOBLO problems as a constrained multi-objective optimization (MOO)problem via the value-function approach. Then we propose a novel multi-gradientaggregation method to solve the challenging constrained MOO problem.Theoretically, we provide the complexity analysis to show the efficiency of theproposed method and a non-asymptotic convergence result. Empirically, extensiveexperiments demonstrate the effectiveness and efficiency of the proposed FORUMmethod in different learning problems. In particular, it achievesstate-of-the-art performance on three multi-task learning benchmark datasets.</description><author>Feiyang Ye, Baijiong Lin, Xiaofeng Cao, Yu Zhang, Ivor Tsang</author><pubDate>Wed, 17 Jan 2024 15:03:37 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.09257v1</guid></item><item><title>Creating Multi-Level Skill Hierarchies in Reinforcement Learning</title><link>http://arxiv.org/abs/2306.09980v2</link><description>What is a useful skill hierarchy for an autonomous agent? We propose ananswer based on a graphical representation of how the interaction between anagent and its environment may unfold. Our approach uses modularity maximisationas a central organising principle to expose the structure of the interactiongraph at multiple levels of abstraction. The result is a collection of skillsthat operate at varying time scales, organised into a hierarchy, where skillsthat operate over longer time scales are composed of skills that operate overshorter time scales. The entire skill hierarchy is generated automatically,with no human intervention, including the skills themselves (their behaviour,when they can be called, and when they terminate) as well as the hierarchicaldependency structure between them. In a wide range of environments, thisapproach generates skill hierarchies that are intuitively appealing and thatconsiderably improve the learning performance of the agent.</description><author>Joshua B. Evans, Özgür Şimşek</author><pubDate>Wed, 17 Jan 2024 15:03:18 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.09980v2</guid></item><item><title>FairTune: Optimizing Parameter Efficient Fine Tuning for Fairness in Medical Image Analysis</title><link>http://arxiv.org/abs/2310.05055v3</link><description>Training models with robust group fairness properties is crucial in ethicallysensitive application areas such as medical diagnosis. Despite the growing bodyof work aiming to minimise demographic bias in AI, this problem remainschallenging. A key reason for this challenge is the fairness generalisationgap: High-capacity deep learning models can fit all training data nearlyperfectly, and thus also exhibit perfect fairness during training. In thiscase, bias emerges only during testing when generalisation performance differsacross subgroups. This motivates us to take a bi-level optimisation perspectiveon fair learning: Optimising the learning strategy based on validationfairness. Specifically, we consider the highly effective workflow of adaptingpre-trained models to downstream medical imaging tasks usingparameter-efficient fine-tuning (PEFT) techniques. There is a trade-off betweenupdating more parameters, enabling a better fit to the task of interest vs.fewer parameters, potentially reducing the generalisation gap. To manage thistradeoff, we propose FairTune, a framework to optimise the choice of PEFTparameters with respect to fairness. We demonstrate empirically that FairTuneleads to improved fairness on a range of medical imaging datasets. The code isavailable at https://github.com/Raman1121/FairTune</description><author>Raman Dutt, Ondrej Bohdal, Sotirios A. Tsaftaris, Timothy Hospedales</author><pubDate>Wed, 17 Jan 2024 14:59:30 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.05055v3</guid></item><item><title>3D Scene Geometry Estimation from 360$^\circ$ Imagery: A Survey</title><link>http://arxiv.org/abs/2401.09252v1</link><description>This paper provides a comprehensive survey on pioneer and state-of-the-art 3Dscene geometry estimation methodologies based on single, two, or multipleimages captured under the omnidirectional optics. We first revisit the basicconcepts of the spherical camera model, and review the most common acquisitiontechnologies and representation formats suitable for omnidirectional (alsocalled 360$^\circ$, spherical or panoramic) images and videos. We then surveymonocular layout and depth inference approaches, highlighting the recentadvances in learning-based solutions suited for spherical data. The classicalstereo matching is then revised on the spherical domain, where methodologiesfor detecting and describing sparse and dense features become crucial. Thestereo matching concepts are then extrapolated for multiple view camera setups,categorizing them among light fields, multi-view stereo, and structure frommotion (or visual simultaneous localization and mapping). We also compile anddiscuss commonly adopted datasets and figures of merit indicated for eachpurpose and list recent results for completeness. We conclude this paper bypointing out current and future trends.</description><author>Thiago Lopes Trugillo da Silveira, Paulo Gamarra Lessa Pinto, Jeffri Erwin Murrugarra Llerena, Claudio Rosito Jung</author><pubDate>Wed, 17 Jan 2024 14:57:27 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.09252v1</guid></item><item><title>Bridging the Gap Between General and Down-Closed Convex Sets in Submodular Maximization</title><link>http://arxiv.org/abs/2401.09251v1</link><description>Optimization of DR-submodular functions has experienced a notable surge insignificance in recent times, marking a pivotal development within the domainof non-convex optimization. Motivated by real-world scenarios, some recentworks have delved into the maximization of non-monotone DR-submodular functionsover general (not necessarily down-closed) convex set constraints. Up to thispoint, these works have all used the minimum $\ell_\infty$ norm of any feasiblesolution as a parameter. Unfortunately, a recent hardness result due to Mualem\&amp; Feldman~\cite{mualem2023resolving} shows that this approach cannot yield asmooth interpolation between down-closed and non-down-closed constraints. Inthis work, we suggest novel offline and online algorithms that provably providesuch an interpolation based on a natural decomposition of the convex bodyconstraint into two distinct convex bodies: a down-closed convex body and ageneral convex body. We also empirically demonstrate the superiority of ourproposed algorithms across three offline and two online applications.</description><author>Loay Mualem, Murad Tukan, Moran Fledman</author><pubDate>Wed, 17 Jan 2024 14:56:42 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.09251v1</guid></item><item><title>Score-based Source Separation with Applications to Digital Communication Signals</title><link>http://arxiv.org/abs/2306.14411v3</link><description>We propose a new method for separating superimposed sources usingdiffusion-based generative models. Our method relies only on separately trainedstatistical priors of independent sources to establish a new objective functionguided by maximum a posteriori estimation with an $\alpha$-posterior, acrossmultiple levels of Gaussian smoothing. Motivated by applications inradio-frequency (RF) systems, we are interested in sources with underlyingdiscrete nature and the recovery of encoded bits from a signal of interest, asmeasured by the bit error rate (BER). Experimental results with RF mixturesdemonstrate that our method results in a BER reduction of 95% over classicaland existing learning-based methods. Our analysis demonstrates that ourproposed method yields solutions that asymptotically approach the modes of anunderlying discrete distribution. Furthermore, our method can be viewed as amulti-source extension to the recently proposed score distillation samplingscheme, shedding additional light on its use beyond conditional sampling. Theproject webpage is available at https://alpha-rgs.github.io</description><author>Tejas Jayashankar, Gary C. F. Lee, Alejandro Lancho, Amir Weiss, Yury Polyanskiy, Gregory W. Wornell</author><pubDate>Wed, 17 Jan 2024 14:55:36 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.14411v3</guid></item><item><title>Learning from Emotions, Demographic Information and Implicit User Feedback in Task-Oriented Document-Grounded Dialogues</title><link>http://arxiv.org/abs/2401.09248v1</link><description>The success of task-oriented and document-grounded dialogue systems dependson users accepting and enjoying using them. To achieve this, recently publishedwork in the field of Human-Computer Interaction suggests that the combinationof considering demographic information, user emotions and learning from theimplicit feedback in their utterances, is particularly important. However,these findings have not yet been transferred to the field of Natural LanguageProcessing, where these data are primarily studied separately. Accordingly, nosufficiently annotated dataset is available. To address this gap, we introduceFEDI, the first English dialogue dataset for task-oriented document-groundeddialogues annotated with demographic information, user emotions and implicitfeedback. Our experiments with FLAN-T5, GPT-2 and LLaMA-2 show that these datahave the potential to improve task completion and the factual consistency ofthe generated responses and user acceptance.</description><author>Dominic Petrak, Thy Thy Tran, Iryna Gurevych</author><pubDate>Wed, 17 Jan 2024 14:52:26 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.09248v1</guid></item><item><title>Uncertainty estimates for semantic segmentation: providing enhanced reliability for automated motor claims handling</title><link>http://arxiv.org/abs/2401.09245v1</link><description>Deep neural network models for image segmentation can be a powerful tool forthe automation of motor claims handling processes in the insurance industry. Acrucial aspect is the reliability of the model outputs when facing adverseconditions, such as low quality photos taken by claimants to document damages.We explore the use of a meta-classification model to assess the precision ofsegments predicted by a model trained for the semantic segmentation of car bodyparts. Different sets of features correlated with the quality of a segment arecompared, and an AUROC score of 0.915 is achieved for distinguishing betweenhigh- and low-quality segments. By removing low-quality segments, the averagemIoU of the segmentation output is improved by 16 percentage points and thenumber of wrongly predicted segments is reduced by 77%.</description><author>Jan Küchler, Daniel Kröll, Sebastian Schoenen, Andreas Witte</author><pubDate>Wed, 17 Jan 2024 14:47:26 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.09245v1</guid></item><item><title>Stochastic Thermodynamics of Learning Parametric Probabilistic Models</title><link>http://arxiv.org/abs/2310.19802v5</link><description>We have formulated a family of machine learning problems as the timeevolution of Parametric Probabilistic Models (PPMs), inherently rendering athermodynamic process. Our primary motivation is to leverage the rich toolboxof thermodynamics of information to assess the information-theoretic content oflearning a probabilistic model. We first introduce two information-theoreticmetrics: Memorized-information (M-info) and Learned-information (L-info), whichtrace the flow of information during the learning process of PPMs. Then, wedemonstrate that the accumulation of L-info during the learning process isassociated with entropy production, and parameters serve as a heat reservoir inthis process, capturing learned information in the form of M-info.</description><author>Shervin Sadat Parsi</author><pubDate>Wed, 17 Jan 2024 14:45:45 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.19802v5</guid></item><item><title>Cross-lingual Offensive Language Detection: A Systematic Review of Datasets, Transfer Approaches and Challenges</title><link>http://arxiv.org/abs/2401.09244v1</link><description>The growing prevalence and rapid evolution of offensive language in socialmedia amplify the complexities of detection, particularly highlighting thechallenges in identifying such content across diverse languages. This surveypresents a systematic and comprehensive exploration of Cross-Lingual TransferLearning (CLTL) techniques in offensive language detection in social media. Ourstudy stands as the first holistic overview to focus exclusively on thecross-lingual scenario in this domain. We analyse 67 relevant papers andcategorise these studies across various dimensions, including thecharacteristics of multilingual datasets used, the cross-lingual resourcesemployed, and the specific CLTL strategies implemented. According to "what totransfer", we also summarise three main CLTL transfer approaches: instance,feature, and parameter transfer. Additionally, we shed light on the currentchallenges and future research opportunities in this field. Furthermore, wehave made our survey resources available online, including two comprehensivetables that provide accessible references to the multilingual datasets and CLTLmethods used in the reviewed literature.</description><author>Aiqi Jiang, Arkaitz Zubiaga</author><pubDate>Wed, 17 Jan 2024 14:44:27 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.09244v1</guid></item><item><title>DiffClone: Enhanced Behaviour Cloning in Robotics with Diffusion-Driven Policy Learning</title><link>http://arxiv.org/abs/2401.09243v1</link><description>Robot learning tasks are extremely compute-intensive and hardware-specific.Thus the avenues of tackling these challenges, using a diverse dataset ofoffline demonstrations that can be used to train robot manipulation agents, isvery appealing. The Train-Offline-Test-Online (TOTO) Benchmark provides awell-curated open-source dataset for offline training comprised mostly ofexpert data and also benchmark scores of the common offline-RL and behaviourcloning agents. In this paper, we introduce DiffClone, an offline algorithm ofenhanced behaviour cloning agent with diffusion-based policy learning, andmeasured the efficacy of our method on real online physical robots at testtime. This is also our official submission to the Train-Offline-Test-Online(TOTO) Benchmark Challenge organized at NeurIPS 2023. We experimented with bothpre-trained visual representation and agent policies. In our experiments, wefind that MOCO finetuned ResNet50 performs the best in comparison to otherfinetuned representations. Goal state conditioning and mapping to transitionsresulted in a minute increase in the success rate and mean-reward. As for theagent policy, we developed DiffClone, a behaviour cloning agent improved usingconditional diffusion.</description><author>Sabariswaran Mani, Abhranil Chandra, Sreyas Venkataraman, Adyan Rizvi, Yash Sirvi, Soumojit Bhattacharya, Aritra Hazra</author><pubDate>Wed, 17 Jan 2024 14:43:59 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.09243v1</guid></item><item><title>Segment Anything Model for Medical Images?</title><link>http://arxiv.org/abs/2304.14660v7</link><description>The Segment Anything Model (SAM) is the first foundation model for generalimage segmentation. It has achieved impressive results on various natural imagesegmentation tasks. However, medical image segmentation (MIS) is morechallenging because of the complex modalities, fine anatomical structures,uncertain and complex object boundaries, and wide-range object scales. To fullyvalidate SAM's performance on medical data, we collected and sorted 53open-source datasets and built a large medical segmentation dataset with 18modalities, 84 objects, 125 object-modality paired targets, 1050K 2D images,and 6033K masks. We comprehensively analyzed different models and strategies onthe so-called COSMOS 1050K dataset. Our findings mainly include the following:1) SAM showed remarkable performance in some specific objects but was unstable,imperfect, or even totally failed in other situations. 2) SAM with the largeViT-H showed better overall performance than that with the small ViT-B. 3) SAMperformed better with manual hints, especially box, than the Everything mode.4) SAM could help human annotation with high labeling quality and less time. 5)SAM was sensitive to the randomness in the center point and tight box prompts,and may suffer from a serious performance drop. 6) SAM performed better thaninteractive methods with one or a few points, but will be outpaced as thenumber of points increases. 7) SAM's performance correlated to differentfactors, including boundary complexity, intensity differences, etc. 8)Finetuning the SAM on specific medical tasks could improve its average DICEperformance by 4.39% and 6.68% for ViT-B and ViT-H, respectively. We hope thatthis comprehensive report can help researchers explore the potential of SAMapplications in MIS, and guide how to appropriately use and develop SAM.</description><author>Yuhao Huang, Xin Yang, Lian Liu, Han Zhou, Ao Chang, Xinrui Zhou, Rusi Chen, Junxuan Yu, Jiongquan Chen, Chaoyu Chen, Sijing Liu, Haozhe Chi, Xindi Hu, Kejuan Yue, Lei Li, Vicente Grau, Deng-Ping Fan, Fajin Dong, Dong Ni</author><pubDate>Wed, 17 Jan 2024 14:42:40 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2304.14660v7</guid></item><item><title>CLadder: Assessing Causal Reasoning in Language Models</title><link>http://arxiv.org/abs/2312.04350v3</link><description>The ability to perform causal reasoning is widely considered a core featureof intelligence. In this work, we investigate whether large language models(LLMs) can coherently reason about causality. Much of the existing work innatural language processing (NLP) focuses on evaluating commonsense causalreasoning in LLMs, thus failing to assess whether a model can perform causalinference in accordance with a set of well-defined formal rules. To addressthis, we propose a new NLP task, causal inference in natural language, inspiredby the "causal inference engine" postulated by Judea Pearl et al. We compose alarge dataset, CLadder, with 10K samples: based on a collection of causalgraphs and queries (associational, interventional, and counterfactual), weobtain symbolic questions and ground-truth answers, through an oracle causalinference engine. These are then translated into natural language. We evaluatemultiple LLMs on our dataset, and we introduce and evaluate a bespokechain-of-thought prompting strategy, CausalCoT. We show that our task is highlychallenging for LLMs, and we conduct an in-depth analysis to gain deeperinsights into the causal reasoning abilities of LLMs. Our data is open-sourcedat https://huggingface.co/datasets/causalNLP/cladder, and our code can be foundat https://github.com/causalNLP/cladder.</description><author>Zhijing Jin, Yuen Chen, Felix Leeb, Luigi Gresele, Ojasv Kamal, Zhiheng Lyu, Kevin Blin, Fernando Gonzalez Adauto, Max Kleiman-Weiner, Mrinmaya Sachan, Bernhard Schölkopf</author><pubDate>Wed, 17 Jan 2024 14:41:55 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.04350v3</guid></item><item><title>A Blockchain-based Model for Securing Data Pipeline in a Heterogeneous Information System</title><link>http://arxiv.org/abs/2401.09240v1</link><description>In our digital world, access to personal and public data has become an itemof concern, with challenging security and privacy aspects. Modern informationsystems are heterogeneous in nature and have an inherent securityvulnerability, which is susceptible to data interception and data modificationdue to unsecured communication data pipelines between connected endpoints. Thisre-search article presents a blockchain-based model for securing data pipelinesin a heterogeneous information system using an integrated multi-hazard earlywarning system (MHEWS) as a case study. The proposed model utilizes theinherent security features of blockchain technology to address the security andprivacy concerns that arise in data pipelines. The model is designed to ensuredata integrity, confidentiality, and authenticity in a decentralized manner.The model is evaluated in a hybrid environment using a prototype implementationand simulation experiments with outcomes that demonstrate advantages overtraditional approaches for a tamper-proof and immutable data pipeline for dataauthenticity and integrity using a confidential ledger.</description><author>MN Ramahlosi, Y Madani, A Akanbi</author><pubDate>Wed, 17 Jan 2024 14:40:09 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.09240v1</guid></item><item><title>DaFoEs: Mixing Datasets towards the generalization of vision-state deep-learning Force Estimation in Minimally Invasive Robotic Surgery</title><link>http://arxiv.org/abs/2401.09239v1</link><description>Precisely determining the contact force during safe interaction in MinimallyInvasive Robotic Surgery (MIRS) is still an open research challenge. Inspiredby post-operative qualitative analysis from surgical videos, the use ofcross-modality data driven deep neural network models has been one of thenewest approaches to predict sensorless force trends. However, these methodsrequired for large and variable datasets which are not currently available. Inthis paper, we present a new vision-haptic dataset (DaFoEs) with variable softenvironments for the training of deep neural models. In order to reduce thebias from a single dataset, we present a pipeline to generalize differentvision and state data inputs for mixed dataset training, using a previouslyvalidated dataset with different setup. Finally, we present a variableencoder-decoder architecture to predict the forces done by the laparoscopictool using single input or sequence of inputs. For input sequence, we use arecurrent decoder, named with the prefix R, and a new temporal sampling torepresent the acceleration of the tool. During our training, we demonstratethat single dataset training tends to overfit to the training data domain, buthas difficulties on translating the results across new domains. However,dataset mixing presents a good translation with a mean relative estimated forceerror of 5% and 12% for the recurrent and non-recurrent models respectively.Our method, also marginally increase the effectiveness of transformers forforce estimation up to a maximum of ~15%, as the volume of available data isincrease by 150%. In conclusion, we demonstrate that mixing experimental setups for vision-state force estimation in MIRS is a possible approach towardsthe general solution of the problem.</description><author>Mikel De Iturrate Reyzabal, Mingcong Chen, Wei Huang, Sebastien Ourselin, Hongbin Liu</author><pubDate>Wed, 17 Jan 2024 14:39:55 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.09239v1</guid></item><item><title>Adversarial Examples are Misaligned in Diffusion Model Manifolds</title><link>http://arxiv.org/abs/2401.06637v3</link><description>In recent years, diffusion models (DMs) have drawn significant attention fortheir success in approximating data distributions, yielding state-of-the-artgenerative results. Nevertheless, the versatility of these models extendsbeyond their generative capabilities to encompass various vision applications,such as image inpainting, segmentation, adversarial robustness, among others.This study is dedicated to the investigation of adversarial attacks through thelens of diffusion models. However, our objective does not involve enhancing theadversarial robustness of image classifiers. Instead, our focus lies inutilizing the diffusion model to detect and analyze the anomalies introduced bythese attacks on images. To that end, we systematically examine the alignmentof the distributions of adversarial examples when subjected to the process oftransformation using diffusion models. The efficacy of this approach isassessed across CIFAR-10 and ImageNet datasets, including varying image sizesin the latter. The results demonstrate a notable capacity to discriminateeffectively between benign and attacked images, providing compelling evidencethat adversarial instances do not align with the learned manifold of the DMs.</description><author>Peter Lorenz, Ricard Durall, Janis Keuper</author><pubDate>Wed, 17 Jan 2024 14:37:58 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.06637v3</guid></item><item><title>Classification and Reconstruction Processes in Deep Predictive Coding Networks: Antagonists or Allies?</title><link>http://arxiv.org/abs/2401.09237v1</link><description>Predictive coding-inspired deep networks for visual computing integrateclassification and reconstruction processes in shared intermediate layers.Although synergy between these processes is commonly assumed, it has yet to beconvincingly demonstrated. In this study, we take a critical look at howclassifying and reconstructing interact in deep learning architectures. Ourapproach utilizes a purposefully designed family of model architecturesreminiscent of autoencoders, each equipped with an encoder, a decoder, and aclassification head featuring varying modules and complexities. We meticulouslyanalyze the extent to which classification- and reconstruction-driveninformation can seamlessly coexist within the shared latent layer of the modelarchitectures. Our findings underscore a significant challenge:Classification-driven information diminishes reconstruction-driven informationin intermediate layers' shared representations and vice versa. While expandingthe shared representation's dimensions or increasing the network's complexitycan alleviate this trade-off effect, our results challenge prevailingassumptions in predictive coding and offer guidance for future iterations ofpredictive coding concepts in deep networks.</description><author>Jan Rathjens, Laurenz Wiskott</author><pubDate>Wed, 17 Jan 2024 14:34:32 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.09237v1</guid></item><item><title>A Characterization Theorem for Equivariant Networks with Point-wise Activations</title><link>http://arxiv.org/abs/2401.09235v1</link><description>Equivariant neural networks have shown improved performance, expressivenessand sample complexity on symmetrical domains. But for some specific symmetries,representations, and choice of coordinates, the most common point-wiseactivations, such as ReLU, are not equivariant, hence they cannot be employedin the design of equivariant neural networks. The theorem we present in thispaper describes all possible combinations of finite-dimensionalrepresentations, choice of coordinates and point-wise activations to obtain anexactly equivariant layer, generalizing and strengthening existingcharacterizations. Notable cases of practical relevance are discussed ascorollaries. Indeed, we prove that rotation-equivariant networks can only beinvariant, as it happens for any network which is equivariant with respect toconnected compact groups. Then, we discuss implications of our findings whenapplied to important instances of exactly equivariant networks. First, wecompletely characterize permutation equivariant networks such as InvariantGraph Networks with point-wise nonlinearities and their geometric counterparts,highlighting a plethora of models whose expressive power and performance arestill unknown. Second, we show that feature spaces of disentangled steerableconvolutional neural networks are trivial representations.</description><author>Marco Pacini, Xiaowen Dong, Bruno Lepri, Gabriele Santin</author><pubDate>Wed, 17 Jan 2024 14:30:46 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.09235v1</guid></item><item><title>Causal Component Analysis</title><link>http://arxiv.org/abs/2305.17225v3</link><description>Independent Component Analysis (ICA) aims to recover independent latentvariables from observed mixtures thereof. Causal Representation Learning (CRL)aims instead to infer causally related (thus often statistically dependent)latent variables, together with the unknown graph encoding their causalrelationships. We introduce an intermediate problem termed Causal ComponentAnalysis (CauCA). CauCA can be viewed as a generalization of ICA, modelling thecausal dependence among the latent components, and as a special case of CRL. Incontrast to CRL, it presupposes knowledge of the causal graph, focusing solelyon learning the unmixing function and the causal mechanisms. Any impossibilityresults regarding the recovery of the ground truth in CauCA also apply for CRL,while possibility results may serve as a stepping stone for extensions to CRL.We characterize CauCA identifiability from multiple datasets generated throughdifferent types of interventions on the latent causal variables. As acorollary, this interventional perspective also leads to new identifiabilityresults for nonlinear ICA -- a special case of CauCA with an empty graph --requiring strictly fewer datasets than previous results. We introduce alikelihood-based approach using normalizing flows to estimate both the unmixingfunction and the causal mechanisms, and demonstrate its effectiveness throughextensive synthetic experiments in the CauCA and ICA setting.</description><author>Liang Wendong, Armin Kekić, Julius von Kügelgen, Simon Buchholz, Michel Besserve, Luigi Gresele, Bernhard Schölkopf</author><pubDate>Wed, 17 Jan 2024 14:22:19 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.17225v3</guid></item><item><title>Dynamic Relation Transformer for Contextual Text Block Detection</title><link>http://arxiv.org/abs/2401.09232v1</link><description>Contextual Text Block Detection (CTBD) is the task of identifying coherenttext blocks within the complexity of natural scenes. Previous methodologieshave treated CTBD as either a visual relation extraction challenge withincomputer vision or as a sequence modeling problem from the perspective ofnatural language processing. We introduce a new framework that frames CTBD as agraph generation problem. This methodology consists of two essentialprocedures: identifying individual text units as graph nodes and discerning thesequential reading order relationships among these units as graph edges.Leveraging the cutting-edge capabilities of DQ-DETR for node detection, ourframework innovates further by integrating a novel mechanism, a DynamicRelation Transformer (DRFormer), dedicated to edge generation. DRFormerincorporates a dual interactive transformer decoder that deftly manages adynamic graph structure refinement process. Through this iterative process, themodel systematically enhances the graph's fidelity, ultimately resulting inimproved precision in detecting contextual text blocks. Comprehensiveexperimental evaluations conducted on both SCUT-CTW-Context and ReCTS-Contextdatasets substantiate that our method achieves state-of-the-art results,underscoring the effectiveness and potential of our graph generation frameworkin advancing the field of CTBD.</description><author>Jiawei Wang, Shunchi Zhang, Kai Hu, Chixiang Ma, Zhuoyao Zhong, Lei Sun, Qiang Huo</author><pubDate>Wed, 17 Jan 2024 14:17:59 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.09232v1</guid></item><item><title>Multi-Lattice Sampling of Quantum Field Theories via Neural Operator-based Flows</title><link>http://arxiv.org/abs/2401.00828v3</link><description>We consider the problem of sampling discrete field configurations $\phi$ fromthe Boltzmann distribution $[d\phi] Z^{-1} e^{-S[\phi]}$, where $S$ is thelattice-discretization of the continuous Euclidean action $\mathcal S$ of somequantum field theory. Since such densities arise as the approximation of theunderlying functional density $[\mathcal D\phi(x)] \mathcal Z^{-1} e^{-\mathcalS[\phi(x)]}$, we frame the task as an instance of operator learning. Inparticular, we propose to approximate a time-dependent operator $\mathcal V_t$whose time integral provides a mapping between the functional distributions ofthe free theory $[\mathcal D\phi(x)] \mathcal Z_0^{-1} e^{-\mathcalS_{0}[\phi(x)]}$ and of the target theory $[\mathcal D\phi(x)]\mathcalZ^{-1}e^{-\mathcal S[\phi(x)]}$. Whenever a particular lattice is chosen, theoperator $\mathcal V_t$ can be discretized to a finite dimensional,time-dependent vector field $V_t$ which in turn induces a continuousnormalizing flow between finite dimensional distributions over the chosenlattice. This flow can then be trained to be a diffeormorphism between thediscretized free and target theories $[d\phi] Z_0^{-1} e^{-S_{0}[\phi]}$,$[d\phi] Z^{-1}e^{-S[\phi]}$. We run experiments on the $\phi^4$-theory toexplore to what extent such operator-based flow architectures generalize tolattice sizes they were not trained on and show that pretraining on smallerlattices can lead to speedup over training only a target lattice size.</description><author>Bálint Máté, François Fleuret</author><pubDate>Wed, 17 Jan 2024 14:17:41 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.00828v3</guid></item><item><title>Information flow and Laplacian dynamics on local optima networks</title><link>http://arxiv.org/abs/2401.09229v1</link><description>We propose a new way of looking at local optima networks (LONs). LONsrepresent fitness landscapes; the nodes are local optima, and the edges aresearch transitions between them. Many metrics computed on LONs have beenproposed and shown to be linked to metaheuristic search difficulty. These havetypically considered LONs as describing static structures. In contrast to this,Laplacian dynamics (LD) is an approach to consider the information flow acrossa network as a dynamical process. We adapt and apply LD to the context of LONs.As a testbed, we consider instances from the quadratic assignment problem (QAP)library. Metrics related to LD are proposed and these are compared withexisting LON metrics. The results show that certain LD metrics are strongpredictors of metaheuristic performance for iterated local search and tabusearch.</description><author>Hendrik Richter, Sarah L. Thomson</author><pubDate>Wed, 17 Jan 2024 14:12:16 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.09229v1</guid></item><item><title>Combining Spatial and Temporal Abstraction in Planning for Better Generalization</title><link>http://arxiv.org/abs/2310.00229v2</link><description>Inspired by human conscious planning, we propose Skipper, a model-basedreinforcement learning agent utilizing spatio-temporal abstractions togeneralize learned skills in novel situations. It automatically decomposes thegiven task into smaller, more manageable subtasks, and hence enables sparsedecision-making and focused computation on the relevant parts of theenvironment. This relies on the extraction of an abstracted proxy problemrepresented as a directed graph, in which vertices and edges are learnedend-to-end from hindsight. Our theoretical analyses provide performanceguarantees under appropriate assumptions and establish where our approach isexpected to be helpful. Generalization-focused experiments validate Skipper'ssignificant advantage in zero-shot generalization, compared to existingstate-of-the-art hierarchical planning methods.</description><author>Mingde Zhao, Safa Alver, Harm van Seijen, Romain Laroche, Doina Precup, Yoshua Bengio</author><pubDate>Wed, 17 Jan 2024 14:10:15 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.00229v2</guid></item><item><title>Wasserstein Distributionally Robust Policy Evaluation and Learning for Contextual Bandits</title><link>http://arxiv.org/abs/2309.08748v3</link><description>Off-policy evaluation and learning are concerned with assessing a givenpolicy and learning an optimal policy from offline data without directinteraction with the environment. Often, the environment in which the data arecollected differs from the environment in which the learned policy is applied.To account for the effect of different environments during learning andexecution, distributionally robust optimization (DRO) methods have beendeveloped that compute worst-case bounds on the policy values assuming that thedistribution of the new environment lies within an uncertainty set. Typically,this uncertainty set is defined based on the KL divergence around the empiricaldistribution computed from the logging dataset. However, the KL uncertainty setfails to encompass distributions with varying support and lacks awareness ofthe geometry of the distribution support. As a result, KL approaches fall shortin addressing practical environment mismatches and lead to over-fitting toworst-case scenarios. To overcome these limitations, we propose a novel DROapproach that employs the Wasserstein distance instead. While Wasserstein DROis generally computationally more expensive compared to KL DRO, we present aregularized method and a practical (biased) stochastic gradient descent methodto optimize the policy efficiently. We also provide a theoretical analysis ofthe finite sample complexity and iteration complexity for our proposed method.We further validate our approach using a public dataset that was recorded in arandomized stoke trial.</description><author>Yi Shen, Pan Xu, Michael M. Zavlanos</author><pubDate>Wed, 17 Jan 2024 14:07:16 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2309.08748v3</guid></item><item><title>PPT: Token Pruning and Pooling for Efficient Vision Transformers</title><link>http://arxiv.org/abs/2310.01812v2</link><description>Vision Transformers (ViTs) have emerged as powerful models in the field ofcomputer vision, delivering superior performance across various vision tasks.However, the high computational complexity poses a significant barrier to theirpractical applications in real-world scenarios. Motivated by the fact that notall tokens contribute equally to the final predictions and fewer tokens bringless computational cost, reducing redundant tokens has become a prevailingparadigm for accelerating vision transformers. However, we argue that it is notoptimal to either only reduce inattentive redundancy by token pruning, or onlyreduce duplicative redundancy by token merging. To this end, in this paper wepropose a novel acceleration framework, namely token Pruning &amp; PoolingTransformers (PPT), to adaptively tackle these two types of redundancy indifferent layers. By heuristically integrating both token pruning and tokenpooling techniques in ViTs without additional trainable parameters, PPTeffectively reduces the model complexity while maintaining its predictiveaccuracy. For example, PPT reduces over 37% FLOPs and improves the throughputby over 45% for DeiT-S without any accuracy drop on the ImageNet dataset. Thecode is available at https://github.com/xjwu1024/PPT andhttps://github.com/mindspore-lab/models/</description><author>Xinjian Wu, Fanhu Zeng, Xiudong Wang, Yunhe Wang, Xinghao Chen</author><pubDate>Wed, 17 Jan 2024 14:04:11 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.01812v2</guid></item><item><title>UniVIE: A Unified Label Space Approach to Visual Information Extraction from Form-like Documents</title><link>http://arxiv.org/abs/2401.09220v1</link><description>Existing methods for Visual Information Extraction (VIE) from form-likedocuments typically fragment the process into separate subtasks, such as keyinformation extraction, key-value pair extraction, and choice group extraction.However, these approaches often overlook the hierarchical structure of formdocuments, including hierarchical key-value pairs and hierarchical choicegroups. To address these limitations, we present a new perspective, reframingVIE as a relation prediction problem and unifying labels of different tasksinto a single label space. This unified approach allows for the definition ofvarious relation types and effectively tackles hierarchical relationships inform-like documents. In line with this perspective, we present UniVIE, aunified model that addresses the VIE problem comprehensively. UniVIE functionsusing a coarse-to-fine strategy. It initially generates tree proposals througha tree proposal network, which are subsequently refined into hierarchical treesby a relation decoder module. To enhance the relation prediction capabilitiesof UniVIE, we incorporate two novel tree constraints into the relation decoder:a tree attention mask and a tree level embedding. Extensive experimentalevaluations on both our in-house dataset HierForms and a publicly availabledataset SIBR, substantiate that our method achieves state-of-the-art results,underscoring the effectiveness and potential of our unified approach inadvancing the field of VIE.</description><author>Kai Hu, Jiawei Wang, Weihong Lin, Zhuoyao Zhong, Lei Sun, Qiang Huo</author><pubDate>Wed, 17 Jan 2024 14:02:36 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.09220v1</guid></item><item><title>The Rise of Diffusion Models in Time-Series Forecasting</title><link>http://arxiv.org/abs/2401.03006v2</link><description>This survey delves into the application of diffusion models in time-seriesforecasting. Diffusion models are demonstrating state-of-the-art results invarious fields of generative AI. The paper includes comprehensive backgroundinformation on diffusion models, detailing their conditioning methods andreviewing their use in time-series forecasting. The analysis covers 11 specifictime-series implementations, the intuition and theory behind them, theeffectiveness on different datasets, and a comparison among each other. Keycontributions of this work are the thorough exploration of diffusion models'applications in time-series forecasting and a chronologically ordered overviewof these models. Additionally, the paper offers an insightful discussion on thecurrent state-of-the-art in this domain and outlines potential future researchdirections. This serves as a valuable resource for researchers in AI andtime-series analysis, offering a clear view of the latest advancements andfuture potential of diffusion models.</description><author>Caspar Meijer, Lydia Y. Chen</author><pubDate>Wed, 17 Jan 2024 14:02:12 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.03006v2</guid></item><item><title>Robust and Large-Payload DNN Watermarking via Fixed, Distribution-Optimized, Weights</title><link>http://arxiv.org/abs/2208.10973v3</link><description>The design of an effective multi-bit watermarking algorithm hinges uponfinding a good trade-off between the three fundamental requirements forming thewatermarking trade-off triangle, namely, robustness against networkmodifications, payload, and unobtrusiveness, ensuring minimal impact on theperformance of the watermarked network. In this paper, we first revisit thenature of the watermarking trade-off triangle for the DNN case, then we exploitour findings to propose a white-box, multi-bit watermarking method achievingvery large payload and strong robustness against network modification. In theproposed system, the weights hosting the watermark are set prior to training,making sure that their amplitude is large enough to bear the target payload andsurvive network modifications, notably retraining, and are left unchangedthroughout the training process. The distribution of the weights carrying thewatermark is theoretically optimised to ensure the secrecy of the watermark andmake sure that the watermarked weights are indistinguishable from thenon-watermarked ones. The proposed method can achieve outstanding performance,with no significant impact on network accuracy, including robustness againstnetwork modifications, retraining and transfer learning, while ensuring apayload which is out of reach of state of the art methods achieving a lower -or at most comparable - robustness.</description><author>Benedetta Tondi, Andrea Costanzo, Mauro Barni</author><pubDate>Wed, 17 Jan 2024 13:50:09 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2208.10973v3</guid></item><item><title>CLSA-CIM: A Cross-Layer Scheduling Approach for Computing-in-Memory Architectures</title><link>http://arxiv.org/abs/2401.07671v2</link><description>The demand for efficient machine learning (ML) accelerators is growingrapidly, driving the development of novel computing concepts such as resistiverandom access memory (RRAM)-based tiled computing-in-memory (CIM)architectures. CIM allows to compute within the memory unit, resulting infaster data processing and reduced power consumption. Efficient compileralgorithms are essential to exploit the potential of tiled CIM architectures.While conventional ML compilers focus on code generation for CPUs, GPUs, andother von Neumann architectures, adaptations are needed to cover CIMarchitectures. Cross-layer scheduling is a promising approach, as it enhancesthe utilization of CIM cores, thereby accelerating computations. Althoughsimilar concepts are implicitly used in previous work, there is a lack of clearand quantifiable algorithmic definitions for cross-layer scheduling for tiledCIM architectures. To close this gap, we present CLSA-CIM, a cross-layerscheduling algorithm for tiled CIM architectures. We integrate CLSA-CIM withexisting weight-mapping strategies and compare performance againststate-of-the-art (SOTA) scheduling algorithms. CLSA-CIM improves theutilization by up to 17.9 x , resulting in an overall speedup increase of up to29.2 x compared to SOTA.</description><author>Rebecca Pelke, Jose Cubero-Cascante, Nils Bosbach, Felix Staudigl, Rainer Leupers, Jan Moritz Joseph</author><pubDate>Wed, 17 Jan 2024 13:49:05 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.07671v2</guid></item><item><title>MIMIR: Masked Image Modeling for Mutual Information-based Adversarial Robustness</title><link>http://arxiv.org/abs/2312.04960v2</link><description>Vision Transformers (ViTs) achieve superior performance on various taskscompared to convolutional neural networks (CNNs), but ViTs are also vulnerableto adversarial attacks. Adversarial training is one of the most successfulmethods to build robust CNN models. Thus, recent works explored newmethodologies for adversarial training of ViTs based on the differences betweenViTs and CNNs, such as better training strategies, preventing attention fromfocusing on a single block, or discarding low-attention embeddings. However,these methods still follow the design of traditional supervised adversarialtraining, limiting the potential of adversarial training on ViTs. This paperproposes a novel defense method, MIMIR, which aims to build a differentadversarial training methodology by utilizing Masked Image Modeling atpre-training. We create an autoencoder that accepts adversarial examples asinput but takes the clean examples as the modeling target. Then, we create amutual information (MI) penalty following the idea of the InformationBottleneck. Among the two information source inputs and correspondingadversarial perturbation, the perturbation information is eliminated due to theconstraint of the modeling target. Next, we provide a theoretical analysis ofMIMIR using the bounds of the MI penalty. We also design two adaptive attackswhen the adversary is aware of the MIMIR defense and show that MIMIR stillperforms well. The experimental results show that MIMIR improves (natural andadversarial) accuracy on average by 4.19% on CIFAR-10 and 5.52% on ImageNet-1K,compared to baselines. On Tiny-ImageNet, we obtained improved natural accuracyof 2.99\% on average and comparable adversarial accuracy. Our code and trainedmodels are publicly available https://github.com/xiaoyunxxy/MIMIR.</description><author>Xiaoyun Xu, Shujian Yu, Jingzheng Wu, Stjepan Picek</author><pubDate>Wed, 17 Jan 2024 13:47:32 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.04960v2</guid></item><item><title>DFB: A Data-Free, Low-Budget, and High-Efficacy Clean-Label Backdoor Attack</title><link>http://arxiv.org/abs/2308.09487v4</link><description>In the domain of backdoor attacks, accurate labeling of injected data isessential for evading rudimentary detection mechanisms. This imperative hascatalyzed the development of clean-label attacks, which are notably moreelusive as they preserve the original labels of the injected data. Currentclean-label attack methodologies primarily depend on extensive knowledge of thetraining dataset. However, practically, such comprehensive dataset access isoften unattainable, given that training datasets are typically compiled fromvarious independent sources. Departing from conventional clean-label attackmethodologies, our research introduces DFB, a data-free, low-budget, andhigh-efficacy clean-label backdoor Attack. DFB is unique in its independencefrom training data access, requiring solely the knowledge of a specific targetclass. Tested on CIFAR10, Tiny-ImageNet, and TSRD, DFB demonstrates remarkableefficacy with minimal poisoning rates of just 0.1%, 0.025%, and 0.4%,respectively. These rates are significantly lower than those required byexisting methods such as LC, HTBA, BadNets, and Blend, yet DFB achievessuperior attack success rates. Furthermore, our findings reveal that DFB posesa formidable challenge to four established backdoor defense algorithms,indicating its potential as a robust tool in advanced clean-label attackstrategies.</description><author>Binhao Ma, Jiahui Wang, Dejun Wang, Bo Meng</author><pubDate>Wed, 17 Jan 2024 13:44:07 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2308.09487v4</guid></item><item><title>Matrix Completion with Hypergraphs:Sharp Thresholds and Efficient Algorithms</title><link>http://arxiv.org/abs/2401.08197v2</link><description>This paper considers the problem of completing a rating matrix based onsub-sampled matrix entries as well as observed social graphs and hypergraphs.We show that there exists a \emph{sharp threshold} on the sample probabilityfor the task of exactly completing the rating matrix -- the task is achievablewhen the sample probability is above the threshold, and is impossible otherwise-- demonstrating a phase transition phenomenon. The threshold can be expressedas a function of the ``quality'' of hypergraphs, enabling us to \emph{quantify}the amount of reduction in sample probability due to the exploitation ofhypergraphs. This also highlights the usefulness of hypergraphs in the matrixcompletion problem. En route to discovering the sharp threshold, we develop acomputationally efficient matrix completion algorithm that effectively exploitsthe observed graphs and hypergraphs. Theoretical analyses show that ouralgorithm succeeds with high probability as long as the sample probabilityexceeds the aforementioned threshold, and this theoretical result is furthervalidated by synthetic experiments. Moreover, our experiments on a real socialnetwork dataset (with both graphs and hypergraphs) show that our algorithmoutperforms other state-of-the-art matrix completion algorithms.</description><author>Zhongtian Ma, Qiaosheng Zhang, Zhen Wang</author><pubDate>Wed, 17 Jan 2024 13:42:40 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.08197v2</guid></item><item><title>An Explainable Proxy Model for Multiabel Audio Segmentation</title><link>http://arxiv.org/abs/2401.08268v2</link><description>Audio signal segmentation is a key task for automatic audio indexing. Itconsists of detecting the boundaries of class-homogeneous segments in thesignal. In many applications, explainable AI is a vital process fortransparency of decision-making with machine learning. In this paper, wepropose an explainable multilabel segmentation model that solves speechactivity (SAD), music (MD), noise (ND), and overlapped speech detection (OSD)simultaneously. This proxy uses the non-negative matrix factorization (NMF) tomap the embedding used for the segmentation to the frequency domain.Experiments conducted on two datasets show similar performances as thepre-trained black box model while showing strong explainability features.Specifically, the frequency bins used for the decision can be easily identifiedat both the segment level (local explanations) and global level (classprototypes).</description><author>Théo Mariotte, Antonio Almudévar, Marie Tahon, Alfonso Ortega</author><pubDate>Wed, 17 Jan 2024 13:28:04 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.08268v2</guid></item><item><title>Machine Learning Insides OptVerse AI Solver: Design Principles and Applications</title><link>http://arxiv.org/abs/2401.05960v2</link><description>In an era of digital ubiquity, efficient resource management anddecision-making are paramount across numerous industries. To this end, wepresent a comprehensive study on the integration of machine learning (ML)techniques into Huawei Cloud's OptVerse AI Solver, which aims to mitigate thescarcity of real-world mathematical programming instances, and to surpass thecapabilities of traditional optimization techniques. We showcase our methodsfor generating complex SAT and MILP instances utilizing generative models thatmirror multifaceted structures of real-world problem. Furthermore, we introducea training framework leveraging augmentation policies to maintain solvers'utility in dynamic environments. Besides the data generation and augmentation,our proposed approaches also include novel ML-driven policies for personalizedsolver strategies, with an emphasis on applications like graph convolutionalnetworks for initial basis selection and reinforcement learning for advancedpresolving and cut selection. Additionally, we detail the incorporation ofstate-of-the-art parameter tuning algorithms which markedly elevate solverperformance. Compared with traditional solvers such as Cplex and SCIP, ourML-augmented OptVerse AI Solver demonstrates superior speed and precisionacross both established benchmarks and real-world scenarios, reinforcing thepractical imperative and effectiveness of machine learning techniques inmathematical programming solvers.</description><author>Xijun Li, Fangzhou Zhu, Hui-Ling Zhen, Weilin Luo, Meng Lu, Yimin Huang, Zhenan Fan, Zirui Zhou, Yufei Kuang, Zhihai Wang, Zijie Geng, Yang Li, Haoyang Liu, Zhiwu An, Muming Yang, Jianshu Li, Jie Wang, Junchi Yan, Defeng Sun, Tao Zhong, Yong Zhang, Jia Zeng, Mingxuan Yuan, Jianye Hao, Jun Yao, Kun Mao</author><pubDate>Wed, 17 Jan 2024 13:26:09 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.05960v2</guid></item></channel></rss>