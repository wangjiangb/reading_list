<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/"><channel><title>Arxivfresh papers</title><link></link><description>Arxiv paper</description><language>en-US</language><lastBuildDate>Tue, 19 Dec 2023 06:00:03 GMT</lastBuildDate><generator>rfeed v1.0.0</generator><docs>https://github.com/svpino/rfeed/blob/master/README.md</docs><item><title>Point Transformer V3: Simpler, Faster, Stronger</title><link>http://arxiv.org/abs/2312.10035v1</link><description>This paper is not motivated to seek innovation within the attentionmechanism. Instead, it focuses on overcoming the existing trade-offs betweenaccuracy and efficiency within the context of point cloud processing,leveraging the power of scale. Drawing inspiration from recent advances in 3Dlarge-scale representation learning, we recognize that model performance ismore influenced by scale than by intricate design. Therefore, we present PointTransformer V3 (PTv3), which prioritizes simplicity and efficiency over theaccuracy of certain mechanisms that are minor to the overall performance afterscaling, such as replacing the precise neighbor search by KNN with an efficientserialized neighbor mapping of point clouds organized with specific patterns.This principle enables significant scaling, expanding the receptive field from16 to 1024 points while remaining efficient (a 3x increase in processing speedand a 10x improvement in memory efficiency compared with its predecessor,PTv2). PTv3 attains state-of-the-art results on over 20 downstream tasks thatspan both indoor and outdoor scenarios. Further enhanced with multi-datasetjoint training, PTv3 pushes these results to a higher level.</description><author>Xiaoyang Wu, Li Jiang, Peng-Shuai Wang, Zhijian Liu, Xihui Liu, Yu Qiao, Wanli Ouyang, Tong He, Hengshuang Zhao</author><pubDate>Fri, 15 Dec 2023 18:59:59 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.10035v1</guid></item><item><title>SlimmeRF: Slimmable Radiance Fields</title><link>http://arxiv.org/abs/2312.10034v1</link><description>Neural Radiance Field (NeRF) and its variants have recently emerged assuccessful methods for novel view synthesis and 3D scene reconstruction.However, most current NeRF models either achieve high accuracy using largemodel sizes, or achieve high memory-efficiency by trading off accuracy. Thislimits the applicable scope of any single model, since high-accuracy modelsmight not fit in low-memory devices, and memory-efficient models might notsatisfy high-quality requirements. To this end, we present SlimmeRF, a modelthat allows for instant test-time trade-offs between model size and accuracythrough slimming, thus making the model simultaneously suitable for scenarioswith different computing budgets. We achieve this through a newly proposedalgorithm named Tensorial Rank Incrementation (TRaIn) which increases the rankof the model's tensorial representation gradually during training. We alsoobserve that our model allows for more effective trade-offs in sparse-viewscenarios, at times even achieving higher accuracy after being slimmed. Wecredit this to the fact that erroneous information such as floaters tend to bestored in components corresponding to higher ranks. Our implementation isavailable at https://github.com/Shiran-Yuan/SlimmeRF.</description><author>Shiran Yuan, Hao Zhao</author><pubDate>Fri, 15 Dec 2023 18:59:55 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.10034v1</guid></item><item><title>Osprey: Pixel Understanding with Visual Instruction Tuning</title><link>http://arxiv.org/abs/2312.10032v1</link><description>Multimodal large language models (MLLMs) have recently achieved impressivegeneral-purpose vision-language capabilities through visual instruction tuning.However, current MLLMs primarily focus on image-level or box-levelunderstanding, falling short of achieving fine-grained vision-languagealignment at the pixel level. Besides, the lack of mask-based instruction datalimits their advancements. In this paper, we propose Osprey, a mask-textinstruction tuning approach, to extend MLLMs by incorporating fine-grained maskregions into language instruction, aiming at achieving pixel-wise visualunderstanding. To achieve this goal, we first meticulously curate a mask-basedregion-text dataset with 724K samples, and then design a vision-language modelby injecting pixel-level representation into LLM. Especially, Osprey adopts aconvolutional CLIP backbone as the vision encoder and employs a mask-awarevisual extractor to extract precise visual mask features from high resolutioninput. Experimental results demonstrate Osprey's superiority in various regionunderstanding tasks, showcasing its new capability for pixel-level instructiontuning. In particular, Osprey can be integrated with Segment Anything Model(SAM) seamlessly to obtain multi-granularity semantics. The source code,dataset and demo can be found at https://github.com/CircleRadon/Osprey.</description><author>Yuqian Yuan, Wentong Li, Jian Liu, Dongqi Tang, Xinjie Luo, Chi Qin, Lei Zhang, Jianke Zhu</author><pubDate>Fri, 15 Dec 2023 18:58:11 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.10032v1</guid></item><item><title>Challenges with unsupervised LLM knowledge discovery</title><link>http://arxiv.org/abs/2312.10029v1</link><description>We show that existing unsupervised methods on large language model (LLM)activations do not discover knowledge -- instead they seem to discover whateverfeature of the activations is most prominent. The idea behind unsupervisedknowledge elicitation is that knowledge satisfies a consistency structure,which can be used to discover knowledge. We first prove theoretically thatarbitrary features (not just knowledge) satisfy the consistency structure of aparticular leading unsupervised knowledge-elicitation method,contrast-consistent search (Burns et al. - arXiv:2212.03827). We then present aseries of experiments showing settings in which unsupervised methods result inclassifiers that do not predict knowledge, but instead predict a differentprominent feature. We conclude that existing unsupervised methods fordiscovering latent knowledge are insufficient, and we contribute sanity checksto apply to evaluating future knowledge elicitation methods. Conceptually, wehypothesise that the identification issues explored here, e.g. distinguishing amodel's knowledge from that of a simulated character's, will persist for futureunsupervised methods.</description><author>Sebastian Farquhar, Vikrant Varma, Zachary Kenton, Johannes Gasteiger, Vladimir Mikulik, Rohin Shah</author><pubDate>Fri, 15 Dec 2023 18:49:43 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.10029v1</guid></item><item><title>Dynamic Gradient Balancing for Enhanced Adversarial Attacks on Multi-Task Models</title><link>http://arxiv.org/abs/2305.12066v2</link><description>Multi-task learning (MTL) creates a single machine learning model calledmulti-task model to simultaneously perform multiple tasks. Although thesecurity of single task classifiers has been extensively studied, there areseveral critical security research questions for multi-task models including 1)How secure are multi-task models to single task adversarial machine learningattacks, 2) Can adversarial attacks be designed to attack multiple taskssimultaneously, and 3) Does task sharing and adversarial training increasemulti-task model robustness to adversarial attacks? In this paper, we answerthese questions through careful analysis and rigorous experimentation. First,we develop na\"ive adaptation of single-task white-box attacks and analyzetheir inherent drawbacks. We then propose a novel attack framework, DynamicGradient Balancing Attack (DGBA). Our framework poses the problem of attackinga multi-task model as an optimization problem based on averaged relative losschange, which can be solved by approximating the problem as an integer linearprogramming problem. Extensive evaluation on two popular MTL benchmarks, NYUv2and Tiny-Taxonomy, demonstrates the effectiveness of DGBA compared to na\"ivemulti-task attack baselines on both clean and adversarially trained multi-taskmodels. The results also reveal a fundamental trade-off between improving taskaccuracy by sharing parameters across tasks and undermining model robustnessdue to increased attack transferability from parameter sharing. DGBA isopen-sourced and available at https://github.com/zhanglijun95/MTLAttack-DGBA.</description><author>Lijun Zhang, Xiao Liu, Kaleel Mahmood, Caiwen Ding, Hui Guan</author><pubDate>Fri, 15 Dec 2023 18:49:38 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.12066v2</guid></item><item><title>Stochastic interpolants with data-dependent couplings</title><link>http://arxiv.org/abs/2310.03725v2</link><description>Generative models inspired by dynamical transport of measure -- such as flowsand diffusions -- construct a continuous-time map between two probabilitydensities. Conventionally, one of these is the target density, only accessiblethrough samples, while the other is taken as a simple base density that isdata-agnostic. In this work, using the framework of stochastic interpolants, weformalize how to \textit{couple} the base and the target densities, wherebysamples from the base are computed conditionally given samples from the targetin a way that is different from (but does preclude) incorporating informationabout class labels or continuous embeddings. This enables us to constructdynamical transport maps that serve as conditional generative models. We showthat these transport maps can be learned by solving a simple square lossregression problem analogous to the standard independent setting. Wedemonstrate the usefulness of constructing dependent couplings in practicethrough experiments in super-resolution and in-painting.</description><author>Michael S. Albergo, Mark Goldstein, Nicholas M. Boffi, Rajesh Ranganath, Eric Vanden-Eijnden</author><pubDate>Fri, 15 Dec 2023 18:44:46 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.03725v2</guid></item><item><title>Accelerating Neural Network Training: A Brief Review</title><link>http://arxiv.org/abs/2312.10024v1</link><description>The process of training a deep neural network is characterized by significanttime requirements and associated costs. Although researchers have madeconsiderable progress in this area, further work is still required due toresource constraints. This study examines innovative approaches to expedite thetraining process of deep neural networks (DNN), with specific emphasis on threestate-of-the-art models such as ResNet50, Vision Transformer (ViT), andEfficientNet. The research utilizes sophisticated methodologies, includingGradient Accumulation (GA), Automatic Mixed Precision (AMP), and Pin Memory(PM), in order to optimize performance and accelerate the training procedure. The study examines the effects of these methodologies on the DNN modelsdiscussed earlier, assessing their efficacy with regard to training rate andcomputational efficacy. The study showcases the efficacy of including GA as astrategic approach, resulting in a noteworthy decrease in the duration requiredfor training. This enables the models to converge at a faster pace. Theutilization of AMP enhances the speed of computations by taking advantage ofthe advantages offered by lower precision arithmetic while maintaining thecorrectness of the model. Furthermore, this study investigates the application of Pin Memory as astrategy to enhance the efficiency of data transmission between the centralprocessing unit and the graphics processing unit, thereby offering a promisingopportunity for enhancing overall performance. The experimental findingsdemonstrate that the combination of these sophisticated methodologiessignificantly accelerates the training of DNNs, offering vital insights forexperts seeking to improve the effectiveness of deep learning processes.</description><author>Sahil Nokhwal, Priyanka Chilakalapudi, Preeti Donekal, Manoj Chandrasekharan, Suman Nokhwal, Ram Swaroop, Raj Bala, Saurabh Pahune, Ankit Chaudhary</author><pubDate>Fri, 15 Dec 2023 18:43:45 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.10024v1</guid></item><item><title>Exploring Adversarial Robustness of Vision Transformers in the Spectral Perspective</title><link>http://arxiv.org/abs/2208.09602v2</link><description>The Vision Transformer has emerged as a powerful tool for imageclassification tasks, surpassing the performance of convolutional neuralnetworks (CNNs). Recently, many researchers have attempted to understand therobustness of Transformers against adversarial attacks. However, previousresearches have focused solely on perturbations in the spatial domain. Thispaper proposes an additional perspective that explores the adversarialrobustness of Transformers against frequency-selective perturbations in thespectral domain. To facilitate comparison between these two domains, an attackframework is formulated as a flexible tool for implementing attacks on imagesin the spatial and spectral domains. The experiments reveal that Transformersrely more on phase and low frequency information, which can render them morevulnerable to frequency-selective attacks than CNNs. This work offers newinsights into the properties and adversarial robustness of Transformers.</description><author>Gihyun Kim, Juyeop Kim, Jong-Seok Lee</author><pubDate>Fri, 15 Dec 2023 18:41:43 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2208.09602v2</guid></item><item><title>Understanding Probe Behaviors through Variational Bounds of Mutual Information</title><link>http://arxiv.org/abs/2312.10019v1</link><description>With the success of self-supervised representations, researchers seek abetter understanding of the information encapsulated within a representation.Among various interpretability methods, we focus on classification-based linearprobing. We aim to foster a solid understanding and provide guidelines forlinear probing by constructing a novel mathematical framework leveraginginformation theory. First, we connect probing with the variational bounds ofmutual information (MI) to relax the probe design, equating linear probing withfine-tuning. Then, we investigate empirical behaviors and practices of probingthrough our mathematical framework. We analyze the layer-wise performance curvebeing convex, which seemingly violates the data processing inequality. However,we show that the intermediate representations can have the biggest MI estimatebecause of the tradeoff between better separability and decreasing MI. Wefurther suggest that the margin of linearly separable representations can be acriterion for measuring the "goodness of representation." We also compareaccuracy with MI as the measuring criteria. Finally, we empirically validateour claims by observing the self-supervised speech models on retaining word andphoneme information.</description><author>Kwanghee Choi, Jee-weon Jung, Shinji Watanabe</author><pubDate>Fri, 15 Dec 2023 18:38:18 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.10019v1</guid></item><item><title>Toward General-Purpose Robots via Foundation Models: A Survey and Meta-Analysis</title><link>http://arxiv.org/abs/2312.08782v2</link><description>Building general-purpose robots that can operate seamlessly, in anyenvironment, with any object, and utilizing various skills to complete diversetasks has been a long-standing goal in Artificial Intelligence. Unfortunately,however, most existing robotic systems have been constrained - having beendesigned for specific tasks, trained on specific datasets, and deployed withinspecific environments. These systems usually require extensively-labeled data,rely on task-specific models, have numerous generalization issues when deployedin real-world scenarios, and struggle to remain robust to distribution shifts.Motivated by the impressive open-set performance and content generationcapabilities of web-scale, large-capacity pre-trained models (i.e., foundationmodels) in research fields such as Natural Language Processing (NLP) andComputer Vision (CV), we devote this survey to exploring (i) how these existingfoundation models from NLP and CV can be applied to the field of robotics, andalso exploring (ii) what a robotics-specific foundation model would look like.We begin by providing an overview of what constitutes a conventional roboticsystem and the fundamental barriers to making it universally applicable. Next,we establish a taxonomy to discuss current work exploring ways to leverageexisting foundation models for robotics and develop ones catered to robotics.Finally, we discuss key challenges and promising future directions in usingfoundation models for enabling general-purpose robotic systems. We encouragereaders to view our living GitHub repository of resources, including papersreviewed in this survey as well as related projects and repositories fordeveloping foundation models for robotics.</description><author>Yafei Hu, Quanting Xie, Vidhi Jain, Jonathan Francis, Jay Patrikar, Nikhil Keetha, Seungchan Kim, Yaqi Xie, Tianyi Zhang, Shibo Zhao, Yu Quan Chong, Chen Wang, Katia Sycara, Matthew Johnson-Roberson, Dhruv Batra, Xiaolong Wang, Sebastian Scherer, Zsolt Kira, Fei Xia, Yonatan Bisk</author><pubDate>Fri, 15 Dec 2023 18:25:48 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.08782v2</guid></item><item><title>Movement Primitive Diffusion: Learning Gentle Robotic Manipulation of Deformable Objects</title><link>http://arxiv.org/abs/2312.10008v1</link><description>Policy learning in robot-assisted surgery (RAS) lacks data efficient andversatile methods that exhibit the desired motion quality for delicate surgicalinterventions. To this end, we introduce Movement Primitive Diffusion (MPD), anovel method for imitation learning (IL) in RAS that focuses on gentlemanipulation of deformable objects. The approach combines the versatility ofdiffusion-based imitation learning (DIL) with the high-quality motiongeneration capabilities of Probabilistic Dynamic Movement Primitives (ProDMPs).This combination enables MPD to achieve gentle manipulation of deformableobjects, while maintaining data efficiency critical for RAS applications wheredemonstration data is scarce. We evaluate MPD across various simulated tasksand a real world robotic setup on both state and image observations. MPDoutperforms state-of-the-art DIL methods in success rate, motion quality, anddata efficiency.</description><author>Paul Maria Scheikl, Nicolas Schreiber, Christoph Haas, Niklas Freymuth, Gerhard Neumann, Rudolf Lioutikov, Franziska Mathis-Ullrich</author><pubDate>Fri, 15 Dec 2023 18:24:28 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.10008v1</guid></item><item><title>Faithful Persona-based Conversational Dataset Generation with Large Language Models</title><link>http://arxiv.org/abs/2312.10007v1</link><description>High-quality conversational datasets are essential for developing AI modelsthat can communicate with users. One way to foster deeper interactions betweena chatbot and its user is through personas, aspects of the user's characterthat provide insights into their personality, motivations, and behaviors.Training Natural Language Processing (NLP) models on a diverse andcomprehensive persona-based dataset can lead to conversational models thatcreate a deeper connection with the user, and maintain their engagement. Inthis paper, we leverage the power of Large Language Models (LLMs) to create alarge, high-quality conversational dataset from a seed dataset. We propose aGenerator-Critic architecture framework to expand the initial dataset, whileimproving the quality of its conversations. The Generator is an LLM prompted tooutput conversations. The Critic consists of a mixture of expert LLMs thatcontrol the quality of the generated conversations. These experts select thebest generated conversations, which we then use to improve the Generator. Werelease Synthetic-Persona-Chat, consisting of 20k conversations seeded fromPersona-Chat. We evaluate the quality of Synthetic-Persona-Chat and ourgeneration framework on different dimensions through extensive experiments, andobserve that the losing rate of Synthetic-Persona-Chat against Persona-Chatduring Turing test decreases from 17.2% to 8.8% over three iterations.</description><author>Pegah Jandaghi, XiangHai Sheng, Xinyi Bai, Jay Pujara, Hakim Sidahmed</author><pubDate>Fri, 15 Dec 2023 18:23:50 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.10007v1</guid></item><item><title>Symplectic Autoencoders for Model Reduction of Hamiltonian Systems</title><link>http://arxiv.org/abs/2312.10004v1</link><description>Many applications, such as optimization, uncertainty quantification andinverse problems, require repeatedly performing simulations oflarge-dimensional physical systems for different choices of parameters. Thiscan be prohibitively expensive. In order to save computational cost, one can construct surrogate models byexpressing the system in a low-dimensional basis, obtained from training data.This is referred to as model reduction. Past investigations have shown that, when performing model reduction ofHamiltonian systems, it is crucial to preserve the symplectic structureassociated with the system in order to ensure long-term numerical stability. Up to this point structure-preserving reductions have largely been limited tolinear transformations. We propose a new neural network architecture in thespirit of autoencoders, which are established tools for dimension reduction andfeature extraction in data science, to obtain more general mappings. In order to train the network, a non-standard gradient descent approach isapplied that leverages the differential-geometric structure emerging from thenetwork design. The new architecture is shown to significantly outperform existing designs inaccuracy.</description><author>Benedikt Brantner, Michael Kraus</author><pubDate>Fri, 15 Dec 2023 18:20:25 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.10004v1</guid></item><item><title>ReST meets ReAct: Self-Improvement for Multi-Step Reasoning LLM Agent</title><link>http://arxiv.org/abs/2312.10003v1</link><description>Answering complex natural language questions often necessitates multi-stepreasoning and integrating external information. Several systems have combinedknowledge retrieval with a large language model (LLM) to answer such questions.These systems, however, suffer from various failure cases, and we cannotdirectly train them end-to-end to fix such failures, as interaction withexternal knowledge is non-differentiable. To address these deficiencies, wedefine a ReAct-style LLM agent with the ability to reason and act upon externalknowledge. We further refine the agent through a ReST-like method thatiteratively trains on previous trajectories, employing growing-batchreinforcement learning with AI feedback for continuous self-improvement andself-distillation. Starting from a prompted large model and after just twoiterations of the algorithm, we can produce a fine-tuned small model thatachieves comparable performance on challenging compositional question-answeringbenchmarks with two orders of magnitude fewer parameters.</description><author>Renat Aksitov, Sobhan Miryoosefi, Zonglin Li, Daliang Li, Sheila Babayan, Kavya Kopparapu, Zachary Fisher, Ruiqi Guo, Sushant Prakash, Pranesh Srinivasan, Manzil Zaheer, Felix Yu, Sanjiv Kumar</author><pubDate>Fri, 15 Dec 2023 18:20:15 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.10003v1</guid></item><item><title>Modeling Unknown Stochastic Dynamical System via Autoencoder</title><link>http://arxiv.org/abs/2312.10001v1</link><description>We present a numerical method to learn an accurate predictive model for anunknown stochastic dynamical system from its trajectory data. The method seeksto approximate the unknown flow map of the underlying system. It employs theidea of autoencoder to identify the unobserved latent random variables. In ourapproach, we design an encoding function to discover the latent variables,which are modeled as unit Gaussian, and a decoding function to reconstruct thefuture states of the system. Both the encoder and decoder are expressed as deepneural networks (DNNs). Once the DNNs are trained by the trajectory data, thedecoder serves as a predictive model for the unknown stochastic system. Throughan extensive set of numerical examples, we demonstrate that the method is ableto produce long-term system predictions by using short bursts of trajectorydata. It is also applicable to systems driven by non-Gaussian noises.</description><author>Zhongshu Xu, Yuan Chen, Qifan Chen, Dongbin Xiu</author><pubDate>Fri, 15 Dec 2023 18:19:22 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.10001v1</guid></item><item><title>One Self-Configurable Model to Solve Many Abstract Visual Reasoning Problems</title><link>http://arxiv.org/abs/2312.09997v1</link><description>Abstract Visual Reasoning (AVR) comprises a wide selection of variousproblems similar to those used in human IQ tests. Recent years have broughtdynamic progress in solving particular AVR tasks, however, in the contemporaryliterature AVR problems are largely dealt with in isolation, leading to highlyspecialized task-specific methods. With the aim of developing universallearning systems in the AVR domain, we propose the unified model for solvingSingle-Choice Abstract visual Reasoning tasks (SCAR), capable of solvingvarious single-choice AVR tasks, without making any a priori assumptions aboutthe task structure, in particular the number and location of panels. Theproposed model relies on a novel Structure-Aware dynamic Layer (SAL), whichadapts its weights to the structure of the considered AVR problem. Experimentsconducted on Raven's Progressive Matrices, Visual Analogy Problems, and Odd OneOut problems show that SCAR (SAL-based models, in general) effectively solvesdiverse AVR tasks, and its performance is on par with the state-of-the-arttask-specific baselines. What is more, SCAR demonstrates effective knowledgereuse in multi-task and transfer learning settings. To our knowledge, this workis the first successful attempt to construct a general single-choice AVR solverrelying on self-configurable architecture and unified solving method. With thiswork we aim to stimulate and foster progress on task-independent research pathsin the AVR domain, with the long-term goal of development of a general AVRsolver.</description><author>Mikołaj Małkiński, Jacek Mańdziuk</author><pubDate>Fri, 15 Dec 2023 18:15:20 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.09997v1</guid></item><item><title>SAT-Based Algorithms for Regular Graph Pattern Matching</title><link>http://arxiv.org/abs/2312.09995v1</link><description>Graph matching is a fundamental problem in pattern recognition, with manyapplications such as software analysis and computational biology. Onewell-known type of graph matching problem is graph isomorphism, which consistsof deciding if two graphs are identical. Despite its usefulness, the propertiesthat one may check using graph isomorphism are rather limited, since it onlyallows strict equality checks between two graphs. For example, it does notallow one to check complex structural properties such as if the target graph isan arbitrary length sequence followed by an arbitrary size loop. We propose a generalization of graph isomorphism that allows one to checksuch properties through a declarative specification. This specification isgiven in the form of a Regular Graph Pattern (ReGaP), a special type of graph,inspired by regular expressions, that may contain wildcard nodes that representarbitrary structures such as variable-sized sequences or subgraphs. We proposea SAT-based algorithm for checking if a target graph matches a given ReGaP. Wealso propose a preprocessing technique for improving the performance of thealgorithm and evaluate it through an extensive experimental evaluation onbenchmarks from the CodeSearchNet dataset.</description><author>Miguel Terra-Neves, José Amaral, Alexandre Lemos, Rui Quintino, Pedro Resende, Antonio Alegria</author><pubDate>Fri, 15 Dec 2023 18:12:44 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.09995v1</guid></item><item><title>CaloQVAE : Simulating high-energy particle-calorimeter interactions using hybrid quantum-classical generative models</title><link>http://arxiv.org/abs/2312.03179v2</link><description>The Large Hadron Collider's high luminosity era presents major computationalchallenges in the analysis of collision events. Large amounts of Monte Carlo(MC) simulation will be required to constrain the statistical uncertainties ofthe simulated datasets below these of the experimental data. Modelling ofhigh-energy particles propagating through the calorimeter section of thedetector is the most computationally intensive MC simulation task. We introducea technique combining recent advancements in generative models and quantumannealing for fast and efficient simulation of high-energy particle-calorimeterinteractions.</description><author>Sehmimul Hoque, Hao Jia, Abhishek Abhishek, Mojde Fadaie, J. Quetzalcoatl Toledo-Marín, Tiago Vale, Roger G. Melko, Maximilian Swiatlowski, Wojciech T. Fedorko</author><pubDate>Fri, 15 Dec 2023 18:07:38 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.03179v2</guid></item><item><title>LLaMAntino: LLaMA 2 Models for Effective Text Generation in Italian Language</title><link>http://arxiv.org/abs/2312.09993v1</link><description>Large Language Models represent state-of-the-art linguistic models designedto equip computers with the ability to comprehend natural language. With itsexceptional capacity to capture complex contextual relationships, the LLaMA(Large Language Model Meta AI) family represents a novel advancement in thefield of natural language processing by releasing foundational models designedto improve the natural language understanding abilities of the transformerarchitecture thanks to their large amount of trainable parameters (7, 13, and70 billion parameters). In many natural language understanding tasks, thesemodels obtain the same performances as private company models such as OpenAIChat-GPT with the advantage to make publicly available weights and code forresearch and commercial uses. In this work, we investigate the possibility ofLanguage Adaptation for LLaMA models, explicitly focusing on addressing thechallenge of Italian Language coverage. Adopting an open science approach, weexplore various tuning approaches to ensure a high-quality text generated inItalian suitable for common tasks in this underrepresented language in theoriginal models' datasets. We aim to release effective text generation modelswith strong linguistic properties for many tasks that seem challenging usingmultilingual or general-purpose LLMs. By leveraging an open science philosophy,this study contributes to Language Adaptation strategies for the Italianlanguage by introducing the novel LLaMAntino family of Italian LLMs.</description><author>Pierpaolo Basile, Elio Musacchio, Marco Polignano, Lucia Siciliani, Giuseppe Fiameni, Giovanni Semeraro</author><pubDate>Fri, 15 Dec 2023 18:06:22 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.09993v1</guid></item><item><title>Towards Architecture-Insensitive Untrained Network Priors for Accelerated MRI Reconstruction</title><link>http://arxiv.org/abs/2312.09988v1</link><description>Untrained neural networks pioneered by Deep Image Prior (DIP) have recentlyenabled MRI reconstruction without requiring fully-sampled measurements fortraining. Their success is widely attributed to the implicit regularizationinduced by suitable network architectures. However, the lack of understandingof such architectural priors results in superfluous design choices andsub-optimal outcomes. This work aims to simplify the architectural designdecisions for DIP-MRI to facilitate its practical deployment. We observe thatcertain architectural components are more prone to causing overfittingregardless of the number of parameters, incurring severe reconstructionartifacts by hindering accurate extrapolation on the un-acquired measurements.We interpret this phenomenon from a frequency perspective and find that thearchitectural characteristics favoring low frequencies, i.e., deep and narrowwith unlearnt upsampling, can lead to enhanced generalization and hence betterreconstruction. Building on this insight, we propose two architecture-agnosticremedies: one to constrain the frequency range of the white-noise input and theother to penalize the Lipschitz constants of the network. We demonstrate thateven with just one extra line of code on the input, the performance gap betweenthe ill-designed models and the high-performing ones can be closed. Theseresults signify that for the first time, architectural biases on untrained MRIreconstruction can be mitigated without architectural modifications.</description><author>Yilin Liu, Yunkui Pang, Jiang Li, Yong Chen, Pew-Thian Yap</author><pubDate>Fri, 15 Dec 2023 18:01:47 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.09988v1</guid></item><item><title>Toward Computationally Efficient Inverse Reinforcement Learning via Reward Shaping</title><link>http://arxiv.org/abs/2312.09983v1</link><description>Inverse reinforcement learning (IRL) is computationally challenging, withcommon approaches requiring the solution of multiple reinforcement learning(RL) sub-problems. This work motivates the use of potential-based rewardshaping to reduce the computational burden of each RL sub-problem. This workserves as a proof-of-concept and we hope will inspire future developmentstowards computationally efficient IRL.</description><author>Lauren H. Cooke, Harvey Klyne, Edwin Zhang, Cassidy Laidlaw, Milind Tambe, Finale Doshi-Velez</author><pubDate>Fri, 15 Dec 2023 17:50:18 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.09983v1</guid></item><item><title>ACPO: AI-Enabled Compiler-Driven Program Optimization</title><link>http://arxiv.org/abs/2312.09982v1</link><description>The key to performance optimization of a program is to decide correctly whena certain transformation should be applied by a compiler. Traditionally, suchprofitability decisions are made by hand-coded algorithms tuned for a verysmall number of benchmarks, usually requiring a great deal of effort to beretuned when the benchmark suite changes. This is an ideal opportunity to applymachine-learning models to speed up the tuning process; while this realizationhas been around since the late 90s, only recent advancements in ML enabled apractical application of ML to compilers as an end-to-end framework. Even so,seamless integration of ML into the compiler would require constant rebuildingof the compiler when models are updated. This paper presents ACPO: \textbf{\underline{A}}I-Enabled\textbf{\underline{C}}ompiler-driven \textbf{\underline{P}}rogram\textbf{\underline{O}}ptimization; a novel framework to provide LLVM withsimple and comprehensive tools to benefit from employing ML models fordifferent optimization passes. We first showcase the high-level view, classhierarchy, and functionalities of ACPO and subsequently, demonstrate \taco{acouple of use cases of ACPO by ML-enabling the Loop Unroll and FunctionInlining passes and describe how ACPO can be leveraged to optimize otherpasses. Experimental results reveal that ACPO model for Loop Unroll is able togain on average 4\% and 3\%, 5.4\%, 0.2\% compared to LLVM's O3 optimizationwhen deployed on Polybench, Coral-2, CoreMark, and Graph-500, respectively.Furthermore, by adding the Inliner model as well, ACPO is able to provide up to4.5\% and 2.4\% on Polybench and Cbench compared with LLVM's O3 optimization,respectively.</description><author>Amir H. Ashouri, Muhammad Asif Manzoor, Duc Minh Vu, Raymond Zhang, Ziwen Wang, Angel Zhang, Bryan Chan, Tomasz S. Czajkowski, Yaoqing Gao</author><pubDate>Fri, 15 Dec 2023 17:49:24 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.09982v1</guid></item><item><title>PulseImpute: A Novel Benchmark Task for Pulsative Physiological Signal Imputation</title><link>http://arxiv.org/abs/2212.07514v2</link><description>The promise of Mobile Health (mHealth) is the ability to use wearable sensorsto monitor participant physiology at high frequencies during daily life toenable temporally-precise health interventions. However, a major challenge isfrequent missing data. Despite a rich imputation literature, existingtechniques are ineffective for the pulsative signals which comprise manymHealth applications, and a lack of available datasets has stymied progress. Weaddress this gap with PulseImpute, the first large-scale pulsative signalimputation challenge which includes realistic mHealth missingness models, anextensive set of baselines, and clinically-relevant downstream tasks. Ourbaseline models include a novel transformer-based architecture designed toexploit the structure of pulsative signals. We hope that PulseImpute willenable the ML community to tackle this significant and challenging task.</description><author>Maxwell A. Xu, Alexander Moreno, Supriya Nagesh, V. Burak Aydemir, David W. Wetter, Santosh Kumar, James M. Rehg</author><pubDate>Fri, 15 Dec 2023 17:45:51 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2212.07514v2</guid></item><item><title>The Art of Balancing: Revolutionizing Mixture of Experts for Maintaining World Knowledge in Language Model Alignment</title><link>http://arxiv.org/abs/2312.09979v1</link><description>Supervised fine-tuning (SFT) is a crucial step for large language models(LLMs), enabling them to align with human instructions and enhance theircapabilities in downstream tasks. When the models are required to align with abroader range of downstream tasks, or there is a desire to notably improve theperformance on a specific task, a substantial increase in fine-tuning dataoften emerges as the solution. However, we find that large-scale increases ininstruction data can disrupt the world knowledge previously stored in the LLMs,i.e., world knowledge forgetting. In this paper, we introduce LoRAMoE toaddress above challenge. The LoRAMoE is a plugin version of Mixture of Experts(MoE). The plugin-form ensures the integrity of world knowledge by freezing thebackbone model during the training phase. And we propose the use of localizedbalancing constraints to coordinate parts of experts for task utilization,meanwhile enables other experts to to fully leverage the world knowledge storedin the models. Experimental results demonstrate that LoRAMoE can reasonlycoordinate experts based on data type during inference, and even dramaticallyincreasing instruction data does not result in knowledge forgetting. Moreover,LoRAMoE provides additional benefits for the performance of downstream tasks,indicating the potential of our approach for multi-task learning.</description><author>Shihan Dou, Enyu Zhou, Yan Liu, Songyang Gao, Jun Zhao, Wei Shen, Yuhao Zhou, Zhiheng Xi, Xiao Wang, Xiaoran Fan, Shiliang Pu, Jiang Zhu, Rui Zheng, Tao Gui, Qi Zhang, Xuanjing Huang</author><pubDate>Fri, 15 Dec 2023 17:45:06 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.09979v1</guid></item><item><title>Small jet engine reservoir computing digital twin</title><link>http://arxiv.org/abs/2312.09978v1</link><description>Machine learning was applied to create a digital twin of a numericalsimulation of a single-scroll jet engine. A similar model based on the insightsgained from this numerical study was used to create a digital twin of a JetCatP100-RX jet engine using only experimental data. Engine data was collected froma custom sensor system measuring parameters such as thrust, exhaust gastemperature, shaft speed, weather conditions, etc. Data was gathered while theengine was placed under different test conditions by controlling shaft speed.The machine learning model was generated (trained) using a next-generationreservoir computer, a best-in-class machine learning algorithm for dynamicalsystems. Once the model was trained, it was used to predict behavior it hadnever seen with an accuracy of better than 1.8% when compared to the testingdata.</description><author>C. J. Wright, N. Biederman, B. Gyovai, D. J. Gauthier, J. P. Wilhelm</author><pubDate>Fri, 15 Dec 2023 17:41:51 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.09978v1</guid></item><item><title>HI-SLAM: Monocular Real-time Dense Mapping with Hybrid Implicit Fields</title><link>http://arxiv.org/abs/2310.04787v2</link><description>In this letter, we present a neural field-based real-time monocular mappingframework for accurate and dense Simultaneous Localization and Mapping (SLAM).Recent neural mapping frameworks show promising results, but rely on RGB-D orpose inputs, or cannot run in real-time. To address these limitations, ourapproach integrates dense-SLAM with neural implicit fields. Specifically, ourdense SLAM approach runs parallel tracking and global optimization, while aneural field-based map is constructed incrementally based on the latest SLAMestimates. For the efficient construction of neural fields, we employmulti-resolution grid encoding and signed distance function (SDF)representation. This allows us to keep the map always up-to-date and adaptinstantly to global updates via loop closing. For global consistency, wepropose an efficient Sim(3)-based pose graph bundle adjustment (PGBA) approachto run online loop closing and mitigate the pose and scale drift. To enhancedepth accuracy further, we incorporate learned monocular depth priors. Wepropose a novel joint depth and scale adjustment (JDSA) module to solve thescale ambiguity inherent in depth priors. Extensive evaluations acrosssynthetic and real-world datasets validate that our approach outperformsexisting methods in accuracy and map completeness while preserving real-timeperformance.</description><author>Wei Zhang, Tiecheng Sun, Sen Wang, Qing Cheng, Norbert Haala</author><pubDate>Fri, 15 Dec 2023 17:35:37 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.04787v2</guid></item><item><title>W-MAE: Pre-trained weather model with masked autoencoder for multi-variable weather forecasting</title><link>http://arxiv.org/abs/2304.08754v2</link><description>Weather forecasting is a long-standing computational challenge with directsocietal and economic impacts. This task involves a large amount of continuousdata collection and exhibits rich spatiotemporal dependencies over longperiods, making it highly suitable for deep learning models. In this paper, weapply pre-training techniques to weather forecasting and propose W-MAE, aWeather model with Masked AutoEncoder pre-training for weather forecasting.W-MAE is pre-trained in a self-supervised manner to reconstruct spatialcorrelations within meteorological variables. On the temporal scale, wefine-tune the pre-trained W-MAE to predict the future states of meteorologicalvariables, thereby modeling the temporal dependencies present in weather data.We conduct our experiments using the fifth-generation ECMWF Reanalysis (ERA5)data, with samples selected every six hours. Experimental results show that ourW-MAE framework offers three key benefits: 1) when predicting the future stateof meteorological variables, the utilization of our pre-trained W-MAE caneffectively alleviate the problem of cumulative errors in prediction,maintaining stable performance in the short-to-medium term; 2) when predictingdiagnostic variables (e.g., total precipitation), our model exhibitssignificant performance advantages over FourCastNet; 3) Our task-agnosticpre-training schema can be easily integrated with various task-specific models.When our pre-training framework is applied to FourCastNet, it yields an average20% performance improvement in Anomaly Correlation Coefficient (ACC).</description><author>Xin Man, Chenghong Zhang, Jin Feng, Changyu Li, Jie Shao</author><pubDate>Fri, 15 Dec 2023 17:34:36 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2304.08754v2</guid></item><item><title>GreenLightningAI: An Efficient AI System with Decoupled Structural and Quantitative Knowledge</title><link>http://arxiv.org/abs/2312.09971v1</link><description>The number and complexity of artificial intelligence (AI) applications isgrowing relentlessly. As a result, even with the many algorithmic andmathematical advances experienced over past decades as well as the impressiveenergy efficiency and computational capacity of current hardware accelerators,training the most powerful and popular deep neural networks comes at very higheconomic and environmental costs. Recognising that additional optimisations ofconventional neural network training is very difficult, this work takes aradically different approach by proposing GreenLightningAI, a new AI systemdesign consisting of a linear model that is capable of emulating the behaviourof deep neural networks by subsetting the model for each particular sample. Thenew AI system stores the information required to select the system subset for agiven sample (referred to as structural information) separately from the linearmodel parameters (referred to as quantitative knowledge). In this paper wepresent a proof of concept, showing that the structural information stabilisesfar earlier than the quantitative knowledge. Additionally, we showexperimentally that the structural information can be kept unmodified whenre-training the AI system with new samples while still achieving a validationaccuracy similar to that obtained when re-training a neural network withsimilar size. Since the proposed AI system is based on a linear model, multiplecopies of the model, trained with different datasets, can be easily combined.This enables faster and greener (re)-training algorithms, including incrementalre-training and federated incremental re-training.</description><author>Jose Duato, Jose I. Mestre, Manuel F. Dolz, Enrique S. Quintana-Ortí</author><pubDate>Fri, 15 Dec 2023 17:34:11 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.09971v1</guid></item><item><title>Federated Inference with Reliable Uncertainty Quantification over Wireless Channels via Conformal Prediction</title><link>http://arxiv.org/abs/2308.04237v2</link><description>In this paper, we consider a wireless federated inference scenario in whichdevices and a server share a pre-trained machine learning model. The devicescommunicate statistical information about their local data to the server over acommon wireless channel, aiming to enhance the quality of the inferencedecision at the server. Recent work has introduced federated conformalprediction (CP), which leverages devices-to-server communication to improve thereliability of the server's decision. With federated CP, devices communicate tothe server information about the loss accrued by the shared pre-trained modelon the local data, and the server leverages this information to calibrate adecision interval, or set, so that it is guaranteed to contain the correctanswer with a pre-defined target reliability level. Previous work assumednoise-free communication, whereby devices can communicate a single real numberto the server. In this paper, we study for the first time federated CP in awireless setting. We introduce a novel protocol, termed wireless federatedconformal prediction (WFCP), which builds on type-based multiple access (TBMA)and on a novel quantile correction strategy. WFCP is proved to provide formalreliability guarantees in terms of coverage of the predicted set produced bythe server. Using numerical results, we demonstrate the significant advantagesof WFCP against digital implementations of existing federated CP schemes,especially in regimes with limited communication resources and/or large numberof devices.</description><author>Meiyi Zhu, Matteo Zecchin, Sangwoo Park, Caili Guo, Chunyan Feng, Osvaldo Simeone</author><pubDate>Fri, 15 Dec 2023 17:30:52 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2308.04237v2</guid></item><item><title>Scalable and hyper-parameter-free non-parametric covariate shift adaptation with conditional sampling</title><link>http://arxiv.org/abs/2312.09969v1</link><description>Many existing covariate shift adaptation methods estimate sample weights tobe used in the risk estimation in order to mitigate the gap between the sourceand the target distribution. However, non-parametrically estimating the optimalweights typically involves computationally expensive hyper-parameter tuningthat is crucial to the final performance. In this paper, we propose a newnon-parametric approach to covariate shift adaptation which avoids estimatingweights and has no hyper-parameter to be tuned. Our basic idea is to labelunlabeled target data according to the $k$-nearest neighbors in the sourcedataset. Our analysis indicates that setting $k = 1$ is an optimal choice.Thanks to this property, there is no need to tune any hyper-parameters, unlikeother non-parametric methods. Moreover, our method achieves a running timequasi-linear in the sample size with a theoretical guarantee, for the firsttime in the literature to the best of our knowledge. Our results include sharprates of convergence for estimating the joint probability distribution of thetarget data. In particular, the variance of our estimators has the same rate ofconvergence as for standard parametric estimation despite their non-parametricnature. Our numerical experiments show that proposed method brings drasticreduction in the running time with accuracy comparable to that of thestate-of-the-art methods.</description><author>François Portier, Lionel Truquet, Ikko Yamane</author><pubDate>Fri, 15 Dec 2023 17:28:09 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.09969v1</guid></item><item><title>Human Perception-Inspired Grain Segmentation Refinement Using Conditional Random Fields</title><link>http://arxiv.org/abs/2312.09968v1</link><description>Accurate segmentation of interconnected line networks, such as grainboundaries in polycrystalline material microstructures, poses a significantchallenge due to the fragmented masks produced by conventional computer visionalgorithms, including convolutional neural networks. These algorithms strugglewith thin masks, often necessitating intricate post-processing for effectivecontour closure and continuity. Addressing this issue, this paper introduces afast, high-fidelity post-processing technique, leveraging domain knowledgeabout grain boundary connectivity and employing conditional random fields andperceptual grouping rules. This approach significantly enhances segmentationmask accuracy, achieving a 79% segment identification accuracy in validationwith a U-Net model on electron microscopy images of a polycrystalline oxide.Additionally, a novel grain alignment metric is introduced, showing a 51%improvement in grain alignment, providing a more detailed assessment ofsegmentation performance for complex microstructures. This method not onlyenables rapid and accurate segmentation but also facilitates an unprecedentedlevel of data analysis, significantly improving the statistical representationof grain boundary networks, making it suitable for a range of disciplines whereprecise segmentation of interconnected line networks is essential.</description><author>Doruk Aksoy, Huolin L. Xin, Timothy J. Rupert, William J. Bowman</author><pubDate>Fri, 15 Dec 2023 17:26:01 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.09968v1</guid></item><item><title>Data and Approaches for German Text simplification -- towards an Accessibility-enhanced Communication</title><link>http://arxiv.org/abs/2312.09966v1</link><description>This paper examines the current state-of-the-art of German textsimplification, focusing on parallel and monolingual German corpora. It reviewsneural language models for simplifying German texts and assesses theirsuitability for legal texts and accessibility requirements. Our findingshighlight the need for additional training data and more appropriate approachesthat consider the specific linguistic characteristics of German, as well as theimportance of the needs and preferences of target groups with cognitive orlanguage impairments. The authors launched the interdisciplinary OPEN-LSproject in April 2023 to address these research gaps. The project aims todevelop a framework for text formats tailored to individuals with low literacylevels, integrate legal texts, and enhance comprehensibility for those withlinguistic or cognitive impairments. It will also explore cost-effective waysto enhance the data with audience-specific illustrations using image-generatingAI. For more and up-to-date information, please visit our project homepagehttps://open-ls.entavis.com</description><author>Thorben Schomacker, Michael Gille, Jörg von der Hülls, Marina Tropmann-Frick</author><pubDate>Fri, 15 Dec 2023 17:23:33 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.09966v1</guid></item><item><title>Symbolic Numeric Planning with Patterns</title><link>http://arxiv.org/abs/2312.09963v1</link><description>In this paper, we propose a novel approach for solving linear numericplanning problems, called Symbolic Pattern Planning. Given a planning problem$\Pi$, a bound $n$ and a pattern -- defined as an arbitrary sequence of actions-- we encode the problem of finding a plan for $\Pi$ with bound $n$ as aformula with fewer variables and/or clauses than the state-of-the-art rolled-upand relaxed-relaxed-$\exists$ encodings. More importantly, we prove that forany given bound, it is never the case that the latter two encodings allowfinding a valid plan while ours does not. On the experimental side, we consider6 other planning systems -- including the ones which participated in thisyear's International Planning Competition (IPC) -- and we show that our plannerPatty has remarkably good comparative performances on this year's IPC problems.</description><author>Matteo Cardellini, Enrico Giunchiglia, Marco Maratea</author><pubDate>Fri, 15 Dec 2023 17:20:25 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.09963v1</guid></item><item><title>How to Use Large Language Models for Text Coding: The Case of Fatherhood Roles in Public Policy Documents</title><link>http://arxiv.org/abs/2311.11844v2</link><description>Recent advances in large language models (LLMs) like GPT-3 and GPT-4 haveopened up new opportunities for text analysis in political science. Theypromise automation with better results and less programming. In this study, weevaluate LLMs on three original coding tasks of non-English political sciencetexts, and we provide a detailed description of a general workflow for usingLLMs for text coding in political science research. Our use case offers apractical guide for researchers looking to incorporate LLMs into their researchon text analysis. We find that, when provided with detailed label definitionsand coding examples, an LLM can be as good as or even better than a humanannotator while being much faster (up to hundreds of times), considerablycheaper (costing up to 60% less than human coding), and much easier to scale tolarge amounts of text. Overall, LLMs present a viable option for most textcoding projects.</description><author>Lorenzo Lupo, Oscar Magnusson, Dirk Hovy, Elin Naurin, Lena Wängnerud</author><pubDate>Fri, 15 Dec 2023 17:18:48 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.11844v2</guid></item><item><title>Risk-Aware Continuous Control with Neural Contextual Bandits</title><link>http://arxiv.org/abs/2312.09961v1</link><description>Recent advances in learning techniques have garnered attention for theirapplicability to a diverse range of real-world sequential decision-makingproblems. Yet, many practical applications have critical constraints foroperation in real environments. Most learning solutions often neglect the riskof failing to meet these constraints, hindering their implementation inreal-world contexts. In this paper, we propose a risk-aware decision-makingframework for contextual bandit problems, accommodating constraints andcontinuous action spaces. Our approach employs an actor multi-criticarchitecture, with each critic characterizing the distribution of performanceand constraint metrics. Our framework is designed to cater to various risklevels, effectively balancing constraint satisfaction against performance. Todemonstrate the effectiveness of our approach, we first compare it againststate-of-the-art baseline methods in a synthetic environment, highlighting theimpact of intrinsic environmental noise across different risk configurations.Finally, we evaluate our framework in a real-world use case involving a 5Gmobile network where only our approach consistently satisfies the systemconstraint (a signal processing reliability target) with a small performancetoll (8.5% increase in power consumption).</description><author>Jose A. Ayala-Romero, Andres Garcia-Saavedra, Xavier Costa-Perez</author><pubDate>Fri, 15 Dec 2023 17:16:04 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.09961v1</guid></item><item><title>Distilling Large Language Models for Matching Patients to Clinical Trials</title><link>http://arxiv.org/abs/2312.09958v1</link><description>The recent success of large language models (LLMs) has paved the way fortheir adoption in the high-stakes domain of healthcare. Specifically, theapplication of LLMs in patient-trial matching, which involves assessing patienteligibility against clinical trial's nuanced inclusion and exclusion criteria,has shown promise. Recent research has shown that GPT-3.5, a widely recognizedLLM developed by OpenAI, can outperform existing methods with minimal 'variableengineering' by simply comparing clinical trial information against patientsummaries. However, there are significant challenges associated with usingclosed-source proprietary LLMs like GPT-3.5 in practical healthcareapplications, such as cost, privacy and reproducibility concerns. To addressthese issues, this study presents the first systematic examination of theefficacy of both proprietary (GPT-3.5, and GPT-4) and open-source LLMs (LLAMA7B,13B, and 70B) for the task of patient-trial matching. Employing amultifaceted evaluation framework, we conducted extensive automated andhuman-centric assessments coupled with a detailed error analysis for eachmodel. To enhance the adaptability of open-source LLMs, we have created aspecialized synthetic dataset utilizing GPT-4, enabling effective fine-tuningunder constrained data conditions. Our findings reveal that open-source LLMs,when fine-tuned on this limited and synthetic dataset, demonstrate performanceparity with their proprietary counterparts. This presents a massive opportunityfor their deployment in real-world healthcare applications. To foster furtherresearch and applications in this field, we release both the annotatedevaluation dataset along with the fine-tuned LLM -- Trial-LLAMA -- for publicuse.</description><author>Mauro Nievas, Aditya Basu, Yanshan Wang, Hrituraj Singh</author><pubDate>Fri, 15 Dec 2023 17:11:07 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.09958v1</guid></item><item><title>Machine Learning for Health symposium 2023 -- Findings track</title><link>http://arxiv.org/abs/2312.00655v3</link><description>A collection of the accepted Findings papers that were presented at the 3rdMachine Learning for Health symposium (ML4H 2023), which was held on December10, 2023, in New Orleans, Louisiana, USA. ML4H 2023 invited high-qualitysubmissions on relevant problems in a variety of health-related disciplinesincluding healthcare, biomedicine, and public health. Two submission trackswere offered: the archival Proceedings track, and the non-archival Findingstrack. Proceedings were targeted at mature work with strong technicalsophistication and a high impact to health. The Findings track looked for newideas that could spark insightful discussion, serve as valuable resources forthe community, or could enable new collaborations. Submissions to theProceedings track, if not accepted, were automatically considered for theFindings track. All the manuscripts submitted to ML4H Symposium underwent adouble-blind peer-review process.</description><author>Stefan Hegselmann, Antonio Parziale, Divya Shanmugam, Shengpu Tang, Mercy Nyamewaa Asiedu, Serina Chang, Thomas Hartvigsen, Harvineet Singh</author><pubDate>Fri, 15 Dec 2023 17:10:35 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.00655v3</guid></item><item><title>DHFormer: A Vision Transformer-Based Attention Module for Image Dehazing</title><link>http://arxiv.org/abs/2312.09955v1</link><description>Images acquired in hazy conditions have degradations induced in them.Dehazing such images is a vexed and ill-posed problem. Scores of prior-basedand learning-based approaches have been proposed to mitigate the effect of hazeand generate haze-free images. Many conventional methods are constrained bytheir lack of awareness regarding scene depth and their incapacity to capturelong-range dependencies. In this paper, a method that uses residual learningand vision transformers in an attention module is proposed. It essentiallycomprises two networks: In the first one, the network takes the ratio of a hazyimage and the approximated transmission matrix to estimate a residual map. Thesecond network takes this residual image as input and passes it throughconvolution layers before superposing it on the generated feature maps. It isthen passed through global context and depth-aware transformer encoders toobtain channel attention. The attention module then infers the spatialattention map before generating the final haze-free image. Experimentalresults, including several quantitative metrics, demonstrate the efficiency andscalability of the suggested methodology.</description><author>Abdul Wasi, O. Jeba Shiney</author><pubDate>Fri, 15 Dec 2023 17:05:32 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.09955v1</guid></item><item><title>Deep Reinforcement Learning for Joint Cruise Control and Intelligent Data Acquisition in UAVs-Assisted Sensor Networks</title><link>http://arxiv.org/abs/2312.09953v1</link><description>Unmanned aerial vehicle (UAV)-assisted sensor networks (UASNets), which playa crucial role in creating new opportunities, are experiencing significantgrowth in civil applications worldwide. UASNets improve disaster managementthrough timely surveillance and advance precision agriculture with detailedcrop monitoring, thereby significantly transforming the commercial economy.UASNets revolutionize the commercial sector by offering greater efficiency,safety, and cost-effectiveness, highlighting their transformative impact. Afundamental aspect of these new capabilities and changes is the collection ofdata from rugged and remote areas. Due to their excellent mobility andmaneuverability, UAVs are employed to collect data from ground sensors in harshenvironments, such as natural disaster monitoring, border surveillance, andemergency response monitoring. One major challenge in these scenarios is thatthe movements of UAVs affect channel conditions and result in packet loss. Fastmovements of UAVs lead to poor channel conditions and rapid signal degradation,resulting in packet loss. On the other hand, slow mobility of a UAV can causebuffer overflows of the ground sensors, as newly arrived data is not promptlycollected by the UAV. Our proposal to address this challenge is to minimize packet loss by jointlyoptimizing the velocity controls and data collection schedules of multipleUAVs.Furthermore, in UASNets, swift movements of UAVs result in poor channelconditions and fast signal attenuation, leading to an extended age ofinformation (AoI). In contrast, slow movements of UAVs prolong flight time,thereby extending the AoI of ground sensors.To address this challenge, wepropose a new mean-field flight resource allocation optimization to minimizethe AoI of sensory data.</description><author>Yousef Emami</author><pubDate>Fri, 15 Dec 2023 17:04:03 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.09953v1</guid></item><item><title>Peer Learning: Learning Complex Policies in Groups from Scratch via Action Recommendations</title><link>http://arxiv.org/abs/2312.09950v1</link><description>Peer learning is a novel high-level reinforcement learning framework foragents learning in groups. While standard reinforcement learning trains anindividual agent in trial-and-error fashion, all on its own, peer learningaddresses a related setting in which a group of agents, i.e., peers, learns tomaster a task simultaneously together from scratch. Peers are allowed tocommunicate only about their own states and actions recommended by others:"What would you do in my situation?". Our motivation is to study the learningbehavior of these agents. We formalize the teacher selection process in theaction advice setting as a multi-armed bandit problem and therefore highlightthe need for exploration. Eventually, we analyze the learning behavior of thepeers and observe their ability to rank the agents' performance within thestudy group and understand which agents give reliable advice. Further, wecompare peer learning with single agent learning and a state-of-the-art actionadvice baseline. We show that peer learning is able to outperform single-agentlearning and the baseline in several challenging discrete and continuous OpenAIGym domains. Doing so, we also show that within such a framework complexpolicies from action recommendations beyond discrete action spaces can evolve.</description><author>Cedric Derstroff, Mattia Cerrato, Jannis Brugger, Jan Peters, Stefan Kramer</author><pubDate>Fri, 15 Dec 2023 17:01:35 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.09950v1</guid></item><item><title>Sketch and shift: a robust decoder for compressive clustering</title><link>http://arxiv.org/abs/2312.09940v1</link><description>Compressive learning is an emerging approach to drastically reduce the memoryfootprint of large-scale learning, by first summarizing a large dataset into alow-dimensional sketch vector, and then decoding from this sketch the latentinformation needed for learning. In light of recent progress on informationpreservation guarantees for sketches based on random features, a majorobjective is to design easy-to-tune algorithms (called decoders) to robustlyand efficiently extract this information. To address the underlying non-convexoptimization problems, various heuristics have been proposed. In the case ofcompressive clustering, the standard heuristic is CL-OMPR, a variant of slidingFrank-Wolfe. Yet, CL-OMPR is hard to tune, and the examination of itsrobustness was overlooked. In this work, we undertake a scrutinized examinationof CL-OMPR to circumvent its limitations. In particular, we show how thisalgorithm can fail to recover the clusters even in advantageous scenarios. Togain insight, we show how the deficiencies of this algorithm can be attributedto optimization difficulties related to the structure of a correlation functionappearing at core steps of the algorithm. To address these limitations, wepropose an alternative decoder offering substantial improvements over CL-OMPR.Its design is notably inspired from the mean shift algorithm, a classicapproach to detect the local maxima of kernel density estimators. The proposedalgorithm can extract clustering information from a sketch of the MNIST datasetthat is 10 times smaller than previously.</description><author>Ayoub Belhadji, Rémi Gribonval</author><pubDate>Fri, 15 Dec 2023 16:53:55 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.09940v1</guid></item><item><title>Quantum Generative Adversarial Networks: Bridging Classical and Quantum Realms</title><link>http://arxiv.org/abs/2312.09939v1</link><description>In this pioneering research paper, we present a groundbreaking explorationinto the synergistic fusion of classical and quantum computing paradigms withinthe realm of Generative Adversarial Networks (GANs). Our objective is toseamlessly integrate quantum computational elements into the conventional GANarchitecture, thereby unlocking novel pathways for enhanced training processes. Drawing inspiration from the inherent capabilities of quantum bits (qubits),we delve into the incorporation of quantum data representation methodologieswithin the GAN framework. By capitalizing on the unique quantum features, weaim to accelerate the training process of GANs, offering a fresh perspective onthe optimization of generative models. Our investigation deals with theoretical considerations and evaluates thepotential quantum advantages that may manifest in terms of training efficiencyand generative quality. We confront the challenges inherent in thequantum-classical amalgamation, addressing issues related to quantum hardwareconstraints, error correction mechanisms, and scalability considerations. Thisresearch is positioned at the forefront of quantum-enhanced machine learning,presenting a critical stride towards harnessing the computational power ofquantum systems to expedite the training of Generative Adversarial Networks.Through our comprehensive examination of the interface between classical andquantum realms, we aim to uncover transformative insights that will propel thefield forward, fostering innovation and advancing the frontier of quantummachine learning.</description><author>Sahil Nokhwal, Suman Nokhwal, Ram Swaroop, Raj Bala, Ankit Chaudhary</author><pubDate>Fri, 15 Dec 2023 16:51:36 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.09939v1</guid></item><item><title>Assume-Guarantee Reinforcement Learning</title><link>http://arxiv.org/abs/2312.09938v1</link><description>We present a modular approach to \emph{reinforcement learning} (RL) inenvironments consisting of simpler components evolving in parallel. Amonolithic view of such modular environments may be prohibitively large tolearn, or may require unrealizable communication between the components in theform of a centralized controller. Our proposed approach is based on theassume-guarantee paradigm where the optimal control for the individualcomponents is synthesized in isolation by making \emph{assumptions} about thebehaviors of neighboring components, and providing \emph{guarantees} abouttheir own behavior. We express these \emph{assume-guarantee contracts} asregular languages and provide automatic translations to scalar rewards to beused in RL. By combining local probabilities of satisfaction for eachcomponent, we provide a lower bound on the probability of satisfaction of thecomplete system. By solving a Markov game for each component, RL can produce acontroller for each component that maximizes this lower bound. The controllerutilizes the information it receives through communication, observations, andany knowledge of a coarse model of other agents. We experimentally demonstratethe efficiency of the proposed approach on a variety of case studies.</description><author>Milad Kazemi, Mateo Perez, Fabio Somenzi, Sadegh Soudjani, Ashutosh Trivedi, Alvaro Velasquez</author><pubDate>Fri, 15 Dec 2023 16:49:57 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.09938v1</guid></item><item><title>Label Words are Anchors: An Information Flow Perspective for Understanding In-Context Learning</title><link>http://arxiv.org/abs/2305.14160v3</link><description>In-context learning (ICL) emerges as a promising capability of large languagemodels (LLMs) by providing them with demonstration examples to perform diversetasks. However, the underlying mechanism of how LLMs learn from the providedcontext remains under-explored. In this paper, we investigate the workingmechanism of ICL through an information flow lens. Our findings reveal thatlabel words in the demonstration examples function as anchors: (1) semanticinformation aggregates into label word representations during the shallowcomputation layers' processing; (2) the consolidated information in label wordsserves as a reference for LLMs' final predictions. Based on these insights, weintroduce an anchor re-weighting method to improve ICL performance, ademonstration compression technique to expedite inference, and an analysisframework for diagnosing ICL errors in GPT2-XL. The promising applications ofour findings again validate the uncovered ICL working mechanism and pave theway for future studies.</description><author>Lean Wang, Lei Li, Damai Dai, Deli Chen, Hao Zhou, Fandong Meng, Jie Zhou, Xu Sun</author><pubDate>Fri, 15 Dec 2023 16:48:15 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.14160v3</guid></item><item><title>LogoStyleFool: Vitiating Video Recognition Systems via Logo Style Transfer</title><link>http://arxiv.org/abs/2312.09935v1</link><description>Video recognition systems are vulnerable to adversarial examples. Recentstudies show that style transfer-based and patch-based unrestrictedperturbations can effectively improve attack efficiency. These attacks,however, face two main challenges: 1) Adding large stylized perturbations toall pixels reduces the naturalness of the video and such perturbations can beeasily detected. 2) Patch-based video attacks are not extensible to targetedattacks due to the limited search space of reinforcement learning that has beenwidely used in video attacks recently. In this paper, we focus on the videoblack-box setting and propose a novel attack framework named LogoStyleFool byadding a stylized logo to the clean video. We separate the attack into threestages: style reference selection, reinforcement-learning-based logo styletransfer, and perturbation optimization. We solve the first challenge byscaling down the perturbation range to a regional logo, while the secondchallenge is addressed by complementing an optimization stage afterreinforcement learning. Experimental results substantiate the overallsuperiority of LogoStyleFool over three state-of-the-art patch-based attacks interms of attack performance and semantic preservation. Meanwhile, LogoStyleFoolstill maintains its performance against two existing patch-based defensemethods. We believe that our research is beneficial in increasing the attentionof the security community to such subregional style transfer attacks.</description><author>Yuxin Cao, Ziyu Zhao, Xi Xiao, Derui Wang, Minhui Xue, Jin Lu</author><pubDate>Fri, 15 Dec 2023 16:44:38 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.09935v1</guid></item><item><title>RDR: the Recap, Deliberate, and Respond Method for Enhanced Language Understanding</title><link>http://arxiv.org/abs/2312.09932v1</link><description>Natural language understanding (NLU) using neural network pipelines oftenrequires additional context that is not solely present in the input data.Through Prior research, it has been evident that NLU benchmarks are susceptibleto manipulation by neural models, wherein these models exploit statisticalartifacts within the encoded external knowledge to artificially inflateperformance metrics for downstream tasks. Our proposed approach, known as theRecap, Deliberate, and Respond (RDR) paradigm, addresses this issue byincorporating three distinct objectives within the neural network pipeline.Firstly, the Recap objective involves paraphrasing the input text using aparaphrasing model in order to summarize and encapsulate its essence. Secondly,the Deliberation objective entails encoding external graph information relatedto entities mentioned in the input text, utilizing a graph embedding model.Finally, the Respond objective employs a classification head model thatutilizes representations from the Recap and Deliberation modules to generatethe final prediction. By cascading these three models and minimizing a combinedloss, we mitigate the potential for gaming the benchmark and establish a robustmethod for capturing the underlying semantic patterns, thus enabling accuratepredictions. To evaluate the effectiveness of the RDR method, we conduct testson multiple GLUE benchmark tasks. Our results demonstrate improved performancecompared to competitive baselines, with an enhancement of up to 2\% on standardmetrics. Furthermore, we analyze the observed evidence for semanticunderstanding exhibited by RDR models, emphasizing their ability to avoidgaming the benchmark and instead accurately capture the true underlyingsemantic patterns.</description><author>Yuxin Zi, Hariram Veeramani, Kaushik Roy, Amit Sheth</author><pubDate>Fri, 15 Dec 2023 16:41:48 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.09932v1</guid></item><item><title>Neurosymbolic Value-Inspired AI (Why, What, and How)</title><link>http://arxiv.org/abs/2312.09928v1</link><description>The rapid progression of Artificial Intelligence (AI) systems, facilitated bythe advent of Large Language Models (LLMs), has resulted in their widespreadapplication to provide human assistance across diverse industries. This trendhas sparked significant discourse centered around the ever-increasing need forLLM-based AI systems to function among humans as part of human society, sharinghuman values, especially as these systems are deployed in high-stakes settings(e.g., healthcare, autonomous driving, etc.). Towards this end, neurosymbolicAI systems are attractive due to their potential to enable easy-to-understandand interpretable interfaces for facilitating value-based decision-making, byleveraging explicit representations of shared values. In this paper, weintroduce substantial extensions to Khaneman's System one/two framework andpropose a neurosymbolic computational framework called Value-Inspired AI (VAI).It outlines the crucial components essential for the robust and practicalimplementation of VAI systems, aiming to represent and integrate variousdimensions of human values. Finally, we further offer insights into the currentprogress made in this direction and outline potential future directions for thefield.</description><author>Amit Sheth, Kaushik Roy</author><pubDate>Fri, 15 Dec 2023 16:33:57 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.09928v1</guid></item><item><title>Incorporating Season and Solar Specificity into Renderings made by a NeRF Architecture using Satellite Images</title><link>http://arxiv.org/abs/2308.01262v2</link><description>As a result of Shadow NeRF and Sat-NeRF, it is possible to take the solarangle into account in a NeRF-based framework for rendering a scene from a novelviewpoint using satellite images for training. Our work extends thosecontributions and shows how one can make the renderings season-specific. Ourmain challenge was creating a Neural Radiance Field (NeRF) that could renderseasonal features independently of viewing angle and solar angle while stillbeing able to render shadows. We teach our network to render seasonal featuresby introducing one more input variable -- time of the year. However, the smalltraining datasets typical of satellite imagery can introduce ambiguities incases where shadows are present in the same location for every image of aparticular season. We add additional terms to the loss function to discouragethe network from using seasonal features for accounting for shadows. We showthe performance of our network on eight Areas of Interest containing imagescaptured by the Maxar WorldView-3 satellite. This evaluation includes testsmeasuring the ability of our framework to accurately render novel views,generate height maps, predict shadows, and specify seasonal featuresindependently from shadows. Our ablation studies justify the choices made fornetwork design parameters.</description><author>Michael Gableman, Avinash Kak</author><pubDate>Fri, 15 Dec 2023 16:33:17 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2308.01262v2</guid></item><item><title>FuXi-S2S: An accurate machine learning model for global subseasonal forecasts</title><link>http://arxiv.org/abs/2312.09926v1</link><description>Skillful subseasonal forecasts beyond 2 weeks are crucial for a wide range ofapplications across various sectors of society. Recently, state-of-the-artmachine learning based weather forecasting models have made significantadvancements, outperforming the high-resolution forecast (HRES) from theEuropean Centre for Medium-Range Weather Forecasts (ECMWF). However, the fullpotential of machine learning models in subseasonal forecasts has yet to befully explored. In this study, we introduce FuXi Subseasonal-to-Seasonal(FuXi-S2S), a machine learning based subseasonal forecasting model thatprovides global daily mean forecasts up to 42 days, covering 5 upper-airatmospheric variables at 13 pressure levels and 11 surface variables. FuXi-S2Sintegrates an enhanced FuXi base model with a perturbation module forflow-dependent perturbations in hidden features, and incorporates Perlin noiseto perturb initial conditions. The model is developed using 72 years of dailystatistics from ECMWF ERA5 reanalysis data. When compared to the ECMWFSubseasonal-to-Seasonal (S2S) reforecasts, the FuXi-S2S forecasts demonstratesuperior deterministic and ensemble forecasts for total precipitation (TP),outgoing longwave radiation (OLR), and geopotential at 500 hPa (Z500). Althoughit shows slightly inferior performance in predicting 2-meter temperature (T2M),it has clear advantages over land area. Regarding the extreme forecasts,FuXi-S2S outperforms ECMWF S2S globally for TP. Furthermore, FuXi-S2S forecastssurpass the ECMWF S2S reforecasts in predicting the Madden Julian Oscillation(MJO), a key source of subseasonal predictability. They extend the skillfulprediction of MJO from 30 days to 36 days.</description><author>Lei Chen, Xiaohui Zhong, Jie Wu, Deliang Chen, Shangping Xie, Qingchen Chao, Chensen Lin, Zixin Hu, Bo Lu, Hao Li, Yuan Qi</author><pubDate>Fri, 15 Dec 2023 16:31:44 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.09926v1</guid></item><item><title>CNC-Net: Self-Supervised Learning for CNC Machining Operations</title><link>http://arxiv.org/abs/2312.09925v1</link><description>CNC manufacturing is a process that employs computer numerical control (CNC)machines to govern the movements of various industrial tools and machinery,encompassing equipment ranging from grinders and lathes to mills and CNCrouters. However, the reliance on manual CNC programming has become abottleneck, and the requirement for expert knowledge can result in significantcosts. Therefore, we introduce a pioneering approach named CNC-Net,representing the use of deep neural networks (DNNs) to simulate CNC machinesand grasp intricate operations when supplied with raw materials. CNC-Netconstitutes a self-supervised framework that exclusively takes an input 3Dmodel and subsequently generates the essential operation parameters required bythe CNC machine to construct the object. Our method has the potential totransformative automation in manufacturing by offering a cost-effectivealternative to the high costs of manual CNC programming while maintainingexceptional precision in 3D object production. Our experiments underscore theeffectiveness of our CNC-Net in constructing the desired 3D objects through theutilization of CNC operations. Notably, it excels in preserving finer localdetails, exhibiting a marked enhancement in precision compared to thestate-of-the-art 3D CAD reconstruction approaches.</description><author>Mohsen Yavartanoo, Sangmin Hong, Reyhaneh Neshatavar, Kyoung Mu Lee</author><pubDate>Fri, 15 Dec 2023 16:31:17 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.09925v1</guid></item><item><title>A Unifying Tensor View for Lightweight CNNs</title><link>http://arxiv.org/abs/2312.09922v1</link><description>Despite the decomposition of convolutional kernels for lightweight CNNs beingwell studied, existing works that rely on tensor network diagrams orhyperdimensional abstraction lack geometry intuition. This work devises a newperspective by linking a 3D-reshaped kernel tensor to its various slice-wiseand rank-1 decompositions, permitting a straightforward connection betweenvarious tensor approximations and efficient CNN modules. Specifically, it isdiscovered that a pointwise-depthwise-pointwise (PDP) configuration constitutesa viable construct for lightweight CNNs. Moreover, a novel link to the latestShiftNet is established, inspiring a first-ever shift layer pruning thatachieves nearly 50% compression with &lt; 1% drop in accuracy for ShiftResNet.</description><author>Jason Chun Lok Li, Rui Lin, Jiajun Zhou, Edmund Yin Mun Lam, Ngai Wong</author><pubDate>Fri, 15 Dec 2023 16:30:59 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.09922v1</guid></item><item><title>Mava: a research library for distributed multi-agent reinforcement learning in JAX</title><link>http://arxiv.org/abs/2107.01460v2</link><description>Multi-agent reinforcement learning (MARL) research is inherentlycomputationally expensive and it is often difficult to obtain a sufficientnumber of experiment samples to test hypotheses and make robust statisticalclaims. Furthermore, MARL algorithms are typically complex in their design andcan be tricky to implement correctly. These aspects of MARL present a difficultchallenge when it comes to creating useful software for advanced research. Ourcriteria for such software is that it should be simple enough to use toimplement new ideas quickly, while at the same time be scalable and fast enoughto test those ideas in a reasonable amount of time. In this preliminarytechnical report, we introduce Mava, a research library for MARL written purelyin JAX, that aims to fulfill these criteria. We discuss the design and corefeatures of Mava, and demonstrate its use and performance across a variety ofenvironments. In particular, we show Mava's substantial speed advantage, withimprovements of 10-100x compared to other popular MARL frameworks, whilemaintaining strong performance. This allows for researchers to test ideas in afew minutes instead of several hours. Finally, Mava forms part of an ecosystemof libraries that seamlessly integrate with each other to help facilitateadvanced research in MARL. We hope Mava will benefit the community and helpdrive scientifically sound and statistically robust research in the field. Theopen-source repository for Mava is available athttps://github.com/instadeepai/Mava.</description><author>Ruan de Kock, Omayma Mahjoub, Sasha Abramowitz, Wiem Khlifi, Callum Rhys Tilbury, Claude Formanek, Andries Smit, Arnu Pretorius</author><pubDate>Fri, 15 Dec 2023 16:29:24 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2107.01460v2</guid></item><item><title>Very high resolution canopy height maps from RGB imagery using self-supervised vision transformer and convolutional decoder trained on Aerial Lidar</title><link>http://arxiv.org/abs/2304.07213v3</link><description>Vegetation structure mapping is critical for understanding the global carboncycle and monitoring nature-based approaches to climate adaptation andmitigation. Repeated measurements of these data allow for the observation ofdeforestation or degradation of existing forests, natural forest regeneration,and the implementation of sustainable agricultural practices like agroforestry.Assessments of tree canopy height and crown projected area at a high spatialresolution are also important for monitoring carbon fluxes and assessingtree-based land uses, since forest structures can be highly spatiallyheterogeneous, especially in agroforestry systems. Very high resolutionsatellite imagery (less than one meter (1m) Ground Sample Distance) makes itpossible to extract information at the tree level while allowing monitoring ata very large scale. This paper presents the first high-resolution canopy heightmap concurrently produced for multiple sub-national jurisdictions.Specifically, we produce very high resolution canopy height maps for the statesof California and Sao Paulo, a significant improvement in resolution over theten meter (10m) resolution of previous Sentinel / GEDI based worldwide maps ofcanopy height. The maps are generated by the extraction of features from aself-supervised model trained on Maxar imagery from 2017 to 2020, and thetraining of a dense prediction decoder against aerial lidar maps. We alsointroduce a post-processing step using a convolutional network trained on GEDIobservations. We evaluate the proposed maps with set-aside validation lidardata as well as by comparing with other remotely sensed maps andfield-collected data, and find our model produces an average Mean AbsoluteError (MAE) of 2.8 meters and Mean Error (ME) of 0.6 meters.</description><author>Jamie Tolan, Hung-I Yang, Ben Nosarzewski, Guillaume Couairon, Huy Vo, John Brandt, Justine Spore, Sayantan Majumdar, Daniel Haziza, Janaki Vamaraju, Theo Moutakanni, Piotr Bojanowski, Tracy Johns, Brian White, Tobias Tiecke, Camille Couprie</author><pubDate>Fri, 15 Dec 2023 16:28:21 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2304.07213v3</guid></item><item><title>Red AI? Inconsistent Responses from GPT3.5 Models on Political Issues in the US and China</title><link>http://arxiv.org/abs/2312.09917v1</link><description>The rising popularity of ChatGPT and other AI-powered large language models(LLMs) has led to increasing studies highlighting their susceptibility tomistakes and biases. However, most of these studies focus on models trained onEnglish texts. Taking an innovative approach, this study investigates politicalbiases in GPT's multilingual models. We posed the same question abouthigh-profile political issues in the United States and China to GPT in bothEnglish and simplified Chinese, and our analysis of the bilingual responsesrevealed that GPT's bilingual models' political "knowledge" (content) and thepolitical "attitude" (sentiment) are significantly more inconsistent onpolitical issues in China. The simplified Chinese GPT models not only tended toprovide pro-China information but also presented the least negative sentimenttowards China's problems, whereas the English GPT was significantly morenegative towards China. This disparity may stem from Chinese state censorshipand US-China geopolitical tensions, which influence the training corpora of GPTbilingual models. Moreover, both Chinese and English models tended to be lesscritical towards the issues of "their own" represented by the language used,than the issues of "the other." This suggests that GPT multilingual modelscould potentially develop a "political identity" and an associated sentimentbias based on their training language. We discussed the implications of ourfindings for information transmission and communication in an increasinglydivided world.</description><author>Di Zhou, Yinxian Zhang</author><pubDate>Fri, 15 Dec 2023 16:25:56 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.09917v1</guid></item><item><title>LAENeRF: Local Appearance Editing for Neural Radiance Fields</title><link>http://arxiv.org/abs/2312.09913v1</link><description>Due to the omnipresence of Neural Radiance Fields (NeRFs), the interesttowards editable implicit 3D representations has surged over the last years.However, editing implicit or hybrid representations as used for NeRFs isdifficult due to the entanglement of appearance and geometry encoded in themodel parameters. Despite these challenges, recent research has shown firstpromising steps towards photorealistic and non-photorealistic appearance edits.The main open issues of related work include limited interactivity, a lack ofsupport for local edits and large memory requirements, rendering them lessuseful in practice. We address these limitations with LAENeRF, a unifiedframework for photorealistic and non-photorealistic appearance editing ofNeRFs. To tackle local editing, we leverage a voxel grid as starting point forregion selection. We learn a mapping from expected ray terminations to finaloutput color, which can optionally be supervised by a style loss, resulting ina framework which can perform photorealistic and non-photorealistic appearanceediting of selected regions. Relying on a single point per ray for our mapping,we limit memory requirements and enable fast optimization. To guaranteeinteractivity, we compose the output color using a set of learned, modifiablebase colors, composed with additive layer mixing. Compared to concurrent work,LAENeRF enables recoloring and stylization while keeping processing time low.Furthermore, we demonstrate that our approach surpasses baseline methods bothquantitatively and qualitatively.</description><author>Lukas Radl, Michael Steiner, Andreas Kurz, Markus Steinberger</author><pubDate>Fri, 15 Dec 2023 16:23:42 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.09913v1</guid></item><item><title>Reliable Probabilistic Classification with Neural Networks</title><link>http://arxiv.org/abs/2312.09912v1</link><description>Venn Prediction (VP) is a new machine learning framework for producingwell-calibrated probabilistic predictions. In particular it provideswell-calibrated lower and upper bounds for the conditional probability of anexample belonging to each possible class of the problem at hand. This paperproposes five VP methods based on Neural Networks (NNs), which is one of themost widely used machine learning techniques. The proposed methods areevaluated experimentally on four benchmark datasets and the obtained resultsdemonstrate the empirical well-calibratedness of their outputs and theirsuperiority over the outputs of the traditional NN classifier.</description><author>Harris Papadopoulos</author><pubDate>Fri, 15 Dec 2023 16:23:25 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.09912v1</guid></item><item><title>TMP: Temporal Motion Propagation for Online Video Super-Resolution</title><link>http://arxiv.org/abs/2312.09909v1</link><description>Online video super-resolution (online-VSR) highly relies on an effectivealignment module to aggregate temporal information, while the strict latencyrequirement makes accurate and efficient alignment very challenging. Thoughmuch progress has been achieved, most of the existing online-VSR methodsestimate the motion fields of each frame separately to perform alignment, whichis computationally redundant and ignores the fact that the motion fields ofadjacent frames are correlated. In this work, we propose an efficient TemporalMotion Propagation (TMP) method, which leverages the continuity of motion fieldto achieve fast pixel-level alignment among consecutive frames. Specifically,we first propagate the offsets from previous frames to the current frame, andthen refine them in the neighborhood, which significantly reduces the matchingspace and speeds up the offset estimation process. Furthermore, to enhance therobustness of alignment, we perform spatial-wise weighting on the warpedfeatures, where the positions with more precise offsets are assigned higherimportance. Experiments on benchmark datasets demonstrate that the proposed TMPmethod achieves leading online-VSR accuracy as well as inference speed. Thesource code of TMP can be found at\href{https://github.com/xtudbxk/TMP}{https://github.com/xtudbxk/TMP}.</description><author>Zhengqiang Zhang, Ruihuang Li, Shi Guo, Yang Cao, Lei Zhang</author><pubDate>Fri, 15 Dec 2023 16:17:34 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.09909v1</guid></item><item><title>Unsupervised Neighborhood Propagation Kernel Layers for Semi-supervised Node Classification</title><link>http://arxiv.org/abs/2301.13764v3</link><description>We present a deep Graph Convolutional Kernel Machine (GCKM) forsemi-supervised node classification in graphs. The method is built of two maintypes of blocks: (i) We introduce unsupervised kernel machine layerspropagating the node features in a one-hop neighborhood, using implicit nodefeature mappings. (ii) We specify a semi-supervised classification kernelmachine through the lens of the Fenchel-Young inequality. We derive aneffective initialization scheme and efficient end-to-end training algorithm inthe dual variables for the full architecture. The main idea underlying GCKM isthat, because of the unsupervised core, the final model can achieve higherperformance in semi-supervised node classification when few labels areavailable for training. Experimental results demonstrate the effectiveness ofthe proposed framework.</description><author>Sonny Achten, Francesco Tonin, Panagiotis Patrinos, Johan A. K. Suykens</author><pubDate>Fri, 15 Dec 2023 16:11:46 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2301.13764v3</guid></item><item><title>Exploring Automatic Text Simplification of German Narrative Documents</title><link>http://arxiv.org/abs/2312.09907v1</link><description>In this paper, we apply transformer-based Natural Language Generation (NLG)techniques to the problem of text simplification. Currently, there are only afew German datasets available for text simplification, even fewer with largerand aligned documents, and not a single one with narrative texts. In thispaper, we explore to which degree modern NLG techniques can be applied toGerman narrative text simplifications. We use Longformer attention and apre-trained mBART model. Our findings indicate that the existing approaches forGerman are not able to solve the task properly. We conclude on a few directionsfor future research to address this problem.</description><author>Thorben Schomacker, Tillmann Dönicke, Marina Tropmann-Frick</author><pubDate>Fri, 15 Dec 2023 16:10:44 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.09907v1</guid></item><item><title>The Missing U for Efficient Diffusion Models</title><link>http://arxiv.org/abs/2310.20092v3</link><description>Diffusion Probabilistic Models stand as a critical tool in generativemodelling, enabling the generation of complex data distributions. This familyof generative models yields record-breaking performance in tasks such as imagesynthesis, video generation, and molecule design. Despite their capabilities,their efficiency, especially in the reverse process, remains a challenge due toslow convergence rates and high computational costs. In this paper, weintroduce an approach that leverages continuous dynamical systems to design anovel denoising network for diffusion models that is more parameter-efficient,exhibits faster convergence, and demonstrates increased noise robustness.Experimenting with Denoising Diffusion Probabilistic Models (DDPMs), ourframework operates with approximately a quarter of the parameters, and $\sim$30\% of the Floating Point Operations (FLOPs) compared to standard U-Nets inDDPMs. Furthermore, our model is notably faster in inference than the baselinewhen measured in fair and equal conditions. We also provide a mathematicalintuition as to why our proposed reverse process is faster as well as amathematical discussion of the empirical tradeoffs in the denoising downstreamtask. Finally, we argue that our method is compatible with existing performanceenhancement techniques, enabling further improvements in efficiency, quality,and speed.</description><author>Sergio Calvo-Ordonez, Chun-Wun Cheng, Jiahao Huang, Lipei Zhang, Guang Yang, Carola-Bibiane Schonlieb, Angelica I Aviles-Rivero</author><pubDate>Fri, 15 Dec 2023 16:09:51 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.20092v3</guid></item><item><title>Sample-Efficient Learning to Solve a Real-World Labyrinth Game Using Data-Augmented Model-Based Reinforcement Learning</title><link>http://arxiv.org/abs/2312.09906v1</link><description>Motivated by the challenge of achieving rapid learning in physicalenvironments, this paper presents the development and training of a roboticsystem designed to navigate and solve a labyrinth game using model-basedreinforcement learning techniques. The method involves extractinglow-dimensional observations from camera images, along with a cropped andrectified image patch centered on the current position within the labyrinth,providing valuable information about the labyrinth layout. The learning of acontrol policy is performed purely on the physical system using model-basedreinforcement learning, where the progress along the labyrinth's path serves asa reward signal. Additionally, we exploit the system's inherent symmetries toaugment the training data. Consequently, our approach learns to successfullysolve a popular real-world labyrinth game in record time, with only 5 hours ofreal-world training data.</description><author>Thomas Bi, Raffaello D'Andrea</author><pubDate>Fri, 15 Dec 2023 16:08:49 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.09906v1</guid></item><item><title>Bimodal Camera Pose Prediction for Endoscopy</title><link>http://arxiv.org/abs/2204.04968v2</link><description>Deducing the 3D structure of endoscopic scenes from images is exceedinglychallenging. In addition to deformation and view-dependent lighting, tubularstructures like the colon present problems stemming from their self-occludingand repetitive anatomical structure. In this paper, we propose SimCol, asynthetic dataset for camera pose estimation in colonoscopy, and a novel methodthat explicitly learns a bimodal distribution to predict the endoscope pose.Our dataset replicates real colonoscope motion and highlights the drawbacks ofexisting methods. We publish 18k RGB images from simulated colonoscopy withcorresponding depth and camera poses and make our data generation environmentin Unity publicly available. We evaluate different camera pose predictionmethods and demonstrate that, when trained on our data, they generalize to realcolonoscopy sequences, and our bimodal approach outperforms prior unimodalwork.</description><author>Anita Rau, Binod Bhattarai, Lourdes Agapito, Danail Stoyanov</author><pubDate>Fri, 15 Dec 2023 16:08:46 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2204.04968v2</guid></item><item><title>Online Saddle Point Problem and Online Convex-Concave Optimization</title><link>http://arxiv.org/abs/2312.06957v2</link><description>Centered around solving the Online Saddle Point problem, this paperintroduces the Online Convex-Concave Optimization (OCCO) framework, whichinvolves a sequence of two-player time-varying convex-concave games. We proposethe generalized duality gap (Dual-Gap) as the performance metric and establishthe parallel relationship between OCCO with Dual-Gap and Online ConvexOptimization (OCO) with regret. To demonstrate the natural extension of OCCOfrom OCO, we develop two algorithms, the implicit online mirror descent-ascentand its optimistic variant. Analysis reveals that their duality gaps sharesimilar expression forms with the corresponding dynamic regrets arising fromimplicit updates in OCO. Empirical results further substantiate theeffectiveness of our algorithms. Simultaneously, we unveil that the dynamicNash equilibrium regret, which was initially introduced in a recent paper, hasinherent defects.</description><author>Qing-xin Meng, Jian-wei Liu</author><pubDate>Fri, 15 Dec 2023 16:04:24 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.06957v2</guid></item><item><title>Concise Fuzzy Planar Embedding of Graphs: a Dimensionality Reduction Approach</title><link>http://arxiv.org/abs/1803.03114v2</link><description>The enormous amount of data to be represented using large graphs exceeds insome cases the resources of a conventional computer. Edges in particular cantake up a considerable amount of memory as compared to the number of nodes.However, rigorous edge storage might not always be essential to be able to drawthe needed conclusions. A similar problem takes records with many variables andattempts to extract the most discernible features. It is said that the``dimension'' of this data is reduced. Following an approach with the sameobjective in mind, we can map a graph representation to a $k$-dimensional spaceand answer queries of neighboring nodes mainly by measuring Euclideandistances. The accuracy of our answers would decrease but would be compensatedfor by fuzzy logic which gives an idea about the likelihood of error. Thismethod allows for reasonable representation in memory while maintaining a fairamount of useful information, and allows for concise embedding in$k$-dimensional Euclidean space as well as solving some problems without havingto decompress the graph. Of particular interest is the case where $k=2$.Promising highly accurate experimental results are obtained and reported.</description><author>Faisal N. Abu-Khzam, Rana H. Mouawi, Amer Hajj Ahmad, Sergio Thoumi</author><pubDate>Fri, 15 Dec 2023 16:04:22 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/1803.03114v2</guid></item><item><title>Semantic Complete Scene Forecasting from a 4D Dynamic Point Cloud Sequence</title><link>http://arxiv.org/abs/2312.08054v2</link><description>We study a new problem of semantic complete scene forecasting (SCSF) in thiswork. Given a 4D dynamic point cloud sequence, our goal is to forecast thecomplete scene corresponding to the future next frame along with its semanticlabels. To tackle this challenging problem, we properly model the synergeticrelationship between future forecasting and semantic scene completion through anovel network named SCSFNet. SCSFNet leverages a hybrid geometricrepresentation for high-resolution complete scene forecasting. To leveragemulti-frame observation as well as the understanding of scene dynamics to easethe completion task, SCSFNet introduces an attention-based skip connectionscheme. To ease the need to model occlusion variations and to better focus onthe occluded part, SCSFNet utilizes auxiliary visibility grids to guide theforecasting task. To evaluate the effectiveness of SCSFNet, we conductexperiments on various benchmarks including two large-scale indoor benchmarkswe contributed and the outdoor SemanticKITTI benchmark. Extensive experimentsshow SCSFNet outperforms baseline methods on multiple metrics by a largemargin, and also prove the synergy between future forecasting and semanticscene completion.</description><author>Zifan Wang, Zhuorui Ye, Haoran Wu, Junyu Chen, Li Yi</author><pubDate>Fri, 15 Dec 2023 16:03:13 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.08054v2</guid></item><item><title>Streaming Active Learning for Regression Problems Using Regression via Classification</title><link>http://arxiv.org/abs/2309.01013v2</link><description>One of the challenges in deploying a machine learning model is that themodel's performance degrades as the operating environment changes. To maintainthe performance, streaming active learning is used, in which the model isretrained by adding a newly annotated sample to the training dataset if theprediction of the sample is not certain enough. Although many streaming activelearning methods have been proposed for classification, few efforts have beenmade for regression problems, which are often handled in the industrial field.In this paper, we propose to use the regression-via-classification frameworkfor streaming active learning for regression. Regression-via-classificationtransforms regression problems into classification problems so that streamingactive learning methods proposed for classification problems can be applieddirectly to regression problems. Experimental validation on four real data setsshows that the proposed method can perform regression with higher accuracy atthe same annotation cost.</description><author>Shota Horiguchi, Kota Dohi, Yohei Kawaguchi</author><pubDate>Fri, 15 Dec 2023 16:01:41 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2309.01013v2</guid></item><item><title>Convergent Data-driven Regularizations for CT Reconstruction</title><link>http://arxiv.org/abs/2212.07786v2</link><description>The reconstruction of images from their corresponding noisy Radon transformis a typical example of an ill-posed linear inverse problem as arising in theapplication of computerized tomography (CT). As the (naive) solution does notdepend on the measured data continuously, regularization is needed tore-establish a continuous dependence. In this work, we investigate simple, butyet still provably convergent approaches to learning linear regularizationmethods from data. More specifically, we analyze two approaches: One genericlinear regularization that learns how to manipulate the singular values of thelinear operator in an extension of our previous work, and one tailored approachin the Fourier domain that is specific to CT-reconstruction. We prove that suchapproaches become convergent regularization methods as well as the fact thatthe reconstructions they provide are typically much smoother than the trainingdata they were trained on. Finally, we compare the spectral as well as theFourier-based approaches for CT-reconstruction numerically, discuss theiradvantages and disadvantages and investigate the effect of discretizationerrors at different resolutions.</description><author>Samira Kabri, Alexander Auras, Danilo Riccio, Hartmut Bauermeister, Martin Benning, Michael Moeller, Martin Burger</author><pubDate>Fri, 15 Dec 2023 15:59:44 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2212.07786v2</guid></item><item><title>SQA-SAM: Segmentation Quality Assessment for Medical Images Utilizing the Segment Anything Model</title><link>http://arxiv.org/abs/2312.09899v1</link><description>Segmentation quality assessment (SQA) plays a critical role in the deploymentof a medical image based AI system. Users need to be informed/alerted wheneveran AI system generates unreliable/incorrect predictions. With the introductionof the Segment Anything Model (SAM), a general foundation segmentation model,new research opportunities emerged in how one can utilize SAM for medical imagesegmentation. In this paper, we propose a novel SQA method, called SQA-SAM,which exploits SAM to enhance the accuracy of quality assessment for medicalimage segmentation. When a medical image segmentation model (MedSeg) producespredictions for a test image, we generate visual prompts based on thepredictions, and SAM is utilized to generate segmentation maps corresponding tothe visual prompts. How well MedSeg's segmentation aligns with SAM'ssegmentation indicates how well MedSeg's segmentation aligns with the generalperception of objectness and image region partition. We develop a score measurefor such alignment. In experiments, we find that the generated scores exhibitmoderate to strong positive correlation (in Pearson correlation and Spearmancorrelation) with Dice coefficient scores reflecting the true segmentationquality.</description><author>Yizhe Zhang, Shuo Wang, Tao Zhou, Qi Dou, Danny Z. Chen</author><pubDate>Fri, 15 Dec 2023 15:49:53 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.09899v1</guid></item><item><title>A Novel Dataset for Financial Education Text Simplification in Spanish</title><link>http://arxiv.org/abs/2312.09897v1</link><description>Text simplification, crucial in natural language processing, aims to maketexts more comprehensible, particularly for specific groups like visuallyimpaired Spanish speakers, a less-represented language in this field. InSpanish, there are few datasets that can be used to create text simplificationsystems. Our research has the primary objective to develop a Spanish financialtext simplification dataset. We created a dataset with 5,314 complex andsimplified sentence pairs using established simplification rules. We alsocompared our dataset with the simplifications generated from GPT-3, Tuner, andMT5, in order to evaluate the feasibility of data augmentation using thesesystems. In this manuscript we present the characteristics of our dataset andthe findings of the comparisons with other systems. The dataset is available atHugging face, saul1917/FEINA.</description><author>Nelson Perez-Rojas, Saul Calderon-Ramirez, Martin Solis-Salazar, Mario Romero-Sandoval, Monica Arias-Monge, Horacio Saggion</author><pubDate>Fri, 15 Dec 2023 15:47:08 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.09897v1</guid></item><item><title>Generative Context-aware Fine-tuning of Self-supervised Speech Models</title><link>http://arxiv.org/abs/2312.09895v1</link><description>When performing tasks like automatic speech recognition or spoken languageunderstanding for a given utterance, access to preceding text or audio providescontextual information can improve performance. Considering the recent advancesin generative large language models (LLM), we hypothesize that an LLM couldgenerate useful context information using the preceding text. With appropriateprompts, LLM could generate a prediction of the next sentence or abstractivetext like titles or topics. In this paper, we study the use of LLM-generatedcontext information and propose an approach to distill the generatedinformation during fine-tuning of self-supervised speech models, which we referto as generative context-aware fine-tuning. This approach allows the fine-tunedmodel to make improved predictions without access to the true surroundingsegments or to the LLM at inference time, while requiring only a very smalladditional context module. We evaluate the proposed approach using the SLUE andLibri-light benchmarks for several downstream tasks: automatic speechrecognition, named entity recognition, and sentiment analysis. The results showthat generative context-aware fine-tuning outperforms a context injectionfine-tuning approach that accesses the ground-truth previous text, and iscompetitive with a generative context injection fine-tuning approach thatrequires the LLM at inference time.</description><author>Suwon Shon, Kwangyoun Kim, Prashant Sridhar, Yi-Te Hsu, Shinji Watanabe, Karen Livescu</author><pubDate>Fri, 15 Dec 2023 15:46:02 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.09895v1</guid></item><item><title>PathoDuet: Foundation Models for Pathological Slide Analysis of H&amp;E and IHC Stains</title><link>http://arxiv.org/abs/2312.09894v1</link><description>Large amounts of digitized histopathological data display a promising futurefor developing pathological foundation models via self-supervised learningmethods. Foundation models pretrained with these methods serve as a good basisfor downstream tasks. However, the gap between natural and histopathologicalimages hinders the direct application of existing methods. In this work, wepresent PathoDuet, a series of pretrained models on histopathological images,and a new self-supervised learning framework in histopathology. The frameworkis featured by a newly-introduced pretext token and later task raisers toexplicitly utilize certain relations between images, like multiplemagnifications and multiple stains. Based on this, two pretext tasks,cross-scale positioning and cross-stain transferring, are designed to pretrainthe model on Hematoxylin and Eosin (H\&amp;E) images and transfer the model toimmunohistochemistry (IHC) images, respectively. To validate the efficacy ofour models, we evaluate the performance over a wide variety of downstreamtasks, including patch-level colorectal cancer subtyping and whole slide image(WSI)-level classification in H\&amp;E field, together with expression levelprediction of IHC marker and tumor identification in IHC field. Theexperimental results show the superiority of our models over most tasks and theefficacy of proposed pretext tasks. The codes and models are available athttps://github.com/openmedlab/PathoDuet.</description><author>Shengyi Hua, Fang Yan, Tianle Shen, Xiaofan Zhang</author><pubDate>Fri, 15 Dec 2023 15:45:52 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.09894v1</guid></item><item><title>She had Cobalt Blue Eyes: Prompt Testing to Create Aligned and Sustainable Language Models</title><link>http://arxiv.org/abs/2310.18333v3</link><description>As the use of large language models (LLMs) increases within society, as doesthe risk of their misuse. Appropriate safeguards must be in place to ensure LLMoutputs uphold the ethical standards of society, highlighting the positive rolethat artificial intelligence technologies can have. Recent events indicateethical concerns around conventionally trained LLMs, leading to overall unsafeuser experiences. This motivates our research question: how do we ensure LLMalignment? In this work, we introduce a test suite of unique prompts to fosterthe development of aligned LLMs that are fair, safe, and robust. We show thatprompting LLMs at every step of the development pipeline, including datacuration, pre-training, and fine-tuning, will result in an overall moreresponsible model. Our test suite evaluates outputs from four state-of-the-artlanguage models: GPT-3.5, GPT-4, OPT, and LLaMA-2. The assessment presented inthis paper highlights a gap between societal alignment and the capabilities ofcurrent LLMs. Additionally, implementing a test suite such as ours lowers theenvironmental overhead of making models safe and fair.</description><author>Veronica Chatrath, Oluwanifemi Bamgbose, Shaina Raza</author><pubDate>Fri, 15 Dec 2023 15:45:51 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.18333v3</guid></item><item><title>Rethinking Visual Prompt Learning as Masked Visual Token Modeling</title><link>http://arxiv.org/abs/2303.04998v2</link><description>Prompt learning has achieved great success in efficiently exploitinglarge-scale pre-trained models in natural language processing (NLP). Itreformulates the downstream tasks as the generative pre-training ones toachieve consistency, thus improving the performance stably. However, whentransferring it to the vision area, current visual prompt learning methods arealmost designed on discriminative pre-trained models, and there is also a lackof careful design to unify the forms of pre-training and downstream tasks. Toexplore prompt learning on the generative pre-trained visual model, as well askeeping the task consistency, we propose Visual Prompt learning as maskedvisual Token Modeling (VPTM) to transform the downstream visual classificationinto the pre-trained masked visual token prediction. In addition, we developthe prototypical verbalizer for mapping the predicted visual token withimplicit semantics to explicit downstream labels. To our best knowledge, VPTMis the first visual prompt method on the generative pre-trained visual model,which achieves consistency between pre-training and downstream visualclassification by task reformulation. Experiments show that VPTM outperformsother visual prompt methods and achieves excellent efficiency. Moreover, thetask consistency of VPTM contributes to the robustness against prompt location,prompt length and prototype dimension, and could be deployed uniformly.</description><author>Ning Liao, Bowen Shi, Xiaopeng Zhang, Min Cao, Junchi Yan, Qi Tian</author><pubDate>Fri, 15 Dec 2023 15:44:28 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2303.04998v2</guid></item><item><title>Grammatical information in BERT sentence embeddings as two-dimensional arrays</title><link>http://arxiv.org/abs/2312.09890v1</link><description>Sentence embeddings induced with various transformer architectures encodemuch semantic and syntactic information in a distributed manner in aone-dimensional array. We investigate whether specific grammatical informationcan be accessed in these distributed representations. Using data from a taskdeveloped to test rule-like generalizations, our experiments on detectingsubject-verb agreement yield several promising results. First, we show thatwhile the usual sentence representations encoded as one-dimensional arrays donot easily support extraction of rule-like regularities, a two-dimensionalreshaping of these vectors allows various learning architectures to access suchinformation. Next, we show that various architectures can detect patterns inthese two-dimensional reshaped sentence embeddings and successfully learn amodel based on smaller amounts of simpler training data, which performs well onmore complex test data. This indicates that current sentence embeddings containinformation that is regularly distributed, and which can be captured when theembeddings are reshaped into higher dimensional arrays. Our results cast lighton representations produced by language models and help move towards developingfew-shot learning approaches.</description><author>Vivi Nastase, Paola Merlo</author><pubDate>Fri, 15 Dec 2023 15:41:52 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.09890v1</guid></item><item><title>Probabilistic learning of the Purkinje network from the electrocardiogram</title><link>http://arxiv.org/abs/2312.09887v1</link><description>The identification of the Purkinje conduction system in the heart is achallenging task, yet essential for a correct definition of cardiac digitaltwins for precision cardiology. Here, we propose a probabilistic approach foridentifying the Purkinje network from non-invasive clinical data such as thestandard electrocardiogram (ECG). We use cardiac imaging to build ananatomically accurate model of the ventricles; we algorithmically generate arule-based Purkinje network tailored to the anatomy; we simulate physiologicalelectrocardiograms with a fast model; we identify the geometrical andelectrical parameters of the Purkinje-ECG model with Bayesian optimization andapproximate Bayesian computation. The proposed approach is inherentlyprobabilistic and generates a population of plausible Purkinje networks, allfitting the ECG within a given tolerance. In this way, we can estimate theuncertainty of the parameters, thus providing reliable predictions. We test ourmethodology in physiological and pathological scenarios, showing that we areable to accurately recover the ECG with our model. We propagate the uncertaintyin the Purkinje network parameters in a simulation of conduction system pacingtherapy. Our methodology is a step forward in creation of digital twins fromnon-invasive data in precision medicine. An open source implementation can befound at http://github.com/fsahli/purkinje-learning</description><author>Felipe Álvarez-Barrientos, Mariana Salinas-Camus, Simone Pezzuto, Francisco Sahli Costabal</author><pubDate>Fri, 15 Dec 2023 15:34:29 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.09887v1</guid></item><item><title>Simple Weak Coresets for Non-Decomposable Classification Measures</title><link>http://arxiv.org/abs/2312.09885v1</link><description>While coresets have been growing in terms of their application, barring fewexceptions, they have mostly been limited to unsupervised settings. We considersupervised classification problems, and non-decomposable evaluation measures insuch settings. We show that stratified uniform sampling based coresets haveexcellent empirical performance that are backed by theoretical guarantees too.We focus on the F1 score and Matthews Correlation Coefficient, two widely usednon-decomposable objective functions that are nontrivial to optimize for andshow that uniform coresets attain a lower bound for coreset size, and have goodempirical performance, comparable with ``smarter'' coreset constructionstrategies.</description><author>Jayesh Malaviya, Anirban Dasgupta, Rachit Chhaya</author><pubDate>Fri, 15 Dec 2023 15:32:25 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.09885v1</guid></item><item><title>Dynamic Heterogeneous Federated Learning with Multi-Level Prototypes</title><link>http://arxiv.org/abs/2312.09881v1</link><description>Federated learning shows promise as a privacy-preserving collaborativelearning technique. Existing heterogeneous federated learning mainly focuses onskewing the label distribution across clients. However, most approaches sufferfrom catastrophic forgetting and concept drift, mainly when the globaldistribution of all classes is extremely unbalanced and the data distributionof the client dynamically evolves over time. In this paper, we study the newtask, i.e., Dynamic Heterogeneous Federated Learning (DHFL), which addressesthe practical scenario where heterogeneous data distributions exist amongdifferent clients and dynamic tasks within the client. Accordingly, we proposea novel federated learning framework named Federated Multi-Level Prototypes(FedMLP) and design federated multi-level regularizations. To mitigate conceptdrift, we construct prototypes and semantic prototypes to provide fruitfulgeneralization knowledge and ensure the continuity of prototype spaces. Tomaintain the model stability and consistency of convergence, threeregularizations are introduced as training losses, i.e., prototype-basedregularization, semantic prototype-based regularization, and federatedinter-task regularization. Extensive experiments show that the proposed methodachieves state-of-the-art performance in various settings.</description><author>Shunxin Guo, Hongsong Wang, Xin Geng</author><pubDate>Fri, 15 Dec 2023 15:28:25 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.09881v1</guid></item><item><title>Colour Passing Revisited: Lifted Model Construction with Commutative Factors</title><link>http://arxiv.org/abs/2309.11236v2</link><description>Lifted probabilistic inference exploits symmetries in a probabilistic modelto allow for tractable probabilistic inference with respect to domain sizes. Toapply lifted inference, a lifted representation has to be obtained, and to doso, the so-called colour passing algorithm is the state of the art. The colourpassing algorithm, however, is bound to a specific inference algorithm and wefound that it ignores commutativity of factors while constructing a liftedrepresentation. We contribute a modified version of the colour passingalgorithm that uses logical variables to construct a lifted representationindependent of a specific inference algorithm while at the same time exploitingcommutativity of factors during an offline-step. Our proposed algorithmefficiently detects more symmetries than the state of the art and therebydrastically increases compression, yielding significantly faster online querytimes for probabilistic inference when the resulting model is applied.</description><author>Malte Luttermann, Tanya Braun, Ralf Möller, Marcel Gehrke</author><pubDate>Fri, 15 Dec 2023 15:28:09 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2309.11236v2</guid></item><item><title>Information Extraction from Unstructured data using Augmented-AI and Computer Vision</title><link>http://arxiv.org/abs/2312.09880v1</link><description>Process of information extraction (IE) is often used to extract meaningfulinformation from unstructured and unlabeled data. Conventional methods of dataextraction including application of OCR and passing extraction engine, areinefficient on large data and have their limitation. In this paper, a peculiartechnique of information extraction is proposed using A2I and computer visiontechnologies, which also includes NLP.</description><author>Aditya Parikh</author><pubDate>Fri, 15 Dec 2023 15:27:41 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.09880v1</guid></item><item><title>Distributed Learning of Mixtures of Experts</title><link>http://arxiv.org/abs/2312.09877v1</link><description>In modern machine learning problems we deal with datasets that are eitherdistributed by nature or potentially large for which distributing thecomputations is usually a standard way to proceed, since centralized algorithmsare in general ineffective. We propose a distributed learning approach formixtures of experts (MoE) models with an aggregation strategy to construct areduction estimator from local estimators fitted parallelly to distributedsubsets of the data. The aggregation is based on an optimal minimization of anexpected transportation divergence between the large MoE composed of localestimators and the unknown desired MoE model. We show that the providedreduction estimator is consistent as soon as the local estimators to beaggregated are consistent, and its construction is performed by a proposedmajorization-minimization (MM) algorithm that is computationally effective. Westudy the statistical and numerical properties for the proposed reductionestimator on experiments that demonstrate its performance compared to namelythe global estimator constructed in a centralized way from the full dataset.For some situations, the computation time is more than ten times faster, for acomparable performance. Our source codes are publicly available on Github.</description><author>Faïcel Chamroukhi, Nhat Thien Pham</author><pubDate>Fri, 15 Dec 2023 15:26:13 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.09877v1</guid></item><item><title>Automatic Image Colourizer</title><link>http://arxiv.org/abs/2312.09876v1</link><description>In this project we have designed and described a model which colourize agray-scale image, with no human intervention. We propose a fully automaticprocess of colouring and re-colouring faded or gray-scale image with vibrantand pragmatic colours. We have used Convolutional Neural Network to hallucinateinput images and feed-forwarded by training thousands of images. This approachresults in trailblazing results.</description><author>Aditya Parikh</author><pubDate>Fri, 15 Dec 2023 15:24:49 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.09876v1</guid></item><item><title>ChemTime: Rapid and Early Classification for Multivariate Time Series Classification of Chemical Sensors</title><link>http://arxiv.org/abs/2312.09871v1</link><description>Multivariate time series data are ubiquitous in the application of machinelearning to problems in the physical sciences. Chemiresistive sensor arrays arehighly promising in chemical detection tasks relevant to industrial, safety,and military applications. Sensor arrays are an inherently multivariate timeseries data collection tool which demand rapid and accurate classification ofarbitrary chemical analytes. Previous research has benchmarked data-agnosticmultivariate time series classifiers across diverse multivariate time seriessupervised tasks in order to find general-purpose classification algorithms. Toour knowledge, there has yet to be an effort to survey machine learning andtime series classification approaches to chemiresistive hardware sensor arraysfor the detection of chemical analytes. In addition to benchmarking existingapproaches to multivariate time series classifiers, we incorporate findingsfrom a model survey to propose the novel \textit{ChemTime} approach to sensorarray classification for chemical sensing. We design experiments addressing theunique challenges of hardware sensor arrays classification including the rapidclassification ability of classifiers and minimization of inference time whilemaintaining performance for deployed lightweight hardware sensing devices. Wefind that \textit{ChemTime} is uniquely positioned for the chemical sensingtask by combining rapid and early classification of time series with beneficialinference and high accuracy.</description><author>Alexander M. Moore, Randy C. Paffenroth, Kenneth T. Ngo, Joshua R. Uzarski</author><pubDate>Fri, 15 Dec 2023 15:18:33 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.09871v1</guid></item><item><title>Learning in Online Principle-Agent Interactions: The Power of Menus</title><link>http://arxiv.org/abs/2312.09869v1</link><description>We study a ubiquitous learning challenge in online principal-agent problemsduring which the principal learns the agent's private information from theagent's revealed preferences in historical interactions. This paradigm includesimportant special cases such as pricing and contract design, which have beenwidely studied in recent literature. However, existing work considers the casewhere the principal can only choose a single strategy at every round tointeract with the agent and then observe the agent's revealed preferencethrough their actions. In this paper, we extend this line of study to allow theprincipal to offer a menu of strategies to the agent and learn additionallyfrom observing the agent's selection from the menu. We provide a thoroughinvestigation of several online principal-agent problem settings andcharacterize their sample complexities, accompanied by the correspondingalgorithms we have developed. We instantiate this paradigm to several importantdesign problems $-$ including Stackelberg (security) games, contract design,and information design. Finally, we also explore the connection between ourfindings and existing results about online learning in Stackelberg games, andwe offer a solution that can overcome a key hard instance of Peng et al.(2019).</description><author>Minbiao Han, Michael Albert, Haifeng Xu</author><pubDate>Fri, 15 Dec 2023 15:14:55 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.09869v1</guid></item><item><title>PLGSLAM: Progressive Neural Scene Represenation with Local to Global Bundle Adjustment</title><link>http://arxiv.org/abs/2312.09866v1</link><description>Neural implicit scene representations have recently shown encouraging resultsin dense visual SLAM. However, existing methods produce low-quality scenereconstruction and low-accuracy localization performance when scaling up tolarge indoor scenes and long sequences. These limitations are mainly due totheir single, global radiance field with finite capacity, which does not adaptto large scenarios. Their end-to-end pose networks are also not robust enoughwith the growth of cumulative errors in large scenes. To this end, we presentPLGSLAM, a neural visual SLAM system which performs high-fidelity surfacereconstruction and robust camera tracking in real time. To handle large-scaleindoor scenes, PLGSLAM proposes a progressive scene representation method whichdynamically allocates new local scene representation trained with frames withina local sliding window. This allows us to scale up to larger indoor scenes andimproves robustness (even under pose drifts). In local scene representation,PLGSLAM utilizes tri-planes for local high-frequency features. We alsoincorporate multi-layer perceptron (MLP) networks for the low-frequencyfeature, smoothness, and scene completion in unobserved areas. Moreover, wepropose local-to-global bundle adjustment method with a global keyframedatabase to address the increased pose drifts on long sequences. Experimentalresults demonstrate that PLGSLAM achieves state-of-the-art scene reconstructionresults and tracking performance across various datasets and scenarios (both insmall and large-scale indoor environments). The code will be open-sourced uponpaper acceptance.</description><author>Tianchen Deng, Guole Shen, Tong Qin, Jianyu Wang, Wentao Zhao, Jingchuan Wang, Danwei Wang, Weidong Chen</author><pubDate>Fri, 15 Dec 2023 15:09:30 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.09866v1</guid></item><item><title>Automating reward function configuration for drug design</title><link>http://arxiv.org/abs/2312.09865v1</link><description>Designing reward functions that guide generative molecular design (GMD)algorithms to desirable areas of chemical space is of critical importance inAI-driven drug discovery. Traditionally, this has been a manual and error-pronetask; the selection of appropriate computational methods to approximatebiological assays is challenging and the aggregation of computed values into asingle score even more so, leading to potential reliance on trial-and-errorapproaches. We propose a novel approach for automated reward configuration thatrelies solely on experimental data, mitigating the challenges of manual rewardadjustment on drug discovery projects. Our method achieves this by constructinga ranking over experimental data based on Pareto dominance over themulti-objective space, then training a neural network to approximate the rewardfunction such that rankings determined by the predicted reward correlate withthose determined by the Pareto dominance relation. We validate our method usingtwo case studies. In the first study we simulate Design-Make-Test-Analyse(DMTA) cycles by alternating reward function updates and generative runs guidedby that function. We show that the learned function adapts over time to yieldcompounds that score highly with respect to evaluation functions taken from theliterature. In the second study we apply our algorithm to historical data fromfour real drug discovery projects. We show that our algorithm yields rewardfunctions that outperform the predictive accuracy of human-defined functions,achieving an improvement of up to 0.4 in Spearman's correlation against aground truth evaluation function that encodes the target drug profile for thatproject. Our method provides an efficient data-driven way to configure rewardfunctions for GMD, and serves as a strong baseline for future research intotransformative approaches for the automation of drug discovery.</description><author>Marius Urbonas, Temitope Ajileye, Paul Gainer, Douglas Pires</author><pubDate>Fri, 15 Dec 2023 15:09:16 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.09865v1</guid></item><item><title>Approximation Algorithms for Preference Aggregation Using CP-Nets</title><link>http://arxiv.org/abs/2312.09162v2</link><description>This paper studies the design and analysis of approximation algorithms foraggregating preferences over combinatorial domains, represented usingConditional Preference Networks (CP-nets). Its focus is on aggregatingpreferences over so-called \emph{swaps}, for which optimal solutions in generalare already known to be of exponential size. We first analyze a trivial2-approximation algorithm that simply outputs the best of the given inputpreferences, and establish a structural condition under which the approximationratio of this algorithm is improved to $4/3$. We then propose a polynomial-timeapproximation algorithm whose outputs are provably no worse than those of thetrivial algorithm, but often substantially better. A family of probleminstances is presented for which our improved algorithm produces optimalsolutions, while, for any $\varepsilon$, the trivial algorithm can\emph{not}\/attain a $(2-\varepsilon)$-approximation. These results may lead to the firstpolynomial-time approximation algorithm that solves the CP-net aggregationproblem for swaps with an approximation ratio substantially better than $2$.</description><author>Abu Mohammmad Hammad Ali, Boting Yang, Sandra Zilles</author><pubDate>Fri, 15 Dec 2023 15:06:57 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.09162v2</guid></item><item><title>SafeAR: Towards Safer Algorithmic Recourse by Risk-Aware Policies</title><link>http://arxiv.org/abs/2308.12367v2</link><description>With the growing use of machine learning (ML) models in critical domains suchas finance and healthcare, the need to offer recourse for those adverselyaffected by the decisions of ML models has become more important; individualsought to be provided with recommendations on actions to take for improvingtheir situation and thus receiving a favorable decision. Prior work onsequential algorithmic recourse -- which recommends a series of changes --focuses on action feasibility and uses the proximity of feature changes todetermine action costs. However, the uncertainties of feature changes and therisk of higher than average costs in recourse have not been considered. It isundesirable if a recourse could (with some probability) result in a worsesituation from which recovery requires an extremely high cost. It is essentialto incorporate risks when computing and evaluating recourse. We call therecourse computed with such risk considerations as Safer Algorithmic Recourse(SafeAR). The objective is to empower people to choose a recourse based ontheir risk tolerance. In this work, we discuss and show how existing recoursedesiderata can fail to capture the risk of higher costs. We present a method tocompute recourse policies that consider variability in cost and connectalgorithmic recourse literature with risk-sensitive reinforcement learning. Wealso adopt measures "Value at Risk" and "Conditional Value at Risk" from thefinancial literature to summarize risk concisely. We apply our method to tworeal-world datasets and compare policies with different risk-aversion levelsusing risk measures and recourse desiderata (sparsity and proximity).</description><author>Haochen Wu, Shubham Sharma, Sunandita Patra, Sriram Gopalakrishnan</author><pubDate>Fri, 15 Dec 2023 15:05:30 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2308.12367v2</guid></item><item><title>Automatic Rao-Blackwellization for Sequential Monte Carlo with Belief Propagation</title><link>http://arxiv.org/abs/2312.09860v1</link><description>Exact Bayesian inference on state-space models~(SSM) is in generaluntractable, and unfortunately, basic Sequential Monte Carlo~(SMC) methods donot yield correct approximations for complex models. In this paper, we proposea mixed inference algorithm that computes closed-form solutions using beliefpropagation as much as possible, and falls back to sampling-based SMC methodswhen exact computations fail. This algorithm thus implements automaticRao-Blackwellization and is even exact for Gaussian tree models.</description><author>Waïss Azizian, Guillaume Baudart, Marc Lelarge</author><pubDate>Fri, 15 Dec 2023 15:05:25 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.09860v1</guid></item><item><title>Deep Unsupervised Domain Adaptation for Time Series Classification: a Benchmark</title><link>http://arxiv.org/abs/2312.09857v1</link><description>Unsupervised Domain Adaptation (UDA) aims to harness labeled source data totrain models for unlabeled target data. Despite extensive research in domainslike computer vision and natural language processing, UDA remains underexploredfor time series data, which has widespread real-world applications ranging frommedicine and manufacturing to earth observation and human activity recognition.Our paper addresses this gap by introducing a comprehensive benchmark forevaluating UDA techniques for time series classification, with a focus on deeplearning methods. We provide seven new benchmark datasets covering variousdomain shifts and temporal dynamics, facilitating fair and standardized UDAmethod assessments with state of the art neural network backbones (e.g.Inception) for time series data. This benchmark offers insights into thestrengths and limitations of the evaluated approaches while preserving theunsupervised nature of domain adaptation, making it directly applicable topractical problems. Our paper serves as a vital resource for researchers andpractitioners, advancing domain adaptation solutions for time series data andfostering innovation in this critical field. The implementation code of thisbenchmark is available at https://github.com/EricssonResearch/UDA-4-TSC.</description><author>Hassan Ismail Fawaz, Ganesh Del Grosso, Tanguy Kerdoncuff, Aurelie Boisbunon, Illyyne Saffar</author><pubDate>Fri, 15 Dec 2023 15:03:55 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.09857v1</guid></item><item><title>Associative Learning Mechanism for Drug-Target Interaction Prediction</title><link>http://arxiv.org/abs/2205.15364v5</link><description>As a necessary process in drug development, finding a drug compound that canselectively bind to a specific protein is highly challenging and costly.Drug-target affinity (DTA), which represents the strength of drug-targetinteraction (DTI), has played an important role in the DTI prediction task overthe past decade. Although deep learning has been applied to DTA-relatedresearch, existing solutions ignore fundamental correlations between molecularsubstructures in molecular representation learning of drug compoundmolecules/protein targets. Moreover, traditional methods lack theinterpretability of the DTA prediction process. This results in missing featureinformation of intermolecular interactions, thereby affecting predictionperformance. Therefore, this paper proposes a DTA prediction method withinteractive learning and an autoencoder mechanism. The proposed model enhancesthe corresponding ability to capture the feature information of a singlemolecular sequence by the drug/protein molecular representation learning moduleand supplements the information interaction between molecular sequence pairs bythe interactive information learning module. The DTA value prediction modulefuses the drug-target pair interaction information to output the predictedvalue of DTA. Additionally, this paper theoretically proves that the proposedmethod maximizes evidence lower bound (ELBO) for the joint distribution of theDTA prediction model, which enhances the consistency of the probabilitydistribution between the actual value and the predicted value. The experimentalresults confirm mutual transformer-drug target affinity (MT-DTA) achievesbetter performance than other comparative methods.</description><author>Zhiqin Zhu, Zheng Yao, Guanqiu Qi, Neal Mazur, Baisen Cong</author><pubDate>Fri, 15 Dec 2023 15:02:34 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2205.15364v5</guid></item><item><title>Q-Segment: Segmenting Images In-Sensor for Vessel-Based Medical Diagnosis</title><link>http://arxiv.org/abs/2312.09854v1</link><description>This paper addresses the growing interest in deploying deep learning modelsdirectly in-sensor. We present "Q-Segment", a quantized real-time segmentationalgorithm, and conduct a comprehensive evaluation on two low-power edge visionplatforms, namely Sony IMX500, which has an in-sensors processor, and SonySpresense, a low-power multi-core ARM Cortex-M microcontroller. One of the maingoals of the model is to achieve end-to-end image segmentation for vessel-basedmedical diagnosis. Deployed on the IMX500 platform, Q-Segment achievesultra-low inference time in-sensor of only 1.9 ms and energy consumption ofonly 5.7 mJ. We compare the proposed network with outperforming existingnetworks on various platforms by a factor of 75x (compared to ERFNet). Thenetwork architecture employs an encoder-decoder structure with skipconnections, and results in a binary accuracy of 97.25% and an Area Under theReceiver Operating Characteristic Curve (AUC) of 96.97% on the CHASE dataset.This research contributes valuable insights into edge-based image segmentation,laying the foundation for efficient algorithms tailored to low-powerenvironments.</description><author>Pietro Bonazzi, Julian Moosmann, Yawei Li, Sizhen Bian, Michele Magno</author><pubDate>Fri, 15 Dec 2023 15:01:41 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.09854v1</guid></item><item><title>Learning Distributions on Manifolds with Free-form Flows</title><link>http://arxiv.org/abs/2312.09852v1</link><description>Many real world data, particularly in the natural sciences and computervision, lie on known Riemannian manifolds such as spheres, tori or the group ofrotation matrices. The predominant approaches to learning a distribution onsuch a manifold require solving a differential equation in order to sample fromthe model and evaluate densities. The resulting sampling times are slowed downby a high number of function evaluations. In this work, we propose analternative approach which only requires a single function evaluation followedby a projection to the manifold. Training is achieved by an adaptation of therecently proposed free-form flow framework to Riemannian manifolds. The centralidea is to estimate the gradient of the negative log-likelihood via a traceevaluated in the tangent space. We evaluate our method on various manifolds,and find significantly faster inference at competitive performance compared toprevious work. We make our code public at https://github.com/vislearn/FFF.</description><author>Peter Sorrenson, Felix Draxler, Armand Rousselot, Sander Hummerich, Ullrich Köthe</author><pubDate>Fri, 15 Dec 2023 14:58:34 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.09852v1</guid></item><item><title>Learned Regularization for Inverse Problems: Insights from a Spectral Model</title><link>http://arxiv.org/abs/2312.09845v1</link><description>The aim of this paper is to provide a theoretically founded investigation ofstate-of-the-art learning approaches for inverse problems. We give an extendeddefinition of regularization methods and their convergence in terms of theunderlying data distributions, which paves the way for future theoreticalstudies. Based on a simple spectral learning model previously introduced forsupervised learning, we investigate some key properties of different learningparadigms for inverse problems, which can be formulated independently ofspecific architectures. In particular we investigate the regularizationproperties, bias, and critical dependence on training data distributions.Moreover, our framework allows to highlight and compare the specific behaviorof the different paradigms in the infinite-dimensional limit.</description><author>Martin Burger, Samira Kabri</author><pubDate>Fri, 15 Dec 2023 14:50:14 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.09845v1</guid></item><item><title>Small Dataset, Big Gains: Enhancing Reinforcement Learning by Offline Pre-Training with Model Based Augmentation</title><link>http://arxiv.org/abs/2312.09844v1</link><description>Offline reinforcement learning leverages pre-collected datasets oftransitions to train policies. It can serve as effective initialization foronline algorithms, enhancing sample efficiency and speeding up convergence.However, when such datasets are limited in size and quality, offlinepre-training can produce sub-optimal policies and lead to degraded onlinereinforcement learning performance. In this paper we propose a model-based dataaugmentation strategy to maximize the benefits of offline reinforcementlearning pre-training and reduce the scale of data needed to be effective. Ourapproach leverages a world model of the environment trained on the offlinedataset to augment states during offline pre-training. We evaluate our approachon a variety of MuJoCo robotic tasks and our results show it can jump-startonline fine-tuning and substantially reduce - in some cases by an order ofmagnitude - the required number of environment interactions.</description><author>Girolamo Macaluso, Alessandro Sestini, Andrew D. Bagdanov</author><pubDate>Fri, 15 Dec 2023 14:49:41 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.09844v1</guid></item><item><title>Mitigating Outlier Activations in Low-Precision Fine-Tuning of Language Models</title><link>http://arxiv.org/abs/2312.09211v2</link><description>Low-precision fine-tuning of language models has gained prominence as acost-effective and energy-efficient approach to deploying large-scale models invarious applications. However, this approach is susceptible to the existence ofoutlier values in activation. The outlier values in the activation cannegatively affect the performance of fine-tuning language models in thelow-precision regime since they affect the scaling factor and thus makerepresenting smaller values harder. This paper investigates techniques formitigating outlier activation in low-precision integer fine-tuning of thelanguage models. Our proposed novel approach enables us to represent theoutlier activation values in 8-bit integers instead of floating-point (FP16)values. The benefit of using integers for outlier values is that it enables usto use operator tiling to avoid performing 16-bit integer matrix multiplicationto address this problem effectively. We provide theoretical analysis andsupporting experiments to demonstrate the effectiveness of our approach inimproving the robustness and performance of low-precision fine-tuned languagemodels.</description><author>Alireza Ghaffari, Justin Yu, Mahsa Ghazvini Nejad, Masoud Asgharian, Boxing Chen, Vahid Partovi Nia</author><pubDate>Fri, 15 Dec 2023 14:46:53 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.09211v2</guid></item><item><title>3D-MuPPET: 3D Multi-Pigeon Pose Estimation and Tracking</title><link>http://arxiv.org/abs/2308.15316v3</link><description>Markerless methods for animal posture tracking have been rapidly developingrecently, but frameworks and benchmarks for tracking large animal groups in 3Dare still lacking. To overcome this gap in the literature, we present3D-MuPPET, a framework to estimate and track 3D poses of up to 10 pigeons atinteractive speed using multiple camera views. We train a pose estimator toinfer 2D keypoints and bounding boxes of multiple pigeons, then triangulate thekeypoints to 3D. For identity matching of individuals in all views, we firstdynamically match 2D detections to global identities in the first frame, thenuse a 2D tracker to maintain IDs across views in subsequent frames. We achievecomparable accuracy to a state of the art 3D pose estimator in terms of medianerror and Percentage of Correct Keypoints. Additionally, we benchmark theinference speed of 3D-MuPPET, with up to 9.45 fps in 2D and 1.89 fps in 3D, andperform quantitative tracking evaluation, which yields encouraging results.Finally, we showcase two novel applications for 3D-MuPPET. First, we train amodel with data of single pigeons and achieve comparable results in 2D and 3Dposture estimation for up to 5 pigeons. Second, we show that 3D-MuPPET alsoworks in outdoors without additional annotations from natural environments.Both use cases simplify the domain shift to new species and environments,largely reducing annotation effort needed for 3D posture tracking. To the bestof our knowledge we are the first to present a framework for 2D/3D animalposture and trajectory tracking that works in both indoor and outdoorenvironments for up to 10 individuals. We hope that the framework can open upnew opportunities in studying animal collective behaviour and encouragesfurther developments in 3D multi-animal posture tracking.</description><author>Urs Waldmann, Alex Hoi Hang Chan, Hemal Naik, Máté Nagy, Iain D. Couzin, Oliver Deussen, Bastian Goldluecke, Fumihiro Kano</author><pubDate>Fri, 15 Dec 2023 14:40:00 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2308.15316v3</guid></item><item><title>Extreme Image Compression using Fine-tuned VQGANs</title><link>http://arxiv.org/abs/2307.08265v3</link><description>Recent advances in generative compression methods have demonstratedremarkable progress in enhancing the perceptual quality of compressed data,especially in scenarios with low bitrates. However, their efficacy andapplicability to achieve extreme compression ratios ($&lt;0.05$ bpp) remainconstrained. In this work, we propose a simple yet effective coding frameworkby introducing vector quantization (VQ)--based generative models into the imagecompression domain. The main insight is that the codebook learned by the VQGANmodel yields a strong expressive capacity, facilitating efficient compressionof continuous information in the latent space while maintaining reconstructionquality. Specifically, an image can be represented as VQ-indices by finding thenearest codeword, which can be encoded using lossless compression methods intobitstreams. We propose clustering a pre-trained large-scale codebook intosmaller codebooks through the K-means algorithm, yielding variable bitrates anddifferent levels of reconstruction quality within the coding framework.Furthermore, we introduce a transformer to predict lost indices and restoreimages in unstable environments. Extensive qualitative and quantitativeexperiments on various benchmark datasets demonstrate that the proposedframework outperforms state-of-the-art codecs in terms of perceptualquality-oriented metrics and human perception at extremely low bitrates ($\le0.04$ bpp). Remarkably, even with the loss of up to $20\%$ of indices, theimages can be effectively restored with minimal perceptual loss.</description><author>Qi Mao, Tinghan Yang, Yinuo Zhang, Zijian Wang, Meng Wang, Shiqi Wang, Siwei Ma</author><pubDate>Fri, 15 Dec 2023 14:39:13 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.08265v3</guid></item><item><title>Disentangling Linear Mode-Connectivity</title><link>http://arxiv.org/abs/2312.09832v1</link><description>Linear mode-connectivity (LMC) (or lack thereof) is one of the intriguingcharacteristics of neural network loss landscapes. While empirically wellestablished, it unfortunately still lacks a proper theoretical understanding.Even worse, although empirical data points are abound, a systematic study ofwhen networks exhibit LMC is largely missing in the literature. In this work weaim to close this gap. We explore how LMC is affected by three factors: (1)architecture (sparsity, weight-sharing), (2) training strategy (optimizationsetup) as well as (3) the underlying dataset. We place particular emphasis onminimal but non-trivial settings, removing as much unnecessary complexity aspossible. We believe that our insights can guide future theoretical works onuncovering the inner workings of LMC.</description><author>Gul Sena Altintas, Gregor Bachmann, Lorenzo Noci, Thomas Hofmann</author><pubDate>Fri, 15 Dec 2023 14:38:28 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.09832v1</guid></item><item><title>Socio-Economic Deprivation Analysis: Diffusion Maps</title><link>http://arxiv.org/abs/2312.09830v1</link><description>This report proposes a model to predict the location of the most deprivedareas in a city using data from the census. A census data is very highdimensional and needs to be simplified. We use a novel algorithm to reducedimensionality and find patterns: The diffusion map. Features are defined byeigenvectors of the Laplacian matrix that defines the diffusion map.Eigenvectors corresponding to the smallest eigenvalues indicate specificpopulation features. Previous work has found qualitatively that the second mostimportant dimension for describing the census data in Bristol is linked todeprivation. In this report, we analyse how good this dimension is as a modelfor predicting deprivation by comparing with the recognised measures. ThePearson correlation coefficient was found to be over 0.7. The top 10 per centof deprived areas in the UK which also locate in Bristol are extracted to testthe accuracy of the model. There are 52 most deprived areas, and 38 areas arecorrectly identified by comparing to the model. The influence of scores of IMDdomains that do not correlate with the models, Eigenvector 2 entries ofnon-deprived OAs and orthogonality of Eigenvectors cause the model to fail theprediction of 14 deprived areas. However, overall, the model shows a high performance to predict the futuredeprivation of overall areas where the project considers. This project isexpected to support the government to allocate resources and funding.</description><author>June Moh Goo</author><pubDate>Fri, 15 Dec 2023 14:34:14 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.09830v1</guid></item><item><title>Deep Diversity-Enhanced Feature Representation of Hyperspectral Images</title><link>http://arxiv.org/abs/2301.06132v2</link><description>In this paper, we study the problem of efficiently and effectively embeddingthe high-dimensional spatio-spectral information of hyperspectral (HS) images,guided by feature diversity. Specifically, based on the theoretical formulationthat feature diversity is correlated with the rank of the unfolded kernelmatrix, we rectify 3D convolution by modifying its topology to enhance the rankupper-bound. This modification yields a rank-enhanced spatial-spectralsymmetrical convolution set (ReS$^3$-ConvSet), which not only learns diverseand powerful feature representations but also saves network parameters.Additionally, we also propose a novel diversity-aware regularization (DA-Reg)term that directly acts on the feature maps to maximize independence amongelements. To demonstrate the superiority of the proposed ReS$^3$-ConvSet andDA-Reg, we apply them to various HS image processing and analysis tasks,including denoising, spatial super-resolution, and classification. Extensiveexperiments show that the proposed approaches outperform state-of-the-artmethods both quantitatively and qualitatively to a significant extent. The codeis publicly available at https://github.com/jinnh/ReSSS-ConvSet.</description><author>Jinhui Hou, Zhiyu Zhu, Junhui Hou, Hui Liu, Huanqiang Zeng, Deyu Meng</author><pubDate>Fri, 15 Dec 2023 14:26:39 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2301.06132v2</guid></item></channel></rss>