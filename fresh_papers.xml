<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/"><channel><title>Arxivfresh papers</title><link></link><description>Arxiv paper</description><language>en-US</language><lastBuildDate>Wed, 08 May 2024 14:00:04 GMT</lastBuildDate><generator>rfeed v1.0.0</generator><docs>https://github.com/svpino/rfeed/blob/master/README.md</docs><item><title>Tactile-Augmented Radiance Fields</title><link>http://arxiv.org/abs/2405.04534v1</link><description>We present a scene representation, which we call a tactile-augmented radiancefield (TaRF), that brings vision and touch into a shared 3D space. Thisrepresentation can be used to estimate the visual and tactile signals for agiven 3D position within a scene. We capture a scene's TaRF from a collectionof photos and sparsely sampled touch probes. Our approach makes use of twoinsights: (i) common vision-based touch sensors are built on ordinary camerasand thus can be registered to images using methods from multi-view geometry,and (ii) visually and structurally similar regions of a scene share the sametactile features. We use these insights to register touch signals to a capturedvisual scene, and to train a conditional diffusion model that, provided with anRGB-D image rendered from a neural radiance field, generates its correspondingtactile signal. To evaluate our approach, we collect a dataset of TaRFs. Thisdataset contains more touch samples than previous real-world datasets, and itprovides spatially aligned visual signals for each captured touch signal. Wedemonstrate the accuracy of our cross-modal generative model and the utility ofthe captured visual-tactile data on several downstream tasks. Project page:https://dou-yiming.github.io/TaRF</description><author>Yiming Dou, Fengyu Yang, Yi Liu, Antonio Loquercio, Andrew Owens</author><pubDate>Tue, 07 May 2024 18:59:50 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.04534v1</guid></item><item><title>ChatHuman: Language-driven 3D Human Understanding with Retrieval-Augmented Tool Reasoning</title><link>http://arxiv.org/abs/2405.04533v1</link><description>Numerous methods have been proposed to detect, estimate, and analyzeproperties of people in images, including the estimation of 3D pose, shape,contact, human-object interaction, emotion, and more. Each of these methodsworks in isolation instead of synergistically. Here we address this problem andbuild a language-driven human understanding system -- ChatHuman, which combinesand integrates the skills of many different methods. To do so, we finetune aLarge Language Model (LLM) to select and use a wide variety of existing toolsin response to user inputs. In doing so, ChatHuman is able to combineinformation from multiple tools to solve problems more accurately than theindividual tools themselves and to leverage tool output to improve its abilityto reason about humans. The novel features of ChatHuman include leveragingacademic publications to guide the application of 3D human-related tools,employing a retrieval-augmented generation model to generatein-context-learning examples for handling new tools, and discriminating andintegrating tool results to enhance 3D human understanding. Our experimentsshow that ChatHuman outperforms existing models in both tool selection accuracyand performance across multiple 3D human-related tasks. ChatHuman is a steptowards consolidating diverse methods for human analysis into a single,powerful, system for 3D human reasoning.</description><author>Jing Lin, Yao Feng, Weiyang Liu, Michael J. Black</author><pubDate>Tue, 07 May 2024 18:59:31 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.04533v1</guid></item><item><title>QServe: W4A8KV4 Quantization and System Co-design for Efficient LLM Serving</title><link>http://arxiv.org/abs/2405.04532v1</link><description>Quantization can accelerate large language model (LLM) inference. Goingbeyond INT8 quantization, the research community is actively exploring evenlower precision, such as INT4. Nonetheless, state-of-the-art INT4 quantizationtechniques only accelerate low-batch, edge LLM inference, failing to deliverperformance gains in large-batch, cloud-based LLM serving. We uncover acritical issue: existing INT4 quantization methods suffer from significantruntime overhead (20-90%) when dequantizing either weights or partial sums onGPUs. To address this challenge, we introduce QoQ, a W4A8KV4 quantizationalgorithm with 4-bit weight, 8-bit activation, and 4-bit KV cache. QoQ standsfor quattuor-octo-quattuor, which represents 4-8-4 in Latin. QoQ is implementedby the QServe inference library that achieves measured speedup. The key insightdriving QServe is that the efficiency of LLM serving on GPUs is criticallyinfluenced by operations on low-throughput CUDA cores. Building upon thisinsight, in QoQ algorithm, we introduce progressive quantization that can allowlow dequantization overhead in W4A8 GEMM. Additionally, we developSmoothAttention to effectively mitigate the accuracy degradation incurred by4-bit KV quantization. In the QServe system, we perform compute-aware weightreordering and take advantage of register-level parallelism to reducedequantization latency. We also make fused attention memory-bound, harnessingthe performance gain brought by KV4 quantization. As a result, QServe improvesthe maximum achievable serving throughput of Llama-3-8B by 1.2x on A100, 1.4xon L40S; and Qwen1.5-72B by 2.4x on A100, 3.5x on L40S, compared toTensorRT-LLM. Remarkably, QServe on L40S GPU can achieve even higher throughputthan TensorRT-LLM on A100. Thus, QServe effectively reduces the dollar cost ofLLM serving by 3x. Code is available at https://github.com/mit-han-lab/qserve.</description><author>Yujun Lin, Haotian Tang, Shang Yang, Zhekai Zhang, Guangxuan Xiao, Chuang Gan, Song Han</author><pubDate>Tue, 07 May 2024 18:59:30 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.04532v1</guid></item><item><title>About rescaling, discretisation and linearisation of $\mathtt{RNN}$</title><link>http://arxiv.org/abs/2312.15974v2</link><description>We explored the mathematical foundations of Recurrent Neural Networks($\mathtt{RNN}$s) and three fundamental procedures: temporal rescaling,discretisation and linearisation. These techniques provide essential tools forcharacterizing $\mathtt{RNN}$s behaviour, enabling insights into temporaldynamics, practical computational implementation, and linear approximations foranalysis. We discuss the flexible order of application of these procedures,emphasizing their significance in modelling and analyzing $\mathtt{RNN}$s forneuroscience and machine learning applications. We explicitly describe hereunder what conditions these procedures can be interchangeable.</description><author>Mariano Caruso, Cecilia Jarne</author><pubDate>Tue, 07 May 2024 18:59:02 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.15974v2</guid></item><item><title>Natural Language Counterfactuals through Representation Surgery</title><link>http://arxiv.org/abs/2402.11355v3</link><description>Interventions targeting the representation space of language models (LMs)have emerged as an effective means to influence model behavior. Such methodsare employed, for example, to eliminate or alter the encoding of demographicinformation such as gender within the model's representations and, in so doing,create a counterfactual representation. However, because the interventionoperates within the representation space, understanding precisely what aspectsof the text it modifies poses a challenge. In this paper, we give a method toconvert representation counterfactuals into string counterfactuals. Wedemonstrate that this approach enables us to analyze the linguistic alterationscorresponding to a given representation space intervention and to interpret thefeatures utilized to encode a specific concept. Moreover, the resultingcounterfactuals can be used to mitigate bias in classification through dataaugmentation.</description><author>Matan Avitan, Ryan Cotterell, Yoav Goldberg, Shauli Ravfogel</author><pubDate>Tue, 07 May 2024 18:58:17 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.11355v3</guid></item><item><title>NaturalCodeBench: Examining Coding Performance Mismatch on HumanEval and Natural User Prompts</title><link>http://arxiv.org/abs/2405.04520v1</link><description>Large language models (LLMs) have manifested strong ability to generate codesfor productive activities. However, current benchmarks for code synthesis, suchas HumanEval, MBPP, and DS-1000, are predominantly oriented towardsintroductory tasks on algorithm and data science, insufficiently satisfyingchallenging requirements prevalent in real-world coding. To fill this gap, wepropose NaturalCodeBench (NCB), a challenging code benchmark designed to mirrorthe complexity and variety of scenarios in real coding tasks. NCB comprises 402high-quality problems in Python and Java, meticulously selected from naturaluser queries from online coding services, covering 6 different domains. Notingthe extraordinary difficulty in creating testing cases for real-world queries,we also introduce a semi-automated pipeline to enhance the efficiency of testcase construction. Comparing with manual solutions, it achieves an efficiencyincrease of more than 4 times. Our systematic experiments on 39 LLMs find thatperformance gaps on NCB between models with close HumanEval scores could stillbe significant, indicating a lack of focus on practical code synthesisscenarios or over-specified optimization on HumanEval. On the other hand, eventhe best-performing GPT-4 is still far from satisfying on NCB. The evaluationtoolkit and development set are available athttps://github.com/THUDM/NaturalCodeBench.</description><author>Shudan Zhang, Hanlin Zhao, Xiao Liu, Qinkai Zheng, Zehan Qi, Xiaotao Gu, Xiaohan Zhang, Yuxiao Dong, Jie Tang</author><pubDate>Tue, 07 May 2024 18:52:51 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.04520v1</guid></item><item><title>xLSTM: Extended Long Short-Term Memory</title><link>http://arxiv.org/abs/2405.04517v1</link><description>In the 1990s, the constant error carousel and gating were introduced as thecentral ideas of the Long Short-Term Memory (LSTM). Since then, LSTMs havestood the test of time and contributed to numerous deep learning successstories, in particular they constituted the first Large Language Models (LLMs).However, the advent of the Transformer technology with parallelizableself-attention at its core marked the dawn of a new era, outpacing LSTMs atscale. We now raise a simple question: How far do we get in language modelingwhen scaling LSTMs to billions of parameters, leveraging the latest techniquesfrom modern LLMs, but mitigating known limitations of LSTMs? Firstly, weintroduce exponential gating with appropriate normalization and stabilizationtechniques. Secondly, we modify the LSTM memory structure, obtaining: (i) sLSTMwith a scalar memory, a scalar update, and new memory mixing, (ii) mLSTM thatis fully parallelizable with a matrix memory and a covariance update rule.Integrating these LSTM extensions into residual block backbones yields xLSTMblocks that are then residually stacked into xLSTM architectures. Exponentialgating and modified memory structures boost xLSTM capabilities to performfavorably when compared to state-of-the-art Transformers and State SpaceModels, both in performance and scaling.</description><author>Maximilian Beck, Korbinian Pöppel, Markus Spanring, Andreas Auer, Oleksandra Prudnikova, Michael Kopp, Günter Klambauer, Johannes Brandstetter, Sepp Hochreiter</author><pubDate>Tue, 07 May 2024 18:50:21 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.04517v1</guid></item><item><title>A Transformer with Stack Attention</title><link>http://arxiv.org/abs/2405.04515v1</link><description>Natural languages are believed to be (mildly) context-sensitive. Despiteunderpinning remarkably capable large language models, transformers are unableto model many context-free language tasks. In an attempt to address thislimitation in the modeling power of transformer-based language models, wepropose augmenting them with a differentiable, stack-based attention mechanism.Our stack-based attention mechanism can be incorporated into anytransformer-based language model and adds a level of interpretability to themodel. We show that the addition of our stack-based attention mechanism enablesthe transformer to model some, but not all, deterministic context-freelanguages.</description><author>Jiaoda Li, Jennifer C. White, Mrinmaya Sachan, Ryan Cotterell</author><pubDate>Tue, 07 May 2024 18:47:57 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.04515v1</guid></item><item><title>Switchable Decision: Dynamic Neural Generation Networks</title><link>http://arxiv.org/abs/2405.04513v1</link><description>Auto-regressive generation models achieve competitive performance across manydifferent NLP tasks such as summarization, question answering, andclassifications. However, they are also known for being slow in inference,which makes them challenging to deploy in real-time applications. We propose aswitchable decision to accelerate inference by dynamically assigningcomputation resources for each data instance. Automatically making decisions onwhere to skip and how to balance quality and computation cost with constrainedoptimization, our dynamic neural generation networks enforce the efficientinference path and determine the optimized trade-off. Experiments acrossquestion answering, summarization, and classification benchmarks show that ourmethod benefits from less computation cost during inference while keeping thesame accuracy. Extensive experiments and ablation studies demonstrate that ourmethod can be general, effective, and beneficial for many NLP tasks.</description><author>Shujian Zhang, Korawat Tanwisuth, Chengyue Gong, Pengcheng He, Mingyuan Zhou</author><pubDate>Tue, 07 May 2024 18:44:54 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.04513v1</guid></item><item><title>Amodal Optical Flow</title><link>http://arxiv.org/abs/2311.07761v2</link><description>Optical flow estimation is very challenging in situations with transparent oroccluded objects. In this work, we address these challenges at the task levelby introducing Amodal Optical Flow, which integrates optical flow with amodalperception. Instead of only representing the visible regions, we define amodaloptical flow as a multi-layered pixel-level motion field that encompasses bothvisible and occluded regions of the scene. To facilitate research on this newtask, we extend the AmodalSynthDrive dataset to include pixel-level labels foramodal optical flow estimation. We present several strong baselines, along withthe Amodal Flow Quality metric to quantify the performance in an interpretablemanner. Furthermore, we propose the novel AmodalFlowNet as an initial steptoward addressing this task. AmodalFlowNet consists of a transformer-basedcost-volume encoder paired with a recurrent transformer decoder whichfacilitates recurrent hierarchical feature propagation and amodal semanticgrounding. We demonstrate the tractability of amodal optical flow in extensiveexperiments and show its utility for downstream tasks such as panoptictracking. We make the dataset, code, and trained models publicly available athttp://amodal-flow.cs.uni-freiburg.de.</description><author>Maximilian Luz, Rohit Mohan, Ahmed Rida Sekkat, Oliver Sawade, Elmar Matthes, Thomas Brox, Abhinav Valada</author><pubDate>Tue, 07 May 2024 18:36:29 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.07761v2</guid></item><item><title>Unraveling the Dominance of Large Language Models Over Transformer Models for Bangla Natural Language Inference: A Comprehensive Study</title><link>http://arxiv.org/abs/2405.02937v2</link><description>Natural Language Inference (NLI) is a cornerstone of Natural LanguageProcessing (NLP), providing insights into the entailment relationships betweentext pairings. It is a critical component of Natural Language Understanding(NLU), demonstrating the ability to extract information from spoken or writteninteractions. NLI is mainly concerned with determining the entailmentrelationship between two statements, known as the premise and hypothesis. Whenthe premise logically implies the hypothesis, the pair is labeled "entailment".If the hypothesis contradicts the premise, the pair receives the"contradiction" label. When there is insufficient evidence to establish aconnection, the pair is described as "neutral". Despite the success of LargeLanguage Models (LLMs) in various tasks, their effectiveness in NLI remainsconstrained by issues like low-resource domain accuracy, model overconfidence,and difficulty in capturing human judgment disagreements. This study addressesthe underexplored area of evaluating LLMs in low-resourced languages such asBengali. Through a comprehensive evaluation, we assess the performance ofprominent LLMs and state-of-the-art (SOTA) models in Bengali NLP tasks,focusing on natural language inference. Utilizing the XNLI dataset, we conductzero-shot and few-shot evaluations, comparing LLMs like GPT-3.5 Turbo andGemini 1.5 Pro with models such as BanglaBERT, Bangla BERT Base, DistilBERT,mBERT, and sahajBERT. Our findings reveal that while LLMs can achievecomparable or superior performance to fine-tuned SOTA models in few-shotscenarios, further research is necessary to enhance our understanding of LLMsin languages with modest resources like Bengali. This study underscores theimportance of continued efforts in exploring LLM capabilities across diverselinguistic contexts.</description><author>Fatema Tuj Johora Faria, Mukaffi Bin Moin, Asif Iftekher Fahim, Pronay Debnath, Faisal Muhammad Shah</author><pubDate>Tue, 07 May 2024 18:34:13 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.02937v2</guid></item><item><title>On the accuracy of interpolation based on single-layer artificial neural networks with a focus on defeating the Runge phenomenon</title><link>http://arxiv.org/abs/2308.10720v2</link><description>In the present paper, we consider one-hidden layer ANNs with a feedforwardarchitecture, also referred to as shallow or two-layer networks, so that thestructure is determined by the number and types of neurons. The determinationof the parameters that define the function, called training, is done via theresolution of the approximation problem, so by imposing the interpolationthrough a set of specific nodes. We present the case where the parameters aretrained using a procedure that is referred to as Extreme Learning Machine (ELM)that leads to a linear interpolation problem. In such hypotheses, the existenceof an ANN interpolating function is guaranteed. The focus is then on theaccuracy of the interpolation outside of the given sampling interpolation nodeswhen they are the equispaced, the Chebychev, and the randomly selected ones.The study is motivated by the well-known bell-shaped Runge example, which makesit clear that the construction of a global interpolating polynomial is accurateonly if trained on suitably chosen nodes, ad example the Chebychev ones. Inorder to evaluate the behavior when growing the number of interpolation nodes,we raise the number of neurons in our network and compare it with theinterpolating polynomial. We test using Runge's function and other well-knownexamples with different regularities. As expected, the accuracy of theapproximation with a global polynomial increases only if the Chebychev nodesare considered. Instead, the error for the ANN interpolating function alwaysdecays and in most cases we observe that the convergence follows what isobserved in the polynomial case on Chebychev nodes, despite the set of nodesused for training.</description><author>Ferdinando Auricchio, Maria Roberta Belardo, Gianluca Fabiani, Francesco Calabrò, Ariel F. Pascaner</author><pubDate>Tue, 07 May 2024 18:30:50 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2308.10720v2</guid></item><item><title>Iterative Reasoning Preference Optimization</title><link>http://arxiv.org/abs/2404.19733v2</link><description>Iterative preference optimization methods have recently been shown to performwell for general instruction tuning tasks, but typically make littleimprovement on reasoning tasks (Yuan et al., 2024, Chen et al., 2024). In thiswork we develop an iterative approach that optimizes the preference betweencompeting generated Chain-of-Thought (CoT) candidates by optimizing for winningvs. losing reasoning steps that lead to the correct answer. We train using amodified DPO loss (Rafailov et al., 2023) with an additional negativelog-likelihood term, which we find to be crucial. We show reasoning improvesacross repeated iterations of this scheme. While only relying on examples inthe training set, our approach results in increasing accuracy on GSM8K, MATH,and ARC-Challenge for Llama-2-70B-Chat, outperforming other Llama-2-basedmodels not relying on additionally sourced datasets. For example, we see alarge improvement from 55.6% to 81.6% on GSM8K and an accuracy of 88.7% withmajority voting out of 32 samples.</description><author>Richard Yuanzhe Pang, Weizhe Yuan, Kyunghyun Cho, He He, Sainbayar Sukhbaatar, Jason Weston</author><pubDate>Tue, 07 May 2024 18:25:08 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.19733v2</guid></item><item><title>A dataset of over one thousand computed tomography scans of battery cells</title><link>http://arxiv.org/abs/2403.02527v4</link><description>Battery technology is increasingly important for global electrificationefforts. However, batteries are highly sensitive to small manufacturingvariations that can induce reliability or safety issues. An importanttechnology for battery quality control is computed tomography (CT) scanning,which is widely used for non-destructive 3D inspection across a variety ofclinical and industrial applications. Historically, however, the utility of CTscanning for high-volume manufacturing has been limited by its low throughputas well as the difficulty of handling its large file sizes. In this work, wepresent a dataset of over one thousand CT scans of as-produced commerciallyavailable batteries. The dataset spans various chemistries (lithium-ion andsodium-ion) as well as various battery form factors (cylindrical, pouch, andprismatic). We evaluate seven different battery types in total. Themanufacturing variability and the presence of battery defects can be observedvia this dataset. This dataset may be of interest to scientists and engineersworking on battery technology, computer vision, or both.</description><author>Amariah Condon, Bailey Buscarino, Eric Moch, William J. Sehnert, Owen Miles, Patrick K. Herring, Peter M. Attia</author><pubDate>Tue, 07 May 2024 18:22:57 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.02527v4</guid></item><item><title>Accelerating Convergence in Bayesian Few-Shot Classification</title><link>http://arxiv.org/abs/2405.01507v3</link><description>Bayesian few-shot classification has been a focal point in the field offew-shot learning. This paper seamlessly integrates mirror descent-basedvariational inference into Gaussian process-based few-shot classification,addressing the challenge of non-conjugate inference. By leveragingnon-Euclidean geometry, mirror descent achieves accelerated convergence byproviding the steepest descent direction along the corresponding manifold. Italso exhibits the parameterization invariance property concerning thevariational distribution. Experimental results demonstrate competitiveclassification accuracy, improved uncertainty quantification, and fasterconvergence compared to baseline models. Additionally, we investigate theimpact of hyperparameters and components. Code is publicly available athttps://github.com/keanson/MD-BSFC.</description><author>Tianjun Ke, Haoqun Cao, Feng Zhou</author><pubDate>Tue, 07 May 2024 18:12:13 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.01507v3</guid></item><item><title>Edit-Your-Motion: Space-Time Diffusion Decoupling Learning for Video Motion Editing</title><link>http://arxiv.org/abs/2405.04496v1</link><description>Existing diffusion-based video editing methods have achieved impressiveresults in motion editing. Most of the existing methods focus on the motionalignment between the edited video and the reference video. However, thesemethods do not constrain the background and object content of the video toremain unchanged, which makes it possible for users to generate unexpectedvideos. In this paper, we propose a one-shot video motion editing method calledEdit-Your-Motion that requires only a single text-video pair for training.Specifically, we design the Detailed Prompt-Guided Learning Strategy (DPL) todecouple spatio-temporal features in space-time diffusion models. DPL separateslearning object content and motion into two training stages. In the firsttraining stage, we focus on learning the spatial features (the features ofobject content) and breaking down the temporal relationships in the videoframes by shuffling them. We further propose Recurrent-Causal Attention(RC-Attn) to learn the consistent content features of the object from unorderedvideo frames. In the second training stage, we restore the temporalrelationship in video frames to learn the temporal feature (the features of thebackground and object's motion). We also adopt the Noise Constraint Loss tosmooth out inter-frame differences. Finally, in the inference stage, we injectthe content features of the source object into the editing branch through atwo-branch structure (editing branch and reconstruction branch). WithEdit-Your-Motion, users can edit the motion of objects in the source video togenerate more exciting and diverse videos. Comprehensive qualitativeexperiments, quantitative experiments and user preference studies demonstratethat Edit-Your-Motion performs better than other methods.</description><author>Yi Zuo, Lingling Li, Licheng Jiao, Fang Liu, Xu Liu, Wenping Ma, Shuyuan Yang, Yuwei Guo</author><pubDate>Tue, 07 May 2024 18:06:59 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.04496v1</guid></item><item><title>Toward In-Context Teaching: Adapting Examples to Students' Misconceptions</title><link>http://arxiv.org/abs/2405.04495v1</link><description>When a teacher provides examples for a student to study, these examples mustbe informative, enabling a student to progress from their current state towarda target concept or skill. Good teachers must therefore simultaneously inferwhat students already know and adapt their teaching to students' changing stateof knowledge. There is increasing interest in using computational models,particularly large language models, as pedagogical tools. As students, languagemodels in particular have shown a remarkable ability to adapt to new tasksgiven small numbers of examples. But how effectively can these models adapt asteachers to students of different types? To study this question, we introduce asuite of models and evaluation methods we call AdapT. AdapT has two components:(1) a collection of simulated Bayesian student models that can be used forevaluation of automated teaching methods; (2) a platform for evaluation withhuman students, to characterize the real-world effectiveness of these methods.We additionally introduce (3) AToM, a new probabilistic model for adaptiveteaching that jointly infers students' past beliefs and optimizes for thecorrectness of future beliefs. In evaluations of simulated students acrossthree learning domains (fraction arithmetic, English morphology, functionlearning), AToM systematically outperforms LLM-based and standard Bayesianteaching models. In human experiments, both AToM and LLMs outperformnon-adaptive random example selection. Our results highlight both thedifficulty of the adaptive teaching task and the potential of learned adaptivemodels for solving it.</description><author>Alexis Ross, Jacob Andreas</author><pubDate>Tue, 07 May 2024 18:05:27 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.04495v1</guid></item><item><title>Representation Learning of Daily Movement Data Using Text Encoders</title><link>http://arxiv.org/abs/2405.04494v1</link><description>Time-series representation learning is a key area of research for remotehealthcare monitoring applications. In this work, we focus on a dataset ofrecordings of in-home activity from people living with Dementia. We design arepresentation learning method based on converting activity to text stringsthat can be encoded using a language model fine-tuned to transform data fromthe same participants within a $30$-day window to similar embeddings in thevector space. This allows for clustering and vector searching over participantsand days, and the identification of activity deviations to aid withpersonalised delivery of care.</description><author>Alexander Capstick, Tianyu Cui, Yu Chen, Payam Barnaghi</author><pubDate>Tue, 07 May 2024 18:04:21 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.04494v1</guid></item><item><title>TorchDriveEnv: A Reinforcement Learning Benchmark for Autonomous Driving with Reactive, Realistic, and Diverse Non-Playable Characters</title><link>http://arxiv.org/abs/2405.04491v1</link><description>The training, testing, and deployment, of autonomous vehicles requiresrealistic and efficient simulators. Moreover, because of the high variabilitybetween different problems presented in different autonomous systems, thesesimulators need to be easy to use, and easy to modify. To address theseproblems we introduce TorchDriveSim and its benchmark extension TorchDriveEnv.TorchDriveEnv is a lightweight reinforcement learning benchmark programmedentirely in Python, which can be modified to test a number of different factorsin learned vehicle behavior, including the effect of varying kinematic models,agent types, and traffic control patterns. Most importantly unlike many replaybased simulation approaches, TorchDriveEnv is fully integrated with a state ofthe art behavioral simulation API. This allows users to train and evaluatedriving models alongside data driven Non-Playable Characters (NPC) whoseinitializations and driving behavior are reactive, realistic, and diverse. Weillustrate the efficiency and simplicity of TorchDriveEnv by evaluating commonreinforcement learning baselines in both training and validation environments.Our experiments show that TorchDriveEnv is easy to use, but difficult to solve.</description><author>Jonathan Wilder Lavington, Ke Zhang, Vasileios Lioutas, Matthew Niedoba, Yunpeng Liu, Dylan Green, Saeid Naderiparizi, Xiaoxuan Liang, Setareh Dabiri, Adam Ścibior, Berend Zwartsenberg, Frank Wood</author><pubDate>Tue, 07 May 2024 18:02:02 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.04491v1</guid></item><item><title>Chain of Thought Empowers Transformers to Solve Inherently Serial Problems</title><link>http://arxiv.org/abs/2402.12875v2</link><description>Instructing the model to generate a sequence of intermediate steps, a.k.a., achain of thought (CoT), is a highly effective method to improve the accuracy oflarge language models (LLMs) on arithmetics and symbolic reasoning tasks.However, the mechanism behind CoT remains unclear. This work provides atheoretical understanding of the power of CoT for decoder-only transformersthrough the lens of expressiveness. Conceptually, CoT empowers the model withthe ability to perform inherently serial computation, which is otherwiselacking in transformers, especially when depth is low. Given input length $n$,previous works have shown that constant-depth transformers with finiteprecision $\mathsf{poly}(n)$ embedding size can only solve problems in$\mathsf{TC}^0$ without CoT. We first show an even tighter expressiveness upperbound for constant-depth transformers with constant-bit precision, which canonly solve problems in $\mathsf{AC}^0$, a proper subset of $ \mathsf{TC}^0$.However, with $T$ steps of CoT, constant-depth transformers using constant-bitprecision and $O(\log n)$ embedding size can solve any problem solvable byboolean circuits of size $T$. Empirically, enabling CoT dramatically improvesthe accuracy for tasks that are hard for parallel computation, including thecomposition of permutation groups, iterated squaring, and circuit valueproblems, especially for low-depth transformers.</description><author>Zhiyuan Li, Hong Liu, Denny Zhou, Tengyu Ma</author><pubDate>Tue, 07 May 2024 18:00:27 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.12875v2</guid></item><item><title>Scalable network reconstruction in subquadratic time</title><link>http://arxiv.org/abs/2401.01404v5</link><description>Network reconstruction consists in determining the unobserved pairwisecouplings between $N$ nodes given only observational data on the resultingbehavior that is conditioned on those couplings -- typically a time-series orindependent samples from a graphical model. A major obstacle to the scalabilityof algorithms proposed for this problem is a seemingly unavoidable quadraticcomplexity of $\Omega(N^2)$, corresponding to the requirement of each possiblepairwise coupling being contemplated at least once, despite the fact that mostnetworks of interest are sparse, with a number of non-zero couplings that isonly $O(N)$. Here we present a general algorithm applicable to a broad range ofreconstruction problems that significantly outperforms this quadratic baseline.Our algorithm relies on a stochastic second neighbor search (Dong et al., 2011)that produces the best edge candidates with high probability, thus bypassing anexhaustive quadratic search. If we rely on the conjecture that thesecond-neighbor search finishes in log-linear time (Baron &amp; Darling, 2020;2022), we demonstrate theoretically that our algorithm finishes in subquadratictime, with a data-dependent complexity loosely upper bounded by $O(N^{3/2}\logN)$, but with a more typical log-linear complexity of $O(N\log^2N)$. Inpractice, we show that our algorithm achieves a performance that is many ordersof magnitude faster than the quadratic baseline -- in a manner consistent withour theoretical analysis -- allows for easy parallelization, and thus enablesthe reconstruction of networks with hundreds of thousands and even millions ofnodes and edges.</description><author>Tiago P. Peixoto</author><pubDate>Tue, 07 May 2024 17:57:08 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.01404v5</guid></item><item><title>S3Former: Self-supervised High-resolution Transformer for Solar PV Profiling</title><link>http://arxiv.org/abs/2405.04489v1</link><description>As the impact of climate change escalates, the global necessity to transitionto sustainable energy sources becomes increasingly evident. Renewable energieshave emerged as a viable solution for users, with Photovoltaic energy being afavored choice for small installations due to its reliability and efficiency.Accurate mapping of PV installations is crucial for understanding the extensionof its adoption and informing energy policy. To meet this need, we introduceS3Former, designed to segment solar panels from aerial imagery and provide sizeand location information critical for analyzing the impact of suchinstallations on the grid. Solar panel identification is challenging due tofactors such as varying weather conditions, roof characteristics, GroundSampling Distance variations and lack of appropriate initialization weights foroptimized training. To tackle these complexities, S3Former features a MaskedAttention Mask Transformer incorporating a self-supervised learning pretrainedbackbone. Specifically, our model leverages low-level and high-level featuresextracted from the backbone and incorporates an instance query mechanismincorporated on the Transformer architecture to enhance the localization ofsolar PV installations. We introduce a self-supervised learning phase (pretexttask) to improve the initialization weights on the backbone of S3Former. Weevaluated S3Former using diverse datasets, demonstrate improvementstate-of-the-art models.</description><author>Minh Tran, Adrian De Luis, Haitao Liao, Ying Huang, Roy McCann, Alan Mantooth, Jack Cothren, Ngan Le</author><pubDate>Tue, 07 May 2024 17:56:21 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.04489v1</guid></item><item><title>MonoPCC: Photometric-invariant Cycle Constraint for Monocular Depth Estimation of Endoscopic Images</title><link>http://arxiv.org/abs/2404.16571v2</link><description>Photometric constraint is indispensable for self-supervised monocular depthestimation. It involves warping a source image onto a target view usingestimated depth&amp;pose, and then minimizing the difference between the warped andtarget images. However, the endoscopic built-in light causes significantbrightness fluctuations, and thus makes the photometric constraint unreliable.Previous efforts only mitigate this relying on extra models to calibrate imagebrightness. In this paper, we propose MonoPCC to address the brightnessinconsistency radically by reshaping the photometric constraint into a cycleform. Instead of only warping the source image, MonoPCC constructs a closedloop consisting of two opposite forward-backward warping paths: from target tosource and then back to target. Thus, the target image finally receives animage cycle-warped from itself, which naturally makes the constraint invariantto brightness changes. Moreover, MonoPCC transplants the source image'sphase-frequency into the intermediate warped image to avoid structure lost, andalso stabilizes the training via an exponential moving average (EMA) strategyto avoid frequent changes in the forward warping. The comprehensive andextensive experimental results on four endoscopic datasets demonstrate that ourproposed MonoPCC shows a great robustness to the brightness inconsistency, andexceeds other state-of-the-arts by reducing the absolute relative error by atleast 7.27%, 9.38%, 9.90% and 3.17%, respectively.</description><author>Zhiwei Wang, Ying Zhou, Shiquan He, Ting Li, Fan Huang, Qiang Ding, Xinxia Feng, Mei Liu, Qiang Li</author><pubDate>Tue, 07 May 2024 17:55:12 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.16571v2</guid></item><item><title>Network reconstruction via the minimum description length principle</title><link>http://arxiv.org/abs/2405.01015v2</link><description>A fundamental problem associated with the task of network reconstruction fromdynamical or behavioral data consists in determining the most appropriate modelcomplexity in a manner that prevents overfitting, and produces an inferrednetwork with a statistically justifiable number of edges. The status quo inthis context is based on $L_{1}$ regularization combined with cross-validation.However, besides its high computational cost, this commonplace approachunnecessarily ties the promotion of sparsity with weight "shrinkage". Thiscombination forces a trade-off between the bias introduced by shrinkage and thenetwork sparsity, which often results in substantial overfitting even aftercross-validation. In this work, we propose an alternative nonparametricregularization scheme based on hierarchical Bayesian inference and weightquantization, which does not rely on weight shrinkage to promote sparsity. Ourapproach follows the minimum description length (MDL) principle, and uncoversthe weight distribution that allows for the most compression of the data, thusavoiding overfitting without requiring cross-validation. The latter propertyrenders our approach substantially faster to employ, as it requires a singlefit to the complete data. As a result, we have a principled and efficientinference scheme that can be used with a large variety of generative models,without requiring the number of edges to be known in advance. We alsodemonstrate that our scheme yields systematically increased accuracy in thereconstruction of both artificial and empirical networks. We highlight the useof our method with the reconstruction of interaction networks between microbialcommunities from large-scale abundance samples involving in the order of$10^{4}$ to $10^{5}$ species, and demonstrate how the inferred model can beused to predict the outcome of interventions in the system.</description><author>Tiago P. Peixoto</author><pubDate>Tue, 07 May 2024 17:54:52 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.01015v2</guid></item><item><title>Adapting WavLM for Speech Emotion Recognition</title><link>http://arxiv.org/abs/2405.04485v1</link><description>Recently, the usage of speech self-supervised models (SSL) for downstreamtasks has been drawing a lot of attention. While large pre-trained modelscommonly outperform smaller models trained from scratch, questions regardingthe optimal fine-tuning strategies remain prevalent. In this paper, we explorethe fine-tuning strategies of the WavLM Large model for the speech emotionrecognition task on the MSP Podcast Corpus. More specifically, we perform aseries of experiments focusing on using gender and semantic information fromutterances. We then sum up our findings and describe the final model we usedfor submission to Speech Emotion Recognition Challenge 2024.</description><author>Daria Diatlova, Anton Udalov, Vitalii Shutov, Egor Spirin</author><pubDate>Tue, 07 May 2024 17:53:42 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.04485v1</guid></item><item><title>OptPDE: Discovering Novel Integrable Systems via AI-Human Collaboration</title><link>http://arxiv.org/abs/2405.04484v1</link><description>Integrable partial differential equation (PDE) systems are of great interestin natural science, but are exceedingly rare and difficult to discover. Tosolve this, we introduce OptPDE, a first-of-its-kind machine learning approachthat Optimizes PDEs' coefficients to maximize their number of conservedquantities, $n_{\rm CQ}$, and thus discover new integrable systems. We discoverfour families of integrable PDEs, one of which was previously known, and threeof which have at least one conserved quantity but are new to the literature tothe best of our knowledge. We investigate more deeply the properties of one ofthese novel PDE families, $u_t = (u_x+a^2u_{xxx})^3$. Our paper offers apromising schema of AI-human collaboration for integrable system discovery:machine learning generates interpretable hypotheses for possible integrablesystems, which human scientists can verify and analyze, to truly close thediscovery loop.</description><author>Subhash Kantamneni, Ziming Liu, Max Tegmark</author><pubDate>Tue, 07 May 2024 17:53:29 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.04484v1</guid></item><item><title>CLIP-KD: An Empirical Study of CLIP Model Distillation</title><link>http://arxiv.org/abs/2307.12732v2</link><description>Contrastive Language-Image Pre-training (CLIP) has become a promisinglanguage-supervised visual pre-training framework. This paper aims to distillsmall CLIP models supervised by a large teacher CLIP model. We propose severaldistillation strategies, including relation, feature, gradient and contrastiveparadigms, to examine the effectiveness of CLIP-Knowledge Distillation (KD). Weshow that a simple feature mimicry with Mean Squared Error loss workssurprisingly well. Moreover, interactive contrastive learning across teacherand student encoders is also effective in performance improvement. We explainthat the success of CLIP-KD can be attributed to maximizing the featuresimilarity between teacher and student. The unified method is applied todistill several student models trained on CC3M+12M. CLIP-KD improves studentCLIP models consistently over zero-shot ImageNet classification and cross-modalretrieval benchmarks. When using ViT-L/14 pretrained on Laion-400M as theteacher, CLIP-KD achieves 57.5\% and 55.4\% zero-shot top-1 ImageNet accuracyover ViT-B/16 and ResNet-50, surpassing the original CLIP without KD by 20.5\%and 20.1\% margins, respectively. Our code is released onhttps://github.com/winycg/CLIP-KD.</description><author>Chuanguang Yang, Zhulin An, Libo Huang, Junyu Bi, Xinqiang Yu, Han Yang, Boyu Diao, Yongjun Xu</author><pubDate>Tue, 07 May 2024 17:49:38 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.12732v2</guid></item><item><title>Concentration Tail-Bound Analysis of Coevolutionary and Bandit Learning Algorithms</title><link>http://arxiv.org/abs/2405.04480v1</link><description>Runtime analysis, as a branch of the theory of AI, studies how the number ofiterations algorithms take before finding a solution (its runtime) depends onthe design of the algorithm and the problem structure. Drift analysis is astate-of-the-art tool for estimating the runtime of randomised algorithms, suchas evolutionary and bandit algorithms. Drift refers roughly to the expectedprogress towards the optimum per iteration. This paper considers the problem ofderiving concentration tail-bounds on the runtime/regret of algorithms. Itprovides a novel drift theorem that gives precise exponential tail-bounds givenpositive, weak, zero and even negative drift. Previously, such exponential tailbounds were missing in the case of weak, zero, or negative drift. Our drifttheorem can be used to prove a strong concentration of the runtime/regret ofalgorithms in AI. For example, we prove that the regret of the \rwab banditalgorithm is highly concentrated, while previous analyses only considered theexpected regret. This means that the algorithm obtains the optimum within agiven time frame with high probability, i.e. a form of algorithm reliability.Moreover, our theorem implies that the time needed by the co-evolutionaryalgorithm RLS-PD to obtain a Nash equilibrium in a \bilinear max-min-benchmarkproblem is highly concentrated. However, we also prove that the algorithmforgets the Nash equilibrium, and the time until this occurs is highlyconcentrated. This highlights a weakness in the RLS-PD which should beaddressed by future work.</description><author>Per Kristian Lehre, Shishen Lin</author><pubDate>Tue, 07 May 2024 17:45:15 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.04480v1</guid></item><item><title>Code-Mixed Probes Show How Pre-Trained Models Generalise On Code-Switched Text</title><link>http://arxiv.org/abs/2403.04872v2</link><description>Code-switching is a prevalent linguistic phenomenon in which multilingualindividuals seamlessly alternate between languages. Despite its widespread useonline and recent research trends in this area, research in code-switchingpresents unique challenges, primarily stemming from the scarcity of labelleddata and available resources. In this study we investigate how pre-trainedLanguage Models handle code-switched text in three dimensions: a) the abilityof PLMs to detect code-switched text, b) variations in the structuralinformation that PLMs utilise to capture code-switched text, and c) theconsistency of semantic information representation in code-switched text. Toconduct a systematic and controlled evaluation of the language models inquestion, we create a novel dataset of well-formed naturalistic code-switchedtext along with parallel translations into the source languages. Our findingsreveal that pre-trained language models are effective in generalising tocode-switched text, shedding light on the abilities of these models togeneralise representations to CS corpora. We release all our code and dataincluding the novel corpus at https://github.com/francesita/code-mixed-probes.</description><author>Frances A. Laureano De Leon, Harish Tayyar Madabushi, Mark Lee</author><pubDate>Tue, 07 May 2024 17:38:25 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.04872v2</guid></item><item><title>CascadedGaze: Efficiency in Global Context Extraction for Image Restoration</title><link>http://arxiv.org/abs/2401.15235v2</link><description>Image restoration tasks traditionally rely on convolutional neural networks.However, given the local nature of the convolutional operator, they struggle tocapture global information. The promise of attention mechanisms in Transformersis to circumvent this problem, but it comes at the cost of intensivecomputational overhead. Many recent studies in image restoration have focusedon solving the challenge of balancing performance and computational cost viaTransformer variants. In this paper, we present CascadedGaze Network (CGNet),an encoder-decoder architecture that employs Global Context Extractor (GCE), anovel and efficient way to capture global information for image restoration.The GCE module leverages small kernels across convolutional layers to learnglobal dependencies, without requiring self-attention. Extensive experimentalresults show that our computationally efficient approach performs competitivelyto a range of state-of-the-art methods on synthetic image denoising and singleimage deblurring tasks, and pushes the performance boundary further on the realimage denoising task.</description><author>Amirhosein Ghasemabadi, Muhammad Kamran Janjua, Mohammad Salameh, Chunhua Zhou, Fengyu Sun, Di Niu</author><pubDate>Tue, 07 May 2024 17:32:18 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.15235v2</guid></item><item><title>Learning Noise-Robust Joint Representation for Multimodal Emotion Recognition under Incomplete Data Scenarios</title><link>http://arxiv.org/abs/2311.16114v2</link><description>Multimodal emotion recognition (MER) in practical scenarios is significantlychallenged by the presence of missing or incomplete data across differentmodalities. To overcome these challenges, researchers have aimed to simulateincomplete conditions during the training phase to enhance the system's overallrobustness. Traditional methods have often involved discarding data orsubstituting data segments with zero vectors to approximate theseincompletenesses. However, such approaches neither accurately representreal-world conditions nor adequately address the issue of noisy dataavailability. For instance, a blurry image cannot be simply replaced with zerovectors, and still retain information. To tackle this issue and develop a moreprecise MER system, we introduce a novel noise-robust MER model thateffectively learns robust multimodal joint representations from noisy data.This approach includes two pivotal components: firstly, a noise scheduler thatadjusts the type and level of noise in the data to emulate various realisticincomplete situations. Secondly, a Variational AutoEncoder (VAE)-based moduleis employed to reconstruct these robust multimodal joint representations fromthe noisy inputs. Notably, the introduction of the noise scheduler enables theexploration of an entirely new type of incomplete data condition, which isimpossible with existing methods. Extensive experimental evaluations on thebenchmark datasets IEMOCAP and CMU-MOSEI demonstrate the effectiveness of thenoise scheduler and the excellent performance of our proposed model.</description><author>Qi Fan, Haolin Zuo, Rui Liu, Zheng Lian, Guanglai Gao</author><pubDate>Tue, 07 May 2024 17:30:05 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.16114v2</guid></item><item><title>Seeing Is Not Always Believing: Invisible Collision Attack and Defence on Pre-Trained Models</title><link>http://arxiv.org/abs/2309.13579v2</link><description>Large-scale pre-trained models (PTMs) such as BERT and GPT have achievedgreat success in diverse fields. The typical paradigm is to pre-train a bigdeep learning model on large-scale data sets, and then fine-tune the model onsmall task-specific data sets for downstream tasks. Although PTMs have rapidlyprogressed with wide real-world applications, they also pose significant risksof potential attacks. Existing backdoor attacks or data poisoning methods oftenbuild up the assumption that the attacker invades the computers of victims oraccesses the target data, which is challenging in real-world scenarios. In thispaper, we propose a novel framework for an invisible attack on PTMs withenhanced MD5 collision. The key idea is to generate two equal-size models withthe same MD5 checksum by leveraging the MD5 chosen-prefix collision.Afterwards, the two ``same" models will be deployed on public websites toinduce victims to download the poisoned model. Unlike conventional attacks ondeep learning models, this new attack is flexible, covert, andmodel-independent. Additionally, we propose a simple defensive strategy forrecognizing the MD5 chosen-prefix collision and provide a theoreticaljustification for its feasibility. We extensively validate the effectivenessand stealthiness of our proposed attack and defensive method on differentmodels and data sets.</description><author>Minghang Deng, Zhong Zhang, Junming Shao</author><pubDate>Tue, 07 May 2024 17:27:05 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2309.13579v2</guid></item><item><title>A Significantly Better Class of Activation Functions Than ReLU Like Activation Functions</title><link>http://arxiv.org/abs/2405.04459v1</link><description>This paper introduces a significantly better class of activation functionsthan the almost universally used ReLU like and Sigmoidal class of activationfunctions. Two new activation functions referred to as the Cone andParabolic-Cone that differ drastically from popular activation functions andsignificantly outperform these on the CIFAR-10 and Imagenette benchmmarks areproposed. The cone activation functions are positive only on a finite intervaland are strictly negative except at the end-points of the interval, where theybecome zero. Thus the set of inputs that produce a positive output for a neuronwith cone activation functions is a hyperstrip and not a half-space as is theusual case. Since a hyper strip is the region between two parallelhyper-planes, it allows neurons to more finely divide the input feature spaceinto positive and negative classes than with infinitely wide half-spaces. Inparticular the XOR function can be learn by a single neuron with cone-likeactivation functions. Both the cone and parabolic-cone activation functions areshown to achieve higher accuracies with significantly fewer neurons onbenchmarks. The results presented in this paper indicate that many nonlinearreal-world datasets may be separated with fewer hyperstrips than half-spaces.The Cone and Parabolic-Cone activation functions have larger derivatives thanReLU and are shown to significantly speedup training.</description><author>Mathew Mithra Noel, Yug Oswal</author><pubDate>Tue, 07 May 2024 17:24:03 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.04459v1</guid></item><item><title>Towards Geographic Inclusion in the Evaluation of Text-to-Image Models</title><link>http://arxiv.org/abs/2405.04457v1</link><description>Rapid progress in text-to-image generative models coupled with theirdeployment for visual content creation has magnified the importance ofthoroughly evaluating their performance and identifying potential biases. Inpursuit of models that generate images that are realistic, diverse, visuallyappealing, and consistent with the given prompt, researchers and practitionersoften turn to automated metrics to facilitate scalable and cost-effectiveperformance profiling. However, commonly-used metrics often fail to account forthe full diversity of human preference; often even in-depth human evaluationsface challenges with subjectivity, especially as interpretations of evaluationcriteria vary across regions and cultures. In this work, we conduct a large,cross-cultural study to study how much annotators in Africa, Europe, andSoutheast Asia vary in their perception of geographic representation, visualappeal, and consistency in real and generated images from state-of-the artpublic APIs. We collect over 65,000 image annotations and 20 survey responses.We contrast human annotations with common automated metrics, finding that humanpreferences vary notably across geographic location and that current metrics donot fully account for this diversity. For example, annotators in differentlocations often disagree on whether exaggerated, stereotypical depictions of aregion are considered geographically representative. In addition, the utilityof automatic evaluations is dependent on assumptions about their set-up, suchas the alignment of feature extractors with human perception of objectsimilarity or the definition of "appeal" captured in reference datasets used toground evaluations. We recommend steps for improved automatic and humanevaluations.</description><author>Melissa Hall, Samuel J. Bell, Candace Ross, Adina Williams, Michal Drozdzal, Adriana Romero Soriano</author><pubDate>Tue, 07 May 2024 17:23:06 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.04457v1</guid></item><item><title>How Fragile is Relation Extraction under Entity Replacements?</title><link>http://arxiv.org/abs/2305.13551v3</link><description>Relation extraction (RE) aims to extract the relations between entity namesfrom the textual context. In principle, textual context determines theground-truth relation and the RE models should be able to correctly identifythe relations reflected by the textual context. However, existing work hasfound that the RE models memorize the entity name patterns to make REpredictions while ignoring the textual context. This motivates us to raise thequestion: ``are RE models robust to the entity replacements?'' In this work, weoperate the random and type-constrained entity replacements over the REinstances in TACRED and evaluate the state-of-the-art RE models under theentity replacements. We observe the 30\% - 50\% F1 score drops on thestate-of-the-art RE models under entity replacements. These results suggestthat we need more efforts to develop effective RE models robust to entityreplacements. We release the source code athttps://github.com/wangywUST/RobustRE.</description><author>Yiwei Wang, Bryan Hooi, Fei Wang, Yujun Cai, Yuxuan Liang, Wenxuan Zhou, Jing Tang, Manjuan Duan, Muhao Chen</author><pubDate>Tue, 07 May 2024 17:22:07 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.13551v3</guid></item><item><title>Using Pre-training and Interaction Modeling for ancestry-specific disease prediction in UK Biobank</title><link>http://arxiv.org/abs/2404.17626v2</link><description>Recent genome-wide association studies (GWAS) have uncovered the geneticbasis of complex traits, but show an under-representation of non-Europeandescent individuals, underscoring a critical gap in genetic research. Here, weassess whether we can improve disease prediction across diverse ancestriesusing multiomic data. We evaluate the performance of Group-LASSOINTERaction-NET (glinternet) and pretrained lasso in disease predictionfocusing on diverse ancestries in the UK Biobank. Models were trained on datafrom White British and other ancestries and validated across a cohort of over96,000 individuals for 8 diseases. Out of 96 models trained, we report 16 withstatistically significant incremental predictive performance in terms ofROC-AUC scores (p-value &lt; 0.05), found for diabetes, arthritis, gall stones,cystitis, asthma and osteoarthritis. For the interaction and pretrained modelsthat outperformed the baseline, the PRS score was the primary driver behindprediction. Our findings indicate that both interaction terms and pre-trainingcan enhance prediction accuracy but for a limited set of diseases and moderateimprovements in accuracy</description><author>Thomas Le Menestrel, Erin Craig, Robert Tibshirani, Trevor Hastie, Manuel Rivas</author><pubDate>Tue, 07 May 2024 17:21:28 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.17626v2</guid></item><item><title>Towards Continual Knowledge Graph Embedding via Incremental Distillation</title><link>http://arxiv.org/abs/2405.04453v1</link><description>Traditional knowledge graph embedding (KGE) methods typically requirepreserving the entire knowledge graph (KG) with significant training costs whennew knowledge emerges. To address this issue, the continual knowledge graphembedding (CKGE) task has been proposed to train the KGE model by learningemerging knowledge efficiently while simultaneously preserving decent oldknowledge. However, the explicit graph structure in KGs, which is critical forthe above goal, has been heavily ignored by existing CKGE methods. On the onehand, existing methods usually learn new triples in a random order, destroyingthe inner structure of new KGs. On the other hand, old triples are preservedwith equal priority, failing to alleviate catastrophic forgetting effectively.In this paper, we propose a competitive method for CKGE based on incrementaldistillation (IncDE), which considers the full use of the explicit graphstructure in KGs. First, to optimize the learning order, we introduce ahierarchical strategy, ranking new triples for layer-by-layer learning. Byemploying the inter- and intra-hierarchical orders together, new triples aregrouped into layers based on the graph structure features. Secondly, topreserve the old knowledge effectively, we devise a novel incrementaldistillation mechanism, which facilitates the seamless transfer of entityrepresentations from the previous layer to the next one, promoting oldknowledge preservation. Finally, we adopt a two-stage training paradigm toavoid the over-corruption of old knowledge influenced by under-trained newknowledge. Experimental results demonstrate the superiority of IncDE overstate-of-the-art baselines. Notably, the incremental distillation mechanismcontributes to improvements of 0.2%-6.5% in the mean reciprocal rank (MRR)score.</description><author>Jiajun Liu, Wenjun Ke, Peng Wang, Ziyu Shang, Jinhua Gao, Guozheng Li, Ke Ji, Yanhe Liu</author><pubDate>Tue, 07 May 2024 17:16:00 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.04453v1</guid></item><item><title>NTIRE 2024 Quality Assessment of AI-Generated Content Challenge</title><link>http://arxiv.org/abs/2404.16687v2</link><description>This paper reports on the NTIRE 2024 Quality Assessment of AI-GeneratedContent Challenge, which will be held in conjunction with the New Trends inImage Restoration and Enhancement Workshop (NTIRE) at CVPR 2024. This challengeis to address a major challenge in the field of image and video processing,namely, Image Quality Assessment (IQA) and Video Quality Assessment (VQA) forAI-Generated Content (AIGC). The challenge is divided into the image track andthe video track. The image track uses the AIGIQA-20K, which contains 20,000AI-Generated Images (AIGIs) generated by 15 popular generative models. Theimage track has a total of 318 registered participants. A total of 1,646submissions are received in the development phase, and 221 submissions arereceived in the test phase. Finally, 16 participating teams submitted theirmodels and fact sheets. The video track uses the T2VQA-DB, which contains10,000 AI-Generated Videos (AIGVs) generated by 9 popular Text-to-Video (T2V)models. A total of 196 participants have registered in the video track. A totalof 991 submissions are received in the development phase, and 185 submissionsare received in the test phase. Finally, 12 participating teams submitted theirmodels and fact sheets. Some methods have achieved better results than baselinemethods, and the winning methods in both tracks have demonstrated superiorprediction performance on AIGC.</description><author>Xiaohong Liu, Xiongkuo Min, Guangtao Zhai, Chunyi Li, Tengchuan Kou, Wei Sun, Haoning Wu, Yixuan Gao, Yuqin Cao, Zicheng Zhang, Xiele Wu, Radu Timofte, Fei Peng, Huiyuan Fu, Anlong Ming, Chuanming Wang, Huadong Ma, Shuai He, Zifei Dou, Shu Chen, Huacong Zhang, Haiyi Xie, Chengwei Wang, Baoying Chen, Jishen Zeng, Jianquan Yang, Weigang Wang, Xi Fang, Xiaoxin Lv, Jun Yan, Tianwu Zhi, Yabin Zhang, Yaohui Li, Yang Li, Jingwen Xu, Jianzhao Liu, Yiting Liao, Junlin Li, Zihao Yu, Yiting Lu, Xin Li, Hossein Motamednia, S. Farhad Hosseini-Benvidi, Fengbin Guan, Ahmad Mahmoudi-Aznaveh, Azadeh Mansouri, Ganzorig Gankhuyag, Kihwan Yoon, Yifang Xu, Haotian Fan, Fangyuan Kong, Shiling Zhao, Weifeng Dong, Haibing Yin, Li Zhu, Zhiling Wang, Bingchen Huang, Avinab Saha, Sandeep Mishra, Shashank Gupta, Raje</author><pubDate>Tue, 07 May 2024 17:13:05 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.16687v2</guid></item><item><title>Depth-Wise Attention (DWAtt): A Layer Fusion Method for Data-Efficient Classification</title><link>http://arxiv.org/abs/2209.15168v2</link><description>Language Models pretrained on large textual data have been shown to encodedifferent types of knowledge simultaneously. Traditionally, only the featuresfrom the last layer are used when adapting to new tasks or data. We put forwardthat, when using or finetuning deep pretrained models, intermediate layerfeatures that may be relevant to the downstream task are buried too deep to beused efficiently in terms of needed samples or steps. To test this, we proposea new layer fusion method: Depth-Wise Attention (DWAtt), to help re-surfacesignals from non-final layers. We compare DWAtt to a basic concatenation-basedlayer fusion method (Concat), and compare both to a deeper model baseline --all kept within a similar parameter budget. Our findings show that DWAtt andConcat are more step- and sample-efficient than the baseline, especially in thefew-shot setting. DWAtt outperforms Concat on larger data sizes. On CoNLL-03NER, layer fusion shows 3.68--9.73% F1 gain at different few-shot sizes. Thelayer fusion models presented significantly outperform the baseline in varioustraining scenarios with different data sizes, architectures, and trainingconstraints.</description><author>Muhammad ElNokrashy, Badr AlKhamissi, Mona Diab</author><pubDate>Tue, 07 May 2024 17:11:04 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2209.15168v2</guid></item><item><title>Improving Complex Reasoning over Knowledge Graph with Logic-Aware Curriculum Tuning</title><link>http://arxiv.org/abs/2405.01649v2</link><description>Answering complex logical queries over incomplete knowledge graphs (KGs) ischallenging. Most previous works have focused on learning entity/relationembeddings and simulating first-order logic operators with various neuralnetworks. However, they are bottlenecked by the inability to share worldknowledge to improve logical reasoning, thus resulting in suboptimalperformance. In this paper, we propose a complex logical reasoning schema overknowledge graphs upon large language models (LLMs), containing acurriculum-based logical-aware instruction tuning framework, named LACT.Specifically, we augment the arbitrary first-order logical queries via binarytree decomposition, to stimulate the reasoning capability of LLMs. To addressthe difficulty gap among different types of complex queries, we design a simpleand flexible logic-aware curriculum learning framework. Experiments acrosswidely used datasets demonstrate that LACT has substantial improvements~(bringsan average +5.5% MRR score) over advanced methods, achieving the newstate-of-the-art. Our code and model will be released at GitHub and huggingfacesoon.</description><author>Tianle Xia, Liang Ding, Guojia Wan, Yibing Zhan, Bo Du, Dacheng Tao</author><pubDate>Tue, 07 May 2024 17:10:51 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.01649v2</guid></item><item><title>Leveraging Intelligent Recommender system as a first step resilience measure -- A data-driven supply chain disruption response framework</title><link>http://arxiv.org/abs/2404.00306v2</link><description>Interests in the value of digital technologies for its potential uses toincrease supply chain resilience (SCRes) are increasing in light to theindustry 4.0 and the global pandemic. Utilization of Recommender systems (RS)as a supply chain (SC) resilience measure is neglected although RS is a capabletool to enhance SC resilience from a reactive aspect. To address this problem,this research proposed a novel data-driven supply chain disruption responseframework based on the intelligent recommender system techniques and validatedthe conceptual model through a practical use case. Results show that ourframework can be implemented as an effective SC disruption mitigation measurein the very first response phrase and help SC participants get better reactionperformance after the SC disruption.</description><author>Yang Hu</author><pubDate>Tue, 07 May 2024 17:09:06 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.00306v2</guid></item><item><title>POV Learning: Individual Alignment of Multimodal Models using Human Perception</title><link>http://arxiv.org/abs/2405.04443v1</link><description>Aligning machine learning systems with human expectations is mostly attemptedby training with manually vetted human behavioral samples, typically explicitfeedback. This is done on a population level since the context that iscapturing the subjective Point-Of-View (POV) of a concrete person in a specificsituational context is not retained in the data. However, we argue thatalignment on an individual level can boost the subjective predictiveperformance for the individual user interacting with the system considerably.Since perception differs for each person, the same situation is observeddifferently. Consequently, the basis for decision making and the subsequentreasoning processes and observable reactions differ. We hypothesize thatindividual perception patterns can be used for improving the alignment on anindividual level. We test this, by integrating perception information intomachine learning systems and measuring their predictive performancewrt.~individual subjective assessments. For our empirical study, we collect anovel data set of multimodal stimuli and corresponding eye tracking sequencesfor the novel task of Perception-Guided Crossmodal Entailment and tackle itwith our Perception-Guided Multimodal Transformer. Our findings suggest thatexploiting individual perception signals for the machine learning of subjectivehuman assessments provides a valuable cue for individual alignment. It does notonly improve the overall predictive performance from the point-of-view of theindividual user but might also contribute to steering AI systems towards everyperson's individual expectations and values.</description><author>Simon Werner, Katharina Christ, Laura Bernardy, Marion G. Müller, Achim Rettinger</author><pubDate>Tue, 07 May 2024 17:07:29 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.04443v1</guid></item><item><title>AugmenTory: A Fast and Flexible Polygon Augmentation Library</title><link>http://arxiv.org/abs/2405.04442v1</link><description>Data augmentation is a key technique for addressing the challenge of limiteddatasets, which have become a major component in the training procedures ofimage processing. Techniques such as geometric transformations and color spaceadjustments have been thoroughly tested for their ability to artificiallyexpand training datasets and generate semi-realistic data for trainingpurposes. Data augmentation is the most important key to addressing thechallenge of limited datasets, which have become a major component of imageprocessing training procedures. Data augmentation techniques, such as geometrictransformations and color space adjustments, are thoroughly tested for theirability to artificially expand training datasets and generate semi-realisticdata for training purposes. Polygons play a crucial role in instancesegmentation and have seen a surge in use across advanced models, such asYOLOv8. Despite their growing popularity, the lack of specialized librarieshampers the polygon-augmentation process. This paper introduces a novelsolution to this challenge, embodied in the newly developed AugmenTory library.Notably, AugmenTory offers reduced computational demands in both time and spacecompared to existing methods. Additionally, the library includes apostprocessing thresholding feature. The AugmenTory package is publiclyavailable on GitHub, where interested users can access the source code:https://github.com/Smartory/AugmenTory</description><author>Tanaz Ghahremani, Mohammad Hoseyni, Mohammad Javad Ahmadi, Pouria Mehrabi, Amirhossein Nikoofard</author><pubDate>Tue, 07 May 2024 17:07:05 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.04442v1</guid></item><item><title>Label-Agnostic Forgetting: A Supervision-Free Unlearning in Deep Models</title><link>http://arxiv.org/abs/2404.00506v2</link><description>Machine unlearning aims to remove information derived from forgotten datawhile preserving that of the remaining dataset in a well-trained model. Withthe increasing emphasis on data privacy, several approaches to machineunlearning have emerged. However, these methods typically rely on completesupervision throughout the unlearning process. Unfortunately, obtaining suchsupervision, whether for the forgetting or remaining data, can be impracticaldue to the substantial cost associated with annotating real-world datasets.This challenge prompts us to propose a supervision-free unlearning approachthat operates without the need for labels during the unlearning process.Specifically, we introduce a variational approach to approximate thedistribution of representations for the remaining data. Leveraging thisapproximation, we adapt the original model to eliminate information from theforgotten data at the representation level. To further address the issue oflacking supervision information, which hinders alignment with ground truth, weintroduce a contrastive loss to facilitate the matching of representationsbetween the remaining data and those of the original model, thus preservingpredictive performance. Experimental results across various unlearning tasksdemonstrate the effectiveness of our proposed method, Label-Agnostic Forgetting(LAF) without using any labels, which achieves comparable performance tostate-of-the-art methods that rely on full supervision information.Furthermore, our approach excels in semi-supervised scenarios, leveraginglimited supervision information to outperform fully supervised baselines. Thiswork not only showcases the viability of supervision-free unlearning in deepmodels but also opens up a new possibility for future research in unlearning atthe representation level.</description><author>Shaofei Shen, Chenhao Zhang, Yawen Zhao, Alina Bialkowski, Weitong Tony Chen, Miao Xu</author><pubDate>Tue, 07 May 2024 17:06:50 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.00506v2</guid></item><item><title>vAttention: Dynamic Memory Management for Serving LLMs without PagedAttention</title><link>http://arxiv.org/abs/2405.04437v1</link><description>Efficient use of GPU memory is essential for high throughput LLM inference.Prior systems reserved memory for the KV-cache ahead-of-time, resulting inwasted capacity due to internal fragmentation. Inspired by OS-based virtualmemory systems, vLLM proposed PagedAttention to enable dynamic memoryallocation for KV-cache. This approach eliminates fragmentation, enablinghigh-throughput LLM serving with larger batch sizes. However, to be able toallocate physical memory dynamically, PagedAttention changes the layout ofKV-cache from contiguous virtual memory to non-contiguous virtual memory. Thischange requires attention kernels to be rewritten to support paging, andserving framework to implement a memory manager. Thus, the PagedAttention modelleads to software complexity, portability issues, redundancy and inefficiency. In this paper, we propose vAttention for dynamic KV-cache memory management.In contrast to PagedAttention, vAttention retains KV-cache in contiguousvirtual memory and leverages low-level system support for demand paging, thatalready exists, to enable on-demand physical memory allocation. Thus,vAttention unburdens the attention kernel developer from having to explicitlysupport paging and avoids re-implementation of memory management in the servingframework. We show that vAttention enables seamless dynamic memory managementfor unchanged implementations of various attention kernels. vAttention alsogenerates tokens up to 1.97x faster than vLLM, while processing input promptsup to 3.92x and 1.45x faster than the PagedAttention variants of FlashAttentionand FlashInfer.</description><author>Ramya Prabhu, Ajay Nayak, Jayashree Mohan, Ramachandran Ramjee, Ashish Panwar</author><pubDate>Tue, 07 May 2024 17:00:32 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.04437v1</guid></item><item><title>Transport meets Variational Inference: Controlled Monte Carlo Diffusions</title><link>http://arxiv.org/abs/2307.01050v7</link><description>Connecting optimal transport and variational inference, we present aprincipled and systematic framework for sampling and generative modellingcentred around divergences on path space. Our work culminates in thedevelopment of the \emph{Controlled Monte Carlo Diffusion} sampler (CMCD) forBayesian computation, a score-based annealing technique that crucially adaptsboth forward and backward dynamics in a diffusion model. On the way, we clarifythe relationship between the EM-algorithm and iterative proportional fitting(IPF) for Schr{\"o}dinger bridges, deriving as well a regularised objectivethat bypasses the iterative bottleneck of standard IPF-updates. Finally, weshow that CMCD has a strong foundation in the Jarzinsky and Crooks identitiesfrom statistical physics, and that it convincingly outperforms competingapproaches across a wide array of experiments.</description><author>Francisco Vargas, Shreyas Padhy, Denis Blessing, Nikolas Nüsken</author><pubDate>Tue, 07 May 2024 17:00:21 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.01050v7</guid></item><item><title>Fast Exact Retrieval for Nearest-neighbor Lookup (FERN)</title><link>http://arxiv.org/abs/2405.04435v1</link><description>Exact nearest neighbor search is a computationally intensive process, andeven its simpler sibling -- vector retrieval -- can be computationally complex.This is exacerbated when retrieving vectors which have high-dimension $d$relative to the number of vectors, $N$, in the database. Exact nearest neighborretrieval has been generally acknowledged to be a $O(Nd)$ problem with nosub-linear solutions. Attention has instead shifted towards ApproximateNearest-Neighbor (ANN) retrieval techniques, many of which have sub-linear oreven logarithmic time complexities. However, if our intuition from binarysearch problems (e.g. $d=1$ vector retrieval) carries, there ought to be a wayto retrieve an organized representation of vectors without brute-forcing ourway to a solution. For low dimension (e.g. $d=2$ or $d=3$ cases),\texttt{kd-trees} provide a $O(d\log N)$ algorithm for retrieval. Unfortunatelythe algorithm deteriorates rapidly to a $O(dN)$ solution at high dimensions(e.g. $k=128$), in practice. We propose a novel algorithm for logarithmic FastExact Retrieval for Nearest-neighbor lookup (FERN), inspired by\texttt{kd-trees}. The algorithm achieves $O(d\log N)$ look-up with 100\%recall on 10 million $d=128$ uniformly randomly generatedvectors.\footnote{Code available at https://github.com/RichardZhu123/ferns}</description><author>Richard Zhu</author><pubDate>Tue, 07 May 2024 16:57:39 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.04435v1</guid></item><item><title>DeepSeek-V2: A Strong, Economical, and Efficient Mixture-of-Experts Language Model</title><link>http://arxiv.org/abs/2405.04434v1</link><description>We present DeepSeek-V2, a strong Mixture-of-Experts (MoE) language modelcharacterized by economical training and efficient inference. It comprises 236Btotal parameters, of which 21B are activated for each token, and supports acontext length of 128K tokens. DeepSeek-V2 adopts innovative architecturesincluding Multi-head Latent Attention (MLA) and DeepSeekMoE. MLA guaranteesefficient inference through significantly compressing the Key-Value (KV) cacheinto a latent vector, while DeepSeekMoE enables training strong models at aneconomical cost through sparse computation. Compared with DeepSeek 67B,DeepSeek-V2 achieves significantly stronger performance, and meanwhile saves42.5% of training costs, reduces the KV cache by 93.3%, and boosts the maximumgeneration throughput to 5.76 times. We pretrain DeepSeek-V2 on a high-qualityand multi-source corpus consisting of 8.1T tokens, and further performSupervised Fine-Tuning (SFT) and Reinforcement Learning (RL) to fully unlockits potential. Evaluation results show that, even with only 21B activatedparameters, DeepSeek-V2 and its chat versions still achieve top-tierperformance among open-source models. The model checkpoints are available at"https://github.com/deepseek-ai/DeepSeek-V2".</description><author>DeepSeek-AI</author><pubDate>Tue, 07 May 2024 16:56:43 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.04434v1</guid></item><item><title>A Critical Survey on Fairness Benefits of Explainable AI</title><link>http://arxiv.org/abs/2310.13007v6</link><description>In this critical survey, we analyze typical claims on the relationshipbetween explainable AI (XAI) and fairness to disentangle the multidimensionalrelationship between these two concepts. Based on a systematic literaturereview and a subsequent qualitative content analysis, we identify sevenarchetypal claims from 175 scientific articles on the alleged fairness benefitsof XAI. We present crucial caveats with respect to these claims and provide anentry point for future discussions around the potentials and limitations of XAIfor specific fairness desiderata. Importantly, we notice that claims are often(i) vague and simplistic, (ii) lacking normative grounding, or (iii) poorlyaligned with the actual capabilities of XAI. We suggest to conceive XAI not asan ethical panacea but as one of many tools to approach the multidimensional,sociotechnical challenge of algorithmic fairness. Moreover, when making a claimabout XAI and fairness, we emphasize the need to be more specific about whatkind of XAI method is used, which fairness desideratum it refers to, howexactly it enables fairness, and who is the stakeholder that benefits from XAI.</description><author>Luca Deck, Jakob Schoeffer, Maria De-Arteaga, Niklas Kühl</author><pubDate>Tue, 07 May 2024 16:50:27 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.13007v6</guid></item><item><title>DistGrid: Scalable Scene Reconstruction with Distributed Multi-resolution Hash Grid</title><link>http://arxiv.org/abs/2405.04416v1</link><description>Neural Radiance Field~(NeRF) achieves extremely high quality in object-scaledand indoor scene reconstruction. However, there exist some challenges whenreconstructing large-scale scenes. MLP-based NeRFs suffer from limited networkcapacity, while volume-based NeRFs are heavily memory-consuming when the sceneresolution increases. Recent approaches propose to geographically partition thescene and learn each sub-region using an individual NeRF. Such partitioningstrategies help volume-based NeRF exceed the single GPU memory limit and scaleto larger scenes. However, this approach requires multiple background NeRF tohandle out-of-partition rays, which leads to redundancy of learning. Inspiredby the fact that the background of current partition is the foreground ofadjacent partition, we propose a scalable scene reconstruction method based onjoint Multi-resolution Hash Grids, named DistGrid. In this method, the scene isdivided into multiple closely-paved yet non-overlapped Axis-Aligned BoundingBoxes, and a novel segmented volume rendering method is proposed to handlecross-boundary rays, thereby eliminating the need for background NeRFs. Theexperiments demonstrate that our method outperforms existing methods on allevaluated large-scale scenes, and provides visually plausible scenereconstruction. The scalability of our method on reconstruction quality isfurther evaluated qualitatively and quantitatively.</description><author>Sidun Liu, Peng Qiao, Zongxin Ye, Wenyu Li, Yong Dou</author><pubDate>Tue, 07 May 2024 16:41:20 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.04416v1</guid></item><item><title>DocRes: A Generalist Model Toward Unifying Document Image Restoration Tasks</title><link>http://arxiv.org/abs/2405.04408v1</link><description>Document image restoration is a crucial aspect of Document AI systems, as thequality of document images significantly influences the overall performance.Prevailing methods address distinct restoration tasks independently, leading tointricate systems and the incapability to harness the potential synergies ofmulti-task learning. To overcome this challenge, we propose DocRes, ageneralist model that unifies five document image restoration tasks includingdewarping, deshadowing, appearance enhancement, deblurring, and binarization.To instruct DocRes to perform various restoration tasks, we propose a novelvisual prompt approach called Dynamic Task-Specific Prompt (DTSPrompt). TheDTSPrompt for different tasks comprises distinct prior features, which areadditional characteristics extracted from the input image. Beyond its role as acue for task-specific execution, DTSPrompt can also serve as supplementaryinformation to enhance the model's performance. Moreover, DTSPrompt is moreflexible than prior visual prompt approaches as it can be seamlessly appliedand adapted to inputs with high and variable resolutions. Experimental resultsdemonstrate that DocRes achieves competitive or superior performance comparedto existing state-of-the-art task-specific models. This underscores thepotential of DocRes across a broader spectrum of document image restorationtasks. The source code is publicly available athttps://github.com/ZZZHANG-jx/DocRes</description><author>Jiaxin Zhang, Dezhi Peng, Chongyu Liu, Peirong Zhang, Lianwen Jin</author><pubDate>Tue, 07 May 2024 16:35:43 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.04408v1</guid></item><item><title>Super-Exponential Regret for UCT, AlphaGo and Variants</title><link>http://arxiv.org/abs/2405.04407v1</link><description>We improve the proofs of the lower bounds of Coquelin and Munos (2007) thatdemonstrate that UCT can have $\exp(\dots\exp(1)\dots)$ regret (with$\Omega(D)$ exp terms) on the $D$-chain environment, and that a `polynomial'UCT variant has $\exp_2(\exp_2(D - O(\log D)))$ regret on the same environment-- the original proofs contain an oversight for rewards bounded in $[0, 1]$,which we fix in the present draft. We also adapt the proofs to AlphaGo's MCTSand its descendants (e.g., AlphaZero, Leela Zero) to also show $\exp_2(\exp_2(D- O(\log D)))$ regret.</description><author>Laurent Orseau, Remi Munos</author><pubDate>Tue, 07 May 2024 16:35:30 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.04407v1</guid></item><item><title>Bayesian Quantile Regression with Subset Selection: A Posterior Summarization Perspective</title><link>http://arxiv.org/abs/2311.02043v2</link><description>Quantile regression is a powerful tool for inferring how covariates affectspecific percentiles of the response distribution. Existing methods eitherestimate conditional quantiles separately for each quantile of interest orestimate the entire conditional distribution using semi- or non-parametricmodels. The former often produce inadequate models for real data and do notshare information across quantiles, while the latter are characterized bycomplex and constrained models that can be difficult to interpret andcomputationally inefficient. Further, neither approach is well-suited forquantile-specific subset selection. Instead, we pose the fundamental problemsof linear quantile estimation, uncertainty quantification, and subset selectionfrom a Bayesian decision analysis perspective. For any Bayesian regressionmodel, we derive optimal and interpretable linear estimates and uncertaintyquantification for each model-based conditional quantile. Our approachintroduces a quantile-focused squared error loss, which enables efficient,closed-form computing and maintains a close relationship with Wasserstein-baseddensity estimation. In an extensive simulation study, our methods demonstratesubstantial gains in quantile estimation accuracy, variable selection, andinference over frequentist and Bayesian competitors. We apply these tools toidentify the quantile-specific impacts of social and environmental stressors oneducational outcomes for a large cohort of children in North Carolina.</description><author>Joseph Feldman, Daniel Kowal</author><pubDate>Tue, 07 May 2024 16:34:27 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.02043v2</guid></item><item><title>Weakly-Supervised Residual Evidential Learning for Multi-Instance Uncertainty Estimation</title><link>http://arxiv.org/abs/2405.04405v1</link><description>Uncertainty estimation (UE), as an effective means of quantifying predictiveuncertainty, is crucial for safe and reliable decision-making, especially inhigh-risk scenarios. Existing UE schemes usually assume that there arecompletely-labeled samples to support fully-supervised learning. In practice,however, many UE tasks often have no sufficiently-labeled data to use, such asthe Multiple Instance Learning (MIL) with only weak instance annotations. Tobridge this gap, this paper, for the first time, addresses theweakly-supervised issue of Multi-Instance UE (MIUE) and proposes a new baselinescheme, Multi-Instance Residual Evidential Learning (MIREL). Particularly, atthe fine-grained instance UE with only weak supervision, we derive amulti-instance residual operator through the Fundamental Theorem of SymmetricFunctions. On this operator derivation, we further propose MIREL to jointlymodel the high-order predictive distribution at bag and instance levels forMIUE. Extensive experiments empirically demonstrate that our MIREL not onlycould often make existing MIL networks perform better in MIUE, but also couldsurpass representative UE methods by large margins, especially ininstance-level UE tasks.</description><author>Pei Liu, Luping Ji</author><pubDate>Tue, 07 May 2024 16:31:58 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.04405v1</guid></item><item><title>On Good Practices for Task-Specific Distillation of Large Pretrained Visual Models</title><link>http://arxiv.org/abs/2402.11305v2</link><description>Large pretrained visual models exhibit remarkable generalization acrossdiverse recognition tasks. Yet, real-world applications often demand compactmodels tailored to specific problems. Variants of knowledge distillation havebeen devised for such a purpose, enabling task-specific compact models (thestudents) to learn from a generic large pretrained one (the teacher). In thispaper, we show that the excellent robustness and versatility of recentpretrained models challenge common practices established in the literature,calling for a new set of optimal guidelines for task-specific distillation. Toaddress the lack of samples in downstream tasks, we also show that a variant ofMixup based on stable diffusion complements standard data augmentation. Thisstrategy eliminates the need for engineered text prompts and improvesdistillation of generic models into streamlined specialized networks.</description><author>Juliette Marrie, Michael Arbel, Julien Mairal, Diane Larlus</author><pubDate>Tue, 07 May 2024 16:30:45 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.11305v2</guid></item><item><title>Vision Mamba: A Comprehensive Survey and Taxonomy</title><link>http://arxiv.org/abs/2405.04404v1</link><description>State Space Model (SSM) is a mathematical model used to describe and analyzethe behavior of dynamic systems. This model has witnessed numerous applicationsin several fields, including control theory, signal processing, economics andmachine learning. In the field of deep learning, state space models are used toprocess sequence data, such as time series analysis, natural languageprocessing (NLP) and video understanding. By mapping sequence data to statespace, long-term dependencies in the data can be better captured. Inparticular, modern SSMs have shown strong representational capabilities in NLP,especially in long sequence modeling, while maintaining linear time complexity.Notably, based on the latest state-space models, Mamba merges time-varyingparameters into SSMs and formulates a hardware-aware algorithm for efficienttraining and inference. Given its impressive efficiency and strong long-rangedependency modeling capability, Mamba is expected to become a new AIarchitecture that may outperform Transformer. Recently, a number of works haveattempted to study the potential of Mamba in various fields, such as generalvision, multi-modal, medical image analysis and remote sensing image analysis,by extending Mamba from natural language domain to visual domain. To fullyunderstand Mamba in the visual domain, we conduct a comprehensive survey andpresent a taxonomy study. This survey focuses on Mamba's application to avariety of visual tasks and data types, and discusses its predecessors, recentadvances and far-reaching impact on a wide range of domains. Since Mamba is nowon an upward trend, please actively notice us if you have new findings, and newprogress on Mamba will be included in this survey in a timely manner andupdated on the Mamba project athttps://github.com/lx6c78/Vision-Mamba-A-Comprehensive-Survey-and-Taxonomy.</description><author>Xiao Liu, Chenxu Zhang, Lei Zhang</author><pubDate>Tue, 07 May 2024 16:30:14 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.04404v1</guid></item><item><title>Learning To See But Forgetting To Follow: Visual Instruction Tuning Makes LLMs More Prone To Jailbreak Attacks</title><link>http://arxiv.org/abs/2405.04403v1</link><description>Augmenting Large Language Models (LLMs) with image-understanding capabilitieshas resulted in a boom of high-performing Vision-Language models (VLMs). Whilestudying the alignment of LLMs to human values has received widespreadattention, the safety of VLMs has not received the same attention. In thispaper, we explore the impact of jailbreaking on three state-of-the-art VLMs,each using a distinct modeling approach. By comparing each VLM to theirrespective LLM backbone, we find that each VLM is more susceptible tojailbreaking. We consider this as an undesirable outcome from visualinstruction-tuning, which imposes a forgetting effect on an LLM's safetyguardrails. Therefore, we provide recommendations for future work based onevaluation strategies that aim to highlight the weaknesses of a VLM, as well astake safety measures into account during visual instruction tuning.</description><author>Georgios Pantazopoulos, Amit Parekh, Malvina Nikandrou, Alessandro Suglia</author><pubDate>Tue, 07 May 2024 16:29:48 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.04403v1</guid></item><item><title>Deep Unlearning: Fast and Efficient Training-free Approach to Class Forgetting</title><link>http://arxiv.org/abs/2312.00761v3</link><description>Machine unlearning is a prominent and challenging field, driven by regulatorydemands for user data deletion and heightened privacy awareness. Existingapproaches involve retraining model or multiple finetuning steps for eachdeletion request, often constrained by computational limits and restricted dataaccess. In this work, we introduce a novel class unlearning algorithm designedto strategically eliminate specific classes from the learned model. Ouralgorithm first estimates the Retain and the Forget Spaces using Singular ValueDecomposition on the layerwise activations for a small subset of samples fromthe retain and unlearn classes, respectively. We then compute the sharedinformation between these spaces and remove it from the forget space to isolateclass-discriminatory feature space. Finally, we obtain the unlearned model byupdating the weights to suppress the class discriminatory features from theactivation spaces. We demonstrate our algorithm's efficacy on ImageNet using aVision Transformer with only $\sim 1.5\%$ drop in retain accuracy compared tothe original model while maintaining under $1\%$ accuracy on the unlearnedclass samples. Further, our algorithm consistently performs well when subjectto Membership Inference Attacks showing $7.8\%$ improvement on average across avariety of image classification datasets and network architectures, as comparedto other baselines while being $\sim 6 \times$ more computationally efficient.Our code is available at https://github.com/sangamesh-kodge/class_forgetting.</description><author>Sangamesh Kodge, Gobinda Saha, Kaushik Roy</author><pubDate>Tue, 07 May 2024 16:26:02 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.00761v3</guid></item><item><title>Predicting Transonic Flowfields in Non-Homogeneous Unstructured Grids Using Autoencoder Graph Convolutional Networks</title><link>http://arxiv.org/abs/2405.04396v1</link><description>This paper focuses on addressing challenges posed by non-homogeneousunstructured grids, commonly used in Computational Fluid Dynamics (CFD). Theirprevalence in CFD scenarios has motivated the exploration of innovativeapproaches for generating reduced-order models. The core of our approachcenters on geometric deep learning, specifically the utilization of graphconvolutional network (GCN). The novel Autoencoder GCN architecture enhancesprediction accuracy by propagating information to distant nodes and emphasizinginfluential points. This architecture, with GCN layers and encoding/decodingmodules, reduces dimensionality based on pressure-gradient values. Theautoencoder structure improves the network capability to identify key features,contributing to a more robust and accurate predictive model. To validate theproposed methodology, we analyzed two different test cases: wing-only model andwing--body configuration. Precise reconstruction of steady-state distributedquantities within a two-dimensional parametric space underscores thereliability and versatility of the implemented approach.</description><author>Gabriele Immordino, Andrea Vaiuso, Andrea Da Ronch, Marcello Righi</author><pubDate>Tue, 07 May 2024 16:18:21 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.04396v1</guid></item><item><title>Efficient Online Set-valued Classification with Bandit Feedback</title><link>http://arxiv.org/abs/2405.04393v1</link><description>Conformal prediction is a distribution-free method that wraps a given machinelearning model and returns a set of plausible labels that contain the truelabel with a prescribed coverage rate. In practice, the empirical coverageachieved highly relies on fully observed label information from data both inthe training phase for model fitting and the calibration phase for quantileestimation. This dependency poses a challenge in the context of online learningwith bandit feedback, where a learner only has access to the correctness ofactions (i.e., pulled an arm) but not the full information of the true label.In particular, when the pulled arm is incorrect, the learner only knows thatthe pulled one is not the true class label, but does not know which label istrue. Additionally, bandit feedback further results in a smaller labeleddataset for calibration, limited to instances with correct actions, therebyaffecting the accuracy of quantile estimation. To address these limitations, wepropose Bandit Class-specific Conformal Prediction (BCCP), offering coverageguarantees on a class-specific granularity. Using an unbiased estimation of anestimand involving the true label, BCCP trains the model and makes set-valuedinferences through stochastic gradient descent. Our approach overcomes thechallenges of sparsely labeled data in each iteration and generalizes thereliability and applicability of conformal prediction to online decision-makingenvironments.</description><author>Zhou Wang, Xingye Qiao</author><pubDate>Tue, 07 May 2024 16:14:51 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.04393v1</guid></item><item><title>BILTS: A novel bi-invariant local trajectory-shape descriptor for rigid-body motion</title><link>http://arxiv.org/abs/2405.04392v1</link><description>Measuring the similarity between motions and established motion models iscrucial for motion analysis, recognition, generation, and adaptation. Toenhance similarity measurement across diverse contexts, invariant motiondescriptors have been proposed. However, for rigid-body motion, few invariantdescriptors exist that are bi-invariant, meaning invariant to both the body andworld reference frames used to describe the motion. Moreover, their robustnessto singularities is limited. This paper introduces a novel Bi-Invariant LocalTrajectory-Shape descriptor (BILTS) and a corresponding dissimilarity measure.Mathematical relationships between BILTS and existing descriptors are derived,providing new insights into their properties. The paper also includes analgorithm to reproduce the motion from the BILTS descriptor, demonstrating itsbidirectionality and usefulness for trajectory generation. Experimentalvalidation using datasets of daily-life activities shows the higher robustnessof the BILTS descriptor compared to the bi-invariant ISA descriptor. Thishigher robustness supports the further application of bi-invariant descriptorsfor motion recognition and generalization.</description><author>Arno Verduyn, Erwin Aertbeliën, Glenn Maes, Joris De Schutter, Maxim Vochten</author><pubDate>Tue, 07 May 2024 16:14:49 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.04392v1</guid></item><item><title>DriveWorld: 4D Pre-trained Scene Understanding via World Models for Autonomous Driving</title><link>http://arxiv.org/abs/2405.04390v1</link><description>Vision-centric autonomous driving has recently raised wide attention due toits lower cost. Pre-training is essential for extracting a universalrepresentation. However, current vision-centric pre-training typically relieson either 2D or 3D pre-text tasks, overlooking the temporal characteristics ofautonomous driving as a 4D scene understanding task. In this paper, we addressthis challenge by introducing a world model-based autonomous driving 4Drepresentation learning framework, dubbed \emph{DriveWorld}, which is capableof pre-training from multi-camera driving videos in a spatio-temporal fashion.Specifically, we propose a Memory State-Space Model for spatio-temporalmodelling, which consists of a Dynamic Memory Bank module for learningtemporal-aware latent dynamics to predict future changes and a Static ScenePropagation module for learning spatial-aware latent statics to offercomprehensive scene contexts. We additionally introduce a Task Prompt todecouple task-aware features for various downstream tasks. The experimentsdemonstrate that DriveWorld delivers promising results on various autonomousdriving tasks. When pre-trained with the OpenScene dataset, DriveWorld achievesa 7.5% increase in mAP for 3D object detection, a 3.0% increase in IoU foronline mapping, a 5.0% increase in AMOTA for multi-object tracking, a 0.1mdecrease in minADE for motion forecasting, a 3.0% increase in IoU for occupancyprediction, and a 0.34m reduction in average L2 error for planning.</description><author>Chen Min, Dawei Zhao, Liang Xiao, Jian Zhao, Xinli Xu, Zheng Zhu, Lei Jin, Jianshu Li, Yulan Guo, Junliang Xing, Liping Jing, Yiming Nie, Bin Dai</author><pubDate>Tue, 07 May 2024 16:14:20 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.04390v1</guid></item><item><title>Pragmatist Intelligence: Where the Principle of Usefulness Can Take ANNs</title><link>http://arxiv.org/abs/2405.04386v1</link><description>Artificial neural networks (ANNs) perform extraordinarily on numerous tasksincluding classification or prediction, e.g., speech processing and imageclassification. These new functions are based on a computational model that isenabled to select freely all necessary internal model parameters as long as iteventually delivers the functionality it is supposed to exhibit. Here, wereview the connection between the model parameter selection in machine learning(ML) algorithms running on ANNs and the epistemological theory of neopragmatismfocusing on the theory's utility and anti-representationalist aspects. Tounderstand the consequences of the model parameter selection of an ANN, wesuggest using neopragmatist theories whose implications are well studied.Incidentally, neopragmatism's notion of optimization is also based on utilityconsiderations. This means that applying this approach elegantly reveals theinherent connections between optimization in ML, using a numerical methodduring the learning phase, and optimization in the ethical theory ofconsequentialism, where it occurs as a maxim of action. We suggest that theseconnections originate from the way relevance is calculated in ML systems. Thiscould ultimately reveal a tendency for specific actions in ML systems.</description><author>Antonio Bikić, Sayan Mukherjee</author><pubDate>Tue, 07 May 2024 16:11:42 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.04386v1</guid></item><item><title>A Survey on Neural Question Generation: Methods, Applications, and Prospects</title><link>http://arxiv.org/abs/2402.18267v2</link><description>In this survey, we present a detailed examination of the advancements inNeural Question Generation (NQG), a field leveraging neural network techniquesto generate relevant questions from diverse inputs like knowledge bases, texts,and images. The survey begins with an overview of NQG's background,encompassing the task's problem formulation, prevalent benchmark datasets,established evaluation metrics, and notable applications. It then methodicallyclassifies NQG approaches into three predominant categories: structured NQG,which utilizes organized data sources, unstructured NQG, focusing on moreloosely structured inputs like texts or visual content, and hybrid NQG, drawingon diverse input modalities. This classification is followed by an in-depthanalysis of the distinct neural network models tailored for each category,discussing their inherent strengths and potential limitations. The surveyculminates with a forward-looking perspective on the trajectory of NQG,identifying emergent research trends and prospective developmental paths.Accompanying this survey is a curated collection of related research papers,datasets and codes, systematically organized on Github, providing an extensivereference for those delving into NQG.</description><author>Shasha Guo, Lizi Liao, Cuiping Li, Tat-Seng Chua</author><pubDate>Tue, 07 May 2024 16:08:56 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.18267v2</guid></item><item><title>Materials Discovery with Extreme Properties via Reinforcement Learning-Guided Combinatorial Chemistry</title><link>http://arxiv.org/abs/2303.11833v2</link><description>The goal of most materials discovery is to discover materials that aresuperior to those currently known. Fundamentally, this is close toextrapolation, which is a weak point for most machine learning models thatlearn the probability distribution of data. Herein, we develop reinforcementlearning-guided combinatorial chemistry, which is a rule-based moleculardesigner driven by trained policy for selecting subsequent molecular fragmentsto get a target molecule. Since our model has the potential to generate allpossible molecular structures that can be obtained from combinations ofmolecular fragments, unknown molecules with superior properties can bediscovered. We theoretically and empirically demonstrate that our model is moresuitable for discovering better compounds than probabilitydistribution-learning models. In an experiment aimed at discovering moleculesthat hit seven extreme target properties, our model discovered 1,315 of alltarget-hitting molecules and 7,629 of five target-hitting molecules out of100,000 trials, whereas the probability distribution-learning models failed.Moreover, it has been confirmed that every molecule generated under the bindingrules of molecular fragments is 100% chemically valid. To illustrate theperformance in actual problems, we also demonstrate that our models work wellon two practical applications: discovering protein docking molecules and HIVinhibitors.</description><author>Hyunseung Kim, Haeyeon Choi, Dongju Kang, Won Bo Lee, Jonggeol Na</author><pubDate>Tue, 07 May 2024 16:07:34 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2303.11833v2</guid></item><item><title>$\textbf{Splat-MOVER}$: Multi-Stage, Open-Vocabulary Robotic Manipulation via Editable Gaussian Splatting</title><link>http://arxiv.org/abs/2405.04378v1</link><description>We present Splat-MOVER, a modular robotics stack for open-vocabulary roboticmanipulation, which leverages the editability of Gaussian Splatting (GSplat)scene representations to enable multi-stage manipulation tasks. Splat-MOVERconsists of: (i) $\textit{ASK-Splat}$, a GSplat representation that distillslatent codes for language semantics and grasp affordance into the 3D scene.ASK-Splat enables geometric, semantic, and affordance understanding of 3Dscenes, which is critical for many robotics tasks; (ii) $\textit{SEE-Splat}$, areal-time scene-editing module using 3D semantic masking and infilling tovisualize the motions of objects that result from robot interactions in thereal-world. SEE-Splat creates a "digital twin" of the evolving environmentthroughout the manipulation task; and (iii) $\textit{Grasp-Splat}$, a graspgeneration module that uses ASK-Splat and SEE-Splat to propose candidate graspsfor open-world objects. ASK-Splat is trained in real-time from RGB images in abrief scanning phase prior to operation, while SEE-Splat and Grasp-Splat run inreal-time during operation. We demonstrate the superior performance ofSplat-MOVER in hardware experiments on a Kinova robot compared to two recentbaselines in four single-stage, open-vocabulary manipulation tasks, as well asin four multi-stage manipulation tasks using the edited scene to reflect scenechanges due to prior manipulation stages, which is not possible with theexisting baselines. Code for this project and a link to the project page willbe made available soon.</description><author>Ola Shorinwa, Johnathan Tucker, Aliyah Smith, Aiden Swann, Timothy Chen, Roya Firoozi, Monroe Kennedy III, Mac Schwager</author><pubDate>Tue, 07 May 2024 16:00:19 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.04378v1</guid></item><item><title>Choose What You Need: Disentangled Representation Learning for Scene Text Recognition, Removal and Editing</title><link>http://arxiv.org/abs/2405.04377v1</link><description>Scene text images contain not only style information (font, background) butalso content information (character, texture). Different scene text tasks needdifferent information, but previous representation learning methods use tightlycoupled features for all tasks, resulting in sub-optimal performance. Wepropose a Disentangled Representation Learning framework (DARLING) aimed atdisentangling these two types of features for improved adaptability in betteraddressing various downstream tasks (choose what you really need).Specifically, we synthesize a dataset of image pairs with identical style butdifferent content. Based on the dataset, we decouple the two types of featuresby the supervision design. Clearly, we directly split the visual representationinto style and content features, the content features are supervised by a textrecognition loss, while an alignment loss aligns the style features in theimage pairs. Then, style features are employed in reconstructing thecounterpart image via an image decoder with a prompt that indicates thecounterpart's content. Such an operation effectively decouples the featuresbased on their distinctive properties. To the best of our knowledge, this isthe first time in the field of scene text that disentangles the inherentproperties of the text images. Our method achieves state-of-the-art performancein Scene Text Recognition, Removal, and Editing.</description><author>Boqiang Zhang, Hongtao Xie, Zuan Gao, Yuxin Wang</author><pubDate>Tue, 07 May 2024 16:00:11 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.04377v1</guid></item><item><title>Towards Stability of Parameter-free Optimization</title><link>http://arxiv.org/abs/2405.04376v1</link><description>Hyperparameter tuning, particularly the selection of an appropriate learningrate in adaptive gradient training methods, remains a challenge. To tackle thischallenge, in this paper, we propose a novel parameter-free optimizer, AdamG(Adam with the golden step size), designed to automatically adapt to diverseoptimization problems without manual tuning. The core technique underlyingAdamG is our golden step size derived for the AdaGrad-Norm algorithm, which isexpected to help AdaGrad-Norm preserve the tuning-free convergence andapproximate the optimal step size in expectation w.r.t. various optimizationscenarios. To better evaluate tuning-free performance, we propose a novelevaluation criterion, stability, to comprehensively assess the efficacy ofparameter-free optimizers in addition to classical performance criteria.Empirical results demonstrate that compared with other parameter-freebaselines, AdamG achieves superior performance, which is consistently on parwith Adam using a manually tuned learning rate across various optimizationtasks.</description><author>Yijiang Pang, Shuyang Yu, Bao Hoang, Jiayu Zhou</author><pubDate>Tue, 07 May 2024 15:58:12 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.04376v1</guid></item><item><title>Leveraging LSTM and GAN for Modern Malware Detection</title><link>http://arxiv.org/abs/2405.04373v1</link><description>The malware booming is a cyberspace equal to the effect of climate change toecosystems in terms of danger. In the case of significant investments incybersecurity technologies and staff training, the global community has becomelocked up in the eternal war with cyber security threats. The multi-form andchanging faces of malware are continuously pushing the boundaries of thecybersecurity practitioners employ various approaches like detection andmitigate in coping with this issue. Some old mannerisms like signature-baseddetection and behavioral analysis are slow to adapt to the speedy evolution ofmalware types. Consequently, this paper proposes the utilization of the DeepLearning Model, LSTM networks, and GANs to amplify malware detection accuracyand speed. A fast-growing, state-of-the-art technology that leverages rawbytestream-based data and deep learning architectures, the AI technologyprovides better accuracy and performance than the traditional methods.Integration of LSTM and GAN model is the technique that is used for thesynthetic generation of data, leading to the expansion of the trainingdatasets, and as a result, the detection accuracy is improved. The paper usesthe VirusShare dataset which has more than one million unique samples of themalware as the training and evaluation set for the presented models. Throughthorough data preparation including tokenization, augmentation, as well asmodel training, the LSTM and GAN models convey the better performance in thetasks compared to straight classifiers. The research outcomes come out with 98%accuracy that shows the efficiency of deep learning plays a decisive role inproactive cybersecurity defense. Aside from that, the paper studies the outputof ensemble learning and model fusion methods as a way to reduce biases andlift model complexity.</description><author>Ishita Gupta, Sneha Kumari, Priya Jha, Mohona Ghosh</author><pubDate>Tue, 07 May 2024 15:57:24 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.04373v1</guid></item><item><title>PoseINN: Realtime Visual-based Pose Regression and Localization with Invertible Neural Networks</title><link>http://arxiv.org/abs/2404.13288v3</link><description>Estimating ego-pose from cameras is an important problem in robotics withapplications ranging from mobile robotics to augmented reality. While SOTAmodels are becoming increasingly accurate, they can still be unwieldy due tohigh computational costs. In this paper, we propose to solve the problem byusing invertible neural networks (INN) to find the mapping between the latentspace of images and poses for a given scene. Our model achieves similarperformance to the SOTA while being faster to train and only requiring offlinerendering of low-resolution synthetic data. By using normalizing flows, theproposed method also provides uncertainty estimation for the output. We alsodemonstrated the efficiency of this method by deploying the model on a mobilerobot.</description><author>Zirui Zang, Ahmad Amine, Rahul Mangharam</author><pubDate>Tue, 07 May 2024 15:56:00 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.13288v3</guid></item><item><title>Explainable machine learning for predicting shellfish toxicity in the Adriatic Sea using long-term monitoring data of HABs</title><link>http://arxiv.org/abs/2405.04372v1</link><description>In this study, explainable machine learning techniques are applied to predictthe toxicity of mussels in the Gulf of Trieste (Adriatic Sea) caused by harmfulalgal blooms. By analysing a newly created 28-year dataset containing recordsof toxic phytoplankton in mussel farming areas and toxin concentrations inmussels (Mytilus galloprovincialis), we train and evaluate the performance ofML models to accurately predict diarrhetic shellfish poisoning (DSP) events.The random forest model provided the best prediction of positive toxicityresults based on the F1 score. Explainability methods such as permutationimportance and SHAP identified key species (Dinophysis fortii and D. caudata)and environmental factors (salinity, river discharge and precipitation) as thebest predictors of DSP outbreaks. These findings are important for improvingearly warning systems and supporting sustainable aquaculture practices.</description><author>Martin Marzidovšek, Janja Francé, Vid Podpečan, Stanka Vadnjal, Jožica Dolenc, Patricija Mozetič</author><pubDate>Tue, 07 May 2024 15:55:42 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.04372v1</guid></item><item><title>Community Detection for Heterogeneous Multiple Social Networks</title><link>http://arxiv.org/abs/2405.04371v1</link><description>The community plays a crucial role in understanding user behavior and networkcharacteristics in social networks. Some users can use multiple social networksat once for a variety of objectives. These users are called overlapping userswho bridge different social networks. Detecting communities across multiplesocial networks is vital for interaction mining, information diffusion, andbehavior migration analysis among networks. This paper presents a communitydetection method based on nonnegative matrix tri-factorization for multipleheterogeneous social networks, which formulates a common consensus matrix torepresent the global fused community. Specifically, the proposed methodinvolves creating adjacency matrices based on network structure and contentsimilarity, followed by alignment matrices which distinguish overlapping usersin different social networks. With the generated alignment matrices, the methodcould enhance the fusion degree of the global community by detectingoverlapping user communities across networks. The effectiveness of the proposedmethod is evaluated with new metrics on Twitter, Instagram, and Tumblrdatasets. The results of the experiments demonstrate its superior performancein terms of community quality and community fusion.</description><author>Ziqing Zhu, Guan Yuan, Tao Zhou, Jiuxin Cao</author><pubDate>Tue, 07 May 2024 15:52:34 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.04371v1</guid></item><item><title>Diff-IP2D: Diffusion-Based Hand-Object Interaction Prediction on Egocentric Videos</title><link>http://arxiv.org/abs/2405.04370v1</link><description>Understanding how humans would behave during hand-object interaction is vitalfor applications in service robot manipulation and extended reality. To achievethis, some recent works have been proposed to simultaneously predict handtrajectories and object affordances on human egocentric videos. They areregarded as the representation of future hand-object interactions, indicatingpotential human motion and motivation. However, the existing approaches mostlyadopt the autoregressive paradigm for unidirectional prediction, which lacksmutual constraints within the holistic future sequence, and accumulates errorsalong the time axis. Meanwhile, these works basically overlook the effect ofcamera egomotion on first-person view predictions. To address theselimitations, we propose a novel diffusion-based interaction prediction method,namely Diff-IP2D, to forecast future hand trajectories and object affordancesconcurrently in an iterative non-autoregressive manner. We transform thesequential 2D images into latent feature space and design a denoising diffusionmodel to predict future latent interaction features conditioned on past ones.Motion features are further integrated into the conditional denoising processto enable Diff-IP2D aware of the camera wearer's dynamics for more accurateinteraction prediction. The experimental results show that our methodsignificantly outperforms the state-of-the-art baselines on both theoff-the-shelf metrics and our proposed new evaluation protocol. This highlightsthe efficacy of leveraging a generative paradigm for 2D hand-object interactionprediction. The code of Diff-IP2D will be released athttps://github.com/IRMVLab/Diff-IP2D.</description><author>Junyi Ma, Jingyi Xu, Xieyuanli Chen, Hesheng Wang</author><pubDate>Tue, 07 May 2024 15:51:05 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.04370v1</guid></item><item><title>Zero Grads: Learning Local Surrogate Losses for Non-Differentiable Graphics</title><link>http://arxiv.org/abs/2308.05739v2</link><description>Gradient-based optimization is now ubiquitous across graphics, butunfortunately can not be applied to problems with undefined or zero gradients.To circumvent this issue, the loss function can be manually replaced by a``surrogate'' that has similar minima but is differentiable. Our proposedframework, ZeroGrads, automates this process by learning a neural approximationof the objective function, which in turn can be used to differentiate througharbitrary black-box graphics pipelines. We train the surrogate on an activelysmoothed version of the objective and encourage locality, focusing thesurrogate's capacity on what matters at the current training episode. Thefitting is performed online, alongside the parameter optimization, andself-supervised, without pre-computed data or pre-trained models. As samplingthe objective is expensive (it requires a full rendering or simulator run), wedevise an efficient sampling scheme that allows for tractable run-times andcompetitive performance at little overhead. We demonstrate optimizing diversenon-convex, non-differentiable black-box problems in graphics, such asvisibility in rendering, discrete parameter spaces in procedural modelling oroptimal control in physics-driven animation. In contrast to otherderivative-free algorithms, our approach scales well to higher dimensions,which we demonstrate on problems with up to 35k interlinked variables.</description><author>Michael Fischer, Tobias Ritschel</author><pubDate>Tue, 07 May 2024 15:50:00 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2308.05739v2</guid></item><item><title>Solving the bongard-logo problem by modeling a probabilistic model</title><link>http://arxiv.org/abs/2403.03173v4</link><description>Abstract reasoning problems challenge the perceptual and cognitive abilitiesof AI algorithms, demanding deeper pattern discernment and inductive reasoningbeyond explicit image features. This study introduces PMoC, a tailoredprobability model for the Bongard-Logo problem, achieving high reasoningaccuracy by constructing independent probability models. Additionally, wepresent Pose-Transformer, an enhanced Transformer-Encoder designed for complexabstract reasoning tasks, including Bongard-Logo, RAVEN, I-RAVEN, and PGM.Pose-Transformer incorporates positional information learning, inspired bycapsule networks' pose matrices, enhancing its focus on local positionalrelationships in image data processing. When integrated with PMoC, it furtherimproves reasoning accuracy. Our approach effectively addresses reasoningdifficulties associated with abstract entities' positional changes,outperforming previous models on the OIG, D3$\times$3 subsets of RAVEN, and PGMdatabases. This research contributes to advancing AI's capabilities in abstractreasoning and cognitive pattern recognition.</description><author>Ruizhuo Song, Beiming Yuan</author><pubDate>Tue, 07 May 2024 15:34:34 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.03173v4</guid></item><item><title>Global Scale Self-Supervised Channel Charting with Sensor Fusion</title><link>http://arxiv.org/abs/2405.04357v1</link><description>The sensing and positioning capabilities foreseen in 6G have great potentialfor technology advancements in various domains, such as future smart cities andindustrial use cases. Channel charting has emerged as a promising technology inrecent years for radio frequency-based sensing and localization. However, theaccuracy of these techniques is yet far behind the numbers envisioned in 6G. Toreduce this gap, in this paper, we propose a novel channel charting techniquecapitalizing on the time of arrival measurements from surrounding TransmissionReception Points (TRPs) along with their locations and leveraging sensor fusionin channel charting by incorporating laser scanner data during the trainingphase of our algorithm. The proposed algorithm remains self-supervised duringtraining and test phases, requiring no geometrical models or user positionground truth. Simulation results validate the achievement of a sub-meter levellocalization accuracy using our algorithm 90% of the time, outperforming thestate-of-the-art channel charting techniques and the traditionaltriangulation-based approaches.</description><author>Omid Esrafilian, Mohsen Ahadi, Florian Kaltenberger, David Gesbert</author><pubDate>Tue, 07 May 2024 15:33:45 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.04357v1</guid></item><item><title>Diffusion-driven GAN Inversion for Multi-Modal Face Image Generation</title><link>http://arxiv.org/abs/2405.04356v1</link><description>We present a new multi-modal face image generation method that converts atext prompt and a visual input, such as a semantic mask or scribble map, into aphoto-realistic face image. To do this, we combine the strengths of GenerativeAdversarial networks (GANs) and diffusion models (DMs) by employing themulti-modal features in the DM into the latent space of the pre-trained GANs.We present a simple mapping and a style modulation network to link two modelsand convert meaningful representations in feature maps and attention maps intolatent codes. With GAN inversion, the estimated latent codes can be used togenerate 2D or 3D-aware facial images. We further present a multi-step trainingstrategy that reflects textual and structural representations into thegenerated image. Our proposed network produces realistic 2D, multi-view, andstylized face images, which align well with inputs. We validate our method byusing pre-trained 2D and 3D GANs, and our results outperform existing methods.Our project page is available athttps://github.com/1211sh/Diffusion-driven_GAN-Inversion/.</description><author>Jihyun Kim, Changjae Oh, Hoseok Do, Soohyun Kim, Kwanghoon Sohn</author><pubDate>Tue, 07 May 2024 15:33:40 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.04356v1</guid></item><item><title>Random walks on simplicial complexes</title><link>http://arxiv.org/abs/2404.08803v2</link><description>The notion of Laplacian of a graph can be generalized to simplicial complexesand hypergraphs, and contains information on the topology of these structures.Even for a graph, the consideration of associated simplicial complexes isinteresting to understand its shape. Whereas the Laplacian of a graph has asimple probabilistic interpretation as the generator of a continuous timeMarkov chain on the graph, things are not so direct when considering simplicialcomplexes. We define here new Markov chains on simplicial complexes. For agiven order~$k$, the state space is the set of $k$-cycles that are chains of$k$-simplexes with null boundary. This new framework is a naturalgeneralization of the canonical Markov chains on graphs. We show that thegenerator of our Markov chain is the upper Laplacian defined in the context ofalgebraic topology for discrete structure. We establish several key propertiesof this new process: in particular, when the number of vertices is finite, theMarkov chain is positive recurrent. This result is not trivial, since thecycles can loop over themselves an unbounded number of times. We study thediffusive limits when the simplicial complexes under scrutiny are a sequence ofever refining triangulations of the flat torus. Using the analogy betweensingular and Hodge homologies, we express this limit as valued in the set ofcurrents. The proof of tightness and the identification of the limitingmartingale problem make use of the flat norm and carefully controls of theerror terms in the convergence of the generator. Uniqueness of the solution tothe martingale problem is left open. An application to hole detection iscarried.</description><author>Thomas Bonis, Laurent Decreusefond, Viet Chi Tran, Zhihan Iris Zhang</author><pubDate>Tue, 07 May 2024 15:31:13 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.08803v2</guid></item><item><title>A Unified Approach for Text- and Image-guided 4D Scene Generation</title><link>http://arxiv.org/abs/2311.16854v3</link><description>Large-scale diffusion generative models are greatly simplifying image, videoand 3D asset creation from user-provided text prompts and images. However, thechallenging problem of text-to-4D dynamic 3D scene generation with diffusionguidance remains largely unexplored. We propose Dream-in-4D, which features anovel two-stage approach for text-to-4D synthesis, leveraging (1) 3D and 2Ddiffusion guidance to effectively learn a high-quality static 3D asset in thefirst stage; (2) a deformable neural radiance field that explicitlydisentangles the learned static asset from its deformation, preserving qualityduring motion learning; and (3) a multi-resolution feature grid for thedeformation field with a displacement total variation loss to effectively learnmotion with video diffusion guidance in the second stage. Through a userpreference study, we demonstrate that our approach significantly advances imageand motion quality, 3D consistency and text fidelity for text-to-4D generationcompared to baseline approaches. Thanks to its motion-disentangledrepresentation, Dream-in-4D can also be easily adapted for controllablegeneration where appearance is defined by one or multiple images, without theneed to modify the motion learning stage. Thus, our method offers, for thefirst time, a unified approach for text-to-4D, image-to-4D and personalized 4Dgeneration tasks.</description><author>Yufeng Zheng, Xueting Li, Koki Nagano, Sifei Liu, Karsten Kreis, Otmar Hilliges, Shalini De Mello</author><pubDate>Tue, 07 May 2024 15:29:18 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.16854v3</guid></item><item><title>FollowIR: Evaluating and Teaching Information Retrieval Models to Follow Instructions</title><link>http://arxiv.org/abs/2403.15246v3</link><description>Modern Language Models (LMs) are capable of following long and complexinstructions that enable a large and diverse set of user requests. WhileInformation Retrieval (IR) models use these LMs as the backbone of theirarchitectures, virtually none of them allow users to provide detailedinstructions alongside queries, thus limiting their ability to satisfy complexinformation needs. In this work, we study the use of instructions in IRsystems. First, we introduce our dataset FollowIR, which contains a rigorousinstruction evaluation benchmark as well as a training set for helping IRmodels learn to better follow real-world instructions. FollowIR repurposesdetailed instructions -- also known as narratives -- developed for professionalassessors to evaluate retrieval systems. In particular, we build our benchmarkfrom three collections curated for shared tasks at the Text REtrievalConference (TREC). These collections contains hundreds to thousands of labeleddocuments per query, making them suitable for our exploration. Through thisprocess, we can measure how well IR models follow instructions, through a newpairwise evaluation framework. Our results indicate that existing retrievalmodels fail to correctly use instructions, using them for basic keywords andstruggling to understand long-form information. However, we show that it ispossible for IR models to learn to follow complex instructions: our newFollowIR-7B model has significant improvements after fine-tuning on ourtraining set.</description><author>Orion Weller, Benjamin Chang, Sean MacAvaney, Kyle Lo, Arman Cohan, Benjamin Van Durme, Dawn Lawrie, Luca Soldaini</author><pubDate>Tue, 07 May 2024 15:25:15 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.15246v3</guid></item><item><title>Revisiting character-level adversarial attacks</title><link>http://arxiv.org/abs/2405.04346v1</link><description>Adversarial attacks in Natural Language Processing apply perturbations in thecharacter or token levels. Token-level attacks, gaining prominence for theiruse of gradient-based methods, are susceptible to altering sentence semantics,leading to invalid adversarial examples. While character-level attacks easilymaintain semantics, they have received less attention as they cannot easilyadopt popular gradient-based methods, and are thought to be easy to defend.Challenging these beliefs, we introduce Charmer, an efficient query-basedadversarial attack capable of achieving high attack success rate (ASR) whilegenerating highly similar adversarial examples. Our method successfully targetsboth small (BERT) and large (Llama 2) models. Specifically, on BERT with SST-2,Charmer improves the ASR in 4.84% points and the USE similarity in 8% pointswith respect to the previous art. Our implementation is available inhttps://github.com/LIONS-EPFL/Charmer.</description><author>Elias Abad Rocamora, Yongtao Wu, Fanghui Liu, Grigorios G. Chrysos, Volkan Cevher</author><pubDate>Tue, 07 May 2024 15:23:22 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.04346v1</guid></item><item><title>Novel View Synthesis with Neural Radiance Fields for Industrial Robot Applications</title><link>http://arxiv.org/abs/2405.04345v1</link><description>Neural Radiance Fields (NeRFs) have become a rapidly growing research fieldwith the potential to revolutionize typical photogrammetric workflows, such asthose used for 3D scene reconstruction. As input, NeRFs require multi-viewimages with corresponding camera poses as well as the interior orientation. Inthe typical NeRF workflow, the camera poses and the interior orientation areestimated in advance with Structure from Motion (SfM). But the quality of theresulting novel views, which depends on different parameters such as the numberand distribution of available images, as well as the accuracy of the relatedcamera poses and interior orientation, is difficult to predict. In addition,SfM is a time-consuming pre-processing step, and its quality strongly dependson the image content. Furthermore, the undefined scaling factor of SfM hinderssubsequent steps in which metric information is required. In this paper, weevaluate the potential of NeRFs for industrial robot applications. We proposean alternative to SfM pre-processing: we capture the input images with acalibrated camera that is attached to the end effector of an industrial robotand determine accurate camera poses with metric scale based on the robotkinematics. We then investigate the quality of the novel views by comparingthem to ground truth, and by computing an internal quality measure based onensemble methods. For evaluation purposes, we acquire multiple datasets thatpose challenges for reconstruction typical of industrial applications, likereflective objects, poor texture, and fine structures. We show that therobot-based pose determination reaches similar accuracy as SfM in non-demandingcases, while having clear advantages in more challenging scenarios. Finally, wepresent first results of applying the ensemble method to estimate the qualityof the synthetic novel view in the absence of a ground truth.</description><author>Markus Hillemann, Robert Langendörfer, Max Heiken, Max Mehltretter, Andreas Schenk, Martin Weinmann, Stefan Hinz, Christian Heipke, Markus Ulrich</author><pubDate>Tue, 07 May 2024 15:22:32 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.04345v1</guid></item><item><title>SDDGR: Stable Diffusion-based Deep Generative Replay for Class Incremental Object Detection</title><link>http://arxiv.org/abs/2402.17323v2</link><description>In the field of class incremental learning (CIL), generative replay hasbecome increasingly prominent as a method to mitigate the catastrophicforgetting, alongside the continuous improvements in generative models.However, its application in class incremental object detection (CIOD) has beensignificantly limited, primarily due to the complexities of scenes involvingmultiple labels. In this paper, we propose a novel approach called stablediffusion deep generative replay (SDDGR) for CIOD. Our method utilizes adiffusion-based generative model with pre-trained text-to-diffusion networks togenerate realistic and diverse synthetic images. SDDGR incorporates aniterative refinement strategy to produce high-quality images encompassing oldclasses. Additionally, we adopt an L2 knowledge distillation technique toimprove the retention of prior knowledge in synthetic images. Furthermore, ourapproach includes pseudo-labeling for old objects within new task images,preventing misclassification as background elements. Extensive experiments onthe COCO 2017 dataset demonstrate that SDDGR significantly outperforms existingalgorithms, achieving a new state-of-the-art in various CIOD scenarios. Thesource code will be made available to the public.</description><author>Junsu Kim, Hoseong Cho, Jihyeon Kim, Yihalem Yimolal Tiruneh, Seungryul Baek</author><pubDate>Tue, 07 May 2024 15:19:13 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.17323v2</guid></item><item><title>Enhancing Scalability of Metric Differential Privacy via Secret Dataset Partitioning and Benders Decomposition</title><link>http://arxiv.org/abs/2405.04344v1</link><description>Metric Differential Privacy (mDP) extends the concept of Differential Privacy(DP) to serve as a new paradigm of data perturbation. It is designed to protectsecret data represented in general metric space, such as text data encoded asword embeddings or geo-location data on the road network or grid maps. Toderive an optimal data perturbation mechanism under mDP, a widely used methodis linear programming (LP), which, however, might suffer from a polynomialexplosion of decision variables, rendering it impractical in large-scale mDP. In this paper, our objective is to develop a new computation framework toenhance the scalability of the LP-based mDP. Considering the connectionsestablished by the mDP constraints among the secret records, we partition theoriginal secret dataset into various subsets. Building upon the partition, wereformulate the LP problem for mDP and solve it via Benders Decomposition,which is composed of two stages: (1) a master program to manage theperturbation calculation across subsets and (2) a set of subproblems, eachmanaging the perturbation derivation within a subset. Our experimental resultson multiple datasets, including geo-location data in the road network/gridmaps, text data, and synthetic data, underscore our proposed mechanism'ssuperior scalability and efficiency.</description><author>Chenxi Qiu</author><pubDate>Tue, 07 May 2024 15:19:09 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.04344v1</guid></item><item><title>The Curse of Diversity in Ensemble-Based Exploration</title><link>http://arxiv.org/abs/2405.04342v1</link><description>We uncover a surprising phenomenon in deep reinforcement learning: training adiverse ensemble of data-sharing agents -- a well-established explorationstrategy -- can significantly impair the performance of the individual ensemblemembers when compared to standard single-agent training. Through carefulanalysis, we attribute the degradation in performance to the low proportion ofself-generated data in the shared training data for each ensemble member, aswell as the inefficiency of the individual ensemble members to learn from suchhighly off-policy data. We thus name this phenomenon the curse of diversity. Wefind that several intuitive solutions -- such as a larger replay buffer or asmaller ensemble size -- either fail to consistently mitigate the performanceloss or undermine the advantages of ensembling. Finally, we demonstrate thepotential of representation learning to counteract the curse of diversity witha novel method named Cross-Ensemble Representation Learning (CERL) in bothdiscrete and continuous control domains. Our work offers valuable insights intoan unexpected pitfall in ensemble-based exploration and raises importantcaveats for future applications of similar approaches.</description><author>Zhixuan Lin, Pierluca D'Oro, Evgenii Nikishin, Aaron Courville</author><pubDate>Tue, 07 May 2024 15:14:50 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.04342v1</guid></item><item><title>Temporal and Heterogeneous Graph Neural Network for Remaining Useful Life Prediction</title><link>http://arxiv.org/abs/2405.04336v1</link><description>Predicting Remaining Useful Life (RUL) plays a crucial role in theprognostics and health management of industrial systems that involve a varietyof interrelated sensors. Given a constant stream of time series sensory datafrom such systems, deep learning models have risen to prominence at identifyingcomplex, nonlinear temporal dependencies in these data. In addition to thetemporal dependencies of individual sensors, spatial dependencies emerge asimportant correlations among these sensors, which can be naturally modelled bya temporal graph that describes time-varying spatial relationships. However,the majority of existing studies have relied on capturing discrete snapshots ofthis temporal graph, a coarse-grained approach that leads to loss of temporalinformation. Moreover, given the variety of heterogeneous sensors, it becomesvital that such inherent heterogeneity is leveraged for RUL prediction intemporal sensor graphs. To capture the nuances of the temporal and spatialrelationships and heterogeneous characteristics in an interconnected graph ofsensors, we introduce a novel model named Temporal and Heterogeneous GraphNeural Networks (THGNN). Specifically, THGNN aggregates historical data fromneighboring nodes to accurately capture the temporal dynamics and spatialcorrelations within the stream of sensor data in a fine-grained manner.Moreover, the model leverages Feature-wise Linear Modulation (FiLM) to addressthe diversity of sensor types, significantly improving the model's capacity tolearn the heterogeneity in the data sources. Finally, we have validated theeffectiveness of our approach through comprehensive experiments. Our empiricalfindings demonstrate significant advancements on the N-CMAPSS dataset,achieving improvements of up to 19.2% and 31.6% in terms of two differentevaluation metrics over state-of-the-art methods.</description><author>Zhihao Wen, Yuan Fang, Pengcheng Wei, Fayao Liu, Zhenghua Chen, Min Wu</author><pubDate>Tue, 07 May 2024 15:08:57 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.04336v1</guid></item><item><title>Rethinking How to Evaluate Language Model Jailbreak</title><link>http://arxiv.org/abs/2404.06407v3</link><description>Large language models (LLMs) have become increasingly integrated with variousapplications. To ensure that LLMs do not generate unsafe responses, they arealigned with safeguards that specify what content is restricted. However, suchalignment can be bypassed to produce prohibited content using a techniquecommonly referred to as jailbreak. Different systems have been proposed toperform the jailbreak automatically. These systems rely on evaluation methodsto determine whether a jailbreak attempt is successful. However, our analysisreveals that current jailbreak evaluation methods have two limitations. (1)Their objectives lack clarity and do not align with the goal of identifyingunsafe responses. (2) They oversimplify the jailbreak result as a binaryoutcome, successful or not. In this paper, we propose three metrics, safeguardviolation, informativeness, and relative truthfulness, to evaluate languagemodel jailbreak. Additionally, we demonstrate how these metrics correlate withthe goal of different malicious actors. To compute these metrics, we introducea multifaceted approach that extends the natural language generation evaluationmethod after preprocessing the response. We evaluate our metrics on a benchmarkdataset produced from three malicious intent datasets and three jailbreaksystems. The benchmark dataset is labeled by three annotators. We compare ourmultifaceted approach with three existing jailbreak evaluation methods.Experiments demonstrate that our multifaceted evaluation outperforms existingmethods, with F1 scores improving on average by 17% compared to existingbaselines. Our findings motivate the need to move away from the binary view ofthe jailbreak problem and incorporate a more comprehensive evaluation to ensurethe safety of the language model.</description><author>Hongyu Cai, Arjun Arunasalam, Leo Y. Lin, Antonio Bianchi, Z. Berkay Celik</author><pubDate>Tue, 07 May 2024 15:06:23 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.06407v3</guid></item><item><title>Calabi-Yau Four/Five/Six-folds as $\mathbb{P}^n_\textbf{w}$ Hypersurfaces: Machine Learning, Approximation, and Generation</title><link>http://arxiv.org/abs/2311.17146v2</link><description>Calabi-Yau four-folds may be constructed as hypersurfaces in weightedprojective spaces of complex dimension 5 defined via weight systems of 6weights. In this work, neural networks were implemented to learn the Calabi-YauHodge numbers from the weight systems, where gradient saliency and symbolicregression then inspired a truncation of the Landau-Ginzburg model formula forthe Hodge numbers of any dimensional Calabi-Yau constructed in this way. Theapproximation always provides a tight lower bound, is shown to be dramaticallyquicker to compute (with compute times reduced by up to four orders ofmagnitude), and gives remarkably accurate results for systems with largeweights. Additionally, complementary datasets of weight systems satisfying thenecessary but insufficient conditions for transversality were constructed,including considerations of the interior point, reflexivity, andintradivisibility properties. Overall producing a classification of this weightsystem landscape, further confirmed with machine learning methods. Using theknowledge of this classification, and the properties of the presentedapproximation, a novel dataset of transverse weight systems consisting of 7weights was generated for a sum of weights $\leq 200$; producing a new databaseof Calabi-Yau five-folds, with their respective topological propertiescomputed. Further to this an equivalent database of candidate Calabi-Yausix-folds was generated with approximated Hodge numbers.</description><author>Edward Hirst, Tancredi Schettini Gherardini</author><pubDate>Tue, 07 May 2024 15:04:30 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.17146v2</guid></item><item><title>PINNsFormer: A Transformer-Based Framework For Physics-Informed Neural Networks</title><link>http://arxiv.org/abs/2307.11833v3</link><description>Physics-Informed Neural Networks (PINNs) have emerged as a promising deeplearning framework for approximating numerical solutions to partialdifferential equations (PDEs). However, conventional PINNs, relying onmultilayer perceptrons (MLP), neglect the crucial temporal dependenciesinherent in practical physics systems and thus fail to propagate the initialcondition constraints globally and accurately capture the true solutions undervarious scenarios. In this paper, we introduce a novel Transformer-basedframework, termed PINNsFormer, designed to address this limitation. PINNsFormercan accurately approximate PDE solutions by utilizing multi-head attentionmechanisms to capture temporal dependencies. PINNsFormer transforms point-wiseinputs into pseudo sequences and replaces point-wise PINNs loss with asequential loss. Additionally, it incorporates a novel activation function,Wavelet, which anticipates Fourier decomposition through deep neural networks.Empirical results demonstrate that PINNsFormer achieves superior generalizationability and accuracy across various scenarios, including PINNs failure modesand high-dimensional PDEs. Moreover, PINNsFormer offers flexibility inintegrating existing learning schemes for PINNs, further enhancing itsperformance.</description><author>Zhiyuan Zhao, Xueying Ding, B. Aditya Prakash</author><pubDate>Tue, 07 May 2024 15:04:16 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.11833v3</guid></item><item><title>A Fourth Wave of Open Data? Exploring the Spectrum of Scenarios for Open Data and Generative AI</title><link>http://arxiv.org/abs/2405.04333v1</link><description>Since late 2022, generative AI has taken the world by storm, with widespreaduse of tools including ChatGPT, Gemini, and Claude. Generative AI and largelanguage model (LLM) applications are transforming how individuals find andaccess data and knowledge. However, the intricate relationship between opendata and generative AI, and the vast potential it holds for driving innovationin this field remain underexplored areas. This white paper seeks to unpack therelationship between open data and generative AI and explore possiblecomponents of a new Fourth Wave of Open Data: Is open data becoming AI ready?Is open data moving towards a data commons approach? Is generative AI makingopen data more conversational? Will generative AI improve open data quality andprovenance? Towards this end, we provide a new Spectrum of Scenarios framework.This framework outlines a range of scenarios in which open data and generativeAI could intersect and what is required from a data quality and provenanceperspective to make open data ready for those specific scenarios. Thesescenarios include: pertaining, adaptation, inference and insight generation,data augmentation, and open-ended exploration. Through this process, we foundthat in order for data holders to embrace generative AI to improve open dataaccess and develop greater insights from open data, they first must makeprogress around five key areas: enhance transparency and documentation, upholdquality and integrity, promote interoperability and standards, improveaccessibility and useability, and address ethical considerations.</description><author>Hannah Chafetz, Sampriti Saxena, Stefaan G. Verhulst</author><pubDate>Tue, 07 May 2024 15:01:33 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.04333v1</guid></item><item><title>Analytical Approximation of the ELBO Gradient in the Context of the Clutter Problem</title><link>http://arxiv.org/abs/2404.10550v2</link><description>We propose an analytical solution for approximating the gradient of theEvidence Lower Bound (ELBO) in variational inference problems where thestatistical model is a Bayesian network consisting of observations drawn from amixture of a Gaussian distribution embedded in unrelated clutter, known as theclutter problem. The method employs the reparameterization trick to move thegradient operator inside the expectation and relies on the assumption that,because the likelihood factorizes over the observed data, the variationaldistribution is generally more compactly supported than the Gaussiandistribution in the likelihood factors. This allows efficient localapproximation of the individual likelihood factors, which leads to ananalytical solution for the integral defining the gradient expectation. Weintegrate the proposed gradient approximation as the expectation step in an EM(Expectation Maximization) algorithm for maximizing ELBO and test againstclassical deterministic approaches in Bayesian inference, such as the Laplaceapproximation, Expectation Propagation and Mean-Field Variational Inference.The proposed method demonstrates good accuracy and rate of convergence togetherwith linear computational complexity.</description><author>Roumen Nikolaev Popov</author><pubDate>Tue, 07 May 2024 15:00:29 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.10550v2</guid></item><item><title>Enhancing Boundary Segmentation for Topological Accuracy with Skeleton-based Methods</title><link>http://arxiv.org/abs/2404.18539v2</link><description>Topological consistency plays a crucial role in the task of boundarysegmentation for reticular images, such as cell membrane segmentation in neuronelectron microscopic images, grain boundary segmentation in materialmicroscopic images and road segmentation in aerial images. In these fields,topological changes in segmentation results have a serious impact on thedownstream tasks, which can even exceed the misalignment of the boundaryitself. To enhance the topology accuracy in segmentation results, we proposethe Skea-Topo Aware loss, which is a novel loss function that takes intoaccount the shape of each object and topological significance of the pixels. Itconsists of two components. First, a skeleton-aware weighted loss improves thesegmentation accuracy by better modeling the object geometry with skeletons.Second, a boundary rectified term effectively identifies and emphasizestopological critical pixels in the prediction errors using both foreground andbackground skeletons in the ground truth and predictions. Experiments provethat our method improves topological consistency by up to 7 points in VIcompared to 13 state-of-art methods, based on objective and subjectiveassessments across three different boundary segmentation datasets. The code isavailable at https://github.com/clovermini/Skea_topo.</description><author>Chuni Liu, Boyuan Ma, Xiaojuan Ban, Yujie Xie, Hao Wang, Weihua Xue, Jingchao Ma, Ke Xu</author><pubDate>Tue, 07 May 2024 14:55:57 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.18539v2</guid></item><item><title>Audio-Visual Speech Representation Expert for Enhanced Talking Face Video Generation and Evaluation</title><link>http://arxiv.org/abs/2405.04327v1</link><description>In the task of talking face generation, the objective is to generate a facevideo with lips synchronized to the corresponding audio while preserving visualdetails and identity information. Current methods face the challenge oflearning accurate lip synchronization while avoiding detrimental effects onvisual quality, as well as robustly evaluating such synchronization. To tacklethese problems, we propose utilizing an audio-visual speech representationexpert (AV-HuBERT) for calculating lip synchronization loss during training.Moreover, leveraging AV-HuBERT's features, we introduce three novel lipsynchronization evaluation metrics, aiming to provide a comprehensiveassessment of lip synchronization performance. Experimental results, along witha detailed ablation study, demonstrate the effectiveness of our approach andthe utility of the proposed evaluation metrics.</description><author>Dogucan Yaman, Fevziye Irem Eyiokur, Leonard Bärmann, Seymanur Aktı, Hazım Kemal Ekenel, Alexander Waibel</author><pubDate>Tue, 07 May 2024 14:55:50 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.04327v1</guid></item><item><title>Deception in Reinforced Autonomous Agents: The Unconventional Rabbit Hat Trick in Legislation</title><link>http://arxiv.org/abs/2405.04325v1</link><description>Recent developments in large language models (LLMs), while offering apowerful foundation for developing natural language agents, raise safetyconcerns about them and the autonomous agents built upon them. Deception is onepotential capability of AI agents of particular concern, which we refer to asan act or statement that misleads, hides the truth, or promotes a belief thatis not true in its entirety or in part. We move away from the conventionalunderstanding of deception through straight-out lying, making objective selfishdecisions, or giving false information, as seen in previous AI safety research.We target a specific category of deception achieved through obfuscation andequivocation. We broadly explain the two types of deception by analogizing themwith the rabbit-out-of-hat magic trick, where (i) the rabbit either comes outof a hidden trap door or (ii) (our focus) the audience is completely distractedto see the magician bring out the rabbit right in front of them using sleightof hand or misdirection. Our novel testbed framework displays intrinsicdeception capabilities of LLM agents in a goal-driven environment when directedto be deceptive in their natural language generations in a two-agentadversarial dialogue system built upon the legislative task of "lobbying" for abill. Along the lines of a goal-driven environment, we show developingdeceptive capacity through a reinforcement learning setup, building it aroundthe theories of language philosophy and cognitive psychology. We find that thelobbyist agent increases its deceptive capabilities by ~ 40% (relative) throughsubsequent reinforcement trials of adversarial interactions, and our deceptiondetection mechanism shows a detection capability of up to 92%. Our resultshighlight potential issues in agent-human interaction, with agents potentiallymanipulating humans towards its programmed end-goal.</description><author>Atharvan Dogra, Ameet Deshpande, John Nay, Tanmay Rajpurohit, Ashwin Kalyan, Balaraman Ravindran</author><pubDate>Tue, 07 May 2024 14:55:11 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.04325v1</guid></item><item><title>Granite Code Models: A Family of Open Foundation Models for Code Intelligence</title><link>http://arxiv.org/abs/2405.04324v1</link><description>Large Language Models (LLMs) trained on code are revolutionizing the softwaredevelopment process. Increasingly, code LLMs are being integrated into softwaredevelopment environments to improve the productivity of human programmers, andLLM-based agents are beginning to show promise for handling complex tasksautonomously. Realizing the full potential of code LLMs requires a wide rangeof capabilities, including code generation, fixing bugs, explaining anddocumenting code, maintaining repositories, and more. In this work, weintroduce the Granite series of decoder-only code models for code generativetasks, trained with code written in 116 programming languages. The Granite Codemodels family consists of models ranging in size from 3 to 34 billionparameters, suitable for applications ranging from complex applicationmodernization tasks to on-device memory-constrained use cases. Evaluation on acomprehensive set of tasks demonstrates that Granite Code models consistentlyreaches state-of-the-art performance among available open-source code LLMs. TheGranite Code model family was optimized for enterprise software developmentworkflows and performs well across a range of coding tasks (e.g. codegeneration, fixing and explanation), making it a versatile all around codemodel. We release all our Granite Code models under an Apache 2.0 license forboth research and commercial use.</description><author>Mayank Mishra, Matt Stallone, Gaoyuan Zhang, Yikang Shen, Aditya Prasad, Adriana Meza Soria, Michele Merler, Parameswaran Selvam, Saptha Surendran, Shivdeep Singh, Manish Sethi, Xuan-Hong Dang, Pengyuan Li, Kun-Lung Wu, Syed Zawad, Andrew Coleman, Matthew White, Mark Lewis, Raju Pavuluri, Yan Koyfman, Boris Lublinsky, Maximilien de Bayser, Ibrahim Abdelaziz, Kinjal Basu, Mayank Agarwal, Yi Zhou, Chris Johnson, Aanchal Goyal, Hima Patel, Yousaf Shah, Petros Zerfos, Heiko Ludwig, Asim Munawar, Maxwell Crouse, Pavan Kapanipathi, Shweta Salaria, Bob Calio, Sophia Wen, Seetharami Seelam, Brian Belgodere, Carlos Fonseca, Amith Singhee, Nirmit Desai, David D. Cox, Ruchir Puri, Rameswar Panda</author><pubDate>Tue, 07 May 2024 14:50:40 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.04324v1</guid></item><item><title>Beyond human subjectivity and error: a novel AI grading system</title><link>http://arxiv.org/abs/2405.04323v1</link><description>The grading of open-ended questions is a high-effort, high-impact task ineducation. Automating this task promises a significant reduction in workloadfor education professionals, as well as more consistent grading outcomes forstudents, by circumventing human subjectivity and error. While recentbreakthroughs in AI technology might facilitate such automation, this has notbeen demonstrated at scale. It this paper, we introduce a novel automatic shortanswer grading (ASAG) system. The system is based on a fine-tuned open-sourcetransformer model which we trained on large set of exam data from universitycourses across a large range of disciplines. We evaluated the trained model'sperformance against held-out test data in a first experiment and found highaccuracy levels across a broad spectrum of unseen questions, even in unseencourses. We further compared the performance of our model with that ofcertified human domain experts in a second experiment: we first assembledanother test dataset from real historical exams - the historic grades containedin that data were awarded to students in a regulated, legally bindingexamination process; we therefore considered them as ground truth for ourexperiment. We then asked certified human domain experts and our model to gradethe historic student answers again without disclosing the historic grades.Finally, we compared the hence obtained grades with the historic grades (ourground truth). We found that for the courses examined, the model deviated lessfrom the official historic grades than the human re-graders - the model'smedian absolute error was 44 % smaller than the human re-graders', implyingthat the model is more consistent than humans in grading. These results suggestthat leveraging AI enhanced grading can reduce human subjectivity, improveconsistency and thus ultimately increase fairness.</description><author>Alexandra Gobrecht, Felix Tuma, Moritz Möller, Thomas Zöller, Mark Zakhvatkin, Alexandra Wuttig, Holger Sommerfeldt, Sven Schütt</author><pubDate>Tue, 07 May 2024 14:49:59 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.04323v1</guid></item><item><title>Genetic Drift Regularization: on preventing Actor Injection from breaking Evolution Strategies</title><link>http://arxiv.org/abs/2405.04322v1</link><description>Evolutionary Algorithms (EA) have been successfully used for the optimizationof neural networks for policy search, but they still remain sample inefficientand underperforming in some cases compared to gradient-based reinforcementlearning (RL). Various methods combine the two approaches, many of themtraining a RL algorithm on data from EA evaluations and injecting the RL actorinto the EA population. However, when using Evolution Strategies (ES) as theEA, the RL actor can drift genetically far from the the ES distribution andinjection can cause a collapse of the ES performance. Here, we highlight thephenomenon of genetic drift where the actor genome and the ES populationdistribution progressively drift apart, leading to injection having a negativeimpact on the ES. We introduce Genetic Drift Regularization (GDR), a simpleregularization method in the actor training loss that prevents the actor genomefrom drifting away from the ES. We show that GDR can improve ES convergence onproblems where RL learns well, but also helps RL training on other tasks, ,fixes the injection issues better than previous controlled injection methods.</description><author>Paul Templier, Emmanuel Rachelson, Antoine Cully, Dennis G. Wilson</author><pubDate>Tue, 07 May 2024 14:48:59 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.04322v1</guid></item><item><title>Molecular Identification via Molecular Fingerprint extraction from Atomic Force Microscopy images</title><link>http://arxiv.org/abs/2405.04321v1</link><description>Non--Contact Atomic Force Microscopy with CO--functionalized metal tips(referred to as HR-AFM) provides access to the internal structure of individualmolecules adsorbed on a surface with totally unprecedented resolution. Previousworks have shown that deep learning (DL) models can retrieve the chemical andstructural information encoded in a 3D stack of constant-height HR--AFM images,leading to molecular identification. In this work, we overcome theirlimitations by using a well-established description of the molecular structurein terms of topological fingerprints, the 1024--bit Extended ConnectivityChemical Fingerprints of radius 2 (ECFP4), that were developed for substructureand similarity searching. ECFPs provide local structural information of themolecule, each bit correlating with a particular substructure within themolecule. Our DL model is able to extract this optimized structural descriptorfrom the 3D HR--AFM stacks and use it, through virtual screening, to identifymolecules from their predicted ECFP4 with a retrieval accuracy on theoreticalimages of 95.4\%. Furthermore, this approach, unlike previous DL models,assigns a confidence score, the Tanimoto similarity, to each of the candidatemolecules, thus providing information on the reliability of the identification. By construction, the number of times a certain substructure is present in themolecule is lost during the hashing process, necessary to make them useful formachine learning applications. We show that it is possible to complement thefingerprint-based virtual screening with global information provided by anotherDL model that predicts from the same HR--AFM stacks the chemical formula,boosting the identification accuracy up to a 97.6\%. Finally, we perform alimited test with experimental images, obtaining promising results towards theapplication of this pipeline under real conditions</description><author>Manuel González Lastre, Pablo Pou, Miguel Wiche, Daniel Ebeling, Andre Schirmeisen, Rubén Pérez</author><pubDate>Tue, 07 May 2024 14:47:35 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.04321v1</guid></item><item><title>PatentGPT: A Large Language Model for Intellectual Property</title><link>http://arxiv.org/abs/2404.18255v4</link><description>In recent years, large language models(LLMs) have attracted significantattention due to their exceptional performance across a multitude of naturallanguage process tasks, and have been widely applied in various fields.However, the application of large language models in the Intellectual Property(IP) domain is challenging due to the strong need for specialized knowledge,privacy protection, processing of extremely long text in this field. In thistechnical report, we present for the first time a low-cost, standardizedprocedure for training IP-oriented LLMs, meeting the unique requirements of theIP domain. Using this standard process, we have trained the PatentGPT seriesmodels based on open-source pretrained models. By evaluating them on theopen-source IP-oriented benchmark MOZIP, our domain-specific LLMs outperformsGPT-4, indicating the effectiveness of the proposed training procedure and theexpertise of the PatentGPT models in the IP domain. Remarkably, our modelsurpassed GPT-4 on the 2019 China Patent Agent Qualification Examination,scoring 65 and matching human expert levels. Additionally, the PatentGPT model,which utilizes the SMoE architecture, achieves performance comparable to thatof GPT-4 in the IP domain and demonstrates a better cost-performance ratio onlong-text tasks, potentially serving as an alternative to GPT-4 within the IPdomain.</description><author>Zilong Bai, Ruiji Zhang, Linqing Chen, Qijun Cai, Yuan Zhong, Cong Wang, Yan Fang, Jie Fang, Jing Sun, Weikuan Wang, Lizhi Zhou, Haoran Hua, Tian Qiu, Chaochao Wang, Cheng Sun, Jianping Lu, Yixin Wang, Yubin Xia, Meng Hu, Haowen Liu, Peng Xu, Licong Xu, Fu Bian, Xiaolong Gu, Lisha Zhang, Weilei Wang, Changyang Tu</author><pubDate>Tue, 07 May 2024 14:44:23 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.18255v4</guid></item><item><title>Motion State: A New Benchmark Multiple Object Tracking</title><link>http://arxiv.org/abs/2312.17641v2</link><description>In the realm of video analysis, the field of multiple object tracking (MOT)assumes paramount importance, with the motion state of objects-whether staticor dynamic relative to the ground-holding practical significance across diversescenarios. However, the extant literature exhibits a notable dearth in theexploration of this aspect. Deep learning methodologies encounter challenges inaccurately discerning object motion states, while conventional approachesreliant on comprehensive mathematical modeling may yield suboptimal trackingaccuracy. To address these challenges, we introduce a Model-Data-Driven MotionState Judgment Object Tracking Method (MoD2T). This innovative architectureadeptly amalgamates traditional mathematical modeling with deep learning-basedmulti-object tracking frameworks. The integration of mathematical modeling anddeep learning within MoD2T enhances the precision of object motion statedetermination, thereby elevating tracking accuracy. Our empiricalinvestigations comprehensively validate the efficacy of MoD2T across variedscenarios, encompassing unmanned aerial vehicle surveillance and street-leveltracking. Furthermore, to gauge the method's adeptness in discerning objectmotion states, we introduce the Motion State Validation F1 (MVF1) metric. Thisnovel performance metric aims to quantitatively assess the accuracy of motionstate classification, furnishing a comprehensive evaluation of MoD2T'sperformance. Elaborate experimental validations corroborate the rationality ofMVF1. In order to holistically appraise MoD2T's performance, we meticulouslyannotate several renowned datasets and subject MoD2T to stringent testing.Remarkably, under conditions characterized by minimal or moderate cameramotion, the achieved MVF1 values are particularly noteworthy, with exemplarsincluding 0.774 for the KITTI dataset, 0.521 for MOT17, and 0.827 for UAVDT.</description><author>Yang Feng, Liao Pan, Wu Di, Liu Bo, Zhang Xingle</author><pubDate>Tue, 07 May 2024 14:42:52 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.17641v2</guid></item></channel></rss>