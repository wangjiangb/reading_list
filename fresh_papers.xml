<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/"><channel><title>Arxivfresh papers</title><link></link><description>Arxiv paper</description><language>en-US</language><lastBuildDate>Thu, 23 Nov 2023 06:01:01 GMT</lastBuildDate><generator>rfeed v1.0.0</generator><docs>https://github.com/svpino/rfeed/blob/master/README.md</docs><item><title>Retrieval-Augmented Layout Transformer for Content-Aware Layout Generation</title><link>http://arxiv.org/abs/2311.13602v1</link><description>Content-aware graphic layout generation aims to automatically arrange visualelements along with a given content, such as an e-commerce product image. Inthis paper, we argue that the current layout generation approaches suffer fromthe limited training data for the high-dimensional layout structure. We showthat a simple retrieval augmentation can significantly improve the generationquality. Our model, which is named Retrieval-Augmented Layout Transformer(RALF), retrieves nearest neighbor layout examples based on an input image andfeeds these results into an autoregressive generator. Our model can applyretrieval augmentation to various controllable generation tasks and yieldhigh-quality layouts within a unified architecture. Our extensive experimentsshow that RALF successfully generates content-aware layouts in both constrainedand unconstrained settings and significantly outperforms the baselines.</description><author>Daichi Horita, Naoto Inoue, Kotaro Kikuchi, Kota Yamaguchi, Kiyoharu Aizawa</author><pubDate>Wed, 22 Nov 2023 18:59:53 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.13602v1</guid></item><item><title>Visual In-Context Prompting</title><link>http://arxiv.org/abs/2311.13601v1</link><description>In-context prompting in large language models (LLMs) has become a prevalentapproach to improve zero-shot capabilities, but this idea is less explored inthe vision domain. Existing visual prompting methods focus on referringsegmentation to segment the most relevant object, falling short of addressingmany generic vision tasks like open-set segmentation and detection. In thispaper, we introduce a universal visual in-context prompting framework for bothtasks. In particular, we build on top of an encoder-decoder architecture, anddevelop a versatile prompt encoder to support a variety of prompts likestrokes, boxes, and points. We further enhance it to take an arbitrary numberof reference image segments as the context. Our extensive explorations showthat the proposed visual in-context prompting elicits extraordinary referringand generic segmentation capabilities to refer and detect, yielding competitiveperformance to close-set in-domain datasets and showing promising results onmany open-set segmentation datasets. By joint training on COCO and SA-1B, ourmodel achieves $57.7$ PQ on COCO and $23.2$ PQ on ADE20K. Code will beavailable at https://github.com/UX-Decoder/DINOv.</description><author>Feng Li, Qing Jiang, Hao Zhang, Tianhe Ren, Shilong Liu, Xueyan Zou, Huaizhe Xu, Hongyang Li, Chunyuan Li, Jianwei Yang, Lei Zhang, Jianfeng Gao</author><pubDate>Wed, 22 Nov 2023 18:59:48 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.13601v1</guid></item><item><title>ZipLoRA: Any Subject in Any Style by Effectively Merging LoRAs</title><link>http://arxiv.org/abs/2311.13600v1</link><description>Methods for finetuning generative models for concept-driven personalizationgenerally achieve strong results for subject-driven or style-driven generation.Recently, low-rank adaptations (LoRA) have been proposed as aparameter-efficient way of achieving concept-driven personalization. Whilerecent work explores the combination of separate LoRAs to achieve jointgeneration of learned styles and subjects, existing techniques do not reliablyaddress the problem; they often compromise either subject fidelity or stylefidelity. We propose ZipLoRA, a method to cheaply and effectively mergeindependently trained style and subject LoRAs in order to achieve generation ofany user-provided subject in any user-provided style. Experiments on a widerange of subject and style combinations show that ZipLoRA can generatecompelling results with meaningful improvements over baselines in subject andstyle fidelity while preserving the ability to recontextualize. Project page:https://ziplora.github.io</description><author>Viraj Shah, Nataniel Ruiz, Forrester Cole, Erika Lu, Svetlana Lazebnik, Yuanzhen Li, Varun Jampani</author><pubDate>Wed, 22 Nov 2023 18:59:36 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.13600v1</guid></item><item><title>T-Rex: Counting by Visual Prompting</title><link>http://arxiv.org/abs/2311.13596v1</link><description>We introduce T-Rex, an interactive object counting model designed to firstdetect and then count any objects. We formulate object counting as an open-setobject detection task with the integration of visual prompts. Users can specifythe objects of interest by marking points or boxes on a reference image, andT-Rex then detects all objects with a similar pattern. Guided by the visualfeedback from T-Rex, users can also interactively refine the counting resultsby prompting on missing or falsely-detected objects. T-Rex has achievedstate-of-the-art performance on several class-agnostic counting benchmarks. Tofurther exploit its potential, we established a new counting benchmarkencompassing diverse scenarios and challenges. Both quantitative andqualitative results show that T-Rex possesses exceptional zero-shot countingcapabilities. We also present various practical application scenarios forT-Rex, illustrating its potential in the realm of visual prompting.</description><author>Qing Jiang, Feng Li, Tianhe Ren, Shilong Liu, Zhaoyang Zeng, Kent Yu, Lei Zhang</author><pubDate>Wed, 22 Nov 2023 18:57:24 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.13596v1</guid></item><item><title>Covariance alignment: from maximum likelihood estimation to Gromov-Wasserstein</title><link>http://arxiv.org/abs/2311.13595v1</link><description>Feature alignment methods are used in many scientific disciplines for datapooling, annotation, and comparison. As an instance of a permutation learningproblem, feature alignment presents significant statistical and computationalchallenges. In this work, we propose the covariance alignment model to studyand compare various alignment methods and establish a minimax lower bound forcovariance alignment that has a non-standard dimension scaling because of thepresence of a nuisance parameter. This lower bound is in fact minimax optimaland is achieved by a natural quasi MLE. However, this estimator involves asearch over all permutations which is computationally infeasible even when theproblem has moderate size. To overcome this limitation, we show that thecelebrated Gromov-Wasserstein algorithm from optimal transport which is moreamenable to fast implementation even on large-scale problems is also minimaxoptimal. These results give the first statistical justification for thedeployment of the Gromov-Wasserstein algorithm in practice.</description><author>Yanjun Han, Philippe Rigollet, George Stepaniants</author><pubDate>Wed, 22 Nov 2023 18:55:27 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.13595v1</guid></item><item><title>Labeling Neural Representations with Inverse Recognition</title><link>http://arxiv.org/abs/2311.13594v1</link><description>Deep Neural Networks (DNNs) demonstrated remarkable capabilities in learningcomplex hierarchical data representations, but the nature of theserepresentations remains largely unknown. Existing global explainabilitymethods, such as Network Dissection, face limitations such as reliance onsegmentation masks, lack of statistical significance testing, and highcomputational demands. We propose Inverse Recognition (INVERT), a scalableapproach for connecting learned representations with human-understandableconcepts by leveraging their capacity to discriminate between these concepts.In contrast to prior work, INVERT is capable of handling diverse types ofneurons, exhibits less computational complexity, and does not rely on theavailability of segmentation masks. Moreover, INVERT provides an interpretablemetric assessing the alignment between the representation and its correspondingexplanation and delivering a measure of statistical significance, emphasizingits utility and credibility. We demonstrate the applicability of INVERT invarious scenarios, including the identification of representations affected byspurious correlations, and the interpretation of the hierarchical structure ofdecision-making within the models.</description><author>Kirill Bykov, Laura Kopf, Shinichi Nakajima, Marius Kloft, Marina M. -C. HÃ¶hne</author><pubDate>Wed, 22 Nov 2023 18:55:25 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.13594v1</guid></item><item><title>Investigating Weight-Perturbed Deep Neural Networks With Application in Iris Presentation Attack Detection</title><link>http://arxiv.org/abs/2311.12764v2</link><description>Deep neural networks (DNNs) exhibit superior performance in various machinelearning tasks, e.g., image classification, speech recognition, biometricrecognition, object detection, etc. However, it is essential to analyze theirsensitivity to parameter perturbations before deploying them in real-worldapplications. In this work, we assess the sensitivity of DNNs againstperturbations to their weight and bias parameters. The sensitivity analysisinvolves three DNN architectures (VGG, ResNet, and DenseNet), three types ofparameter perturbations (Gaussian noise, weight zeroing, and weight scaling),and two settings (entire network and layer-wise). We perform experiments in thecontext of iris presentation attack detection and evaluate on two publiclyavailable datasets: LivDet-Iris-2017 and LivDet-Iris-2020. Based on thesensitivity analysis, we propose improved models simply by perturbingparameters of the network without undergoing training. We further combine theseperturbed models at the score-level and at the parameter-level to improve theperformance over the original model. The ensemble at the parameter-level showsan average improvement of 43.58% on the LivDet-Iris-2017 dataset and 9.25% onthe LivDet-Iris-2020 dataset. The source code is available athttps://github.com/redwankarimsony/WeightPerturbation-MSU.</description><author>Renu Sharma, Redwan Sony, Arun Ross</author><pubDate>Wed, 22 Nov 2023 18:52:11 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.12764v2</guid></item><item><title>Risk-sensitive Markov Decision Process and Learning under General Utility Functions</title><link>http://arxiv.org/abs/2311.13589v1</link><description>Reinforcement Learning (RL) has gained substantial attention across diverseapplication domains and theoretical investigations. Existing literature on RLtheory largely focuses on risk-neutral settings where the decision-maker learnsto maximize the expected cumulative reward. However, in practical scenariossuch as portfolio management and e-commerce recommendations, decision-makersoften persist in heterogeneous risk preferences subject to outcomeuncertainties, which can not be well-captured by the risk-neural framework.Incorporating these preferences can be approached through utility theory, yetthe development of risk-sensitive RL under general utility functions remains anopen question for theoretical exploration. In this paper, we consider a scenario where the decision-maker seeks tooptimize a general utility function of the cumulative reward in the frameworkof a Markov decision process (MDP). To facilitate the Dynamic ProgrammingPrinciple and Bellman equation, we enlarge the state space with an additionaldimension that accounts for the cumulative reward. We propose a discretizedapproximation scheme to the MDP under enlarged state space, which is tractableand key for algorithmic design. We then propose a modified value iterationalgorithm that employs an epsilon-covering over the space of cumulative reward.When a simulator is accessible, our algorithm efficiently learns a near-optimalpolicy with guaranteed sample complexity. In the absence of a simulator, ouralgorithm, designed with an upper-confidence-bound exploration approach,identifies a near-optimal policy while ensuring a guaranteed regret bound. Forboth algorithms, we match the theoretical lower bounds for the risk-neutralsetting.</description><author>Zhengqi Wu, Renyuan Xu</author><pubDate>Wed, 22 Nov 2023 18:50:06 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.13589v1</guid></item><item><title>A Survey of Serverless Machine Learning Model Inference</title><link>http://arxiv.org/abs/2311.13587v1</link><description>Recent developments in Generative AI, Computer Vision, and Natural LanguageProcessing have led to an increased integration of AI models into variousproducts. This widespread adoption of AI requires significant efforts indeploying these models in production environments. When hosting machinelearning models for real-time predictions, it is important to meet definedService Level Objectives (SLOs), ensuring reliability, minimal downtime, andoptimizing operational costs of the underlying infrastructure. Large machinelearning models often demand GPU resources for efficient inference to meetSLOs. In the context of these trends, there is growing interest in hosting AImodels in a serverless architecture while still providing GPU access forinference tasks. This survey aims to summarize and categorize the emergingchallenges and optimization opportunities for large-scale deep learning servingsystems. By providing a novel taxonomy and summarizing recent trends, we hopethat this survey could shed light on new optimization perspectives and motivatenovel works in large-scale deep learning serving systems.</description><author>Kamil Kojs</author><pubDate>Wed, 22 Nov 2023 18:46:05 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.13587v1</guid></item><item><title>On diffusion-based generative models and their error bounds: The log-concave case with full convergence estimates</title><link>http://arxiv.org/abs/2311.13584v1</link><description>We provide full theoretical guarantees for the convergence behaviour ofdiffusion-based generative models under the assumption of strongly logconcavedata distributions while our approximating class of functions used for scoreestimation is made of Lipschitz continuous functions. We demonstrate via amotivating example, sampling from a Gaussian distribution with unknown mean,the powerfulness of our approach. In this case, explicit estimates are providedfor the associated optimization problem, i.e. score approximation, while theseare combined with the corresponding sampling estimates. As a result, we obtainthe best known upper bound estimates in terms of key quantities of interest,such as the dimension and rates of convergence, for the Wasserstein-2 distancebetween the data distribution (Gaussian with unknown mean) and our samplingalgorithm. Beyond the motivating example and in order to allow for the use of a diverserange of stochastic optimizers, we present our results using an $L^2$-accuratescore estimation assumption, which crucially is formed under an expectationwith respect to the stochastic optimizer and our novel auxiliary process thatuses only known information. This approach yields the best known convergencerate for our sampling algorithm.</description><author>Stefano Bruno, Ying Zhang, Dong-Young Lim, Ãmer Deniz Akyildiz, Sotirios Sabanis</author><pubDate>Wed, 22 Nov 2023 18:40:45 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.13584v1</guid></item><item><title>Adaptive Sampling for Deep Learning via Efficient Nonparametric Proxies</title><link>http://arxiv.org/abs/2311.13583v1</link><description>Data sampling is an effective method to improve the training speed of neuralnetworks, with recent results demonstrating that it can even break the neuralscaling laws. These results critically rely on high-quality scores to estimatethe importance of an input to the network. We observe that there are twodominant strategies: static sampling, where the scores are determined beforetraining, and dynamic sampling, where the scores can depend on the modelweights. Static algorithms are computationally inexpensive but less effectivethan their dynamic counterparts, which can cause end-to-end slowdown due totheir need to explicitly compute losses. To address this problem, we propose anovel sampling distribution based on nonparametric kernel regression thatlearns an effective importance score as the neural network trains. However,nonparametric regression models are too computationally expensive to accelerateend-to-end training. Therefore, we develop an efficient sketch-basedapproximation to the Nadaraya-Watson estimator. Using recent techniques fromhigh-dimensional statistics and randomized algorithms, we prove that ourNadaraya-Watson sketch approximates the estimator with exponential convergenceguarantees. Our sampling algorithm outperforms the baseline in terms ofwall-clock time and accuracy on four datasets.</description><author>Shabnam Daghaghi, Benjamin Coleman, Benito Geordie, Anshumali Shrivastava</author><pubDate>Wed, 22 Nov 2023 18:40:18 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.13583v1</guid></item><item><title>PaSS: Parallel Speculative Sampling</title><link>http://arxiv.org/abs/2311.13581v1</link><description>Scaling the size of language models to tens of billions of parameters has ledto impressive performance on a wide range of tasks. At generation, these modelsare used auto-regressively, requiring a forward pass for each generated token,and thus reading the full set of parameters from memory. This memory accessforms the primary bottleneck for generation and it worsens as the model sizeincreases. Moreover, executing a forward pass for multiple tokens in paralleloften takes nearly the same time as it does for just one token. These twoobservations lead to the development of speculative sampling, where a secondsmaller model is used to draft a few tokens, that are then validated orrejected using a single forward pass of the large model. Unfortunately, thismethod requires two models that share the same tokenizer and thus limits itsadoption. As an alternative, we propose to use parallel decoding as a way todraft multiple tokens from a single model with no computational cost, nor theneed for a second model. Our approach only requires an additional input tokenthat marks the words that will be generated simultaneously. We show promisingperformance (up to $30\%$ speed-up) while requiring only as few as $O(d_{emb})$additional parameters.</description><author>Giovanni Monea, Armand Joulin, Edouard Grave</author><pubDate>Wed, 22 Nov 2023 18:37:27 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.13581v1</guid></item><item><title>$Ï$-PCA: a unified neural model for linear and nonlinear principal component analysis</title><link>http://arxiv.org/abs/2311.13580v1</link><description>Linear principal component analysis (PCA), nonlinear PCA, and linearindependent component analysis (ICA) -- those are three methods withsingle-layer autoencoder formulations for learning linear transformations fromdata. Linear PCA learns orthogonal transformations (rotations) that orient axesto maximise variance, but it suffers from a subspace rotational indeterminacy:it fails to find a unique rotation for axes that share the same variance. Bothnonlinear PCA and linear ICA reduce the subspace indeterminacy from rotationalto permutational by maximising statistical independence under the assumption ofunit variance. The main difference between them is that nonlinear PCA onlylearns rotations while linear ICA learns not just rotations but any lineartransformation with unit variance. The relationship between all three can beunderstood by the singular value decomposition of the linear ICA transformationinto a sequence of rotation, scale, rotation. Linear PCA learns the firstrotation; nonlinear PCA learns the second. The scale is simply the inverse ofthe standard deviations. The problem is that, in contrast to linear PCA,conventional nonlinear PCA cannot be used directly on the data to learn thefirst rotation, the first being special as it reduces dimensionality and ordersby variances. In this paper, we have identified the cause, and as a solution wepropose $\sigma$-PCA: a unified neural model for linear and nonlinear PCA assingle-layer autoencoders. One of its key ingredients: modelling not just therotation but also the scale -- the variances. This model bridges the disparitybetween linear and nonlinear PCA. And so, like linear PCA, it can learn asemi-orthogonal transformation that reduces dimensionality and orders byvariances, but, unlike linear PCA, it does not suffer from rotationalindeterminacy.</description><author>Fahdi Kanavati, Lucy Katsnith, Masayuki Tsuneki</author><pubDate>Wed, 22 Nov 2023 18:34:49 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.13580v1</guid></item><item><title>Physical Reasoning and Object Planning for Household Embodied Agents</title><link>http://arxiv.org/abs/2311.13577v1</link><description>In this study, we explore the sophisticated domain of task planning forrobust household embodied agents, with a particular emphasis on the intricatetask of selecting substitute objects. We introduce the CommonSense ObjectAffordance Task (COAT), a novel framework designed to analyze reasoningcapabilities in commonsense scenarios. This approach is centered onunderstanding how these agents can effectively identify and utilize alternativeobjects when executing household tasks, thereby offering insights into thecomplexities of practical decision-making in real-world environments.Drawinginspiration from human decision-making, we explore how large language modelstackle this challenge through three meticulously crafted commonsensequestion-and-answer datasets, featuring refined rules and human annotations.Our evaluation of state-of-the-art language models on these datasets shedslight on three pivotal considerations: 1) aligning an object's inherent utilitywith the task at hand, 2) navigating contextual dependencies (societal norms,safety, appropriateness, and efficiency), and 3) accounting for the currentphysical state of the object. To maintain accessibility, we introduce fiveabstract variables reflecting an object's physical condition, modulated byhuman insights to simulate diverse household scenarios. Our contributionsinclude insightful Object-Utility mappings addressing the first considerationand two extensive QA datasets (15k and 130k questions) probing the intricaciesof contextual dependencies and object states. The datasets, along with ourfindings, are accessible at: \url{https://github.com/com-phy-affordance/COAT}.This research not only advances our understanding of physical commonsensereasoning in language models but also paves the way for future improvements inhousehold agent intelligence.</description><author>Ayush Agrawal, Raghav Prabhakar, Anirudh Goyal, Dianbo Liu</author><pubDate>Wed, 22 Nov 2023 18:32:03 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.13577v1</guid></item><item><title>XAGen: 3D Expressive Human Avatars Generation</title><link>http://arxiv.org/abs/2311.13574v1</link><description>Recent advances in 3D-aware GAN models have enabled the generation ofrealistic and controllable human body images. However, existing methods focuson the control of major body joints, neglecting the manipulation of expressiveattributes, such as facial expressions, jaw poses, hand poses, and so on. Inthis work, we present XAGen, the first 3D generative model for human avatarscapable of expressive control over body, face, and hands. To enhance thefidelity of small-scale regions like face and hands, we devise a multi-scaleand multi-part 3D representation that models fine details. Based on thisrepresentation, we propose a multi-part rendering technique that disentanglesthe synthesis of body, face, and hands to ease model training and enhancegeometric quality. Furthermore, we design multi-part discriminators thatevaluate the quality of the generated avatars with respect to their appearanceand fine-grained control capabilities. Experiments show that XAGen surpassesstate-of-the-art methods in terms of realism, diversity, and expressive controlabilities. Code and data will be made available athttps://showlab.github.io/xagen.</description><author>Zhongcong Xu, Jianfeng Zhang, Jun Hao Liew, Jiashi Feng, Mike Zheng Shou</author><pubDate>Wed, 22 Nov 2023 18:30:42 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.13574v1</guid></item><item><title>Prediction of Effective Elastic Moduli of Rocks using Graph Neural Networks</title><link>http://arxiv.org/abs/2310.19274v2</link><description>This study presents a Graph Neural Networks (GNNs)-based approach forpredicting the effective elastic moduli of rocks from their digital CT-scanimages. We use the Mapper algorithm to transform 3D digital rock images intograph datasets, encapsulating essential geometrical information. These graphs,after training, prove effective in predicting elastic moduli. Our GNN modelshows robust predictive capabilities across various graph sizes derived fromvarious subcube dimensions. Not only does it perform well on the test dataset,but it also maintains high prediction accuracy for unseen rocks and unexploredsubcube sizes. Comparative analysis with Convolutional Neural Networks (CNNs)reveals the superior performance of GNNs in predicting unseen rock properties.Moreover, the graph representation of microstructures significantly reduces GPUmemory requirements (compared to the grid representation for CNNs), enablinggreater flexibility in the batch size selection. This work demonstrates thepotential of GNN models in enhancing the prediction accuracy of rock propertiesand boosting the efficiency of digital rock analysis.</description><author>Jaehong Chung, Rasool Ahmad, WaiChing Sun, Wei Cai, Tapan Mukerji</author><pubDate>Wed, 22 Nov 2023 18:27:15 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.19274v2</guid></item><item><title>WildFusion: Learning 3D-Aware Latent Diffusion Models in View Space</title><link>http://arxiv.org/abs/2311.13570v1</link><description>Modern learning-based approaches to 3D-aware image synthesis achieve highphotorealism and 3D-consistent viewpoint changes for the generated images.Existing approaches represent instances in a shared canonical space. However,for in-the-wild datasets a shared canonical system can be difficult to defineor might not even exist. In this work, we instead model instances in viewspace, alleviating the need for posed images and learned camera distributions.We find that in this setting, existing GAN-based methods are prone togenerating flat geometry and struggle with distribution coverage. We hencepropose WildFusion, a new approach to 3D-aware image synthesis based on latentdiffusion models (LDMs). We first train an autoencoder that infers a compressedlatent representation, which additionally captures the images' underlying 3Dstructure and enables not only reconstruction but also novel view synthesis. Tolearn a faithful 3D representation, we leverage cues from monocular depthprediction. Then, we train a diffusion model in the 3D-aware latent space,thereby enabling synthesis of high-quality 3D-consistent image samples,outperforming recent state-of-the-art GAN-based methods. Importantly, our3D-aware LDM is trained without any direct supervision from multiview images or3D geometry and does not require posed images or learned pose or cameradistributions. It directly learns a 3D representation without relying oncanonical camera coordinates. This opens up promising research avenues forscalable 3D-aware image synthesis and 3D content creation from in-the-wildimage data. See https://katjaschwarz.github.io/wildfusion for videos of our 3Dresults.</description><author>Katja Schwarz, Seung Wook Kim, Jun Gao, Sanja Fidler, Andreas Geiger, Karsten Kreis</author><pubDate>Wed, 22 Nov 2023 18:25:51 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.13570v1</guid></item><item><title>Drilling Down into the Discourse Structure with LLMs for Long Document Question Answering</title><link>http://arxiv.org/abs/2311.13565v1</link><description>We address the task of evidence retrieval for long document questionanswering, which involves locating relevant paragraphs within a document toanswer a question. We aim to assess the applicability of large language models(LLMs) in the task of zero-shot long document evidence retrieval, owing totheir unprecedented performance across various NLP tasks. However, currentlythe LLMs can consume limited context lengths as input, thus providing documentchunks as inputs might overlook the global context while missing out oncapturing the inter-segment dependencies. Moreover, directly feeding the largeinput sets can incur significant computational costs, particularly whenprocessing the entire document (and potentially incurring monetary expenseswith enterprise APIs like OpenAI's GPT variants). To address these challenges,we propose a suite of techniques that exploit the discourse structure commonlyfound in documents. By utilizing this structure, we create a condensedrepresentation of the document, enabling a more comprehensive understanding andanalysis of relationships between different parts. We retain $99.6\%$ of thebest zero-shot approach's performance, while processing only $26\%$ of thetotal tokens used by the best approach in the information seeking evidenceretrieval setup. We also show how our approach can be combined with\textit{self-ask} reasoning agent to achieve best zero-shot performance incomplex multi-hop question answering, just $\approx 4\%$ short of zero-shotperformance using gold evidence.</description><author>Inderjeet Nair, Shwetha Somasundaram, Apoorv Saxena, Koustava Goswami</author><pubDate>Wed, 22 Nov 2023 18:22:56 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.13565v1</guid></item><item><title>Soulstyler: Using Large Language Model to Guide Image Style Transfer for Target Object</title><link>http://arxiv.org/abs/2311.13562v1</link><description>Image style transfer occupies an important place in both computer graphicsand computer vision. However, most current methods require reference tostylized images and cannot individually stylize specific objects. To overcomethis limitation, we propose the "Soulstyler" framework, which allows users toguide the stylization of specific objects in an image through simple textualdescriptions. We introduce a large language model to parse the text andidentify stylization goals and specific styles. Combined with a CLIP-basedsemantic visual embedding encoder, the model understands and matches text andimage content. We also introduce a novel localized text-image block matchingloss that ensures that style transfer is performed only on specified targetobjects, while non-target regions remain in their original style. Experimentalresults demonstrate that our model is able to accurately perform style transferon target objects according to textual descriptions without affecting the styleof background regions. Our code will be available athttps://github.com/yisuanwang/Soulstyler.</description><author>Junhao Chen, Peng Rong, Jingbo Sun, Chao Li, Xiang Li, Hongwu Lv</author><pubDate>Wed, 22 Nov 2023 18:15:43 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.13562v1</guid></item><item><title>Transfer Learning-based Real-time Handgun Detection</title><link>http://arxiv.org/abs/2311.13559v1</link><description>Traditional surveillance systems rely on human attention, limiting theireffectiveness. This study employs convolutional neural networks and transferlearning to develop a real-time computer vision system for automatic handgundetection. Comprehensive analysis of online handgun detection methods isconducted, emphasizing reducing false positives and learning time. Transferlearning is demonstrated as an effective approach. Despite technicalchallenges, the proposed system achieves a precision rate of 84.74%,demonstrating promising performance comparable to related works, enablingfaster learning and accurate automatic handgun detection for enhanced security.This research advances security measures by reducing human monitoringdependence, showcasing the potential of transfer learning-based approaches forefficient and reliable handgun detection.</description><author>Youssef Elmir, Sid Ahmed Laouar, Larbi Hamdaoui</author><pubDate>Wed, 22 Nov 2023 18:09:42 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.13559v1</guid></item><item><title>A Unified Framework for Trace-induced Quantum Kernels</title><link>http://arxiv.org/abs/2311.13552v1</link><description>Quantum kernel methods are promising candidates for achieving a practicalquantum advantage for certain machine learning tasks. Similar to classicalmachine learning, an exact form of a quantum kernel is expected to have a greatimpact on the model performance. In this work we combine all trace-inducedquantum kernels, including the commonly-used global fidelity and localprojected quantum kernels, into a common framework. We show how generalizedtrace-induced quantum kernels can be constructed as combinations of thefundamental building blocks we coin "Lego" kernels, which impose an inductivebias on the resulting quantum models. We relate the expressive power andgeneralization ability to the number of non-zero weight Lego kernels andpropose a systematic approach to increase the complexity of a quantum kernelmodel, leading to a new form of the local projected kernels that require fewerquantum resources in terms of the number of quantum gates and measurementshots. We show numerically that models based on local projected kernels canachieve comparable performance to the global fidelity quantum kernel. Our workunifies existing quantum kernels and provides a systematic framework to comparetheir properties.</description><author>Beng Yee Gan, Daniel Leykam, Supanut Thanasilp</author><pubDate>Wed, 22 Nov 2023 17:50:00 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.13552v1</guid></item><item><title>ADriver-I: A General World Model for Autonomous Driving</title><link>http://arxiv.org/abs/2311.13549v1</link><description>Typically, autonomous driving adopts a modular design, which divides the fullstack into perception, prediction, planning and control parts. Thoughinterpretable, such modular design tends to introduce a substantial amount ofredundancy. Recently, multimodal large language models (MLLM) and diffusiontechniques have demonstrated their superior performance on comprehension andgeneration ability. In this paper, we first introduce the concept ofinterleaved vision-action pair, which unifies the format of visual features andcontrol signals. Based on the vision-action pairs, we construct a general worldmodel based on MLLM and diffusion model for autonomous driving, termedADriver-I. It takes the vision-action pairs as inputs and autoregressivelypredicts the control signal of the current frame. The generated control signalstogether with the historical vision-action pairs are further conditioned topredict the future frames. With the predicted next frame, ADriver-I performsfurther control signal prediction. Such a process can be repeated infinitetimes, ADriver-I achieves autonomous driving in the world created by itself.Extensive experiments are conducted on nuScenes and our large-scale privatedatasets. ADriver-I shows impressive performance compared to severalconstructed baselines. We hope our ADriver-I can provide some new insights forfuture autonomous driving and embodied intelligence.</description><author>Fan Jia, Weixin Mao, Yingfei Liu, Yucheng Zhao, Yuqing Wen, Chi Zhang, Xiangyu Zhang, Tiancai Wang</author><pubDate>Wed, 22 Nov 2023 17:44:29 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.13549v1</guid></item><item><title>Efficient Numerical Integration in Reproducing Kernel Hilbert Spaces via Leverage Scores Sampling</title><link>http://arxiv.org/abs/2311.13548v1</link><description>In this work we consider the problem of numerical integration, i.e.,approximating integrals with respect to a target probability measure using onlypointwise evaluations of the integrand. We focus on the setting in which thetarget distribution is only accessible through a set of $n$ i.i.d.observations, and the integrand belongs to a reproducing kernel Hilbert space.We propose an efficient procedure which exploits a small i.i.d. random subsetof $m&lt;n$ samples drawn either uniformly or using approximate leverage scoresfrom the initial observations. Our main result is an upper bound on theapproximation error of this procedure for both sampling strategies. It yieldssufficient conditions on the subsample size to recover the standard (optimal)$n^{-1/2}$ rate while reducing drastically the number of functions evaluations,and thus the overall computational cost. Moreover, we obtain rates with respectto the number $m$ of evaluations of the integrand which adapt to itssmoothness, and match known optimal rates for instance for Sobolev spaces. Weillustrate our theoretical findings with numerical experiments on realdatasets, which highlight the attractive efficiency-accuracy tradeoff of ourmethod compared to existing randomized and greedy quadrature methods. We notethat, the problem of numerical integration in RKHS amounts to designing adiscrete approximation of the kernel mean embedding of the target distribution.As a consequence, direct applications of our results also include the efficientcomputation of maximum mean discrepancies between distributions and the designof efficient kernel-based tests.</description><author>Antoine Chatalic, Nicolas Schreuder, Ernesto De Vito, Lorenzo Rosasco</author><pubDate>Wed, 22 Nov 2023 17:44:18 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.13548v1</guid></item><item><title>Medical Image Retrieval Using Pretrained Embeddings</title><link>http://arxiv.org/abs/2311.13547v1</link><description>A wide range of imaging techniques and data formats available for medicalimages make accurate retrieval from image databases challenging. Efficient retrieval systems are crucial in advancing medical research,enabling large-scale studies and innovative diagnostic tools. Thus, addressingthe challenges of medical image retrieval is essential for the continuedenhancement of healthcare and research. In this study, we evaluated the feasibility of employing fourstate-of-the-art pretrained models for medical image retrieval at modality,body region, and organ levels and compared the results of two similarityindexing approaches. Since the employed networks take 2D images, we analyzedthe impacts of weighting and sampling strategies to incorporate 3D informationduring retrieval of 3D volumes. We showed that medical image retrieval isfeasible using pretrained networks without any additional training orfine-tuning steps. Using pretrained embeddings, we achieved a recall of 1 forvarious tasks at modality, body region, and organ level.</description><author>Farnaz Khun Jush, Tuan Truong, Steffen Vogler, Matthias Lenga</author><pubDate>Wed, 22 Nov 2023 17:42:33 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.13547v1</guid></item><item><title>Enigma: Privacy-Preserving Execution of QAOA on Untrusted Quantum Computers</title><link>http://arxiv.org/abs/2311.13546v1</link><description>Quantum computers can solve problems that are beyond the capabilities ofconventional computers. As quantum computers are expensive and hard tomaintain, the typical model for performing quantum computation is to send thecircuit to a quantum cloud provider. This leads to privacy concerns forcommercial entities as an untrusted server can learn protected information fromthe provided circuit. Current proposals for Secure Quantum Computing (SQC)either rely on emerging technologies (such as quantum networks) or incurprohibitive overheads (for Quantum Homomorphic Encryption). The goal of ourpaper is to enable low-cost privacy-preserving quantum computation that can beused with current systems. We propose Enigma, a suite of privacy-preserving schemes specificallydesigned for the Quantum Approximate Optimization Algorithm (QAOA). Unlikeprevious SQC techniques that obfuscate quantum circuits, Enigma transforms theinput problem of QAOA, such that the resulting circuit and the outcomes areunintelligible to the server. We introduce three variants of Enigma. Enigma-Iprotects the coefficients of QAOA using random phase flipping and fudging ofvalues. Enigma-II protects the nodes of the graph by introducing decoy qubits,which are indistinguishable from primary ones. Enigma-III protects the edgeinformation of the graph by modifying the graph such that each node has anidentical number of connections. For all variants of Enigma, we demonstratethat we can still obtain the solution for the original problem. We evaluateEnigma using IBM quantum devices and show that the privacy improvements ofEnigma come at only a small reduction in fidelity (1%-13%).</description><author>Ramin Ayanzadeh, Ahmad Mousavi, Narges Alavisamani, Moinuddin Qureshi</author><pubDate>Wed, 22 Nov 2023 17:40:23 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.13546v1</guid></item><item><title>Linear Log-Normal Attention with Unbiased Concentration</title><link>http://arxiv.org/abs/2311.13541v1</link><description>Transformer models have achieved remarkable results in a wide range ofapplications. However, their scalability is hampered by the quadratic time andmemory complexity of the self-attention mechanism concerning the sequencelength. This limitation poses a substantial obstacle when dealing with longdocuments or high-resolution images. In this work, we study the self-attentionmechanism by analyzing the distribution of the attention matrix and itsconcentration ability. Furthermore, we propose instruments to measure thesequantities and introduce a novel self-attention mechanism, Linear Log-NormalAttention, designed to emulate the distribution and concentration behavior ofthe original self-attention. Our experimental results on popular naturallanguage benchmarks reveal that our proposed Linear Log-Normal Attentionoutperforms other linearized attention alternatives, offering a promisingavenue for enhancing the scalability of transformer models. Our code isavailable in supplementary materials.</description><author>Yury Nahshan, Joseph Kampeas, Emir Haleva</author><pubDate>Wed, 22 Nov 2023 17:30:41 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.13541v1</guid></item><item><title>Learned Nonlinear Predictor for Critically Sampled 3D Point Cloud Attribute Compression</title><link>http://arxiv.org/abs/2311.13539v1</link><description>We study 3D point cloud attribute compression via a volumetric approach:assuming point cloud geometry is known at both encoder and decoder, parameters$\theta$ of a continuous attribute function $f: \mathbb{R}^3 \mapsto\mathbb{R}$ are quantized to $\hat{\theta}$ and encoded, so that discretesamples $f_{\hat{\theta}}(\mathbf{x}_i)$ can be recovered at known 3D points$\mathbf{x}_i \in \mathbb{R}^3$ at the decoder. Specifically, we consider anested sequences of function subspaces $\mathcal{F}^{(p)}_{l_0} \subseteq\cdots \subseteq \mathcal{F}^{(p)}_L$, where $\mathcal{F}_l^{(p)}$ is a familyof functions spanned by B-spline basis functions of order $p$, $f_l^*$ is theprojection of $f$ on $\mathcal{F}_l^{(p)}$ and encoded as low-pass coefficients$F_l^*$, and $g_l^*$ is the residual function in orthogonal subspace$\mathcal{G}_l^{(p)}$ (where $\mathcal{G}_l^{(p)} \oplus \mathcal{F}_l^{(p)} =\mathcal{F}_{l+1}^{(p)}$) and encoded as high-pass coefficients $G_l^*$. Inthis paper, to improve coding performance over [1], we study predicting$f_{l+1}^*$ at level $l+1$ given $f_l^*$ at level $l$ and encoding of $G_l^*$for the $p=1$ case (RAHT($1$)). For the prediction, we formalize RAHT(1) linearprediction in MPEG-PCC in a theoretical framework, and propose a new nonlinearpredictor using a polynomial of bilateral filter. We derive equations toefficiently compute the critically sampled high-pass coefficients $G_l^*$amenable to encoding. We optimize parameters in our resulting feed-forwardnetwork on a large training set of point clouds by minimizing a rate-distortionLagrangian. Experimental results show that our improved framework outperformedthe MPEG G-PCC predictor by $11$ to $12\%$ in bit rate reduction.</description><author>Tam Thuc Do, Philip A. Chou, Gene Cheung</author><pubDate>Wed, 22 Nov 2023 17:26:54 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.13539v1</guid></item><item><title>Edge2Node: Reducing Edge Prediction to Node Classification</title><link>http://arxiv.org/abs/2311.02921v3</link><description>Despite the success of graph neural network models in node classification,edge prediction (the task of predicting missing or potential links betweennodes in a graph) remains a challenging problem for these models. A commonapproach for edge prediction is to first obtain the embeddings of two nodes,and then a predefined scoring function is used to predict the existence of anedge between the two nodes. Here, we introduce a preliminary idea calledEdge2Node which suggests to directly obtain an embedding for each edge, withoutthe need for a scoring function. This idea wants to create a new graph H basedon the graph G given for the edge prediction task, and then suggests reducingthe edge prediction task on G to a node classification task on H. We anticipatethat this introductory method could stimulate further investigations for edgeprediction task.</description><author>Zahed Rahmati</author><pubDate>Wed, 22 Nov 2023 17:26:08 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.02921v3</guid></item><item><title>Speak Like a Native: Prompting Large Language Models in a Native Style</title><link>http://arxiv.org/abs/2311.13538v1</link><description>Existing work has found that the prompt engineering heavily influences theperformance of large language models (LLMs). Chain-of-thought (CoT), as apopular prompt engineering technique, prompted LLMs using in-context exampleswith reasoning steps. In current studies, the few-shot examples of CoT aregenerally handcrafted by humans. However, how the text style of in-contextexamples influence the outputs of LLMs still remains under-explored. This paperpresents a novel and effective approach, named \textbf{AlignCoT}, to improvethe reasoning capability of LLMs by aligning the in-context examples with thenative style of LLMs. ``Native'' refers to the inherent characteristic style ofLLMs which can be probed by original zero-shot scenarios. AlignCoT isorthogonal to other prompt engineering methods, making it easy to combine withstate-of-the-art techniques to further improve the LLMs' performance. Weconduct extensive and comprehensive experiments on several benchmarks. Theempirical results demonstrate that our AlignCoTsignificantly improvesperformance over the carefully handcrafted in-context examples. For instance,with GPT-3.5-turbo, we observed a +2.5\% improvement on GSM8K. Furthermore, ourAlignCoT consistently improve the performance when combined with otherstate-of-the-art prompt engineering methods. The source code and dataset willbe available at\href{https://github.com/yangzhch6/AlignCoT}{https://github.com/yangzhch6/AlignCoT}.</description><author>Zhicheng Yang, Yiwei Wang, Yinya Huang, Jing Xiong, Xiaodan Liang, Jing Tang</author><pubDate>Wed, 22 Nov 2023 17:24:21 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.13538v1</guid></item><item><title>DiffusionMat: Alpha Matting as Sequential Refinement Learning</title><link>http://arxiv.org/abs/2311.13535v1</link><description>In this paper, we introduce DiffusionMat, a novel image matting frameworkthat employs a diffusion model for the transition from coarse to refined alphamattes. Diverging from conventional methods that utilize trimaps merely asloose guidance for alpha matte prediction, our approach treats image matting asa sequential refinement learning process. This process begins with the additionof noise to trimaps and iteratively denoises them using a pre-trained diffusionmodel, which incrementally guides the prediction towards a clean alpha matte.The key innovation of our framework is a correction module that adjusts theoutput at each denoising step, ensuring that the final result is consistentwith the input image's structures. We also introduce the Alpha ReliabilityPropagation, a novel technique designed to maximize the utility of availableguidance by selectively enhancing the trimap regions with confident alphainformation, thus simplifying the correction task. To train the correctionmodule, we devise specialized loss functions that target the accuracy of thealpha matte's edges and the consistency of its opaque and transparent regions.We evaluate our model across several image matting benchmarks, and the resultsindicate that DiffusionMat consistently outperforms existing methods. Projectpage at~\url{https://cnnlstm.github.io/DiffusionMat</description><author>Yangyang Xu, Shengfeng He, Wenqi Shao, Kwan-Yee K. Wong, Yu Qiao, Ping Luo</author><pubDate>Wed, 22 Nov 2023 17:16:44 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.13535v1</guid></item><item><title>LM-Cocktail: Resilient Tuning of Language Models via Model Merging</title><link>http://arxiv.org/abs/2311.13534v1</link><description>The pre-trained language models are continually fine-tuned to better supportdownstream applications. However, this operation may result in significantperformance degeneration on general tasks beyond the targeted domain. Toovercome this problem, we propose a novel method which enables the fine-tunedmodel to stay resilient in general perspectives. Our method is conducted in theform of model merging (namely LM-Cocktail), where the fine-tuned language modelis merged with the pre-trained base model or the peer models from other domainsthrough weighted average. Despite simplicity, LM-Cocktail is surprisinglyeffective: the resulted model is able to achieve a strong empirical performancein the whole scope of general tasks while preserving a superior capacity in itstargeted domain. We conduct comprehensive experiments with LLama and BGE modelon popular benchmarks, including FLAN, MMLU, MTEB, whose results validate theefficacy of our proposed method. The code and checkpoints are available athttps://github.com/FlagOpen/FlagEmbedding.</description><author>Shitao Xiao, Zheng Liu, Peitian Zhang, Xingrun Xing</author><pubDate>Wed, 22 Nov 2023 17:14:54 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.13534v1</guid></item><item><title>Leveraging CNNs and Ensemble Learning for Automated Disaster Image Classification</title><link>http://arxiv.org/abs/2311.13531v1</link><description>Natural disasters act as a serious threat globally, requiring effective andefficient disaster management and recovery. This paper focuses on classifyingnatural disaster images using Convolutional Neural Networks (CNNs). MultipleCNN architectures were built and trained on a dataset containing images ofearthquakes, floods, wildfires, and volcanoes. A stacked CNN ensemble approachproved to be the most effective, achieving 95% accuracy and an F1 score goingup to 0.96 for individual classes. Tuning hyperparameters of individual modelsfor optimization was critical to maximize the models' performance. The stackingof CNNs with XGBoost acting as the meta-model utilizes the strengths of the CNNand ResNet models to improve the overall accuracy of the classification.Results obtained from the models illustrated the potency of CNN-based modelsfor automated disaster image classification. This lays the foundation forexpanding these techniques to build robust systems for disaster response,damage assessment, and recovery management.</description><author>Archit Rathod, Veer Pariawala, Mokshit Surana, Kumkum Saxena</author><pubDate>Wed, 22 Nov 2023 17:06:57 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.13531v1</guid></item><item><title>A Good Feature Extractor Is All You Need for Weakly Supervised Learning in Histopathology</title><link>http://arxiv.org/abs/2311.11772v2</link><description>Deep learning is revolutionising pathology, offering novel opportunities indisease prognosis and personalised treatment. Historically, stain normalisationhas been a crucial preprocessing step in computational pathology pipelines, andpersists into the deep learning era. Yet, with the emergence of featureextractors trained using self-supervised learning (SSL) on diverse pathologydatasets, we call this practice into question. In an empirical evaluation ofpublicly available feature extractors, we find that omitting stainnormalisation and image augmentations does not compromise downstreamperformance, while incurring substantial savings in memory and compute.Further, we show that the top-performing feature extractors are remarkablyrobust to variations in stain and augmentations like rotation in their latentspace. Contrary to previous patch-level benchmarking studies, our approachemphasises clinical relevance by focusing on slide-level prediction tasks in aweakly supervised setting with external validation cohorts. This workrepresents the most comprehensive robustness evaluation of public pathology SSLfeature extractors to date, involving more than 6,000 training runs across ninetasks, five datasets, three downstream architectures, and various preprocessingsetups. Our findings stand to streamline digital pathology workflows byminimising preprocessing needs and informing the selection of featureextractors.</description><author>Georg WÃ¶lflein, Dyke Ferber, Asier Rabasco Meneghetti, Omar S. M. El Nahhas, Daniel Truhn, Zunamys I. Carrero, David J. Harrison, Ognjen ArandjeloviÄ, Jakob N. Kather</author><pubDate>Wed, 22 Nov 2023 17:06:31 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.11772v2</guid></item><item><title>GraphCFC: A Directed Graph Based Cross-Modal Feature Complementation Approach for Multimodal Conversational Emotion Recognition</title><link>http://arxiv.org/abs/2207.12261v4</link><description>Emotion Recognition in Conversation (ERC) plays a significant part inHuman-Computer Interaction (HCI) systems since it can provide empatheticservices. Multimodal ERC can mitigate the drawbacks of uni-modal approaches.Recently, Graph Neural Networks (GNNs) have been widely used in a variety offields due to their superior performance in relation modeling. In multimodalERC, GNNs are capable of extracting both long-distance contextual informationand inter-modal interactive information. Unfortunately, since existing methodssuch as MMGCN directly fuse multiple modalities, redundant information may begenerated and diverse information may be lost. In this work, we present adirected Graph based Cross-modal Feature Complementation (GraphCFC) module thatcan efficiently model contextual and interactive information. GraphCFCalleviates the problem of heterogeneity gap in multimodal fusion by utilizingmultiple subspace extractors and Pair-wise Cross-modal Complementary (PairCC)strategy. We extract various types of edges from the constructed graph forencoding, thus enabling GNNs to extract crucial contextual and interactiveinformation more accurately when performing message passing. Furthermore, wedesign a GNN structure called GAT-MLP, which can provide a new unified networkframework for multimodal learning. The experimental results on two benchmarkdatasets show that our GraphCFC outperforms the state-of-the-art (SOTA)approaches.</description><author>Jiang Li, Xiaoping Wang, Guoqing Lv, Zhigang Zeng</author><pubDate>Wed, 22 Nov 2023 16:59:55 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2207.12261v4</guid></item><item><title>LucidDreamer: Towards High-Fidelity Text-to-3D Generation via Interval Score Matching</title><link>http://arxiv.org/abs/2311.11284v2</link><description>The recent advancements in text-to-3D generation mark a significant milestonein generative models, unlocking new possibilities for creating imaginative 3Dassets across various real-world scenarios. While recent advancements intext-to-3D generation have shown promise, they often fall short in renderingdetailed and high-quality 3D models. This problem is especially prevalent asmany methods base themselves on Score Distillation Sampling (SDS). This paperidentifies a notable deficiency in SDS, that it brings inconsistent andlow-quality updating direction for the 3D model, causing the over-smoothingeffect. To address this, we propose a novel approach called Interval ScoreMatching (ISM). ISM employs deterministic diffusing trajectories and utilizesinterval-based score matching to counteract over-smoothing. Furthermore, weincorporate 3D Gaussian Splatting into our text-to-3D generation pipeline.Extensive experiments show that our model largely outperforms thestate-of-the-art in quality and training efficiency.</description><author>Yixun Liang, Xin Yang, Jiantao Lin, Haodong Li, Xiaogang Xu, Yingcong Chen</author><pubDate>Wed, 22 Nov 2023 16:54:17 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.11284v2</guid></item><item><title>Audio classification with Dilated Convolution with Learnable Spacings</title><link>http://arxiv.org/abs/2309.13972v2</link><description>Dilated convolution with learnable spacings (DCLS) is a recent convolutionmethod in which the positions of the kernel elements are learned throughouttraining by backpropagation. Its interest has recently been demonstrated incomputer vision (ImageNet classification and downstream tasks). Here we showthat DCLS is also useful for audio tagging using the AudioSet classificationbenchmark. We took two state-of-the-art convolutional architectures usingdepthwise separable convolutions (DSC), ConvNeXt and ConvFormer, and a hybridone using attention in addition, FastViT, and drop-in replaced all the DSClayers by DCLS ones. This significantly improved the mean average precision(mAP) with the three architectures without increasing the number of parametersand with only a low cost on the throughput. The method code is based on PyTorchand is available at https://github.com/K-H-Ismail/DCLS-Audio</description><author>Ismail Khalfaoui-Hassani, TimothÃ©e Masquelier, Thomas Pellegrini</author><pubDate>Wed, 22 Nov 2023 16:49:20 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2309.13972v2</guid></item><item><title>Tensor Train for Global Optimization Problems in Robotics</title><link>http://arxiv.org/abs/2206.05077v5</link><description>The convergence of many numerical optimization techniques is highly dependenton the initial guess given to the solver. To address this issue, we propose anovel approach that utilizes tensor methods to initialize existing optimizationsolvers near global optima. Our method does not require access to a database ofgood solutions. We first transform the cost function, which depends on bothtask parameters and optimization variables, into a probability densityfunction. Unlike existing approaches, the joint probability distribution of thetask parameters and optimization variables is approximated using the TensorTrain model, which enables efficient conditioning and sampling. We treat thetask parameters as random variables, and for a given task, we generate samplesfor decision variables from the conditional distribution to initialize theoptimization solver. Our method can produce multiple solutions (when theyexist) faster than existing methods. We first evaluate the approach onbenchmark functions for numerical optimization that are hard to solve usinggradient-based optimization solvers with a naive initialization. The resultsshow that the proposed method can generate samples close to global optima andfrom multiple modes. We then demonstrate the generality and relevance of ourframework to robotics by applying it to inverse kinematics with obstacles andmotion planning problems with a 7-DoF manipulator.</description><author>Suhan Shetty, Teguh Lembono, Tobias Loew, Sylvain Calinon</author><pubDate>Wed, 22 Nov 2023 16:45:11 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2206.05077v5</guid></item><item><title>Hybrid Whale-Mud-Ring Optimization for Precise Color Skin Cancer Image Segmentation</title><link>http://arxiv.org/abs/2311.13512v1</link><description>Timely identification and treatment of rapidly progressing skin cancers cansignificantly contribute to the preservation of patients' health andwell-being. Dermoscopy, a dependable and accessible tool, plays a pivotal rolein the initial stages of skin cancer detection. Consequently, the effectiveprocessing of digital dermoscopy images holds significant importance inelevating the accuracy of skin cancer diagnoses. Multilevel thresholding is akey tool in medical imaging that extracts objects within the image tofacilitate its analysis. In this paper, an enhanced version of the Mud RingAlgorithm hybridized with the Whale Optimization Algorithm, named WMRA, isproposed. The proposed approach utilizes bubble-net attack and mud ringstrategy to overcome stagnation in local optima and obtain optimal thresholds.The experimental results show that WMRA is powerful against a cluster of recentmethods in terms of fitness, Peak Signal to Noise Ratio (PSNR), and Mean SquareError (MSE).</description><author>Amir Hamza, Badis Lekouaghet, Yassine Himeur</author><pubDate>Wed, 22 Nov 2023 16:35:43 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.13512v1</guid></item><item><title>Naturalness of Attention: Revisiting Attention in Code Language Models</title><link>http://arxiv.org/abs/2311.13508v1</link><description>Language models for code such as CodeBERT offer the capability to learnadvanced source code representation, but their opacity poses barriers tounderstanding of captured properties. Recent attention analysis studies provideinitial interpretability insights by focusing solely on attention weightsrather than considering the wider context modeling of Transformers. This studyaims to shed some light on the previously ignored factors of the attentionmechanism beyond the attention weights. We conduct an initial empirical studyanalyzing both attention distributions and transformed representations inCodeBERT. Across two programming languages, Java and Python, we find that thescaled transformation norms of the input better capture syntactic structurecompared to attention weights alone. Our analysis reveals characterization ofhow CodeBERT embeds syntactic code properties. The findings demonstrate theimportance of incorporating factors beyond just attention weights forrigorously understanding neural code models. This lays the groundwork fordeveloping more interpretable models and effective uses of attention mechanismsin program analysis.</description><author>Mootez Saad, Tushar Sharma</author><pubDate>Wed, 22 Nov 2023 16:34:12 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.13508v1</guid></item><item><title>Applying Dimensionality Reduction as Precursor to LSTM-CNN Models for Classifying Imagery and Motor Signals in ECoG-Based BCIs</title><link>http://arxiv.org/abs/2311.13507v1</link><description>Motor impairments, frequently caused by neurological incidents like strokesor traumatic brain injuries, present substantial obstacles in rehabilitationtherapy. This research aims to elevate the field by optimizing motor imageryclassification algorithms within Brain-Computer Interfaces (BCIs). By improvingthe efficiency of BCIs, we offer a novel approach that holds significantpromise for enhancing motor rehabilitation outcomes. Utilizing unsupervisedtechniques for dimensionality reduction, namely Uniform Manifold Approximationand Projection (UMAP) coupled with K-Nearest Neighbors (KNN), we evaluate thenecessity of employing supervised methods such as Long Short-Term Memory (LSTM)and Convolutional Neural Networks (CNNs) for classification tasks. Importantly,participants who exhibited high KNN scores following UMAP dimensionalityreduction also achieved high accuracy in supervised deep learning (DL) models.Due to individualized model requirements and massive neural training data,dimensionality reduction becomes an effective preprocessing step that minimizesthe need for extensive data labeling and supervised deep learning techniques.This approach has significant implications not only for targeted therapies inmotor dysfunction but also for addressing regulatory, safety, and reliabilityconcerns in the rapidly evolving BCI field.</description><author>Soham Bafana</author><pubDate>Wed, 22 Nov 2023 16:34:06 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.13507v1</guid></item><item><title>Bitformer: An efficient Transformer with bitwise operation-based attention for Big Data Analytics at low-cost low-precision devices</title><link>http://arxiv.org/abs/2311.13502v1</link><description>In the current landscape of large models, the Transformer stands as acornerstone, playing a pivotal role in shaping the trajectory of modern models.However, its application encounters challenges attributed to the substantialcomputational intricacies intrinsic to its attention mechanism. Moreover, itsreliance on high-precision floating-point operations presents specific hurdles,particularly evident in computation-intensive scenarios such as edge computingenvironments. These environments, characterized by resource-constrained devicesand a preference for lower precision, necessitate innovative solutions. To tackle the exacting data processing demands posed by edge devices, weintroduce the Bitformer model, an inventive extension of the Transformerparadigm. Central to this innovation is a novel attention mechanism thatadeptly replaces conventional floating-point matrix multiplication with bitwiseoperations. This strategic substitution yields dual advantages. Not only doesit maintain the attention mechanism's prowess in capturing intricate long-rangeinformation dependencies, but it also orchestrates a profound reduction in thecomputational complexity inherent in the attention operation. The transitionfrom an $O(n^2d)$ complexity, typical of floating-point operations, to an$O(n^2T)$ complexity characterizing bitwise operations, substantiates thisadvantage. Notably, in this context, the parameter $T$ remains markedly smallerthan the conventional dimensionality parameter $d$. The Bitformer model in essence endeavors to reconcile the indomitablerequirements of modern computing landscapes with the constraints posed by edgecomputing scenarios. By forging this innovative path, we bridge the gap betweenhigh-performing models and resource-scarce environments, thus unveiling apromising trajectory for further advancements in the field.</description><author>Gaoxiang Duan, Junkai Zhang, Xiaoying Zheng, Yongxin Zhu</author><pubDate>Wed, 22 Nov 2023 16:20:24 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.13502v1</guid></item><item><title>Adversarial Backdoor Attack by Naturalistic Data Poisoning on Trajectory Prediction in Autonomous Driving</title><link>http://arxiv.org/abs/2306.15755v2</link><description>In autonomous driving, behavior prediction is fundamental for safe motionplanning, hence the security and robustness of prediction models againstadversarial attacks are of paramount importance. We propose a novel adversarialbackdoor attack against trajectory prediction models as a means of studyingtheir potential vulnerabilities. Our attack affects the victim at training timevia naturalistic, hence stealthy, poisoned samples crafted using a noveltwo-step approach. First, the triggers are crafted by perturbing the trajectoryof attacking vehicle and then disguised by transforming the scene using abi-level optimization technique. The proposed attack does not depend on aparticular model architecture and operates in a black-box manner, thus can beeffective without any knowledge of the victim model. We conduct extensiveempirical studies using state-of-the-art prediction models on two benchmarkdatasets using metrics customized for trajectory prediction. We show that theproposed attack is highly effective, as it can significantly hinder theperformance of prediction models, unnoticeable by the victims, and efficient asit forces the victim to generate malicious behavior even under constrainedconditions. Via ablative studies, we analyze the impact of different attackdesign choices followed by an evaluation of existing defence mechanisms againstthe proposed attack.</description><author>Mozhgan Pourkeshavarz, Mohammad Sabokrou, Amir Rasouli</author><pubDate>Wed, 22 Nov 2023 16:16:43 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.15755v2</guid></item><item><title>Current Topological and Machine Learning Applications for Bias Detection in Text</title><link>http://arxiv.org/abs/2311.13495v1</link><description>Institutional bias can impact patient outcomes, educational attainment, andlegal system navigation. Written records often reflect bias, and once bias isidentified; it is possible to refer individuals for training to reduce bias.Many machine learning tools exist to explore text data and create predictivemodels that can search written records to identify real-time bias. However, fewprevious studies investigate large language model embeddings and geometricmodels of biased text data to understand geometry's impact on bias modelingaccuracy. To overcome this issue, this study utilizes the RedditBias databaseto analyze textual biases. Four transformer models, including BERT and RoBERTavariants, were explored. Post-embedding, t-SNE allowed two-dimensionalvisualization of data. KNN classifiers differentiated bias types, with lowerk-values proving more effective. Findings suggest BERT, particularly mini BERT,excels in bias classification, while multilingual models lag. Therecommendation emphasizes refining monolingual models and exploringdomain-specific biases.</description><author>Colleen Farrelly, Yashbir Singh, Quincy A. Hathaway, Gunnar Carlsson, Ashok Choudhary, Rahul Paul, Gianfranco Doretto, Yassine Himeur, Shadi Atalls, Wathiq Mansoor</author><pubDate>Wed, 22 Nov 2023 16:12:42 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.13495v1</guid></item><item><title>Integrating Pre-trained Language Model into Neural Machine Translation</title><link>http://arxiv.org/abs/2310.19680v3</link><description>Neural Machine Translation (NMT) has become a significant technology innatural language processing through extensive research and development.However, the deficiency of high-quality bilingual language pair data stillposes a major challenge to improving NMT performance. Recent studies have beenexploring the use of contextual information from pre-trained language model(PLM) to address this problem. Yet, the issue of incompatibility between PLMand NMT model remains unresolved. This study proposes PLM-integrated NMT(PiNMT) model to overcome the identified problems. PiNMT model consists ofthree critical components, PLM Multi Layer Converter, Embedding Fusion, andCosine Alignment, each playing a vital role in providing effective PLMinformation to NMT. Furthermore, two training strategies, Separate LearningRates and Dual Step Training, are also introduced in this paper. Byimplementing the proposed PiNMT model and training strategy, we achievestate-of-the-art performance on the IWSLT'14 En$\leftrightarrow$De dataset.This study's outcomes are noteworthy as they demonstrate a novel approach forefficiently integrating PLM with NMT to overcome incompatibility and enhanceperformance.</description><author>Soon-Jae Hwang, Chang-Sung Jeong</author><pubDate>Wed, 22 Nov 2023 16:12:39 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.19680v3</guid></item><item><title>Grad-Shafranov equilibria via data-free physics informed neural networks</title><link>http://arxiv.org/abs/2311.13491v1</link><description>A large number of magnetohydrodynamic (MHD) equilibrium calculations areoften required for uncertainty quantification, optimization, and real-timediagnostic information, making MHD equilibrium codes vital to the field ofplasma physics. In this paper, we explore a method for solving theGrad-Shafranov equation by using Physics-Informed Neural Networks (PINNs). ForPINNs, we optimize neural networks by directly minimizing the residual of thePDE as a loss function. We show that PINNs can accurately and effectively solvethe Grad-Shafranov equation with several different boundary conditions. We alsoexplore the parameter space by varying the size of the model, the learningrate, and boundary conditions to map various trade-offs such as betweenreconstruction error and computational speed. Additionally, we introduce aparameterized PINN framework, expanding the input space to include variablessuch as pressure, aspect ratio, elongation, and triangularity in order tohandle a broader range of plasma scenarios within a single network.Parametrized PINNs could be used in future work to solve inverse problems suchas shape optimization.</description><author>Byoungchan Jang, Alan A. Kaptanoglu, Rahul Gaur, Shaw Pan, Matt Landreman, William Dorland</author><pubDate>Wed, 22 Nov 2023 16:08:38 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.13491v1</guid></item><item><title>Benchmarking Toxic Molecule Classification using Graph Neural Networks and Few Shot Learning</title><link>http://arxiv.org/abs/2311.13490v1</link><description>Traditional methods like Graph Convolutional Networks (GCNs) face challengeswith limited data and class imbalance, leading to suboptimal performance ingraph classification tasks during toxicity prediction of molecules as a whole.To address these issues, we harness the power of Graph Isomorphic Networks,Multi Headed Attention and Free Large-scale Adversarial Augmentation separatelyon Graphs for precisely capturing the structural data of molecules and theirtoxicological properties. Additionally, we incorporate Few-Shot Learning toimprove the model's generalization with limited annotated samples. Extensiveexperiments on a diverse toxicology dataset demonstrate that our methodachieves an impressive state-of-art AUC-ROC value of 0.816, surpassing thebaseline GCN model by 11.4%. This highlights the significance of our proposedmethodology and Few Shot Learning in advancing Toxic Molecular Classification,with the potential to enhance drug discovery and environmental risk assessmentprocesses.</description><author>Bhavya Mehta, Kush Kothari, Reshmika Nambiar, Seema Shrawne</author><pubDate>Wed, 22 Nov 2023 16:07:32 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.13490v1</guid></item><item><title>Deep-learning-based acceleration of MRI for radiotherapy planning of pediatric patients with brain tumors</title><link>http://arxiv.org/abs/2311.13485v1</link><description>Magnetic Resonance Imaging (MRI) is a non-invasive diagnostic andradiotherapy (RT) planning tool, offering detailed insights into the anatomy ofthe human body. The extensive scan time is stressful for patients, who mustremain motionless in a prolonged imaging procedure that prioritizes reductionof imaging artifacts. This is challenging for pediatric patients who mayrequire measures for managing voluntary motions such as anesthesia. Severalcomputational approaches reduce scan time (fast MRI), by recording fewermeasurements and digitally recovering full information via post-acquisitionreconstruction. However, most fast MRI approaches were developed for diagnosticimaging, without addressing reconstruction challenges specific to RT planning.In this work, we developed a deep learning-based method (DeepMRIRec) for MRIreconstruction from undersampled data acquired with RT-specific receiver coilarrangements. We evaluated our method against fully sampled data of T1-weightedMR images acquired from 73 children with brain tumors/surgical beds using loopand posterior coils (12 channels), with and without applying virtualcompression of coil elements. DeepMRIRec reduced scanning time by a factor offour producing a structural similarity score surpassing the evaluatedstate-of-the-art method (0.960 vs 0.896), thereby demonstrating its potentialfor accelerating MRI scanning for RT planning.</description><author>Shahinur Alam, Jinsoo Uh, Alexander Dresner, Chia-ho Hua, Khaled Khairy</author><pubDate>Wed, 22 Nov 2023 16:01:44 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.13485v1</guid></item><item><title>Pelvic floor MRI segmentation based on semi-supervised deep learning</title><link>http://arxiv.org/abs/2311.03105v2</link><description>The semantic segmentation of pelvic organs via MRI has important clinicalsignificance. Recently, deep learning-enabled semantic segmentation hasfacilitated the three-dimensional geometric reconstruction of pelvic floororgans, providing clinicians with accurate and intuitive diagnostic results.However, the task of labeling pelvic floor MRI segmentation, typicallyperformed by clinicians, is labor-intensive and costly, leading to a scarcityof labels. Insufficient segmentation labels limit the precise segmentation andreconstruction of pelvic floor organs. To address these issues, we propose asemi-supervised framework for pelvic organ segmentation. The implementation ofthis framework comprises two stages. In the first stage, it performsself-supervised pre-training using image restoration tasks. Subsequently,fine-tuning of the self-supervised model is performed, using labeled data totrain the segmentation model. In the second stage, the self-supervisedsegmentation model is used to generate pseudo labels for unlabeled data.Ultimately, both labeled and unlabeled data are utilized in semi-supervisedtraining. Upon evaluation, our method significantly enhances the performance inthe semantic segmentation and geometric reconstruction of pelvic organs, Dicecoefficient can increase by 2.65% averagely. Especially for organs that aredifficult to segment, such as the uterus, the accuracy of semantic segmentationcan be improved by up to 3.70%.</description><author>Jianwei Zuo, Fei Feng, Zhuhui Wang, James A. Ashton-Miller, John O. L. Delancey, Jiajia Luo</author><pubDate>Wed, 22 Nov 2023 15:46:00 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.03105v2</guid></item><item><title>A Dual-Stream Recurrence-Attention Network With Global-Local Awareness for Emotion Recognition in Textual Dialog</title><link>http://arxiv.org/abs/2307.00449v2</link><description>In real-world dialog systems, the ability to understand the user's emotionsand interact anthropomorphically is of great significance. Emotion Recognitionin Conversation (ERC) is one of the key ways to accomplish this goal and hasattracted growing attention. How to model the context in a conversation is acentral aspect and a major challenge of ERC tasks. Most existing approachesstruggle to adequately incorporate both global and local contextualinformation, and their network structures are overly sophisticated. For thisreason, we propose a simple and effective Dual-stream Recurrence-AttentionNetwork (DualRAN), which is based on Recurrent Neural Network (RNN) andMulti-head ATtention network (MAT). DualRAN eschews the complex components ofcurrent methods and focuses on combining recurrence-based methods withattention-based ones. DualRAN is a dual-stream structure mainly consisting oflocal- and global-aware modules, modeling a conversation simultaneously fromdistinct perspectives. In addition, we develop two single-stream networkvariants for DualRAN, i.e., SingleRANv1 and SingleRANv2. According to theexperimental findings, DualRAN boosts the weighted F1 scores by 1.43% and 0.64%on the IEMOCAP and MELD datasets, respectively, in comparison to the strongestbaseline. On two other datasets (i.e., EmoryNLP and DailyDialog), our methodalso attains competitive results.</description><author>Jiang Li, Xiaoping Wang, Zhigang Zeng</author><pubDate>Wed, 22 Nov 2023 15:43:23 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.00449v2</guid></item><item><title>Machine Translation to Control Formality Features in the Target Language</title><link>http://arxiv.org/abs/2311.13475v1</link><description>Formality plays a significant role in language communication, especially inlow-resource languages such as Hindi, Japanese and Korean. These languagesutilise formal and informal expressions to convey messages based on socialcontexts and relationships. When a language translation technique is used totranslate from a source language that does not pertain the formality (e.g.English) to a target language that does, there is a missing information onformality that could be a challenge in producing an accurate outcome. Thisresearch explores how this issue should be resolved when machine learningmethods are used to translate from English to languages with formality, usingHindi as the example data. This was done by training a bilingual model in aformality-controlled setting and comparing its performance with a pre-trainedmultilingual model in a similar setting. Since there are not a lot of trainingdata with ground truth, automated annotation techniques were employed toincrease the data size. The primary modeling approach involved leveragingtransformer models, which have demonstrated effectiveness in various naturallanguage processing tasks. We evaluate the official formality accuracy(ACC) bycomparing the predicted masked tokens with the ground truth. This metricprovides a quantitative measure of how well the translations align with thedesired outputs. Our study showcases a versatile translation strategy thatconsiders the nuances of formality in the target language, catering to diverselanguage communication needs and scenarios.</description><author>Harshita Tyagi, Prashasta Jung, Hyowon Lee</author><pubDate>Wed, 22 Nov 2023 15:42:51 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.13475v1</guid></item><item><title>Complexity-Guided Curriculum Learning for Text Graphs</title><link>http://arxiv.org/abs/2311.13472v1</link><description>Curriculum learning provides a systematic approach to training. It refinestraining progressively, tailors training to task requirements, and improvesgeneralization through exposure to diverse examples. We present a curriculumlearning approach that builds on existing knowledge about text and graphcomplexity formalisms for training with text graph data. The core part of ourapproach is a novel data scheduler, which employs "spaced repetition" andcomplexity formalisms to guide the training process. We demonstrate theeffectiveness of the proposed approach on several text graph tasks and graphneural network architectures. The proposed model gains more and uses less data;consistently prefers text over graph complexity indices throughout training,while the best curricula derived from text and graph complexity indices areequally effective; and it learns transferable curricula across GNN models anddatasets. In addition, we find that both node-level (local) and graph-level(global) graph complexity indices, as well as shallow and traditional textcomplexity indices play a crucial role in effective curriculum learning.</description><author>Nidhi Vakil, Hadi Amiri</author><pubDate>Wed, 22 Nov 2023 15:40:57 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.13472v1</guid></item><item><title>DNA-TEQ: An Adaptive Exponential Quantization of Tensors for DNN Inference</title><link>http://arxiv.org/abs/2306.16430v2</link><description>Quantization is commonly used in Deep Neural Networks (DNNs) to reduce thestorage and computational complexity by decreasing the arithmetical precisionof activations and weights, a.k.a. tensors. Efficient hardware architecturesemploy linear quantization to enable the deployment of recent DNNs ontoembedded systems and mobile devices. However, linear uniform quantizationcannot usually reduce the numerical precision to less than 8 bits withoutsacrificing high performance in terms of model accuracy. The performance lossis due to the fact that tensors do not follow uniform distributions. In thispaper, we show that a significant amount of tensors fit into an exponentialdistribution. Then, we propose DNA-TEQ to exponentially quantize DNN tensorswith an adaptive scheme that achieves the best trade-off between numericalprecision and accuracy loss. The experimental results show that DNA-TEQprovides a much lower quantization bit-width compared to previous proposals,resulting in an average compression ratio of 40% over the linear INT8 baseline,with negligible accuracy loss and without retraining the DNNs. Besides, DNA-TEQleads the way in performing dot-product operations in the exponential domain,which saves 66% of energy consumption on average for a set of widely used DNNs.</description><author>Bahareh Khabbazan, Marc Riera, Antonio GonzÃ¡lez</author><pubDate>Wed, 22 Nov 2023 15:39:14 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.16430v2</guid></item><item><title>Ensemble transport smoothing. Part II: Nonlinear updates</title><link>http://arxiv.org/abs/2210.17435v2</link><description>Smoothing is a specialized form of Bayesian inference for state-space modelsthat characterizes the posterior distribution of a collection of states givenan associated sequence of observations. Ramgraber et al. (2023) proposes ageneral framework for transport-based ensemble smoothing, which includes linearKalman-type smoothers as special cases. Here, we build on this foundation torealize and demonstrate nonlinear backward ensemble transport smoothers. Wediscuss parameterization and regularization of the associated transport maps,and then examine the performance of these smoothers for nonlinear and chaoticdynamical systems that exhibit non-Gaussian behavior. In these settings, ournonlinear transport smoothers yield lower estimation error than conventionallinear smoothers and state-of-the-art iterative ensemble Kalman smoothers, forcomparable numbers of model evaluations.</description><author>Maximilian Ramgraber, Ricardo Baptista, Dennis McLaughlin, Youssef Marzouk</author><pubDate>Wed, 22 Nov 2023 15:38:58 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2210.17435v2</guid></item><item><title>A principled deep learning approach for geological facies generation</title><link>http://arxiv.org/abs/2305.13318v2</link><description>The simulation of geological facies in an unobservable volume is essential invarious geoscience applications. Given the complexity of the problem, deepgenerative learning is a promising approach to overcome the limitations oftraditional geostatistical simulation models, in particular their lack ofphysical realism. This research aims to investigate the application ofgenerative adversarial networks and deep variational inference forconditionally simulating meandering channels in underground volumes. In thispaper, we review the generative deep learning approaches, in particular theadversarial ones and the stabilization techniques that aim to facilitate theirtraining. The proposed approach is tested on 2D and 3D simulations generated bythe stochastic process-based model Flumy. Morphological metrics are utilized tocompare our proposed method with earlier iterations of generative adversarialnetworks. The results indicate that by utilizing recent stabilizationtechniques, generative adversarial networks can efficiently sample from targetdata distributions. Moreover, we demonstrate the ability to simulateconditioned simulations through the latent variable model property of theproposed approach.</description><author>Ferdinand Bhavsar, Nicolas Desassis, Fabien Ors, Thomas Romary</author><pubDate>Wed, 22 Nov 2023 15:38:47 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.13318v2</guid></item><item><title>Comparative Analysis of Linear Regression, Gaussian Elimination, and LU Decomposition for CT Real Estate Purchase Decisions</title><link>http://arxiv.org/abs/2311.13471v1</link><description>This paper presents a comprehensive evaluation of three distinctcomputational algorithms applied to the decision-making process of real estatepurchases. Specifically, we analyze the efficacy of Linear Regression fromScikit-learn library, Gaussian Elimination with partial pivoting, and LUDecomposition in predicting the advisability of buying a house in the State ofConnecticut based on a set of financial and market-related parameters. Thealgorithms' performances were compared using a dataset encompassingtown-specific details, yearly data, interest rates, and median sale ratios. Ourresults demonstrate significant differences in predictive accuracy, with LinearRegression and LU Decomposition providing the most reliable recommendations andGaussian Elimination showing limitations in stability and performance. Thestudy's findings emphasize the importance of algorithm selection in predictiveanalytic and offer insights into the practical applications of computationalmethods in real estate investment strategies. By evaluating model efficacythrough metrics such as R-squared scores and Mean Squared Error, we provide anuanced understanding of each method's strengths and weaknesses, contributingvaluable knowledge to the fields of real estate analysis and predictivemodeling.</description><author>Xilin Cheng</author><pubDate>Wed, 22 Nov 2023 15:35:56 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.13471v1</guid></item><item><title>Span-Based Optimal Sample Complexity for Average Reward MDPs</title><link>http://arxiv.org/abs/2311.13469v1</link><description>We study the sample complexity of learning an $\varepsilon$-optimal policy inan average-reward Markov decision process (MDP) under a generative model. Weestablish the complexity bound $\widetilde{O}\left(SA\frac{H}{\varepsilon^2}\right)$, where $H$ is the span of the bias function of the optimal policy and$SA$ is the cardinality of the state-action space. Our result is the first thatis minimax optimal (up to log factors) in all parameters $S,A,H$ and$\varepsilon$, improving on existing work that either assumes uniformly boundedmixing times for all policies or has suboptimal dependence on the parameters. Our result is based on reducing the average-reward MDP to a discounted MDP.To establish the optimality of this reduction, we develop improved bounds for$\gamma$-discounted MDPs, showing that$\widetilde{O}\left(SA\frac{H}{(1-\gamma)^2\varepsilon^2} \right)$ samplessuffice to learn a $\varepsilon$-optimal policy in weakly communicating MDPsunder the regime that $\gamma \geq 1 - \frac{1}{H}$, circumventing thewell-known lower bound of$\widetilde{\Omega}\left(SA\frac{1}{(1-\gamma)^3\varepsilon^2} \right)$ forgeneral $\gamma$-discounted MDPs. Our analysis develops upper bounds on certaininstance-dependent variance parameters in terms of the span parameter. Thesebounds are tighter than those based on the mixing time or diameter of the MDPand may be of broader use.</description><author>Matthew Zurek, Yudong Chen</author><pubDate>Wed, 22 Nov 2023 15:34:44 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.13469v1</guid></item><item><title>Accelerating Inference in Molecular Diffusion Models with Latent Representations of Protein Structure</title><link>http://arxiv.org/abs/2311.13466v1</link><description>Diffusion generative models have emerged as a powerful framework foraddressing problems in structural biology and structure-based drug design.These models operate directly on 3D molecular structures. Due to theunfavorable scaling of graph neural networks (GNNs) with graph size as well asthe relatively slow inference speeds inherent to diffusion models, manyexisting molecular diffusion models rely on coarse-grained representations ofprotein structure to make training and inference feasible. However, suchcoarse-grained representations discard essential information for modelingmolecular interactions and impair the quality of generated structures. In thiswork, we present a novel GNN-based architecture for learning latentrepresentations of molecular structure. When trained end-to-end with adiffusion model for de novo ligand design, our model achieves comparableperformance to one with an all-atom protein representation while exhibiting a3-fold reduction in inference time.</description><author>Ian Dunn, David Ryan Koes</author><pubDate>Wed, 22 Nov 2023 15:32:31 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.13466v1</guid></item><item><title>Attention-based Adversarial Appearance Learning of Augmented Pedestrians</title><link>http://arxiv.org/abs/2107.02673v2</link><description>Synthetic data became already an essential component of machinelearning-based perception in the field of autonomous driving. Yet it stillcannot replace real data completely due to the sim2real domain shift. In thiswork, we propose a method that leverages the advantages of the augmentationprocess and adversarial training to synthesize realistic data for thepedestrian recognition task. Our approach utilizes an attention mechanismdriven by an adversarial loss to learn domain discrepancies and improvesim2real adaptation. Our experiments confirm that the proposed adaptationmethod is robust to such discrepancies and reveals both visual realism andsemantic consistency. Furthermore, we evaluate our data generation pipeline onthe task of pedestrian recognition and demonstrate that generated data resembleproperties of the real domain.</description><author>Kevin Strauss, Artem Savkin, Federico Tombari</author><pubDate>Wed, 22 Nov 2023 15:27:53 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2107.02673v2</guid></item><item><title>Multi-Objective Bayesian Optimization with Active Preference Learning</title><link>http://arxiv.org/abs/2311.13460v1</link><description>There are a lot of real-world black-box optimization problems that need tooptimize multiple criteria simultaneously. However, in a multi-objectiveoptimization (MOO) problem, identifying the whole Pareto front requires theprohibitive search cost, while in many practical scenarios, the decision maker(DM) only needs a specific solution among the set of the Pareto optimalsolutions. We propose a Bayesian optimization (BO) approach to identifying themost preferred solution in the MOO with expensive objective functions, in whicha Bayesian preference model of the DM is adaptively estimated by an interactivemanner based on the two types of supervisions called the pairwise preferenceand improvement request. To explore the most preferred solution, we define anacquisition function in which the uncertainty both in the objective functionsand the DM preference is incorporated. Further, to minimize the interactioncost with the DM, we also propose an active learning strategy for thepreference estimation. We empirically demonstrate the effectiveness of ourproposed method through the benchmark function optimization and thehyper-parameter optimization problems for machine learning models.</description><author>Ryota Ozaki, Kazuki Ishikawa, Youhei Kanzaki, Shinya Suzuki, Shion Takeno, Ichiro Takeuchi, Masayuki Karasuyama</author><pubDate>Wed, 22 Nov 2023 15:24:36 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.13460v1</guid></item><item><title>The Tempered Hilbert Simplex Distance and Its Application To Non-linear Embeddings of TEMs</title><link>http://arxiv.org/abs/2311.13459v1</link><description>Tempered Exponential Measures (TEMs) are a parametric generalization of theexponential family of distributions maximizing the tempered entropy functionamong positive measures subject to a probability normalization of their powerdensities. Calculus on TEMs relies on a deformed algebra of arithmeticoperators induced by the deformed logarithms used to define the temperedentropy. In this work, we introduce three different parameterizations of finitediscrete TEMs via Legendre functions of the negative tempered entropy function.In particular, we establish an isometry between such parameterizations in termsof a generalization of the Hilbert log cross-ratio simplex distance to atempered Hilbert co-simplex distance. Similar to the Hilbert geometry, thetempered Hilbert distance is characterized as a $t$-symmetrization of theoriented tempered Funk distance. We motivate our construction by introducingthe notion of $t$-lengths of smooth curves in a tautological Finsler manifold.We then demonstrate the properties of our generalized structure in differentsettings and numerically examine the quality of its differentiableapproximations for optimization in machine learning settings.</description><author>Ehsan Amid, Frank Nielsen, Richard Nock, Manfred K. Warmuth</author><pubDate>Wed, 22 Nov 2023 15:24:29 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.13459v1</guid></item><item><title>Leveraging Different Learning Styles for Improved Knowledge Distillation in Biomedical Imaging</title><link>http://arxiv.org/abs/2212.02931v3</link><description>Learning style refers to a type of training mechanism adopted by anindividual to gain new knowledge. As suggested by the VARK model, humans havedifferent learning preferences, like Visual (V), Auditory (A), Read/Write (R),and Kinesthetic (K), for acquiring and effectively processing information. Ourwork endeavors to leverage this concept of knowledge diversification to improvethe performance of model compression techniques like Knowledge Distillation(KD) and Mutual Learning (ML). Consequently, we use a single-teacher andtwo-student network in a unified framework that not only allows for thetransfer of knowledge from teacher to students (KD) but also encouragescollaborative learning between students (ML). Unlike the conventional approach,where the teacher shares the same knowledge in the form of predictions orfeature representations with the student network, our proposed approach employsa more diversified strategy by training one student with predictions and theother with feature maps from the teacher. We further extend this knowledgediversification by facilitating the exchange of predictions and feature mapsbetween the two student networks, enriching their learning experiences. We haveconducted comprehensive experiments with three benchmark datasets for bothclassification and segmentation tasks using two different network architecturecombinations. These experimental results demonstrate that knowledgediversification in a combined KD and ML framework outperforms conventional KDor ML techniques (with similar network configuration) that only use predictionswith an average improvement of 2%. Furthermore, consistent improvement inperformance across different tasks, with various network architectures, andover state-of-the-art techniques establishes the robustness andgeneralizability of the proposed model</description><author>Usma Niyaz, Abhishek Singh Sambyal, Deepti R. Bathula</author><pubDate>Wed, 22 Nov 2023 15:23:44 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2212.02931v3</guid></item><item><title>Generation of Explanations for Logic Reasoning</title><link>http://arxiv.org/abs/2311.13455v1</link><description>This thesis delves into a fortiori arguments in deductive reasoning,underscoring their relevance in various domains such as law, philosophy, andartificial intelligence. The research is centred on employing GPT-3.5-turbo toautomate the analysis of these arguments, with a focus on understandingintricate reasoning processes, generating clear and coherent explanations, andcreating novel arguments. The methodology encompasses a series of tasksincluding detailed reasoning, interpretation, and the augmentation of afortiori arguments. It involves meticulously identifying these arguments indiverse contexts, differentiating comparative elements, and categorizing thembased on their logical structure. Extensive experiments reveals the challenges encountered by GPT-3.5-turbo inaccurately detecting and classifying a fortiori arguments. Nevertheless, themodel demonstrates a performance that rivals specialized models, particularlyin extracting key components and interpreting underlying properties. Theintegration of external information into the model's processing significantlyelevates the quality of the generated explanations. Additionally, the modelexhibits a noteworthy capability in augmenting arguments, thus contributing tothe enrichment of the data set. Despite facing certain limitations, this thesis makes significantcontributions to the fields of artificial intelligence and logical reasoning.It introduces novel methodologies, establishes a rigorous evaluation framework,and provides deep insights that set the stage for future advancements inautomated logical reasoning. The findings and methodologies presented hereinnot only underscore the potential of AI in complex reasoning tasks but alsohighlight areas for future research and development.</description><author>Yanyi Pu</author><pubDate>Wed, 22 Nov 2023 15:22:04 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.13455v1</guid></item><item><title>Explaining high-dimensional text classifiers</title><link>http://arxiv.org/abs/2311.13454v1</link><description>Explainability has become a valuable tool in the last few years, helpinghumans better understand AI-guided decisions. However, the classicexplainability tools are sometimes quite limited when consideringhigh-dimensional inputs and neural network classifiers. We present a newexplainability method using theoretically proven high-dimensional properties inneural network classifiers. We present two usages of it: 1) On the classicalsentiment analysis task for the IMDB reviews dataset, and 2) ourMalware-Detection task for our PowerShell scripts dataset.</description><author>Odelia Melamed, Rich Caruana</author><pubDate>Wed, 22 Nov 2023 15:20:12 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.13454v1</guid></item><item><title>Ensemble transport smoothing. Part I: Unified framework</title><link>http://arxiv.org/abs/2210.17000v2</link><description>Smoothers are algorithms for Bayesian time series re-analysis. Mostoperational smoothers rely either on affine Kalman-type transformations or onsequential importance sampling. These strategies occupy opposite ends of aspectrum that trades computational efficiency and scalability for statisticalgenerality and consistency: non-Gaussianity renders affine Kalman updatesinconsistent with the true Bayesian solution, while the ensemble size requiredfor successful importance sampling can be prohibitive. This paper revisits thesmoothing problem from the perspective of measure transport, which offers theprospect of consistent prior-to-posterior transformations for Bayesianinference. We leverage this capacity by proposing a general ensemble frameworkfor transport-based smoothing. Within this framework, we derive a comprehensiveset of smoothing recursions based on nonlinear transport maps and detail howthey exploit the structure of state-space models in fully non-Gaussiansettings. We also describe how many standard Kalman-type smoothing algorithmsemerge as special cases of our framework. A companion paper (Ramgraber et al.,2023) explores the implementation of nonlinear ensemble transport smoothers ingreater depth.</description><author>Maximilian Ramgraber, Ricardo Baptista, Dennis McLaughlin, Youssef Marzouk</author><pubDate>Wed, 22 Nov 2023 15:17:40 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2210.17000v2</guid></item><item><title>Differentially Private Non-Convex Optimization under the KL Condition with Optimal Rates</title><link>http://arxiv.org/abs/2311.13447v1</link><description>We study private empirical risk minimization (ERM) problem for lossessatisfying the $(\gamma,\kappa)$-Kurdyka-{\L}ojasiewicz (KL) condition. ThePolyak-{\L}ojasiewicz (PL) condition is a special case of this condition when$\kappa=2$. Specifically, we study this problem under the constraint of $\rho$zero-concentrated differential privacy (zCDP). When $\kappa\in[1,2]$ and theloss function is Lipschitz and smooth over a sufficiently large region, weprovide a new algorithm based on variance reduced gradient descent thatachieves the rate$\tilde{O}\big(\big(\frac{\sqrt{d}}{n\sqrt{\rho}}\big)^\kappa\big)$ on theexcess empirical risk, where $n$ is the dataset size and $d$ is the dimension.We further show that this rate is nearly optimal. When $\kappa \geq 2$ and theloss is instead Lipschitz and weakly convex, we show it is possible to achievethe rate $\tilde{O}\big(\big(\frac{\sqrt{d}}{n\sqrt{\rho}}\big)^\kappa\big)$with a private implementation of the proximal point method. When the KLparameters are unknown, we provide a novel modification and analysis of thenoisy gradient descent algorithm and show that this algorithm achieves a rateof$\tilde{O}\big(\big(\frac{\sqrt{d}}{n\sqrt{\rho}}\big)^{\frac{2\kappa}{4-\kappa}}\big)$adaptively, which is nearly optimal when $\kappa = 2$. We further show that,without assuming the KL condition, the same gradient descent algorithm canachieve fast convergence to a stationary point when the gradient stayssufficiently large during the run of the algorithm. Specifically, we show thatthis algorithm can approximate stationary points of Lipschitz, smooth (andpossibly nonconvex) objectives with rate as fast as$\tilde{O}\big(\frac{\sqrt{d}}{n\sqrt{\rho}}\big)$ and never worse than$\tilde{O}\big(\big(\frac{\sqrt{d}}{n\sqrt{\rho}}\big)^{1/2}\big)$. The latterrate matches the best known rate for methods that do not rely on variancereduction.</description><author>Michael Menart, Enayat Ullah, Raman Arora, Raef Bassily, CristÃ³bal GuzmÃ¡n</author><pubDate>Wed, 22 Nov 2023 15:12:42 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.13447v1</guid></item><item><title>Transfer Attacks and Defenses for Large Language Models on Coding Tasks</title><link>http://arxiv.org/abs/2311.13445v1</link><description>Modern large language models (LLMs), such as ChatGPT, have demonstratedimpressive capabilities for coding tasks including writing and reasoning aboutcode. They improve upon previous neural network models of code, such ascode2seq or seq2seq, that already demonstrated competitive results whenperforming tasks such as code summarization and identifying codevulnerabilities. However, these previous code models were shown vulnerable toadversarial examples, i.e. small syntactic perturbations that do not change theprogram's semantics, such as the inclusion of "dead code" through falseconditions or the addition of inconsequential print statements, designed to"fool" the models. LLMs can also be vulnerable to the same adversarialperturbations but a detailed study on this concern has been lacking so far. Inthis paper we aim to investigate the effect of adversarial perturbations oncoding tasks with LLMs. In particular, we study the transferability ofadversarial examples, generated through white-box attacks on smaller codemodels, to LLMs. Furthermore, to make the LLMs more robust against suchadversaries without incurring the cost of retraining, we propose prompt-baseddefenses that involve modifying the prompt to include additional informationsuch as examples of adversarially perturbed code and explicit instructions forreversing adversarial perturbations. Our experiments show that adversarialexamples obtained with a smaller code model are indeed transferable, weakeningthe LLMs' performance. The proposed defenses show promise in improving themodel's resilience, paving the way to more robust defensive solutions for LLMsin code-related applications.</description><author>Chi Zhang, Zifan Wang, Ravi Mangal, Matt Fredrikson, Limin Jia, Corina Pasareanu</author><pubDate>Wed, 22 Nov 2023 15:11:35 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.13445v1</guid></item><item><title>SkeletonGait: Gait Recognition Using Skeleton Maps</title><link>http://arxiv.org/abs/2311.13444v1</link><description>The choice of the representations is essential for deep gait recognitionmethods. The binary silhouettes and skeletal coordinates are two dominantrepresentations in recent literature, achieving remarkable advances in manyscenarios. However, inherent challenges remain, in which silhouettes are notalways guaranteed in unconstrained scenes, and structural cues have not beenfully utilized from skeletons. In this paper, we introduce a novel skeletalgait representation named Skeleton Map, together with SkeletonGait, askeleton-based method to exploit structural information from human skeletonmaps. Specifically, the skeleton map represents the coordinates of human jointsas a heatmap with Gaussian approximation, exhibiting a silhouette-like imagedevoid of exact body structure. Beyond achieving state-of-the-art performancesover five popular gait datasets, more importantly, SkeletonGait uncovers novelinsights about how important structural features are in describing gait andwhen do they play a role. Furthermore, we propose a multi-branch architecture,named SkeletonGait++, to make use of complementary features from both skeletonsand silhouettes. Experiments indicate that SkeletonGait++ outperforms existingstate-of-the-art methods by a significant margin in various scenarios. Forinstance, it achieves an impressive rank-1 accuracy of over $85\%$ on thechallenging GREW dataset. All the source code will be available athttps://github.com/ShiqiYu/OpenGait.</description><author>Chao Fan, Jingzhe Ma, Dongyang Jin, Chuanfu Shen, Shiqi Yu</author><pubDate>Wed, 22 Nov 2023 15:09:59 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.13444v1</guid></item><item><title>Guided Flows for Generative Modeling and Decision Making</title><link>http://arxiv.org/abs/2311.13443v1</link><description>Classifier-free guidance is a key component for improving the performance ofconditional generative models for many downstream tasks. It drasticallyimproves the quality of samples produced, but has so far only been used fordiffusion models. Flow Matching (FM), an alternative simulation-free approach,trains Continuous Normalizing Flows (CNFs) based on regressing vector fields.It remains an open question whether classifier-free guidance can be performedfor Flow Matching models, and to what extent does it improve performance. Inthis paper, we explore the usage of Guided Flows for a variety of downstreamapplications involving conditional image generation, speech synthesis, andreinforcement learning. In particular, we are the first to apply flow models tothe offline reinforcement learning setting. We also show that Guided Flowssignificantly improves the sample quality in image generation and zero-shottext-to-speech synthesis, and can make use of drastically low amounts ofcomputation without affecting the agent's overall performance.</description><author>Qinqing Zheng, Matt Le, Neta Shaul, Yaron Lipman, Aditya Grover, Ricky T. Q. Chen</author><pubDate>Wed, 22 Nov 2023 15:07:59 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.13443v1</guid></item><item><title>Peeking Inside the Schufa Blackbox: Explaining the German Housing Scoring System</title><link>http://arxiv.org/abs/2311.11655v2</link><description>Explainable Artificial Intelligence is a concept aimed at making complexalgorithms transparent to users through a uniform solution. Researchers havehighlighted the importance of integrating domain specific contexts to developexplanations tailored to end users. In this study, we focus on the Schufahousing scoring system in Germany and investigate how users information needsand expectations for explanations vary based on their roles. Using thespeculative design approach, we asked business information students to imagineuser interfaces that provide housing credit score explanations from theperspectives of both tenants and landlords. Our preliminary findings suggestthat although there are general needs that apply to all users, there are alsoconflicting needs that depend on the practical realities of their roles and howcredit scores affect them. We contribute to Human centered XAI research byproposing future research directions that examine users explanatory needsconsidering their roles and agencies.</description><author>Dean-Robin Kern, Gunnar Stevens, Erik Dethier, Sidra Naveed, Fatemeh Alizadeh, Delong Du, Md Shajalal</author><pubDate>Wed, 22 Nov 2023 14:57:21 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.11655v2</guid></item><item><title>PG-Video-LLaVA: Pixel Grounding Large Video-Language Models</title><link>http://arxiv.org/abs/2311.13435v1</link><description>Extending image-based Large Multimodal Models (LMM) to videos is challengingdue to the inherent complexity of video data. The recent approaches extendingimage-based LMM to videos either lack the grounding capabilities (e.g.,VideoChat, Video-ChatGPT, Video-LLaMA) or do not utilize the audio-signals forbetter video understanding (e.g., Video-ChatGPT). Addressing these gaps, wepropose Video-LLaVA, the first LMM with pixel-level grounding capability,integrating audio cues by transcribing them into text to enrich video-contextunderstanding. Our framework uses an off-the-shelf tracker and a novelgrounding module, enabling it to spatially and temporally localize objects invideos following user instructions. We evaluate Video-LLaVA using video-basedgenerative and question-answering benchmarks and introduce new benchmarksspecifically designed to measure prompt-based object grounding performance invideos. Further, we propose the use of Vicuna over GPT-3.5, as utilized inVideo-ChatGPT, for video-based conversation benchmarking, ensuringreproducibility of results which is a concern with the proprietary nature ofGPT-3.5. Our framework builds on SoTA image-based LLaVA model and extends itsadvantages to the video domain, delivering promising gains on video-basedconversation and grounding tasks. Project Page:https://github.com/mbzuai-oryx/Video-LLaVA</description><author>Shehan Munasinghe, Rusiru Thushara, Muhammad Maaz, Hanoona Abdul Rasheed, Salman Khan, Mubarak Shah, Fahad Khan</author><pubDate>Wed, 22 Nov 2023 14:48:30 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.13435v1</guid></item><item><title>Recurrent neural networks and transfer learning for elasto-plasticity in woven composites</title><link>http://arxiv.org/abs/2311.13434v1</link><description>As a surrogate for computationally intensive meso-scale simulation of wovencomposites, this article presents Recurrent Neural Network (RNN) models.Leveraging the power of transfer learning, the initialization challenges andsparse data issues inherent in cyclic shear strain loads are addressed in theRNN models. A mean-field model generates a comprehensive data set representingelasto-plastic behavior. In simulations, arbitrary six-dimensional strainhistories are used to predict stresses under random walking as the source taskand cyclic loading conditions as the target task. Incorporating sub-scaleproperties enhances RNN versatility. In order to achieve accurate predictions,the model uses a grid search method to tune network architecture andhyper-parameter configurations. The results of this study demonstrate thattransfer learning can be used to effectively adapt the RNN to varying strainconditions, which establishes its potential as a useful tool for modelingpath-dependent responses in woven composites.</description><author>Ehsan Ghane, Martin FagerstrÃ¶m, Mohsen Mirkhalaf</author><pubDate>Wed, 22 Nov 2023 14:47:54 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.13434v1</guid></item><item><title>Extracting individual variable information for their decoupling, direct mutual information and multi-feature Granger causality</title><link>http://arxiv.org/abs/2311.13431v1</link><description>Working with multiple variables they usually contain difficult to controlcomplex dependencies. This article proposes extraction of their individualinformation, e.g. $\overline{X|Y}$ as random variable containing informationfrom $X$, but with removed information about $Y$, by using $(x,y)\leftrightarrow (\bar{x}=\textrm{CDF}_{X|Y=y}(x),y)$ reversible normalization.One application can be decoupling of individual information of variables:reversibly transform $(X_1,\ldots,X_n)\leftrightarrow(\tilde{X}_1,\ldots\tilde{X}_n)$ together containing the same information, but being independent:$\forall_{i\neq j} \tilde{X}_i\perp \tilde{X}_j, \tilde{X}_i\perp X_j$. Itrequires detailed models of complex conditional probability distributions - itis generally a difficult task, but here can be done through multiple dependencyreducing iterations, using imperfect methods (here HCR: HierarchicalCorrelation Reconstruction). It could be also used for direct mutualinformation - evaluating direct information transfer: without use ofintermediate variables. For causality direction there is discussedmulti-feature Granger causality, e.g. to trace various types of individualinformation transfers between such decoupled variables, including propagationtime (delay).</description><author>Jarek Duda</author><pubDate>Wed, 22 Nov 2023 14:45:30 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.13431v1</guid></item><item><title>From Principle to Practice: Vertical Data Minimization for Machine Learning</title><link>http://arxiv.org/abs/2311.10500v2</link><description>Aiming to train and deploy predictive models, organizations collect largeamounts of detailed client data, risking the exposure of private information inthe event of a breach. To mitigate this, policymakers increasingly demandcompliance with the data minimization (DM) principle, restricting datacollection to only that data which is relevant and necessary for the task.Despite regulatory pressure, the problem of deploying machine learning modelsthat obey DM has so far received little attention. In this work, we addressthis challenge in a comprehensive manner. We propose a novel vertical DM (vDM)workflow based on data generalization, which by design ensures that nofull-resolution client data is collected during training and deployment ofmodels, benefiting client privacy by reducing the attack surface in case of abreach. We formalize and study the corresponding problem of findinggeneralizations that both maximize data utility and minimize empirical privacyrisk, which we quantify by introducing a diverse set of policy-alignedadversarial scenarios. Finally, we propose a range of baseline vDM algorithms,as well as Privacy-aware Tree (PAT), an especially effective vDM algorithm thatoutperforms all baselines across several settings. We plan to release our codeas a publicly available library, helping advance the standardization of DM formachine learning. Overall, we believe our work can help lay the foundation forfurther exploration and adoption of DM principles in real-world applications.</description><author>Robin Staab, Nikola JovanoviÄ, Mislav BalunoviÄ, Martin Vechev</author><pubDate>Wed, 22 Nov 2023 14:42:12 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.10500v2</guid></item><item><title>Confident Naturalness Explanation (CNE): A Framework to Explain and Assess Patterns Forming Naturalness</title><link>http://arxiv.org/abs/2311.08936v2</link><description>Protected natural areas are regions that have been minimally affected byhuman activities such as urbanization, agriculture, and other humaninterventions. To better understand and map the naturalness of these areas,machine learning models can be used to analyze satellite imagery. Specifically,explainable machine learning methods show promise in uncovering patterns thatcontribute to the concept of naturalness within these protected environments.Additionally, addressing the uncertainty inherent in machine learning models iscrucial for a comprehensive understanding of this concept. However, existingapproaches have limitations. They either fail to provide explanations that areboth valid and objective or struggle to offer a quantitative metric thataccurately measures the contribution of specific patterns to naturalness, alongwith the associated confidence. In this paper, we propose a novel frameworkcalled the Confident Naturalness Explanation (CNE) framework. This frameworkcombines explainable machine learning and uncertainty quantification to assessand explain naturalness. We introduce a new quantitative metric that describesthe confident contribution of patterns to the concept of naturalness.Furthermore, we generate an uncertainty-aware segmentation mask for each inputsample, highlighting areas where the model lacks knowledge. To demonstrate theeffectiveness of our framework, we apply it to a study site in Fennoscandiausing two open-source satellite datasets.</description><author>Ahmed Emam, Mohamed Farag, Ribana Roscher</author><pubDate>Wed, 22 Nov 2023 14:25:55 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.08936v2</guid></item><item><title>From Images to Connections: Can DQN with GNNs learn the Strategic Game of Hex?</title><link>http://arxiv.org/abs/2311.13414v1</link><description>The gameplay of strategic board games such as chess, Go and Hex is oftencharacterized by combinatorial, relational structures -- capturing distinctinteractions and non-local patterns -- and not just images. Nonetheless, mostcommon self-play reinforcement learning (RL) approaches simply approximatepolicy and value functions using convolutional neural networks (CNN). A keyfeature of CNNs is their relational inductive bias towards locality andtranslational invariance. In contrast, graph neural networks (GNN) can encodemore complicated and distinct relational structures. Hence, we investigate thecrucial question: Can GNNs, with their ability to encode complex connections,replace CNNs in self-play reinforcement learning? To this end, we do acomparison with Hex -- an abstract yet strategically rich board game -- servingas our experimental platform. Our findings reveal that GNNs excel at dealingwith long range dependency situations in game states and are less prone tooverfitting, but also showing a reduced proficiency in discerning localpatterns. This suggests a potential paradigm shift, signaling the use ofgame-specific structures to reshape self-play reinforcement learning.</description><author>Yannik Keller, Jannis BlÃ¼ml, Gopika Sudhakaran, Kristian Kersting</author><pubDate>Wed, 22 Nov 2023 14:20:15 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.13414v1</guid></item><item><title>Bayesian inference of a new Mallows model for characterising symptom sequences applied in primary progressive aphasia</title><link>http://arxiv.org/abs/2311.13411v1</link><description>Machine learning models offer the potential to understand diverse datasets ina data-driven way, powering insights into individual disease experiences andensuring equitable healthcare. In this study, we explore Bayesian inference forcharacterising symptom sequences, and the associated modelling challenges. Weadapted the Mallows model to account for partial rankings and right-censoreddata, employing custom MCMC fitting. Our evaluation, encompassing syntheticdata and a primary progressive aphasia dataset, highlights the model's efficacyin revealing mean orderings and estimating ranking variance. This holds thepotential to enhance clinical comprehension of symptom occurrence. However, ourwork encounters limitations concerning model scalability and small datasetsizes.</description><author>Beatrice Taylor, Cameron Shand, Chris J. D. Hardy, Neil Oxtoby</author><pubDate>Wed, 22 Nov 2023 14:16:20 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.13411v1</guid></item><item><title>CompenHR: Efficient Full Compensation for High-resolution Projector</title><link>http://arxiv.org/abs/2311.13409v1</link><description>Full projector compensation is a practical task of projector-camera systems.It aims to find a projector input image, named compensation image, such thatwhen projected it cancels the geometric and photometric distortions due to thephysical environment and hardware. State-of-the-art methods use deep learningto address this problem and show promising performance for low-resolutionsetups. However, directly applying deep learning to high-resolution setups isimpractical due to the long training time and high memory cost. To address thisissue, this paper proposes a practical full compensation solution. Firstly, wedesign an attention-based grid refinement network to improve geometriccorrection quality. Secondly, we integrate a novel sampling scheme into anend-to-end compensation network to alleviate computation and introduceattention blocks to preserve key features. Finally, we construct a benchmarkdataset for high-resolution projector full compensation. In experiments, ourmethod demonstrates clear advantages in both efficiency and quality.</description><author>Yuxi Wang, Haibin Ling, Bingyao Huang</author><pubDate>Wed, 22 Nov 2023 14:13:27 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.13409v1</guid></item><item><title>The effect of speech pathology on automatic speaker verification -- a large-scale study</title><link>http://arxiv.org/abs/2204.06450v3</link><description>Navigating the challenges of data-driven speech processing, one of theprimary hurdles is accessing reliable pathological speech data. While publicdatasets appear to offer solutions, they come with inherent risks of potentialunintended exposure of patient health information via re-identificationattacks. Using a comprehensive real-world pathological speech corpus, with overn=3,800 test subjects spanning various age groups and speech disorders, weemployed a deep-learning-driven automatic speaker verification (ASV) approach.This resulted in a notable mean equal error rate (EER) of 0.89% with a standarddeviation of 0.06%, outstripping traditional benchmarks. Our comprehensiveassessments demonstrate that pathological speech overall faces heightenedprivacy breach risks compared to healthy speech. Specifically, adults withdysphonia are at heightened re-identification risks, whereas conditions likedysarthria yield results comparable to those of healthy speakers. Crucially,speech intelligibility does not influence the ASV system's performance metrics.In pediatric cases, particularly those with cleft lip and palate, the recordingenvironment plays a decisive role in re-identification. Merging data acrosspathological types led to a marked EER decrease, suggesting the potentialbenefits of pathological diversity in ASV, accompanied by a logarithmic boostin ASV effectiveness. In essence, this research sheds light on the dynamicsbetween pathological speech and speaker verification, emphasizing its crucialrole in safeguarding patient confidentiality in our increasingly digitizedhealthcare era.</description><author>Soroosh Tayebi Arasteh, Tobias Weise, Maria Schuster, Elmar Noeth, Andreas Maier, Seung Hee Yang</author><pubDate>Wed, 22 Nov 2023 14:10:56 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2204.06450v3</guid></item><item><title>Defense semantics of argumentation: revisit</title><link>http://arxiv.org/abs/2311.12207v2</link><description>In this paper we introduce a novel semantics, called defense semantics, forDung's abstract argumentation frameworks in terms of a notion of (partial)defence, which is a triple encoding that one argument is (partially) defendedby another argument via attacking the attacker of the first argument. In termsof defense semantics, we show that defenses related to self-attacked argumentsand arguments in 3-cycles are unsatifiable under any situation and thereforecan be removed without affecting the defense semantics of an AF. Then, weintroduce a new notion of defense equivalence of AFs, and compare defenseequivalence with standard equivalence and strong equivalence, respectively.Finally, by exploiting defense semantics, we define two kinds of reasons foraccepting arguments, i.e., direct reasons and root reasons, and a notion ofroot equivalence of AFs that can be used in argumentation summarization.</description><author>Beishui Liao, Leendert van der Torre</author><pubDate>Wed, 22 Nov 2023 14:07:51 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.12207v2</guid></item><item><title>Hinge-Wasserstein: Mitigating Overconfidence in Regression by Classification</title><link>http://arxiv.org/abs/2306.00560v2</link><description>Computer vision systems that are deployed in safety-critical applicationsneed to quantify their output uncertainty. We study regression from images toparameter values and here it is common to detect uncertainty by predictingprobability distributions. In this context, we investigate theregression-by-classification paradigm which can represent multimodaldistributions, without a prior assumption on the number of modes. Throughexperiments on a specifically designed synthetic dataset, we demonstrate thattraditional loss functions lead to poor probability distribution estimates andsevere overconfidence, in the absence of full ground truth distributions. Inorder to alleviate these issues, we propose hinge-Wasserstein -- a simpleimprovement of the Wasserstein loss that reduces the penalty for weak secondarymodes during training. This enables prediction of complex distributions withmultiple modes, and allows training on datasets where full ground truthdistributions are not available. In extensive experiments, we show that theproposed loss leads to substantially better uncertainty estimation on twochallenging computer vision tasks: horizon line detection and stereo disparityestimation.</description><author>Ziliang Xiong, Arvi Jonnarth, Abdelrahman Eldesokey, Joakim Johnander, Bastian Wandt, Per-Erik Forssen</author><pubDate>Wed, 22 Nov 2023 14:02:07 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.00560v2</guid></item><item><title>Animatable 3D Gaussians for High-fidelity Synthesis of Human Motions</title><link>http://arxiv.org/abs/2311.13404v1</link><description>We present a novel animatable 3D Gaussian model for rendering high-fidelityfree-view human motions in real time. Compared to existing NeRF-based methods,the model owns better capability in synthesizing high-frequency details withoutthe jittering problem across video frames. The core of our model is a novelaugmented 3D Gaussian representation, which attaches each Gaussian with alearnable code. The learnable code serves as a pose-dependent appearanceembedding for refining the erroneous appearance caused by geometrictransformation of Gaussians, based on which an appearance refinement model islearned to produce residual Gaussian properties to match the appearance intarget pose. To force the Gaussians to learn the foreground human only withoutbackground interference, we further design a novel alpha loss to explicitlyconstrain the Gaussians within the human body. We also propose to jointlyoptimize the human joint parameters to improve the appearance accuracy. Theanimatable 3D Gaussian model can be learned with shallow MLPs, so new humanmotions can be synthesized in real time (66 fps on avarage). Experiments showthat our model has superior performance over NeRF-based methods.</description><author>Keyang Ye, Tianjia Shao, Kun Zhou</author><pubDate>Wed, 22 Nov 2023 14:00:23 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.13404v1</guid></item><item><title>BEVTrack: A Simple and Strong Baseline for 3D Single Object Tracking in Bird's-Eye View</title><link>http://arxiv.org/abs/2309.02185v4</link><description>3D Single Object Tracking (SOT) is a fundamental task of computer vision,proving essential for applications like autonomous driving. It remainschallenging to localize the target from surroundings due to appearancevariations, distractors, and the high sparsity of point clouds. The spatialinformation indicating objects' spatial adjacency across consecutive frames iscrucial for effective object tracking. However, existing trackers typicallyemploy point-wise representation with irregular formats, leading toinsufficient use of this important spatial knowledge. As a result, thesetrackers usually require elaborate designs and solving multiple subtasks. Inthis paper, we propose BEVTrack, a simple yet effective baseline that performstracking in Bird's-Eye View (BEV). This representation greatly retains spatialinformation owing to its ordered structure and inherently encodes the implicitmotion relations of the target as well as distractors. To achieve accurateregression for targets with diverse attributes (\textit{e.g.}, sizes and motionpatterns), BEVTrack constructs the likelihood function with the learnedunderlying distributions adapted to different targets, rather than making afixed Laplace or Gaussian assumption as in previous works. This providesvaluable priors for tracking and thus further boosts performance. While onlyusing a single regression loss with a plain convolutional architecture,BEVTrack achieves state-of-the-art performance on three large-scale datasets,KITTI, NuScenes, and Waymo Open Dataset while maintaining a high inferencespeed of about 200 FPS. The code will be released athttps://github.com/xmm-prio/BEVTrack.</description><author>Yuxiang Yang, Yingqi Deng, Jing Zhang, Jiahao Nie, Zheng-Jun Zha</author><pubDate>Wed, 22 Nov 2023 13:56:48 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2309.02185v4</guid></item><item><title>Depth-Regularized Optimization for 3D Gaussian Splatting in Few-Shot Images</title><link>http://arxiv.org/abs/2311.13398v1</link><description>In this paper, we present a method to optimize Gaussian splatting with alimited number of images while avoiding overfitting. Representing a 3D scene bycombining numerous Gaussian splats has yielded outstanding visual quality.However, it tends to overfit the training views when only a small number ofimages are available. To address this issue, we introduce a dense depth map asa geometry guide to mitigate overfitting. We obtained the depth map using apre-trained monocular depth estimation model and aligning the scale and offsetusing sparse COLMAP feature points. The adjusted depth aids in the color-basedoptimization of 3D Gaussian splatting, mitigating floating artifacts, andensuring adherence to geometric constraints. We verify the proposed method onthe NeRF-LLFF dataset with varying numbers of few images. Our approachdemonstrates robust geometry compared to the original method that relies solelyon images.</description><author>Jaeyoung Chung, Jeongtaek Oh, Kyoung Mu Lee</author><pubDate>Wed, 22 Nov 2023 13:53:04 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.13398v1</guid></item><item><title>SegVol: Universal and Interactive Volumetric Medical Image Segmentation</title><link>http://arxiv.org/abs/2311.13385v1</link><description>Precise image segmentation provides clinical study with meaningful andwell-structured information. Despite the remarkable progress achieved inmedical image segmentation, there is still an absence of foundationsegmentation model that can segment a wide range of anatomical categories witheasy user interaction. In this paper, we propose a universal and interactivevolumetric medical image segmentation model, named SegVol. By training on 90kunlabeled Computed Tomography (CT) volumes and 6k labeled CTs, this foundationmodel supports the segmentation of over 200 anatomical categories usingsemantic and spatial prompts. Extensive experiments verify that SegVoloutperforms the state of the art by a large margin on multiple segmentationbenchmarks. Notably, on three challenging lesion datasets, our method achievesaround 20% higher Dice score than nnU-Net. The model and data are publiclyavailable at: https://github.com/BAAI-DCAI/SegVol.</description><author>Yuxin Du, Fan Bai, Tiejun Huang, Bo Zhao</author><pubDate>Wed, 22 Nov 2023 13:27:36 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.13385v1</guid></item><item><title>LucidDreamer: Domain-free Generation of 3D Gaussian Splatting Scenes</title><link>http://arxiv.org/abs/2311.13384v1</link><description>With the widespread usage of VR devices and contents, demands for 3D scenegeneration techniques become more popular. Existing 3D scene generation models,however, limit the target scene to specific domain, primarily due to theirtraining strategies using 3D scan dataset that is far from the real-world. Toaddress such limitation, we propose LucidDreamer, a domain-free scenegeneration pipeline by fully leveraging the power of existing large-scalediffusion-based generative model. Our LucidDreamer has two alternate steps:Dreaming and Alignment. First, to generate multi-view consistent images frominputs, we set the point cloud as a geometrical guideline for each imagegeneration. Specifically, we project a portion of point cloud to the desiredview and provide the projection as a guidance for inpainting using thegenerative model. The inpainted images are lifted to 3D space with estimateddepth maps, composing a new points. Second, to aggregate the new points intothe 3D scene, we propose an aligning algorithm which harmoniously integratesthe portions of newly generated 3D scenes. The finally obtained 3D scene servesas initial points for optimizing Gaussian splats. LucidDreamer producesGaussian splats that are highly-detailed compared to the previous 3D scenegeneration methods, with no constraint on domain of the target scene.</description><author>Jaeyoung Chung, Suyoung Lee, Hyeongjin Nam, Jaerin Lee, Kyoung Mu Lee</author><pubDate>Wed, 22 Nov 2023 13:27:34 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.13384v1</guid></item><item><title>Confidant: Customizing Transformer-based LLMs via Collaborative Edge Training</title><link>http://arxiv.org/abs/2311.13381v1</link><description>Transformer-based large language models (LLMs) have demonstrated impressivecapabilities in a variety of natural language processing (NLP) tasks.Nonetheless, it is challenging to deploy and fine-tune LLMs on mobile edgedevices with limited computing, memory, and energy budgets. In this paper, wepropose Confidant, a multi-backend collaborative training framework forcustomizing state-of-the-art LLMs on commodity mobile devices like smartphones.Confidant partitions an LLM into several sub-models so that each fits into amobile device's memory. A pipeline parallel training mechanism is furtherdeveloped to ensure fast and efficient distributed training. In addition, wepropose a novel backend scheduler to allocate different attention heads toheterogeneous compute hardware, including mobile CPU and GPUs, to maximize thecompute resource utilization on each edge device. Our preliminary experimentalresults show that Confidant achieves at most 45.3% memory reduction and 8.03xinference speedup in practical settings.</description><author>Yuhao Chen, Yuxuan Yan, Qianqian Yang, Yuanchao Shu, Shibo He, Jiming Chen</author><pubDate>Wed, 22 Nov 2023 13:20:59 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.13381v1</guid></item><item><title>Deriving Comprehensible Theories from Probabilistic Circuits</title><link>http://arxiv.org/abs/2311.13379v1</link><description>The field of Explainable AI (XAI) is seeking to shed light on the innerworkings of complex AI models and uncover the rationale behind their decisions.One of the models gaining attention are probabilistic circuits (PCs), which area general and unified framework for tractable probabilistic models that supportefficient computation of various probabilistic queries. Probabilistic circuitsguarantee inference that is polynomial in the size of the circuit. In thispaper, we improve the explainability of probabilistic circuits by computing acomprehensible, readable logical theory that covers the high-density regionsgenerated by a PC. To achieve this, pruning approaches based on generativesignificance are used in a new method called PUTPUT (Probabilistic circuitUnderstanding Through Pruning Underlying logical Theories). The method isapplied to a real world use case where music playlists are automaticallygenerated and expressed as readable (database) queries. Evaluation shows thatthis approach can effectively produce a comprehensible logical theory thatdescribes the high-density regions of a PC and outperforms state of the artmethods when exploring the performance-comprehensibility trade-off.</description><author>Sieben Bocklandt, Wannes Meert, Koen Vanderstraeten, Wouter Pijpops, Kurt Jaspers</author><pubDate>Wed, 22 Nov 2023 13:19:45 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.13379v1</guid></item><item><title>Point Projection Mapping System for Tracking, Registering, Labeling and Validating Optical Tissue Measurements</title><link>http://arxiv.org/abs/2311.13378v1</link><description>Validation of newly developed optical tissue sensing techniques for tumordetection during cancer surgery requires an accurate correlation withhistological results. Additionally, such accurate correlation facilitatesprecise data labeling for developing high-performance machine-learning tissueclassification models. In this paper, a newly developed Point ProjectionMapping system will be introduced, which allows non-destructive tracking of themeasurement locations on tissue specimens. Additionally, a framework foraccurate registration, validation, and labeling with histopathology results isproposed and validated on a case study. The proposed framework provides a morerobust and accurate method for tracking and validation of optical tissuesensing techniques, which saves time and resources compared to conventionaltechniques available.</description><author>Lianne Feenstra, Stefan D. van der Stel, Marcos Da Silva Guimaraes, Theo J. M Ruers, Behdad Dashtbozorg</author><pubDate>Wed, 22 Nov 2023 13:19:41 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.13378v1</guid></item><item><title>An Empirical Study of Uncertainty Estimation Techniques for Detecting Drift in Data Streams</title><link>http://arxiv.org/abs/2311.13374v1</link><description>In safety-critical domains such as autonomous driving and medical diagnosis,the reliability of machine learning models is crucial. One significantchallenge to reliability is concept drift, which can cause model deteriorationover time. Traditionally, drift detectors rely on true labels, which are oftenscarce and costly. This study conducts a comprehensive empirical evaluation ofusing uncertainty values as substitutes for error rates in detecting drifts,aiming to alleviate the reliance on labeled post-deployment data. We examinefive uncertainty estimation methods in conjunction with the ADWIN detectoracross seven real-world datasets. Our results reveal that while the SWAG methodexhibits superior calibration, the overall accuracy in detecting drifts is notnotably impacted by the choice of uncertainty estimation method, with even themost basic method demonstrating competitive performance. These findings offervaluable insights into the practical applicability of uncertainty-based driftdetection in real-world, safety-critical applications.</description><author>Anton Winter, Nicolas Jourdan, Tristan Wirth, Volker Knauthe, Arjan Kuijper</author><pubDate>Wed, 22 Nov 2023 13:17:55 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.13374v1</guid></item><item><title>Large Language Model is a Good Policy Teacher for Training Reinforcement Learning Agents</title><link>http://arxiv.org/abs/2311.13373v1</link><description>Recent studies have shown that Large Language Models (LLMs) can be utilizedfor solving complex sequential decision-making tasks by providing high-levelinstructions. However, LLM-based agents face limitations in real-time dynamicenvironments due to their lack of specialization in solving specific targetproblems. Moreover, the deployment of such LLM-based agents is both costly andtime-consuming in practical scenarios. In this paper, we introduce a novelframework that addresses these challenges by training a smaller scalespecialized student agent using instructions from an LLM-based teacher agent.By leveraging guided actions provided by the teachers, the prior knowledge ofthe LLM is distilled into the local student model. Consequently, the studentagent can be trained with significantly less data. Furthermore, subsequenttraining with environment feedback empowers the student agents to surpass thecapabilities of their teachers. We conducted experiments on three challengingMiniGrid environments to evaluate the effectiveness of our framework. Theresults demonstrate that our approach enhances sample efficiency and achievessuperior performance compared to baseline methods.</description><author>Zihao Zhou, Bin Hu, Pu Zhang, Chenyang Zhao, Bin Liu</author><pubDate>Wed, 22 Nov 2023 13:15:42 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.13373v1</guid></item><item><title>MRGazer: Decoding Eye Gaze Points from Functional Magnetic Resonance Imaging in Individual Space</title><link>http://arxiv.org/abs/2311.13372v1</link><description>Eye-tracking research has proven valuable in understanding numerous cognitivefunctions. Recently, Frey et al. provided an exciting deep learning method forlearning eye movements from fMRI data. However, it needed to co-register fMRIinto standard space to obtain eyeballs masks, and thus required additionaltemplates and was time consuming. To resolve this issue, in this paper, wepropose a framework named MRGazer for predicting eye gaze points from fMRI inindividual space. The MRGazer consisted of eyeballs extraction module and aresidual network-based eye gaze prediction. Compared to the previous method,the proposed framework skips the fMRI co-registration step, simplifies theprocessing protocol and achieves end-to-end eye gaze regression. The proposedmethod achieved superior performance in a variety of eye movement tasks thanthe co-registration-based method, and delivered objective results within ashorter time (~ 0.02 Seconds for each volume) than prior method (~0.3 Secondsfor each volume).</description><author>Xiuwen Wu, Rongjie Hu, Jie Liang, Yanming Wang, Bensheng Qiu, Xiaoxiao Wang</author><pubDate>Wed, 22 Nov 2023 13:13:19 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.13372v1</guid></item><item><title>Droplets of Good Representations: Grokking as a First Order Phase Transition in Two Layer Networks</title><link>http://arxiv.org/abs/2310.03789v2</link><description>A key property of deep neural networks (DNNs) is their ability to learn newfeatures during training. This intriguing aspect of deep learning stands outmost clearly in recently reported Grokking phenomena. While mainly reflected asa sudden increase in test accuracy, Grokking is also believed to be a beyondlazy-learning/Gaussian Process (GP) phenomenon involving feature learning. Herewe apply a recent development in the theory of feature learning, the adaptivekernel approach, to two teacher-student models with cubic-polynomial andmodular addition teachers. We provide analytical predictions on featurelearning and Grokking properties of these models and demonstrate a mappingbetween Grokking and the theory of phase transitions. We show that afterGrokking, the state of the DNN is analogous to the mixed phase following afirst-order phase transition. In this mixed phase, the DNN generates usefulinternal representations of the teacher that are sharply distinct from thosebefore the transition.</description><author>Noa Rubin, Inbar Seroussi, Zohar Ringel</author><pubDate>Wed, 22 Nov 2023 12:55:08 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.03789v2</guid></item><item><title>Applying Large Language Models to Power Systems: Potential Security Threats</title><link>http://arxiv.org/abs/2311.13361v1</link><description>Applying large language models (LLMs) to power systems presents a promisingavenue for enhancing decision-making and operational efficiency. However, thisaction may also incur potential security threats, which have not been fullyrecognized so far. To this end, this letter analyzes potential threats incurredby applying LLMs to power systems, emphasizing the need for urgent research anddevelopment of countermeasures.</description><author>Jiaqi Ruan, Gaoqi Liang, Huan Zhao, Guolong Liu, Jing Qiu, Junhua Zhao, Zhao Xu, Fushuan Wen, Zhao Yang Dong</author><pubDate>Wed, 22 Nov 2023 12:55:02 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.13361v1</guid></item><item><title>Discrete approximations of Gaussian smoothing and Gaussian derivatives</title><link>http://arxiv.org/abs/2311.11317v2</link><description>This paper develops an in-depth treatment concerning the problem ofapproximating the Gaussian smoothing and Gaussian derivative computations inscale-space theory for application on discrete data. With close connections toprevious axiomatic treatments of continuous and discrete scale-space theory, weconsider three main ways discretizing these scale-space operations in terms ofexplicit discrete convolutions, based on either (i) sampling the Gaussiankernels and the Gaussian derivative kernels, (ii) locally integrating theGaussian kernels and the Gaussian derivative kernels over each pixel supportregion and (iii) basing the scale-space analysis on the discrete analogue ofthe Gaussian kernel, and then computing derivative approximations by applyingsmall-support central difference operators to the spatially smoothed imagedata. We study the properties of these three main discretization methods boththeoretically and experimentally, and characterize their performance byquantitative measures, including the results they give rise to with respect tothe task of scale selection, investigated for four different use cases, andwith emphasis on the behaviour at fine scales. The results show that thesampled Gaussian kernels and derivatives as well as the integrated Gaussiankernels and derivatives perform very poorly at very fine scales. At very finescales, the discrete analogue of the Gaussian kernel with its correspondingdiscrete derivative approximations performs substantially better. The sampledGaussian kernel and the sampled Gaussian derivatives do, on the other hand,lead to numerically very good approximations of the corresponding continuousresults, when the scale parameter is sufficiently large, in the experimentspresented in the paper, when the scale parameter is greater than a value ofabout 1, in units of the grid spacing.</description><author>Tony Lindeberg</author><pubDate>Wed, 22 Nov 2023 12:52:41 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.11317v2</guid></item><item><title>Uncertainty Estimation in Multi-Agent Distributed Learning</title><link>http://arxiv.org/abs/2311.13356v1</link><description>Traditionally, IoT edge devices have been perceived primarily as low-powercomponents with limited capabilities for autonomous operations. Yet, withemerging advancements in embedded AI hardware design, a foundational shiftpaves the way for future possibilities. Thus, the aim of the KDT NEUROKIT2Eproject is to establish a new open-source framework to further facilitate AIapplications on edge devices by developing new methods in quantization,pruning-aware training, and sparsification. These innovations hold thepotential to expand the functional range of such devices considerably, enablingthem to manage complex Machine Learning (ML) tasks utilizing local resourcesand laying the groundwork for innovative learning approaches. In the context of 6G's transformative potential, distributed learning amongindependent agents emerges as a pivotal application, attributed to 6G networks'support for ultra-reliable low-latency communication, enhanced data rates, andadvanced edge computing capabilities. Our research focuses on the mechanisms and methodologies that allow edgenetwork-enabled agents to engage in collaborative learning in distributedenvironments. Particularly, one of the key issues within distributedcollaborative learning is determining the degree of confidence in the learningresults, considering the spatio-temporal locality of data sets perceived byindependent agents.</description><author>Gleb Radchenko, Victoria Andrea Fill</author><pubDate>Wed, 22 Nov 2023 12:48:20 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.13356v1</guid></item><item><title>Unified Classification and Rejection: A One-versus-All Framework</title><link>http://arxiv.org/abs/2311.13355v1</link><description>Classifying patterns of known classes and rejecting ambiguous and novel (alsocalled as out-of-distribution (OOD)) inputs are involved in open world patternrecognition. Deep neural network models usually excel in closed-setclassification while performing poorly in rejecting OOD. To tackle thisproblem, numerous methods have been designed to perform open set recognition(OSR) or OOD rejection/detection tasks. Previous methods mostly takepost-training score transformation or hybrid models to ensure low scores on OODinputs while separating known classes. In this paper, we attempt to build aunified framework for building open set classifiers for both classification andOOD rejection. We formulate the open set recognition of $ K $-known-class as a$ (K + 1) $-class classification problem with model trained on known-classsamples only. By decomposing the $ K $-class problem into $ K $ one-versus-all(OVA) binary classification tasks and binding some parameters, we show thatcombining the scores of OVA classifiers can give $ (K + 1) $-class posteriorprobabilities, which enables classification and OOD rejection in a unifiedframework. To maintain the closed-set classification accuracy of the OVAtrained classifier, we propose a hybrid training strategy combining OVA lossand multi-class cross-entropy loss. We implement the OVA framework and hybridtraining strategy on the recently proposed convolutional prototype network.Experiments on popular OSR and OOD detection datasets demonstrate that theproposed framework, using a single multi-class classifier, yields competitiveperformance in closed-set classification, OOD detection, and misclassificationdetection.</description><author>Zhen Cheng, Xu-Yao Zhang, Cheng-Lin Liu</author><pubDate>Wed, 22 Nov 2023 12:47:12 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.13355v1</guid></item><item><title>Fact-based Court Judgment Prediction</title><link>http://arxiv.org/abs/2311.13350v1</link><description>This extended abstract extends the research presented in "ILDC for CJPE:Indian Legal Documents Corpus for Court Judgment Prediction and Explanation"\cite{malik-etal-2021-ildc}, focusing on fact-based judgment prediction withinthe context of Indian legal documents. We introduce two distinct problemvariations: one based solely on facts, and another combining facts with rulingsfrom lower courts (RLC). Our research aims to enhance early-phase case outcomeprediction, offering significant benefits to legal professionals and thegeneral public. The results, however, indicated a performance decline comparedto the original ILDC for CJPE study, even after implementing various weightageschemes in our DELSumm algorithm. Additionally, using only facts for legaljudgment prediction with different transformer models yielded results inferiorto the state-of-the-art outcomes reported in the "ILDC for CJPE" study.</description><author>Shubham Kumar Nigam, Aniket Deroy</author><pubDate>Wed, 22 Nov 2023 12:39:28 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.13350v1</guid></item><item><title>Efficient Vision Transformer for Human Pose Estimation via Patch Selection</title><link>http://arxiv.org/abs/2306.04225v2</link><description>While Convolutional Neural Networks (CNNs) have been widely successful in 2Dhuman pose estimation, Vision Transformers (ViTs) have emerged as a promisingalternative to CNNs, boosting state-of-the-art performance. However, thequadratic computational complexity of ViTs has limited their applicability forprocessing high-resolution images. In this paper, we propose three methods forreducing ViT's computational complexity, which are based on selecting andprocessing a small number of most informative patches while disregardingothers. The first two methods leverage a lightweight pose estimation network toguide the patch selection process, while the third method utilizes a set oflearnable joint tokens to ensure that the selected patches contain the mostimportant information about body joints. Experiments across six benchmarks showthat our proposed methods achieve a significant reduction in computationalcomplexity, ranging from 30% to 44%, with only a minimal drop in accuracybetween 0% and 3.5%.</description><author>Kaleab A. Kinfu, Rene Vidal</author><pubDate>Wed, 22 Nov 2023 12:35:08 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.04225v2</guid></item><item><title>REDS: Resource-Efficient Deep Subnetworks for Dynamic Resource Constraints</title><link>http://arxiv.org/abs/2311.13349v1</link><description>Deep models deployed on edge devices frequently encounter resourcevariability, which arises from fluctuating energy levels, timing constraints,or prioritization of other critical tasks within the system. State-of-the-artmachine learning pipelines generate resource-agnostic models, not capable toadapt at runtime. In this work we introduce Resource-Efficient Deep Subnetworks(REDS) to tackle model adaptation to variable resources. In contrast to thestate-of-the-art, REDS use structured sparsity constructively by exploitingpermutation invariance of neurons, which allows for hardware-specificoptimizations. Specifically, REDS achieve computational efficiency by (1)skipping sequential computational blocks identified by a novel iterativeknapsack optimizer, and (2) leveraging simple math to re-arrange the order ofoperations in REDS computational graph to take advantage of the data cache.REDS support conventional deep networks frequently deployed on the edge andprovide computational benefits even for small and simple networks. We evaluateREDS on six benchmark architectures trained on the Google Speech Commands,FMNIST and CIFAR10 datasets, and test on four off-the-shelf mobile and embeddedhardware platforms. We provide a theoretical result and empirical evidence forREDS outstanding performance in terms of submodels' test set accuracy, anddemonstrate an adaptation time in response to dynamic resource constraints ofunder 40$\mu$s, utilizing a 2-layer fully-connected network on Arduino Nano 33BLE Sense.</description><author>Francesco Corti, Balz Maag, Joachim Schauer, Ulrich Pferschy, Olga Saukh</author><pubDate>Wed, 22 Nov 2023 12:34:51 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.13349v1</guid></item><item><title>Predict, Refine, Synthesize: Self-Guiding Diffusion Models for Probabilistic Time Series Forecasting</title><link>http://arxiv.org/abs/2307.11494v3</link><description>Diffusion models have achieved state-of-the-art performance in generativemodeling tasks across various domains. Prior works on time series diffusionmodels have primarily focused on developing conditional models tailored tospecific forecasting or imputation tasks. In this work, we explore thepotential of task-agnostic, unconditional diffusion models for several timeseries applications. We propose TSDiff, an unconditionally-trained diffusionmodel for time series. Our proposed self-guidance mechanism enablesconditioning TSDiff for downstream tasks during inference, without requiringauxiliary networks or altering the training procedure. We demonstrate theeffectiveness of our method on three different time series tasks: forecasting,refinement, and synthetic data generation. First, we show that TSDiff iscompetitive with several task-specific conditional forecasting methods(predict). Second, we leverage the learned implicit probability density ofTSDiff to iteratively refine the predictions of base forecasters with reducedcomputational overhead over reverse diffusion (refine). Notably, the generativeperformance of the model remains intact -- downstream forecasters trained onsynthetic samples from TSDiff outperform forecasters that are trained onsamples from other state-of-the-art generative time series models, occasionallyeven outperforming models trained on real data (synthesize).</description><author>Marcel Kollovieh, Abdul Fatir Ansari, Michael Bohlke-Schneider, Jasper Zschiegner, Hao Wang, Yuyang Wang</author><pubDate>Wed, 22 Nov 2023 12:25:41 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.11494v3</guid></item></channel></rss>