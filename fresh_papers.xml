<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/"><channel><title>Arxivfresh papers</title><link></link><description>Arxiv paper</description><language>en-US</language><lastBuildDate>Fri, 07 Jun 2024 06:00:33 GMT</lastBuildDate><generator>rfeed v1.0.0</generator><docs>https://github.com/svpino/rfeed/blob/master/README.md</docs><item><title>Stereo-Depth Fusion through Virtual Pattern Projection</title><link>http://arxiv.org/abs/2406.04345v1</link><description>This paper presents a novel general-purpose stereo and depth data fusionparadigm that mimics the active stereo principle by replacing the unreliablephysical pattern projector with a depth sensor. It works by projecting virtualpatterns consistent with the scene geometry onto the left and right imagesacquired by a conventional stereo camera, using the sparse hints obtained froma depth sensor, to facilitate the visual correspondence. Purposely, any depthsensing device can be seamlessly plugged into our framework, enabling thedeployment of a virtual active stereo setup in any possible environment andovercoming the severe limitations of physical pattern projection, such as thelimited working range and environmental conditions. Exhaustive experiments onindoor and outdoor datasets featuring both long and close range, includingthose providing raw, unfiltered depth hints from off-the-shelf depth sensors,highlight the effectiveness of our approach in notably boosting the robustnessand accuracy of algorithms and deep stereo without any code modification andeven without re-training. Additionally, we assess the performance of ourstrategy on active stereo evaluation datasets with conventional patternprojection. Indeed, in all these scenarios, our virtual pattern projectionparadigm achieves state-of-the-art performance. The source code is availableat: https://github.com/bartn8/vppstereo.</description><author>Luca Bartolomei, Matteo Poggi, Fabio Tosi, Andrea Conti, Stefano Mattoccia</author><pubDate>Thu, 06 Jun 2024 18:59:58 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.04345v1</guid></item><item><title>Learning 1D Causal Visual Representation with De-focus Attention Networks</title><link>http://arxiv.org/abs/2406.04342v1</link><description>Modality differences have led to the development of heterogeneousarchitectures for vision and language models. While images typically require 2Dnon-causal modeling, texts utilize 1D causal modeling. This distinction posessignificant challenges in constructing unified multi-modal models. This paperexplores the feasibility of representing images using 1D causal modeling. Weidentify an "over-focus" issue in existing 1D causal vision models, whereattention overly concentrates on a small proportion of visual tokens. The issueof "over-focus" hinders the model's ability to extract diverse visual featuresand to receive effective gradients for optimization. To address this, wepropose De-focus Attention Networks, which employ learnable bandpass filters tocreate varied attention patterns. During training, large and scheduled droppath rates, and an auxiliary loss on globally pooled features for globalunderstanding tasks are introduced. These two strategies encourage the model toattend to a broader range of tokens and enhance network optimization. Extensiveexperiments validate the efficacy of our approach, demonstrating that 1D causalvisual representation can perform comparably to 2D non-causal representation intasks such as global perception, dense prediction, and multi-modalunderstanding. Code is released athttps://github.com/OpenGVLab/De-focus-Attention-Networks.</description><author>Chenxin Tao, Xizhou Zhu, Shiqian Su, Lewei Lu, Changyao Tian, Xuan Luo, Gao Huang, Hongsheng Li, Yu Qiao, Jie Zhou, Jifeng Dai</author><pubDate>Thu, 06 Jun 2024 18:59:56 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.04342v1</guid></item><item><title>Verbalized Machine Learning: Revisiting Machine Learning with Language Models</title><link>http://arxiv.org/abs/2406.04344v1</link><description>Motivated by the large progress made by large language models (LLMs), weintroduce the framework of verbalized machine learning (VML). In contrast toconventional machine learning models that are typically optimized over acontinuous parameter space, VML constrains the parameter space to behuman-interpretable natural language. Such a constraint leads to a newperspective of function approximation, where an LLM with a text prompt can beviewed as a function parameterized by the text prompt. Guided by thisperspective, we revisit classical machine learning problems, such as regressionand classification, and find that these problems can be solved by anLLM-parameterized learner and optimizer. The major advantages of VML include(1) easy encoding of inductive bias: prior knowledge about the problem andhypothesis class can be encoded in natural language and fed into theLLM-parameterized learner; (2) automatic model class selection: the optimizercan automatically select a concrete model class based on data and verbalizedprior knowledge, and it can update the model class during training; and (3)interpretable learner updates: the LLM-parameterized optimizer can provideexplanations for why each learner update is performed. We conduct severalstudies to empirically evaluate the effectiveness of VML, and hope that VML canserve as a stepping stone to stronger interpretability and trustworthiness inML.</description><author>Tim Z. Xiao, Robert Bamler, Bernhard Schölkopf, Weiyang Liu</author><pubDate>Thu, 06 Jun 2024 18:59:56 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.04344v1</guid></item><item><title>Flash3D: Feed-Forward Generalisable 3D Scene Reconstruction from a Single Image</title><link>http://arxiv.org/abs/2406.04343v1</link><description>In this paper, we propose Flash3D, a method for scene reconstruction andnovel view synthesis from a single image which is both very generalisable andefficient. For generalisability, we start from a "foundation" model formonocular depth estimation and extend it to a full 3D shape and appearancereconstructor. For efficiency, we base this extension on feed-forward GaussianSplatting. Specifically, we predict a first layer of 3D Gaussians at thepredicted depth, and then add additional layers of Gaussians that are offset inspace, allowing the model to complete the reconstruction behind occlusions andtruncations. Flash3D is very efficient, trainable on a single GPU in a day, andthus accessible to most researchers. It achieves state-of-the-art results whentrained and tested on RealEstate10k. When transferred to unseen datasets likeNYU it outperforms competitors by a large margin. More impressively, whentransferred to KITTI, Flash3D achieves better PSNR than methods trainedspecifically on that dataset. In some instances, it even outperforms recentmethods that use multiple views as input. Code, models, demo, and more resultsare available at https://www.robots.ox.ac.uk/~vgg/research/flash3d/.</description><author>Stanislaw Szymanowicz, Eldar Insafutdinov, Chuanxia Zheng, Dylan Campbell, João F. Henriques, Christian Rupprecht, Andrea Vedaldi</author><pubDate>Thu, 06 Jun 2024 18:59:56 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.04343v1</guid></item><item><title>Interpreting the Second-Order Effects of Neurons in CLIP</title><link>http://arxiv.org/abs/2406.04341v1</link><description>We interpret the function of individual neurons in CLIP by automaticallydescribing them using text. Analyzing the direct effects (i.e. the flow from aneuron through the residual stream to the output) or the indirect effects(overall contribution) fails to capture the neurons' function in CLIP.Therefore, we present the "second-order lens", analyzing the effect flowingfrom a neuron through the later attention heads, directly to the output. Wefind that these effects are highly selective: for each neuron, the effect issignificant for &lt;2% of the images. Moreover, each effect can be approximated bya single direction in the text-image space of CLIP. We describe neurons bydecomposing these directions into sparse sets of text representations. The setsreveal polysemantic behavior - each neuron corresponds to multiple, oftenunrelated, concepts (e.g. ships and cars). Exploiting this neuron polysemy, wemass-produce "semantic" adversarial examples by generating images with conceptsspuriously correlated to the incorrect class. Additionally, we use thesecond-order effects for zero-shot segmentation and attribute discovery inimages. Our results indicate that a scalable understanding of neurons can beused for model deception and for introducing new model capabilities.</description><author>Yossi Gandelsman, Alexei A. Efros, Jacob Steinhardt</author><pubDate>Thu, 06 Jun 2024 18:59:52 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.04341v1</guid></item><item><title>GLACE: Global Local Accelerated Coordinate Encoding</title><link>http://arxiv.org/abs/2406.04340v1</link><description>Scene coordinate regression (SCR) methods are a family of visual localizationmethods that directly regress 2D-3D matches for camera pose estimation. Theyare effective in small-scale scenes but face significant challenges inlarge-scale scenes that are further amplified in the absence of ground truth 3Dpoint clouds for supervision. Here, the model can only rely on reprojectionconstraints and needs to implicitly triangulate the points. The challenges stemfrom a fundamental dilemma: The network has to be invariant to observations ofthe same landmark at different viewpoints and lighting conditions, etc., but atthe same time discriminate unrelated but similar observations. The latterbecomes more relevant and severe in larger scenes. In this work, we tackle thisproblem by introducing the concept of co-visibility to the network. We proposeGLACE, which integrates pre-trained global and local encodings and enables SCRto scale to large scenes with only a single small-sized network. Specifically,we propose a novel feature diffusion technique that implicitly groups thereprojection constraints with co-visibility and avoids overfitting to trivialsolutions. Additionally, our position decoder parameterizes the outputpositions for large-scale scenes more effectively. Without using 3D models ordepth maps for supervision, our method achieves state-of-the-art results onlarge-scale scenes with a low-map-size model. On Cambridge landmarks, with asingle model, we achieve 17% lower median position error than Poker, theensemble variant of the state-of-the-art SCR method ACE. Code is available at:https://github.com/cvg/glace.</description><author>Fangjinhua Wang, Xudong Jiang, Silvano Galliani, Christoph Vogel, Marc Pollefeys</author><pubDate>Thu, 06 Jun 2024 18:59:50 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.04340v1</guid></item><item><title>RoboMamba: Multimodal State Space Model for Efficient Robot Reasoning and Manipulation</title><link>http://arxiv.org/abs/2406.04339v1</link><description>A fundamental objective in robot manipulation is to enable models tocomprehend visual scenes and execute actions. Although existing robotMultimodal Large Language Models (MLLMs) can handle a range of basic tasks,they still face challenges in two areas: 1) inadequate reasoning ability totackle complex tasks, and 2) high computational costs for MLLM fine-tuning andinference. The recently proposed state space model (SSM) known as Mambademonstrates promising capabilities in non-trivial sequence modeling withlinear inference complexity. Inspired by this, we introduce RoboMamba, anend-to-end robotic MLLM that leverages the Mamba model to deliver both roboticreasoning and action capabilities, while maintaining efficient fine-tuning andinference. Specifically, we first integrate the vision encoder with Mamba,aligning visual data with language embedding through co-training, empoweringour model with visual common sense and robot-related reasoning. To furtherequip RoboMamba with action pose prediction abilities, we explore an efficientfine-tuning strategy with a simple policy head. We find that once RoboMambapossesses sufficient reasoning capability, it can acquire manipulation skillswith minimal fine-tuning parameters (0.1\% of the model) and time (20 minutes).In experiments, RoboMamba demonstrates outstanding reasoning capabilities ongeneral and robotic evaluation benchmarks. Meanwhile, our model showcasesimpressive pose prediction results in both simulation and real-worldexperiments, achieving inference speeds 7 times faster than existing robotMLLMs. Our project web page: https://sites.google.com/view/robomamba-web</description><author>Jiaming Liu, Mengzhen Liu, Zhenyu Wang, Lily Lee, Kaichen Zhou, Pengju An, Senqiao Yang, Renrui Zhang, Yandong Guo, Shanghang Zhang</author><pubDate>Thu, 06 Jun 2024 18:59:47 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.04339v1</guid></item><item><title>Physics3D: Learning Physical Properties of 3D Gaussians via Video Diffusion</title><link>http://arxiv.org/abs/2406.04338v1</link><description>In recent years, there has been rapid development in 3D generation models,opening up new possibilities for applications such as simulating the dynamicmovements of 3D objects and customizing their behaviors. However, current 3Dgenerative models tend to focus only on surface features such as color andshape, neglecting the inherent physical properties that govern the behavior ofobjects in the real world. To accurately simulate physics-aligned dynamics, itis essential to predict the physical properties of materials and incorporatethem into the behavior prediction process. Nonetheless, predicting the diversematerials of real-world objects is still challenging due to the complex natureof their physical attributes. In this paper, we propose \textbf{Physics3D}, anovel method for learning various physical properties of 3D objects through avideo diffusion model. Our approach involves designing a highly generalizablephysical simulation system based on a viscoelastic material model, whichenables us to simulate a wide range of materials with high-fidelitycapabilities. Moreover, we distill the physical priors from a video diffusionmodel that contains more understanding of realistic object materials. Extensiveexperiments demonstrate the effectiveness of our method with both elastic andplastic materials. Physics3D shows great potential for bridging the gap betweenthe physical world and virtual neural space, providing a better integration andapplication of realistic physical principles in virtual environments. Projectpage: https://liuff19.github.io/Physics3D.</description><author>Fangfu Liu, Hanyang Wang, Shunyu Yao, Shengjun Zhang, Jie Zhou, Yueqi Duan</author><pubDate>Thu, 06 Jun 2024 18:59:47 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.04338v1</guid></item><item><title>Coherent Zero-Shot Visual Instruction Generation</title><link>http://arxiv.org/abs/2406.04337v1</link><description>Despite the advances in text-to-image synthesis, particularly with diffusionmodels, generating visual instructions that require consistent representationand smooth state transitions of objects across sequential steps remains aformidable challenge. This paper introduces a simple, training-free frameworkto tackle the issues, capitalizing on the advancements in diffusion models andlarge language models (LLMs). Our approach systematically integrates textcomprehension and image generation to ensure visual instructions are visuallyappealing and maintain consistency and accuracy throughout the instructionsequence. We validate the effectiveness by testing multi-step instructions andcomparing the text alignment and consistency with several baselines. Ourexperiments show that our approach can visualize coherent and visually pleasinginstructions</description><author>Quynh Phung, Songwei Ge, Jia-Bin Huang</author><pubDate>Thu, 06 Jun 2024 18:59:44 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.04337v1</guid></item><item><title>On the Expressive Power of Spectral Invariant Graph Neural Networks</title><link>http://arxiv.org/abs/2406.04336v1</link><description>Incorporating spectral information to enhance Graph Neural Networks (GNNs)has shown promising results but raises a fundamental challenge due to theinherent ambiguity of eigenvectors. Various architectures have been proposed toaddress this ambiguity, referred to as spectral invariant architectures.Notable examples include GNNs and Graph Transformers that use spectraldistances, spectral projection matrices, or other invariant spectral features.However, the potential expressive power of these spectral invariantarchitectures remains largely unclear. The goal of this work is to gain a deeptheoretical understanding of the expressive power obtainable when usingspectral features. We first introduce a unified message-passing framework fordesigning spectral invariant GNNs, called Eigenspace Projection GNN (EPNN). Acomprehensive analysis shows that EPNN essentially unifies all prior spectralinvariant architectures, in that they are either strictly less expressive orequivalent to EPNN. A fine-grained expressiveness hierarchy among differentarchitectures is also established. On the other hand, we prove that EPNN itselfis bounded by a recently proposed class of Subgraph GNNs, implying that allthese spectral invariant architectures are strictly less expressive than 3-WL.Finally, we discuss whether using spectral features can gain additionalexpressiveness when combined with more expressive GNNs.</description><author>Bohang Zhang, Lingxiao Zhao, Haggai Maron</author><pubDate>Thu, 06 Jun 2024 18:59:41 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.04336v1</guid></item><item><title>Subhomogeneous Deep Equilibrium Models</title><link>http://arxiv.org/abs/2403.00720v2</link><description>Implicit-depth neural networks have grown as powerful alternatives totraditional networks in various applications in recent years. However, thesemodels often lack guarantees of existence and uniqueness, raising stability,performance, and reproducibility issues. In this paper, we present a newanalysis of the existence and uniqueness of fixed points for implicit-depthneural networks based on the concept of subhomogeneous operators and thenonlinear Perron-Frobenius theory. Compared to previous similar analyses, ourtheory allows for weaker assumptions on the parameter matrices, thus yielding amore flexible framework for well-defined implicit networks. We illustrate theperformance of the resulting subhomogeneous networks on feedforward,convolutional, and graph neural network examples.</description><author>Pietro Sittoni, Francesco Tudisco</author><pubDate>Thu, 06 Jun 2024 18:59:38 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.00720v2</guid></item><item><title>DeepStack: Deeply Stacking Visual Tokens is Surprisingly Simple and Effective for LMMs</title><link>http://arxiv.org/abs/2406.04334v1</link><description>Most large multimodal models (LMMs) are implemented by feeding visual tokensas a sequence into the first layer of a large language model (LLM). Theresulting architecture is simple but significantly increases computation andmemory costs, as it has to handle a large number of additional tokens in itsinput layer. This paper presents a new architecture DeepStack for LMMs.Considering $N$ layers in the language and vision transformer of LMMs, we stackthe visual tokens into $N$ groups and feed each group to its alignedtransformer layer \textit{from bottom to top}. Surprisingly, this simple methodgreatly enhances the power of LMMs to model interactions among visual tokensacross layers but with minimal additional cost. We apply DeepStack to bothlanguage and vision transformer in LMMs, and validate the effectiveness ofDeepStack LMMs with extensive empirical results. Using the same context length,our DeepStack 7B and 13B parameters surpass their counterparts by \textbf{2.7}and \textbf{2.9} on average across \textbf{9} benchmarks, respectively. Usingonly one-fifth of the context length, DeepStack rivals closely to thecounterparts that use the full context length. These gains are particularlypronounced on high-resolution tasks, e.g., \textbf{4.2}, \textbf{11.0}, and\textbf{4.0} improvements on TextVQA, DocVQA, and InfoVQA compared toLLaVA-1.5-7B, respectively. We further apply DeepStack to vision transformerlayers, which brings us a similar amount of improvements, \textbf{3.8} onaverage compared with LLaVA-1.5-7B.</description><author>Lingchen Meng, Jianwei Yang, Rui Tian, Xiyang Dai, Zuxuan Wu, Jianfeng Gao, Yu-Gang Jiang</author><pubDate>Thu, 06 Jun 2024 18:59:34 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.04334v1</guid></item><item><title>BitsFusion: 1.99 bits Weight Quantization of Diffusion Model</title><link>http://arxiv.org/abs/2406.04333v1</link><description>Diffusion-based image generation models have achieved great success in recentyears by showing the capability of synthesizing high-quality content. However,these models contain a huge number of parameters, resulting in a significantlylarge model size. Saving and transferring them is a major bottleneck forvarious applications, especially those running on resource-constrained devices.In this work, we develop a novel weight quantization method that quantizes theUNet from Stable Diffusion v1.5 to 1.99 bits, achieving a model with 7.9Xsmaller size while exhibiting even better generation quality than the originalone. Our approach includes several novel techniques, such as assigning optimalbits to each layer, initializing the quantized model for better performance,and improving the training strategy to dramatically reduce quantization error.Furthermore, we extensively evaluate our quantized model across variousbenchmark datasets and through human evaluation to demonstrate its superiorgeneration quality.</description><author>Yang Sui, Yanyu Li, Anil Kag, Yerlan Idelbayev, Junli Cao, Ju Hu, Dhritiman Sagar, Bo Yuan, Sergey Tulyakov, Jian Ren</author><pubDate>Thu, 06 Jun 2024 18:59:23 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.04333v1</guid></item><item><title>Coarse-To-Fine Tensor Trains for Compact Visual Representations</title><link>http://arxiv.org/abs/2406.04332v1</link><description>The ability to learn compact, high-quality, and easy-to-optimizerepresentations for visual data is paramount to many applications such as novelview synthesis and 3D reconstruction. Recent work has shown substantial successin using tensor networks to design such compact and high-qualityrepresentations. However, the ability to optimize tensor-based representations,and in particular, the highly compact tensor train representation, is stilllacking. This has prevented practitioners from deploying the full potential oftensor networks for visual data. To this end, we propose 'ProlongationUpsampling Tensor Train (PuTT)', a novel method for learning tensor trainrepresentations in a coarse-to-fine manner. Our method involves the prolongingor `upsampling' of a learned tensor train representation, creating a sequenceof 'coarse-to-fine' tensor trains that are incrementally refined. We evaluateour representation along three axes: (1). compression, (2). denoisingcapability, and (3). image completion capability. To assess these axes, weconsider the tasks of image fitting, 3D fitting, and novel view synthesis,where our method shows an improved performance compared to state-of-the-arttensor-based methods. For full results see our project webpage:https://sebulo.github.io/PuTT_website/</description><author>Sebastian Loeschcke, Dan Wang, Christian Leth-Espensen, Serge Belongie, Michael J. Kastoryano, Sagie Benaim</author><pubDate>Thu, 06 Jun 2024 18:59:23 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.04332v1</guid></item><item><title>Parameter-Inverted Image Pyramid Networks</title><link>http://arxiv.org/abs/2406.04330v1</link><description>Image pyramids are commonly used in modern computer vision tasks to obtainmulti-scale features for precise understanding of images. However, imagepyramids process multiple resolutions of images using the same large-scalemodel, which requires significant computational cost. To overcome this issue,we propose a novel network architecture known as the Parameter-Inverted ImagePyramid Networks (PIIP). Our core idea is to use models with differentparameter sizes to process different resolution levels of the image pyramid,thereby balancing computational efficiency and performance. Specifically, theinput to PIIP is a set of multi-scale images, where higher resolution imagesare processed by smaller networks. We further propose a feature interactionmechanism to allow features of different resolutions to complement each otherand effectively integrate information from different spatial scales. Extensiveexperiments demonstrate that the PIIP achieves superior performance in taskssuch as object detection, segmentation, and image classification, compared totraditional image pyramid methods and single-branch networks, while reducingcomputational cost. Notably, when applying our method on a large-scale visionfoundation model InternViT-6B, we improve its performance by 1%-2% on detectionand segmentation with only 40%-60% of the original computation. These resultsvalidate the effectiveness of the PIIP approach and provide a new technicaldirection for future vision computing tasks. Our code and models are availableat https://github.com/OpenGVLab/PIIP.</description><author>Xizhou Zhu, Xue Yang, Zhaokai Wang, Hao Li, Wenhan Dou, Junqi Ge, Lewei Lu, Yu Qiao, Jifeng Dai</author><pubDate>Thu, 06 Jun 2024 18:59:10 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.04330v1</guid></item><item><title>PaCE: Parsimonious Concept Engineering for Large Language Models</title><link>http://arxiv.org/abs/2406.04331v1</link><description>Large Language Models (LLMs) are being used for a wide variety of tasks.While they are capable of generating human-like responses, they can alsoproduce undesirable output including potentially harmful information, racist orsexist language, and hallucinations. Alignment methods are designed to reducesuch undesirable output, via techniques such as fine-tuning, promptengineering, and representation engineering. However, existing methods faceseveral challenges: some require costly fine-tuning for every alignment task;some do not adequately remove undesirable concepts, failing alignment; someremove benign concepts, lowering the linguistic capabilities of LLMs. Toaddress these issues, we propose Parsimonious Concept Engineering (PaCE), anovel activation engineering framework for alignment. First, to sufficientlymodel the concepts, we construct a large-scale concept dictionary in theactivation space, in which each atom corresponds to a semantic concept. Then,given any alignment task, we instruct a concept partitioner to efficientlyannotate the concepts as benign or undesirable. Finally, at inference time, wedecompose the LLM activations along the concept dictionary via sparse coding,to accurately represent the activation as a linear combination of the benignand undesirable components. By removing the latter ones from the activation, wereorient the behavior of LLMs towards alignment goals. We conduct experimentson tasks such as response detoxification, faithfulness enhancement, andsentiment revising, and show that PaCE achieves state-of-the-art alignmentperformance while maintaining linguistic capabilities.</description><author>Jinqi Luo, Tianjiao Ding, Kwan Ho Ryan Chan, Darshan Thaker, Aditya Chattopadhyay, Chris Callison-Burch, René Vidal</author><pubDate>Thu, 06 Jun 2024 18:59:10 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.04331v1</guid></item><item><title>Simplified and Generalized Masked Diffusion for Discrete Data</title><link>http://arxiv.org/abs/2406.04329v1</link><description>Masked (or absorbing) diffusion is actively explored as an alternative toautoregressive models for generative modeling of discrete data. However,existing work in this area has been hindered by unnecessarily complex modelformulations and unclear relationships between different perspectives, leadingto suboptimal parameterization, training objectives, and ad hoc adjustments tocounteract these issues. In this work, we aim to provide a simple and generalframework that unlocks the full potential of masked diffusion models. We showthat the continuous-time variational objective of masked diffusion models is asimple weighted integral of cross-entropy losses. Our framework also enablestraining generalized masked diffusion models with state-dependent maskingschedules. When evaluated by perplexity, our models trained on OpenWebTextsurpass prior diffusion language models at GPT-2 scale and demonstrate superiorperformance on 4 out of 5 zero-shot language modeling tasks. Furthermore, ourmodels vastly outperform previous discrete diffusion models on pixel-levelimage modeling, achieving 2.78~(CIFAR-10) and 3.42 (ImageNet 64$\times$64) bitsper dimension that are comparable or better than autoregressive models ofsimilar sizes.</description><author>Jiaxin Shi, Kehang Han, Zhe Wang, Arnaud Doucet, Michalis K. Titsias</author><pubDate>Thu, 06 Jun 2024 18:59:10 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.04329v1</guid></item><item><title>Causal Estimation of Memorisation Profiles</title><link>http://arxiv.org/abs/2406.04327v1</link><description>Understanding memorisation in language models has practical and societalimplications, e.g., studying models' training dynamics or preventing copyrightinfringements. Prior work defines memorisation as the causal effect of trainingwith an instance on the model's ability to predict that instance. Thisdefinition relies on a counterfactual: the ability to observe what would havehappened had the model not seen that instance. Existing methods struggle toprovide computationally efficient and accurate estimates of thiscounterfactual. Further, they often estimate memorisation for a modelarchitecture rather than for a specific model instance. This paper fills animportant gap in the literature, proposing a new, principled, and efficientmethod to estimate memorisation based on the difference-in-differences designfrom econometrics. Using this method, we characterise a model's memorisationprofile--its memorisation trends across training--by only observing itsbehaviour on a small set of instances throughout training. In experiments withthe Pythia model suite, we find that memorisation (i) is stronger and morepersistent in larger models, (ii) is determined by data order and learningrate, and (iii) has stable trends across model sizes, thus making memorisationin larger models predictable from smaller ones.</description><author>Pietro Lesci, Clara Meister, Thomas Hofmann, Andreas Vlachos, Tiago Pimentel</author><pubDate>Thu, 06 Jun 2024 18:59:09 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.04327v1</guid></item><item><title>The Brain's Bitter Lesson: Scaling Speech Decoding With Self-Supervised Learning</title><link>http://arxiv.org/abs/2406.04328v1</link><description>The past few years have produced a series of spectacular advances in thedecoding of speech from brain activity. The engine of these advances has beenthe acquisition of labelled data, with increasingly large datasets acquiredfrom single subjects. However, participants exhibit anatomical and otherindividual differences, and datasets use varied scanners and task designs. As aresult, prior work has struggled to leverage data from multiple subjects,multiple datasets, multiple tasks, and unlabelled datasets. In turn, the fieldhas not benefited from the rapidly growing number of open neural datarepositories to exploit large-scale data and deep learning. To address this, wedevelop an initial set of neuroscience-inspired self-supervised objectives,together with a neural architecture, for representation learning fromheterogeneous and unlabelled neural recordings. Experimental results show thatrepresentations learned with these objectives generalise across subjects,datasets, and tasks, and are also learned faster than using only labelled data.In addition, we set new benchmarks for two foundational speech decoding tasks.Taken together, these methods now unlock the potential for training speechdecoding models with orders of magnitude more existing data.</description><author>Dulhan Jayalath, Gilad Landau, Brendan Shillingford, Mark Woolrich, Oiwi Parker Jones</author><pubDate>Thu, 06 Jun 2024 18:59:09 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.04328v1</guid></item><item><title>ShareGPT4Video: Improving Video Understanding and Generation with Better Captions</title><link>http://arxiv.org/abs/2406.04325v1</link><description>We present the ShareGPT4Video series, aiming to facilitate the videounderstanding of large video-language models (LVLMs) and the video generationof text-to-video models (T2VMs) via dense and precise captions. The seriescomprises: 1) ShareGPT4Video, 40K GPT4V annotated dense captions of videos withvarious lengths and sources, developed through carefully designed datafiltering and annotating strategy. 2) ShareCaptioner-Video, an efficient andcapable captioning model for arbitrary videos, with 4.8M high-quality aestheticvideos annotated by it. 3) ShareGPT4Video-8B, a simple yet superb LVLM thatreached SOTA performance on three advancing video benchmarks. To achieve this,taking aside the non-scalable costly human annotators, we find using GPT4V tocaption video with a naive multi-frame or frame-concatenation input strategyleads to less detailed and sometimes temporal-confused results. We argue thechallenge of designing a high-quality video captioning strategy lies in threeaspects: 1) Inter-frame precise temporal change understanding. 2) Intra-framedetailed content description. 3) Frame-number scalability for arbitrary-lengthvideos. To this end, we meticulously designed a differential video captioningstrategy, which is stable, scalable, and efficient for generating captions forvideos with arbitrary resolution, aspect ratios, and length. Based on it, weconstruct ShareGPT4Video, which contains 40K high-quality videos spanning awide range of categories, and the resulting captions encompass rich worldknowledge, object attributes, camera movements, and crucially, detailed andprecise temporal descriptions of events. Based on ShareGPT4Video, we furtherdevelop ShareCaptioner-Video, a superior captioner capable of efficientlygenerating high-quality captions for arbitrary videos...</description><author>Lin Chen, Xilin Wei, Jinsong Li, Xiaoyi Dong, Pan Zhang, Yuhang Zang, Zehui Chen, Haodong Duan, Bin Lin, Zhenyu Tang, Li Yuan, Yu Qiao, Dahua Lin, Feng Zhao, Jiaqi Wang</author><pubDate>Thu, 06 Jun 2024 18:58:54 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.04325v1</guid></item><item><title>Eureka-Moments in Transformers: Multi-Step Tasks Reveal Softmax Induced Optimization Problems</title><link>http://arxiv.org/abs/2310.12956v2</link><description>In this work, we study rapid improvements of the training loss intransformers when being confronted with multi-step decision tasks. We foundthat transformers struggle to learn the intermediate task and both training andvalidation loss saturate for hundreds of epochs. When transformers finallylearn the intermediate task, they do this rapidly and unexpectedly. We callthese abrupt improvements Eureka-moments, since the transformer appears tosuddenly learn a previously incomprehensible concept. We designed synthetictasks to study the problem in detail, but the leaps in performance can beobserved also for language modeling and in-context learning (ICL). We suspectthat these abrupt transitions are caused by the multi-step nature of thesetasks. Indeed, we find connections and show that ways to improve on thesynthetic multi-step tasks can be used to improve the training of languagemodeling and ICL. Using the synthetic data we trace the problem back to theSoftmax function in the self-attention block of transformers and show ways toalleviate the problem. These fixes reduce the required number of trainingsteps, lead to higher likelihood to learn the intermediate task, to higherfinal accuracy and training becomes more robust to hyper-parameters.</description><author>David T. Hoffmann, Simon Schrodi, Jelena Bratulić, Nadine Behrmann, Volker Fischer, Thomas Brox</author><pubDate>Thu, 06 Jun 2024 18:58:45 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.12956v2</guid></item><item><title>SF-V: Single Forward Video Generation Model</title><link>http://arxiv.org/abs/2406.04324v1</link><description>Diffusion-based video generation models have demonstrated remarkable successin obtaining high-fidelity videos through the iterative denoising process.However, these models require multiple denoising steps during sampling,resulting in high computational costs. In this work, we propose a novelapproach to obtain single-step video generation models by leveragingadversarial training to fine-tune pre-trained video diffusion models. We showthat, through the adversarial training, the multi-steps video diffusion model,i.e., Stable Video Diffusion (SVD), can be trained to perform single forwardpass to synthesize high-quality videos, capturing both temporal and spatialdependencies in the video data. Extensive experiments demonstrate that ourmethod achieves competitive generation quality of synthesized videos withsignificantly reduced computational overhead for the denoising process (i.e.,around $23\times$ speedup compared with SVD and $6\times$ speedup compared withexisting works, with even better generation quality), paving the way forreal-time video synthesis and editing. More visualization results are madepublicly available at https://snap-research.github.io/SF-V.</description><author>Zhixing Zhang, Yanyu Li, Yushu Wu, Yanwu Xu, Anil Kag, Ivan Skorokhodov, Willi Menapace, Aliaksandr Siarohin, Junli Cao, Dimitris Metaxas, Sergey Tulyakov, Jian Ren</author><pubDate>Thu, 06 Jun 2024 18:58:27 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.04324v1</guid></item><item><title>ATraDiff: Accelerating Online Reinforcement Learning with Imaginary Trajectories</title><link>http://arxiv.org/abs/2406.04323v1</link><description>Training autonomous agents with sparse rewards is a long-standing problem inonline reinforcement learning (RL), due to low data efficiency. Prior workovercomes this challenge by extracting useful knowledge from offline data,often accomplished through the learning of action distribution from offlinedata and utilizing the learned distribution to facilitate online RL. However,since the offline data are given and fixed, the extracted knowledge isinherently limited, making it difficult to generalize to new tasks. We proposea novel approach that leverages offline data to learn a generative diffusionmodel, coined as Adaptive Trajectory Diffuser (ATraDiff). This model generatessynthetic trajectories, serving as a form of data augmentation and consequentlyenhancing the performance of online RL methods. The key strength of ourdiffuser lies in its adaptability, allowing it to effectively handle varyingtrajectory lengths and mitigate distribution shifts between online and offlinedata. Because of its simplicity, ATraDiff seamlessly integrates with a widespectrum of RL methods. Empirical evaluation shows that ATraDiff consistentlyachieves state-of-the-art performance across a variety of environments, withparticularly pronounced improvements in complicated settings. Our code and demovideo are available at https://atradiff.github.io .</description><author>Qianlan Yang, Yu-Xiong Wang</author><pubDate>Thu, 06 Jun 2024 18:58:15 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.04323v1</guid></item><item><title>DIRECT-3D: Learning Direct Text-to-3D Generation on Massive Noisy 3D Data</title><link>http://arxiv.org/abs/2406.04322v1</link><description>We present DIRECT-3D, a diffusion-based 3D generative model for creatinghigh-quality 3D assets (represented by Neural Radiance Fields) from textprompts. Unlike recent 3D generative models that rely on clean and well-aligned3D data, limiting them to single or few-class generation, our model is directlytrained on extensive noisy and unaligned `in-the-wild' 3D assets, mitigatingthe key challenge (i.e., data scarcity) in large-scale 3D generation. Inparticular, DIRECT-3D is a tri-plane diffusion model that integrates twoinnovations: 1) A novel learning framework where noisy data are filtered andaligned automatically during the training process. Specifically, after aninitial warm-up phase using a small set of clean data, an iterativeoptimization is introduced in the diffusion process to explicitly estimate the3D pose of objects and select beneficial data based on conditional density. 2)An efficient 3D representation that is achieved by disentangling objectgeometry and color features with two separate conditional diffusion models thatare optimized hierarchically. Given a prompt input, our model generateshigh-quality, high-resolution, realistic, and complex 3D objects with accurategeometric details in seconds. We achieve state-of-the-art performance in bothsingle-class generation and text-to-3D generation. We also demonstrate thatDIRECT-3D can serve as a useful 3D geometric prior of objects, for example toalleviate the well-known Janus problem in 2D-lifting methods such asDreamFusion. The code and models are available for research purposes at:https://github.com/qihao067/direct3d.</description><author>Qihao Liu, Yi Zhang, Song Bai, Adam Kortylewski, Alan Yuille</author><pubDate>Thu, 06 Jun 2024 18:58:15 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.04322v1</guid></item><item><title>VidMuse: A Simple Video-to-Music Generation Framework with Long-Short-Term Modeling</title><link>http://arxiv.org/abs/2406.04321v1</link><description>In this work, we systematically study music generation conditioned solely onthe video. First, we present a large-scale dataset comprising 190K video-musicpairs, including various genres such as movie trailers, advertisements, anddocumentaries. Furthermore, we propose VidMuse, a simple framework forgenerating music aligned with video inputs. VidMuse stands out by producinghigh-fidelity music that is both acoustically and semantically aligned with thevideo. By incorporating local and global visual cues, VidMuse enables thecreation of musically coherent audio tracks that consistently match the videocontent through Long-Short-Term modeling. Through extensive experiments,VidMuse outperforms existing models in terms of audio quality, diversity, andaudio-visual alignment. The code and datasets will be available athttps://github.com/ZeyueT/VidMuse/.</description><author>Zeyue Tian, Zhaoyang Liu, Ruibin Yuan, Jiahao Pan, Xiaoqiang Huang, Qifeng Liu, Xu Tan, Qifeng Chen, Wei Xue, Yike Guo</author><pubDate>Thu, 06 Jun 2024 18:58:11 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.04321v1</guid></item><item><title>Chimera: Effectively Modeling Multivariate Time Series with 2-Dimensional State Space Models</title><link>http://arxiv.org/abs/2406.04320v1</link><description>Modeling multivariate time series is a well-established problem with a widerange of applications from healthcare to financial markets. Traditional StateSpace Models (SSMs) are classical approaches for univariate time seriesmodeling due to their simplicity and expressive power to represent lineardependencies. They, however, have fundamentally limited expressive power tocapture non-linear dependencies, are slow in practice, and fail to model theinter-variate information flow. Despite recent attempts to improve theexpressive power of SSMs by using deep structured SSMs, the existing methodsare either limited to univariate time series, fail to model complex patterns(e.g., seasonal patterns), fail to dynamically model the dependencies ofvariate and time dimensions, and/or are input-independent. We present Chimerathat uses two input-dependent 2-D SSM heads with different discretizationprocesses to learn long-term progression and seasonal patterns. To improve theefficiency of complex 2D recurrence, we present a fast training using a new2-dimensional parallel selective scan. We further present and discuss2-dimensional Mamba and Mamba-2 as the spacial cases of our 2D SSM. Ourexperimental evaluation shows the superior performance of Chimera on extensiveand diverse benchmarks, including ECG and speech time series classification,long-term and short-term time series forecasting, and time series anomalydetection.</description><author>Ali Behrouz, Michele Santacatterina, Ramin Zabih</author><pubDate>Thu, 06 Jun 2024 18:58:09 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.04320v1</guid></item><item><title>Adaptive Sampling of k-Space in Magnetic Resonance for Rapid Pathology Prediction</title><link>http://arxiv.org/abs/2406.04318v1</link><description>Magnetic Resonance (MR) imaging, despite its proven diagnostic utility,remains an inaccessible imaging modality for disease surveillance at thepopulation level. A major factor rendering MR inaccessible is lengthy scantimes. An MR scanner collects measurements associated with the underlyinganatomy in the Fourier space, also known as the k-space. Creating ahigh-fidelity image requires collecting large quantities of such measurements,increasing the scan time. Traditionally to accelerate an MR scan, imagereconstruction from under-sampled k-space data is the method of choice.However, recent works show the feasibility of bypassing image reconstructionand directly learning to detect disease directly from a sparser learned subsetof the k-space measurements. In this work, we propose Adaptive Sampling for MR(ASMR), a sampling method that learns an adaptive policy to sequentially selectk-space samples to optimize for target disease detection. On 6 out of 8pathology classification tasks spanning the Knee, Brain, and Prostate MR scans,ASMR reaches within 2% of the performance of a fully sampled classifier whileusing only 8% of the k-space, as well as outperforming prior state-of-the-artwork in k-space sampling such as EMRT, LOUPE, and DPS.</description><author>Chen-Yu Yen, Raghav Singhal, Umang Sharma, Rajesh Ranganath, Sumit Chopra, Lerrel Pinto</author><pubDate>Thu, 06 Jun 2024 18:58:00 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.04318v1</guid></item><item><title>Regularized KL-Divergence for Well-Defined Function-Space Variational Inference in Bayesian neural networks</title><link>http://arxiv.org/abs/2406.04317v1</link><description>Bayesian neural networks (BNN) promise to combine the predictive performanceof neural networks with principled uncertainty modeling important forsafety-critical systems and decision making. However, posterior uncertaintyestimates depend on the choice of prior, and finding informative priors inweight-space has proven difficult. This has motivated variational inference(VI) methods that pose priors directly on the function generated by the BNNrather than on weights. In this paper, we address a fundamental issue with suchfunction-space VI approaches pointed out by Burt et al. (2020), who showed thatthe objective function (ELBO) is negative infinite for most priors of interest.Our solution builds on generalized VI (Knoblauch et al., 2019) with theregularized KL divergence (Quang, 2019) and is, to the best of our knowledge,the first well-defined variational objective for function-space inference inBNNs with Gaussian process (GP) priors. Experiments show that our methodincorporates the properties specified by the GP prior on synthetic and smallreal-world data sets, and provides competitive uncertainty estimates forregression, classification and out-of-distribution detection compared to BNNbaselines with both function and weight-space priors.</description><author>Tristan Cinquin, Robert Bamler</author><pubDate>Thu, 06 Jun 2024 18:57:49 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.04317v1</guid></item><item><title>Omni6DPose: A Benchmark and Model for Universal 6D Object Pose Estimation and Tracking</title><link>http://arxiv.org/abs/2406.04316v1</link><description>6D Object Pose Estimation is a crucial yet challenging task in computervision, suffering from a significant lack of large-scale datasets. Thisscarcity impedes comprehensive evaluation of model performance, limitingresearch advancements. Furthermore, the restricted number of availableinstances or categories curtails its applications. To address these issues,this paper introduces Omni6DPose, a substantial dataset characterized by itsdiversity in object categories, large scale, and variety in object materials.Omni6DPose is divided into three main components: ROPE (Real 6D Object PoseEstimation Dataset), which includes 332K images annotated with over 1.5Mannotations across 581 instances in 149 categories; SOPE(Simulated 6D ObjectPose Estimation Dataset), consisting of 475K images created in a mixed realitysetting with depth simulation, annotated with over 5M annotations across 4162instances in the same 149 categories; and the manually aligned real scannedobjects used in both ROPE and SOPE. Omni6DPose is inherently challenging due tothe substantial variations and ambiguities. To address this challenge, weintroduce GenPose++, an enhanced version of the SOTA category-level poseestimation framework, incorporating two pivotal improvements: Semantic-awarefeature extraction and Clustering-based aggregation. Moreover, we provide acomprehensive benchmarking analysis to evaluate the performance of previousmethods on this large-scale dataset in the realms of 6D object pose estimationand pose tracking.</description><author>Jiyao Zhang, Weiyao Huang, Bo Peng, Mingdong Wu, Fei Hu, Zijian Chen, Bo Zhao, Hao Dong</author><pubDate>Thu, 06 Jun 2024 18:57:20 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.04316v1</guid></item><item><title>Step-aware Preference Optimization: Aligning Preference with Denoising Performance at Each Step</title><link>http://arxiv.org/abs/2406.04314v1</link><description>Recently, Direct Preference Optimization (DPO) has extended its success fromaligning large language models (LLMs) to aligning text-to-image diffusionmodels with human preferences. Unlike most existing DPO methods that assume alldiffusion steps share a consistent preference order with the final generatedimages, we argue that this assumption neglects step-specific denoisingperformance and that preference labels should be tailored to each step'scontribution. To address this limitation, we propose Step-aware PreferenceOptimization (SPO), a novel post-training approach that independently evaluatesand adjusts the denoising performance at each step, using a step-awarepreference model and a step-wise resampler to ensure accurate step-awaresupervision. Specifically, at each denoising step, we sample a pool of images,find a suitable win-lose pair, and, most importantly, randomly select a singleimage from the pool to initialize the next denoising step. This step-wiseresampler process ensures the next win-lose image pair comes from the sameimage, making the win-lose comparison independent of the previous step. Toassess the preferences at each step, we train a separate step-aware preferencemodel that can be applied to both noisy and clean images. Our experiments withStable Diffusion v1.5 and SDXL demonstrate that SPO significantly outperformsthe latest Diffusion-DPO in aligning generated images with complex, detailedprompts and enhancing aesthetics, while also achieving more than 20x timesfaster in training efficiency. Code and model:https://rockeycoss.github.io/spo.github.io/</description><author>Zhanhao Liang, Yuhui Yuan, Shuyang Gu, Bohan Chen, Tiankai Hang, Ji Li, Liang Zheng</author><pubDate>Thu, 06 Jun 2024 18:57:09 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.04314v1</guid></item><item><title>Bridging the Empirical-Theoretical Gap in Neural Network Formal Language Learning Using Minimum Description Length</title><link>http://arxiv.org/abs/2402.10013v2</link><description>Neural networks offer good approximation to many tasks but consistently failto reach perfect generalization, even when theoretical work shows that suchperfect solutions can be expressed by certain architectures. Using the task offormal language learning, we focus on one simple formal language and show thatthe theoretically correct solution is in fact not an optimum of commonly usedobjectives -- even with regularization techniques that according to commonwisdom should lead to simple weights and good generalization (L1, L2) or othermeta-heuristics (early-stopping, dropout). On the other hand, replacingstandard targets with the Minimum Description Length objective (MDL) results inthe correct solution being an optimum.</description><author>Nur Lan, Emmanuel Chemla, Roni Katzir</author><pubDate>Thu, 06 Jun 2024 17:16:12 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.10013v2</guid></item><item><title>What Do Language Models Learn in Context? The Structured Task Hypothesis</title><link>http://arxiv.org/abs/2406.04216v1</link><description>Large language models (LLMs) exhibit an intriguing ability to learn a noveltask from in-context examples presented in a demonstration, termed in-contextlearning (ICL). Understandably, a swath of research has been dedicated touncovering the theories underpinning ICL. One popular hypothesis explains ICLby task selection. LLMs identify the task based on the demonstration andgeneralize it to the prompt. Another popular hypothesis is that ICL is a formof meta-learning, i.e., the models learn a learning algorithm at pre-trainingtime and apply it to the demonstration. Finally, a third hypothesis argues thatLLMs use the demonstration to select a composition of tasks learned duringpre-training to perform ICL. In this paper, we empirically explore these threehypotheses that explain LLMs' ability to learn in context with a suite ofexperiments derived from common text classification tasks. We invalidate thefirst two hypotheses with counterexamples and provide evidence in support ofthe last hypothesis. Our results suggest an LLM could learn a novel task incontext via composing tasks learned during pre-training.</description><author>Jiaoda Li, Yifan Hou, Mrinmaya Sachan, Ryan Cotterell</author><pubDate>Thu, 06 Jun 2024 17:15:34 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.04216v1</guid></item><item><title>mCSQA: Multilingual Commonsense Reasoning Dataset with Unified Creation Strategy by Language Models and Humans</title><link>http://arxiv.org/abs/2406.04215v1</link><description>It is very challenging to curate a dataset for language-specific knowledgeand common sense in order to evaluate natural language understandingcapabilities of language models. Due to the limitation in the availability ofannotators, most current multilingual datasets are created through translation,which cannot evaluate such language-specific aspects. Therefore, we proposeMultilingual CommonsenseQA (mCSQA) based on the construction process of CSQAbut leveraging language models for a more efficient construction, e.g., byasking LM to generate questions/answers, refine answers and verify QAs followedby reduced human efforts for verification. Constructed dataset is a benchmarkfor cross-lingual language-transfer capabilities of multilingual LMs, andexperimental results showed high language-transfer capabilities for questionsthat LMs could easily solve, but lower transfer capabilities for questionsrequiring deep knowledge or commonsense. This highlights the necessity oflanguage-specific datasets for evaluation and training. Finally, our methoddemonstrated that multilingual LMs could create QA including language-specificknowledge, significantly reducing the dataset creation cost compared to manualcreation. The datasets are available athttps://huggingface.co/datasets/yusuke1997/mCSQA.</description><author>Yusuke Sakai, Hidetaka Kamigaito, Taro Watanabe</author><pubDate>Thu, 06 Jun 2024 17:14:54 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.04215v1</guid></item><item><title>ValueBench: Towards Comprehensively Evaluating Value Orientations and Understanding of Large Language Models</title><link>http://arxiv.org/abs/2406.04214v1</link><description>Large Language Models (LLMs) are transforming diverse fields and gainingincreasing influence as human proxies. This development underscores the urgentneed for evaluating value orientations and understanding of LLMs to ensuretheir responsible integration into public-facing applications. This workintroduces ValueBench, the first comprehensive psychometric benchmark forevaluating value orientations and value understanding in LLMs. ValueBenchcollects data from 44 established psychometric inventories, encompassing 453multifaceted value dimensions. We propose an evaluation pipeline grounded inrealistic human-AI interactions to probe value orientations, along with noveltasks for evaluating value understanding in an open-ended value space. Withextensive experiments conducted on six representative LLMs, we unveil theirshared and distinctive value orientations and exhibit their ability toapproximate expert conclusions in value-related extraction and generationtasks. ValueBench is openly accessible athttps://github.com/Value4AI/ValueBench.</description><author>Yuanyi Ren, Haoran Ye, Hanjun Fang, Xin Zhang, Guojie Song</author><pubDate>Thu, 06 Jun 2024 17:14:16 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.04214v1</guid></item><item><title>The Revolution of Multimodal Large Language Models: A Survey</title><link>http://arxiv.org/abs/2402.12451v2</link><description>Connecting text and visual modalities plays an essential role in generativeintelligence. For this reason, inspired by the success of large languagemodels, significant research efforts are being devoted to the development ofMultimodal Large Language Models (MLLMs). These models can seamlessly integratevisual and textual modalities, while providing a dialogue-based interface andinstruction-following capabilities. In this paper, we provide a comprehensivereview of recent visual-based MLLMs, analyzing their architectural choices,multimodal alignment strategies, and training techniques. We also conduct adetailed analysis of these models across a wide range of tasks, includingvisual grounding, image generation and editing, visual understanding, anddomain-specific applications. Additionally, we compile and describe trainingdatasets and evaluation benchmarks, conducting comparisons among existingmodels in terms of performance and computational requirements. Overall, thissurvey offers a comprehensive overview of the current state of the art, layingthe groundwork for future MLLMs.</description><author>Davide Caffagni, Federico Cocchi, Luca Barsellotti, Nicholas Moratelli, Sara Sarto, Lorenzo Baraldi, Lorenzo Baraldi, Marcella Cornia, Rita Cucchiara</author><pubDate>Thu, 06 Jun 2024 17:13:43 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.12451v2</guid></item><item><title>Spatial-Temporal Graph Representation Learning for Tactical Networks Future State Prediction</title><link>http://arxiv.org/abs/2403.13872v2</link><description>Resource allocation in tactical ad-hoc networks presents unique challengesdue to their dynamic and multi-hop nature. Accurate prediction of futurenetwork connectivity is essential for effective resource allocation in suchenvironments. In this paper, we introduce the Spatial-Temporal GraphEncoder-Decoder (STGED) framework for Tactical Communication Networks thatleverages both spatial and temporal features of network states to learn latenttactical behaviors effectively. STGED hierarchically utilizes graph-basedattention mechanism to spatially encode a series of communication networkstates, leverages a recurrent neural network to temporally encode the evolutionof states, and a fully-connected feed-forward network to decode theconnectivity in the future state. Through extensive experiments, we demonstratethat STGED consistently outperforms baseline models by large margins acrossdifferent time-steps input, achieving an accuracy of up to 99.2\% for thefuture state prediction task of tactical communication networks.</description><author>Liu Junhua, Albrethsen Justin, Goh Lincoln, Yau David, Lim Kwan Hui</author><pubDate>Thu, 06 Jun 2024 17:13:41 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.13872v2</guid></item><item><title>Transfer Learning for Latent Variable Network Models</title><link>http://arxiv.org/abs/2406.03437v2</link><description>We study transfer learning for estimation in latent variable network models.In our setting, the conditional edge probability matrices given the latentvariables are represented by $P$ for the source and $Q$ for the target. We wishto estimate $Q$ given two kinds of data: (1) edge data from a subgraph inducedby an $o(1)$ fraction of the nodes of $Q$, and (2) edge data from all of $P$.If the source $P$ has no relation to the target $Q$, the estimation error mustbe $\Omega(1)$. However, we show that if the latent variables are shared, thenvanishing error is possible. We give an efficient algorithm that utilizes theordering of a suitably defined graph distance. Our algorithm achieves $o(1)$error and does not assume a parametric form on the source or target networks.Next, for the specific case of Stochastic Block Models we prove a minimax lowerbound and show that a simple algorithm achieves this rate. Finally, weempirically demonstrate our algorithm's use on real-world and simulated graphtransfer problems.</description><author>Akhil Jalan, Arya Mazumdar, Soumendu Sundar Mukherjee, Purnamrita Sarkar</author><pubDate>Thu, 06 Jun 2024 17:13:41 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.03437v2</guid></item><item><title>Towards Avoiding the Data Mess: Industry Insights from Data Mesh Implementations</title><link>http://arxiv.org/abs/2302.01713v4</link><description>With the increasing importance of data and artificial intelligence,organizations strive to become more data-driven. However, current dataarchitectures are not necessarily designed to keep up with the scale and scopeof data and analytics use cases. In fact, existing architectures often fail todeliver the promised value associated with them. Data mesh is asocio-technical, decentralized, distributed concept for enterprise datamanagement. As the concept of data mesh is still novel, it lacks empiricalinsights from the field. Specifically, an understanding of the motivationalfactors for introducing data mesh, the associated challenges, implementationstrategies, its business impact, and potential archetypes is missing. Toaddress this gap, we conduct 15 semi-structured interviews with industryexperts. Our results show, among other insights, that organizations havedifficulties with the transition toward federated governance associated withthe data mesh concept, the shift of responsibility for the development,provision, and maintenance of data products, and the comprehension of theoverall concept. In our work, we derive multiple implementation strategies andsuggest organizations introduce a cross-domain steering unit, observe the dataproduct usage, create quick wins in the early phases, and favor small dedicatedteams that prioritize data products. While we acknowledge that organizationsneed to apply implementation strategies according to their individual needs, wealso deduct two archetypes that provide suggestions in more detail. Ourfindings synthesize insights from industry experts and provide researchers andprofessionals with preliminary guidelines for the successful adoption of datamesh.</description><author>Jan Bode, Niklas Kühl, Dominik Kreuzberger, Sebastian Hirschl, Carsten Holtmann</author><pubDate>Thu, 06 Jun 2024 17:13:09 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2302.01713v4</guid></item><item><title>A Study of Optimizations for Fine-tuning Large Language Models</title><link>http://arxiv.org/abs/2406.02290v2</link><description>Fine-tuning large language models is a popular choice among users trying toadapt them for specific applications. However, fine-tuning these models is ademanding task because the user has to examine several factors, such asresource budget, runtime, model size and context length among others. Aspecific challenge is that fine-tuning is memory intensive, imposingconstraints on the required hardware memory and context length of training datathat can be handled. In this work, we share a detailed study on a variety offine-tuning optimizations across different fine-tuning scenarios. Inparticular, we assess Gradient Checkpointing, Low-Rank Adaptation, DeepSpeed'sZero Redundancy Optimizer and FlashAttention. With a focus on memory andruntime, we examine the impact of different optimization combinations on GPUmemory usage and execution runtime during fine-tuning phase. We provide ourrecommendation on the best default optimization for balancing memory andruntime across diverse model sizes. We share effective strategies forfine-tuning very large models with tens or hundreds of billions of parametersand enabling large context lengths during fine-tuning. Furthermore, we proposethe appropriate optimization mixtures for fine-tuning under GPU resourcelimitations.</description><author>Arjun Singh, Nikhil Pandey, Anup Shirgaonkar, Pavan Manoj, Vijay Aski</author><pubDate>Thu, 06 Jun 2024 17:09:31 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.02290v2</guid></item><item><title>Aligning Agents like Large Language Models</title><link>http://arxiv.org/abs/2406.04208v1</link><description>Training agents to behave as desired in complex 3D environments fromhigh-dimensional sensory information is challenging. Imitation learning fromdiverse human behavior provides a scalable approach for training an agent witha sensible behavioral prior, but such an agent may not perform the specificbehaviors of interest when deployed. To address this issue, we draw an analogybetween the undesirable behaviors of imitation learning agents and theunhelpful responses of unaligned large language models (LLMs). We theninvestigate how the procedure for aligning LLMs can be applied to aligningagents in a 3D environment from pixels. For our analysis, we utilize anacademically illustrative part of a modern console game in which the humanbehavior distribution is multi-modal, but we want our agent to imitate a singlemode of this behavior. We demonstrate that we can align our agent toconsistently perform the desired mode, while providing insights and advice forsuccessfully applying this approach to training agents. Project webpage athttps://adamjelley.github.io/aligning-agents-like-llms .</description><author>Adam Jelley, Yuhan Cao, Dave Bignell, Sam Devlin, Tabish Rashid</author><pubDate>Thu, 06 Jun 2024 17:05:45 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.04208v1</guid></item><item><title>CDMamba: Remote Sensing Image Change Detection with Mamba</title><link>http://arxiv.org/abs/2406.04207v1</link><description>Recently, the Mamba architecture based on state space models has demonstratedremarkable performance in a series of natural language processing tasks and hasbeen rapidly applied to remote sensing change detection (CD) tasks. However,most methods enhance the global receptive field by directly modifying thescanning mode of Mamba, neglecting the crucial role that local informationplays in dense prediction tasks (e.g., CD). In this article, we propose a modelcalled CDMamba, which effectively combines global and local features forhandling CD tasks. Specifically, the Scaled Residual ConvMamba (SRCM) block isproposed to utilize the ability of Mamba to extract global features andconvolution to enhance the local details, to alleviate the issue that currentMamba-based methods lack detailed clues and are difficult to achieve finedetection in dense prediction tasks. Furthermore, considering thecharacteristics of bi-temporal feature interaction required for CD, theAdaptive Global Local Guided Fusion (AGLGF) block is proposed to dynamicallyfacilitate the bi-temporal interaction guided by other temporal global/localfeatures. Our intuition is that more discriminative change features can beacquired with the guidance of other temporal features. Extensive experiments onthree datasets demonstrate that our proposed CDMamba outperforms the currentstate-of-the-art methods. Our code will be open-sourced athttps://github.com/zmoka-zht/CDMamba.</description><author>Haotian Zhang, Keyan Chen, Chenyang Liu, Hao Chen, Zhengxia Zou, Zhenwei Shi</author><pubDate>Thu, 06 Jun 2024 17:04:30 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.04207v1</guid></item><item><title>A Survey on Multilingual Large Language Models: Corpora, Alignment, and Bias</title><link>http://arxiv.org/abs/2404.00929v2</link><description>Based on the foundation of Large Language Models (LLMs), Multilingual LargeLanguage Models (MLLMs) have been developed to address the challenges ofmultilingual natural language processing tasks, hoping to achieve knowledgetransfer from high-resource to low-resource languages. However, significantlimitations and challenges still exist, such as language imbalance,multilingual alignment, and inherent bias. In this paper, we aim to provide acomprehensive analysis of MLLMs, delving deeply into discussions surroundingthese critical issues. First of all, we start by presenting an overview ofMLLMs, covering their evolution, key techniques, and multilingual capacities.Secondly, we explore widely utilized multilingual corpora for MLLMs' trainingand multilingual datasets oriented for downstream tasks that are crucial forenhancing the cross-lingual capability of MLLMs. Thirdly, we survey theexisting studies on multilingual representations and investigate whether thecurrent MLLMs can learn a universal language representation. Fourthly, wediscuss bias on MLLMs including its category and evaluation metrics, andsummarize the existing debiasing techniques. Finally, we discuss existingchallenges and point out promising research directions. By demonstrating theseaspects, this paper aims to facilitate a deeper understanding of MLLMs andtheir potentiality in various domains.</description><author>Yuemei Xu, Ling Hu, Jiayi Zhao, Zihan Qiu, Yuqi Ye, Hanwen Gu</author><pubDate>Thu, 06 Jun 2024 17:04:15 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.00929v2</guid></item><item><title>Diffusion-based image inpainting with internal learning</title><link>http://arxiv.org/abs/2406.04206v1</link><description>Diffusion models are now the undisputed state-of-the-art for image generationand image restoration. However, they require large amounts of computationalpower for training and inference. In this paper, we propose lightweightdiffusion models for image inpainting that can be trained on a single image, ora few images. We show that our approach competes with large state-of-the-artmodels in specific cases. We also show that training a model on a single imageis particularly relevant for image acquisition modality that differ from theRGB images of standard learning databases. We show results in three differentcontexts: texture images, line drawing images, and materials BRDF, for which weachieve state-of-the-art results in terms of realism, with a computational loadthat is greatly reduced compared to concurrent methods.</description><author>Nicolas Cherel, Andrés Almansa, Yann Gousseau, Alasdair Newson</author><pubDate>Thu, 06 Jun 2024 17:04:06 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.04206v1</guid></item><item><title>NormAd: A Benchmark for Measuring the Cultural Adaptability of Large Language Models</title><link>http://arxiv.org/abs/2404.12464v4</link><description>The integration of Large Language Models (LLMs) into various global culturesfundamentally presents a cultural challenge: LLMs must navigate interactions,respect social norms, and avoid transgressing cultural boundaries. However, itis still unclear if LLMs can adapt their outputs to diverse cultural norms. Ourstudy focuses on this aspect. We introduce NormAd, a novel dataset, whichincludes 2.6k stories that represent social and cultural norms from 75countries, to assess the ability of LLMs to adapt to different granular levelsof socio-cultural contexts such as the country of origin, its associatedcultural values, and prevalent social norms. Our study reveals that LLMsstruggle with cultural reasoning across all contextual granularities, showingstronger adaptability to English-centric cultures over those from the GlobalSouth. Even with explicit social norms, the top-performing model,Mistral-7b-Instruct, achieves only 81.8\% accuracy, lagging behind the 95.6\%achieved by humans. Evaluation on NormAd further reveals that LLMs struggle toadapt to stories involving gift-giving across cultures. Due to inherentagreement or sycophancy biases, LLMs find it considerably easier to assess thesocial acceptability of stories that adhere to cultural norms than those thatdeviate from them. Our benchmark measures the cultural adaptability (or lackthereof) of LLMs, emphasizing the potential to make these technologies moreequitable and useful for global audiences. We release the NormAd dataset andits associated code on GitHub.</description><author>Abhinav Rao, Akhila Yerukola, Vishwa Shah, Katharina Reinecke, Maarten Sap</author><pubDate>Thu, 06 Jun 2024 17:02:39 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.12464v4</guid></item><item><title>Does Pre-trained Language Model Actually Infer Unseen Links in Knowledge Graph Completion?</title><link>http://arxiv.org/abs/2311.09109v2</link><description>Knowledge graphs (KGs) consist of links that describe relationships betweenentities. Due to the difficulty of manually enumerating all relationshipsbetween entities, automatically completing them is essential for KGs. KnowledgeGraph Completion (KGC) is a task that infers unseen relationships betweenentities in a KG. Traditional embedding-based KGC methods, such as RESCAL,TransE, DistMult, ComplEx, RotatE, HAKE, HousE, etc., infer missing links usingonly the knowledge from training data. In contrast, the recent Pre-trainedLanguage Model (PLM)-based KGC utilizes knowledge obtained during pre-training.Therefore, PLM-based KGC can estimate missing links between entities by reusingmemorized knowledge from pre-training without inference. This approach isproblematic because building KGC models aims to infer unseen links betweenentities. However, conventional evaluations in KGC do not consider inferenceand memorization abilities separately. Thus, a PLM-based KGC method, whichachieves high performance in current KGC evaluations, may be ineffective inpractical applications. To address this issue, we analyze whether PLM-based KGCmethods make inferences or merely access memorized knowledge. For this purpose,we propose a method for constructing synthetic datasets specified in thisanalysis and conclude that PLMs acquire the inference abilities required forKGC through pre-training, even though the performance improvements mostly comefrom textual information of entities and relations.</description><author>Yusuke Sakai, Hidetaka Kamigaito, Katsuhiko Hayashi, Taro Watanabe</author><pubDate>Thu, 06 Jun 2024 17:01:08 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.09109v2</guid></item><item><title>Legal Documents Drafting with Fine-Tuned Pre-Trained Large Language Model</title><link>http://arxiv.org/abs/2406.04202v1</link><description>With the development of large-scale Language Models (LLM), fine-tuningpre-trained LLM has become a mainstream paradigm for solving downstream tasksof natural language processing. However, training a language model in the legalfield requires a large number of legal documents so that the language model canlearn legal terminology and the particularity of the format of legal documents.The typical NLP approaches usually rely on many manually annotated data setsfor training. However, in the legal field application, it is difficult toobtain a large number of manually annotated data sets, which restricts thetypical method applied to the task of drafting legal documents. Theexperimental results of this paper show that not only can we leverage a largenumber of annotation-free legal documents without Chinese word segmentation tofine-tune a large-scale language model, but more importantly, it can fine-tunea pre-trained LLM on the local computer to achieve the generating legaldocument drafts task, and at the same time achieve the protection ofinformation privacy and to improve information security issues.</description><author>Chun-Hsien Lin, Pu-Jen Cheng</author><pubDate>Thu, 06 Jun 2024 17:00:20 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.04202v1</guid></item><item><title>Towards Principled Superhuman AI for Multiplayer Symmetric Games</title><link>http://arxiv.org/abs/2406.04201v1</link><description>Multiplayer games, when the number of players exceeds two, present uniquechallenges that fundamentally distinguish them from the extensively studiedtwo-player zero-sum games. These challenges arise from the non-uniqueness ofequilibria and the risk of agents performing highly suboptimally when adoptingequilibrium strategies. While a line of recent works developed learning systemssuccessfully achieving human-level or even superhuman performance in popularmultiplayer games such as Mahjong, Poker, and Diplomacy, two critical questionsremain unaddressed: (1) What is the correct solution concept that AI agentsshould find? and (2) What is the general algorithmic framework that provablysolves all games within this class? This paper takes the first step towardssolving these unique challenges of multiplayer games by provably addressingboth questions in multiplayer symmetric normal-form games. We also demonstratethat many meta-algorithms developed in prior practical systems for multiplayergames can fail to achieve even the basic goal of obtaining agent's equal shareof the total reward.</description><author>Jiawei Ge, Yuanhao Wang, Wenzhe Li, Chi Jin</author><pubDate>Thu, 06 Jun 2024 16:59:17 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.04201v1</guid></item><item><title>DICE: Detecting In-distribution Contamination in LLM's Fine-tuning Phase for Math Reasoning</title><link>http://arxiv.org/abs/2406.04197v1</link><description>The advancement of large language models (LLMs) relies on evaluation usingpublic benchmarks, but data contamination can lead to overestimatedperformance. Previous researches focus on detecting contamination bydetermining whether the model has seen the exact same data during training. Inthis work, we argue that even training on data similar to benchmark datainflates performance on in-distribution tasks without improving overallcapacity, which we called In-distribution contamination. To effectively detectin-distribution contamination, we propose DICE, a novel method that leveragesthe internal states of LLMs to locate-then-detect the contamination. DICE firstidentifies the most sensitive layer to contamination, then trains a classifierbased on the internal states of that layer. Experiments reveal DICE's highaccuracy in detecting in-distribution contamination across various LLMs andmath reasoning datasets. We also show the generalization capability of thetrained DICE detector, which is able to detect contamination across multiplebenchmarks with similar distributions. Additionally, we find that the DICEdetection scores are positively correlated with the performance of ten LLMsfine-tuned by either us or other organizations on four math reasoning datasets(with $R^2$ values between 0.6 and 0.75). This indicates that thein-distribution contamination problem potentially lead to an overestimation ofthe true capabilities of many existing models. The code and data are availableat https://github.com/THU-KEG/DICE.</description><author>Shangqing Tu, Kejian Zhu, Yushi Bai, Zijun Yao, Lei Hou, Juanzi Li</author><pubDate>Thu, 06 Jun 2024 16:55:53 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.04197v1</guid></item><item><title>Predictive Uncertainty Quantification via Risk Decompositions for Strictly Proper Scoring Rules</title><link>http://arxiv.org/abs/2402.10727v2</link><description>Uncertainty quantification in predictive modeling often relies on ad hocmethods as there is no universally accepted formal framework for that. Thispaper introduces a theoretical approach to understanding uncertainty throughstatistical risks, distinguishing between aleatoric (data-related) andepistemic (model-related) uncertainties. We explain how to split pointwise riskinto Bayes risk and excess risk. In particular, we show that excess risk,related to epistemic uncertainty, aligns with Bregman divergences. To turnconsidered risk measures into actual uncertainty estimates, we suggest usingthe Bayesian approach by approximating the risks with the help of posteriordistributions. We tested our method on image datasets, evaluating itsperformance in detecting out-of-distribution and misclassified data using theAUROC metric. Our results confirm the effectiveness of the considered approachand offer practical guidance for estimating uncertainty in real-worldapplications.</description><author>Nikita Kotelevskii, Maxim Panov</author><pubDate>Thu, 06 Jun 2024 16:52:17 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.10727v2</guid></item><item><title>Parameter-Adaptive Approximate MPC: Tuning Neural-Network Controllers without Retraining</title><link>http://arxiv.org/abs/2404.05835v2</link><description>Model Predictive Control (MPC) is a method to control nonlinear systems withguaranteed stability and constraint satisfaction but suffers from highcomputation times. Approximate MPC (AMPC) with neural networks (NNs) hasemerged to address this limitation, enabling deployment on resource-constrainedembedded systems. However, when tuning AMPCs for real-world systems, largedatasets need to be regenerated and the NN needs to be retrained at everytuning step. This work introduces a novel, parameter-adaptive AMPC architecturecapable of online tuning without recomputing large datasets and retraining. Byincorporating local sensitivities of nonlinear programs, the proposed methodnot only mimics optimal MPC inputs but also adjusts to known changes inphysical parameters of the model using linear predictions while stillguaranteeing stability. We showcase the effectiveness of parameter-adaptiveAMPC by controlling the swing-ups of two different real cartpole systems with aseverely resource-constrained microcontroller (MCU). We use the same NN acrossboth system instances that have different parameters. This work not onlyrepresents the first experimental demonstration of AMPC for fast-moving systemson low-cost MCUs to the best of our knowledge, but also showcasesgeneralization across system instances and variations through ourparameter-adaptation method. Taken together, these contributions represent amarked step toward the practical application of AMPC in real-world systems.</description><author>Henrik Hose, Alexander Gräfe, Sebastian Trimpe</author><pubDate>Thu, 06 Jun 2024 16:51:35 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.05835v2</guid></item><item><title>Imbalanced Data Clustering using Equilibrium K-Means</title><link>http://arxiv.org/abs/2402.14490v3</link><description>Centroid-based clustering algorithms, such as hard K-means (HKM) and fuzzyK-means (FKM), have suffered from learning bias towards large clusters. Theircentroids tend to be crowded in large clusters, compromising performance whenthe true underlying data groups vary in size (i.e., imbalanced data). Toaddress this, we propose a new clustering objective function based on theBoltzmann operator, which introduces a novel centroid repulsion mechanism,where data points surrounding the centroids repel other centroids. Largerclusters repel more, effectively mitigating the issue of large cluster learningbias. The proposed new algorithm, called equilibrium K-means (EKM), is simple,alternating between two steps; resource-saving, with the same time and spacecomplexity as FKM; and scalable to large datasets via batch learning. Wesubstantially evaluate the performance of EKM on synthetic and real-worlddatasets. The results show that EKM performs competitively on balanced data andsignificantly outperforms benchmark algorithms on imbalanced data. Deepclustering experiments demonstrate that EKM is a better alternative to HKM andFKM on imbalanced data as more discriminative representation can be obtained.Additionally, we reformulate HKM, FKM, and EKM in a general form of gradientdescent and demonstrate how this general form facilitates a uniform study ofK-means algorithms.</description><author>Yudong He</author><pubDate>Thu, 06 Jun 2024 16:51:21 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.14490v3</guid></item><item><title>Sequential memory improves sample and memory efficiency in Episodic Control</title><link>http://arxiv.org/abs/2112.14734v2</link><description>State of the art deep reinforcement learning algorithms are sampleinefficient due to the large number of episodes they require to achieveasymptotic performance. Episodic Reinforcement Learning (ERL) algorithms,inspired by the mammalian hippocampus, typically use extended memory systems tobootstrap learning from past events to overcome this sample-inefficiencyproblem. However, such memory augmentations are often used as mere buffers,from which isolated past experiences are drawn to learn from in an offlinefashion (e.g., replay). Here, we demonstrate that including a bias in theacquired memory content derived from the order of episodic sampling improvesboth the sample and memory efficiency of an episodic control algorithm. We testour Sequential Episodic Control (SEC) model in a foraging task to show thatstoring and using integrated episodes as event sequences leads to fasterlearning with fewer memory requirements as opposed to a standard ERL benchmark,Model-Free Episodic Control, that buffers isolated events only. We also studythe effect of memory constraints and forgetting on the sequential andnon-sequential version of the SEC algorithm. Furthermore, we discuss how ahippocampal-like fast memory system could bootstrap slow cortical andsubcortical learning subserving habit formation in the mammalian brain.</description><author>Ismael T. Freire, Adrián F. Amil, Paul F. M. J. Verschure</author><pubDate>Thu, 06 Jun 2024 16:50:45 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2112.14734v2</guid></item><item><title>Learning Regularities from Data using Spiking Functions: A Theory</title><link>http://arxiv.org/abs/2405.11684v2</link><description>Deep neural networks trained in an end-to-end manner are proven to beefficient in a wide range of machine learning tasks. However, there is onedrawback of end-to-end learning: The learned features and information areimplicitly represented in neural network parameters, which cannot be used asregularities, concepts or knowledge to explicitly represent the dataprobability distribution. To resolve this issue, we propose in this paper a newmachine learning theory, which defines in mathematics what are regularities.Briefly, regularities are concise representations of the non-random features,or 'non-randomness' in the data probability distribution. Combining this withinformation theory, we claim that regularities can also be regarded as a smallamount of information encoding a large amount of information. Our theory isbased on spiking functions. That is, if a function can react to, or spike onspecific data samples more frequently than random noise inputs, we say thatsuch a function discovers non-randomness from the data distribution. Also, wesay that the discovered non-randomness is encoded into regularities if thefunction is simple enough. Our theory also discusses applying multiple spikingfunctions to the same data distribution. In this process, we claim that the'best' regularities, or the optimal spiking functions, are those who cancapture the largest amount of information from the data distribution, and thenencode the captured information in the most concise way. Theorems andhypotheses are provided to describe in mathematics what are 'best' regularitiesand optimal spiking functions. Finally, we propose a machine learning approach,which can potentially obtain the optimal spiking functions regarding the givendataset in practice.</description><author>Canlin Zhang, Xiuwen Liu</author><pubDate>Thu, 06 Jun 2024 16:41:38 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.11684v2</guid></item><item><title>Shield Synthesis for LTL Modulo Theories</title><link>http://arxiv.org/abs/2406.04184v1</link><description>In recent years, Machine Learning (ML) models have achieved remarkablesuccess in various domains. However, these models also tend to demonstrateunsafe behaviors, precluding their deployment in safety-critical systems. Tocope with this issue, ample research focuses on developing methods thatguarantee the safe behaviour of a given ML model. A prominent example isshielding which incorporates an external component (a "shield") that blocksunwanted behavior. Despite significant progress, shielding suffers from a mainsetback: it is currently geared towards properties encoded solely inpropositional logics (e.g., LTL) and is unsuitable for richer logics. This, inturn, limits the widespread applicability of shielding in many real-worldsystems. In this work, we address this gap, and extend shielding to LTL modulotheories, by building upon recent advances in reactive synthesis modulotheories. This allowed us to develop a novel approach for generating shieldsconforming to complex safety specifications in these more expressive, logics.We evaluated our shields and demonstrate their ability to handle rich data withtemporal dynamics. To the best of our knowledge, this is the first approach forsynthesizing shields for such expressivity.</description><author>Andoni Rodriguez, Guy Amir, Davide Corsi, Cesar Sanchez, Guy Katz</author><pubDate>Thu, 06 Jun 2024 16:40:29 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.04184v1</guid></item><item><title>Encoding Semantic Priors into the Weights of Implicit Neural Representation</title><link>http://arxiv.org/abs/2406.04178v1</link><description>Implicit neural representation (INR) has recently emerged as a promisingparadigm for signal representations, which takes coordinates as inputs andgenerates corresponding signal values. Since these coordinates contain nosemantic features, INR fails to take any semantic information intoconsideration. However, semantic information has been proven critical in manyvision tasks, especially for visual signal representation. This paper proposesa reparameterization method termed as SPW, which encodes the semantic priors tothe weights of INR, thus making INR contain semantic information implicitly andenhancing its representational capacity. Specifically, SPW uses the SemanticNeural Network (SNN) to extract both low- and high-level semantic informationof the target visual signal and generates the semantic vector, which is inputinto the Weight Generation Network (WGN) to generate the weights of INR model.Finally, INR uses the generated weights with semantic priors to map thecoordinates to the signal values. After training, we only retain the generatedweights while abandoning both SNN and WGN, thus SPW introduces no extra costsin inference. Experimental results show that SPW can improve the performance ofvarious INR models significantly on various tasks, including image fitting, CTreconstruction, MRI reconstruction, and novel view synthesis. Furtherexperiments illustrate that model with SPW has lower weight redundancy andlearns more novel representations, validating the effectiveness of SPW.</description><author>Zhicheng Cai, Qiu Shen</author><pubDate>Thu, 06 Jun 2024 16:35:41 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.04178v1</guid></item><item><title>A Voxel-based Approach for Simulating Microbial Decomposition in Soil: Comparison with LBM and Improvement of Morphological Models</title><link>http://arxiv.org/abs/2406.04177v1</link><description>This study presents a new computational approach for simulating the microbialdecomposition of organic matter, from 3D micro-computed tomography (micro-CT)images of soil. The method employs a valuated graph of connected voxels tosimulate transformation and diffusion processes involved in microbialdecomposition within the complex soil matrix. The resulting model can beadapted to simulate any diffusion-transformation processes in porous media. Weimplemented parallelization strategies and explored different numericalmethods, including implicit, explicit, synchronous, and asynchronous schemes.To validate our method, we compared simulation outputs with those provided byLBioS and by Mosaic models. LBioS uses a lattice-Boltzmann method for diffusionand Mosaic takes benefit of Pore Network Geometrical Modelling (PNGM) by meansof geometrical primitives such as spheres and ellipsoids. This approachachieved comparable results to traditional LBM-based simulations, but requiredonly one-fourth of the computing time. Compared to Mosaic simulation, theproposed method is slower but more accurate and does not require anycalibration. Furthermore, we present a theoretical framework and an applicationexample to enhance PNGM-based simulations. This is accomplished byapproximating the diffusional conductance coefficients using stochasticgradient descent and data generated by the current approach.</description><author>Mouad Klai, Olivier Monga, Mohamed Soufiane Jouini, Valérie Pot</author><pubDate>Thu, 06 Jun 2024 16:35:25 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.04177v1</guid></item><item><title>Knowledge Graph Question Answering for Materials Science (KGQA4MAT): Developing Natural Language Interface for Metal-Organic Frameworks Knowledge Graph (MOF-KG) Using LLM</title><link>http://arxiv.org/abs/2309.11361v2</link><description>We present a comprehensive benchmark dataset for Knowledge Graph QuestionAnswering in Materials Science (KGQA4MAT), with a focus on metal-organicframeworks (MOFs). A knowledge graph for metal-organic frameworks (MOF-KG) hasbeen constructed by integrating structured databases and knowledge extractedfrom the literature. To enhance MOF-KG accessibility for domain experts, we aimto develop a natural language interface for querying the knowledge graph. Wehave developed a benchmark comprised of 161 complex questions involvingcomparison, aggregation, and complicated graph structures. Each question isrephrased in three additional variations, resulting in 644 questions and 161 KGqueries. To evaluate the benchmark, we have developed a systematic approach forutilizing the LLM, ChatGPT, to translate natural language questions into formalKG queries. We also apply the approach to the well-known QALD-9 dataset,demonstrating ChatGPT's potential in addressing KGQA issues for differentplatforms and query languages. The benchmark and the proposed approach aim tostimulate further research and development of user-friendly and efficientinterfaces for querying domain-specific materials science knowledge graphs,thereby accelerating the discovery of novel materials.</description><author>Yuan An, Jane Greenberg, Alex Kalinowski, Xintong Zhao, Xiaohua Hu, Fernando J. Uribe-Romo, Kyle Langlois, Jacob Furst, Diego A. Gómez-Gualdrón</author><pubDate>Thu, 06 Jun 2024 16:35:09 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2309.11361v2</guid></item><item><title>Confabulation: The Surprising Value of Large Language Model Hallucinations</title><link>http://arxiv.org/abs/2406.04175v1</link><description>This paper presents a systematic defense of large language model (LLM)hallucinations or 'confabulations' as a potential resource instead of acategorically negative pitfall. The standard view is that confabulations areinherently problematic and AI research should eliminate this flaw. In thispaper, we argue and empirically demonstrate that measurable semanticcharacteristics of LLM confabulations mirror a human propensity to utilizeincreased narrativity as a cognitive resource for sense-making andcommunication. In other words, it has potential value. Specifically, we analyzepopular hallucination benchmarks and reveal that hallucinated outputs displayincreased levels of narrativity and semantic coherence relative to veridicaloutputs. This finding reveals a tension in our usually dismissiveunderstandings of confabulation. It suggests, counter-intuitively, that thetendency for LLMs to confabulate may be intimately associated with a positivecapacity for coherent narrative-text generation.</description><author>Peiqi Sui, Eamon Duede, Sophie Wu, Richard Jean So</author><pubDate>Thu, 06 Jun 2024 16:32:29 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.04175v1</guid></item><item><title>Entropy annealing for policy mirror descent in continuous time and space</title><link>http://arxiv.org/abs/2405.20250v2</link><description>Entropy regularization has been extensively used in policy optimizationalgorithms to regularize the optimization landscape and accelerate convergence;however, it comes at the cost of introducing an additional regularization bias.This work quantifies the impact of entropy regularization on the convergence ofpolicy gradient methods for stochastic exit time control problems. We analyze acontinuous-time policy mirror descent dynamics, which updates the policy basedon the gradient of an entropy-regularized value function and adjusts thestrength of entropy regularization as the algorithm progresses. We prove thatwith a fixed entropy level, the dynamics converges exponentially to the optimalsolution of the regularized problem. We further show that when the entropylevel decays at suitable polynomial rates, the annealed flow converges to thesolution of the unregularized problem at a rate of $\mathcal O(1/S)$ fordiscrete action spaces and, under suitable conditions, at a rate of $\mathcalO(1/\sqrt{S})$ for general action spaces, with $S$ being the gradient flowtime. This paper explains how entropy regularization improves policyoptimization, even with the true gradient, from the perspective of convergencerate.</description><author>Deven Sethi, David Šiška, Yufei Zhang</author><pubDate>Thu, 06 Jun 2024 16:31:08 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.20250v2</guid></item><item><title>Element-wise Multiplication Based Physics-informed Neural Networks</title><link>http://arxiv.org/abs/2406.04170v1</link><description>As a promising framework for resolving partial differential equations (PDEs),physics-informed neural networks (PINNs) have received widespread attentionfrom industrial and scientific fields. However, lack of expressive ability andinitialization pathology issues are found to prevent the application of PINNsin complex PDEs. In this work, we propose Element-wise Multiplication BasedPhysics-informed Neural Networks (EM-PINNs) to resolve these issues. Theelement-wise multiplication operation is adopted to transform features intohigh-dimensional, non-linear spaces, which effectively enhance the expressivecapability of PINNs. Benefiting from element-wise multiplication operation,EM-PINNs can eliminate the initialization pathologies of PINNs. The proposedstructure is verified on various benchmarks. The results show that EM-PINNshave strong expressive ability.</description><author>Feilong Jiang, Xiaonan Hou, Min Xia</author><pubDate>Thu, 06 Jun 2024 16:27:52 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.04170v1</guid></item><item><title>Whole Heart 3D+T Representation Learning Through Sparse 2D Cardiac MR Images</title><link>http://arxiv.org/abs/2406.00329v2</link><description>Cardiac Magnetic Resonance (CMR) imaging serves as the gold-standard forevaluating cardiac morphology and function. Typically, a multi-view CMR stack,covering short-axis (SA) and 2/3/4-chamber long-axis (LA) views, is acquiredfor a thorough cardiac assessment. However, efficiently streamlining thecomplex, high-dimensional 3D+T CMR data and distilling compact, coherentrepresentation remains a challenge. In this work, we introduce a whole-heartself-supervised learning framework that utilizes masked imaging modeling toautomatically uncover the correlations between spatial and temporal patchesthroughout the cardiac stacks. This process facilitates the generation ofmeaningful and well-clustered heart representations without relying on thetraditionally required, and often costly, labeled data. The learned heartrepresentation can be directly used for various downstream tasks. Furthermore,our method demonstrates remarkable robustness, ensuring consistentrepresentations even when certain CMR planes are missing/flawed. We train ourmodel on 14,000 unlabeled CMR data from UK BioBank and evaluate it on 1,000annotated data. The proposed method demonstrates superior performance tobaselines in tasks that demand comprehensive 3D+T cardiac information, e.g.cardiac phenotype (ejection fraction and ventricle volume) prediction andmulti-plane/multi-frame CMR segmentation, highlighting its effectiveness inextracting comprehensive cardiac features that are both anatomically andpathologically relevant.</description><author>Yundi Zhang, Chen Chen, Suprosanna Shit, Sophie Starck, Daniel Rueckert, Jiazhen Pan</author><pubDate>Thu, 06 Jun 2024 16:27:12 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.00329v2</guid></item><item><title>Integrating Pre-Trained Speech and Language Models for End-to-End Speech Recognition</title><link>http://arxiv.org/abs/2312.03668v2</link><description>Advances in machine learning have made it possible to perform various textand speech processing tasks, such as automatic speech recognition (ASR), in anend-to-end (E2E) manner. E2E approaches utilizing pre-trained models aregaining attention for conserving training data and resources. However, most oftheir applications in ASR involve only one of either a pre-trained speech or alanguage model. This paper proposes integrating a pre-trained speechrepresentation model and a large language model (LLM) for E2E ASR. The proposedmodel enables the optimization of the entire ASR process, including acousticfeature extraction and acoustic and language modeling, by combining pre-trainedmodels with a bridge network and also enables the application of remarkabledevelopments in LLM utilization, such as parameter-efficient domain adaptationand inference optimization. Experimental results demonstrate that the proposedmodel achieves a performance comparable to that of modern E2E ASR models byutilizing powerful pre-training models with the proposed integrated approach.</description><author>Yukiya Hono, Koh Mitsuda, Tianyu Zhao, Kentaro Mitsui, Toshiaki Wakatsuki, Kei Sawada</author><pubDate>Thu, 06 Jun 2024 16:24:16 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.03668v2</guid></item><item><title>Collapse-Aware Triplet Decoupling for Adversarially Robust Image Retrieval</title><link>http://arxiv.org/abs/2312.07364v4</link><description>Adversarial training has achieved substantial performance in defending imageretrieval against adversarial examples. However, existing studies in deepmetric learning (DML) still suffer from two major limitations: weak adversaryand model collapse. In this paper, we address these two limitations byproposing Collapse-Aware TRIplet DEcoupling (CA-TRIDE). Specifically, TRIDEyields a stronger adversary by spatially decoupling the perturbation targetsinto the anchor and the other candidates. Furthermore, CA prevents theconsequential model collapse, based on a novel metric, collapseness, which isincorporated into the optimization of perturbation. We also identify twodrawbacks of the existing robustness metric in image retrieval and propose anew metric for a more reasonable robustness evaluation. Extensive experimentson three datasets demonstrate that CA-TRIDE outperforms existing defensemethods in both conventional and new metrics. Codes are available athttps://github.com/michaeltian108/CA-TRIDE.</description><author>Qiwei Tian, Chenhao Lin, Zhengyu Zhao, Qian Li, Chao Shen</author><pubDate>Thu, 06 Jun 2024 16:24:15 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.07364v4</guid></item><item><title>Repurposing Language Models into Embedding Models: Finding the Compute-Optimal Recipe</title><link>http://arxiv.org/abs/2406.04165v1</link><description>Text embeddings are essential for many tasks, such as document retrieval,clustering, and semantic similarity assessment. In this paper, we study how tocontrastively train text embedding models in a compute-optimal fashion, given asuite of pre-trained decoder-only language models. Our innovation is analgorithm that produces optimal configurations of model sizes, data quantities,and fine-tuning methods for text-embedding models at different computationalbudget levels. The resulting recipe, which we obtain through extensiveexperiments, can be used by practitioners to make informed design choices fortheir embedding models. Specifically, our findings suggest that fullfine-tuning and low-rank adaptation fine-tuning produce optimal models at lowerand higher computational budgets respectively.</description><author>Alicja Ziarko, Albert Q. Jiang, Bartosz Piotrowski, Wenda Li, Mateja Jamnik, Piotr Miłoś</author><pubDate>Thu, 06 Jun 2024 16:22:33 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.04165v1</guid></item><item><title>Learned feature representations are biased by complexity, learning order, position, and more</title><link>http://arxiv.org/abs/2405.05847v2</link><description>Representation learning, and interpreting learned representations, are keyareas of focus in machine learning and neuroscience. Both fields generally userepresentations as a means to understand or improve a system's computations. Inthis work, however, we explore surprising dissociations between representationand computation that may pose challenges for such efforts. We create datasetsin which we attempt to match the computational role that different featuresplay, while manipulating other properties of the features or the data. We trainvarious deep learning architectures to compute these multiple abstract featuresabout their inputs. We find that their learned feature representations aresystematically biased towards representing some features more strongly thanothers, depending upon extraneous properties such as feature complexity, theorder in which features are learned, and the distribution of features over theinputs. For example, features that are simpler to compute or learned first tendto be represented more strongly and densely than features that are more complexor learned later, even if all features are learned equally well. We alsoexplore how these biases are affected by architectures, optimizers, andtraining regimes (e.g., in transformers, features decoded earlier in the outputsequence also tend to be represented more strongly). Our results help tocharacterize the inductive biases of gradient-based representation learning.These results also highlight a key challenge for interpretability $-$ or forcomparing the representations of models and brains $-$ disentangling extraneousbiases from the computationally important aspects of a system's internalrepresentations.</description><author>Andrew Kyle Lampinen, Stephanie C. Y. Chan, Katherine Hermann</author><pubDate>Thu, 06 Jun 2024 16:22:31 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.05847v2</guid></item><item><title>Essentially Sharp Estimates on the Entropy Regularization Error in Discrete Discounted Markov Decision Processes</title><link>http://arxiv.org/abs/2406.04163v1</link><description>We study the error introduced by entropy regularization of infinite-horizondiscrete discounted Markov decision processes. We show that this errordecreases exponentially in the inverse regularization strength both in aweighted KL-divergence and in value with a problem-specific exponent. Weprovide a lower bound matching our upper bound up to a polynomial factor. Ourproof relies on the correspondence of the solutions of entropy-regularizedMarkov decision processes with gradient flows of the unregularized reward withrespect to a Riemannian metric common in natural policy gradient methods.Further, this correspondence allows us to identify the limit of the gradientflow as the generalized maximum entropy optimal policy, thereby characterizingthe implicit bias of the Kakade gradient flow which corresponds to atime-continuous version of the natural policy gradient method. We use this toshow that for entropy-regularized natural policy gradient methods the overallerror decays exponentially in the square root of the number of iterationsimproving existing sublinear guarantees.</description><author>Johannes Müller, Semih Cayci</author><pubDate>Thu, 06 Jun 2024 16:20:37 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.04163v1</guid></item><item><title>Adam: Dense Retrieval Distillation with Adaptive Dark Examples</title><link>http://arxiv.org/abs/2212.10192v2</link><description>To improve the performance of the dual-encoder retriever, one effectiveapproach is knowledge distillation from the cross-encoder ranker. Existingworks construct the candidate passages following the supervised learningsetting where a query is paired with a positive passage and a batch ofnegatives. However, through empirical observation, we find that even the hardnegatives from advanced methods are still too trivial for the teacher todistinguish, preventing the teacher from transferring abundant dark knowledgeto the student through its soft label. To alleviate this issue, we proposeADAM, a knowledge distillation framework that can better transfer the darkknowledge held in the teacher with Adaptive Dark exAMples. Different fromprevious works that only rely on one positive and hard negatives as candidatepassages, we create dark examples that all have moderate relevance to the querythrough mixing-up and masking in discrete space. Furthermore, as the quality ofknowledge held in different training instances varies as measured by theteacher's confidence score, we propose a self-paced distillation strategy thatadaptively concentrates on a subset of high-quality instances to conduct ourdark-example-based knowledge distillation to help the student learn better. Weconduct experiments on two widely-used benchmarks and verify the effectivenessof our method.</description><author>Chongyang Tao, Chang Liu, Tao Shen, Can Xu, Xiubo Geng, Binxing Jiao, Daxin Jiang</author><pubDate>Thu, 06 Jun 2024 16:20:27 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2212.10192v2</guid></item><item><title>Sparse Multi-baseline SAR Cross-modal 3D Reconstruction of Vehicle Targets</title><link>http://arxiv.org/abs/2406.04158v1</link><description>Multi-baseline SAR 3D imaging faces significant challenges due to datasparsity. In recent years, deep learning techniques have achieved notablesuccess in enhancing the quality of sparse SAR 3D imaging. However, previouswork typically rely on full-aperture high-resolution radar images to supervisethe training of deep neural networks (DNNs), utilizing only single-modalinformation from radar data. Consequently, imaging performance is limited, andacquiring full-aperture data for multi-baseline SAR is costly and sometimesimpractical in real-world applications. In this paper, we propose a Cross-ModalReconstruction Network (CMR-Net), which integrates differentiable render andcross-modal supervision with optical images to reconstruct highly sparsemulti-baseline SAR 3D images of vehicle targets into visually structured andhigh-resolution images. We meticulously designed the network architecture andtraining strategies to enhance network generalization capability. Remarkably,CMR-Net, trained solely on simulated data, demonstrates high-resolutionreconstruction capabilities on both publicly available simulation datasets andreal measured datasets, outperforming traditional sparse reconstructionalgorithms based on compressed sensing and other learning-based methods.Additionally, using optical images as supervision provides a cost-effective wayto build training datasets, reducing the difficulty of method dissemination.Our work showcases the broad prospects of deep learning in multi-baseline SAR3D imaging and offers a novel path for researching radar imaging based oncross-modal learning theory.</description><author>Da Li, Guoqiang Zhao, Houjun Sun, Jiacheng Bao</author><pubDate>Thu, 06 Jun 2024 16:18:59 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.04158v1</guid></item><item><title>Multi-modal Stance Detection: New Datasets and Model</title><link>http://arxiv.org/abs/2402.14298v3</link><description>Stance detection is a challenging task that aims to identify public opinionfrom social media platforms with respect to specific targets. Previous work onstance detection largely focused on pure texts. In this paper, we studymulti-modal stance detection for tweets consisting of texts and images, whichare prevalent in today's fast-growing social media platforms where people oftenpost multi-modal messages. To this end, we create five new multi-modal stancedetection datasets of different domains based on Twitter, in which each exampleconsists of a text and an image. In addition, we propose a simple yet effectiveTargeted Multi-modal Prompt Tuning framework (TMPT), where target informationis leveraged to learn multi-modal stance features from textual and visualmodalities. Experimental results on our five benchmark datasets show that theproposed TMPT achieves state-of-the-art performance in multi-modal stancedetection.</description><author>Bin Liang, Ang Li, Jingqian Zhao, Lin Gui, Min Yang, Yue Yu, Kam-Fai Wong, Ruifeng Xu</author><pubDate>Thu, 06 Jun 2024 16:17:58 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.14298v3</guid></item><item><title>Pointer-Guided Pre-Training: Infusing Large Language Models with Paragraph-Level Contextual Awareness</title><link>http://arxiv.org/abs/2406.04156v1</link><description>We introduce "pointer-guided segment ordering" (SO), a novel pre-trainingtechnique aimed at enhancing the contextual understanding of paragraph-leveltext representations in large language models. Our methodology leverages aself-attention-driven pointer network to restore the original sequence ofshuffled text segments, addressing the challenge of capturing the structuralcoherence and contextual dependencies within documents. This pre-trainingapproach is complemented by a fine-tuning methodology that incorporates dynamicsampling, augmenting the diversity of training instances and improving sampleefficiency for various downstream applications. We evaluate our method on adiverse set of datasets, demonstrating its efficacy in tasks requiringsequential text classification across scientific literature and financialreporting domains. Our experiments show that pointer-guided pre-trainingsignificantly enhances the model's ability to understand complex documentstructures, leading to state-of-the-art performance in downstreamclassification tasks.</description><author>Lars Hillebrand, Prabhupad Pradhan, Christian Bauckhage, Rafet Sifa</author><pubDate>Thu, 06 Jun 2024 16:17:51 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.04156v1</guid></item><item><title>Improving Physics-Augmented Continuum Neural Radiance Field-Based Geometry-Agnostic System Identification with Lagrangian Particle Optimization</title><link>http://arxiv.org/abs/2406.04155v1</link><description>Geometry-agnostic system identification is a technique for identifying thegeometry and physical properties of an object from video sequences without anygeometric assumptions. Recently, physics-augmented continuum neural radiancefields (PAC-NeRF) has demonstrated promising results for this technique byutilizing a hybrid Eulerian-Lagrangian representation, in which the geometry isrepresented by the Eulerian grid representations of NeRF, the physics isdescribed by a material point method (MPM), and they are connected viaLagrangian particles. However, a notable limitation of PAC-NeRF is that itsperformance is sensitive to the learning of the geometry from the first framesowing to its two-step optimization. First, the grid representations areoptimized with the first frames of video sequences, and then the physicalproperties are optimized through video sequences utilizing the fixedfirst-frame grid representations. This limitation can be critical when learningof the geometric structure is difficult, for example, in a few-shot (sparseview) setting. To overcome this limitation, we propose Lagrangian particleoptimization (LPO), in which the positions and features of particles areoptimized through video sequences in Lagrangian space. This method allows forthe optimization of the geometric structure across the entire video sequencewithin the physical constraints imposed by the MPM. The experimental resultsdemonstrate that the LPO is useful for geometric correction and physicalidentification in sparse-view settings.</description><author>Takuhiro Kaneko</author><pubDate>Thu, 06 Jun 2024 16:17:33 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.04155v1</guid></item><item><title>Learned Feature Importance Scores for Automated Feature Engineering</title><link>http://arxiv.org/abs/2406.04153v1</link><description>Feature engineering has demonstrated substantial utility for many machinelearning workflows, such as in the small data regime or when distributionshifts are severe. Thus automating this capability can relieve much manualeffort and improve model performance. Towards this, we propose AutoMAN, orAutomated Mask-based Feature Engineering, an automated feature engineeringframework that achieves high accuracy, low latency, and can be extended toheterogeneous and time-varying data. AutoMAN is based on effectively exploringthe candidate transforms space, without explicitly manifesting transformedfeatures. This is achieved by learning feature importance masks, which can beextended to support other modalities such as time series. AutoMAN learnsfeature transform importance end-to-end, incorporating a dataset's task targetdirectly into feature engineering, resulting in state-of-the-art performancewith significantly lower latency compared to alternatives.</description><author>Yihe Dong, Sercan Arik, Nathanael Yoder, Tomas Pfister</author><pubDate>Thu, 06 Jun 2024 16:17:00 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.04153v1</guid></item><item><title>DoWhy-GCM: An extension of DoWhy for causal inference in graphical causal models</title><link>http://arxiv.org/abs/2206.06821v2</link><description>We present DoWhy-GCM, an extension of the DoWhy Python library, whichleverages graphical causal models. Unlike existing causality libraries, whichmainly focus on effect estimation, DoWhy-GCM addresses diverse causal queries,such as identifying the root causes of outliers and distributional changes,attributing causal influences to the data generating process of each node, ordiagnosis of causal structures. With DoWhy-GCM, users typically specifycause-effect relations via a causal graph, fit causal mechanisms, and posecausal queries -- all with just a few lines of code. The general documentationis available at https://www.pywhy.org/dowhy and the DoWhy-GCM specific code athttps://github.com/py-why/dowhy/tree/main/dowhy/gcm.</description><author>Patrick Blöbaum, Peter Götz, Kailash Budhathoki, Atalanti A. Mastakouri, Dominik Janzing</author><pubDate>Thu, 06 Jun 2024 16:16:26 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2206.06821v2</guid></item><item><title>AgentGym: Evolving Large Language Model-based Agents across Diverse Environments</title><link>http://arxiv.org/abs/2406.04151v1</link><description>Building generalist agents that can handle diverse tasks and evolvethemselves across different environments is a long-term goal in the AIcommunity. Large language models (LLMs) are considered a promising foundationto build such agents due to their generalized capabilities. Current approacheseither have LLM-based agents imitate expert-provided trajectories step-by-step,requiring human supervision, which is hard to scale and limits environmentalexploration; or they let agents explore and learn in isolated environments,resulting in specialist agents with limited generalization. In this paper, wetake the first step towards building generally-capable LLM-based agents withself-evolution ability. We identify a trinity of ingredients: 1) diverseenvironments for agent exploration and learning, 2) a trajectory set to equipagents with basic capabilities and prior knowledge, and 3) an effective andscalable evolution method. We propose AgentGym, a new framework featuring avariety of environments and tasks for broad, real-time, uni-format, andconcurrent agent exploration. AgentGym also includes a database with expandedinstructions, a benchmark suite, and high-quality trajectories acrossenvironments. Next, we propose a novel method, AgentEvol, to investigate thepotential of agent self-evolution beyond previously seen data across tasks andenvironments. Experimental results show that the evolved agents can achieveresults comparable to SOTA models. We release the AgentGym suite, including theplatform, dataset, benchmark, checkpoints, and algorithm implementations. TheAgentGym suite is available on https://github.com/WooooDyy/AgentGym.</description><author>Zhiheng Xi, Yiwen Ding, Wenxiang Chen, Boyang Hong, Honglin Guo, Junzhe Wang, Dingwen Yang, Chenyang Liao, Xin Guo, Wei He, Songyang Gao, Lu Chen, Rui Zheng, Yicheng Zou, Tao Gui, Qi Zhang, Xipeng Qiu, Xuanjing Huang, Zuxuan Wu, Yu-Gang Jiang</author><pubDate>Thu, 06 Jun 2024 16:15:41 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.04151v1</guid></item><item><title>A novel robust meta-analysis model using the $t$ distribution for outlier accommodation and detection</title><link>http://arxiv.org/abs/2406.04150v1</link><description>Random effects meta-analysis model is an important tool for integratingresults from multiple independent studies. However, the standard model is basedon the assumption of normal distributions for both random effects andwithin-study errors, making it susceptible to outlying studies. Although robustmodeling using the $t$ distribution is an appealing idea, the existing work,that explores the use of the $t$ distribution only for random effects, involvescomplicated numerical integration and numerical optimization. In this paper, anovel robust meta-analysis model using the $t$ distribution is proposed($t$Meta). The novelty is that the marginal distribution of the effect size in$t$Meta follows the $t$ distribution, enabling that $t$Meta can simultaneouslyaccommodate and detect outlying studies in a simple and adaptive manner. Asimple and fast EM-type algorithm is developed for maximum likelihoodestimation. Due to the mathematical tractability of the $t$ distribution,$t$Meta frees from numerical integration and allows for efficient optimization.Experiments on real data demonstrate that $t$Meta is compared favorably withrelated competitors in situations involving mild outliers. Moreover, in thepresence of gross outliers, while related competitors may fail, $t$Metacontinues to perform consistently and robustly.</description><author>Yue Wang, Jianhua Zhao, Fen Jiang, Lei Shi, Jianxin Pan</author><pubDate>Thu, 06 Jun 2024 16:15:39 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.04150v1</guid></item><item><title>Characterizing segregation in blast rock piles a deep-learning approach leveraging aerial image analysis</title><link>http://arxiv.org/abs/2406.04149v1</link><description>Blasted rock material serves a critical role in various engineeringapplications, yet the phenomenon of segregation-where particle sizes varysignificantly along the gradient of a quarry pile-presents challenges foroptimizing quarry material storage and handling. This study introduces anadvanced image analysis methodology to characterize such segregation of rockfragments. The accurate delineation of detailed rock fragment sizedistributions was achieved through the analysis of drone-captured imagery,coupled with the application of an enhanced Unet semantic segmentation modelintegrated with an expansion-based post-processing technique. The quarry slopewas stratified into four vertical sections, with the size distribution of eachsection quantified via ellipsoid shape approximations. Our results disclosepronounced vertical segregation patterns, with finer particles concentrated inthe upper slope regions and coarser particles in the lower. Utilizing relativecharacteristic diameters, we offered insight into the degree of segregation,thereby illustrating the spatial heterogeneity in fragment size more clearly.The techniques outlined in this study deliver a scalable and accurate methodfor assessing fragment size distribution, with the potential to better informresource management and operational decisions in quarry management.</description><author>Chengeng Liu, Sihong Liu, Chaomin Shen, Yupeng Gao, Yuxuan Liu</author><pubDate>Thu, 06 Jun 2024 16:13:56 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.04149v1</guid></item><item><title>Fast Redescription Mining Using Locality-Sensitive Hashing</title><link>http://arxiv.org/abs/2406.04148v1</link><description>Redescription mining is a data analysis technique that has found applicationsin diverse fields. The most used redescription mining approaches involve twophases: finding matching pairs among data attributes and extending the pairs.This process is relatively efficient when the number of attributes remainslimited and when the attributes are Boolean, but becomes almost intractablewhen the data consist of many numerical attributes. In this paper, we presentnew algorithms that perform the matching and extension orders of magnitudefaster than the existing approaches. Our algorithms are based onlocality-sensitive hashing with a tailored approach to handle thediscretisation of numerical attributes as used in redescription mining.</description><author>Maiju Karjalainen, Esther Galbrun, Pauli Miettinen</author><pubDate>Thu, 06 Jun 2024 16:13:48 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.04148v1</guid></item><item><title>E(n) Equivariant Message Passing Cellular Networks</title><link>http://arxiv.org/abs/2406.03145v2</link><description>This paper introduces E(n) Equivariant Message Passing Cellular Networks(EMPCNs), an extension of E(n) Equivariant Graph Neural Networks toCW-complexes. Our approach addresses two aspects of geometric message passingnetworks: 1) enhancing their expressiveness by incorporating arbitrary cells,and 2) achieving this in a computationally efficient way with a decoupledEMPCNs technique. We demonstrate that EMPCNs achieve close to state-of-the-artperformance on multiple tasks without the need for steerability, includingmany-body predictions and motion capture. Moreover, ablation studies confirmthat decoupled EMPCNs exhibit stronger generalization capabilities than theirnon-topologically informed counterparts. These findings show that EMPCNs can beused as a scalable and expressive framework for higher-order message passing ingeometric and topological graphs</description><author>Veljko Kovač, Erik J. Bekkers, Pietro Liò, Floor Eijkelboom</author><pubDate>Thu, 06 Jun 2024 16:12:55 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.03145v2</guid></item><item><title>MVTN: Learning Multi-View Transformations for 3D Understanding</title><link>http://arxiv.org/abs/2212.13462v2</link><description>Multi-view projection techniques have shown themselves to be highly effectivein achieving top-performing results in the recognition of 3D shapes. Thesemethods involve learning how to combine information from multiple view-points.However, the camera view-points from which these views are obtained are oftenfixed for all shapes. To overcome the static nature of current multi-viewtechniques, we propose learning these view-points. Specifically, we introducethe Multi-View Transformation Network (MVTN), which uses differentiablerendering to determine optimal view-points for 3D shape recognition. As aresult, MVTN can be trained end-to-end with any multi-view network for 3D shapeclassification. We integrate MVTN into a novel adaptive multi-view pipelinethat is capable of rendering both 3D meshes and point clouds. Our approachdemonstrates state-of-the-art performance in 3D classification and shaperetrieval on several benchmarks (ModelNet40, ScanObjectNN, ShapeNet Core55).Further analysis indicates that our approach exhibits improved robustness toocclusion compared to other methods. We also investigate additional aspects ofMVTN, such as 2D pretraining and its use for segmentation. To support furtherresearch in this area, we have released MVTorch, a PyTorch library for 3Dunderstanding and generation using multi-view projections.</description><author>Abdullah Hamdi, Faisal AlZahrani, Silvio Giancola, Bernard Ghanem</author><pubDate>Thu, 06 Jun 2024 16:12:31 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2212.13462v2</guid></item><item><title>PEMT: Multi-Task Correlation Guided Mixture-of-Experts Enables Parameter-Efficient Transfer Learning</title><link>http://arxiv.org/abs/2402.15082v2</link><description>Parameter-efficient fine-tuning (PEFT) has emerged as an effective method foradapting pre-trained language models to various tasks efficiently. Recently,there has been a growing interest in transferring knowledge from one ormultiple tasks to the downstream target task to achieve performanceimprovements. However, current approaches typically either train adapters onindividual tasks or distill shared knowledge from source tasks, failing tofully exploit task-specific knowledge and the correlation between source andtarget tasks. To overcome these limitations, we propose PEMT, a novelparameter-efficient fine-tuning framework based on multi-task transferlearning. PEMT extends the mixture-of-experts (MoE) framework to capture thetransferable knowledge as a weighted combination of adapters trained on sourcetasks. These weights are determined by a gated unit, measuring the correlationbetween the target and each source task using task description prompt vectors.To fully exploit the task-specific knowledge, we also propose the Task SparsityLoss to improve the sparsity of the gated unit. We conduct experiments on abroad range of tasks over 17 datasets. The experimental results demonstrate ourPEMT yields stable improvements over full fine-tuning, and state-of-the-artPEFT and knowledge transferring methods on various tasks. The results highlightthe effectiveness of our method which is capable of sufficiently exploiting theknowledge and correlation features across multiple tasks.</description><author>Zhisheng Lin, Han Fu, Chenghao Liu, Zhuo Li, Jianling Sun</author><pubDate>Thu, 06 Jun 2024 16:11:29 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.15082v2</guid></item><item><title>Towards Understanding Task-agnostic Debiasing Through the Lenses of Intrinsic Bias and Forgetfulness</title><link>http://arxiv.org/abs/2406.04146v1</link><description>While task-agnostic debiasing provides notable generalizability and reducedreliance on downstream data, its impact on language modeling ability and therisk of relearning social biases from downstream task-specific data remain asthe two most significant challenges when debiasing Pretrained Language Models(PLMs). The impact on language modeling ability can be alleviated given ahigh-quality and long-contextualized debiasing corpus, but there remains adeficiency in understanding the specifics of relearning biases. We empiricallyascertain that the effectiveness of task-agnostic debiasing hinges on thequantitative bias level of both the task-specific data used for downstreamapplications and the debiased model. We empirically show that the lower boundof the bias level of the downstream fine-tuned model can be approximated by thebias level of the debiased model, in most practical cases. To gain morein-depth understanding about how the parameters of PLMs change duringfine-tuning due to the forgetting issue of PLMs, we propose a novel frameworkwhich can Propagate Socially-fair Debiasing to Downstream Fine-tuning,ProSocialTuning. Our proposed framework can push the fine-tuned model toapproach the bias lower bound during downstream fine-tuning, indicating thatthe ineffectiveness of debiasing can be alleviated by overcoming the forgettingissue through regularizing successfully debiased attention heads based on thePLMs' bias levels from stages of pretraining and debiasing.</description><author>Guangliang Liu, Milad Afshari, Xitong Zhang, Zhiyu Xue, Avrajit Ghosh, Bidhan Bashyal, Rongrong Wang, Kristen Johnson</author><pubDate>Thu, 06 Jun 2024 16:11:11 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.04146v1</guid></item><item><title>Every Answer Matters: Evaluating Commonsense with Probabilistic Measures</title><link>http://arxiv.org/abs/2406.04145v1</link><description>Large language models have demonstrated impressive performance on commonsensetasks; however, these tasks are often posed as multiple-choice questions,allowing models to exploit systematic biases. Commonsense is also inherentlyprobabilistic with multiple correct answers. The purpose of "boiling water"could be making tea and cooking, but it also could be killing germs. Existingtasks do not capture the probabilistic nature of common sense. To this end, wepresent commonsense frame completion (CFC), a new generative task thatevaluates common sense via multiple open-ended generations. We also propose amethod of probabilistic evaluation that strongly correlates with humanjudgments. Humans drastically outperform strong language model baselines on ourdataset, indicating this approach is both a challenging and useful evaluationof machine common sense.</description><author>Qi Cheng, Michael Boratko, Pranay Kumar Yelugam, Tim O'Gorman, Nalini Singh, Andrew McCallum, Xiang Lorraine Li</author><pubDate>Thu, 06 Jun 2024 16:10:27 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.04145v1</guid></item><item><title>Breaking through the learning plateaus of in-context learning in Transformer</title><link>http://arxiv.org/abs/2309.06054v3</link><description>In-context learning, i.e., learning from context examples, is an impressiveability of Transformer. Training Transformers to possess this in-contextlearning skill is computationally intensive due to the occurrence of learningplateaus, which are periods within the training process where there is minimalor no enhancement in the model's in-context learning capability. To study themechanism behind the learning plateaus, we conceptually seperate a componentwithin the model's internal representation that is exclusively affected by themodel's weights. We call this the "weights component", and the remainder isidentified as the "context component". By conducting meticulous and controlledexperiments on synthetic tasks, we note that the persistence of learningplateaus correlates with compromised functionality of the weights component.Recognizing the impaired performance of the weights component as a fundamentalbehavior drives learning plateaus, we have developed three strategies toexpedite the learning of Transformers. The effectiveness of these strategies isfurther confirmed in natural language processing tasks. In conclusion, ourresearch demonstrates the feasibility of cultivating a powerful in-contextlearning ability within AI systems in an eco-friendly manner.</description><author>Jingwen Fu, Tao Yang, Yuwang Wang, Yan Lu, Nanning Zheng</author><pubDate>Thu, 06 Jun 2024 16:09:52 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2309.06054v3</guid></item><item><title>Redundancy-aware Action Spaces for Robot Learning</title><link>http://arxiv.org/abs/2406.04144v1</link><description>Joint space and task space control are the two dominant action modes forcontrolling robot arms within the robot learning literature. Actions in jointspace provide precise control over the robot's pose, but tend to suffer frominefficient training; actions in task space boast data-efficient training butsacrifice the ability to perform tasks in confined spaces due to limitedcontrol over the full joint configuration. This work analyses the criteria fordesigning action spaces for robot manipulation and introduces ER (End-effectorRedundancy), a novel action space formulation that, by addressing theredundancies present in the manipulator, aims to combine the advantages of bothjoint and task spaces, offering fine-grained comprehensive control withoveractuated robot arms whilst achieving highly efficient robot learning. Wepresent two implementations of ER, ERAngle (ERA) and ERJoint (ERJ), and we showthat ERJ in particular demonstrates superior performance across multiplesettings, especially when precise control over the robot configuration isrequired. We validate our results both in simulated and real roboticenvironments.</description><author>Pietro Mazzaglia, Nicholas Backshall, Xiao Ma, Stephen James</author><pubDate>Thu, 06 Jun 2024 16:08:41 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.04144v1</guid></item><item><title>Do Language Models Understand Morality? Towards a Robust Detection of Moral Content</title><link>http://arxiv.org/abs/2406.04143v1</link><description>The task of detecting moral values in text has significant implications invarious fields, including natural language processing, social sciences, andethical decision-making. Previously proposed supervised models often sufferfrom overfitting, leading to hyper-specialized moral classifiers that struggleto perform well on data from different domains. To address this issue, weintroduce novel systems that leverage abstract concepts and common-senseknowledge acquired from Large Language Models and Natural Language Inferencemodels during previous stages of training on multiple data sources. By doingso, we aim to develop versatile and robust methods for detecting moral valuesin real-world scenarios. Our approach uses the GPT 3.5 model as a zero-shotready-made unsupervised multi-label classifier for moral values detection,eliminating the need for explicit training on labeled data. We compare it witha smaller NLI-based zero-shot model. The results show that the NLI approachachieves competitive results compared to the Davinci model. Furthermore, weconduct an in-depth investigation of the performance of supervised systems inthe context of cross-domain multi-label moral value detection. This involvestraining supervised models on different domains to explore their effectivenessin handling data from different sources and comparing their performance withthe unsupervised methods. Our contributions encompass a thorough analysis ofboth supervised and unsupervised methodologies for cross-domain valuedetection. We introduce the Davinci model as a state-of-the-art zero-shotunsupervised moral values classifier, pushing the boundaries of moral valuedetection without the need for explicit training on labeled data. Additionally,we perform a comparative evaluation of our approach with the supervised models,shedding light on their respective strengths and weaknesses.</description><author>Luana Bulla, Aldo Gangemi, Misael Mongiovì</author><pubDate>Thu, 06 Jun 2024 16:08:16 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.04143v1</guid></item><item><title>Stochastic Polyak Step-sizes and Momentum: Convergence Guarantees and Practical Performance</title><link>http://arxiv.org/abs/2406.04142v1</link><description>Stochastic gradient descent with momentum, also known as Stochastic HeavyBall method (SHB), is one of the most popular algorithms for solvinglarge-scale stochastic optimization problems in various machine learning tasks.In practical scenarios, tuning the step-size and momentum parameters of themethod is a prohibitively expensive and time-consuming process. In this work,inspired by the recent advantages of stochastic Polyak step-size in theperformance of stochastic gradient descent (SGD), we propose and explore newPolyak-type variants suitable for the update rule of the SHB method. Inparticular, using the Iterate Moving Average (IMA) viewpoint of SHB, we proposeand analyze three novel step-size selections: MomSPS$_{\max}$, MomDecSPS, andMomAdaSPS. For MomSPS$_{\max}$, we provide convergence guarantees for SHB to aneighborhood of the solution for convex and smooth problems (without assuminginterpolation). If interpolation is also satisfied, then using MomSPS$_{\max}$,SHB converges to the true solution at a fast rate matching the deterministicHB. The other two variants, MomDecSPS and MomAdaSPS, are the first adaptivestep-sizes for SHB that guarantee convergence to the exact minimizer withoutprior knowledge of the problem parameters and without assuming interpolation.The convergence analysis of SHB is tight and obtains the convergence guaranteesof SGD with stochastic Polyak step-sizes as a special case. We supplement ouranalysis with experiments that validate the theory and demonstrate theeffectiveness and robustness of the new algorithms.</description><author>Dimitris Oikonomou, Nicolas Loizou</author><pubDate>Thu, 06 Jun 2024 16:08:06 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.04142v1</guid></item><item><title>Model Free Prediction with Uncertainty Assessment</title><link>http://arxiv.org/abs/2405.12684v2</link><description>Deep nonparametric regression, characterized by the utilization of deepneural networks to learn target functions, has emerged as a focus of researchattention in recent years. Despite considerable progress in understandingconvergence rates, the absence of asymptotic properties hinders rigorousstatistical inference. To address this gap, we propose a novel framework thattransforms the deep estimation paradigm into a platform conducive toconditional mean estimation, leveraging the conditional diffusion model.Theoretically, we develop an end-to-end convergence rate for the conditionaldiffusion model and establish the asymptotic normality of the generatedsamples. Consequently, we are equipped to construct confidence regions,facilitating robust statistical inference. Furthermore, through numericalexperiments, we empirically validate the efficacy of our proposed methodology.</description><author>Yuling Jiao, Lican Kang, Jin Liu, Heng Peng, Heng Zuo</author><pubDate>Thu, 06 Jun 2024 16:06:54 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.12684v2</guid></item><item><title>The 3D-PC: a benchmark for visual perspective taking in humans and machines</title><link>http://arxiv.org/abs/2406.04138v1</link><description>Visual perspective taking (VPT) is the ability to perceive and reason aboutthe perspectives of others. It is an essential feature of human intelligence,which develops over the first decade of life and requires an ability to processthe 3D structure of visual scenes. A growing number of reports have indicatedthat deep neural networks (DNNs) become capable of analyzing 3D scenes aftertraining on large image datasets. We investigated if this emergent ability for3D analysis in DNNs is sufficient for VPT with the 3D perception challenge(3D-PC): a novel benchmark for 3D perception in humans and DNNs. The 3D-PC iscomprised of three 3D-analysis tasks posed within natural scene images: 1. asimple test of object depth order, 2. a basic VPT task (VPT-basic), and 3.another version of VPT (VPT-Strategy) designed to limit the effectiveness of"shortcut" visual strategies. We tested human participants (N=33) and linearlyprobed or text-prompted over 300 DNNs on the challenge and found that nearlyall of the DNNs approached or exceeded human accuracy in analyzing object depthorder. Surprisingly, DNN accuracy on this task correlated with their objectrecognition performance. In contrast, there was an extraordinary gap betweenDNNs and humans on VPT-basic. Humans were nearly perfect, whereas most DNNswere near chance. Fine-tuning DNNs on VPT-basic brought them close to humanperformance, but they, unlike humans, dropped back to chance when tested onVPT-perturb. Our challenge demonstrates that the training routines andarchitectures of today's DNNs are well-suited for learning basic 3D propertiesof scenes and objects but are ill-suited for reasoning about these propertieslike humans do. We release our 3D-PC datasets and code to help bridge this gapin 3D perception between humans and machines.</description><author>Drew Linsley, Peisen Zhou, Alekh Karkada Ashok, Akash Nagaraj, Gaurav Gaonkar, Francis E Lewis, Zygmunt Pizlo, Thomas Serre</author><pubDate>Thu, 06 Jun 2024 15:59:39 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.04138v1</guid></item><item><title>Optimal Batched Linear Bandits</title><link>http://arxiv.org/abs/2406.04137v1</link><description>We introduce the E$^4$ algorithm for the batched linear bandit problem,incorporating an Explore-Estimate-Eliminate-Exploit framework. With a properchoice of exploration rate, we prove E$^4$ achieves the finite-time minimaxoptimal regret with only $O(\log\log T)$ batches, and the asymptoticallyoptimal regret with only $3$ batches as $T\rightarrow\infty$, where $T$ is thetime horizon. We further prove a lower bound on the batch complexity of linearcontextual bandits showing that any asymptotically optimal algorithm mustrequire at least $3$ batches in expectation as $T\rightarrow\infty$, whichindicates E$^4$ achieves the asymptotic optimality in regret and batchcomplexity simultaneously. To the best of our knowledge, E$^4$ is the firstalgorithm for linear bandits that simultaneously achieves the minimax andasymptotic optimality in regret with the corresponding optimal batchcomplexities. In addition, we show that with another choice of exploration rateE$^4$ achieves an instance-dependent regret bound requiring at most $O(\log T)$batches, and maintains the minimax optimality and asymptotic optimality. Weconduct thorough experiments to evaluate our algorithm on randomly generatedinstances and the challenging \textit{End of Optimism} instances\citep{lattimore2017end} which were shown to be hard to learn for optimismbased algorithms. Empirical results show that E$^4$ consistently outperformsbaseline algorithms with respect to regret minimization, batch complexity, andcomputational efficiency.</description><author>Xuanfei Ren, Tianyuan Jin, Pan Xu</author><pubDate>Thu, 06 Jun 2024 15:57:52 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.04137v1</guid></item><item><title>Legal Judgment Reimagined: PredEx and the Rise of Intelligent AI Interpretation in Indian Courts</title><link>http://arxiv.org/abs/2406.04136v1</link><description>In the era of Large Language Models (LLMs), predicting judicial outcomesposes significant challenges due to the complexity of legal proceedings and thescarcity of expert-annotated datasets. Addressing this, we introduce\textbf{Pred}iction with \textbf{Ex}planation (\texttt{PredEx}), the largestexpert-annotated dataset for legal judgment prediction and explanation in theIndian context, featuring over 15,000 annotations. This groundbreaking corpussignificantly enhances the training and evaluation of AI models in legalanalysis, with innovations including the application of instruction tuning toLLMs. This method has markedly improved the predictive accuracy and explanatorydepth of these models for legal judgments. We employed varioustransformer-based models, tailored for both general and Indian legal contexts.Through rigorous lexical, semantic, and expert assessments, our modelseffectively leverage \texttt{PredEx} to provide precise predictions andmeaningful explanations, establishing it as a valuable benchmark for both thelegal profession and the NLP community.</description><author>Shubham Kumar Nigam, Anurag Sharma, Danush Khanna, Noel Shallum, Kripabandhu Ghosh, Arnab Bhattacharya</author><pubDate>Thu, 06 Jun 2024 15:57:48 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.04136v1</guid></item><item><title>Generalised Diffusion Probabilistic Scale-Spaces</title><link>http://arxiv.org/abs/2309.08511v2</link><description>Diffusion probabilistic models excel at sampling new images from learneddistributions. Originally motivated by drift-diffusion concepts from physics,they apply image perturbations such as noise and blur in a forward process thatresults in a tractable probability distribution. A corresponding learnedreverse process generates images and can be conditioned on side information,which leads to a wide variety of practical applications. Most of the researchfocus currently lies on practice-oriented extensions. In contrast, thetheoretical background remains largely unexplored, in particular the relationsto drift-diffusion. In order to shed light on these connections to classicalimage filtering, we propose a generalised scale-space theory for diffusionprobabilistic models. Moreover, we show conceptual and empirical connections todiffusion and osmosis filters.</description><author>Pascal Peter</author><pubDate>Thu, 06 Jun 2024 15:56:47 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2309.08511v2</guid></item><item><title>When is Tree Search Useful for LLM Planning? It Depends on the Discriminator</title><link>http://arxiv.org/abs/2402.10890v2</link><description>In this paper, we examine how large language models (LLMs) solve multi-stepproblems under a language agent framework with three components: a generator, adiscriminator, and a planning method. We investigate the practical utility oftwo advanced planning methods, iterative correction and tree search. We presenta comprehensive analysis of how discrimination accuracy affects the overallperformance of agents when using these two methods or a simpler method,re-ranking. Experiments on two tasks, text-to-SQL parsing and mathematicalreasoning, show that: (1) advanced planning methods demand discriminators withat least 90% accuracy to achieve significant improvements over re-ranking; (2)current LLMs' discrimination abilities have not met the needs of advancedplanning methods to achieve such improvements; (3) with LLM-baseddiscriminators, advanced planning methods may not adequately balance accuracyand efficiency. For example, compared to the other two methods, tree search isat least 10--20 times slower but leads to negligible performance gains, whichhinders its real-world applications. Code and data are available athttps://github.com/OSU-NLP-Group/llm-planning-eval.</description><author>Ziru Chen, Michael White, Raymond Mooney, Ali Payani, Yu Su, Huan Sun</author><pubDate>Thu, 06 Jun 2024 15:55:40 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.10890v2</guid></item><item><title>LenslessFace: An End-to-End Optimized Lensless System for Privacy-Preserving Face Verification</title><link>http://arxiv.org/abs/2406.04129v1</link><description>Lensless cameras, innovatively replacing traditional lenses for ultra-thin,flat optics, encode light directly onto sensors, producing images that are notimmediately recognizable. This compact, lightweight, and cost-effective imagingsolution offers inherent privacy advantages, making it attractive forprivacy-sensitive applications like face verification. Typical lensless faceverification adopts a two-stage process of reconstruction followed byverification, incurring privacy risks from reconstructed faces and highcomputational costs. This paper presents an end-to-end optimization approachfor privacy-preserving face verification directly on encoded lensless captures,ensuring that the entire software pipeline remains encoded with no visiblefaces as intermediate results. To achieve this, we propose several techniquesto address unique challenges from the lensless setup which precludestraditional face detection and alignment. Specifically, we propose a facecenter alignment scheme, an augmentation curriculum to build robustness againstvariations, and a knowledge distillation method to smooth optimization andenhance performance. Evaluations under both simulation and real environmentdemonstrate our method outperforms two-stage lensless verification whileenhancing privacy and efficiency. Project website:\url{lenslessface.github.io}.</description><author>Xin Cai, Hailong Zhang, Chenchen Wang, Wentao Liu, Jinwei Gu, Tianfan Xue</author><pubDate>Thu, 06 Jun 2024 15:50:15 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.04129v1</guid></item><item><title>Are We Done with MMLU?</title><link>http://arxiv.org/abs/2406.04127v1</link><description>Maybe not. We identify and analyse errors in the popular Massive MultitaskLanguage Understanding (MMLU) benchmark. Even though MMLU is widely adopted,our analysis demonstrates numerous ground truth errors that obscure the truecapabilities of LLMs. For example, we find that 57% of the analysed questionsin the Virology subset contain errors. To address this issue, we introduce acomprehensive framework for identifying dataset errors using a novel errortaxonomy. Then, we create MMLU-Redux, which is a subset of 3,000 manuallyre-annotated questions across 30 MMLU subjects. Using MMLU-Redux, wedemonstrate significant discrepancies with the model performance metrics thatwere originally reported. Our results strongly advocate for revising MMLU'serror-ridden questions to enhance its future utility and reliability as abenchmark. Therefore, we open up MMLU-Redux for additional annotationhttps://huggingface.co/datasets/edinburgh-dawg/mmlu-redux.</description><author>Aryo Pradipta Gema, Joshua Ong Jun Leang, Giwon Hong, Alessio Devoto, Alberto Carlo Maria Mancino, Rohit Saxena, Xuanli He, Yu Zhao, Xiaotang Du, Mohammad Reza Ghasemi Madani, Claire Barale, Robert McHardy, Joshua Harris, Jean Kaddour, Emile van Krieken, Pasquale Minervini</author><pubDate>Thu, 06 Jun 2024 15:49:06 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.04127v1</guid></item><item><title>Leveraging Codebook Knowledge with NLI and ChatGPT for Zero-Shot Political Relation Classification</title><link>http://arxiv.org/abs/2308.07876v3</link><description>Is it possible accurately classify political relations within evolving eventontologies without extensive annotations? This study investigates zero-shotlearning methods that use expert knowledge from existing annotation codebook,and evaluates the performance of advanced ChatGPT (GPT-3.5/4) and a naturallanguage inference (NLI)-based model called ZSP. ChatGPT uses codebook'slabeled summaries as prompts, whereas ZSP breaks down the classification taskinto context, event mode, and class disambiguation to refine task-specifichypotheses. This decomposition enhances interpretability, efficiency, andadaptability to schema changes. The experiments reveal ChatGPT's strengths andlimitations, and crucially show ZSP's outperformance of dictionary-basedmethods and its competitive edge over some supervised models. These findingsaffirm the value of ZSP for validating event records and advancing ontologydevelopment. Our study underscores the efficacy of leveraging transfer learningand existing domain expertise to enhance research efficiency and scalability.</description><author>Yibo Hu, Erick Skorupa Parolin, Latifur Khan, Patrick T. Brandt, Javier Osorio, Vito J. D'Orazio</author><pubDate>Thu, 06 Jun 2024 15:46:44 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2308.07876v3</guid></item><item><title>RIFF: Learning to Rephrase Inputs for Few-shot Fine-tuning of Language Models</title><link>http://arxiv.org/abs/2403.02271v2</link><description>Pre-trained Language Models (PLMs) can be accurately fine-tuned fordownstream text processing tasks. Recently, researchers have introduced severalparameter-efficient fine-tuning methods that optimize input prompts or adjust asmall number of model parameters (e.g LoRA). In this study, we explore theimpact of altering the input text of the original task in conjunction withparameter-efficient fine-tuning methods. To most effectively rewrite the inputtext, we train a few-shot paraphrase model with a Maximum-Marginal Likelihoodobjective. Using six few-shot text classification datasets, we show thatenriching data with paraphrases at train and test time enhances the performancebeyond what can be achieved with parameter-efficient fine-tuning alone. Thecode used for our experiments can be found athttps://github.com/SaeedNajafi/RIFF.</description><author>Saeed Najafi, Alona Fyshe</author><pubDate>Thu, 06 Jun 2024 15:43:30 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.02271v2</guid></item><item><title>T-RAG: Lessons from the LLM Trenches</title><link>http://arxiv.org/abs/2402.07483v2</link><description>Large Language Models (LLM) have shown remarkable language capabilitiesfueling attempts to integrate them into applications across a wide range ofdomains. An important application area is question answering over privateenterprise documents where the main considerations are data security, whichnecessitates applications that can be deployed on-prem, limited computationalresources and the need for a robust application that correctly responds toqueries. Retrieval-Augmented Generation (RAG) has emerged as the most prominentframework for building LLM-based applications. While building a RAG isrelatively straightforward, making it robust and a reliable applicationrequires extensive customization and relatively deep knowledge of theapplication domain. We share our experiences building and deploying an LLMapplication for question answering over private organizational documents. Ourapplication combines the use of RAG with a finetuned open-source LLM.Additionally, our system, which we call Tree-RAG (T-RAG), uses a tree structureto represent entity hierarchies within the organization. This is used togenerate a textual description to augment the context when responding to userqueries pertaining to entities within the organization's hierarchy. Ourevaluations, including a Needle in a Haystack test, show that this combinationperforms better than a simple RAG or finetuning implementation. Finally, weshare some lessons learned based on our experiences building an LLM applicationfor real-world use.</description><author>Masoomali Fatehkia, Ji Kim Lucas, Sanjay Chawla</author><pubDate>Thu, 06 Jun 2024 15:42:47 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.07483v2</guid></item><item><title>DiffCAD: Weakly-Supervised Probabilistic CAD Model Retrieval and Alignment from an RGB Image</title><link>http://arxiv.org/abs/2311.18610v2</link><description>Perceiving 3D structures from RGB images based on CAD model primitives canenable an effective, efficient 3D object-based representation of scenes.However, current approaches rely on supervision from expensive annotations ofCAD models associated with real images, and encounter challenges due to theinherent ambiguities in the task -- both in depth-scale ambiguity in monocularperception, as well as inexact matches of CAD database models to realobservations. We thus propose DiffCAD, the first weakly-supervisedprobabilistic approach to CAD retrieval and alignment from an RGB image. Weformulate this as a conditional generative task, leveraging diffusion to learnimplicit probabilistic models capturing the shape, pose, and scale of CADobjects in an image. This enables multi-hypothesis generation of differentplausible CAD reconstructions, requiring only a few hypotheses to characterizeambiguities in depth/scale and inexact shape matches. Our approach is trainedonly on synthetic data, leveraging monocular depth and mask estimates to enablerobust zero-shot adaptation to various real target domains. Despite beingtrained solely on synthetic data, our multi-hypothesis approach can evensurpass the supervised state-of-the-art on the Scan2CAD dataset by 5.9% with 8hypotheses.</description><author>Daoyi Gao, Dávid Rozenberszki, Stefan Leutenegger, Angela Dai</author><pubDate>Thu, 06 Jun 2024 15:37:01 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.18610v2</guid></item><item><title>Promoting Fairness and Diversity in Speech Datasets for Mental Health and Neurological Disorders Research</title><link>http://arxiv.org/abs/2406.04116v1</link><description>Current research in machine learning and artificial intelligence is largelycentered on modeling and performance evaluation, less so on data collection.However, recent research demonstrated that limitations and biases in data maynegatively impact trustworthiness and reliability. These aspects areparticularly impactful on sensitive domains such as mental health andneurological disorders, where speech data are used to develop AI applicationsaimed at improving the health of patients and supporting healthcare providers.In this paper, we chart the landscape of available speech datasets for thisdomain, to highlight possible pitfalls and opportunities for improvement andpromote fairness and diversity. We present a comprehensive list of desideratafor building speech datasets for mental health and neurological disorders anddistill it into a checklist focused on ethical concerns to foster moreresponsible research.</description><author>Eleonora Mancini, Ana Tanevska, Andrea Galassi, Alessio Galatolo, Federico Ruggeri, Paolo Torroni</author><pubDate>Thu, 06 Jun 2024 15:36:07 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.04116v1</guid></item><item><title>Global Parameterization-based Texture Space Optimization</title><link>http://arxiv.org/abs/2406.04115v1</link><description>Texture mapping is a common technology in the area of computer graphics, itmaps the 3D surface space onto the 2D texture space. However, the loose texturespace will reduce the efficiency of data storage and GPU memory addressing inthe rendering process. Many of the existing methods focus on repacking giventextures, but they still suffer from high computational cost and hardly producea wholly tight texture space. In this paper, we propose a method to optimizethe texture space and produce a new texture mapping which is compact based onglobal parameterization. The proposed method is computationally robust andefficient. Experiments show the effectiveness of the proposed method and thepotency in improving the storage and rendering efficiency.</description><author>Wei Chen, Yuxue Ren, Na Lei, Zhongxuan Luo, Xianfeng Gu</author><pubDate>Thu, 06 Jun 2024 15:36:02 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.04115v1</guid></item></channel></rss>