<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/"><channel><title>Arxivfresh papers</title><link></link><description>Arxiv paper</description><language>en-US</language><lastBuildDate>Mon, 28 Oct 2024 13:00:26 GMT</lastBuildDate><generator>rfeed v1.0.0</generator><docs>https://github.com/svpino/rfeed/blob/master/README.md</docs><item><title>Model merging with SVD to tie the Knots</title><link>http://arxiv.org/abs/2410.19735v1</link><description>Recent model merging methods demonstrate that the parameters offully-finetuned models specializing in distinct tasks can be combined into onemodel capable of solving all tasks without retraining. Yet, this success doesnot transfer well when merging LoRA finetuned models. We study this phenomenonand observe that the weights of LoRA finetuned models showcase a lower degreeof alignment compared to their fully-finetuned counterparts. We hypothesizethat improving this alignment is key to obtaining better LoRA model merges, andpropose KnOTS to address this problem. KnOTS uses the SVD to jointly transformthe weights of different LoRA models into an aligned space, where existingmerging methods can be applied. In addition, we introduce a new benchmark thatexplicitly evaluates whether merged models are general models. Notably, KnOTSconsistently improves LoRA merging by up to 4.3% across several vision andlanguage benchmarks, including our new setting. We release our code at:https://github.com/gstoica27/KnOTS.</description><author>George Stoica, Pratik Ramesh, Boglarka Ecsedi, Leshem Choshen, Judy Hoffman</author><pubDate>Fri, 25 Oct 2024 17:59:55 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.19735v1</guid></item><item><title>The Potential and Value of AI Chatbot in Personalized Cognitive Training</title><link>http://arxiv.org/abs/2410.19733v1</link><description>In recent years, the rapid aging of the global population has led to anincrease in cognitive disorders, such as Alzheimer's disease, presentingsignificant public health challenges. Although no effective treatmentscurrently exist to reverse Alzheimer's, prevention and early intervention,including cognitive training, are critical. This report explores the potentialof AI chatbots in enhancing personalized cognitive training. We introduce ReMe,a web-based framework designed to create AI chatbots that facilitate cognitivetraining research, specifically targeting episodic memory tasks derived frompersonal life logs. By leveraging large language models, ReMe provides enhanceduser-friendly, interactive, and personalized training experiences. Case studiesdemonstrate ReMe's effectiveness in engaging users through life recall andopen-ended language puzzles, highlighting its potential to improve cognitivetraining design. Despite promising results, further research is needed tovalidate training effectiveness through large-scale studies that includecognitive ability evaluations. Overall, ReMe offers a promising approach topersonalized cognitive training, utilizing AI capabilities to meet the growingdemand for non-pharmacological interventions in cognitive health, with futureresearch aiming to expand its applications and efficacy.</description><author>Zilong Wang, Nan Chen, Luna K. Qiu, Ling Yue, Geli Guo, Yang Ou, Shiqi Jiang, Yuqing Yang, Lili Qiu</author><pubDate>Fri, 25 Oct 2024 17:59:36 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.19733v1</guid></item><item><title>Rethinking Visual Dependency in Long-Context Reasoning for Large Vision-Language Models</title><link>http://arxiv.org/abs/2410.19732v1</link><description>Large Vision-Language Models (LVLMs) excel in cross-model tasks butexperience performance declines in long-context reasoning due to overrelianceon textual information and reduced visual dependency. In this study, weempirically analyze LVLMs in long-context reasoning, revealing that increasedcontext length leads to a higher dependence on language at the expense ofvisual dependency. To address this issue, we propose a novel training-freecontext pruning method that selectively removes less critical textualinformation. Our approach enhances visual dependency and reduces textual noise,thereby improving LVLM performance in long-context reasoning. We validate ourmethod by constructing a long-context dataset, demonstrating its effectivenessacross various LVLMs. Moreover, further analysis confirms the robustness ofdifferent token pruning strategies and preliminary explores scaling lawsbetween pruning rates and context length.</description><author>Yucheng Zhou, Zhi Rao, Jun Wan, Jianbing Shen</author><pubDate>Fri, 25 Oct 2024 17:59:09 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.19732v1</guid></item><item><title>LoLCATs: On Low-Rank Linearizing of Large Language Models</title><link>http://arxiv.org/abs/2410.10254v2</link><description>Recent works show we can linearize large language models (LLMs) -- swappingthe quadratic attentions of popular Transformer-based LLMs with subquadraticanalogs, such as linear attention -- avoiding the expensive pretraining costs.However, linearizing LLMs often significantly degrades model quality, stillrequires training over billions of tokens, and remains limited to smaller 1.3Bto 7B LLMs. We thus propose Low-rank Linear Conversion via Attention Transfer(LoLCATs), a simple two-step method that improves LLM linearizing quality withorders of magnitudes less memory and compute. We base these steps on twofindings. First, we can replace an LLM's softmax attentions withclosely-approximating linear attentions, simply by training the linearattentions to match their softmax counterparts with an output MSE loss("attention transfer"). Then, this enables adjusting for approximation errorsand recovering LLM quality simply with low-rank adaptation (LoRA). LoLCATssignificantly improves linearizing quality, training efficiency, andscalability. We significantly reduce the linearizing quality gap and producestate-of-the-art subquadratic LLMs from Llama 3 8B and Mistral 7B v0.1, leadingto 20+ points of improvement on 5-shot MMLU. Furthermore, LoLCATs does so withonly 0.2% of past methods' model parameters and 0.4% of their training tokens.Finally, we apply LoLCATs to create the first linearized 70B and 405B LLMs (50xlarger than prior work). When compared with prior approaches under the samecompute budgets, LoLCATs significantly improves linearizing quality, closingthe gap between linearized and original Llama 3.1 70B and 405B LLMs by 77.8%and 78.1% on 5-shot MMLU.</description><author>Michael Zhang, Simran Arora, Rahul Chalamala, Alan Wu, Benjamin Spector, Aaryan Singhal, Krithik Ramesh, Christopher Ré</author><pubDate>Fri, 25 Oct 2024 17:59:04 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.10254v2</guid></item><item><title>Counting Ability of Large Language Models and Impact of Tokenization</title><link>http://arxiv.org/abs/2410.19730v1</link><description>Transformers, the backbone of modern large language models (LLMs), faceinherent architectural limitations that impede their reasoning capabilities.Unlike recurrent networks, Transformers lack recurrent connections, confiningthem to constant-depth computation. This restriction places them in thecomplexity class TC$^0$, making them theoretically incapable of solving tasksthat demand increasingly deep reasoning as input length grows. Counting, afundamental component of many reasoning tasks, also requires reasoning depth togrow linearly to be performed inductively. While previous studies haveestablished the upper limits of counting ability in Transformer-based expertmodels (i.e., models specifically trained for counting tasks), these findingsdo not directly extend to general-purpose LLMs due to differences in reasoningmechanisms. Recent work has highlighted how Chain of Thought (CoT) reasoningcan help alleviate some of the architectural limitations of Transformers incounting tasks. However, little attention has been paid to the role oftokenization in these models. Unlike expert models that often usecharacter-level tokenization, LLMs typically rely on byte-level (BPE)tokenizers, which fundamentally alters the way reasoning is processed. Our workinvestigates the impact of tokenization on the counting abilities of LLMs,uncovering substantial performance variations based on input tokenizationdifferences. We provide both theoretical and experimental analyses, offeringinsights into how tokenization choices can undermine models' theoreticalcomputability, thereby inspiring the design of new tokenization methods toenhance reasoning in LLMs.</description><author>Xiang Zhang, Juntai Cao, Chenyu You</author><pubDate>Fri, 25 Oct 2024 17:56:24 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.19730v1</guid></item><item><title>cymyc -- Calabi-Yau Metrics, Yukawas, and Curvature</title><link>http://arxiv.org/abs/2410.19728v1</link><description>We introduce \texttt{cymyc}, a high-performance Python library for numericalinvestigation of the geometry of a large class of string compactificationmanifolds and their associated moduli spaces. We develop a well-definedgeometric ansatz to numerically model tensor fields of arbitrary degree on alarge class of Calabi-Yau manifolds. \texttt{cymyc} includes a machine learningcomponent which incorporates this ansatz to model tensor fields of interest onthese spaces by finding an approximate solution to the system of partialdifferential equations they should satisfy.</description><author>Per Berglund, Giorgi Butbaia, Tristan Hübsch, Vishnu Jejjala, Challenger Mishra, Damián Mayorga Peña, Justin Tan</author><pubDate>Fri, 25 Oct 2024 17:55:01 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.19728v1</guid></item><item><title>FISHNET: Financial Intelligence from Sub-querying, Harmonizing, Neural-Conditioning, Expert Swarms, and Task Planning</title><link>http://arxiv.org/abs/2410.19727v1</link><description>Financial intelligence generation from vast data sources has typically reliedon traditional methods of knowledge-graph construction or database engineering.Recently, fine-tuned financial domain-specific Large Language Models (LLMs),have emerged. While these advancements are promising, limitations such as highinference costs, hallucinations, and the complexity of concurrently analyzinghigh-dimensional financial data, emerge. This motivates our invention FISHNET(Financial Intelligence from Sub-querying, Harmonizing, Neural-Conditioning,Expert swarming, and Task planning), an agentic architecture that accomplisheshighly complex analytical tasks for more than 98,000 regulatory filings thatvary immensely in terms of semantics, data hierarchy, or format. FISHNET showsremarkable performance for financial insight generation (61.8% success rateover 5.0% Routing, 45.6% RAG R-Precision). We conduct rigorous ablations toempirically prove the success of FISHNET, each agent's importance, and theoptimized performance of assembling all agents. Our modular architecture can beleveraged for a myriad of use-cases, enabling scalability, flexibility, anddata integrity that are critical for financial tasks.</description><author>Nicole Cho, Nishan Srishankar, Lucas Cecchi, William Watson</author><pubDate>Fri, 25 Oct 2024 17:53:47 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.19727v1</guid></item><item><title>On the Benefits of Active Data Collection in Operator Learning</title><link>http://arxiv.org/abs/2410.19725v1</link><description>We investigate active data collection strategies for operator learning whenthe target operator is linear and the input functions are drawn from amean-zero stochastic process with continuous covariance kernels. With an activedata collection strategy, we establish an error convergence rate in terms ofthe decay rate of the eigenvalues of the covariance kernel. Thus, withsufficiently rapid eigenvalue decay of the covariance kernels, arbitrarily fasterror convergence rates can be achieved. This contrasts with the passive(i.i.d.) data collection strategies, where the convergence rate is never fasterthan $\sim n^{-1}$. In fact, for our setting, we establish a\emph{non-vanishing} lower bound for any passive data collection strategy,regardless of the eigenvalues decay rate of the covariance kernel. Overall, ourresults show the benefit of active over passive data collection strategies inoperator learning.</description><author>Unique Subedi, Ambuj Tewari</author><pubDate>Fri, 25 Oct 2024 17:52:53 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.19725v1</guid></item><item><title>Sparse Decomposition of Graph Neural Networks</title><link>http://arxiv.org/abs/2410.19723v1</link><description>Graph Neural Networks (GNN) exhibit superior performance in graphrepresentation learning, but their inference cost can be high, due to anaggregation operation that can require a memory fetch for a very large numberof nodes. This inference cost is the major obstacle to deploying GNN modelswith \emph{online prediction} to reflect the potentially dynamic node features.To address this, we propose an approach to reduce the number of nodes that areincluded during aggregation. We achieve this through a sparse decomposition,learning to approximate node representations using a weighted sum of linearlytransformed features of a carefully selected subset of nodes within theextended neighbourhood. The approach achieves linear complexity with respect tothe average node degree and the number of layers in the graph neural network.We introduce an algorithm to compute the optimal parameters for the sparsedecomposition, ensuring an accurate approximation of the original GNN model,and present effective strategies to reduce the training time and improve thelearning process. We demonstrate via extensive experiments that our methodoutperforms other baselines designed for inference speedup, achievingsignificant accuracy gains with comparable inference times for both nodeclassification and spatio-temporal forecasting tasks.</description><author>Yaochen Hu, Mai Zeng, Ge Zhang, Pavel Rumiantsev, Liheng Ma, Yingxue Zhang, Mark Coates</author><pubDate>Fri, 25 Oct 2024 17:52:16 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.19723v1</guid></item><item><title>Temporal Convolution-based Hybrid Model Approach with Representation Learning for Real-Time Acoustic Anomaly Detection</title><link>http://arxiv.org/abs/2410.19722v1</link><description>The early detection of potential failures in industrial machinery componentsis paramount for ensuring the reliability and safety of operations, therebypreserving Machine Condition Monitoring (MCM). This research addresses thisimperative by introducing an innovative approach to Real-Time Acoustic AnomalyDetection. Our method combines semi-supervised temporal convolution withrepresentation learning and a hybrid model strategy with Temporal ConvolutionalNetworks (TCN) to handle various intricate anomaly patterns found in acousticdata effectively. The proposed model demonstrates superior performance comparedto established research in the field, underscoring the effectiveness of thisapproach. Not only do we present quantitative evidence of its superiority, butwe also employ visual representations, such as t-SNE plots, to furthersubstantiate the model's efficacy.</description><author>Sahan Dissanayaka, Manjusri Wickramasinghe, Pasindu Marasinghe</author><pubDate>Fri, 25 Oct 2024 17:50:48 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.19722v1</guid></item><item><title>2D-DPO: Scaling Direct Preference Optimization with 2-Dimensional Supervision</title><link>http://arxiv.org/abs/2410.19720v1</link><description>Recent advancements in Direct Preference Optimization (DPO) havesignificantly enhanced the alignment of Large Language Models (LLMs) with humanpreferences, owing to its simplicity and effectiveness. However, existingmethods typically optimize a scalar score or ranking reward, therebyoverlooking the multi-dimensional nature of human preferences. In this work, wepropose to extend the preference of DPO to two dimensions: segments andaspects. We first introduce a 2D supervision dataset called HelpSteer-2D. Forthe segment dimension, we divide the response into sentences and assign scoresto each segment. For the aspect dimension, we meticulously design severalcriteria covering the response quality rubrics. With the 2-dimensional signalsas feedback, we develop a 2D-DPO framework, decomposing the overall objectiveinto multi-segment and multi-aspect objectives. Extensive experiments onpopular benchmarks demonstrate that 2D-DPO performs better than methods thatoptimize for scalar or 1-dimensional preferences.</description><author>Shilong Li, Yancheng He, Hui Huang, Xingyuan Bu, Jiaheng Liu, Hangyu Guo, Weixun Wang, Jihao Gu, Wenbo Su, Bo Zheng</author><pubDate>Fri, 25 Oct 2024 17:47:35 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.19720v1</guid></item><item><title>Arabic Music Classification and Generation using Deep Learning</title><link>http://arxiv.org/abs/2410.19719v1</link><description>This paper proposes a machine learning approach for classifying classical andnew Egyptian music by composer and generating new similar music. The proposedsystem utilizes a convolutional neural network (CNN) for classification and aCNN autoencoder for generation. The dataset used in this project consists ofnew and classical Egyptian music pieces composed by different composers. To classify the music by composer, each sample is normalized and transformedinto a mel spectrogram. The CNN model is trained on the dataset using the melspectrograms as input features and the composer labels as output classes. Themodel achieves 81.4\% accuracy in classifying the music by composer,demonstrating the effectiveness of the proposed approach. To generate new music similar to the original pieces, a CNN autoencoder istrained on a similar dataset. The model is trained to encode the melspectrograms of the original pieces into a lower-dimensional latent space andthen decode them back into the original mel spectrogram. The generated music isproduced by sampling from the latent space and decoding the samples back intomel spectrograms, which are then transformed into audio. In conclusion, the proposed system provides a promising approach toclassifying and generating classical Egyptian music, which can be applied invarious musical applications, such as music recommendation systems, musicproduction, and music education.</description><author>Mohamed Elshaarawy, Ashrakat Saeed, Mariam Sheta, Abdelrahman Said, Asem Bakr, Omar Bahaa, Walid Gomaa</author><pubDate>Fri, 25 Oct 2024 17:47:08 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.19719v1</guid></item><item><title>Evolving Neural Networks Reveal Emergent Collective Behavior from Minimal Agent Interactions</title><link>http://arxiv.org/abs/2410.19718v1</link><description>Understanding the mechanisms behind emergent behaviors in multi-agent systemsis critical for advancing fields such as swarm robotics and artificialintelligence. In this study, we investigate how neural networks evolve tocontrol agents' behavior in a dynamic environment, focusing on the relationshipbetween the network's complexity and collective behavior patterns. Byperforming quantitative and qualitative analyses, we demonstrate that thedegree of network non-linearity correlates with the complexity of emergentbehaviors. Simpler behaviors, such as lane formation and laminar flow, arecharacterized by more linear network operations, while complex behaviors likeswarming and flocking show highly non-linear neural processing. Moreover,specific environmental parameters, such as moderate noise, broader field ofview, and lower agent density, promote the evolution of non-linear networksthat drive richer, more intricate collective behaviors. These results highlightthe importance of tuning evolutionary conditions to induce desired behaviors inmulti-agent systems, offering new pathways for optimizing coordination inautonomous swarms. Our findings contribute to a deeper understanding of howneural mechanisms influence collective dynamics, with implications for thedesign of intelligent, self-organizing systems.</description><author>Guilherme S. Y. Giardini, John F. Hardy II, Carlo R. da Cunha</author><pubDate>Fri, 25 Oct 2024 17:43:00 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.19718v1</guid></item><item><title>Automated Rewards via LLM-Generated Progress Functions</title><link>http://arxiv.org/abs/2410.09187v2</link><description>Large Language Models (LLMs) have the potential to automate rewardengineering by leveraging their broad domain knowledge across various tasks.However, they often need many iterations of trial-and-error to generateeffective reward functions. This process is costly because evaluating everysampled reward function requires completing the full policy optimizationprocess for each function. In this paper, we introduce an LLM-driven rewardgeneration framework that is able to produce state-of-the-art policies on thechallenging Bi-DexHands benchmark with 20x fewer reward function samples thanthe prior state-of-the-art work. Our key insight is that we reduce the problemof generating task-specific rewards to the problem of coarsely estimating taskprogress. Our two-step solution leverages the task domain knowledge and thecode synthesis abilities of LLMs to author progress functions that estimatetask progress from a given state. Then, we use this notion of progress todiscretize states, and generate count-based intrinsic rewards using thelow-dimensional state space. We show that the combination of LLM-generatedprogress functions and count-based intrinsic rewards is essential for ourperformance gains, while alternatives such as generic hash-based counts orusing progress directly as a reward function fall short.</description><author>Vishnu Sarukkai, Brennan Shacklett, Zander Majercik, Kush Bhatia, Christopher Ré, Kayvon Fatahalian</author><pubDate>Fri, 25 Oct 2024 17:37:59 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.09187v2</guid></item><item><title>UnCLe: Unsupervised Continual Learning of Depth Completion</title><link>http://arxiv.org/abs/2410.18074v2</link><description>We propose UnCLe, a standardized benchmark for Unsupervised ContinualLearning of a multimodal depth estimation task: Depth completion aims to infera dense depth map from a pair of synchronized RGB image and sparse depth map.We benchmark depth completion models under the practical scenario ofunsupervised learning over continuous streams of data. Existing methods aretypically trained on a static, or stationary, dataset. However, when adaptingto novel non-stationary distributions, they "catastrophically forget"previously learned information. UnCLe simulates these non-stationarydistributions by adapting depth completion models to sequences of datasetscontaining diverse scenes captured from distinct domains using different visualand range sensors. We adopt representative methods from continual learningparadigms and translate them to enable unsupervised continual learning of depthcompletion. We benchmark these models for indoor and outdoor and investigatethe degree of catastrophic forgetting through standard quantitative metrics.Furthermore, we introduce model inversion quality as an additional measure offorgetting. We find that unsupervised continual learning of depth completion isan open problem, and we invite researchers to leverage UnCLe as a developmentplatform.</description><author>Suchisrit Gangopadhyay, Xien Chen, Michael Chu, Patrick Rim, Hyoungseob Park, Alex Wong</author><pubDate>Fri, 25 Oct 2024 17:37:29 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.18074v2</guid></item><item><title>Block and Detail: Scaffolding Sketch-to-Image Generation</title><link>http://arxiv.org/abs/2402.18116v2</link><description>We introduce a novel sketch-to-image tool that aligns with the iterativerefinement process of artists. Our tool lets users sketch blocking strokes tocoarsely represent the placement and form of objects and detail strokes torefine their shape and silhouettes. We develop a two-pass algorithm forgenerating high-fidelity images from such sketches at any point in theiterative process. In the first pass we use a ControlNet to generate an imagethat strictly follows all the strokes (blocking and detail) and in the secondpass we add variation by renoising regions surrounding blocking strokes. Wealso present a dataset generation scheme that, when used to train a ControlNetarchitecture, allows regions that do not contain strokes to be interpreted asnot-yet-specified regions rather than empty space. We show that thispartial-sketch-aware ControlNet can generate coherent elements from partialsketches that only contain a small number of strokes. The high-fidelity imagesproduced by our approach serve as scaffolds that can help the user adjust theshape and proportions of objects or add additional elements to the composition.We demonstrate the effectiveness of our approach with a variety of examples andevaluative comparisons. Quantitatively, evaluative user feedback indicates thatnovice viewers prefer the quality of images from our algorithm over a baselineScribble ControlNet for 84% of the pairs and found our images had lessdistortion in 81% of the pairs.</description><author>Vishnu Sarukkai, Lu Yuan, Mia Tang, Maneesh Agrawala, Kayvon Fatahalian</author><pubDate>Fri, 25 Oct 2024 17:35:05 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.18116v2</guid></item><item><title>Adversarial Environment Design via Regret-Guided Diffusion Models</title><link>http://arxiv.org/abs/2410.19715v1</link><description>Training agents that are robust to environmental changes remains asignificant challenge in deep reinforcement learning (RL). Unsupervisedenvironment design (UED) has recently emerged to address this issue bygenerating a set of training environments tailored to the agent's capabilities.While prior works demonstrate that UED has the potential to learn a robustpolicy, their performance is constrained by the capabilities of the environmentgeneration. To this end, we propose a novel UED algorithm, adversarialenvironment design via regret-guided diffusion models (ADD). The proposedmethod guides the diffusion-based environment generator with the regret of theagent to produce environments that the agent finds challenging but conducive tofurther improvement. By exploiting the representation power of diffusionmodels, ADD can directly generate adversarial environments while maintainingthe diversity of training environments, enabling the agent to effectively learna robust policy. Our experimental results demonstrate that the proposed methodsuccessfully generates an instructive curriculum of environments, outperformingUED baselines in zero-shot generalization across novel, out-of-distributionenvironments. Project page: https://github.com/rllab-snu.github.io/projects/ADD</description><author>Hojun Chung, Junseo Lee, Minsoo Kim, Dohyeong Kim, Songhwai Oh</author><pubDate>Fri, 25 Oct 2024 17:35:03 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.19715v1</guid></item><item><title>On Designing Effective RL Reward at Training Time for LLM Reasoning</title><link>http://arxiv.org/abs/2410.15115v2</link><description>Reward models have been increasingly critical for improving the reasoningcapability of LLMs. Existing research has shown that a well-trained rewardmodel can substantially improve model performances at inference time viasearch. However, the potential of reward models during RL training time stillremains largely under-explored. It is currently unclear whether these rewardmodels can provide additional training signals to enhance the reasoningcapabilities of LLMs in RL training that uses sparse success rewards, whichverify the correctness of solutions. In this work, we evaluate popular rewardmodels for RL training, including the Outcome-supervised Reward Model (ORM) andthe Process-supervised Reward Model (PRM), and train a collection of LLMs formath problems using RL by combining these learned rewards with success rewards.Surprisingly, even though these learned reward models have stronginference-time performances, they may NOT help or even hurt RL training,producing worse performances than LLMs trained with the success reward only.Our analysis reveals that an LLM can receive high rewards from some of thesereward models by repeating correct but unnecessary reasoning steps, leading toa severe reward hacking issue. Therefore, we introduce two novel rewardrefinement techniques, including Clipping and Delta. The key idea is to ensurethe accumulative reward of any reasoning trajectory is upper-bounded to keep alearned reward model effective without being exploited. We evaluate ourtechniques with multiple reward models over a set of 1.5B and 7B LLMs on MATHand GSM8K benchmarks and demonstrate that with a carefully designed rewardfunction, RL training without any additional supervised tuning can improve allthe evaluated LLMs, including the state-of-the-art 7B LLMQwen2.5-Math-7B-Instruct on MATH and GSM8K benchmarks.</description><author>Jiaxuan Gao, Shusheng Xu, Wenjie Ye, Weilin Liu, Chuyi He, Wei Fu, Zhiyu Mei, Guangju Wang, Yi Wu</author><pubDate>Fri, 25 Oct 2024 17:34:22 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.15115v2</guid></item><item><title>Limit Theorems for Stochastic Gradient Descent with Infinite Variance</title><link>http://arxiv.org/abs/2410.16340v2</link><description>Stochastic gradient descent is a classic algorithm that has gained greatpopularity especially in the last decades as the most common approach fortraining models in machine learning. While the algorithm has been well-studiedwhen stochastic gradients are assumed to have a finite variance, there issignificantly less research addressing its theoretical properties in the caseof infinite variance gradients. In this paper, we establish the asymptoticbehavior of stochastic gradient descent in the context of infinite variancestochastic gradients, assuming that the stochastic gradient is regular varyingwith index $\alpha\in(1,2)$. The closest result in this context was establishedin 1969 , in the one-dimensional case and assuming that stochastic gradientsbelong to a more restrictive class of distributions. We extend it to themultidimensional case, covering a broader class of infinite variancedistributions. As we show, the asymptotic distribution of the stochasticgradient descent algorithm can be characterized as the stationary distributionof a suitably defined Ornstein-Uhlenbeck process driven by an appropriatestable L\'evy process. Additionally, we explore the applications of theseresults in linear regression and logistic regression models.</description><author>Jose Blanchet, Aleksandar Mijatović, Wenhao Yang</author><pubDate>Fri, 25 Oct 2024 17:32:38 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.16340v2</guid></item><item><title>Hate speech detection in algerian dialect using deep learning</title><link>http://arxiv.org/abs/2309.11611v2</link><description>With the proliferation of hate speech on social networks under differentformats, such as abusive language, cyberbullying, and violence, etc., peoplehave experienced a significant increase in violence, putting them inuncomfortable situations and threats. Plenty of efforts have been dedicated inthe last few years to overcome this phenomenon to detect hate speech indifferent structured languages like English, French, Arabic, and others.However, a reduced number of works deal with Arabic dialects like Tunisian,Egyptian, and Gulf, mainly the Algerian ones. To fill in the gap, we propose inthis work a complete approach for detecting hate speech on online Algerianmessages. Many deep learning architectures have been evaluated on the corpus wecreated from some Algerian social networks (Facebook, YouTube, and Twitter).This corpus contains more than 13.5K documents in Algerian dialect written inArabic, labeled as hateful or non-hateful. Promising results are obtained,which show the efficiency of our approach.</description><author>Dihia Lanasri, Juan Olano, Sifal Klioui, Sin Liang Lee, Lamia Sekkai</author><pubDate>Fri, 25 Oct 2024 17:32:08 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2309.11611v2</guid></item><item><title>Two-Step Offline Preference-Based Reinforcement Learning with Constrained Actions</title><link>http://arxiv.org/abs/2401.00330v3</link><description>Preference-based reinforcement learning (PBRL) in the offline setting hassucceeded greatly in industrial applications such as chatbots. A two-steplearning framework where one applies a reinforcement learning step after areward modeling step has been widely adopted for the problem. However, such amethod faces challenges from the risk of reward hacking and the complexity ofreinforcement learning. To overcome the challenge, our insight is that bothchallenges come from the state-actions not supported in the dataset. Suchstate-actions are unreliable and increase the complexity of the reinforcementlearning problem at the second step. Based on the insight, we develop a noveltwo-step learning method called PRC: preference-based reinforcement learningwith constrained actions. The high-level idea is to limit the reinforcementlearning agent to optimize over a constrained action space that excludes theout-of-distribution state-actions. We empirically verify that our method hashigh learning efficiency on various datasets in robotic control environments.</description><author>Yinglun Xu, Tarun Suresh, Rohan Gumaste, David Zhu, Ruirui Li, Zhengyang Wang, Haoming Jiang, Xianfeng Tang, Qingyu Yin, Monica Xiao Cheng, Qi Zeng, Chao Zhang, Gagandeep Singh</author><pubDate>Fri, 25 Oct 2024 17:31:50 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.00330v3</guid></item><item><title>Water and Electricity Consumption Forecasting at an Educational Institution using Machine Learning models with Metaheuristic Optimization</title><link>http://arxiv.org/abs/2410.19709v1</link><description>Educational institutions are essential for economic and social development.Budget cuts in Brazil in recent years have made it difficult to carry out theiractivities and projects. In the case of expenses with water and electricity,unexpected situations can occur, such as leaks and equipment failures, whichmake their management challenging. This study proposes a comparison between twomachine learning models, Random Forest (RF) and Support Vector Regression(SVR), for water and electricity consumption forecasting at the FederalInstitute of Paran\'a-Campus Palmas, with a 12-month forecasting horizon, aswell as evaluating the influence of the application of climatic variables asexogenous features. The data were collected over the past five years, combiningdetails pertaining to invoices with exogenous and endogenous variables. The twomodels had their hyperpa-rameters optimized using the Genetic Algorithm (GA) toselect the individuals with the best fitness to perform the forecasting withand without climatic variables. The absolute percentage errors and root meansquared error were used as performance measures to evaluate the forecastingaccuracy. The results suggest that in forecasting water and electricityconsumption over a 12-step horizon, the Random Forest model exhibited the mostsuperior performance. The integration of climatic variables often led todiminished forecasting accuracy, resulting in higher errors. Both models stillhad certain difficulties in predicting water consumption, indicating that newstudies with different models or variables are welcome.</description><author>Eduardo Luiz Alba, Matheus Henrique Dal Molin Ribeiro, Gilson Adamczuk, Flavio Trojan, Erick Oliveira Rodrigues</author><pubDate>Fri, 25 Oct 2024 17:30:12 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.19709v1</guid></item><item><title>The Endoscapes Dataset for Surgical Scene Segmentation, Object Detection, and Critical View of Safety Assessment: Official Splits and Benchmark</title><link>http://arxiv.org/abs/2312.12429v3</link><description>This technical report provides a detailed overview of Endoscapes, a datasetof laparoscopic cholecystectomy (LC) videos with highly intricate annotationstargeted at automated assessment of the Critical View of Safety (CVS).Endoscapes comprises 201 LC videos with frames annotated sparsely but regularlywith segmentation masks, bounding boxes, and CVS assessment by three differentclinical experts. Altogether, there are 11090 frames annotated with CVS and1933 frames annotated with tool and anatomy bounding boxes from the 201 videos,as well as an additional 422 frames from 50 of the 201 videos annotated withtool and anatomy segmentation masks. In this report, we provide detaileddataset statistics (size, class distribution, dataset splits, etc.) and acomprehensive performance benchmark for instance segmentation, objectdetection, and CVS prediction. The dataset and model checkpoints are publicallyavailable at https://github.com/CAMMA-public/Endoscapes.</description><author>Aditya Murali, Deepak Alapatt, Pietro Mascagni, Armine Vardazaryan, Alain Garcia, Nariaki Okamoto, Guido Costamagna, Didier Mutter, Jacques Marescaux, Bernard Dallemagne, Nicolas Padoy</author><pubDate>Fri, 25 Oct 2024 17:28:43 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.12429v3</guid></item><item><title>Super Gradient Descent: Global Optimization requires Global Gradient</title><link>http://arxiv.org/abs/2410.19706v1</link><description>Global minimization is a fundamental challenge in optimization, especially inmachine learning, where finding the global minimum of a function directlyimpacts model performance and convergence. This report introduces a noveloptimization method that we called Super Gradient Descent, designedspecifically for one-dimensional functions, guaranteeing convergence to theglobal minimum for any k-Lipschitz function defined on a closed interval [a,b]. Our approach addresses the limitations of traditional optimizationalgorithms, which often get trapped in local minima. In particular, weintroduce the concept of global gradient which offers a robust solution forprecise and well-guided global optimization. By focusing on the globalminimization problem, this work bridges a critical gap in optimization theory,offering new insights and practical advancements in different optimizationproblems in particular Machine Learning problems like line search.</description><author>Seifeddine Achour</author><pubDate>Fri, 25 Oct 2024 17:28:39 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.19706v1</guid></item><item><title>Robust Thompson Sampling Algorithms Against Reward Poisoning Attacks</title><link>http://arxiv.org/abs/2410.19705v1</link><description>Thompson sampling is one of the most popular learning algorithms for onlinesequential decision-making problems and has rich real-world applications.However, current Thompson sampling algorithms are limited by the assumptionthat the rewards received are uncorrupted, which may not be true in real-worldapplications where adversarial reward poisoning exists. To make Thompsonsampling more reliable, we want to make it robust against adversarial rewardpoisoning. The main challenge is that one can no longer compute the actualposteriors for the true reward, as the agent can only observe the rewards aftercorruption. In this work, we solve this problem by computing pseudo-posteriorsthat are less likely to be manipulated by the attack. We propose robustalgorithms based on Thompson sampling for the popular stochastic and contextuallinear bandit settings in both cases where the agent is aware or unaware of thebudget of the attacker. We theoretically show that our algorithms guaranteenear-optimal regret under any attack strategy.</description><author>Yinglun Xu, Zhiwei Wang, Gagandeep Singh</author><pubDate>Fri, 25 Oct 2024 17:27:58 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.19705v1</guid></item><item><title>Good Parenting is all you need -- Multi-agentic LLM Hallucination Mitigation</title><link>http://arxiv.org/abs/2410.14262v3</link><description>This study explores the ability of Large Language Model (LLM) agents todetect and correct hallucinations in AI-generated content. A primary agent wastasked with creating a blog about a fictional Danish artist named Flipfloppidy,which was then reviewed by another agent for factual inaccuracies. Most LLMshallucinated the existence of this artist. Across 4,900 test runs involvingvarious combinations of primary and reviewing agents, advanced AI models suchas Llama3-70b and GPT-4 variants demonstrated near-perfect accuracy inidentifying hallucinations and successfully revised outputs in 85% to 100% ofcases following feedback. These findings underscore the potential of advancedAI models to significantly enhance the accuracy and reliability of generatedcontent, providing a promising approach to improving AI workflow orchestration.</description><author>Ted Kwartler, Matthew Berman, Alan Aqrawi</author><pubDate>Fri, 25 Oct 2024 17:24:16 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.14262v3</guid></item><item><title>Multi-view biomedical foundation models for molecule-target and property prediction</title><link>http://arxiv.org/abs/2410.19704v1</link><description>Foundation models applied to bio-molecular space hold promise to acceleratedrug discovery. Molecular representation is key to building such models.Previous works have typically focused on a single representation or view of themolecules. Here, we develop a multi-view foundation model approach, thatintegrates molecular views of graph, image and text. Single-view foundationmodels are each pre-trained on a dataset of up to 200M molecules and thenaggregated into combined representations. Our multi-view model is validated ona diverse set of 18 tasks, encompassing ligand-protein binding, molecularsolubility, metabolism and toxicity. We show that the multi-view models performrobustly and are able to balance the strengths and weaknesses of specificviews. We then apply this model to screen compounds against a large (&gt;100targets) set of G Protein-Coupled receptors (GPCRs). From this library oftargets, we identify 33 that are related to Alzheimer's disease. On thissubset, we employ our model to identify strong binders, which are validatedthrough structure-based modeling and identification of key binding motifs.</description><author>Parthasarathy Suryanarayanan, Yunguang Qiu, Shreyans Sethi, Diwakar Mahajan, Hongyang Li, Yuxin Yang, Elif Eyigoz, Aldo Guzman Saenz, Daniel E. Platt, Timothy H. Rumbell, Kenney Ng, Sanjoy Dey, Myson Burch, Bum Chul Kwon, Pablo Meyer, Feixiong Cheng, Jianying Hu, Joseph A. Morrone</author><pubDate>Fri, 25 Oct 2024 17:22:33 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.19704v1</guid></item><item><title>TimeSuite: Improving MLLMs for Long Video Understanding via Grounded Tuning</title><link>http://arxiv.org/abs/2410.19702v1</link><description>Multimodal Large Language Models (MLLMs) have demonstrated impressiveperformance in short video understanding. However, understanding long-formvideos still remains challenging for MLLMs. This paper proposes TimeSuite, acollection of new designs to adapt the existing short-form video MLLMs for longvideo understanding, including a simple yet efficient framework to process longvideo sequence, a high-quality video dataset for grounded tuning of MLLMs, anda carefully-designed instruction tuning task to explicitly incorporate thegrounding supervision in the traditional QA format. Specifically, based onVideoChat, we propose our long-video MLLM, coined as VideoChat-T, byimplementing a token shuffling to compress long video tokens and introducingTemporal Adaptive Position Encoding (TAPE) to enhance the temporal awareness ofvisual representation. Meanwhile, we introduce the TimePro, a comprehensivegrounding-centric instruction tuning dataset composed of 9 tasks and 349khigh-quality grounded annotations. Notably, we design a new instruction tuningtask type, called Temporal Grounded Caption, to peform detailed videodescriptions with the corresponding time stamps prediction. This explicittemporal location prediction will guide MLLM to correctly attend on the visualcontent when generating description, and thus reduce the hallucination riskcaused by the LLMs. Experimental results demonstrate that our TimeSuiteprovides a successful solution to enhance the long video understandingcapability of short-form MLLM, achieving improvement of 5.6% and 6.8% on thebenchmarks of Egoschema and VideoMME, respectively. In addition, VideoChat-Texhibits robust zero-shot temporal grounding capabilities, significantlyoutperforming the existing state-of-the-art MLLMs. After fine-tuning, itperforms on par with the traditional supervised expert models.</description><author>Xiangyu Zeng, Kunchang Li, Chenting Wang, Xinhao Li, Tianxiang Jiang, Ziang Yan, Songze Li, Yansong Shi, Zhengrong Yue, Yi Wang, Yali Wang, Yu Qiao, Limin Wang</author><pubDate>Fri, 25 Oct 2024 17:19:55 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.19702v1</guid></item><item><title>Enhancing Resilience and Scalability in Travel Booking Systems: A Microservices Approach to Fault Tolerance, Load Balancing, and Service Discovery</title><link>http://arxiv.org/abs/2410.19701v1</link><description>This paper investigates the inclusion of microservices architecture in thedevelopment of scalable and reliable airline reservation systems. Most of thetraditional reservation systems are very rigid and centralized which makes themprone to bottlenecks and a single point of failure. As such, systems do notmeet the requirements of modern airlines which are dynamic. Microservices offerbetter resiliency and scalability because the services do not depend on oneanother and can be deployed independently. The approach is grounded on theCircuit Breaker Pattern to maintain fault tolerance while consuming foreignresources such as flight APIs and payment systems. This avoided the failurepropagation to the systems by 60% enabling the systems to function underexternal failures. Traffic rerouting also bolstered this with a guarantee ofabove 99.95% uptime in systems where high availability was demanded. To addressthis, load balancing was used, particularly the Round-Robin method whichmanaged to enhance performance by 35% through the equal distribution of userrequests among the service instances. Health checks, as well as monitoring inreal-time, helped as well with failure management as they helped to containfailures before the users of the system were affected. The results suggest thatthe use of microservices led to a 40% increase in system scalability, a 50%decrease in downtime and a support for 30% more concurrent users than the useof monolithic architectures. These findings affirm the capability ofmicroservices in the development of robust and flexible airline ticket bookingsystems that are responsive to change and recover from external systemunavailability.</description><author>Biman Barua, M. Shamim Kaiser</author><pubDate>Fri, 25 Oct 2024 17:19:42 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.19701v1</guid></item><item><title>IPPON: Common Sense Guided Informative Path Planning for Object Goal Navigation</title><link>http://arxiv.org/abs/2410.19697v1</link><description>Navigating efficiently to an object in an unexplored environment is acritical skill for general-purpose intelligent robots. Recent approaches tothis object goal navigation problem have embraced a modular strategy,integrating classical exploration algorithms-notably frontier exploration-witha learned semantic mapping/exploration module. This paper introduces a novelinformative path planning and 3D object probability mapping approach. Themapping module computes the probability of the object of interest throughsemantic segmentation and a Bayes filter. Additionally, it stores probabilitiesfor common objects, which semantically guides the exploration based on commonsense priors from a large language model. The planner terminates when thecurrent viewpoint captures enough voxels identified with high confidence as theobject of interest. Although our planner follows a zero-shot approach, itachieves state-of-the-art performance as measured by the Success weighted byPath Length (SPL) and Soft SPL in the Habitat ObjectNav Challenge 2023,outperforming other works by more than 20%. Furthermore, we validate itseffectiveness on real robots. Project webpage: https://ippon-paper.github.io/</description><author>Kaixian Qu, Jie Tan, Tingnan Zhang, Fei Xia, Cesar Cadena, Marco Hutter</author><pubDate>Fri, 25 Oct 2024 17:11:33 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.19697v1</guid></item><item><title>Less is More: Extreme Gradient Boost Rank-1 Adaption for Efficient Finetuning of LLMs</title><link>http://arxiv.org/abs/2410.19694v1</link><description>Fine-tuning Large Language Models (LLMs) has become a crucial technique foradapting pre-trained models to downstream tasks. However, the enormous size ofLLMs poses significant challenges in terms of computational complexity andresource requirements. Low-Rank Adaptation (LoRA) has emerged as a promisingsolution. However, there exists a gap between the practical performance oflow-rank adaptations and its theoretical optimum. In this work, we proposeeXtreme Gradient Boosting LoRA (XGBLoRA), a novel framework that bridges thisgap by leveraging the power of ensemble learning. Inspired by gradientboosting, XGBLoRA iteratively learns and merges a sequence of LoRA adaptationsto refine model predictions. It achieves better performance than the standardLoRA, while enjoying the computational efficiency of rank-1 adaptations. Weprovide theoretical analysis to show the convergence and optimality of ourapproach, and conduct extensive experiments on a range of natural languageprocessing tasks. The results demonstrate that XGBLoRA consistently outperformsstandard LoRA and achieves performance comparable to full fine-tuning withsignificantly fewer trainable parameters. This work advancesparameter-efficient fine-tuning for LLMs, and offers a promising solution foradapting LLMs to downstream tasks while optimizing performance and efficiency.</description><author>Yifei Zhang, Hao Zhu, Aiwei Liu, Han Yu, Piotr Koniusz, Irwin King</author><pubDate>Fri, 25 Oct 2024 17:07:13 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.19694v1</guid></item><item><title>MILES: Making Imitation Learning Easy with Self-Supervision</title><link>http://arxiv.org/abs/2410.19693v1</link><description>Data collection in imitation learning often requires significant, laborioushuman supervision, such as numerous demonstrations, and/or frequent environmentresets for methods that incorporate reinforcement learning. In this work, wepropose an alternative approach, MILES: a fully autonomous, self-superviseddata collection paradigm, and we show that this enables efficient policylearning from just a single demonstration and a single environment reset. MILESautonomously learns a policy for returning to and then following the singledemonstration, whilst being self-guided during data collection, eliminating theneed for additional human interventions. We evaluated MILES across severalreal-world tasks, including tasks that require precise contact-richmanipulation such as locking a lock with a key. We found that, under theconstraints of a single demonstration and no repeated environment resetting,MILES significantly outperforms state-of-the-art alternatives like imitationlearning methods that leverage reinforcement learning. Videos of ourexperiments and code can be found on our webpage: www.robot-learning.uk/miles.</description><author>Georgios Papagiannis, Edward Johns</author><pubDate>Fri, 25 Oct 2024 17:06:50 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.19693v1</guid></item><item><title>AGENT-CQ: Automatic Generation and Evaluation of Clarifying Questions for Conversational Search with LLMs</title><link>http://arxiv.org/abs/2410.19692v1</link><description>Generating diverse and effective clarifying questions is crucial forimproving query understanding and retrieval performance in open-domainconversational search (CS) systems. We propose AGENT-CQ (Automatic GENeration,and evaluaTion of Clarifying Questions), an end-to-end LLM-based frameworkaddressing the challenges of scalability and adaptability faced by existingmethods that rely on manual curation or template-based approaches. AGENT-CQconsists of two stages: a generation stage employing LLM prompting strategiesto generate clarifying questions, and an evaluation stage (CrowdLLM) thatsimulates human crowdsourcing judgments using multiple LLM instances to assessgenerated questions and answers based on comprehensive quality metrics.Extensive experiments on the ClariQ dataset demonstrate CrowdLLM'seffectiveness in evaluating question and answer quality. Human evaluation andCrowdLLM show that the AGENT-CQ - generation stage, consistently outperformsbaselines in various aspects of question and answer quality. In retrieval-basedevaluation, LLM-generated questions significantly enhance retrievaleffectiveness for both BM25 and cross-encoder models compared tohuman-generated questions.</description><author>Clemencia Siro, Yifei Yuan, Mohammad Aliannejadi, Maarten de Rijke</author><pubDate>Fri, 25 Oct 2024 17:06:27 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.19692v1</guid></item><item><title>Deep Learning for Classification of Inflammatory Bowel Disease Activity in Whole Slide Images of Colonic Histopathology</title><link>http://arxiv.org/abs/2410.19690v1</link><description>Grading inflammatory bowel disease (IBD) activity using standardizedhistopathological scoring systems remains challenging due to resourceconstraints and inter-observer variability. In this study, we developed a deeplearning model to classify activity grades in hematoxylin and eosin-stainedwhole slide images (WSIs) from patients with IBD, offering a robust approachfor general pathologists. We utilized 2,077 WSIs from 636 patients treated atDartmouth-Hitchcock Medical Center in 2018 and 2019, scanned at 40xmagnification (0.25 micron/pixel). Board-certified gastrointestinalpathologists categorized the WSIs into four activity classes: inactive, mildlyactive, moderately active, and severely active. A transformer-based model wasdeveloped and validated using five-fold cross-validation to classify IBDactivity. Using HoVerNet, we examined neutrophil distribution across activitygrades. Attention maps from our model highlighted areas contributing to itsprediction. The model classified IBD activity with weighted averages of 0.871[95% Confidence Interval (CI): 0.860-0.883] for the area under the curve, 0.695[95% CI: 0.674-0.715] for precision, 0.697 [95% CI: 0.678-0.716] for recall,and 0.695 [95% CI: 0.674-0.714] for F1-score. Neutrophil distribution wassignificantly different across activity classes. Qualitative evaluation ofattention maps by a gastrointestinal pathologist suggested their potential forimproved interpretability. Our model demonstrates robust diagnostic performanceand could enhance consistency and efficiency in IBD activity assessment.</description><author>Amit Das, Tanmay Shukla, Naofumi Tomita, Ryland Richards, Laura Vidis, Bing Ren, Saeed Hassanpour</author><pubDate>Fri, 25 Oct 2024 17:00:31 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.19690v1</guid></item><item><title>Towards Automated Penetration Testing: Introducing LLM Benchmark, Analysis, and Improvements</title><link>http://arxiv.org/abs/2410.17141v2</link><description>Hacking poses a significant threat to cybersecurity, inflicting billions ofdollars in damages annually. To mitigate these risks, ethical hacking, orpenetration testing, is employed to identify vulnerabilities in systems andnetworks. Recent advancements in large language models (LLMs) have shownpotential across various domains, including cybersecurity. However, there iscurrently no comprehensive, open, end-to-end automated penetration testingbenchmark to drive progress and evaluate the capabilities of these models insecurity contexts. This paper introduces a novel open benchmark for LLM-basedautomated penetration testing, addressing this critical gap. We first evaluatethe performance of LLMs, including GPT-4o and Llama 3.1-405B, using thestate-of-the-art PentestGPT tool. Our findings reveal that while Llama 3.1demonstrates an edge over GPT-4o, both models currently fall short ofperforming fully automated, end-to-end penetration testing. Next, we advancethe state-of-the-art and present ablation studies that provide insights intoimproving the PentestGPT tool. Our research illuminates the challenges LLMsface in each aspect of Pentesting, e.g. enumeration, exploitation, andprivilege escalation. This work contributes to the growing body of knowledge onAI-assisted cybersecurity and lays the foundation for future research inautomated penetration testing using large language models.</description><author>Isamu Isozaki, Manil Shrestha, Rick Console, Edward Kim</author><pubDate>Fri, 25 Oct 2024 16:58:37 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.17141v2</guid></item><item><title>ProvocationProbe: Instigating Hate Speech Dataset from Twitter</title><link>http://arxiv.org/abs/2410.19687v1</link><description>In the recent years online social media platforms has been flooded withhateful remarks such as racism, sexism, homophobia etc. As a result, there havebeen many measures taken by various social media platforms to mitigate thespread of hate-speech over the internet. One particular concept within thedomain of hate speech is instigating hate, which involves provoking hatredagainst a particular community, race, colour, gender, religion or ethnicity. Inthis work, we introduce \textit{ProvocationProbe} - a dataset designed toexplore what distinguishes instigating hate speech from general hate speech.For this study, we collected around twenty thousand tweets from Twitter,encompassing a total of nine global controversies. These controversies spanvarious themes including racism, politics, and religion. In this paper, i) wepresent an annotated dataset after comprehensive examination of all thecontroversies, ii) we also highlight the difference between hate speech andinstigating hate speech by identifying distinguishing features, such astargeted identity attacks and reasons for hate.</description><author>Abhay Kumar, Vigneshwaran Shankaran, Rajesh Sharma</author><pubDate>Fri, 25 Oct 2024 16:57:59 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.19687v1</guid></item><item><title>Can GPT Redefine Medical Understanding? Evaluating GPT on Biomedical Machine Reading Comprehension</title><link>http://arxiv.org/abs/2405.18682v2</link><description>Large language models (LLMs) have shown remarkable performance on many tasksin different domains. However, their performance in closed-book biomedicalmachine reading comprehension (MRC) has not been evaluated in depth. In thiswork, we evaluate GPT on four closed-book biomedical MRC benchmarks. Weexperiment with different conventional prompting techniques as well asintroduce our own novel prompting method. To solve some of the retrievalproblems inherent to LLMs, we propose a prompting strategy named ImplicitRetrieval Augmented Generation (RAG) that alleviates the need for using vectordatabases to retrieve important chunks in traditional RAG setups. Moreover, wereport qualitative assessments on the natural language generation outputs fromour approach. The results show that our new prompting technique is able to getthe best performance in two out of four datasets and ranks second in rest ofthem. Experiments show that modern-day LLMs like GPT even in a zero-shotsetting can outperform supervised models, leading to new state-of-the-art(SoTA) results on two of the benchmarks.</description><author>Shubham Vatsal, Ayush Singh</author><pubDate>Fri, 25 Oct 2024 16:57:43 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.18682v2</guid></item><item><title>Compress then Serve: Serving Thousands of LoRA Adapters with Little Overhead</title><link>http://arxiv.org/abs/2407.00066v2</link><description>Fine-tuning large language models (LLMs) with low-rank adaptations (LoRAs)has become common practice, often yielding numerous copies of the same LLMdiffering only in their LoRA updates. This paradigm presents challenges forsystems that serve real-time responses to queries that each involve a differentLoRA. Prior works optimize the design of such systems but still requirecontinuous loading and offloading of LoRAs, as it is infeasible to storethousands of LoRAs in GPU memory. To mitigate this issue, we investigate theefficacy of model compression when serving LoRAs. We propose a method for jointcompression of LoRAs into a shared basis paired with LoRA-specific scalingmatrices. We extend our algorithm to learn clusters of LoRAs that are moreamenable to joint compression, allowing it to scale gracefully to large LoRAcollections. Our experiments with up to 500 LoRAs demonstrate that compressedLoRAs preserve performance while offering major throughput gains in realisticserving scenarios with over a thousand LoRAs, maintaining 80% of the throughputof serving a single LoRA.</description><author>Rickard Brüel-Gabrielsson, Jiacheng Zhu, Onkar Bhardwaj, Leshem Choshen, Kristjan Greenewald, Mikhail Yurochkin, Justin Solomon</author><pubDate>Fri, 25 Oct 2024 16:57:10 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.00066v2</guid></item><item><title>On Biases in a UK Biobank-based Retinal Image Classification Model</title><link>http://arxiv.org/abs/2408.02676v2</link><description>Recent work has uncovered alarming disparities in the performance of machinelearning models in healthcare. In this study, we explore whether suchdisparities are present in the UK Biobank fundus retinal images by training andevaluating a disease classification model on these images. We assess possibledisparities across various population groups and find substantial differencesdespite strong overall performance of the model. In particular, we discoverunfair performance for certain assessment centres, which is surprising giventhe rigorous data standardisation protocol. We compare how these differencesemerge and apply a range of existing bias mitigation methods to each one. A keyinsight is that each disparity has unique properties and responds differentlyto the mitigation methods. We also find that these methods are largely unableto enhance fairness, highlighting the need for better bias mitigation methodstailored to the specific type of bias.</description><author>Anissa Alloula, Rima Mustafa, Daniel R McGowan, Bartłomiej W. Papież</author><pubDate>Fri, 25 Oct 2024 16:51:19 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.02676v2</guid></item><item><title>Optimizing Hearthstone Agents using an Evolutionary Algorithm</title><link>http://arxiv.org/abs/2410.19681v1</link><description>Digital collectible card games are not only a growing part of the video gameindustry, but also an interesting research area for the field of computationalintelligence. This game genre allows researchers to deal with hiddeninformation, uncertainty and planning, among other aspects. This paper proposesthe use of evolutionary algorithms (EAs) to develop agents who play a cardgame, Hearthstone, by optimizing a data-driven decision-making mechanism thattakes into account all the elements currently in play. Agents featureself-learning by means of a competitive coevolutionary training approach,whereby no external sparring element defined by the user is required for theoptimization process. One of the agents developed through the proposed approachwas runner-up (best 6%) in an international Hearthstone Artificial Intelligence(AI) competition. Our proposal performed remarkably well, even when it facedstate-of-the-art techniques that attempted to take into account future gamestates, such as Monte-Carlo Tree search. This outcome shows how evolutionarycomputation could represent a considerable advantage in developing AIs forcollectible card games such as Hearthstone.</description><author>Pablo García-Sánchez, Alberto Tonda, Antonio J. Fernández-Leiva, Carlos Cotta</author><pubDate>Fri, 25 Oct 2024 16:49:11 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.19681v1</guid></item><item><title>Inferring Neural Signed Distance Functions by Overfitting on Single Noisy Point Clouds through Finetuning Data-Driven based Priors</title><link>http://arxiv.org/abs/2410.19680v1</link><description>It is important to estimate an accurate signed distance function (SDF) from apoint cloud in many computer vision applications. The latest methods learnneural SDFs using either a data-driven based or an overfitting-based strategy.However, these two kinds of methods are with either poor generalization or slowconvergence, which limits their capability under challenging scenarios likehighly noisy point clouds. To resolve this issue, we propose a method topromote pros of both data-driven based and overfitting-based methods for bettergeneralization, faster inference, and higher accuracy in learning neural SDFs.We introduce a novel statistical reasoning algorithm in local regions which isable to finetune data-driven based priors without signed distance supervision,clean point cloud, or point normals. This helps our method start with a goodinitialization, and converge to a minimum in a much faster way. Our numericaland visual comparisons with the state-of-the-art methods show our superiorityover these methods in surface reconstruction and point cloud denoising onwidely used shape and scene benchmarks. The code is available athttps://github.com/chenchao15/LocalN2NM.</description><author>Chao Chen, Yu-Shen Liu, Zhizhong Han</author><pubDate>Fri, 25 Oct 2024 16:48:44 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.19680v1</guid></item><item><title>Few Exemplar-Based General Medical Image Segmentation via Domain-Aware Selective Adaptation</title><link>http://arxiv.org/abs/2410.09254v2</link><description>Medical image segmentation poses challenges due to domain gaps, data modalityvariations, and dependency on domain knowledge or experts, especially for low-and middle-income countries (LMICs). Whereas for humans, given a few exemplars(with corresponding labels), we are able to segment different medical imageseven without exten-sive domain-specific clinical training. In addition, currentSAM-based medical segmentation models use fine-grained visual prompts, such asthe bounding rectangle generated from manually annotated target segmentationmask, as the bounding box (bbox) prompt during the testing phase. However, inactual clinical scenarios, no such precise prior knowledge is available. Ourexperimental results also reveal that previous models nearly fail to predictwhen given coarser bbox prompts. Considering these issues, in this paper, weintroduce a domain-aware selective adaptation approach to adapt the generalknowledge learned from a large model trained with natural images to thecorresponding medical domains/modalities, with access to only a few (e.g. lessthan 5) exemplars. Our method mitigates the aforementioned limitations,providing an efficient and LMICs-friendly solution. Extensive experimentalanalysis showcases the effectiveness of our approach, offering potentialadvancements in healthcare diagnostics and clinical applications in LMICs.</description><author>Chen Xu, Qiming Huang, Yuqi Hou, Jiangxing Wu, Fan Zhang, Hyung Jin Chang, Jianbo Jiao</author><pubDate>Fri, 25 Oct 2024 16:45:19 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.09254v2</guid></item><item><title>Learning the Regularization Strength for Deep Fine-Tuning via a Data-Emphasized Variational Objective</title><link>http://arxiv.org/abs/2410.19675v1</link><description>A number of popular transfer learning methods rely on grid search to selectregularization hyperparameters that control over-fitting. This grid searchrequirement has several key disadvantages: the search is computationallyexpensive, requires carving out a validation set that reduces the size ofavailable data for model training, and requires practitioners to specifycandidate values. In this paper, we propose an alternative to grid search:directly learning regularization hyperparameters on the full training set viamodel selection techniques based on the evidence lower bound ("ELBo") objectivefrom variational methods. For deep neural networks with millions of parameters,we specifically recommend a modified ELBo that upweights the influence of thedata likelihood relative to the prior while remaining a valid bound on theevidence for Bayesian model selection. Our proposed technique overcomes allthree disadvantages of grid search. We demonstrate effectiveness on imageclassification tasks on several datasets, yielding heldout accuracy comparableto existing approaches with far less compute time.</description><author>Ethan Harvey, Mikhail Petrov, Michael C. Hughes</author><pubDate>Fri, 25 Oct 2024 16:32:11 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.19675v1</guid></item><item><title>Spatial Shortcuts in Graph Neural Controlled Differential Equations</title><link>http://arxiv.org/abs/2410.19673v1</link><description>We incorporate prior graph topology information into a Neural ControlledDifferential Equation (NCDE) to predict the future states of a dynamical systemdefined on a graph. The informed NCDE infers the future dynamics at thevertices of simulated advection data on graph edges with a known causal graph,observed only at vertices during training. We investigate different positionsin the model architecture to inform the NCDE with graph information andidentify an outer position between hidden state and control as theoreticallyand empirically favorable. Our such informed NCDE requires fewer parameters toreach a lower Mean Absolute Error (MAE) compared to previous methods that donot incorporate additional graph topology information.</description><author>Michael Detzel, Gabriel Nobis, Jackie Ma, Wojciech Samek</author><pubDate>Fri, 25 Oct 2024 16:25:49 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.19673v1</guid></item><item><title>OneRef: Unified One-tower Expression Grounding and Segmentation with Mask Referring Modeling</title><link>http://arxiv.org/abs/2410.08021v2</link><description>Constrained by the separate encoding of vision and language, existinggrounding and referring segmentation works heavily rely on bulkyTransformer-based fusion en-/decoders and a variety of early-stage interactiontechnologies. Simultaneously, the current mask visual language modeling (MVLM)fails to capture the nuanced referential relationship between image-text inreferring tasks. In this paper, we propose OneRef, a minimalist referringframework built on the modality-shared one-tower transformer that unifies thevisual and linguistic feature spaces. To modeling the referential relationship,we introduce a novel MVLM paradigm called Mask Referring Modeling (MRefM),which encompasses both referring-aware mask image modeling and referring-awaremask language modeling. Both modules not only reconstruct modality-relatedcontent but also cross-modal referring content. Within MRefM, we propose areferring-aware dynamic image masking strategy that is aware of the referredregion rather than relying on fixed ratios or generic random masking schemes.By leveraging the unified visual language feature space and incorporatingMRefM's ability to model the referential relations, our approach enables directregression of the referring results without resorting to various complextechniques. Our method consistently surpasses existing approaches and achievesSoTA performance on both grounding and segmentation tasks, providing valuableinsights for future research. Our code and models are available athttps://github.com/linhuixiao/OneRef.</description><author>Linhui Xiao, Xiaoshan Yang, Fang Peng, Yaowei Wang, Changsheng Xu</author><pubDate>Fri, 25 Oct 2024 16:25:26 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.08021v2</guid></item><item><title>Electromechanical Dynamics of the Heart: A Study of Cardiac Hysteresis During Physical Stress Test</title><link>http://arxiv.org/abs/2410.19667v1</link><description>Cardiovascular diseases are best diagnosed using multiple modalities thatassess both the heart's electrical and mechanical functions. While effective,imaging techniques like echocardiography and nuclear imaging are costly and notwidely accessible. More affordable technologies, such as simultaneouselectrocardiography (ECG) and phonocardiography (PCG), may provide valuableinsights into electromechanical coupling and could be useful for prescreeningin low-resource settings. Using physical stress test data from the EPHNOGRAM ECG-PCG dataset, collectedfrom 23 healthy male subjects (age: 25.4+/-1.9 yrs), we investigatedelectromechanical intervals (RR, QT, systolic, and diastolic) and theirinteractions during exercise, along with hysteresis between cardiac electricalactivity and mechanical responses. Time delay analysis revealed distinct temporal relationships between QT,systolic, and diastolic intervals, with RR as the primary driver. The diastolicinterval showed near-synchrony with RR, while QT responded to RR intervalchanges with an average delay of 10.5s, and the systolic interval respondedmore slowly, with an average delay of 28.3s. We examined QT-RR, systolic-RR,and diastolic-RR hysteresis, finding narrower loops for diastolic RR and widerloops for systolic RR. Significant correlations (average:0.75) were foundbetween heart rate changes and hysteresis loop areas, suggesting the equivalentcircular area diameter as a promising biomarker for cardiac function underexercise stress. Deep learning models, including Long Short-Term Memory and ConvolutionalNeural Networks, estimated the QT, systolic, and diastolic intervals from RRdata, confirming the nonlinear relationship between RR and other intervals.Findings highlight a significant cardiac memory effect, linking ECG and PCGmorphology and timing to heart rate history.</description><author>Sajjad Karimi, Shirin Karimi, Amit J. Shah, Gari D. Clifford, Reza Sameni</author><pubDate>Fri, 25 Oct 2024 16:23:19 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.19667v1</guid></item><item><title>MetaTrading: An Immersion-Aware Model Trading Framework for Vehicular Metaverse Services</title><link>http://arxiv.org/abs/2410.19665v1</link><description>Updates of extensive Internet of Things (IoT) data are critical to theimmersion of vehicular metaverse services. However, providing high-quality andsustainable data in unstable and resource-constrained vehicular networksremains a significant challenge. To address this problem, we put forth a novelimmersion-aware model trading framework that incentivizes metaverse users (MUs)to contribute learning models trained by their latest local data for augmentedreality (AR) services in the vehicular metaverse, while preserving theirprivacy through federated learning. To comprehensively evaluate thecontribution of locally trained learning models provided by MUs to AR services,we design a new immersion metric that captures service immersion by consideringthe freshness and accuracy of learning models, as well as the amount andpotential value of raw data used for training. We model the tradinginteractions between metaverse service providers (MSPs) and MUs as anequilibrium problem with equilibrium constraints (EPEC) to analyze and balancetheir costs and gains. Moreover, considering dynamic network conditions andprivacy concerns, we formulate the reward decisions of MSPs as a multi-agentMarkov decision process. Then, a fully distributed dynamic reward method basedon deep reinforcement learning is presented, which operates without any privateinformation about MUs and other MSPs. Experimental results demonstrate that theproposed framework can effectively provide higher-value models for objectdetection and classification in AR services on real AR-related vehicle datasetscompared to benchmark schemes.</description><author>Hongjia Wu, Hui Zeng, Zehui Xiong, Jiawen Kang, Zhiping Cai, Tse-Tin Chan, Dusit Niyato, Zhu Han</author><pubDate>Fri, 25 Oct 2024 16:20:46 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.19665v1</guid></item><item><title>Can GPT Improve the State of Prior Authorization via Guideline Based Automated Question Answering?</title><link>http://arxiv.org/abs/2402.18419v2</link><description>Health insurance companies have a defined process called prior authorization(PA) which is a health plan cost-control process that requires doctors andother healthcare professionals to get clearance in advance from a health planbefore performing a particular procedure on a patient in order to be eligiblefor payment coverage. For health insurance companies, approving PA requests forpatients in the medical domain is a time-consuming and challenging task. One ofthose key challenges is validating if a request matches up to certain criteriasuch as age, gender, etc. In this work, we evaluate whether GPT can validatenumerous key factors, in turn helping health plans reach a decision drasticallyfaster. We frame it as a question answering task, prompting GPT to answer aquestion from patient electronic health record. We experiment with differentconventional prompting techniques as well as introduce our own novel promptingtechnique. Moreover, we report qualitative assessment by humans on the naturallanguage generation outputs from our approach. Results show that our methodachieves superior performance with the mean weighted F1 score of 0.61 ascompared to its standard counterparts.</description><author>Shubham Vatsal, Ayush Singh, Shabnam Tafreshi</author><pubDate>Fri, 25 Oct 2024 16:19:18 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.18419v2</guid></item><item><title>Demonstration-based learning for few-shot biomedical named entity recognition under machine reading comprehension</title><link>http://arxiv.org/abs/2308.06454v2</link><description>Although deep learning techniques have shown significant achievements, theyfrequently depend on extensive amounts of hand-labeled data and tend to performinadequately in few-shot scenarios. The objective of this study is to devise astrategy that can improve the model's capability to recognize biomedicalentities in scenarios of few-shot learning. By redefining biomedical namedentity recognition (BioNER) as a machine reading comprehension (MRC) problem,we propose a demonstration-based learning method to address few-shot BioNER,which involves constructing appropriate task demonstrations. In assessing ourproposed method, we compared the proposed method with existing advanced methodsusing six benchmark datasets, including BC4CHEMD, BC5CDR-Chemical,BC5CDR-Disease, NCBI-Disease, BC2GM, and JNLPBA. We examined the models'efficacy by reporting F1 scores from both the 25-shot and 50-shot learningexperiments. In 25-shot learning, we observed 1.1% improvements in the averageF1 scores compared to the baseline method, reaching 61.7%, 84.1%, 69.1%, 70.1%,50.6%, and 59.9% on six datasets, respectively. In 50-shot learning, we furtherimproved the average F1 scores by 1.0% compared to the baseline method,reaching 73.1%, 86.8%, 76.1%, 75.6%, 61.7%, and 65.4%, respectively. Wereported that in the realm of few-shot learning BioNER, MRC-based languagemodels are much more proficient in recognizing biomedical entities compared tothe sequence labeling approach. Furthermore, our MRC-language models cancompete successfully with fully-supervised learning methodologies that relyheavily on the availability of abundant annotated data. These results highlightpossible pathways for future advancements in few-shot BioNER methodologies.</description><author>Leilei Su, Jian Chen, Yifan Peng, Cong Sun</author><pubDate>Fri, 25 Oct 2024 16:17:49 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2308.06454v2</guid></item><item><title>DiffGS: Functional Gaussian Splatting Diffusion</title><link>http://arxiv.org/abs/2410.19657v1</link><description>3D Gaussian Splatting (3DGS) has shown convincing performance in renderingspeed and fidelity, yet the generation of Gaussian Splatting remains achallenge due to its discreteness and unstructured nature. In this work, wepropose DiffGS, a general Gaussian generator based on latent diffusion models.DiffGS is a powerful and efficient 3D generative model which is capable ofgenerating Gaussian primitives at arbitrary numbers for high-fidelity renderingwith rasterization. The key insight is to represent Gaussian Splatting in adisentangled manner via three novel functions to model Gaussian probabilities,colors and transforms. Through the novel disentanglement of 3DGS, we representthe discrete and unstructured 3DGS with continuous Gaussian Splattingfunctions, where we then train a latent diffusion model with the target ofgenerating these Gaussian Splatting functions both unconditionally andconditionally. Meanwhile, we introduce a discretization algorithm to extractGaussians at arbitrary numbers from the generated functions via octree-guidedsampling and optimization. We explore DiffGS for various tasks, includingunconditional generation, conditional generation from text, image, and partial3DGS, as well as Point-to-Gaussian generation. We believe that DiffGS providesa new direction for flexibly modeling and generating Gaussian Splatting.</description><author>Junsheng Zhou, Weiqi Zhang, Yu-Shen Liu</author><pubDate>Fri, 25 Oct 2024 16:08:08 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.19657v1</guid></item><item><title>Continuously Learning, Adapting, and Improving: A Dual-Process Approach to Autonomous Driving</title><link>http://arxiv.org/abs/2405.15324v2</link><description>Autonomous driving has advanced significantly due to sensors, machinelearning, and artificial intelligence improvements. However, prevailing methodsstruggle with intricate scenarios and causal relationships, hinderingadaptability and interpretability in varied environments. To address the aboveproblems, we introduce LeapAD, a novel paradigm for autonomous driving inspiredby the human cognitive process. Specifically, LeapAD emulates human attentionby selecting critical objects relevant to driving decisions, simplifyingenvironmental interpretation, and mitigating decision-making complexities.Additionally, LeapAD incorporates an innovative dual-process decision-makingmodule, which consists of an Analytic Process (System-II) for thorough analysisand reasoning, along with a Heuristic Process (System-I) for swift andempirical processing. The Analytic Process leverages its logical reasoning toaccumulate linguistic driving experience, which is then transferred to theHeuristic Process by supervised fine-tuning. Through reflection mechanisms anda growing memory bank, LeapAD continuously improves itself from past mistakesin a closed-loop environment. Closed-loop testing in CARLA shows that LeapADoutperforms all methods relying solely on camera input, requiring 1-2 orders ofmagnitude less labeled data. Experiments also demonstrate that as the memorybank expands, the Heuristic Process with only 1.8B parameters can inherit theknowledge from a GPT-4 powered Analytic Process and achieve continuousperformance improvement. Project page: https://pjlab-adg.github.io/LeapAD.</description><author>Jianbiao Mei, Yukai Ma, Xuemeng Yang, Licheng Wen, Xinyu Cai, Xin Li, Daocheng Fu, Bo Zhang, Pinlong Cai, Min Dou, Botian Shi, Liang He, Yong Liu, Yu Qiao</author><pubDate>Fri, 25 Oct 2024 16:00:54 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.15324v2</guid></item><item><title>Graph Diffusion Policy Optimization</title><link>http://arxiv.org/abs/2402.16302v2</link><description>Recent research has made significant progress in optimizing diffusion modelsfor downstream objectives, which is an important pursuit in fields such asgraph generation for drug design. However, directly applying these models tograph presents challenges, resulting in suboptimal performance. This paperintroduces graph diffusion policy optimization (GDPO), a novel approach tooptimize graph diffusion models for arbitrary (e.g., non-differentiable)objectives using reinforcement learning. GDPO is based on an eager policygradient tailored for graph diffusion models, developed through meticulousanalysis and promising improved performance. Experimental results show thatGDPO achieves state-of-the-art performance in various graph generation taskswith complex and diverse objectives. Code is available athttps://github.com/sail-sg/GDPO.</description><author>Yijing Liu, Chao Du, Tianyu Pang, Chongxuan Li, Min Lin, Wei Chen</author><pubDate>Fri, 25 Oct 2024 15:59:35 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.16302v2</guid></item><item><title>Conformal Prediction for Multimodal Regression</title><link>http://arxiv.org/abs/2410.19653v1</link><description>This paper introduces multimodal conformal regression. Traditionally confinedto scenarios with solely numerical input features, conformal prediction is nowextended to multimodal contexts through our methodology, which harnessesinternal features from complex neural network architectures processing imagesand unstructured text. Our findings highlight the potential for internal neuralnetwork features, extracted from convergence points where multimodalinformation is combined, to be used by conformal prediction to constructprediction intervals (PIs). This capability paves new paths for deployingconformal prediction in domains abundant with multimodal data, enabling abroader range of problems to benefit from guaranteed distribution-freeuncertainty quantification.</description><author>Alexis Bose, Jonathan Ethier, Paul Guinand</author><pubDate>Fri, 25 Oct 2024 15:56:39 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.19653v1</guid></item><item><title>Deep learning-based identification of patients at increased risk of cancer using routine laboratory markers</title><link>http://arxiv.org/abs/2410.19646v1</link><description>Early screening for cancer has proven to improve the survival rate and sparepatients from intensive and costly treatments due to late diagnosis. Cancerscreening in the healthy population involves an initial risk stratificationstep to determine the screening method and frequency, primarily to optimizeresource allocation by targeting screening towards individuals who draw mostbenefit. For most screening programs, age and clinical risk factors such asfamily history are part of the initial risk stratification algorithm. In thispaper, we focus on developing a blood marker-based risk stratificationapproach, which could be used to identify patients with elevated cancer risk tobe encouraged for taking a diagnostic test or participate in a screeningprogram. We demonstrate that the combination of simple, widely available bloodtests, such as complete blood count and complete metabolic panel, couldpotentially be used to identify patients at risk for colorectal, liver, andlung cancers with areas under the ROC curve of 0.76, 0.85, 0.78, respectively.Furthermore, we hypothesize that such an approach could not only be used aspre-screening risk assessment for individuals but also as population healthmanagement tool, for example to better interrogate the cancer risk in certainsub-populations.</description><author>Vivek Singh, Shikha Chaganti, Matthias Siebert, Soumya Rajesh, Andrei Puiu, Raj Gopalan, Jamie Gramz, Dorin Comaniciu, Ali Kamen</author><pubDate>Fri, 25 Oct 2024 15:50:27 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.19646v1</guid></item><item><title>Improving Stochastic Cubic Newton with Momentum</title><link>http://arxiv.org/abs/2410.19644v1</link><description>We study stochastic second-order methods for solving general non-convexoptimization problems. We propose using a special version of momentum tostabilize the stochastic gradient and Hessian estimates in Newton's method. Weshow that momentum provably improves the variance of stochastic estimates andallows the method to converge for any noise level. Using the cubicregularization technique, we prove a global convergence rate for our method ongeneral non-convex problems to a second-order stationary point, even when usingonly a single stochastic data sample per iteration. This starkly contrasts withall existing stochastic second-order methods for non-convex problems, whichtypically require large batches. Therefore, we are the first to demonstrateglobal convergence for batches of arbitrary size in the non-convex case for theStochastic Cubic Newton. Additionally, we show improved speed on convexstochastic problems for our regularized Newton methods with momentum.</description><author>El Mahdi Chayti, Nikita Doikov, Martin Jaggi</author><pubDate>Fri, 25 Oct 2024 15:49:16 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.19644v1</guid></item><item><title>Impact of Leakage on Data Harmonization in Machine Learning Pipelines in Class Imbalance Across Sites</title><link>http://arxiv.org/abs/2410.19643v1</link><description>Machine learning (ML) models benefit from large datasets. Collecting data inbiomedical domains is costly and challenging, hence, combining datasets hasbecome a common practice. However, datasets obtained under different conditionscould present undesired site-specific variability. Data harmonization methodsaim to remove site-specific variance while retaining biologically relevantinformation. This study evaluates the effectiveness of popularly usedComBat-based methods for harmonizing data in scenarios where the class balanceis not equal across sites. We find that these methods struggle with dataleakage issues. To overcome this problem, we propose a novel approachPrettYharmonize, designed to harmonize data by pretending the target labels. Wevalidate our approach using controlled datasets designed to benchmark theutility of harmonization. Finally, using real-world MRI and clinical data, wecompare leakage-prone methods with PrettYharmonize and show that it achievescomparable performance while avoiding data leakage, particularly insite-target-dependence scenarios.</description><author>Nicolás Nieto, Simon B. Eickhoff, Christian Jung, Martin Reuter, Kersten Diers, Malte Kelm, Artur Lichtenberg, Federico Raimondo, Kaustubh R. Patil</author><pubDate>Fri, 25 Oct 2024 15:49:04 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.19643v1</guid></item><item><title>The Double-Edged Sword of Behavioral Responses in Strategic Classification: Theory and User Studies</title><link>http://arxiv.org/abs/2410.18066v2</link><description>When humans are subject to an algorithmic decision system, they canstrategically adjust their behavior accordingly (``game'' the system). While agrowing line of literature on strategic classification has used game-theoreticmodeling to understand and mitigate such gaming, these existing works considerstandard models of fully rational agents. In this paper, we propose a strategicclassification model that considers behavioral biases in human responses toalgorithms. We show how misperceptions of a classifier (specifically, of itsfeature weights) can lead to different types of discrepancies between biasedand rational agents' responses, and identify when behavioral agents over- orunder-invest in different features. We also show that strategic agents withbehavioral biases can benefit or (perhaps, unexpectedly) harm the firm comparedto fully rational strategic agents. We complement our analytical results withuser studies, which support our hypothesis of behavioral biases in humanresponses to the algorithm. Together, our findings highlight the need toaccount for human (cognitive) biases when designing AI systems, and providingexplanations of them, to strategic human in the loop.</description><author>Raman Ebrahimi, Kristen Vaccaro, Parinaz Naghizadeh</author><pubDate>Fri, 25 Oct 2024 15:48:34 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.18066v2</guid></item><item><title>VARS: Vision-based Assessment of Risk in Security Systems</title><link>http://arxiv.org/abs/2410.19642v1</link><description>The accurate prediction of danger levels in video content is critical forenhancing safety and security systems, particularly in environments where quickand reliable assessments are essential. In this study, we perform a comparativeanalysis of various machine learning and deep learning models to predict dangerratings in a custom dataset of 100 videos, each containing 50 frames, annotatedwith human-rated danger scores ranging from 0 to 10. The danger ratings arefurther classified into three categories: no alert (less than 7)and high alert(greater than equal to 7). Our evaluation covers classical machine learningmodels, such as Support Vector Machines, as well as Neural Networks, andtransformer-based models. Model performance is assessed using standard metricssuch as accuracy, F1-score, and mean absolute error (MAE), and the results arecompared to identify the most robust approach. This research contributes todeveloping a more accurate and generalizable danger assessment framework forvideo-based risk detection.</description><author>Pranav Gupta, Pratham Gohil, Sridhar S</author><pubDate>Fri, 25 Oct 2024 15:47:13 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.19642v1</guid></item><item><title>Planning-Aware Diffusion Networks for Enhanced Motion Forecasting in Autonomous Driving</title><link>http://arxiv.org/abs/2410.19639v1</link><description>Autonomous driving technology has seen significant advancements, but existingmodels often fail to fully capture the complexity of multi-agent environments,where interactions between dynamic agents are critical. To address this, wepropose the Planning-Integrated Forecasting Model (PIFM), a novel frameworkinspired by neural mechanisms governing decision-making and multi-agentcoordination in the brain. PIFM leverages rich contextual information,integrating road structures, traffic rules, and the behavior of surroundingvehicles to improve both the accuracy and interpretability of predictions. Byadopting a diffusion-based architecture, akin to neural diffusion processesinvolved in predicting and planning, PIFM is able to forecast futuretrajectories of all agents within a scenario. This architecture enhances modeltransparency, as it parallels the brain's method of dynamically adjustingpredictions based on external stimuli and other agents'behaviors. Extensiveexperiments validate PIFM's capacity to provide interpretable,neuroscience-driven solutions for safer and more efficient autonomous drivingsystems, with an extremely low number of parameters.</description><author>Liu Yunhao, Ding Hong, Zhang Ziming, Wang Huixin, Liu Jinzhao, Xi Suyang</author><pubDate>Fri, 25 Oct 2024 15:44:51 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.19639v1</guid></item><item><title>A distributional simplicity bias in the learning dynamics of transformers</title><link>http://arxiv.org/abs/2410.19637v1</link><description>The remarkable capability of over-parameterised neural networks to generaliseeffectively has been explained by invoking a ``simplicity bias'': neuralnetworks prevent overfitting by initially learning simple classifiers beforeprogressing to more complex, non-linear functions. While simplicity biases havebeen described theoretically and experimentally in feed-forward networks forsupervised learning, the extent to which they also explain the remarkablesuccess of transformers trained with self-supervised techniques remainsunclear. In our study, we demonstrate that transformers, trained on naturallanguage data, also display a simplicity bias. Specifically, they sequentiallylearn many-body interactions among input tokens, reaching a saturation point inthe prediction error for low-degree interactions while continuing to learnhigh-degree interactions. To conduct this analysis, we develop a procedure togenerate \textit{clones} of a given natural language data set, which rigorouslycapture the interactions between tokens up to a specified order. This approachopens up the possibilities of studying how interactions of different orders inthe data affect learning, in natural language processing and beyond.</description><author>Riccardo Rende, Federica Gerace, Alessandro Laio, Sebastian Goldt</author><pubDate>Fri, 25 Oct 2024 15:39:34 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.19637v1</guid></item><item><title>Frozen-DETR: Enhancing DETR with Image Understanding from Frozen Foundation Models</title><link>http://arxiv.org/abs/2410.19635v1</link><description>Recent vision foundation models can extract universal representations andshow impressive abilities in various tasks. However, their application onobject detection is largely overlooked, especially without fine-tuning them. Inthis work, we show that frozen foundation models can be a versatile featureenhancer, even though they are not pre-trained for object detection.Specifically, we explore directly transferring the high-level imageunderstanding of foundation models to detectors in the following two ways.First, the class token in foundation models provides an in-depth understandingof the complex scene, which facilitates decoding object queries in thedetector's decoder by providing a compact context. Additionally, the patchtokens in foundation models can enrich the features in the detector's encoderby providing semantic details. Utilizing frozen foundation models asplug-and-play modules rather than the commonly used backbone can significantlyenhance the detector's performance while preventing the problems caused by thearchitecture discrepancy between the detector's backbone and the foundationmodel. With such a novel paradigm, we boost the SOTA query-based detector DINOfrom 49.0% AP to 51.9% AP (+2.9% AP) and further to 53.8% AP (+4.8% AP) byintegrating one or two foundation models respectively, on the COCO validationset after training for 12 epochs with R50 as the detector's backbone.</description><author>Shenghao Fu, Junkai Yan, Qize Yang, Xihan Wei, Xiaohua Xie, Wei-Shi Zheng</author><pubDate>Fri, 25 Oct 2024 15:38:24 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.19635v1</guid></item><item><title>Efficient Biological Data Acquisition through Inference Set Design</title><link>http://arxiv.org/abs/2410.19631v1</link><description>In drug discovery, highly automated high-throughput laboratories are used toscreen a large number of compounds in search of effective drugs. Theseexperiments are expensive, so we might hope to reduce their cost byexperimenting on a subset of the compounds, and predicting the outcomes of theremaining experiments. In this work, we model this scenario as a sequentialsubset selection problem: we aim to select the smallest set of candidates inorder to achieve some desired level of accuracy for the system as a whole. Ourkey observation is that, if there is heterogeneity in the difficulty of theprediction problem across the input space, selectively obtaining the labels forthe hardest examples in the acquisition pool will leave only the relativelyeasy examples to remain in the inference set, leading to better overall systemperformance. We call this mechanism inference set design, and propose the useof an uncertainty-based active learning solution to prune out these challengingexamples. Our algorithm includes an explicit stopping criterion that stopsrunning the experiments when it is sufficiently confident that the system hasreached the target performance. Our empirical studies on image and moleculardatasets, as well as a real-world large-scale biological assay, show thatdeploying active learning for inference set design leads to significantreduction in experimental cost while obtaining high system performance.</description><author>Ihor Neporozhnii, Julien Roy, Emmanuel Bengio, Jason Hartford</author><pubDate>Fri, 25 Oct 2024 15:34:03 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.19631v1</guid></item><item><title>Advanced deep-reinforcement-learning methods for flow control: group-invariant and positional-encoding networks improve learning speed and quality</title><link>http://arxiv.org/abs/2407.17822v2</link><description>Flow control is key to maximize energy efficiency in a wide range ofapplications. However, traditional flow-control methods face significantchallenges in addressing non-linear systems and high-dimensional data, limitingtheir application in realistic energy systems. This study advancesdeep-reinforcement-learning (DRL) methods for flow control, particularlyfocusing on integrating group-invariant networks and positional encoding intoDRL architectures. Our methods leverage multi-agent reinforcement learning(MARL) to exploit policy invariance in space, in combination withgroup-invariant networks to ensure local symmetry invariance. Additionally, apositional encoding inspired by the transformer architecture is incorporated toprovide location information to the agents, mitigating action constraints fromstrict invariance. The proposed methods are verified using a case study ofRayleigh-B\'enard convection, where the goal is to minimize the Nusselt numberNu. The group-invariant neural networks (GI-NNs) show faster convergencecompared to the base MARL, achieving better average policy performance. TheGI-NNs not only cut DRL training time in half but also notably enhance learningreproducibility. Positional encoding further enhances these results,effectively reducing the minimum Nu and stabilizing convergence. Interestingly,group invariant networks specialize in improving learning speed and positionalencoding specializes in improving learning quality. These results demonstratethat choosing a suitable feature-representation method according to the purposeas well as the characteristics of each control problem is essential. We believethat the results of this study will not only inspire novel DRL methods withinvariant and unique representations, but also provide useful insights forindustrial applications.</description><author>Joongoo Jeon, Jean Rabault, Joel Vasanth, Francisco Alcántara-Ávila, Shilaj Baral, Ricardo Vinuesa</author><pubDate>Fri, 25 Oct 2024 15:27:40 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.17822v2</guid></item><item><title>EVOTER: Evolution of Transparent Explainable Rule-sets</title><link>http://arxiv.org/abs/2204.10438v5</link><description>Most AI systems are black boxes generating reasonable outputs for giveninputs. Some domains, however, have explainability and trustworthinessrequirements that cannot be directly met by these approaches. Various methodshave therefore been developed to interpret black-box models after training.This paper advocates an alternative approach where the models are transparentand explainable to begin with. This approach, EVOTER, evolves rule-sets basedon simple logical expressions. The approach is evaluated in severalprediction/classification and prescription/policy search domains with andwithout a surrogate. It is shown to discover meaningful rule sets that performsimilarly to black-box models. The rules can provide insight into the domain,and make biases hidden in the data explicit. It may also be possible to editthem directly to remove biases and add constraints. EVOTER thus forms apromising foundation for building trustworthy AI systems for real-worldapplications in the future.</description><author>Hormoz Shahrzad, Babak Hodjat, Risto Miikkulainen</author><pubDate>Fri, 25 Oct 2024 15:27:18 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2204.10438v5</guid></item><item><title>Knowledge Graph Enhanced Language Agents for Recommendation</title><link>http://arxiv.org/abs/2410.19627v1</link><description>Language agents have recently been used to simulate human behavior anduser-item interactions for recommendation systems. However, current languageagent simulations do not understand the relationships between users and items,leading to inaccurate user profiles and ineffective recommendations. In thiswork, we explore the utility of Knowledge Graphs (KGs), which contain extensiveand reliable relationships between users and items, for recommendation. Our keyinsight is that the paths in a KG can capture complex relationships betweenusers and items, eliciting the underlying reasons for user preferences andenriching user profiles. Leveraging this insight, we propose Knowledge GraphEnhanced Language Agents(KGLA), a framework that unifies language agents and KGfor recommendation systems. In the simulated recommendation scenario, weposition the user and item within the KG and integrate KG paths as naturallanguage descriptions into the simulation. This allows language agents tointeract with each other and discover sufficient rationale behind theirinteractions, making the simulation more accurate and aligned with real-worldcases, thus improving recommendation performance. Our experimental results showthat KGLA significantly improves recommendation performance (with a 33%-95%boost in NDCG@1 among three widely used benchmarks) compared to the previousbest baseline method.</description><author>Taicheng Guo, Chaochun Liu, Hai Wang, Varun Mannam, Fang Wang, Xin Chen, Xiangliang Zhang, Chandan K. Reddy</author><pubDate>Fri, 25 Oct 2024 15:25:36 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.19627v1</guid></item><item><title>$C^2$: Scalable Auto-Feedback for LLM-based Chart Generation</title><link>http://arxiv.org/abs/2410.18652v2</link><description>Generating high-quality charts with Large Language Models presentssignificant challenges due to limited data and the high cost of scaling throughhuman curation. Instruction, data, and code triplets are scarce and expensiveto manually curate as their creation demands technical expertise. To addressthis scalability issue, we introduce a reference-free automatic feedbackgenerator, which eliminates the need for costly human intervention. Our novelframework, $C^2$, consists of (1) an automatic feedback provider (ChartAF) and(2) a diverse, reference-free dataset (ChartUIE-8K). Quantitative results arecompelling: in our first experiment, 74% of respondents strongly preferred, and10% preferred, the results after feedback. The second post-feedback experimentdemonstrates that ChartAF outperforms nine baselines. Moreover, ChartUIE-8Ksignificantly improves data diversity by increasing queries, datasets, andchart types by 5982%, 1936%, and 91%, respectively, over benchmarks. Finally,an LLM user study revealed that 94% of participants preferred ChartUIE-8K'squeries, with 93% deeming them aligned with real-world use cases. Corecontributions are available as open-source at an anonymized project site, withample qualitative examples.</description><author>Woosung Koh, Jang Han Yoon, MinHyung Lee, Youngjin Song, Jaegwan Cho, Jaehyun Kang, Taehyeon Kim, Se-young Yun, Youngjae Yu, Bongshin Lee</author><pubDate>Fri, 25 Oct 2024 15:23:54 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.18652v2</guid></item><item><title>Contrast Sets for Evaluating Language-Guided Robot Policies</title><link>http://arxiv.org/abs/2406.13636v2</link><description>Robot evaluations in language-guided, real world settings are time-consumingand often sample only a small space of potential instructions across complexscenes. In this work, we introduce contrast sets for robotics as an approach tomake small, but specific, perturbations to otherwise independent, identicallydistributed (i.i.d.) test instances. We investigate the relationship betweenexperimenter effort to carry out an evaluation and the resulting estimated testperformance as well as the insights that can be drawn from performance onperturbed instances. We use the relative performance change of differentcontrast set perturbations to characterize policies at reduced experimentereffort in both a simulated manipulation task and a physical robotvision-and-language navigation task. We encourage the use of contrast setevaluations as a more informative alternative to small scale, i.i.d.demonstrations on physical robots, and as a scalable alternative toindustry-scale real world evaluations.</description><author>Abrar Anwar, Rohan Gupta, Jesse Thomason</author><pubDate>Fri, 25 Oct 2024 15:23:07 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.13636v2</guid></item><item><title>Toward Generalizable Multiple Sclerosis Lesion Segmentation Models</title><link>http://arxiv.org/abs/2410.19623v1</link><description>Automating Multiple Sclerosis (MS) lesion segmentation would be of greatbenefit in initial diagnosis as well as monitoring disease progression. Deeplearning based segmentation models perform well in many domains, but thestate-of-the-art in MS lesion segmentation is still suboptimal. Complementaryto previous MS lesion segmentation challenges which focused on optimizing theperformance on a single evaluation dataset, this study aims to develop modelsthat generalize across diverse evaluation datasets, mirroring real-worldclinical scenarios that involve varied scanners, settings, and patient cohorts.To this end, we used all high-quality publicly-available MS lesion segmentationdatasets on which we systematically trained a state-of-the-art UNet++architecture. The resulting models demonstrate consistent performance acrossthe remaining test datasets (are generalizable), with larger and moreheterogeneous datasets leading to better models. To the best of our knowledge,this represents the most comprehensive cross-dataset evaluation of MS lesionsegmentation models to date using publicly available datasets. Additionally,explicitly enhancing dataset size by merging datasets improved modelperformance. Specifically, a model trained on the combined MSSEG2016-train,ISBI2015, and 3D-MR-MS datasets surpasses the winner of the MICCAI-2016competition. Moreover, we demonstrate that the generalizability of our modelsalso relies on our original use of quantile normalization on MRI intensities.</description><author>Liviu Badea, Maria Popa</author><pubDate>Fri, 25 Oct 2024 15:21:54 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.19623v1</guid></item><item><title>Parametric model reduction of mean-field and stochastic systems via higher-order action matching</title><link>http://arxiv.org/abs/2410.12000v2</link><description>The aim of this work is to learn models of population dynamics of physicalsystems that feature stochastic and mean-field effects and that depend onphysics parameters. The learned models can act as surrogates of classicalnumerical models to efficiently predict the system behavior over the physicsparameters. Building on the Benamou-Brenier formula from optimal transport andaction matching, we use a variational problem to infer parameter- andtime-dependent gradient fields that represent approximations of the populationdynamics. The inferred gradient fields can then be used to rapidly generatesample trajectories that mimic the dynamics of the physical system on apopulation level over varying physics parameters. We show that combining MonteCarlo sampling with higher-order quadrature rules is critical for accuratelyestimating the training objective from sample data and for stabilizing thetraining process. We demonstrate on Vlasov-Poisson instabilities as well as onhigh-dimensional particle and chaotic systems that our approach accuratelypredicts population dynamics over a wide range of parameters and outperformsstate-of-the-art diffusion-based and flow-based modeling that simply conditionon time and physics parameters.</description><author>Jules Berman, Tobias Blickhan, Benjamin Peherstorfer</author><pubDate>Fri, 25 Oct 2024 15:05:14 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.12000v2</guid></item><item><title>Shared Control with Black Box Agents using Oracle Queries</title><link>http://arxiv.org/abs/2410.19612v1</link><description>Shared control problems involve a robot learning to collaborate with a human.When learning a shared control policy, short communication between the agentscan often significantly reduce running times and improve the system's accuracy.We extend the shared control problem to include the ability to directly query acooperating agent. We consider two types of potential responses to a query,namely oracles: one that can provide the learner with the best action theyshould take, even when that action might be myopically wrong, and one with abounded knowledge limited to its part of the system. Given this additionalinformation channel, this work further presents three heuristics for choosingwhen to query: reinforcement learning-based, utility-based, and entropy-based.These heuristics aim to reduce a system's overall learning cost. Empiricalresults on two environments show the benefits of querying to learn a bettercontrol policy and the tradeoffs between the proposed heuristics.</description><author>Inbal Avraham, Reuth Mirsky</author><pubDate>Fri, 25 Oct 2024 15:04:37 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.19612v1</guid></item><item><title>OpenWebVoyager: Building Multimodal Web Agents via Iterative Real-World Exploration, Feedback and Optimization</title><link>http://arxiv.org/abs/2410.19609v1</link><description>The rapid development of large language and multimodal models has sparkedsignificant interest in using proprietary models, such as GPT-4o, to developautonomous agents capable of handling real-world scenarios like web navigation.Although recent open-source efforts have tried to equip agents with the abilityto explore environments and continuously improve over time, they are buildingtext-only agents in synthetic environments where the reward signals are clearlydefined. Such agents struggle to generalize to realistic settings that requiremultimodal perception abilities and lack ground-truth signals. In this paper,we introduce an open-source framework designed to facilitate the development ofmultimodal web agent that can autonomously conduct real-world exploration andimprove itself. We first train the base model with imitation learning to gainthe basic abilities. We then let the agent explore the open web and collectfeedback on its trajectories. After that, it further improves its policy bylearning from well-performing trajectories judged by another general-purposemodel. This exploration-feedback-optimization cycle can continue for severaliterations. Experimental results show that our web agent successfully improvesitself after each iteration, demonstrating strong performance across multipletest sets.</description><author>Hongliang He, Wenlin Yao, Kaixin Ma, Wenhao Yu, Hongming Zhang, Tianqing Fang, Zhenzhong Lan, Dong Yu</author><pubDate>Fri, 25 Oct 2024 15:01:27 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.19609v1</guid></item><item><title>Analyzing Neural Network Robustness Using Graph Curvature</title><link>http://arxiv.org/abs/2410.19607v1</link><description>This paper presents a new look at the neural network (NN) robustness problem,from the point of view of graph theory analysis, specifically graph curvature.Graph curvature (e.g., Ricci curvature) has been used to analyze systemdynamics and identify bottlenecks in many domains, including road trafficanalysis and internet routing. We define the notion of neural Ricci curvatureand use it to identify bottleneck NN edges that are heavily used to ``transportdata" to the NN outputs. We provide an evaluation on MNIST that illustratesthat such edges indeed occur more frequently for inputs where NNs are lessrobust. These results will serve as the basis for an alternative method ofrobust training, by minimizing the number of bottleneck edges.</description><author>Shuhang Tan, Jayson Sia, Paul Bogdan, Radoslav Ivanov</author><pubDate>Fri, 25 Oct 2024 14:59:58 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.19607v1</guid></item><item><title>Multi-modal Motion Prediction using Temporal Ensembling with Learning-based Aggregation</title><link>http://arxiv.org/abs/2410.19606v1</link><description>Recent years have seen a shift towards learning-based methods for trajectoryprediction, with challenges remaining in addressing uncertainty and capturingmulti-modal distributions. This paper introduces Temporal Ensembling withLearning-based Aggregation, a meta-algorithm designed to mitigate the issue ofmissing behaviors in trajectory prediction, which leads to inconsistentpredictions across consecutive frames. Unlike conventional model ensembling,temporal ensembling leverages predictions from nearby frames to enhance spatialcoverage and prediction diversity. By confirming predictions from multipleframes, temporal ensembling compensates for occasional errors in individualframe predictions. Furthermore, trajectory-level aggregation, often utilized inmodel ensembling, is insufficient for temporal ensembling due to a lack ofconsideration of traffic context and its tendency to assign candidatetrajectories with incorrect driving behaviors to final predictions. We furtheremphasize the necessity of learning-based aggregation by utilizing mode querieswithin a DETR-like architecture for our temporal ensembling, leveraging thecharacteristics of predictions from nearby frames. Our method, validated on theArgoverse 2 dataset, shows notable improvements: a 4% reduction in minADE, a 5%decrease in minFDE, and a 1.16% reduction in the miss rate compared to thestrongest baseline, QCNet, highlighting its efficacy and potential inautonomous driving.</description><author>Kai-Yin Hong, Chieh-Chih Wang, Wen-Chieh Lin</author><pubDate>Fri, 25 Oct 2024 14:59:07 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.19606v1</guid></item><item><title>CoqPilot, a plugin for LLM-based generation of proofs</title><link>http://arxiv.org/abs/2410.19605v1</link><description>We present CoqPilot, a VS Code extension designed to help automate writing ofCoq proofs. The plugin collects the parts of proofs marked with the admittactic in a Coq file, i.e., proof holes, and combines LLMs along withnon-machine-learning methods to generate proof candidates for the holes. Then,CoqPilot checks if each proof candidate solves the given subgoal and, ifsuccessful, replaces the hole with it. The focus of CoqPilot is twofold.Firstly, we want to allow users to seamlessly combine multiple Coq generationapproaches and provide a zero-setup experience for our tool. Secondly, we wantto deliver a platform for LLM-based experiments on Coq proof generation. Wedeveloped a benchmarking system for Coq generation methods, available in theplugin, and conducted an experiment using it, showcasing the framework'spossibilities. Demo of CoqPilot is available at: https://youtu.be/oB1Lx-So9Lo.Code at: https://github.com/JetBrains-Research/coqpilot</description><author>Andrei Kozyrev, Gleb Solovev, Nikita Khramov, Anton Podkopaev</author><pubDate>Fri, 25 Oct 2024 14:57:29 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.19605v1</guid></item><item><title>Microplastic Identification Using AI-Driven Image Segmentation and GAN-Generated Ecological Context</title><link>http://arxiv.org/abs/2410.19604v1</link><description>Current methods for microplastic identification in water samples are costlyand require expert analysis. Here, we propose a deep learning segmentationmodel to automatically identify microplastics in microscopic images. We labeledimages of microplastic from the Moore Institute for Plastic Pollution Researchand employ a Generative Adversarial Network (GAN) to supplement and generatediverse training data. To verify the validity of the generated data, weconducted a reader study where an expert was able to discern the generatedmicroplastic from real microplastic at a rate of 68 percent. Our segmentationmodel trained on the combined data achieved an F1-Score of 0.91 on a diversedataset, compared to the model without generated data's 0.82. With our findingswe aim to enhance the ability of both experts and citizens to detectmicroplastic across diverse ecological contexts, thereby improving the cost andaccessibility of microplastic analysis.</description><author>Alex Dils, David Raymond, Jack Spottiswood, Samay Kodige, Dylan Karmin, Rikhil Kokal, Win Cowger, Chris Sadée</author><pubDate>Fri, 25 Oct 2024 14:57:09 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.19604v1</guid></item><item><title>Language Models Need Inductive Biases to Count Inductively</title><link>http://arxiv.org/abs/2405.20131v2</link><description>Counting is a fundamental example of generalization, whether viewed throughthe mathematical lens of Peano's axioms defining the natural numbers or thecognitive science literature for children learning to count. The argument holdsfor both cases that learning to count means learning to count infinitely. Whilefew papers have tried to distill transformer "reasoning" to the simplest caseof counting, investigating length generalization does occur throughout theliterature. In the "train short, test long" paradigm of NLP, length refers tothe training sentence length. In formal language recognition, length refers tothe input sequence length, or the maximum stack size induced by a pushdownautomata. In general problem solving, length refers to the number of hops in adeductive reasoning chain or the recursion depth. For all cases, counting iscentral to task success. And crucially, generalizing counting inductively iscentral to success on OOD instances. This work provides extensive empiricalresults on training language models to count. We experiment with architecturesranging from RNNs, Transformers, State-Space Models and RWKV. We presentcarefully-designed task formats, auxiliary tasks and positional embeddings toavoid limitations in generalization with OOD-position and OOD-vocabulary. Wefind that while traditional RNNs trivially achieve inductive counting,Transformers have to rely on positional embeddings to count out-of-domain. Ascounting is the basis for many arguments concerning the expressivity ofTransformers, our finding calls for the community to reexamine the applicationscope of primitive functions defined in formal characterizations. Finally,modern RNNs also largely underperform traditional RNNs in generalizing countinginductively. We discuss how design choices that enable parallelized training ofmodern RNNs cause them to lose merits of a recurrent nature.</description><author>Yingshan Chang, Yonatan Bisk</author><pubDate>Fri, 25 Oct 2024 14:50:45 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.20131v2</guid></item><item><title>Take Caution in Using LLMs as Human Surrogates: Scylla Ex Machina</title><link>http://arxiv.org/abs/2410.19599v1</link><description>Recent studies suggest large language models (LLMs) can exhibit human-likereasoning, aligning with human behavior in economic experiments, surveys, andpolitical discourse. This has led many to propose that LLMs can be used assurrogates for humans in social science research. However, LLMs differfundamentally from humans, relying on probabilistic patterns, absent theembodied experiences or survival objectives that shape human cognition. Weassess the reasoning depth of LLMs using the 11-20 money request game. Almostall advanced approaches fail to replicate human behavior distributions acrossmany models, except in one case involving fine-tuning using a substantialamount of human behavior data. Causes of failure are diverse, relating to inputlanguage, roles, and safeguarding. These results caution against using LLMs tostudy human behaviors or as human surrogates.</description><author>Yuan Gao, Dokyun Lee, Gordon Burtch, Sina Fazelpour</author><pubDate>Fri, 25 Oct 2024 14:46:07 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.19599v1</guid></item><item><title>Mask-Weighted Spatial Likelihood Coding for Speaker-Independent Joint Localization and Mask Estimation</title><link>http://arxiv.org/abs/2410.19595v1</link><description>Due to their robustness and flexibility, neural-driven beamformers are apopular choice for speech separation in challenging environments with a varyingamount of simultaneous speakers alongside noise and reverberation.Time-frequency masks and relative directions of the speakers regarding a fixedspatial grid can be used to estimate the beamformer's parameters. To somedegree, speaker-independence is achieved by ensuring a greater amount ofspatial partitions than speech sources. In this work, we analyze how to encodeboth mask and positioning into such a grid to enable joint estimation of bothquantities. We propose mask-weighted spatial likelihood coding and show that itachieves considerable performance in both tasks compared to baseline encodingsoptimized for either localization or mask estimation. In the same setup, wedemonstrate superiority for joint estimation of both quantities. Conclusively,we propose a universal approach which can replace an upstream sound sourcelocalization system solely by adapting the training framework, making it highlyrelevant in performance-critical scenarios.</description><author>Jakob Kienegger, Alina Mannanova, Timo Gerkmann</author><pubDate>Fri, 25 Oct 2024 14:43:32 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.19595v1</guid></item><item><title>Learning Unlabeled Clients Divergence for Federated Semi-Supervised Learning via Anchor Model Aggregation</title><link>http://arxiv.org/abs/2407.10327v2</link><description>Federated semi-supervised learning (FedSemi) refers to scenarios where theremay be clients with fully labeled data, clients with partially labeled, andeven fully unlabeled clients while preserving data privacy. However, challengesarise from client drift due to undefined heterogeneous class distributions anderroneous pseudo-labels. Existing FedSemi methods typically fail to aggregatemodels from unlabeled clients due to their inherent unreliability, thusoverlooking unique information from their heterogeneous data distribution,leading to sub-optimal results. In this paper, we enable unlabeled clientaggregation through SemiAnAgg, a novel Semi-supervised Anchor-Based federatedAggregation. SemiAnAgg learns unlabeled client contributions via an anchormodel, effectively harnessing their informative value. Our key idea is that byfeeding local client data to the same global model and the same consistentlyinitialized anchor model (i.e., random model), we can measure the importance ofeach unlabeled client accordingly. Extensive experiments demonstrate thatSemiAnAgg achieves new state-of-the-art results on four widely used FedSemibenchmarks, leading to substantial performance improvements: a 9% increase inaccuracy on CIFAR-100 and a 7.6% improvement in recall on the medical datasetISIC-18, compared with prior state-of-the-art. Code is available at:https://github.com/xmed-lab/SemiAnAgg.</description><author>Marawan Elbatel, Hualiang Wang, Jixiang Chen, Hao Wang, Xiaomeng Li</author><pubDate>Fri, 25 Oct 2024 14:39:37 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.10327v2</guid></item><item><title>An Optimal Tightness Bound for the Simulation Lemma</title><link>http://arxiv.org/abs/2406.16249v2</link><description>We present a bound for value-prediction error with respect to modelmisspecification that is tight, including constant factors. This is a directimprovement of the "simulation lemma," a foundational result in reinforcementlearning. We demonstrate that existing bounds are quite loose, becoming vacuousfor large discount factors, due to the suboptimal treatment of compoundingprobability errors. By carefully considering this quantity on its own, insteadof as a subcomponent of value error, we derive a bound that is sub-linear withrespect to transition function misspecification. We then demonstrate broaderapplicability of this technique, improving a similar bound in the relatedsubfield of hierarchical abstraction.</description><author>Sam Lobel, Ronald Parr</author><pubDate>Fri, 25 Oct 2024 14:39:04 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.16249v2</guid></item><item><title>GPT vs RETRO: Exploring the Intersection of Retrieval and Parameter-Efficient Fine-Tuning</title><link>http://arxiv.org/abs/2407.04528v4</link><description>Parameter-Efficient Fine-Tuning (PEFT) and Retrieval-Augmented Generation(RAG) have become popular methods for adapting large language models whileminimizing compute requirements. In this paper, we apply PEFT methods(P-tuning, Adapters, and LoRA) to a modified Retrieval-Enhanced Transformer(RETRO) and a baseline GPT model across several sizes, ranging from 823 millionto 48 billion parameters. We show that RETRO models outperform GPT models inzero-shot settings due to their unique pre-training process but GPT models havehigher performance potential with PEFT. Additionally, our study indicates that8B parameter models strike an optimal balance between cost and performance andP-tuning lags behind other PEFT techniques. We further provide a comparativeanalysis between applying PEFT to an Instruction-tuned RETRO model and baseRETRO model. This work presents the first comprehensive comparison of variousPEFT methods integrated with RAG, applied to both GPT and RETRO models,highlighting their relative performance.</description><author>Aleksander Ficek, Jiaqi Zeng, Oleksii Kuchaiev</author><pubDate>Fri, 25 Oct 2024 14:33:23 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.04528v4</guid></item><item><title>MonoDGP: Monocular 3D Object Detection with Decoupled-Query and Geometry-Error Priors</title><link>http://arxiv.org/abs/2410.19590v1</link><description>Perspective projection has been extensively utilized in monocular 3D objectdetection methods. It introduces geometric priors from 2D bounding boxes and 3Dobject dimensions to reduce the uncertainty of depth estimation. However, dueto depth errors originating from the object's visual surface, the height of thebounding box often fails to represent the actual projected central height,which undermines the effectiveness of geometric depth. Direct prediction forthe projected height unavoidably results in a loss of 2D priors, whilemulti-depth prediction with complex branches does not fully leverage geometricdepth. This paper presents a Transformer-based monocular 3D object detectionmethod called MonoDGP, which adopts perspective-invariant geometry errors tomodify the projection formula. We also try to systematically discuss andexplain the mechanisms and efficacy behind geometry errors, which serve as asimple but effective alternative to multi-depth prediction. Additionally,MonoDGP decouples the depth-guided decoder and constructs a 2D decoder onlydependent on visual features, providing 2D priors and initializing objectqueries without the disturbance of 3D detection. To further optimize andfine-tune input tokens of the transformer decoder, we also introduce a RegionSegment Head (RSH) that generates enhanced features and segment embeddings. Ourmonocular method demonstrates state-of-the-art performance on the KITTIbenchmark without extra data. Code is available athttps://github.com/PuFanqi23/MonoDGP.</description><author>Fanqi Pu, Yifan Wang, Jiru Deng, Wenming Yang</author><pubDate>Fri, 25 Oct 2024 14:31:43 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.19590v1</guid></item><item><title>README: Bridging Medical Jargon and Lay Understanding for Patient Education through Data-Centric NLP</title><link>http://arxiv.org/abs/2312.15561v5</link><description>The advancement in healthcare has shifted focus toward patient-centricapproaches, particularly in self-care and patient education, facilitated byaccess to Electronic Health Records (EHR). However, medical jargon in EHRsposes significant challenges in patient comprehension. To address this, weintroduce a new task of automatically generating lay definitions, aiming tosimplify complex medical terms into patient-friendly lay language. We firstcreated the README dataset, an extensive collection of over 50,000 unique(medical term, lay definition) pairs and 300,000 mentions, each offeringcontext-aware lay definitions manually annotated by domain experts. We havealso engineered a data-centric Human-AI pipeline that synergizes datafiltering, augmentation, and selection to improve data quality. We then usedREADME as the training data for models and leveraged a Retrieval-AugmentedGeneration method to reduce hallucinations and improve the quality of modeloutputs. Our extensive automatic and human evaluations demonstrate thatopen-source mobile-friendly models, when fine-tuned with high-quality data, arecapable of matching or even surpassing the performance of state-of-the-artclosed-source large language models like ChatGPT. This research represents asignificant stride in closing the knowledge gap in patient education andadvancing patient-centric healthcare solutions.</description><author>Zonghai Yao, Nandyala Siddharth Kantu, Guanghao Wei, Hieu Tran, Zhangqi Duan, Sunjae Kwon, Zhichao Yang, README annotation team, Hong Yu</author><pubDate>Fri, 25 Oct 2024 14:30:28 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.15561v5</guid></item><item><title>Diverse Sign Language Translation</title><link>http://arxiv.org/abs/2410.19586v1</link><description>Like spoken languages, a single sign language expression could correspond tomultiple valid textual interpretations. Hence, learning a rigid one-to-onemapping for sign language translation (SLT) models might be inadequate,particularly in the case of limited data. In this work, we introduce a DiverseSign Language Translation (DivSLT) task, aiming to generate diverse yetaccurate translations for sign language videos. Firstly, we employ largelanguage models (LLM) to generate multiple references for the widely-usedCSL-Daily and PHOENIX14T SLT datasets. Here, native speakers are only invitedto touch up inaccurate references, thus significantly improving the annotationefficiency. Secondly, we provide a benchmark model to spur research in thistask. Specifically, we investigate multi-reference training strategies toenable our DivSLT model to achieve diverse translations. Then, to enhancetranslation accuracy, we employ the max-reward-driven reinforcement learningobjective that maximizes the reward of the translated result. Additionally, weutilize multiple metrics to assess the accuracy, diversity, and semanticprecision of the DivSLT task. Experimental results on the enriched datasetsdemonstrate that our DivSLT method achieves not only better translationperformance but also diverse translation results.</description><author>Xin Shen, Lei Shen, Shaozu Yuan, Heming Du, Haiyang Sun, Xin Yu</author><pubDate>Fri, 25 Oct 2024 14:28:20 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.19586v1</guid></item><item><title>Human-like Episodic Memory for Infinite Context LLMs</title><link>http://arxiv.org/abs/2407.09450v2</link><description>Large language models (LLMs) have shown remarkable capabilities, but stillstruggle with processing extensive contexts, limiting their ability to maintaincoherence and accuracy over long sequences. In contrast, the human brain excelsat organising and retrieving episodic experiences across vast temporal scales,spanning a lifetime. In this work, we introduce EM-LLM, a novel approach thatintegrates key aspects of human episodic memory and event cognition into LLMswith no fine-tuning, enabling them to handle practically infinite contextlengths while maintaining computational efficiency. EM-LLM organises sequencesof tokens into coherent episodic events using a combination of Bayesiansurprise and graph-theoretic boundary refinement in an online fashion. Whenneeded, these events are retrieved through a two-stage memory process,combining similarity-based and temporally contiguous retrieval for efficientand human-like access to relevant information. Experiments on the LongBench andInfiniteBench benchmarks demonstrate EM-LLM's superior performance,consistently outperforming the state-of-the-art retrieval model InfLLM acrossvarious baseline LLMs. In addition, EM-LLM outperforms its popular counterpart,RAG, in a wide range of tasks, while requiring similar resources. Notably,EM-LLM's performance even surpasses full-context models in most tasks, whilesuccessfully performing retrieval across 10 million tokens - a scalecomputationally infeasible for such models. Finally, our analysis revealsstrong correlations between EM-LLM's event segmentation and human-perceivedevents, suggesting a bridge between this artificial system and its biologicalcounterpart, thereby offering a novel computational framework for exploringhuman memory mechanisms.</description><author>Zafeirios Fountas, Martin A Benfeghoul, Adnan Oomerjee, Fenia Christopoulou, Gerasimos Lampouras, Haitham Bou-Ammar, Jun Wang</author><pubDate>Fri, 25 Oct 2024 14:27:23 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.09450v2</guid></item><item><title>AutoRD: An Automatic and End-to-End System for Rare Disease Knowledge Graph Construction Based on Ontologies-enhanced Large Language Models</title><link>http://arxiv.org/abs/2403.00953v4</link><description>Rare diseases affect millions worldwide but often face limited research focusdue to their low prevalence. This results in prolonged diagnoses and a lack ofapproved therapies. Recent advancements in Large Language Models (LLMs) haveshown promise in automating the extraction of medical information, offeringpotential to improve medical diagnosis and management. However, most LLMs lackprofessional medical knowledge, especially concerning rare diseases, andstruggle to handle the latest rare disease information. They also cannoteffectively manage rare disease data and are not directly suitable fordiagnosis and management tasks. Our objective is to create an end-to-end systemcalled AutoRD, which automates the extraction of information from medical textsabout rare diseases, focusing on entities and their relations. AutoRDintegrates up-to-date structured knowledge and demonstrates superiorperformance in rare disease extraction tasks. We conduct various experiments toevaluate AutoRD's performance, aiming to surpass common LLMs and traditionalmethods.</description><author>Lang Cao, Jimeng Sun, Adam Cross</author><pubDate>Fri, 25 Oct 2024 14:20:32 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.00953v4</guid></item><item><title>Hybrid Memetic Search for Electric Vehicle Routing with Time Windows, Simultaneous Pickup-Delivery, and Partial Recharges</title><link>http://arxiv.org/abs/2410.19580v1</link><description>With growing environmental concerns, electric vehicles for logistics havegained significant attention within the computational intelligence community inrecent years. This work addresses an emerging and significant extension of theelectric vehicle routing problem (EVRP), namely EVRP with time windows,simultaneous pickup-delivery, and partial recharges (EVRP-TW-SPD), which haswide real-world applications. We propose a hybrid memetic algorithm (HMA) forsolving EVRP-TW-SPD. HMA incorporates two novel components: aparallel-sequential station insertion procedure for handling partial rechargesthat can better avoid local optima compared to purely sequential insertion, anda cross-domain neighborhood search that explores solution spaces of bothelectric and non-electric problem domains simultaneously. These components canalso be easily applied to various EVRP variants. To bridge the gap betweenexisting benchmarks and real-world scenarios, we introduce a new, large-scaleEVRP-TW-SPD benchmark set derived from real-world applications, containinginstances with many more customers and charging stations than existingbenchmark instances. Extensive experiments demonstrate the significantperformance advantages of HMA over existing algorithms across a wide range ofproblem instances. Both the benchmark set and HMA will be open-sourced tofacilitate further research in this area.</description><author>Zubin Zheng, Shengcai Liu, Yew-Soon Ong</author><pubDate>Fri, 25 Oct 2024 14:18:24 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.19580v1</guid></item><item><title>Steering Knowledge Selection Behaviours in LLMs via SAE-Based Representation Engineering</title><link>http://arxiv.org/abs/2410.15999v2</link><description>Large language models (LLMs) can store a significant amount of factualknowledge in their parameters. However, their parametric knowledge may conflictwith the information provided in the context -- this phenomenon, known as\emph{context-memory knowledge conflicts}, can lead to undesirable modelbehaviour, such as reliance on outdated or incorrect information. Analysing theinternal activations of LLMs, we find that they can internally register thesignals of knowledge conflict at mid-layers. Such signals allow us to detectwhether a knowledge conflict occurs and use \emph{inference-time} interventionstrategies to resolve it. In this work, we propose \textsc{SpARE}, a\emph{training-free} representation engineering method that uses pre-trainedsparse auto-encoders (SAEs) to control the knowledge selection behaviour ofLLMs. \textsc{SpARE} identifies the functional features that control theknowledge selection behaviours and applies them to edit the internalactivations of LLMs at inference time. Our experimental results show that\textsc{SpARE} can effectively control the usage of either knowledge source toresolve knowledge conflict in open-domain question-answering tasks, surpassingexisting representation engineering methods ($+10\%$) as well as contrastivedecoding methods ($+15\%$).</description><author>Yu Zhao, Alessio Devoto, Giwon Hong, Xiaotang Du, Aryo Pradipta Gema, Hongru Wang, Xuanli He, Kam-Fai Wong, Pasquale Minervini</author><pubDate>Fri, 25 Oct 2024 14:17:28 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.15999v2</guid></item><item><title>What Variables Affect Out-of-Distribution Generalization in Pretrained Models?</title><link>http://arxiv.org/abs/2405.15018v3</link><description>Embeddings produced by pre-trained deep neural networks (DNNs) are widelyused; however, their efficacy for downstream tasks can vary widely. We studythe factors influencing transferability and out-of-distribution (OOD)generalization of pre-trained DNN embeddings through the lens of the tunneleffect hypothesis, which is closely related to intermediate neural collapse.This hypothesis suggests that deeper DNN layers compress representations andhinder OOD generalization. Contrary to earlier work, our experiments show thisis not a universal phenomenon. We comprehensively investigate the impact of DNNarchitecture, training data, image resolution, and augmentations ontransferability. We identify that training with high-resolution datasetscontaining many classes greatly reduces representation compression and improvestransferability. Our results emphasize the danger of generalizing findings fromtoy datasets to broader contexts.</description><author>Md Yousuf Harun, Kyungbok Lee, Jhair Gallardo, Giri Krishnan, Christopher Kanan</author><pubDate>Fri, 25 Oct 2024 14:14:39 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.15018v3</guid></item><item><title>Adaptive High-Frequency Transformer for Diverse Wildlife Re-Identification</title><link>http://arxiv.org/abs/2410.06977v2</link><description>Wildlife ReID involves utilizing visual technology to identify specificindividuals of wild animals in different scenarios, holding significantimportance for wildlife conservation, ecological research, and environmentalmonitoring. Existing wildlife ReID methods are predominantly tailored tospecific species, exhibiting limited applicability. Although some approachesleverage extensively studied person ReID techniques, they struggle to addressthe unique challenges posed by wildlife. Therefore, in this paper, we present aunified, multi-species general framework for wildlife ReID. Given thathigh-frequency information is a consistent representation of unique features invarious species, significantly aiding in identifying contours and details suchas fur textures, we propose the Adaptive High-Frequency Transformer model withthe goal of enhancing high-frequency information learning. To mitigate theinevitable high-frequency interference in the wilderness environment, weintroduce an object-aware high-frequency selection strategy to adaptivelycapture more valuable high-frequency components. Notably, we unify theexperimental settings of multiple wildlife datasets for ReID, achievingsuperior performance over state-of-the-art ReID methods. In domaingeneralization scenarios, our approach demonstrates robust generalization tounknown species.</description><author>Chenyue Li, Shuoyi Chen, Mang Ye</author><pubDate>Fri, 25 Oct 2024 14:13:28 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.06977v2</guid></item><item><title>Considerations for Distribution Shift Robustness of Diagnostic Models in Healthcare</title><link>http://arxiv.org/abs/2410.19575v1</link><description>We consider robustness to distribution shifts in the context of diagnosticmodels in healthcare, where the prediction target $Y$, e.g., the presence of adisease, is causally upstream of the observations $X$, e.g., a biomarker.Distribution shifts may occur, for instance, when the training data iscollected in a domain with patients having particular demographiccharacteristics while the model is deployed on patients from a differentdemographic group. In the domain of applied ML for health, it is common topredict $Y$ from $X$ without considering further information about the patient.However, beyond the direct influence of the disease $Y$ on biomarker $X$, apredictive model may learn to exploit confounding dependencies (or shortcuts)between $X$ and $Y$ that are unstable under certain distribution shifts. Inthis work, we highlight a data generating mechanism common to healthcaresettings and discuss how recent theoretical results from the causalityliterature can be applied to build robust predictive models. We theoreticallyshow why ignoring covariates as well as common invariant learning approacheswill in general not yield robust predictors in the studied setting, whileincluding certain covariates into the prediction model will. In an extensivesimulation study, we showcase the robustness (or lack thereof) of differentpredictors under various data generating processes. Lastly, we analyze theperformance of the different approaches using the PTB-XL dataset, a publicdataset of annotated ECG recordings.</description><author>Arno Blaas, Adam Goliński, Andrew Miller, Luca Zappella, Jörn-Henrik Jacobsen, Christina Heinze-Deml</author><pubDate>Fri, 25 Oct 2024 14:13:09 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.19575v1</guid></item><item><title>DistRL: An Asynchronous Distributed Reinforcement Learning Framework for On-Device Control Agents</title><link>http://arxiv.org/abs/2410.14803v2</link><description>On-device control agents, especially on mobile devices, are responsible foroperating mobile devices to fulfill users' requests, enabling seamless andintuitive interactions. Integrating Multimodal Large Language Models (MLLMs)into these agents enhances their ability to understand and execute complexcommands, thereby improving user experience. However, fine-tuning MLLMs foron-device control presents significant challenges due to limited dataavailability and inefficient online training processes. This paper introducesDistRL, a novel framework designed to enhance the efficiency of online RLfine-tuning for mobile device control agents. DistRL employs centralizedtraining and decentralized data acquisition to ensure efficient fine-tuning inthe context of dynamic online interactions. Additionally, the framework isbacked by our tailor-made RL algorithm, which effectively balances explorationwith the prioritized utilization of collected data to ensure stable and robusttraining. Our experiments show that, on average, DistRL delivers a 3Ximprovement in training efficiency and enables training data collection 2.4Xfaster than the leading synchronous multi-machine methods. Notably, aftertraining, DistRL achieves a 20% relative improvement in success rate comparedto state-of-the-art methods on general Android tasks from an open benchmark,significantly outperforming existing approaches while maintaining the sametraining time. These results validate DistRL as a scalable and efficientsolution, offering substantial improvements in both training efficiency andagent performance for real-world, in-the-wild device control tasks.</description><author>Taiyi Wang, Zhihao Wu, Jianheng Liu, Jianye Hao, Jun Wang, Kun Shao</author><pubDate>Fri, 25 Oct 2024 14:12:11 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.14803v2</guid></item><item><title>FastPCI: Motion-Structure Guided Fast Point Cloud Frame Interpolation</title><link>http://arxiv.org/abs/2410.19573v1</link><description>Point cloud frame interpolation is a challenging task that involves accuratescene flow estimation across frames and maintaining the geometry structure.Prevailing techniques often rely on pre-trained motion estimators or intensivetesting-time optimization, resulting in compromised interpolation accuracy orprolonged inference. This work presents FastPCI that introduces PyramidConvolution-Transformer architecture for point cloud frame interpolation. Ourhybrid Convolution-Transformer improves the local and long-range featurelearning, while the pyramid network offers multilevel features and reduces thecomputation. In addition, FastPCI proposes a unique Dual-DirectionMotion-Structure block for more accurate scene flow estimation. Our design ismotivated by two facts: (1) accurate scene flow preserves 3D structure, and (2)point cloud at the previous timestep should be reconstructable using reversemotion from future timestep. Extensive experiments show that FastPCIsignificantly outperforms the state-of-the-art PointINet and NeuralPCI withnotable gains (e.g. 26.6% and 18.3% reduction in Chamfer Distance in KITTI),while being more than 10x and 600x faster, respectively. Code is available athttps://github.com/genuszty/FastPCI</description><author>Tianyu Zhang, Guocheng Qian, Jin Xie, Jian Yang</author><pubDate>Fri, 25 Oct 2024 14:10:17 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.19573v1</guid></item><item><title>ChunkRAG: Novel LLM-Chunk Filtering Method for RAG Systems</title><link>http://arxiv.org/abs/2410.19572v1</link><description>Retrieval-Augmented Generation (RAG) systems using large language models(LLMs) often generate inaccurate responses due to the retrieval of irrelevantor loosely related information. Existing methods, which operate at the documentlevel, fail to effectively filter out such content. We propose LLM-driven chunkfiltering, ChunkRAG, a framework that enhances RAG systems by evaluating andfiltering retrieved information at the chunk level. Our approach employssemantic chunking to divide documents into coherent sections and utilizesLLM-based relevance scoring to assess each chunk's alignment with the user'squery. By filtering out less pertinent chunks before the generation phase, wesignificantly reduce hallucinations and improve factual accuracy. Experimentsshow that our method outperforms existing RAG models, achieving higher accuracyon tasks requiring precise information retrieval. This advancement enhances thereliability of RAG systems, making them particularly beneficial forapplications like fact-checking and multi-hop reasoning.</description><author>Ritvik Aggarwal Ishneet Sukhvinder Singh Ibrahim Allahverdiyev, Muhammad Taha, Aslihan Akalin, Kevin Zhu</author><pubDate>Fri, 25 Oct 2024 14:07:53 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.19572v1</guid></item><item><title>Prediction of microstructural representativity from a single image</title><link>http://arxiv.org/abs/2410.19568v1</link><description>In this study, we present a method for predicting the representativity of thephase fraction observed in a single image (2D or 3D) of a material. Traditionalapproaches often require large datasets and extensive statistical analysis toestimate the Integral Range, a key factor in determining the variance ofmicrostructural properties. Our method leverages the Two-Point Correlationfunction to directly estimate the variance from a single image (2D or 3D),thereby enabling phase fraction prediction with associated confidence levels.We validate our approach using open-source datasets, demonstrating its efficacyacross diverse microstructures. This technique significantly reduces the datarequirements for representativity analysis, providing a practical tool formaterial scientists and engineers working with limited microstructural data. Tomake the method easily accessible, we have created a web-application,\url{www.imagerep.io}, for quick, simple and informative use of the method.</description><author>Amir Dahari, Ronan Docherty, Steve Kench, Samuel J. Cooper</author><pubDate>Fri, 25 Oct 2024 13:59:22 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.19568v1</guid></item><item><title>How Critical is Site-Specific RAN Optimization? 5G Open-RAN Uplink Air Interface Performance Test and Optimization from Macro-Cell CIR Data</title><link>http://arxiv.org/abs/2410.19565v1</link><description>In this paper, we consider the importance of channel measurement data fromspecific sites and its impact on air interface optimization and test.Currently, a range of statistical channel models including 3GPP 38.901 tappeddelay line (TDL), clustered delay line (CDL), urban microcells (UMi) and urbanmacrocells (UMa) type channels are widely used for air interface performancetesting and simulation. However, there remains a gap in the realism of thesemodels for air interface testing and optimization when compared with real worldmeasurement based channels. To address this gap, we compare the performanceimpacts of training neural receivers with 1) statistical 3GPP TDL models, and2) measured macro-cell channel impulse response (CIR) data. We leverage ourOmniPHY-5G neural receiver for NR PUSCH uplink simulation, with a trainingprocedure that uses statistical TDL channel models for pre-training, andfine-tuning based on measured site specific MIMO CIR data. The proposedfine-tuning method achieves a 10% block error rate (BLER) at a 1.85 dB lowersignal-to-noise ratio (SNR) compared to pre-training only on simulated TDLchannels, illustrating a rough magnitude of the gap that can be closed bysite-specific training, and gives the first answer to the question "how muchcan fine-tuning the RAN for site-specific channels help?"</description><author>Johnathan Corgan, Nitin Nair, Rajib Bhattacharjea, Wan Liu, Serhat Tadik, Tom Tsou, Timothy J. O'Shea</author><pubDate>Fri, 25 Oct 2024 13:57:48 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.19565v1</guid></item><item><title>Skews in the Phenomenon Space Hinder Generalization in Text-to-Image Generation</title><link>http://arxiv.org/abs/2403.16394v2</link><description>The literature on text-to-image generation is plagued by issues of faithfullycomposing entities with relations. But there lacks a formal understanding ofhow entity-relation compositions can be effectively learned. Moreover, theunderlying phenomenon space that meaningfully reflects the problem structure isnot well-defined, leading to an arms race for larger quantities of data in thehope that generalization emerges out of large-scale pretraining. We hypothesizethat the underlying phenomenological coverage has not been proportionallyscaled up, leading to a skew of the presented phenomenon which harmsgeneralization. We introduce statistical metrics that quantify both thelinguistic and visual skew of a dataset for relational learning, and show thatgeneralization failures of text-to-image generation are a direct result ofincomplete or unbalanced phenomenological coverage. We first performexperiments in a synthetic domain and demonstrate that systematicallycontrolled metrics are strongly predictive of generalization performance. Thenwe move to natural images and show that simple distribution perturbations inlight of our theories boost generalization without enlarging the absolute datasize. This work informs an important direction towards quality-enhancing thedata diversity or balance orthogonal to scaling up the absolute size. Ourdiscussions point out important open questions on 1) Evaluation of generatedentity-relation compositions, and 2) Better models for reasoning with abstractrelations.</description><author>Yingshan Chang, Yasi Zhang, Zhiyuan Fang, Yingnian Wu, Yonatan Bisk, Feng Gao</author><pubDate>Fri, 25 Oct 2024 13:56:36 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.16394v2</guid></item><item><title>Neuromorphic IoT Architecture for Efficient Water Management: A Smart Village Case Study</title><link>http://arxiv.org/abs/2410.19562v1</link><description>The exponential growth of IoT networks necessitates a paradigm shift towardsarchitectures that offer high flexibility and learning capabilities whilemaintaining low energy consumption, minimal communication overhead, and lowlatency. Traditional IoT systems, particularly when integrated with machinelearning approaches, often suffer from high communication overhead andsignificant energy consumption. This work addresses these challenges byproposing a neuromorphic architecture inspired by biological systems. Toillustrate the practical application of our proposed architecture, we present acase study focusing on water management in the Carinthian community of Neuhaus.Preliminary results regarding water consumption prediction and anomalydetection in this community are presented. We also introduce a novelneuromorphic IoT architecture that integrates biological principles into thedesign of IoT systems. This architecture is specifically tailored for edgecomputing scenarios, where low power and high efficiency are crucial. Ourapproach leverages the inherent advantages of neuromorphic computing, such asasynchronous processing and event-driven communication, to create an IoTframework that is both energy-efficient and responsive. This case studydemonstrates how the neuromorphic IoT architecture can be deployed in areal-world scenario, highlighting its benefits in terms of energy savings,reduced communication overhead, and improved system responsiveness.</description><author>Mugdim Bublin, Heimo Hirner, Antoine-Martin Lanners, Radu Grosu</author><pubDate>Fri, 25 Oct 2024 13:51:34 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.19562v1</guid></item><item><title>Connecting Joint-Embedding Predictive Architecture with Contrastive Self-supervised Learning</title><link>http://arxiv.org/abs/2410.19560v1</link><description>In recent advancements in unsupervised visual representation learning, theJoint-Embedding Predictive Architecture (JEPA) has emerged as a significantmethod for extracting visual features from unlabeled imagery through aninnovative masking strategy. Despite its success, two primary limitations havebeen identified: the inefficacy of Exponential Moving Average (EMA) from I-JEPAin preventing entire collapse and the inadequacy of I-JEPA prediction inaccurately learning the mean of patch representations. Addressing thesechallenges, this study introduces a novel framework, namely C-JEPA(Contrastive-JEPA), which integrates the Image-based Joint-Embedding PredictiveArchitecture with the Variance-Invariance-Covariance Regularization (VICReg)strategy. This integration is designed to effectively learn thevariance/covariance for preventing entire collapse and ensuring invariance inthe mean of augmented views, thereby overcoming the identified limitations.Through empirical and theoretical evaluations, our work demonstrates thatC-JEPA significantly enhances the stability and quality of visualrepresentation learning. When pre-trained on the ImageNet-1K dataset, C-JEPAexhibits rapid and improved convergence in both linear probing and fine-tuningperformance metrics.</description><author>Shentong Mo, Shengbang Tong</author><pubDate>Fri, 25 Oct 2024 13:48:12 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.19560v1</guid></item><item><title>Not (yet) the whole story: Evaluating Visual Storytelling Requires More than Measuring Coherence, Grounding, and Repetition</title><link>http://arxiv.org/abs/2407.04559v4</link><description>Visual storytelling consists in generating a natural language story given atemporally ordered sequence of images. This task is not only challenging formodels, but also very difficult to evaluate with automatic metrics since thereis no consensus about what makes a story 'good'. In this paper, we introduce anovel method that measures story quality in terms of human likeness regardingthree key aspects highlighted in previous work: visual grounding, coherence,and repetitiveness. We then use this method to evaluate the stories generatedby several models, showing that the foundation model LLaVA obtains the bestresult, but only slightly so compared to TAPM, a 50-times smaller visualstorytelling model. Upgrading the visual and language components of TAPMresults in a model that yields competitive performance with a relatively lownumber of parameters. Finally, we carry out a human evaluation study, whoseresults suggest that a 'good' story may require more than a human-like level ofvisual grounding, coherence, and repetition.</description><author>Aditya K Surikuchi, Raquel Fernández, Sandro Pezzelle</author><pubDate>Fri, 25 Oct 2024 13:47:11 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.04559v4</guid></item></channel></rss>