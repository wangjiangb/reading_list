<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/"><channel><title>Arxivfresh papers</title><link></link><description>Arxiv paper</description><language>en-US</language><lastBuildDate>Wed, 29 Jan 2025 01:00:21 GMT</lastBuildDate><generator>rfeed v1.0.0</generator><docs>https://github.com/svpino/rfeed/blob/master/README.md</docs><item><title>RelightVid: Temporal-Consistent Diffusion Model for Video Relighting</title><link>http://arxiv.org/abs/2501.16330v1</link><description>Diffusion models have demonstrated remarkable success in image generation andediting, with recent advancements enabling albedo-preserving image relighting.However, applying these models to video relighting remains challenging due tothe lack of paired video relighting datasets and the high demands for outputfidelity and temporal consistency, further complicated by the inherentrandomness of diffusion models. To address these challenges, we introduceRelightVid, a flexible framework for video relighting that can acceptbackground video, text prompts, or environment maps as relighting conditions.Trained on in-the-wild videos with carefully designed illuminationaugmentations and rendered videos under extreme dynamic lighting, RelightVidachieves arbitrary video relighting with high temporal consistency withoutintrinsic decomposition while preserving the illumination priors of its imagebackbone.</description><author>Ye Fang, Zeyi Sun, Shangzhan Zhang, Tong Wu, Yinghao Xu, Pan Zhang, Jiaqi Wang, Gordon Wetzstein, Dahua Lin</author><pubDate>Mon, 27 Jan 2025 18:59:57 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.16330v1</guid></item><item><title>sDREAMER: Self-distilled Mixture-of-Modality-Experts Transformer for Automatic Sleep Staging</title><link>http://arxiv.org/abs/2501.16329v1</link><description>Automatic sleep staging based on electroencephalography (EEG) andelectromyography (EMG) signals is an important aspect of sleep-relatedresearch. Current sleep staging methods suffer from two major drawbacks. First,there are limited information interactions between modalities in the existingmethods. Second, current methods do not develop unified models that can handledifferent sources of input. To address these issues, we propose a novel sleepstage scoring model sDREAMER, which emphasizes cross-modality interaction andper-channel performance. Specifically, we develop a mixture-of-modality-expert(MoME) model with three pathways for EEG, EMG, and mixed signals with partiallyshared weights. We further propose a self-distillation training scheme forfurther information interaction across modalities. Our model is trained withmulti-channel inputs and can make classifications on either single-channel ormulti-channel inputs. Experiments demonstrate that our model outperforms theexisting transformer-based sleep scoring methods for multi-channel inference.For single-channel inference, our model also outperforms the transformer-basedmodels trained with single-channel signals.</description><author>Jingyuan Chen, Yuan Yao, Mie Anderson, Natalie Hauglund, Celia Kjaerby, Verena Untiet, Maiken Nedergaard, Jiebo Luo</author><pubDate>Mon, 27 Jan 2025 18:59:55 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.16329v1</guid></item><item><title>LUCY: Linguistic Understanding and Control Yielding Early Stage of Her</title><link>http://arxiv.org/abs/2501.16327v1</link><description>The film Her features Samantha, a sophisticated AI audio agent who is capableof understanding both linguistic and paralinguistic information in human speechand delivering real-time responses that are natural, informative and sensitiveto emotional subtleties. Moving one step toward more sophisticated audio agentfrom recent advancement in end-to-end (E2E) speech systems, we propose LUCY, aE2E speech model that (1) senses and responds to user's emotion, (2) deliverresponses in a succinct and natural style, and (3) use external tool to answerreal-time inquiries. Experiment results show that LUCY is better at emotioncontrol than peer models, generating emotional responses based on linguisticemotional instructions and responding to paralinguistic emotional cues. Lucy isalso able to generate responses in a more natural style, as judged by externallanguage models, without sacrificing much performance on general questionanswering. Finally, LUCY can leverage function calls to answer questions thatare out of its knowledge scope.</description><author>Heting Gao, Hang Shao, Xiong Wang, Chaofan Qiu, Yunhang Shen, Siqi Cai, Yuchen Shi, Zihan Xu, Zuwei Long, Yike Zhang, Shaoqi Dong, Chaoyou Fu, Ke Li, Long Ma, Xing Sun</author><pubDate>Mon, 27 Jan 2025 18:59:51 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.16327v1</guid></item><item><title>GUI-Bee: Align GUI Action Grounding to Novel Environments via Autonomous Exploration</title><link>http://arxiv.org/abs/2501.13896v2</link><description>Graphical User Interface (GUI) action grounding is a critical step in GUIautomation that maps language instructions to actionable elements on GUIscreens. Most recent works of GUI action grounding leverage large GUI datasetsto fine-tune MLLMs. However, the fine-tuning data always covers limited GUIenvironments, and we find the performance of the resulting model deterioratesin novel environments. We argue that the GUI grounding models should be furtheraligned to the novel environments to reveal their full potential, when theinference is known to involve novel environments, i.e., environments not usedduring the previous fine-tuning. To realize this, we first propose GUI-Bee, anMLLM-based autonomous agent, to collect high-quality, environment-specific datathrough exploration and then continuously fine-tune GUI grounding models withthe collected data. Our agent leverages a novel Q-value-Incentive In-ContextReinforcement Learning (Q-ICRL) method to optimize exploration efficiency anddata quality. Additionally, we introduce NovelScreenSpot, a benchmark fortesting how well the data can help align GUI action grounding models to novelenvironments and demonstrate the effectiveness of data collected by GUI-Bee inthe experiments. Furthermore, we conduct an ablation study to validate theQ-ICRL method in enhancing the efficiency of GUI-Bee. Project page:https://gui-bee.github.io</description><author>Yue Fan, Handong Zhao, Ruiyi Zhang, Yu Shen, Xin Eric Wang, Gang Wu</author><pubDate>Mon, 27 Jan 2025 18:58:42 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.13896v2</guid></item><item><title>Tailored Forecasting from Short Time Series via Meta-learning</title><link>http://arxiv.org/abs/2501.16325v1</link><description>Machine learning (ML) models can be effective for forecasting the dynamics ofunknown systems from time-series data, but they often require large amounts ofdata and struggle to generalize across systems with varying dynamics. Combined,these issues make forecasting from short time series particularly challenging.To address this problem, we introduce Meta-learning for Tailored Forecastingfrom Related Time Series (METAFORS), which uses related systems with longertime-series data to supplement limited data from the system of interest. Byleveraging a library of models trained on related systems, METAFORS buildstailored models to forecast system evolution with limited data. Using areservoir computing implementation and testing on simulated chaotic systems, wedemonstrate METAFORS' ability to predict both short-term dynamics and long-termstatistics, even when test and related systems exhibit significantly differentbehaviors and the available data are scarce, highlighting its robustness andversatility in data-limited scenarios.</description><author>Declan A. Norton, Edward Ott, Andrew Pomerance, Brian Hunt, Michelle Girvan</author><pubDate>Mon, 27 Jan 2025 18:58:04 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.16325v1</guid></item><item><title>Implicit Bias in Matrix Factorization and its Explicit Realization in a New Architecture</title><link>http://arxiv.org/abs/2501.16322v1</link><description>Gradient descent for matrix factorization is known to exhibit an implicitbias toward approximately low-rank solutions. While existing theories oftenassume the boundedness of iterates, empirically the bias persists even withunbounded sequences. We thus hypothesize that implicit bias is driven bydivergent dynamics markedly different from the convergent dynamics for datafitting. Using this perspective, we introduce a new factorization model:$X\approx UDV^\top$, where $U$ and $V$ are constrained within norm balls, while$D$ is a diagonal factor allowing the model to span the entire search space.Our experiments reveal that this model exhibits a strong implicit biasregardless of initialization and step size, yielding truly (rather thanapproximately) low-rank solutions. Furthermore, drawing parallels betweenmatrix factorization and neural networks, we propose a novel neural networkmodel featuring constrained layers and diagonal components. This model achievesstrong performance across various regression and classification tasks whilefinding low-rank solutions, resulting in efficient and lightweight networks.</description><author>Yikun Hou, Suvrit Sra, Alp Yurtsever</author><pubDate>Mon, 27 Jan 2025 18:56:22 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.16322v1</guid></item><item><title>Adaptive Iterative Compression for High-Resolution Files: an Approach Focused on Preserving Visual Quality in Cinematic Workflows</title><link>http://arxiv.org/abs/2501.16319v1</link><description>This study presents an iterative adaptive compression model forhigh-resolution DPX-derived TIFF files used in cinematographic workflows anddigital preservation. The model employs SSIM and PSNR metrics to dynamicallyadjust compression parameters across three configurations (C0, C1, C2),achieving storage reductions up to 83.4 % while maintaining high visualfidelity (SSIM &gt; 0.95). Validation across three diverse productions - black andwhite classic, soft-palette drama, and complex action film - demonstrated themethod's effectiveness in preserving critical visual elements whilesignificantly reducing storage requirements. Professional evaluators reported90% acceptance rate for the optimal C1 configuration, with artifacts remainingbelow perceptual threshold in critical areas. Comparative analysis withJPEG2000 and H.265 showed superior quality preservation at equivalentcompression rates, particularly for high bit-depth content. While requiringadditional computational overhead, the method's storage benefits and qualitycontrol capabilities make it suitable for professional workflows, withpotential applications in medical imaging and cloud storage optimization.</description><author>Leonardo Melo, Filipe Litaiff</author><pubDate>Mon, 27 Jan 2025 18:55:21 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.16319v1</guid></item><item><title>Path Analysis for Effective Fault Localization in Deep Neural Networks</title><link>http://arxiv.org/abs/2310.18987v4</link><description>Deep learning has revolutionized numerous fields, yet the reliability of DeepNeural Networks (DNNs) remains a concern due to their complexity and datadependency. Traditional software fault localization methods, such asSpectrum-based Fault Localization (SBFL), have been adapted for DNNs but oftenfall short in effectiveness. These methods typically overlook the propagationof faults through neural pathways, resulting in less precise fault detection.Research indicates that examining neural pathways, rather than individualneurons, is crucial because issues in one neuron can affect its entire pathway.By investigating these interconnected pathways, we can better identify andaddress problems arising from the collective activity of neurons. To addressthis limitation, we introduce the NP-SBFL method, which leverages Layer-wiseRelevance Propagation (LRP) to identify essential faulty neural pathways. Ourmethod explores multiple fault sources to accurately pinpoint faulty neurons byanalyzing their interconnections. Additionally, our multi-stage gradient ascent(MGA) technique, an extension of gradient ascent (GA), enables sequentialneuron activation to enhance fault detection. We evaluated NP-SBFL-MGA on thewell-established MNIST and CIFAR-10 datasets, comparing it to other methodslike DeepFault and NP-SBFL-GA, as well as three neuron measures: Tarantula,Ochiai, and Barinel. Our evaluation utilized all training and test samples(60,000 for MNIST and 50,000 for CIFAR-10) and revealed that NP-SBFL-MGAsignificantly outperformed the baselines in identifying suspicious pathways andgenerating adversarial inputs. Notably, Tarantula with NP-SBFL-MGA achieved aremarkable 96.75% fault detection rate compared to DeepFault's 89.90%.NP-SBFL-MGA highlights a strong correlation between critical path coverage andthe number of failed tests in DNN fault localization.</description><author>Soroush Hashemifar, Saeed Parsa, Akram Kalaee</author><pubDate>Mon, 27 Jan 2025 18:54:54 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.18987v4</guid></item><item><title>DynaGRAG | Exploring the Topology of Information for Advancing Language Understanding and Generation in Graph Retrieval-Augmented Generation</title><link>http://arxiv.org/abs/2412.18644v2</link><description>Graph Retrieval-Augmented Generation (GRAG or Graph RAG) architectures aim toenhance language understanding and generation by leveraging external knowledge.However, effectively capturing and integrating the rich semantic informationpresent in textual and structured data remains a challenge. To address this, anovel GRAG framework, Dynamic Graph Retrieval-Agumented Generation (DynaGRAG),is proposed to focus on enhancing subgraph representation and diversity withinthe knowledge graph. By improving graph density, capturing entity and relationinformation more effectively, and dynamically prioritizing relevant and diversesubgraphs and information within them, the proposed approach enables a morecomprehensive understanding of the underlying semantic structure. This isachieved through a combination of de-duplication processes, two-step meanpooling of embeddings, query-aware retrieval considering unique nodes, and aDynamic Similarity-Aware BFS (DSA-BFS) traversal algorithm. Integrating GraphConvolutional Networks (GCNs) and Large Language Models (LLMs) through hardprompting further enhances the learning of rich node and edge representationswhile preserving the hierarchical subgraph structure. Experimental resultsdemonstrate the effectiveness of DynaGRAG, showcasing the significance ofenhanced subgraph representation and diversity for improved languageunderstanding and generation.</description><author>Karishma Thakrar</author><pubDate>Mon, 27 Jan 2025 18:54:42 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.18644v2</guid></item><item><title>λ: A Benchmark for Data-Efficiency in Long-Horizon Indoor Mobile Manipulation Robotics</title><link>http://arxiv.org/abs/2412.05313v4</link><description>Efficiently learning and executing long-horizon mobile manipulation (MoMa)tasks is crucial for advancing robotics in household and workplace settings.However, current MoMa models are data-inefficient, underscoring the need forimproved models that require realistic-sized benchmarks to evaluate theirefficiency, which do not exist. To address this, we introduce the LAMBDA({\lambda}) benchmark (Long-horizon Actions for Mobile-manipulationBenchmarking of Directed Activities), which evaluates the data efficiency ofmodels on language-conditioned, long-horizon, multi-room, multi-floor,pick-and-place tasks using a dataset of manageable size, more feasible forcollection. The benchmark includes 571 human-collected demonstrations thatprovide realism and diversity in simulated and real-world settings. Unlikeplanner-generated data, these trajectories offer natural variability andreplay-verifiability, ensuring robust learning and evaluation. We benchmarkseveral models, including learning-based models and a neuro-symbolic modularapproach combining foundation models with task and motion planning.Learning-based models show suboptimal success rates, even when leveragingpretrained weights, underscoring significant data inefficiencies. However, theneuro-symbolic approach performs significantly better while being more dataefficient. Findings highlight the need for more data-efficient learning-basedMoMa approaches. {\lambda} addresses this gap by serving as a key benchmark forevaluating the data efficiency of those future models in handling householdrobotics tasks.</description><author>Ahmed Jaafar, Shreyas Sundara Raman, Yichen Wei, Sudarshan Harithas, Sofia Juliani, Anneke Wernerfelt, Benedict Quartey, Ifrah Idrees, Jason Xinyu Liu, Stefanie Tellex</author><pubDate>Mon, 27 Jan 2025 18:53:40 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.05313v4</guid></item><item><title>Empirical Studies of Parameter Efficient Methods for Large Language Models of Code and Knowledge Transfer to R</title><link>http://arxiv.org/abs/2405.01553v2</link><description>Parameter Efficient Fine-Tuning (PEFT) methods are proposed as an alternativefine-tuning approach for Large Language Models (LLM) to minimize high trainingcosts. While prior research demonstrates the effectiveness of PEFT methods inknowledge transfer using smaller language models, their application to largerLLMs, particularly in low-resource and unseen programming languages such as R,remains under-explored. In this work, we evaluate PEFT methods, LoRA,Compacter, and IA^3 on LLMs for code summarization and generation, with aparticular emphasis on knowledge transfer to R as an unseen under-exploredtarget language. Our experiments reveal that LoRA consistently outperformsCompacter and IA^3 in all settings, while Compacter offers significant resourceefficiency with minimal performance trade-offs. Additionally, we find that thenumber of trainable parameters has a greater influence on the functionalaccuracy of the generated code than PEFT architecture. Our study can directfuture research in developing code intelligent tasks for unseen languagesincluding R, as well as the choice of PEFT methods for knowledge transfer,especially when balancing the computational cost and performance.</description><author>Amirreza Esmaeili, Iman Saberi, Fatemeh H. Fard</author><pubDate>Mon, 27 Jan 2025 18:51:36 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.01553v2</guid></item><item><title>LinPrim: Linear Primitives for Differentiable Volumetric Rendering</title><link>http://arxiv.org/abs/2501.16312v1</link><description>Volumetric rendering has become central to modern novel view synthesismethods, which use differentiable rendering to optimize 3D scenerepresentations directly from observed views. While many recent works build onNeRF or 3D Gaussians, we explore an alternative volumetric scenerepresentation. More specifically, we introduce two new scene representationsbased on linear primitives-octahedra and tetrahedra-both of which definehomogeneous volumes bounded by triangular faces. This formulation alignsnaturally with standard mesh-based tools, minimizing overhead for downstreamapplications. To optimize these primitives, we present a differentiablerasterizer that runs efficiently on GPUs, allowing end-to-end gradient-basedoptimization while maintaining realtime rendering capabilities. Throughexperiments on real-world datasets, we demonstrate comparable performance tostate-of-the-art volumetric methods while requiring fewer primitives to achievesimilar reconstruction fidelity. Our findings provide insights into thegeometry of volumetric rendering and suggest that adopting explicit polyhedracan expand the design space of scene representations.</description><author>Nicolas von Lützow, Matthias Nießner</author><pubDate>Mon, 27 Jan 2025 18:49:38 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.16312v1</guid></item><item><title>Evaluating The Performance of Using Large Language Models to Automate Summarization of CT Simulation Orders in Radiation Oncology</title><link>http://arxiv.org/abs/2501.16309v1</link><description>Purpose: This study aims to use a large language model (LLM) to automate thegeneration of summaries from the CT simulation orders and evaluate itsperformance. Materials and Methods: A total of 607 CT simulation orders for patients werecollected from the Aria database at our institution. A locally hosted Llama 3.1405B model, accessed via the Application Programming Interface (API) service,was used to extract keywords from the CT simulation orders and generatesummaries. The downloaded CT simulation orders were categorized into sevengroups based on treatment modalities and disease sites. For each group, acustomized instruction prompt was developed collaboratively with therapists toguide the Llama 3.1 405B model in generating summaries. The ground truth forthe corresponding summaries was manually derived by carefully reviewing each CTsimulation order and subsequently verified by therapists. The accuracy of theLLM-generated summaries was evaluated by therapists using the verified groundtruth as a reference. Results: About 98% of the LLM-generated summaries aligned with the manuallygenerated ground truth in terms of accuracy. Our evaluations showed an improvedconsistency in format and enhanced readability of the LLM-generated summariescompared to the corresponding therapists-generated summaries. This automatedapproach demonstrated a consistent performance across all groups, regardless ofmodality or disease site. Conclusions: This study demonstrated the high precision and consistency ofthe Llama 3.1 405B model in extracting keywords and summarizing CT simulationorders, suggesting that LLMs have great potential to help with this task,reduce the workload of therapists and improve workflow efficiency.</description><author>Meiyun Cao, Shaw Hu, Jason Sharp, Edward Clouser, Jason Holmes, Linda L. Lam, Xiaoning Ding, Diego Santos Toesca, Wendy S. Lindholm, Samir H. Patel, Sujay A. Vora, Peilong Wang, Wei Liu</author><pubDate>Mon, 27 Jan 2025 18:47:58 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.16309v1</guid></item><item><title>MedPromptX: Grounded Multimodal Prompting for Chest X-ray Diagnosis</title><link>http://arxiv.org/abs/2403.15585v4</link><description>Chest X-ray images are commonly used for predicting acute and chroniccardiopulmonary conditions, but efforts to integrate them with structuredclinical data face challenges due to incomplete electronic health records(EHR). This paper introduces MedPromptX, the first clinical decision supportsystem that integrates multimodal large language models (MLLMs), few-shotprompting (FP) and visual grounding (VG) to combine imagery with EHR data forchest X-ray diagnosis. A pre-trained MLLM is utilized to complement the missingEHR information, providing a comprehensive understanding of patients' medicalhistory. Additionally, FP reduces the necessity for extensive training of MLLMswhile effectively tackling the issue of hallucination. Nevertheless, theprocess of determining the optimal number of few-shot examples and selectinghigh-quality candidates can be burdensome, yet it profoundly influences modelperformance. Hence, we propose a new technique that dynamically refinesfew-shot data for real-time adjustment to new patient scenarios. Moreover, VGnarrows the search area in X-ray images, thereby enhancing the identificationof abnormalities. We also release MedPromptX-VQA, a new in-context visualquestion answering dataset encompassing interleaved images and EHR data derivedfrom MIMIC-IV and MIMIC-CXR-JPG databases. Results demonstrate the SOTAperformance of MedPromptX, achieving an 11% improvement in F1-score compared tothe baselines. Code and data are publicly available onhttps://github.com/BioMedIA-MBZUAI/MedPromptX.</description><author>Mai A. Shaaban, Adnan Khan, Mohammad Yaqub</author><pubDate>Mon, 27 Jan 2025 18:46:41 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.15585v4</guid></item><item><title>Graph Neural Network Based Hybrid Beamforming Design in Wideband Terahertz MIMO-OFDM Systems</title><link>http://arxiv.org/abs/2501.16306v1</link><description>6G wireless technology is projected to adopt higher and wider frequencybands, enabled by highly directional beamforming. However, the vast bandwidthsavailable also make the impact of beam squint in massive multiple input andmultiple output (MIMO) systems non-negligible. Traditional approaches such asadding a true-time-delay line (TTD) on each antenna are costly due to themassive antenna arrays required. This paper puts forth a signal processingalternative, specifically adapted to the multicarrier structure of OFDMsystems, through an innovative application of Graph Neural Networks (GNNs) tooptimize hybrid beamforming. By integrating two types of graph nodes torepresent the analog and the digital beamforming matrices efficiently, ourapproach not only reduces the computational and memory burdens but alsoachieves high spectral efficiency performance, approaching that of all digitalbeamforming. The GNN runtime and memory requirement are at a fraction of theprocessing time and resource consumption of traditional signal processingmethods, hence enabling real-time adaptation of hybrid beamforming.Furthermore, the proposed GNN exhibits strong resiliency to beam squinting,achieving almost constant spectral efficiency even as the system bandwidthincreases at higher carrier frequencies.</description><author>Beier Li, Mai Vu</author><pubDate>Mon, 27 Jan 2025 18:45:54 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.16306v1</guid></item><item><title>Selective Generation for Controllable Language Models</title><link>http://arxiv.org/abs/2307.09254v4</link><description>Trustworthiness of generative language models (GLMs) is crucial in theirdeployment to critical decision making systems. Hence, certified risk controlmethods such as selective prediction and conformal prediction have been appliedto mitigating the hallucination problem in various supervised downstream tasks.However, the lack of appropriate correctness metric hinders applying suchprincipled methods to language generation tasks. In this paper, we circumventthis problem by leveraging the concept of textual entailment to evaluate thecorrectness of the generated sequence, and propose two selective generationalgorithms which control the false discovery rate with respect to the textualentailment relation (FDR-E) with a theoretical guarantee:$\texttt{SGen}^{\texttt{Sup}}$ and $\texttt{SGen}^{\texttt{Semi}}$.$\texttt{SGen}^{\texttt{Sup}}$, a direct modification of the selectiveprediction, is a supervised learning algorithm which exploitsentailment-labeled data, annotated by humans. Since human annotation is costly,we further propose a semi-supervised version, $\texttt{SGen}^{\texttt{Semi}}$,which fully utilizes the unlabeled data by pseudo-labeling, leveraging anentailment set function learned via conformal prediction. Furthermore,$\texttt{SGen}^{\texttt{Semi}}$ enables to use more general class of selectionfunctions, neuro-selection functions, and provides users with an optimalselection function class given multiple candidates. Finally, we demonstrate theefficacy of the $\texttt{SGen}$ family in achieving a desired FDR-E level withcomparable selection efficiency to those from baselines on both open and closedsource GLMs. Code and datasets are provided athttps://github.com/ml-postech/selective-generation.</description><author>Minjae Lee, Kyungmin Kim, Taesoo Kim, Sangdon Park</author><pubDate>Mon, 27 Jan 2025 18:45:22 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.09254v4</guid></item><item><title>RAPID: Retrieval-Augmented Parallel Inference Drafting for Text-Based Video Event Retrieval</title><link>http://arxiv.org/abs/2501.16303v1</link><description>Retrieving events from videos using text queries has become increasinglychallenging due to the rapid growth of multimedia content. Existing methods fortext-based video event retrieval often focus heavily on object-leveldescriptions, overlooking the crucial role of contextual information. Thislimitation is especially apparent when queries lack sufficient context, such asmissing location details or ambiguous background elements. To address thesechallenges, we propose a novel system called RAPID (Retrieval-AugmentedParallel Inference Drafting), which leverages advancements in Large LanguageModels (LLMs) and prompt-based learning to semantically correct and enrich userqueries with relevant contextual information. These enriched queries are thenprocessed through parallel retrieval, followed by an evaluation step to selectthe most relevant results based on their alignment with the original query.Through extensive experiments on our custom-developed dataset, we demonstratethat RAPID significantly outperforms traditional retrieval methods,particularly for contextually incomplete queries. Our system was validated forboth speed and accuracy through participation in the Ho Chi Minh City AIChallenge 2024, where it successfully retrieved events from over 300 hours ofvideo. Further evaluation comparing RAPID with the baseline proposed by thecompetition organizers demonstrated its superior effectiveness, highlightingthe strength and robustness of our approach.</description><author>Long Nguyen, Huy Nguyen, Bao Khuu, Huy Luu, Huy Le, Tuan Nguyen, Tho Quan</author><pubDate>Mon, 27 Jan 2025 18:45:07 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.16303v1</guid></item><item><title>Matryoshka Re-Ranker: A Flexible Re-Ranking Architecture With Configurable Depth and Width</title><link>http://arxiv.org/abs/2501.16302v1</link><description>Large language models (LLMs) provide powerful foundations to performfine-grained text re-ranking. However, they are often prohibitive in realitydue to constraints on computation bandwidth. In this work, we propose a\textbf{flexible} architecture called \textbf{Matroyshka Re-Ranker}, which isdesigned to facilitate \textbf{runtime customization} of model layers andsequence lengths at each layer based on users' configurations. Consequently,the LLM-based re-rankers can be made applicable across various real-worldsituations. The increased flexibility may come at the cost of precision loss.To address this problem, we introduce a suite of techniques to optimize theperformance. First, we propose \textbf{cascaded self-distillation}, where eachsub-architecture learns to preserve a precise re-ranking performance from itssuper components, whose predictions can be exploited as smooth and informativeteacher signals. Second, we design a \textbf{factorized compensationmechanism}, where two collaborative Low-Rank Adaptation modules, vertical andhorizontal, are jointly employed to compensate for the precision loss resultedfrom arbitrary combinations of layer and sequence compression. We performcomprehensive experiments based on the passage and document retrieval datasetsfrom MSMARCO, along with all public datasets from BEIR benchmark. In ourexperiments, Matryoshka Re-Ranker substantially outperforms the existingmethods, while effectively preserving its superior performance across variousforms of compression and different application scenarios.</description><author>Zheng Liu, Chaofan Li, Shitao Xiao, Chaozhuo Li, Defu Lian, Yingxia Shao</author><pubDate>Mon, 27 Jan 2025 18:42:48 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.16302v1</guid></item><item><title>AlgoRxplorers | Precision in Mutation -- Enhancing Drug Design with Advanced Protein Stability Prediction Tools</title><link>http://arxiv.org/abs/2501.07014v2</link><description>Predicting the impact of single-point amino acid mutations on proteinstability is essential for understanding disease mechanisms and advancing drugdevelopment. Protein stability, quantified by changes in Gibbs free energy($\Delta\Delta G$), is influenced by these mutations. However, the scarcity ofdata and the complexity of model interpretation pose challenges in accuratelypredicting stability changes. This study proposes the application of deepneural networks, leveraging transfer learning and fusing complementaryinformation from different models, to create a feature-rich representation ofthe protein stability landscape. We developed four models, with our thirdmodel, ThermoMPNN+, demonstrating the best performance in predicting$\Delta\Delta G$ values. This approach, which integrates diverse feature setsand embeddings through latent transfusion techniques, aims to refine$\Delta\Delta G$ predictions and contribute to a deeper understanding ofprotein dynamics, potentially leading to advancements in disease research anddrug discovery.</description><author>Karishma Thakrar, Jiangqin Ma, Max Diamond, Akash Patel</author><pubDate>Mon, 27 Jan 2025 18:41:22 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.07014v2</guid></item><item><title>Large Models in Dialogue for Active Perception and Anomaly Detection</title><link>http://arxiv.org/abs/2501.16300v1</link><description>Autonomous aerial monitoring is an important task aimed at gatheringinformation from areas that may not be easily accessible by humans. At the sametime, this task often requires recognizing anomalies from a significantdistance or not previously encountered in the past. In this paper, we propose anovel framework that leverages the advanced capabilities provided by LargeLanguage Models (LLMs) to actively collect information and perform anomalydetection in novel scenes. To this end, we propose an LLM based model dialogueapproach, in which two deep learning models engage in a dialogue to activelycontrol a drone to increase perception and anomaly detection accuracy. Weconduct our experiments in a high fidelity simulation environment where an LLMis provided with a predetermined set of natural language movement commandsmapped into executable code functions. Additionally, we deploy a multimodalVisual Question Answering (VQA) model charged with the task of visual questionanswering and captioning. By engaging the two models in conversation, the LLMasks exploratory questions while simultaneously flying a drone into differentparts of the scene, providing a novel way to implement active perception. Byleveraging LLMs reasoning ability, we output an improved detailed descriptionof the scene going beyond existing static perception approaches. In addition toinformation gathering, our approach is utilized for anomaly detection and ourresults demonstrate the proposed methods effectiveness in informing andalerting about potential hazards.</description><author>Tzoulio Chamiti, Nikolaos Passalis, Anastasios Tefas</author><pubDate>Mon, 27 Jan 2025 18:38:36 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.16300v1</guid></item><item><title>Two-Timescale Gradient Descent Ascent Algorithms for Nonconvex Minimax Optimization</title><link>http://arxiv.org/abs/2408.11974v3</link><description>We provide a unified analysis of two-timescale gradient descent ascent(TTGDA) for solving structured nonconvex minimax optimization problems in theform of $\min_\textbf{x} \max_{\textbf{y} \in Y} f(\textbf{x}, \textbf{y})$,where the objective function $f(\textbf{x}, \textbf{y})$ is nonconvex in$\textbf{x}$ and concave in $\textbf{y}$, and the constraint set $Y \subseteq\mathbb{R}^n$ is convex and bounded. In the convex-concave setting, thesingle-timescale gradient descent ascent (GDA) algorithm is widely used inapplications and has been shown to have strong convergence guarantees. In moregeneral settings, however, it can fail to converge. Our contribution is todesign TTGDA algorithms that are effective beyond the convex-concave setting,efficiently finding a stationary point of the function $\Phi(\cdot) :=\max_{\textbf{y} \in Y} f(\cdot, \textbf{y})$. We also establish theoreticalbounds on the complexity of solving both smooth and nonsmooth nonconvex-concaveminimax optimization problems. To the best of our knowledge, this is the firstsystematic analysis of TTGDA for nonconvex minimax optimization, shedding lighton its superior performance in training generative adversarial networks (GANs)and in other real-world application problems.</description><author>Tianyi Lin, Chi Jin, Michael. I. Jordan</author><pubDate>Mon, 27 Jan 2025 18:37:18 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.11974v3</guid></item><item><title>FALCON: Resolving Visual Redundancy and Fragmentation in High-resolution Multimodal Large Language Models via Visual Registers</title><link>http://arxiv.org/abs/2501.16297v1</link><description>The incorporation of high-resolution visual input equips multimodal largelanguage models (MLLMs) with enhanced visual perception capabilities forreal-world tasks. However, most existing high-resolution MLLMs rely on acropping-based approach to process images, which leads to fragmented visualencoding and a sharp increase in redundant tokens. To tackle these issues, wepropose the FALCON model. FALCON introduces a novel visual register techniqueto simultaneously: 1) Eliminate redundant tokens at the stage of visualencoding. To directly address the visual redundancy present in the output ofvision encoder, we propose a Register-based Representation Compacting(ReCompact) mechanism. This mechanism introduces a set of learnable visualregisters designed to adaptively aggregate essential information whilediscarding redundancy. It enables the encoder to produce a more compact visualrepresentation with a minimal number of output tokens, thus eliminating theneed for an additional compression module. 2) Ensure continuity in visualencoding. To address the potential encoding errors caused by fragmented visualinputs, we develop a Register Interactive Attention (ReAtten) module. Thismodule facilitates effective and efficient information exchange acrosssub-images by enabling interactions between visual registers. It ensures thecontinuity of visual semantics throughout the encoding. We conductcomprehensive experiments with FALCON on high-resolution benchmarks across awide range of scenarios. FALCON demonstrates superior performance with aremarkable 9-fold and 16-fold reduction in visual tokens.</description><author>Renshan Zhang, Rui Shao, Gongwei Chen, Kaiwen Zhou, Weili Guan, Liqiang Nie</author><pubDate>Mon, 27 Jan 2025 18:36:10 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.16297v1</guid></item><item><title>Mixture-of-Mamba: Enhancing Multi-Modal State-Space Models with Modality-Aware Sparsity</title><link>http://arxiv.org/abs/2501.16295v1</link><description>State Space Models (SSMs) have emerged as efficient alternatives toTransformers for sequential modeling, but their inability to leveragemodality-specific features limits their performance in multi-modal pretraining.Here, we propose Mixture-of-Mamba, a novel SSM architecture that introducesmodality-aware sparsity through modality-specific parameterization of the Mambablock. Building on Mixture-of-Transformers (W. Liang et al. arXiv:2411.04996;2024), we extend the benefits of modality-aware sparsity to SSMs whilepreserving their computational efficiency. We evaluate Mixture-of-Mamba acrossthree multi-modal pretraining settings: Transfusion (interleaved text andcontinuous image tokens with diffusion loss), Chameleon (interleaved text anddiscrete image tokens), and an extended three-modality framework incorporatingspeech. Mixture-of-Mamba consistently reaches the same loss values at earliertraining steps with significantly reduced computational costs. In theTransfusion setting, Mixture-of-Mamba achieves equivalent image loss using only34.76% of the training FLOPs at the 1.4B scale. In the Chameleon setting,Mixture-of-Mamba reaches similar image loss with just 42.50% of the FLOPs atthe 1.4B scale, and similar text loss with just 65.40% of the FLOPs. In thethree-modality setting, MoM matches speech loss at 24.80% of the FLOPs at the1.4B scale. Our ablation study highlights the synergistic effects of decouplingprojection components, where joint decoupling yields greater gains thanindividual modifications. These results establish modality-aware sparsity as aversatile and effective design principle, extending its impact fromTransformers to SSMs and setting new benchmarks in multi-modal pretraining. Ourcode can be accessed at https://github.com/Weixin-Liang/Mixture-of-Mamba</description><author>Weixin Liang, Junhong Shen, Genghan Zhang, Ning Dong, Luke Zettlemoyer, Lili Yu</author><pubDate>Mon, 27 Jan 2025 18:35:05 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.16295v1</guid></item><item><title>CENTS: Generating synthetic electricity consumption time series for rare and unseen scenarios</title><link>http://arxiv.org/abs/2501.14426v2</link><description>Recent breakthroughs in large-scale generative modeling have demonstrated thepotential of foundation models in domains such as natural language, computervision, and protein structure prediction. However, their application in theenergy and smart grid sector remains limited due to the scarcity andheterogeneity of high-quality data. In this work, we propose a method forcreating high-fidelity electricity consumption time series data for rare andunseen context variables (e.g. location, building type, photovoltaics). Ourapproach, Context Encoding and Normalizing Time Series Generation, or CENTS,includes three key innovations: (i) A context normalization approach thatenables inverse transformation for time series context variables unseen duringtraining, (ii) a novel context encoder to condition any state-of-the-arttime-series generator on arbitrary numbers and combinations of contextvariables, (iii) a framework for training this context encoder jointly with atime-series generator using an auxiliary context classification loss designedto increase expressivity of context embeddings and improve model performance.We further provide a comprehensive overview of different evaluation metrics forgenerative time series models. Our results highlight the efficacy of theproposed method in generating realistic household-level electricity consumptiondata, paving the way for training larger foundation models in the energy domainon synthetic as well as real-world data.</description><author>Michael Fuest, Alfredo Cuesta, Kalyan Veeramachaneni</author><pubDate>Mon, 27 Jan 2025 18:34:26 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.14426v2</guid></item><item><title>MetRex: A Benchmark for Verilog Code Metric Reasoning Using LLMs</title><link>http://arxiv.org/abs/2411.03471v2</link><description>Large Language Models (LLMs) have been applied to various hardware designtasks, including Verilog code generation, EDA tool scripting, and RTL bugfixing. Despite this extensive exploration, LLMs are yet to be used for thetask of post-synthesis metric reasoning and estimation of HDL designs. In thispaper, we assess the ability of LLMs to reason about post-synthesis metrics ofVerilog designs. We introduce MetRex, a large-scale dataset comprising 25,868Verilog HDL designs and their corresponding post-synthesis metrics, namelyarea, delay, and static power. MetRex incorporates a Chain of Thought (CoT)template to enhance LLMs' reasoning about these metrics. Extensive experimentsshow that Supervised Fine-Tuning (SFT) boosts the LLM's reasoning capabilitieson average by 37.0\%, 25.3\%, and 25.7\% on the area, delay, and static power,respectively. While SFT improves performance on our benchmark, it remains farfrom achieving optimal results, especially on complex problems. Comparing tostate-of-the-art regression models, our approach delivers accuratepost-synthesis predictions for 17.4\% more designs (within a 5\% error margin),in addition to offering a 1.7x speedup by eliminating the need forpre-processing. This work lays the groundwork for advancing LLM-based Verilogcode metric reasoning.</description><author>Manar Abdelatty, Jingxiao Ma, Sherief Reda</author><pubDate>Mon, 27 Jan 2025 18:27:32 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2411.03471v2</guid></item><item><title>Multi-view Structural Convolution Network for Domain-Invariant Point Cloud Recognition of Autonomous Vehicles</title><link>http://arxiv.org/abs/2501.16289v1</link><description>Point cloud representation has recently become a research hotspot in thefield of computer vision and has been utilized for autonomous vehicles.However, adapting deep learning networks for point cloud data recognition ischallenging due to the variability in datasets and sensor technologies. Thisvariability underscores the necessity for adaptive techniques to maintainaccuracy under different conditions. In this paper, we present the Multi-ViewStructural Convolution Network (MSCN) designed for domain-invariant point cloudrecognition. MSCN comprises Structural Convolution Layers (SCL) that extractlocal context geometric features from point clouds and Structural AggregationLayers (SAL) that extract and aggregate both local and overall context featuresfrom point clouds. Additionally, our MSCN enhances feature representationrobustness by training with unseen domain point clouds derived from sourcedomain point clouds. This method acquires domain-invariant features andexhibits robust, consistent performance across various point cloud datasets,ensuring compatibility with diverse sensor configurations without the need forparameter adjustments. This highlights MSCN's potential to significantlyimprove the reliability and domain invariant features in differentenvironments. Our code is available at https://github.com/MLMLab/MSCN.</description><author>Younggun Kim, Beomsik Cho, Seonghoon Ryoo, Soomok Lee</author><pubDate>Mon, 27 Jan 2025 18:25:35 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.16289v1</guid></item><item><title>Upside Down Reinforcement Learning with Policy Generators</title><link>http://arxiv.org/abs/2501.16288v1</link><description>Upside Down Reinforcement Learning (UDRL) is a promising framework forsolving reinforcement learning problems which focuses on learningcommand-conditioned policies. In this work, we extend UDRL to the task oflearning a command-conditioned generator of deep neural network policies. Weaccomplish this using Hypernetworks - a variant of Fast Weight Programmers,which learn to decode input commands representing a desired expected returninto command-specific weight matrices. Our method, dubbed Upside DownReinforcement Learning with Policy Generators (UDRLPG), streamlines comparabletechniques by removing the need for an evaluator or critic to update theweights of the generator. To counteract the increased variance in last returnscaused by not having an evaluator, we decouple the sampling probability of thebuffer from the absolute number of policies in it, which, together with asimple weighting strategy, improves the empirical convergence of the algorithm.Compared with existing algorithms, UDRLPG achieves competitive performance andhigh returns, sometimes outperforming more complex architectures. Ourexperiments show that a trained generator can generalize to create policiesthat achieve unseen returns zero-shot. The proposed method appears to beeffective in mitigating some of the challenges associated with learning highlymultimodal functions. Altogether, we believe that UDRLPG represents a promisingstep forward in achieving greater empirical sample efficiency in RL. A fullimplementation of UDRLPG is publicly available athttps://github.com/JacopoD/udrlpg_</description><author>Jacopo Di Ventura, Dylan R. Ashley, Francesco Faccio, Vincent Herrmann, Jürgen Schmidhuber</author><pubDate>Mon, 27 Jan 2025 18:25:04 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.16288v1</guid></item><item><title>A Unified Representation of Density-Power-Based Divergences Reducible to M-Estimation</title><link>http://arxiv.org/abs/2501.16287v1</link><description>Density-power-based divergences are known to provide robust inferenceprocedures against outliers, and their extensions have been widely studied. Acharacteristic of successful divergences is that the estimation problem can bereduced to M-estimation. In this paper, we define a norm-based Bregman densitypower divergence (NB-DPD) -- density-power-based divergence with functionalflexibility within the framework of Bregman divergences that can be reduced toM-estimation. We show that, by specifying the function $\phi_\gamma$, NB-DPDreduces to well-known divergences, such as the density power divergence and the$\gamma$-divergence. Furthermore, by examining the combinations of functions$\phi_\gamma$ corresponding to existing divergences, we show that a newdivergence connecting these existing divergences can be derived. Finally, weshow that the redescending property, one of the key indicators of robustness,holds only for the $\gamma$-divergence.</description><author>Masahiro Kobayashi</author><pubDate>Mon, 27 Jan 2025 18:23:59 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.16287v1</guid></item><item><title>Towards understanding the bias in decision trees</title><link>http://arxiv.org/abs/2501.04903v2</link><description>There is a widespread and longstanding belief that machine learning modelsare biased towards the majority (or negative) class when learning fromimbalanced data, leading them to neglect or ignore the minority (or positive)class. In this study, we show that this belief is not necessarily correct fordecision trees, and that their bias can actually be in the opposite direction.Motivated by a recent simulation study that suggested that decision trees canbe biased towards the minority class, our paper aims to reconcile the conflictbetween that study and decades of other works. First, we critically evaluatepast literature on this problem, finding that failing to consider the datagenerating process has led to incorrect conclusions about the bias in decisiontrees. We then prove that, under specific conditions related to the predictors,decision trees fit to purity and trained on a dataset with only one positivecase are biased towards the minority class. Finally, we demonstrate that splitsin a decision tree are also biased when there is more than one positive case.Our findings have implications on the use of popular tree-based models, such asrandom forests.</description><author>Nathan Phelps, Daniel J. Lizotte, Douglas G. Woolford</author><pubDate>Mon, 27 Jan 2025 18:22:59 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.04903v2</guid></item><item><title>PEP-GS: Perceptually-Enhanced Precise Structured 3D Gaussians for View-Adaptive Rendering</title><link>http://arxiv.org/abs/2411.05731v2</link><description>Recently, 3D Gaussian Splatting (3D-GS) has achieved significant success inreal-time, high-quality 3D scene rendering. However, it faces severalchallenges, including Gaussian redundancy, limited ability to captureview-dependent effects, and difficulties in handling complex lighting andspecular reflections. Additionally, methods that use spherical harmonics forcolor representation often struggle to effectively capture specular highlightsand anisotropic components, especially when modeling view-dependent colorsunder complex lighting conditions, leading to insufficient contrast andunnatural color saturation. To address these limitations, we introduce PEP-GS,a perceptually-enhanced framework that dynamically predicts Gaussianattributes, including opacity, color, and covariance. We replace traditionalspherical harmonics with a Hierarchical Granular-Structural Attentionmechanism, which enables more accurate modeling of complex view-dependent coloreffects and specular highlights. By employing a stable and interpretableframework for opacity and covariance estimation, PEP-GS avoids the removal ofessential Gaussians prematurely, ensuring a more accurate scene representation.Furthermore, perceptual optimization is applied to the final rendered images,enhancing perceptual consistency across different views and ensuringhigh-quality renderings with improved texture fidelity and fine-scale detailpreservation. Experimental results demonstrate that PEP-GS outperformsstate-of-the-art methods, particularly in challenging scenarios involvingview-dependent effects, specular reflections, and fine-scale details.</description><author>Junxi Jin, Xiulai Li, Haiping Huang, Lianjun Liu, Yujie Sun, Boyi Liu</author><pubDate>Mon, 27 Jan 2025 18:21:19 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2411.05731v2</guid></item><item><title>Brain-Adapter: Enhancing Neurological Disorder Analysis with Adapter-Tuning Multimodal Large Language Models</title><link>http://arxiv.org/abs/2501.16282v1</link><description>Understanding brain disorders is crucial for accurate clinical diagnosis andtreatment. Recent advances in Multimodal Large Language Models (MLLMs) offer apromising approach to interpreting medical images with the support of textdescriptions. However, previous research has primarily focused on 2D medicalimages, leaving richer spatial information of 3D images under-explored, andsingle-modality-based methods are limited by overlooking the critical clinicalinformation contained in other modalities. To address this issue, this paperproposes Brain-Adapter, a novel approach that incorporates an extra bottlenecklayer to learn new knowledge and instill it into the original pre-trainedknowledge. The major idea is to incorporate a lightweight bottleneck layer totrain fewer parameters while capturing essential information and utilize aContrastive Language-Image Pre-training (CLIP) strategy to align multimodaldata within a unified representation space. Extensive experiments demonstratedthe effectiveness of our approach in integrating multimodal data tosignificantly improve the diagnosis accuracy without high computational costs,highlighting the potential to enhance real-world diagnostic workflows.</description><author>Jing Zhang, Xiaowei Yu, Yanjun Lyu, Lu Zhang, Tong Chen, Chao Cao, Yan Zhuang, Minheng Chen, Tianming Liu, Dajiang Zhu</author><pubDate>Mon, 27 Jan 2025 18:20:49 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.16282v1</guid></item><item><title>2.5 Years in Class: A Multimodal Textbook for Vision-Language Pretraining</title><link>http://arxiv.org/abs/2501.00958v3</link><description>Compared to image-text pair data, interleaved corpora enable Vision-LanguageModels (VLMs) to understand the world more naturally like humans. However, suchexisting datasets are crawled from webpage, facing challenges like lowknowledge density, loose image-text relations, and poor logical coherencebetween images. On the other hand, the internet hosts vast instructional videos(e.g., online geometry courses) that are widely used by humans to learnfoundational subjects, yet these valuable resources remain underexplored in VLMtraining. In this paper, we introduce a high-quality \textbf{multimodaltextbook} corpus with richer foundational knowledge for VLM pretraining. Itcollects over 2.5 years of instructional videos, totaling 22,000 class hours.We first use an LLM-proposed taxonomy to systematically gather instructionalvideos. Then we progressively extract and refine visual (keyframes), audio(ASR), and textual knowledge (OCR) from the videos, and organize as animage-text interleaved corpus based on temporal order. Compared to itscounterparts, our video-centric textbook offers more coherent context, richerknowledge, and better image-text alignment. Experiments demonstrate its superbpretraining performance, particularly in knowledge- and reasoning-intensivetasks like ScienceQA and MathVista. Moreover, VLMs pre-trained on our textbookexhibit outstanding interleaved context awareness, leveraging visual andtextual cues in their few-shot context for task solving. Our code are availableat https://github.com/DAMO-NLP-SG/multimodal_textbook.</description><author>Wenqi Zhang, Hang Zhang, Xin Li, Jiashuo Sun, Yongliang Shen, Weiming Lu, Deli Zhao, Yueting Zhuang, Lidong Bing</author><pubDate>Mon, 27 Jan 2025 18:17:26 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.00958v3</guid></item><item><title>Towards Physically Interpretable World Models: Meaningful Weakly Supervised Representations for Visual Trajectory Prediction</title><link>http://arxiv.org/abs/2412.12870v2</link><description>Deep learning models are increasingly employed for perception, prediction,and control in complex systems. Embedding physical knowledge into these modelsis crucial for achieving realistic and consistent outputs, a challenge oftenaddressed by physics-informed machine learning. However, integrating physicalknowledge with representation learning becomes difficult when dealing withhigh-dimensional observation data, such as images, particularly underconditions of incomplete or imprecise state information. To address this, wepropose Physically Interpretable World Models, a novel architecture that alignslearned latent representations with real-world physical quantities. Our methodcombines a variational autoencoder with a dynamical model that incorporatesunknown system parameters, enabling the discovery of physically meaningfulrepresentations. By employing weak supervision with interval-based constraints,our approach eliminates the reliance on ground-truth physical annotations.Experimental results demonstrate that our method improves the quality oflearned representations while achieving accurate predictions of future states,advancing the field of representation learning in dynamic systems.</description><author>Zhenjiang Mao, Ivan Ruchkin</author><pubDate>Mon, 27 Jan 2025 18:13:37 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.12870v2</guid></item><item><title>URAG: Implementing a Unified Hybrid RAG for Precise Answers in University Admission Chatbots -- A Case Study at HCMUT</title><link>http://arxiv.org/abs/2501.16276v1</link><description>With the rapid advancement of Artificial Intelligence, particularly inNatural Language Processing, Large Language Models (LLMs) have become pivotalin educational question-answering systems, especially university admissionchatbots. Concepts such as Retrieval-Augmented Generation (RAG) and otheradvanced techniques have been developed to enhance these systems by integratingspecific university data, enabling LLMs to provide informed responses onadmissions and academic counseling. However, these enhanced RAG techniquesoften involve high operational costs and require the training of complex,specialized modules, which poses challenges for practical deployment.Additionally, in the educational context, it is crucial to provide accurateanswers to prevent misinformation, a task that LLM-based systems findchallenging without appropriate strategies and methods. In this paper, weintroduce the Unified RAG (URAG) Framework, a hybrid approach thatsignificantly improves the accuracy of responses, particularly for criticalqueries. Experimental results demonstrate that URAG enhances our in-house,lightweight model to perform comparably to state-of-the-art commercial models.Moreover, to validate its practical applicability, we conducted a case study atour educational institution, which received positive feedback and acclaim. Thisstudy not only proves the effectiveness of URAG but also highlights itsfeasibility for real-world implementation in educational settings.</description><author>Long Nguyen, Tho Quan</author><pubDate>Mon, 27 Jan 2025 18:10:34 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.16276v1</guid></item><item><title>What is Formal Verification without Specifications? A Survey on mining LTL Specifications</title><link>http://arxiv.org/abs/2501.16274v1</link><description>Virtually all verification techniques using formal methods rely on theavailability of a formal specification, which describes the design requirementsprecisely. However, formulating specifications remains a manual task that isnotoriously challenging and error-prone. To address this bottleneck in formalverification, recent research has thus focussed on automatically generatingspecifications for formal verification from examples of (desired and undesired)system behavior. In this survey, we list and compare recent advances in miningspecifications in Linear Temporal Logic (LTL), the de facto standardspecification language for reactive systems. Several approaches have beendesigned for learning LTL formulas, which address different aspects andsettings of specification design. Moreover, the approaches rely on a diverserange of techniques such as constraint solving, neural network training,enumerative search, etc. We survey the current state-of-the-art techniques andcompare them for the convenience of the formal methods practitioners.</description><author>Daniel Neider, Rajarshi Roy</author><pubDate>Mon, 27 Jan 2025 18:06:48 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.16274v1</guid></item><item><title>Return of the Encoder: Maximizing Parameter Efficiency for SLMs</title><link>http://arxiv.org/abs/2501.16273v1</link><description>The dominance of large decoder-only language models has overshadowedencoder-decoder architectures, despite their fundamental efficiency advantagesin sequence processing. For small language models (SLMs) - those with 1 billionparameters or fewer - our systematic analysis across GPU, CPU, and NPUplatforms reveals that encoder-decoder architectures achieve 47% lowerfirst-token latency and 4.7x higher throughput compared to decoder-only modelson edge devices. These gains may be attributed to encoder-decoder's one-timeinput processing and efficient separation of understanding and generationphases. We introduce a novel knowledge distillation framework that enablesencoder-decoder models to leverage capabilities from large scalabledecoder-only teachers while preserving their architectural advantages,achieving up to 6 average performance points improvement across diverse tasks,with significant gains in asymmetric sequence tasks where input and outputdistributions can benefit from different processing approaches. When combined with modern advances like Rotary Positional Embeddings (RoPE)and Vision encoders, our systematic investigation demonstrates thatencoder-decoder architectures provide a more practical path toward deployingcapable language models in resource-constrained environments. Our findingschallenge the prevailing trend toward decoder-only scaling, showing thatarchitectural choices become increasingly crucial as parameter budgetsdecrease, particularly for on-device and edge deployments where computationalefficiency is paramount.</description><author>Mohamed Elfeki, Rui Liu, Chad Voegele</author><pubDate>Mon, 27 Jan 2025 18:06:36 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.16273v1</guid></item><item><title>From Molecules to Mixtures: Learning Representations of Olfactory Mixture Similarity using Inductive Biases</title><link>http://arxiv.org/abs/2501.16271v1</link><description>Olfaction -- how molecules are perceived as odors to humans -- remains poorlyunderstood. Recently, the principal odor map (POM) was introduced to digitizethe olfactory properties of single compounds. However, smells in real life arenot pure single molecules, but complex mixtures of molecules, whoserepresentations remain relatively under-explored. In this work, we introducePOMMix, an extension of the POM to represent mixtures. Our representationbuilds upon the symmetries of the problem space in a hierarchical manner: (1)graph neural networks for building molecular embeddings, (2) attentionmechanisms for aggregating molecular representations into mixturerepresentations, and (3) cosine prediction heads to encode olfactory perceptualdistance in the mixture embedding space. POMMix achieves state-of-the-artpredictive performance across multiple datasets. We also evaluate thegeneralizability of the representation on multiple splits when applied tounseen molecules and mixture sizes. Our work advances the effort to digitizeolfaction, and highlights the synergy of domain expertise and deep learning incrafting expressive representations in low-data regimes.</description><author>Gary Tom, Cher Tian Ser, Ella M. Rajaonson, Stanley Lo, Hyun Suk Park, Brian K. Lee, Benjamin Sanchez-Lengeling</author><pubDate>Mon, 27 Jan 2025 18:05:28 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.16271v1</guid></item><item><title>A Survey on Knowledge Organization Systems of Research Fields: Resources and Challenges</title><link>http://arxiv.org/abs/2409.04432v2</link><description>Knowledge Organization Systems (KOSs), such as term lists, thesauri,taxonomies, and ontologies, play a fundamental role in categorising, managing,and retrieving information. In the academic domain, KOSs are often adopted forrepresenting research areas and their relationships, primarily aiming toclassify research articles, academic courses, patents, books, scientificvenues, domain experts, grants, software, experiment materials, and severalother relevant products and agents. These structured representations ofresearch areas, widely embraced by many academic fields, have proven effectivein empowering AI-based systems to i) enhance retrievability of relevantdocuments, ii) enable advanced analytic solutions to quantify the impact ofacademic research, and iii) analyse and forecast research dynamics. This paperaims to present a comprehensive survey of the current KOS for academicdisciplines. We analysed and compared 45 KOSs according to five maindimensions: scope, structure, curation, usage, and links to other KOSs. Ourresults reveal a very heterogeneous scenario in terms of scope, scale, quality,and usage, highlighting the need for more integrated solutions for representingresearch knowledge across academic fields. We conclude by discussing the mainchallenges and the most promising future directions.</description><author>Angelo Salatino, Tanay Aggarwal, Andrea Mannocci, Francesco Osborne, Enrico Motta</author><pubDate>Mon, 27 Jan 2025 18:03:08 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2409.04432v2</guid></item><item><title>Training Dynamics of In-Context Learning in Linear Attention</title><link>http://arxiv.org/abs/2501.16265v1</link><description>While attention-based models have demonstrated the remarkable ability ofin-context learning, the theoretical understanding of how these models acquiredthis ability through gradient descent training is still preliminary. Towardsanswering this question, we study the gradient descent dynamics of multi-headlinear self-attention trained for in-context linear regression. We examine twoparametrizations of linear self-attention: one with the key and query weightsmerged as a single matrix (common in theoretical studies), and one withseparate key and query matrices (closer to practical settings). For the mergedparametrization, we show the training dynamics has two fixed points and theloss trajectory exhibits a single, abrupt drop. We derive an analyticaltime-course solution for a certain class of datasets and initialization. Forthe separate parametrization, we show the training dynamics has exponentiallymany fixed points and the loss exhibits saddle-to-saddle dynamics, which wereduce to scalar ordinary differential equations. During training, the modelimplements principal component regression in context with the number ofprincipal components increasing over training time. Overall, we characterizehow in-context learning abilities evolve during gradient descent training oflinear attention, revealing dynamics of abrupt acquisition versus progressiveimprovements in models with different parametrizations.</description><author>Yedi Zhang, Aaditya K. Singh, Peter E. Latham, Andrew Saxe</author><pubDate>Mon, 27 Jan 2025 18:03:00 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.16265v1</guid></item><item><title>Beyond the Neural Fog: Interpretable Learning for AC Optimal Power Flow</title><link>http://arxiv.org/abs/2408.05228v2</link><description>The AC optimal power flow (AC-OPF) problem is essential for power systemoperations, but its non-convex nature makes it challenging to solve. A widelyused simplification is the linearized DC optimal power flow (DC-OPF) problem,which can be solved to global optimality, but whose optimal solution is alwaysinfeasible in the original AC-OPF problem. Recently, neural networks (NN) havebeen introduced for solving the AC-OPF problem at significantly fastercomputation times. However, these methods necessitate extensive datasets, aredifficult to train, and are often viewed as black boxes, leading to resistancefrom operators who prefer more transparent and interpretable solutions. In thispaper, we introduce a novel learning-based approach that merges simplicity andinterpretability, providing a bridge between traditional approximation methodsand black-box learning techniques. Our approach not only provides transparencyfor operators but also achieves competitive accuracy. Numerical results acrossvarious power networks demonstrate that our method provides accuracy comparableto, and often surpassing, that of neural networks, particularly when trainingdatasets are limited.</description><author>Salvador Pineda, Juan Pérez-Ruiz, Juan Miguel Morales</author><pubDate>Mon, 27 Jan 2025 17:58:12 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.05228v2</guid></item><item><title>Improving DBMS Scheduling Decisions with Fine-grained Performance Prediction on Concurrent Queries -- Extended</title><link>http://arxiv.org/abs/2501.16256v1</link><description>Query scheduling is a critical task that directly impacts query performancein database management systems (DBMS). Deeply integrated schedulers, whichrequire changes to DBMS internals, are usually customized for a specific engineand can take months to implement. In contrast, non-intrusive schedulers makecoarse-grained decisions, such as controlling query admission and re-orderingquery execution, without requiring modifications to DBMS internals. Theyrequire much less engineering effort and can be applied across a wide range ofDBMS engines, offering immediate benefits to end users. However, most existingnon-intrusive scheduling systems rely on simplified cost models and heuristicsthat cannot accurately model query interactions under concurrency and differentsystem states, possibly leading to suboptimal scheduling decisions. This work introduces IconqSched, a new, principled non-intrusive schedulerthat optimizes the execution order and timing of queries to enhance totalend-to-end runtime as experienced by the user query queuing time plus systemruntime. Unlike previous approaches, IconqSched features a novel fine-grainedpredictor, Iconq, which treats the DBMS as a black box and accurately estimatesthe system runtime of concurrently executed queries under different systemstates. Using these predictions, IconqSched is able to capture system runtimevariations across different query mixes and system loads. It then employs agreedy scheduling algorithm to effectively determine which queries to submitand when to submit them. We compare IconqSched to other schedulers in terms ofend-to-end runtime using real workload traces. On Postgres, IconqSched reducesend-to-end runtime by 16.2%-28.2% on average and 33.6%-38.9% in the tail.Similarly, on Redshift, it reduces end-to-end runtime by 10.3%-14.1% on averageand 14.9%-22.2% in the tail.</description><author>Ziniu Wu, Markos Markakis, Chunwei Liu, Peter Baile Chen, Balakrishnan Narayanaswamy, Tim Kraska, Samuel Madden</author><pubDate>Mon, 27 Jan 2025 17:55:39 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.16256v1</guid></item><item><title>A foundation model for human-AI collaboration in medical literature mining</title><link>http://arxiv.org/abs/2501.16255v1</link><description>Systematic literature review is essential for evidence-based medicine,requiring comprehensive analysis of clinical trial publications. However, theapplication of artificial intelligence (AI) models for medical literaturemining has been limited by insufficient training and evaluation across broadtherapeutic areas and diverse tasks. Here, we present LEADS, an AI foundationmodel for study search, screening, and data extraction from medical literature.The model is trained on 633,759 instruction data points in LEADSInstruct,curated from 21,335 systematic reviews, 453,625 clinical trial publications,and 27,015 clinical trial registries. We showed that LEADS demonstratesconsistent improvements over four cutting-edge generic large language models(LLMs) on six tasks. Furthermore, LEADS enhances expert workflows by providingsupportive references following expert requests, streamlining processes whilemaintaining high-quality results. A study with 16 clinicians and medicalresearchers from 14 different institutions revealed that experts collaboratingwith LEADS achieved a recall of 0.81 compared to 0.77 experts working alone instudy selection, with a time savings of 22.6%. In data extraction tasks,experts using LEADS achieved an accuracy of 0.85 versus 0.80 without usingLEADS, alongside a 26.9% time savings. These findings highlight the potentialof specialized medical literature foundation models to outperform genericmodels, delivering significant quality and efficiency benefits when integratedinto expert workflows for medical literature mining.</description><author>Zifeng Wang, Lang Cao, Qiao Jin, Joey Chan, Nicholas Wan, Behdad Afzali, Hyun-Jin Cho, Chang-In Choi, Mehdi Emamverdi, Manjot K. Gill, Sun-Hyung Kim, Yijia Li, Yi Liu, Hanley Ong, Justin Rousseau, Irfan Sheikh, Jenny J. Wei, Ziyang Xu, Christopher M. Zallek, Kyungsang Kim, Yifan Peng, Zhiyong Lu, Jimeng Sun</author><pubDate>Mon, 27 Jan 2025 17:55:37 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.16255v1</guid></item><item><title>Multi-Agent Geospatial Copilots for Remote Sensing Workflows</title><link>http://arxiv.org/abs/2501.16254v1</link><description>We present GeoLLM-Squad, a geospatial Copilot that introduces the novelmulti-agent paradigm to remote sensing (RS) workflows. Unlike existingsingle-agent approaches that rely on monolithic large language models (LLM),GeoLLM-Squad separates agentic orchestration from geospatial task-solving, bydelegating RS tasks to specialized sub-agents. Built on the open-source AutoGenand GeoLLM-Engine frameworks, our work enables the modular integration ofdiverse applications, spanning urban monitoring, forestry protection, climateanalysis, and agriculture studies. Our results demonstrate that whilesingle-agent systems struggle to scale with increasing RS task complexity,GeoLLM-Squad maintains robust performance, achieving a 17% improvement inagentic correctness over state-of-the-art baselines. Our findings highlight thepotential of multi-agent AI in advancing RS workflows.</description><author>Chaehong Lee, Varatheepan Paramanayakam, Andreas Karatzas, Yanan Jian, Michael Fore, Heming Liao, Fuxun Yu, Ruopu Li, Iraklis Anagnostopoulos, Dimitrios Stamoulis</author><pubDate>Mon, 27 Jan 2025 17:54:31 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.16254v1</guid></item><item><title>Runtime Analysis of the Compact Genetic Algorithm on the LeadingOnes Benchmark</title><link>http://arxiv.org/abs/2501.16250v1</link><description>The compact genetic algorithm (cGA) is one of the simplestestimation-of-distribution algorithms (EDAs). Next to the univariate marginaldistribution algorithm (UMDA) -- another simple EDA -- , the cGA has beensubject to extensive mathematical runtime analyses, often showcasing a similaror even superior performance to competing approaches. Surprisingly though, upto date and in contrast to the UMDA and many other heuristics, we lack arigorous runtime analysis of the cGA on the LeadingOnes benchmark -- one of themost studied theory benchmarks in the domain of evolutionary computation. We fill this gap in the literature by conducting a formal runtime analysis ofthe cGA on LeadingOnes. For the cGA's single parameter -- called thehypothetical population size -- at least polylogarithmically larger than theproblem size, we prove that the cGA samples the optimum of LeadingOnes withhigh probability within a number of function evaluations quasi-linear in theproblem size and linear in the hypothetical population size. For the besthypothetical population size, our result matches, up to polylogarithmicfactors, the typical quadratic runtime that many randomized search heuristicsexhibit on LeadingOnes. Our analysis exhibits some noteworthy differences inthe working principles of the two algorithms which were not visible in previousworks.</description><author>Marcel Chwiałkowski, Benjamin Doerr, Martin S. Krejca</author><pubDate>Mon, 27 Jan 2025 17:51:51 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.16250v1</guid></item><item><title>Lightweight Weighted Average Ensemble Model for Pneumonia Detection in Chest X-Ray Images</title><link>http://arxiv.org/abs/2501.16249v1</link><description>Pneumonia is a leading cause of illness and death in children, underscoringthe need for early and accurate detection. In this study, we propose a novellightweight ensemble model for detecting pneumonia in children using chestX-ray images. This ensemble model integrates two pre-trained convolutionalneural networks (CNNs), MobileNetV2 and NASNetMobile, selected for theirbalance of computational efficiency and accuracy. These models were fine-tunedon a pediatric chest X-ray dataset and combined to enhance classificationperformance. Our proposed ensemble model achieved a classification accuracy of98.63%, significantly outperforming individual models such as MobileNetV2(97.10%) and NASNetMobile(96.25%) in terms of accuracy, precision, recall, andF1 score. Moreover, the ensemble model outperformed state-of-the-artarchitectures, including ResNet50, InceptionV3, and DenseNet201, whilemaintaining computational efficiency. The proposed lightweight ensemble modelpresents a highly effective and resource-efficient solution for pneumoniadetection, making it particularly suitable for deployment inresource-constrained settings.</description><author>Suresh Babu Nettur, Shanthi Karpurapu, Unnati Nettur, Likhit Sagar Gajja, Sravanthy Myneni, Akhil Dusi, Lalithya Posham</author><pubDate>Mon, 27 Jan 2025 17:51:29 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.16249v1</guid></item><item><title>Gaussian entropic optimal transport: Schrödinger bridges and the Sinkhorn algorithm</title><link>http://arxiv.org/abs/2412.18432v2</link><description>Entropic optimal transport problems are regularized versions of optimaltransport problems. These models play an increasingly important role in machinelearning and generative modelling. For finite spaces, these problems arecommonly solved using Sinkhorn algorithm (a.k.a. iterative proportional fittingprocedure). However, in more general settings the Sinkhorn iterations are basedon nonlinear conditional/conjugate transformations and exact finite-dimensionalsolutions cannot be computed. This article presents a finite-dimensionalrecursive formulation of the iterative proportional fitting procedure forgeneral Gaussian multivariate models. As expected, this recursive formulationis closely related to the celebrated Kalman filter and related Riccati matrixdifference equations, and it yields algorithms that can be implemented inpractical settings without further approximations. We extend this filteringmethodology to develop a refined and self-contained convergence analysis ofGaussian Sinkhorn algorithms, including closed form expressions of entropictransport maps and Schr\"odinger bridges.</description><author>O. Deniz Akyildiz, Pierre Del Moral, Joaquín Miguez</author><pubDate>Mon, 27 Jan 2025 17:50:26 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.18432v2</guid></item><item><title>Zero-Shot Decision Tree Construction via Large Language Models</title><link>http://arxiv.org/abs/2501.16247v1</link><description>This paper introduces a novel algorithm for constructing decision trees usinglarge language models (LLMs) in a zero-shot manner based on Classification andRegression Trees (CART) principles. Traditional decision tree induction methodsrely heavily on labeled data to recursively partition data using criteria suchas information gain or the Gini index. In contrast, we propose a method thatuses the pre-trained knowledge embedded in LLMs to build decision trees withoutrequiring training data. Our approach leverages LLMs to perform operationsessential for decision tree construction, including attribute discretization,probability calculation, and Gini index computation based on the probabilities.We show that these zero-shot decision trees can outperform baseline zero-shotmethods and achieve competitive performance compared to supervised data-drivendecision trees on tabular datasets. The decision trees constructed via thismethod provide transparent and interpretable models, addressing data scarcitywhile preserving interpretability. This work establishes a new baseline inlow-data machine learning, offering a principled, knowledge-driven alternativeto data-driven tree construction.</description><author>Lucas Carrasco, Felipe Urrutia, Andrés Abeliuk</author><pubDate>Mon, 27 Jan 2025 17:48:48 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.16247v1</guid></item><item><title>CLISC: Bridging clip and sam by enhanced cam for unsupervised brain tumor segmentation</title><link>http://arxiv.org/abs/2501.16246v1</link><description>Brain tumor segmentation is important for diagnosis of the tumor, and currentdeep-learning methods rely on a large set of annotated images for training,with high annotation costs. Unsupervised segmentation is promising to avoidhuman annotations while the performance is often limited. In this study, wepresent a novel unsupervised segmentation approach that leverages thecapabilities of foundation models, and it consists of three main steps: (1) Avision-language model (i.e., CLIP) is employed to obtain image-levelpseudo-labels for training a classification network. Class Activation Mapping(CAM) is then employed to extract Regions of Interest (ROIs), where an adaptivemasking-based data augmentation is used to enhance ROI identification.(2) TheROIs are used to generate bounding box and point prompts for the SegmentAnything Model (SAM) to obtain segmentation pseudo-labels. (3) A 3Dsegmentation network is trained with the SAM-derived pseudo-labels, wherelow-quality pseudo-labels are filtered out in a self-learning process based onthe similarity between the SAM's output and the network's prediction.Evaluation on the BraTS2020 dataset demonstrates that our approach obtained anaverage Dice Similarity Score (DSC) of 85.60%, outperforming fivestate-of-the-art unsupervised segmentation methods by more than 10 percentagepoints. Besides, our approach outperforms directly using SAM for zero-shotinference, and its performance is close to fully supervised learning.</description><author>Xiaochuan Ma, Jia Fu, Wenjun Liao, Shichuan Zhang, Guotai Wang</author><pubDate>Mon, 27 Jan 2025 17:43:51 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.16246v1</guid></item><item><title>From Dashcam Videos to Driving Simulations: Stress Testing Automated Vehicles against Rare Events</title><link>http://arxiv.org/abs/2411.16027v2</link><description>Testing Automated Driving Systems (ADS) in simulation with realistic drivingscenarios is important for verifying their performance. However, convertingreal-world driving videos into simulation scenarios is a significant challengedue to the complexity of interpreting high-dimensional video data and thetime-consuming nature of precise manual scenario reconstruction. In this work,we propose a novel framework that automates the conversion of real-world carcrash videos into detailed simulation scenarios for ADS testing. Our approachleverages prompt-engineered Video Language Models(VLM) to transform dashcamfootage into SCENIC scripts, which define the environment and driving behaviorsin the CARLA simulator, enabling the generation of realistic simulationscenarios. Importantly, rather than solely aiming for one-to-one scenarioreconstruction, our framework focuses on capturing the essential drivingbehaviors from the original video while offering flexibility in parameters suchas weather or road conditions to facilitate search-based testing. Additionally,we introduce a similarity metric that helps iteratively refine the generatedscenario through feedback by comparing key features of driving behaviorsbetween the real and simulated videos. Our preliminary results demonstratesubstantial time efficiency, finishing the real-to-sim conversion in minuteswith full automation and no human intervention, while maintaining high fidelityto the original driving events.</description><author>Yan Miao, Georgios Fainekos, Bardh Hoxha, Hideki Okamoto, Danil Prokhorov, Sayan Mitra</author><pubDate>Mon, 27 Jan 2025 17:43:42 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2411.16027v2</guid></item><item><title>Accelerating Quantum Reinforcement Learning with a Quantum Natural Policy Gradient Based Approach</title><link>http://arxiv.org/abs/2501.16243v1</link><description>We address the problem of quantum reinforcement learning (QRL) undermodel-free settings with quantum oracle access to the Markov Decision Process(MDP). This paper introduces a Quantum Natural Policy Gradient (QNPG)algorithm, which replaces the random sampling used in classical Natural PolicyGradient (NPG) estimators with a deterministic gradient estimation approach,enabling seamless integration into quantum systems. While this modificationintroduces a bounded bias in the estimator, the bias decays exponentially withincreasing truncation levels. This paper demonstrates that the proposed QNPGalgorithm achieves a sample complexity of$\tilde{\mathcal{O}}(\epsilon^{-1.5})$ for queries to the quantum oracle,significantly improving the classical lower bound of$\tilde{\mathcal{O}}(\epsilon^{-2})$ for queries to the MDP.</description><author>Yang Xu, Vaneet Aggarwal</author><pubDate>Mon, 27 Jan 2025 17:38:30 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.16243v1</guid></item><item><title>Community Detection for Contextual-LSBM: Theoretical Limitations of Misclassification Rate and Efficient Algorithms</title><link>http://arxiv.org/abs/2501.11139v3</link><description>The integration of network information and node attribute information hasrecently gained significant attention in the community detection literature. Inthis work, we consider community detection in the Contextual Labeled StochasticBlock Model (CLSBM), where the network follows an LSBM and node attributesfollow a Gaussian Mixture Model (GMM). Our primary focus is themisclassification rate, which measures the expected number of nodesmisclassified by community detection algorithms. We first establish a lowerbound on the optimal misclassification rate that holds for any algorithm. Whenwe specialize our setting to the LSBM (which preserves only networkinformation) or the GMM (which preserves only node attribute information), ourlower bound recovers prior results. Moreover, we present an efficientspectral-based algorithm tailored for the CLSBM and derive an upper bound onits misclassification rate. Although the algorithm does not attain the lowerbound, it serves as a reliable starting point for designing more accuratecommunity detection algorithms (as many algorithms use spectral method as aninitial step, followed by refinement procedures to enhance accuracy).</description><author>Dian Jin, Yuqian Zhang, Qiaosheng Zhang</author><pubDate>Mon, 27 Jan 2025 17:38:03 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.11139v3</guid></item><item><title>Phase Transitions in Large Language Models and the $O(N)$ Model</title><link>http://arxiv.org/abs/2501.16241v1</link><description>Large language models (LLMs) exhibit unprecedentedly rich scaling behaviors.In physics, scaling behavior is closely related to phase transitions, criticalphenomena, and field theory. To investigate the phase transition phenomena inLLMs, we reformulated the Transformer architecture as an $O(N)$ model. Ourstudy reveals two distinct phase transitions corresponding to the temperatureused in text generation and the model's parameter size, respectively. The firstphase transition enables us to estimate the internal dimension of the model,while the second phase transition is of \textit{higher-depth} and signals theemergence of new capabilities. As an application, the energy of the $O(N)$model can be used to evaluate whether an LLM's parameters are sufficient tolearn the training data.</description><author>Youran Sun, Babak Haghighat</author><pubDate>Mon, 27 Jan 2025 17:36:06 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.16241v1</guid></item><item><title>Distilling foundation models for robust and efficient models in digital pathology</title><link>http://arxiv.org/abs/2501.16239v1</link><description>In recent years, the advent of foundation models (FM) for digital pathologyhas relied heavily on scaling the pre-training datasets and the model size,yielding large and powerful models. While it resulted in improving theperformance on diverse downstream tasks, it also introduced increasedcomputational cost and inference time. In this work, we explore thedistillation of a large foundation model into a smaller one, reducing thenumber of parameters by several orders of magnitude. Leveraging distillationtechniques, our distilled model, H0-mini, achieves nearly comparableperformance to large FMs at a significantly reduced inference cost. It isevaluated on several public benchmarks, achieving 3rd place on the HESTbenchmark and 5th place on the EVA benchmark. Additionally, a robustnessanalysis conducted on the PLISM dataset demonstrates that our distilled modelreaches excellent robustness to variations in staining and scanning conditions,significantly outperforming other state-of-the art models. This opens newperspectives to design lightweight and robust models for digital pathology,without compromising on performance.</description><author>Alexandre Filiot, Nicolas Dop, Oussama Tchita, Auriane Riou, Thomas Peeters, Daria Valter, Marin Scalbert, Charlie Saillard, Geneviève Robin, Antoine Olivier</author><pubDate>Mon, 27 Jan 2025 17:35:39 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.16239v1</guid></item><item><title>Application of Structured State Space Models to High energy physics with locality-sensitive hashing</title><link>http://arxiv.org/abs/2501.16237v1</link><description>Modern high-energy physics (HEP) experiments are increasingly challenged bythe vast size and complexity of their datasets, particularly regardinglarge-scale point cloud processing and long sequences. In this study, toaddress these challenges, we explore the application of structured state spacemodels (SSMs), proposing one of the first trials to integrate local-sensitivehashing into either a hybrid or pure Mamba Model. Our results demonstrate thatpure SSMs could serve as powerful backbones for HEP problems involving tasksfor long sequence data with local inductive bias. By integratinglocality-sensitive hashing into Mamba blocks, we achieve significantimprovements over traditional backbones in key HEP tasks, surpassing them ininference speed and physics metrics while reducing computational overhead. Inkey tests, our approach demonstrated promising results, presenting a viablealternative to traditional transformer backbones by significantly reducingFLOPS while maintaining robust performance.</description><author>Cheng Jiang, Sitian Qian</author><pubDate>Mon, 27 Jan 2025 17:34:04 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.16237v1</guid></item><item><title>Echoes of Discord: Forecasting Hater Reactions to Counterspeech</title><link>http://arxiv.org/abs/2501.16235v1</link><description>Hate speech (HS) erodes the inclusiveness of online users and propagatesnegativity and division. Counterspeech has been recognized as a way to mitigatethe harmful consequences. While some research has investigated the impact ofuser-generated counterspeech on social media platforms, few have examined andmodeled haters' reactions toward counterspeech, despite the immediatealteration of haters' attitudes being an important aspect of counterspeech.This study fills the gap by analyzing the impact of counterspeech from thehater's perspective, focusing on whether the counterspeech leads the hater toreenter the conversation and if the reentry is hateful. We compile the RedditEchoes of Hate dataset (ReEco), which consists of triple-turn conversationsfeaturing haters' reactions, to assess the impact of counterspeech. Thelinguistic analysis sheds insights on the language of counterspeech to hateeliciting different haters' reactions. Experimental results demonstrate thatthe 3-way classification model outperforms the two-stage reaction predictor,which first predicts reentry and then determines the reentry type. We concludethe study with an assessment showing the most common errors identified by thebest-performing model.</description><author>Xiaoying Song, Sharon Lisseth Perez, Xinchen Yu, Eduardo Blanco, Lingzi Hong</author><pubDate>Mon, 27 Jan 2025 17:33:38 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.16235v1</guid></item><item><title>Enhancing Brain Age Estimation with a Multimodal 3D CNN Approach Combining Structural MRI and AI-Synthesized Cerebral Blood Volume Data</title><link>http://arxiv.org/abs/2412.01865v3</link><description>The increasing global aging population necessitates improved methods toassess brain aging and its related neurodegenerative changes. Brain Age GapEstimation (BrainAGE) offers a neuroimaging biomarker for understanding thesechanges by predicting brain age from MRI scans. Current approaches primarilyuse T1-weighted magnetic resonance imaging (T1w MRI) data, capturing onlystructural brain information. To address this limitation, AI-generated CerebralBlood Volume (AICBV) data, synthesized from non-contrast MRI scans, offersfunctional insights by revealing subtle blood-tissue contrasts otherwiseundetectable in standard imaging. We integrated AICBV with T1w MRI to predictbrain age, combining both structural and functional metrics. We developed adeep learning model using a VGG-based architecture for both modalities andcombined their predictions using linear regression. Our model achieved a meanabsolute error (MAE) of 3.95 years and an $R^2$ of 0.943 on the test set ($n =288$), outperforming existing models trained on similar data. We have furthercreated gradient-based class activation maps (Grad-CAM) to visualize theregions of the brain that most influenced the model's predictions, providinginterpretable insights into the structural and functional contributors to brainaging.</description><author>Jordan Jomsky, Zongyu Li, Yiren Zhang, Tal Nuriel, Jia Guo</author><pubDate>Mon, 27 Jan 2025 17:24:51 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.01865v3</guid></item><item><title>PDC-ViT : Source Camera Identification using Pixel Difference Convolution and Vision Transformer</title><link>http://arxiv.org/abs/2501.16227v1</link><description>Source camera identification has emerged as a vital solution to unlockincidents involving critical cases like terrorism, violence, and other criminalactivities. The ability to trace the origin of an image/video can aid lawenforcement agencies in gathering evidence and constructing the timeline ofevents. Moreover, identifying the owner of a certain device narrows down thearea of search in a criminal investigation where smartphone devices areinvolved. This paper proposes a new pixel-based method for source cameraidentification, integrating Pixel Difference Convolution (PDC) with a VisionTransformer network (ViT), and named PDC-ViT. While the PDC acts as thebackbone for feature extraction by exploiting Angular PDC (APDC) and Radial PDC(RPDC). These techniques enhance the capability to capture subtle variations inpixel information, which are crucial for distinguishing between differentsource cameras. The second part of the methodology focuses on classification,which is based on a Vision Transformer network. Unlike traditional methods thatutilize image patches directly for training the classification network, theproposed approach uniquely inputs PDC features into the Vision Transformernetwork. To demonstrate the effectiveness of the PDC-ViT approach, it has beenassessed on five different datasets, which include various image contents andvideo scenes. The method has also been compared with state-of-the-art sourcecamera identification methods. Experimental results demonstrate theeffectiveness and superiority of the proposed system in terms of accuracy androbustness when compared to its competitors. For example, our proposed PDC-ViThas achieved an accuracy of 94.30%, 84%, 94.22% and 92.29% using the Visiondataset, Daxing dataset, Socrates dataset and QUFVD dataset, respectively.</description><author>Omar Elharrouss, Younes Akbari, Noor Almaadeed, Somaya Al-Maadeed, Fouad Khelifi, Ahmed Bouridane</author><pubDate>Mon, 27 Jan 2025 17:21:33 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.16227v1</guid></item><item><title>The Effect of Optimal Self-Distillation in Noisy Gaussian Mixture Model</title><link>http://arxiv.org/abs/2501.16226v1</link><description>Self-distillation (SD), a technique where a model refines itself from its ownpredictions, has garnered attention as a simple yet powerful approach inmachine learning. Despite its widespread use, the mechanisms underlying itseffectiveness remain unclear. In this study, we investigate the efficacy ofhyperparameter-tuned multi-stage SD in binary classification tasks with noisylabeled Gaussian mixture data, utilizing a replica theory. Our findings revealsthat the primary driver of SD's performance improvement is denoising throughhard pseudo-labels, with the most notable gains observed in moderately sizeddatasets. We also demonstrate the efficacy of practical heuristics, such asearly stopping for extracting meaningful signal and bias fixation forimbalanced data. These results provide both theoretical guarantees andpractical insights, advancing our understanding and application of SD in noisysettings.</description><author>Kaito Takanami, Takashi Takahashi, Ayaka Sakata</author><pubDate>Mon, 27 Jan 2025 17:20:48 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.16226v1</guid></item><item><title>Language-Based Bayesian Optimization Research Assistant (BORA)</title><link>http://arxiv.org/abs/2501.16224v1</link><description>Many important scientific problems involve multivariate optimization coupledwith slow and laborious experimental measurements. These complex,high-dimensional searches can be defined by non-convex optimization landscapesthat resemble needle-in-a-haystack surfaces, leading to entrapment in localminima. Contextualizing optimizers with human domain knowledge is a powerfulapproach to guide searches to localized fruitful regions. However, thisapproach is susceptible to human confirmation bias and it is also challengingfor domain experts to keep track of the rapidly expanding scientificliterature. Here, we propose the use of Large Language Models (LLMs) forcontextualizing Bayesian optimization (BO) via a hybrid optimization frameworkthat intelligently and economically blends stochastic inference with domainknowledge-based insights from the LLM, which is used to suggest new,better-performing areas of the search space for exploration. Our method fostersuser engagement by offering real-time commentary on the optimization progress,explaining the reasoning behind the search strategies. We validate theeffectiveness of our approach on synthetic benchmarks with up to 15 independentvariables and demonstrate the ability of LLMs to reason in four real-worldexperimental tasks where context-aware suggestions boost optimizationperformance substantially.</description><author>Abdoulatif Cissé, Xenophon Evangelopoulos, Vladimir V. Gusev, Andrew I. Cooper</author><pubDate>Mon, 27 Jan 2025 17:20:04 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.16224v1</guid></item><item><title>What Does an Audio Deepfake Detector Focus on? A Study in the Time Domain</title><link>http://arxiv.org/abs/2501.13887v2</link><description>Adding explanations to audio deepfake detection (ADD) models will boost theirreal-world application by providing insight on the decision making process. Inthis paper, we propose a relevancy-based explainable AI (XAI) method to analyzethe predictions of transformer-based ADD models. We compare against standardGrad-CAM and SHAP-based methods, using quantitative faithfulness metrics aswell as a partial spoof test, to comprehensively analyze the relativeimportance of different temporal regions in an audio. We consider largedatasets, unlike previous works where only limited utterances are studied, andfind that the XAI methods differ in their explanations. The proposedrelevancy-based XAI method performs the best overall on a variety of metrics.Further investigation on the relative importance of speech/non-speech, phoneticcontent, and voice onsets/offsets suggest that the XAI results obtained fromanalyzing limited utterances don't necessarily hold when evaluated on largedatasets.</description><author>Petr Grinberg, Ankur Kumar, Surya Koppisetti, Gaurav Bharaj</author><pubDate>Mon, 27 Jan 2025 17:17:08 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.13887v2</guid></item><item><title>Contextual Feedback Loops: Amplifying Deep Reasoning with Iterative Top-Down Feedback</title><link>http://arxiv.org/abs/2412.17737v5</link><description>Conventional deep networks rely on one-way backpropagation that overlooksreconciling high-level predictions with lower-level representations. We propose\emph{Contextual Feedback Loops} (CFLs), a lightweight mechanism thatre-injects top-down context into earlier layers for iterative refinement.Concretely, CFLs map the network's prediction to a compact \emph{contextvector}, which is fused back into each layer via gating adapters. Unrolled overmultiple feedback steps, CFLs unify feed-forward and feedback-driven inference,letting top-level outputs continually refine lower-level features. Despiteminimal overhead, CFLs yield consistent gains on tasks including CIFAR-10,ImageNet-1k, SpeechCommands, and GLUE SST-2. Moreover, by a Banach Fixed Pointargument under mild Lipschitz conditions, these updates converge stably.Overall, CFLs show that even modest top-down feedback can substantially improvedeep models, aligning with cognitive theories of iterative perception.</description><author>Jacob Fein-Ashley, Rajgopal Kannan, Viktor Prasanna</author><pubDate>Mon, 27 Jan 2025 17:14:45 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.17737v5</guid></item><item><title>Statistical Inference for Low-Rank Tensor Models</title><link>http://arxiv.org/abs/2501.16223v1</link><description>Statistical inference for tensors has emerged as a critical challenge inanalyzing high-dimensional data in modern data science. This paper introduces aunified framework for inferring general and low-Tucker-rank linear functionalsof low-Tucker-rank signal tensors for several low-rank tensor models. Ourmethodology tackles two primary goals: achieving asymptotic normality andconstructing minimax-optimal confidence intervals. By leveraging a debiasingstrategy and projecting onto the tangent space of the low-Tucker-rank manifold,we enable inference for general and structured linear functionals, extendingfar beyond the scope of traditional entrywise inference. Specifically, in thelow-Tucker-rank tensor regression or PCA model, we establish the computationaland statistical efficiency of our approach, achieving near-optimal sample sizerequirements (in regression model) and signal-to-noise ratio (SNR) conditions(in PCA model) for general linear functionals without requiring sparsity in theloading tensor. Our framework also attains both computationally andstatistically optimal sample size and SNR thresholds for low-Tucker-rank linearfunctionals. Numerical experiments validate our theoretical results, showcasingthe framework's utility in diverse applications. This work addressessignificant methodological gaps in statistical inference, advancing tensoranalysis for complex and high-dimensional data environments.</description><author>Ke Xu, Elynn Chen, Yuefeng Han</author><pubDate>Mon, 27 Jan 2025 17:14:35 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.16223v1</guid></item><item><title>SPECIAL: Zero-shot Hyperspectral Image Classification With CLIP</title><link>http://arxiv.org/abs/2501.16222v1</link><description>Hyperspectral image (HSI) classification aims at categorizing each pixel inan HSI into a specific land cover class, which is crucial for applications likeremote sensing, environmental monitoring, and agriculture. Although deeplearning-based HSI classification methods have achieved significantadvancements, existing methods still rely on manually labeled data fortraining, which is both time-consuming and labor-intensive.To address thislimitation, we introduce a novel zero-shot hyperspectral image classificationframework based on CLIP (SPECIAL), aiming to eliminate the need for manualannotations. The SPECIAL framework consists of two main stages: (1) CLIP-basedpseudo-label generation, and (2) noisy label learning. In the first stage, HSIis spectrally interpolated to produce RGB bands. These bands are subsequentlyclassified using CLIP, resulting in noisy pseudo-labels that are accompanied byconfidence scores.To improve the quality of these labels, we propose a scalingstrategy that fuses predictions from multiple spatial scales. In the secondstage, spectral information and a label refinement technique are incorporatedto mitigate label noise and further enhance classification accuracy.Experimental results on three benchmark datasets demonstrate that our SPECIALoutperforms existing methods in zero-shot HSI classification, showing itspotential for more practical applications. The code is available athttps://github.com/LiPang/SPECIAL.</description><author>Li Pang, Jing Yao, Kaiyu Li, Xiangyong Cao</author><pubDate>Mon, 27 Jan 2025 17:13:03 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.16222v1</guid></item><item><title>Automatic Calibration of a Multi-Camera System with Limited Overlapping Fields of View for 3D Surgical Scene Reconstruction</title><link>http://arxiv.org/abs/2501.16221v1</link><description>Purpose: The purpose of this study is to develop an automated and accurateexternal camera calibration method for multi-camera systems used in 3D surgicalscene reconstruction (3D-SSR), eliminating the need for operator interventionor specialized expertise. The method specifically addresses the problem oflimited overlapping fields of view caused by significant variations in opticalzoom levels and camera locations. Methods: We contribute a novel, fast, and fully automatic calibration methodbased on the projection of multi-scale markers (MSMs) using a ceiling-mountedprojector. MSMs consist of 2D patterns projected at varying scales, ensuringaccurate extraction of well distributed point correspondences acrosssignificantly different viewpoints and zoom levels. Validation is performedusing both synthetic and real data captured in a mock-up OR, with comparisonsto traditional manual marker-based methods as well as markerless calibrationmethods. Results: The method achieves accuracy comparable to manual,operator-dependent calibration methods while exhibiting higher robustness underconditions of significant differences in zoom levels. Additionally, we showthat state-of-the-art Structure-from-Motion (SfM) pipelines are ineffective in3D-SSR settings, even when additional texture is projected onto the OR floor. Conclusion: The use of a ceiling-mounted entry-level projector proves to bean effective alternative to operator-dependent, traditional marker-basedmethods, paving the way for fully automated 3D-SSR.</description><author>Tim Flückiger, Jonas Hein, Valery Fischer, Philipp Fürnstahl, Lilian Calvet</author><pubDate>Mon, 27 Jan 2025 17:10:33 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.16221v1</guid></item><item><title>DBRouting: Routing End User Queries to Databases for Answerability</title><link>http://arxiv.org/abs/2501.16220v1</link><description>Enterprise level data is often distributed across multiple sources andidentifying the correct set-of data-sources with relevant information for aknowledge request is a fundamental challenge. In this work, we define the noveltask of routing an end-user query to the appropriate data-source, where thedata-sources are databases. We synthesize datasets by extending existingdatasets designed for NL-to-SQL semantic parsing. We create baselines on thesedatasets by using open-source LLMs, using both pre-trained and task specificembeddings fine-tuned using the training data. With these baselines wedemonstrate that open-source LLMs perform better than embedding based approach,but suffer from token length limitations. Embedding based approaches benefitfrom task specific fine-tuning, more so when there is availability of data interms of database specific questions for training. We further find that thetask becomes more difficult (i) with an increase in the number of data-sources,(ii) having data-sources closer in terms of their domains,(iii) havingdatabases without external domain knowledge required to interpret its entitiesand (iv) with ambiguous and complex queries requiring more fine-grainedunderstanding of the data-sources or logical reasoning for routing to anappropriate source. This calls for the need for developing more sophisticatedsolutions to better address the task.</description><author>Priyangshu Mandal, Manasi Patwardhan, Mayur Patidar, Lovekesh Vig</author><pubDate>Mon, 27 Jan 2025 17:09:47 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.16220v1</guid></item><item><title>Enhancing Visual Inspection Capability of Multi-Modal Large Language Models on Medical Time Series with Supportive Conformalized and Interpretable Small Specialized Models</title><link>http://arxiv.org/abs/2501.16215v1</link><description>Large language models (LLMs) exhibit remarkable capabilities in visualinspection of medical time-series data, achieving proficiency comparable tohuman clinicians. However, their broad scope limits domain-specific precision,and proprietary weights hinder fine-tuning for specialized datasets. Incontrast, small specialized models (SSMs) excel in targeted tasks but lack thecontextual reasoning required for complex clinical decision-making. To addressthese challenges, we propose ConMIL (Conformalized Multiple Instance Learning),a decision-support SSM that integrates seamlessly with LLMs. By using MultipleInstance Learning (MIL) to identify clinically significant signal segments andconformal prediction for calibrated set-valued outputs, ConMIL enhances LLMs'interpretative capabilities for medical time-series analysis. Experimentalresults demonstrate that ConMIL significantly improves the performance ofstate-of-the-art LLMs, such as ChatGPT4.0 and Qwen2-VL-7B. Specifically,\ConMIL{}-supported Qwen2-VL-7B achieves 94.92% and 96.82% precision forconfident samples in arrhythmia detection and sleep staging, compared tostandalone LLM accuracy of 46.13% and 13.16%. These findings highlight thepotential of ConMIL to bridge task-specific precision and broader contextualreasoning, enabling more reliable and interpretable AI-driven clinical decisionsupport.</description><author>Huayu Li, Xiwen Chen, Ci Zhang, Stuart F. Quan, William D. S. Killgore, Shu-Fen Wung, Chen X. Chen, Geng Yuan, Jin Lu, Ao Li</author><pubDate>Mon, 27 Jan 2025 17:07:20 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.16215v1</guid></item><item><title>Provence: efficient and robust context pruning for retrieval-augmented generation</title><link>http://arxiv.org/abs/2501.16214v1</link><description>Retrieval-augmented generation improves various aspects of large languagemodels (LLMs) generation, but suffers from computational overhead caused bylong contexts as well as the propagation of irrelevant retrieved informationinto generated responses. Context pruning deals with both aspects, by removingirrelevant parts of retrieved contexts before LLM generation. Existing contextpruning approaches are however limited, and do not provide a universal modelthat would be both efficient and robust in a wide range of scenarios, e.g.,when contexts contain a variable amount of relevant information or vary inlength, or when evaluated on various domains. In this work, we close this gapand introduce Provence (Pruning and Reranking Of retrieVEd relevaNt ContExts),an efficient and robust context pruner for Question Answering, whichdynamically detects the needed amount of pruning for a given context and can beused out-of-the-box for various domains. The three key ingredients of Provenceare formulating the context pruning task as sequence labeling, unifying contextpruning capabilities with context reranking, and training on diverse data. Ourexperimental results show that Provence enables context pruning with negligibleto no drop in performance, in various domains and settings, at almost no costin a standard RAG pipeline. We also conduct a deeper analysis alongside variousablations to provide insights into training context pruners for future work.</description><author>Nadezhda Chirkova, Thibault Formal, Vassilina Nikoulina, Stéphane Clinchant</author><pubDate>Mon, 27 Jan 2025 17:06:56 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.16214v1</guid></item><item><title>Large Language Model-based Augmentation for Imbalanced Node Classification on Text-Attributed Graphs</title><link>http://arxiv.org/abs/2410.16882v2</link><description>Node classification on graphs often suffers from class imbalance, leading tobiased predictions and significant risks in real-world applications. Whiledata-centric solutions have been explored, they largely overlookText-Attributed Graphs (TAGs) and the potential of using rich textual semanticsto improve the classification of minority nodes. Given this gap, we proposeLarge Language Model-based Augmentation on Text-Attributed Graphs (LA-TAG), anovel framework that leverages Large Language Models (LLMs) to handleimbalanced node classification. Specifically, we develop prompting strategiesinspired by interpolation to synthesize textual node attributes. Additionally,to effectively integrate synthetic nodes into the graph structure, we introducea textual link predictor that connects the generated nodes to the originalgraph, preserving structural and contextual information. Experiments acrossvarious datasets and evaluation metrics demonstrate that LA-TAG outperformsexisting textual augmentation and graph imbalance learning methods, emphasizingthe efficacy of our approach in addressing class imbalance in TAGs.</description><author>Leyao Wang, Yu Wang, Bo Ni, Yuying Zhao, Tyler Derr</author><pubDate>Mon, 27 Jan 2025 17:06:48 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.16882v2</guid></item><item><title>From Cool Demos to Production-Ready FMware: Core Challenges and a Technology Roadmap</title><link>http://arxiv.org/abs/2410.20791v2</link><description>The rapid expansion of foundation models (FMs), such as large language models(LLMs), has given rise to FMware--software systems that integrate FMs as corecomponents. While building demonstration-level FMware is relativelystraightforward, transitioning to production-ready systems presents numerouschallenges, including reliability, high implementation costs, scalability, andcompliance with privacy regulations. Our paper conducts a semi-structuredthematic synthesis to identify the key challenges in productionizing FMwareacross diverse data sources including our own industry experience in developingFMArts--a FMware lifecycle engineering platform and integrating it into Huaweicloud, grey literature, academic publications, hands-on involvement in the OpenPlatform for Enterprise AI (OPEA), organizing the AIware conference andBootcamp, and co-leading the ISO SPDX SBOM working group on AI and datasets. Weidentify critical issues in FM selection, data and model alignment, promptengineering, agent orchestration, system testing, and deployment, alongsidecross-cutting concerns such as memory management, observability, and feedbackintegration. We discuss needed technologies and strategies to address thesechallenges and offer guidance on how to enable the transition fromdemonstration systems to scalable, production-ready FMware solutions. Ourfindings underscore the importance of continued research and multi-industrycollaboration to advance the development of production-ready FMware.</description><author>Gopi Krishnan Rajbahadur, Gustavo A. Oliva, Dayi Lin, Ahmed E. Hassan</author><pubDate>Mon, 27 Jan 2025 17:05:55 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.20791v2</guid></item><item><title>An FPGA-Based Neuro-Fuzzy Sensor for Personalized Driving Assistance</title><link>http://arxiv.org/abs/2501.16212v1</link><description>Advanced driving-assistance systems (ADAS) are intended to automatize drivertasks, as well as improve driving and vehicle safety. This work proposes anintelligent neuro-fuzzy sensor for driving style (DS) recognition, suitable forADAS enhancement. The development of the driving style intelligent sensor usesnaturalistic driving data from the SHRP2 study, which includes data from a CANbus, inertial measurement unit, and front radar. The system has beensuccessfully implemented using a field-programmable gate array (FPGA) device ofthe Xilinx Zynq programmable system-on-chip (PSoC). It can mimic the typicaltiming parameters of a group of drivers as well as tune these typicalparameters to model individual DSs. The neuro-fuzzy intelligent sensor provideshigh-speed real-time active ADAS implementation and is able to personalize itsbehavior into safe margins without driver intervention. In particular, thepersonalization procedure of the time headway (THW) parameter for an ACC insteady car following was developed, achieving a performance of 0.53microseconds. This performance fulfilled the requirements of cutting-edgeactive ADAS specifications.</description><author>Óscar Mata-Carballeira, Jon Gutiérrez-Zaballa, Inés del Campo, Victoria Martínez</author><pubDate>Mon, 27 Jan 2025 17:04:12 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.16212v1</guid></item><item><title>UDBE: Unsupervised Diffusion-based Brightness Enhancement in Underwater Images</title><link>http://arxiv.org/abs/2501.16211v1</link><description>Activities in underwater environments are paramount in several scenarios,which drives the continuous development of underwater image enhancementtechniques. A major challenge in this domain is the depth at which images arecaptured, with increasing depth resulting in a darker environment. Mostexisting methods for underwater image enhancement focus on noise removal andcolor adjustment, with few works dedicated to brightness enhancement. This workintroduces a novel unsupervised learning approach to underwater imageenhancement using a diffusion model. Our method, called UDBE, is based onconditional diffusion to maintain the brightness details of the unpaired inputimages. The input image is combined with a color map and a Signal-NoiseRelation map (SNR) to ensure stable training and prevent color distortion inthe output images. The results demonstrate that our approach achieves animpressive accuracy rate in the datasets UIEB, SUIM and RUIE, well-establishedunderwater image benchmarks. Additionally, the experiments validate therobustness of our approach, regarding the image quality metrics PSNR, SSIM,UIQM, and UISM, indicating the good performance of the brightness enhancementprocess. The source code is available here: https://github.com/gusanagy/UDBE.</description><author>Tatiana Taís Schein, Gustavo Pereira de Almeira, Stephanie Loi Brião, Rodrigo Andrade de Bem, Felipe Gomes de Oliveira, Paulo L. J. Drews-Jr</author><pubDate>Mon, 27 Jan 2025 17:01:45 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.16211v1</guid></item><item><title>Solving Turbulent Rayleigh-Bénard Convection using Fourier Neural Operators</title><link>http://arxiv.org/abs/2501.16209v1</link><description>We train Fourier Neural Operator (FNO) surrogate models for Rayleigh-B\'enardConvection (RBC), a model for convection processes that occur in nature andindustrial settings. We compare the prediction accuracy and model properties ofFNO surrogates to two popular surrogates used in fluid dynamics: the DynamicMode Decomposition and the Linearly-Recurrent Autoencoder Network. We regardDirect Numerical Simulations (DNS) of the RBC equations as the ground truth onwhich the models are trained and evaluated in different settings. The FNOperforms favorably when compared to the DMD and LRAN and its predictions arefast and highly accurate for this task. Additionally, we show its zero-shotsuper-resolution ability for the convection dynamics. The FNO model has a highpotential to be used in downstream tasks such as flow control in RBC.</description><author>Michiel Straat, Thorben Markmann, Barbara Hammer</author><pubDate>Mon, 27 Jan 2025 17:01:27 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.16209v1</guid></item><item><title>From Informal to Formal -- Incorporating and Evaluating LLMs on Natural Language Requirements to Verifiable Formal Proofs</title><link>http://arxiv.org/abs/2501.16207v1</link><description>The research in AI-based formal mathematical reasoning has shown anunstoppable growth trend. These studies have excelled in mathematicalcompetitions like IMO, showing significant progress. However, these studiesintertwined multiple skills simultaneously, i.e., problem-solving, reasoning,and writing formal specifications, making it hard to precisely identify theLLMs' strengths and weaknesses in each task. This paper focuses on formalverification, an immediate application scenario of formal reasoning, anddecomposes it into six sub-tasks. We constructed 18k high-qualityinstruction-response pairs across five mainstream formal specificationlanguages (Coq, Lean4, Dafny, ACSL, and TLA+) in sixformal-verification-related tasks by distilling GPT-4o. They are split into a14k+ fine-tuning dataset FM-alpaca and a 4k benchmark FM-Bench. We found thatLLMs are good at writing proof segments when given either the code, or thedetailed description of proof steps. Also, the fine-tuning brought about anearly threefold improvement at most. Interestingly, we observed thatfine-tuning with formal data also enhances mathematics, reasoning, and codingabilities. We hope our findings inspire further research. Fine-tuned models arereleased to facilitate subsequent studies</description><author>Jialun Cao, Yaojie Lu, Meiziniu Li, Haoyang Ma, Haokun Li, Mengda He, Cheng Wen, Le Sun, Hongyu Zhang, Shengchao Qin, Shing-Chi Cheung, Cong Tian</author><pubDate>Mon, 27 Jan 2025 17:00:56 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.16207v1</guid></item><item><title>Discrete Lagrangian Neural Networks with Automatic Symmetry Discovery</title><link>http://arxiv.org/abs/2211.10830v2</link><description>By one of the most fundamental principles in physics, a dynamical system willexhibit those motions which extremise an action functional. This leads to theformation of the Euler-Lagrange equations, which serve as a model of how thesystem will behave in time. If the dynamics exhibit additional symmetries, thenthe motion fulfils additional conservation laws, such as conservation of energy(time invariance), momentum (translation invariance), or angular momentum(rotational invariance). To learn a system representation, one could learn thediscrete Euler-Lagrange equations, or alternatively, learn the discreteLagrangian function $\mathcal{L}_d$ which defines them. Based on ideas from Liegroup theory, in this work we introduce a framework to learn a discreteLagrangian along with its symmetry group from discrete observations of motionsand, therefore, identify conserved quantities. The learning process does notrestrict the form of the Lagrangian, does not require velocity or momentumobservations or predictions and incorporates a cost term which safeguardsagainst unwanted solutions and against potential numerical issues in forwardsimulations. The learnt discrete quantities are related to their continuousanalogues using variational backward error analysis and numerical resultsdemonstrate the improvement such models can have both qualitatively andquantitatively even in the presence of noise.</description><author>Yana Lishkova, Paul Scherer, Steffen Ridderbusch, Mateja Jamnik, Pietro Liò, Sina Ober-Blöbaum, Christian Offen</author><pubDate>Mon, 27 Jan 2025 16:56:29 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2211.10830v2</guid></item><item><title>Does Generative AI speak Nigerian-Pidgin?: Issues about Representativeness and Bias for Multilingualism in LLMs</title><link>http://arxiv.org/abs/2404.19442v3</link><description>Nigeria is a multilingual country with 500+ languages. Naija is aNigerian-Pidgin spoken by approx. 120M speakers in Nigeria and it is a mixedlanguage (e.g., English, Portuguese, Yoruba, Hausa and Igbo). Although it hasmainly been a spoken language until recently, there are now various platformspublishing exclusively in Naija such as Naija Wikipedia. However, it is hard todistinguish by non-native from a larger pidgin languages spoken across WestAfrica known as West African Pidgin English (WAPE) -- which is more simpliedand understandable by wider audience in Ghana, Nigeria, and Cameroon. BBC newsplatform publishes exclusively in WAPE to cater for several countries in WestAfrica. In our paper, we show through statistical analyses and MachineTranslation experiments that these two creole varieties do not represent eachother (i.e., there are linguistic differences in word order and vocabulary) andGenerative AI operates only based on WAPE. In other words, Naija isunder-represented in Generative AI, and it is hard to teach LLMs with fewexamples.</description><author>David Ifeoluwa Adelani, A. Seza Doğruöz, Iyanuoluwa Shode, Anuoluwapo Aremu</author><pubDate>Mon, 27 Jan 2025 16:55:57 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.19442v3</guid></item><item><title>Enhancing and Exploring Mild Cognitive Impairment Detection with W2V-BERT-2.0</title><link>http://arxiv.org/abs/2501.16201v1</link><description>This study explores a multi-lingual audio self-supervised learning model fordetecting mild cognitive impairment (MCI) using the TAUKADIAL cross-lingualdataset. While speech transcription-based detection with BERT models iseffective, limitations exist due to a lack of transcriptions and temporalinformation. To address these issues, the study utilizes features directly fromspeech utterances with W2V-BERT-2.0. We propose a visualization method todetect essential layers of the model for MCI classification and design aspecific inference logic considering the characteristics of MCI. The experimentshows competitive results, and the proposed inference logic significantlycontributes to the improvements from the baseline. We also conduct detailedanalysis which reveals the challenges related to speaker bias in the featuresand the sensitivity of MCI classification accuracy to the data split, providingvaluable insights for future research.</description><author>Yueguan Wang, Tatsunari Matsushima, Soichiro Matsushima, Toshimitsu Sakai</author><pubDate>Mon, 27 Jan 2025 16:55:38 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.16201v1</guid></item><item><title>Federated Granger Causality Learning for Interdependent Clients with State Space Representation</title><link>http://arxiv.org/abs/2501.13890v2</link><description>Advanced sensors and IoT devices have improved the monitoring and control ofcomplex industrial enterprises. They have also created an interdependent fabricof geographically distributed process operations (clients) across theseenterprises. Granger causality is an effective approach to detect and quantifyinterdependencies by examining how one client's state affects others over time.Understanding these interdependencies captures how localized events, such asfaults and disruptions, can propagate throughout the system, possibly causingwidespread operational impacts. However, the large volume and complexity ofindustrial data pose challenges in modeling these interdependencies. This paperdevelops a federated approach to learning Granger causality. We utilize alinear state space system framework that leverages low-dimensional stateestimates to analyze interdependencies. This addresses bandwidth limitationsand the computational burden commonly associated with centralized dataprocessing. We propose augmenting the client models with the Granger causalityinformation learned by the server through a Machine Learning (ML) function. Weexamine the co-dependence between the augmented client and server models andreformulate the framework as a standalone ML algorithm providing conditions forits sublinear and linear convergence rates. We also study the convergence ofthe framework to a centralized oracle model. Moreover, we include adifferential privacy analysis to ensure data security while preserving causalinsights. Using synthetic data, we conduct comprehensive experiments todemonstrate the robustness of our approach to perturbations in causality, thescalability to the size of communication, number of clients, and the dimensionsof raw data. We also evaluate the performance on two real-world industrialcontrol system datasets by reporting the volume of data saved bydecentralization.</description><author>Ayush Mohanty, Nazal Mohamed, Paritosh Ramanan, Nagi Gebraeel</author><pubDate>Mon, 27 Jan 2025 16:49:19 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.13890v2</guid></item><item><title>Raiders of the Lost Dependency: Fixing Dependency Conflicts in Python using LLMs</title><link>http://arxiv.org/abs/2501.16191v1</link><description>Fixing Python dependency issues is a tedious and error-prone task fordevelopers, who must manually identify and resolve environment dependencies andversion constraints of third-party modules and Python interpreters. Researchershave attempted to automate this process by relying on large knowledge graphsand database lookup tables. However, these traditional approaches facelimitations due to the variety of dependency error types, large sets ofpossible module versions, and conflicts among transitive dependencies. Thisstudy explores the potential of using large language models (LLMs) toautomatically fix dependency issues in Python programs. We introduce PLLM(pronounced "plum"), a novel technique that employs retrieval-augmentedgeneration (RAG) to help an LLM infer Python versions and required modules fora given Python file. PLLM builds a testing environment that iteratively (1)prompts the LLM for module combinations, (2) tests the suggested changes, and(3) provides feedback (error messages) to the LLM to refine the fix. Thisfeedback cycle leverages natural language processing (NLP) to intelligentlyparse and interpret build error messages. We benchmark PLLM on the GistableHG2.9K dataset, a collection of challenging single-file Python gists. Wecompare PLLM against two state-of-the-art automatic dependency inferenceapproaches, namely PyEGo and ReadPyE, w.r.t. the ability to resolve dependencyissues. Our results indicate that PLLM can fix more dependency issues than thetwo baselines, with +218 (+15.97%) more fixes over ReadPyE and +281 (+21.58%)over PyEGo. Our deeper analyses suggest that PLLM is particularly beneficialfor projects with many dependencies and for specific third-party numerical andmachine-learning modules. Our findings demonstrate the potential of LLM-basedapproaches to iteratively resolve Python dependency issues.</description><author>Antony Bartlett, Cynthia Liem, Annibale Panichella</author><pubDate>Mon, 27 Jan 2025 16:45:34 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.16191v1</guid></item><item><title>Learn to Optimize Resource Allocation under QoS Constraint of AR</title><link>http://arxiv.org/abs/2501.16186v1</link><description>This paper studies the uplink and downlink power allocation for interactiveaugmented reality (AR) services, where live video captured by an AR device isuploaded to the network edge and then the augmented video is subsequentlydownloaded. By modeling the AR transmission process as a tandem queuing system,we derive an upper bound for the probabilistic quality of service (QoS)requirement concerning end-to-end latency and reliability. The resourceallocation with the QoS constraints results in a functional optimizationproblem. To address it, we design a deep neural network to learn the powerallocation policy, leveraging the structure of optimal power allocation toenhance learning performance. Simulation results demonstrate that the proposedmethod effectively reduces transmit powers while meeting the QoS requirement.</description><author>Shiyong Chen, Yuwei Dai, Shengqian Han</author><pubDate>Mon, 27 Jan 2025 16:42:48 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.16186v1</guid></item><item><title>ACT-JEPA: Joint-Embedding Predictive Architecture Improves Policy Representation Learning</title><link>http://arxiv.org/abs/2501.14622v2</link><description>Learning efficient representations for decision-making policies is achallenge in imitation learning (IL). Current IL methods require expertdemonstrations, which are expensive to collect. Consequently, they often haveunderdeveloped world models. Self-supervised learning (SSL) offers analternative by allowing models to learn from diverse, unlabeled data, includingfailures. However, SSL methods often operate in raw input space, making theminefficient. In this work, we propose ACT-JEPA, a novel architecture thatintegrates IL and SSL to enhance policy representations. We train a policy topredict (1) action sequences and (2) abstract observation sequences. The firstobjective uses action chunking to improve action prediction and reducecompounding errors. The second objective extends this idea of chunking bypredicting abstract observation sequences. We utilize Joint-EmbeddingPredictive Architecture to predict in abstract representation space, allowingthe model to filter out irrelevant details, improve efficiency, and develop arobust world model. Our experiments show that ACT-JEPA improves the quality ofrepresentations by learning temporal environment dynamics. Additionally, themodel's ability to predict abstract observation sequences results inrepresentations that effectively generalize to action sequence prediction.ACT-JEPA performs on par with established baselines across a range ofdecision-making tasks.</description><author>Aleksandar Vujinovic, Aleksandar Kovacevic</author><pubDate>Mon, 27 Jan 2025 16:39:40 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.14622v2</guid></item><item><title>Hands-On Tutorial: Labeling with LLM and Human-in-the-Loop</title><link>http://arxiv.org/abs/2411.04637v3</link><description>Training and deploying machine learning models relies on a large amount ofhuman-annotated data. As human labeling becomes increasingly expensive andtime-consuming, recent research has developed multiple strategies to speed upannotation and reduce costs and human workload: generating synthetic trainingdata, active learning, and hybrid labeling. This tutorial is oriented towardpractical applications: we will present the basics of each strategy, highlighttheir benefits and limitations, and discuss in detail real-life case studies.Additionally, we will walk through best practices for managing human annotatorsand controlling the quality of the final dataset. The tutorial includes ahands-on workshop, where attendees will be guided in implementing a hybridannotation setup. This tutorial is designed for NLP practitioners from bothresearch and industry backgrounds who are involved in or interested inoptimizing data labeling projects.</description><author>Ekaterina Artemova, Akim Tsvigun, Dominik Schlechtweg, Natalia Fedorova, Konstantin Chernyshev, Sergei Tilga, Boris Obmoroshev</author><pubDate>Mon, 27 Jan 2025 16:38:30 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2411.04637v3</guid></item><item><title>MoColl: Agent-Based Specific and General Model Collaboration for Image Captioning</title><link>http://arxiv.org/abs/2501.01834v3</link><description>Image captioning is a critical task at the intersection of computer visionand natural language processing, with wide-ranging applications across variousdomains. For complex tasks such as diagnostic report generation, deep learningmodels require not only domain-specific image-caption datasets but also theincorporation of relevant general knowledge to provide contextual accuracy.Existing approaches exhibit inherent limitations: specialized models excel incapturing domain-specific details but lack generalization, whilevision-language models (VLMs) built on large language models (LLMs) leveragegeneral knowledge but struggle with domain-specific adaptation. To addressthese limitations, this paper proposes a novel agent-enhanced modelcollaboration framework, which we call MoColl, designed to effectivelyintegrate domain-specific and general knowledge. Specifically, our approach isto decompose complex image captioning tasks into a series of interconnectedquestion-answer subtasks. A trainable visual question answering (VQA) model isemployed as a specialized tool to focus on domain-specific visual analysis,answering task-specific questions based on image content. Concurrently, anLLM-based agent with general knowledge formulates these questions andsynthesizes the resulting question-answer pairs into coherent captions. Beyondits role in leveraging the VQA model, the agent further guides its training toenhance its domain-specific capabilities. Experimental results on radiologyreport generation validate the effectiveness of the proposed framework,demonstrating significant improvements in the quality of generated reports.</description><author>Pu Yang, Bin Dong</author><pubDate>Mon, 27 Jan 2025 16:34:59 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.01834v3</guid></item><item><title>Beyond the Alphabet: Deep Signal Embedding for Enhanced DNA Clustering</title><link>http://arxiv.org/abs/2410.06188v2</link><description>The emerging field of DNA storage employs strands of DNA bases (A/T/C/G) as astorage medium for digital information to enable massive density anddurability. The DNA storage pipeline includes: (1) encoding the raw data intosequences of DNA bases; (2) synthesizing the sequences as DNA \textit{strands}that are stored over time as an unordered set; (3) sequencing the DNA strandsto generate DNA \textit{reads}; and (4) deducing the original data. The DNAsynthesis and sequencing stages each generate several independent error-proneduplicates of each strand which are then utilized in the final stage toreconstruct the best estimate for the original strand. Specifically, the readsare first \textit{clustered} into groups likely originating from the samestrand (based on their similarity to each other), and then each groupapproximates the strand that led to the reads of that group. This work improvesthe DNA clustering stage by embedding it as part of the DNA sequencing.Traditional DNA storage solutions begin after the DNA sequencing processgenerates discrete DNA reads (A/T/C/G), yet we identify that there is untappedpotential in using the raw signals generated by the Nanopore DNA sequencingmachine before they are discretized into bases, a process known as\textit{basecalling}, which is done using a deep neural network. We propose adeep neural network that clusters these signals directly, demonstratingsuperior accuracy, and reduced computation times compared to current approachesthat cluster after basecalling.</description><author>Hadas Abraham, Barak Gahtan, Adir Kobovich, Orian Leitersdorf, Alex M. Bronstein, Eitan Yaakobi</author><pubDate>Mon, 27 Jan 2025 16:32:53 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.06188v2</guid></item><item><title>The Linear Attention Resurrection in Vision Transformer</title><link>http://arxiv.org/abs/2501.16182v1</link><description>Vision Transformers (ViTs) have recently taken computer vision by storm.However, the softmax attention underlying ViTs comes with a quadraticcomplexity in time and memory, hindering the application of ViTs tohigh-resolution images. We revisit the attention design and propose a linearattention method to address the limitation, which doesn't sacrifice ViT's coreadvantage of capturing global representation like existing methods (e.g. localwindow attention of Swin). We further investigate the key difference betweenlinear attention and softmax attention. Our empirical results suggest thatlinear attention lacks a fundamental property of concentrating the distributionof the attention matrix. Inspired by this observation, we introduce a localconcentration module to enhance linear attention. By incorporating enhancedlinear global attention and local window attention, we propose a new ViTarchitecture, dubbed L$^2$ViT. Notably, L$^2$ViT can effectively capture bothglobal interactions and local representations while enjoying linearcomputational complexity. Extensive experiments demonstrate the strongperformance of L$^2$ViT. On image classification, L$^2$ViT achieves 84.4% Top-1accuracy on ImageNet-1K without any extra training data or label. By furtherpre-training on ImageNet-22k, it attains 87.0% when fine-tuned with resolution384$^2$. For downstream tasks, L$^2$ViT delivers favorable performance as abackbone on object detection as well as semantic segmentation.</description><author>Chuanyang Zheng</author><pubDate>Mon, 27 Jan 2025 16:29:17 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.16182v1</guid></item><item><title>Text-driven Adaptation of Foundation Models for Few-shot Surgical Workflow Analysis</title><link>http://arxiv.org/abs/2501.09555v2</link><description>Purpose: Surgical workflow analysis is crucial for improving surgicalefficiency and safety. However, previous studies rely heavily on large-scaleannotated datasets, posing challenges in cost, scalability, and reliance onexpert annotations. To address this, we propose Surg-FTDA (Few-shot Text-drivenAdaptation), designed to handle various surgical workflow analysis tasks withminimal paired image-label data. Methods: Our approach has two key components. First, Few-shot selection-basedmodality alignment selects a small subset of images and aligns their embeddingswith text embeddings from the downstream task, bridging the modality gap.Second, Text-driven adaptation leverages only text data to train a decoder,eliminating the need for paired image-text data. This decoder is then appliedto aligned image embeddings, enabling image-related tasks without explicitimage-text pairs. Results: We evaluate our approach to generative tasks (image captioning) anddiscriminative tasks (triplet recognition and phase recognition). Results showthat Surg-FTDA outperforms baselines and generalizes well across downstreamtasks. Conclusion: We propose a text-driven adaptation approach that mitigates themodality gap and handles multiple downstream tasks in surgical workflowanalysis, with minimal reliance on large annotated datasets. The code anddataset will be released in https://github.com/CAMMA-public/Surg-FTDA</description><author>Tingxuan Chen, Kun Yuan, Vinkle Srivastav, Nassir Navab, Nicolas Padoy</author><pubDate>Mon, 27 Jan 2025 16:28:21 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.09555v2</guid></item><item><title>Can summarization approximate simplification? A gold standard comparison</title><link>http://arxiv.org/abs/2501.16181v1</link><description>This study explores the overlap between text summarization and simplificationoutputs. While summarization evaluation methods are streamlined, simplificationlacks cohesion, prompting the question: how closely can abstractivesummarization resemble gold-standard simplification? We address this byapplying two BART-based BRIO summarization methods to the Newsela corpus,comparing outputs with manually annotated simplifications and achieving a topROUGE-L score of 0.654. This provides insight into where summarization andsimplification outputs converge and differ.</description><author>Giacomo Magnifico, Eduard Barbu</author><pubDate>Mon, 27 Jan 2025 16:27:41 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.16181v1</guid></item><item><title>Sources of Uncertainty in Supervised Machine Learning -- A Statisticians' View</title><link>http://arxiv.org/abs/2305.16703v2</link><description>Supervised machine learning and predictive models have achieved an impressivestandard today, enabling us to answer questions that were inconceivable a fewyears ago. Besides these successes, it becomes clear, that beyond pureprediction, which is the primary strength of most supervised machine learningalgorithms, the quantification of uncertainty is relevant and necessary aswell. However, before quantification is possible, types and sources ofuncertainty need to be defined precisely. While first concepts and ideas inthis direction have emerged in recent years, this paper adopts a conceptual,basic science perspective and examines possible sources of uncertainty. Byadopting the viewpoint of a statistician, we discuss the concepts of aleatoricand epistemic uncertainty, which are more commonly associated with machinelearning. The paper aims to formalize the two types of uncertainty anddemonstrates that sources of uncertainty are miscellaneous and can not alwaysbe decomposed into aleatoric and epistemic. Drawing parallels betweenstatistical concepts and uncertainty in machine learning, we emphasise the roleof data and their influence on uncertainty.</description><author>Cornelia Gruber, Patrick Oliver Schenk, Malte Schierholz, Frauke Kreuter, Göran Kauermann</author><pubDate>Mon, 27 Jan 2025 16:26:48 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.16703v2</guid></item><item><title>SWIFT: Mapping Sub-series with Wavelet Decomposition Improves Time Series Forecasting</title><link>http://arxiv.org/abs/2501.16178v1</link><description>In recent work on time-series prediction, Transformers and even largelanguage models have garnered significant attention due to their strongcapabilities in sequence modeling. However, in practical deployments,time-series prediction often requires operation in resource-constrainedenvironments, such as edge devices, which are unable to handle thecomputational overhead of large models. To address such scenarios, somelightweight models have been proposed, but they exhibit poor performance onnon-stationary sequences. In this paper, we propose $\textit{SWIFT}$, alightweight model that is not only powerful, but also efficient in deploymentand inference for Long-term Time Series Forecasting (LTSF). Our model is basedon three key points: (i) Utilizing wavelet transform to perform losslessdownsampling of time series. (ii) Achieving cross-band information fusion witha learnable filter. (iii) Using only one shared linear layer or one shallow MLPfor sub-series' mapping. We conduct comprehensive experiments, and the resultsshow that $\textit{SWIFT}$ achieves state-of-the-art (SOTA) performance onmultiple datasets, offering a promising method for edge computing anddeployment in this task. Moreover, it is noteworthy that the number ofparameters in $\textit{SWIFT-Linear}$ is only 25\% of what it would be with asingle-layer linear model for time-domain prediction. Our code is available athttps://github.com/LancelotXWX/SWIFT.</description><author>Wenxuan Xie, Fanpu Cao</author><pubDate>Mon, 27 Jan 2025 16:26:07 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.16178v1</guid></item><item><title>MOSAIC: Multiple Observers Spotting AI Content, a Robust Approach to Machine-Generated Text Detection</title><link>http://arxiv.org/abs/2409.07615v2</link><description>The dissemination of Large Language Models (LLMs), trained at scale, andendowed with powerful text-generating abilities has vastly increased thethreats posed by generative AI technologies by reducing the cost of producingharmful, toxic, faked or forged content. In response, various proposals havebeen made to automatically discriminate artificially generated fromhuman-written texts, typically framing the problem as a classification problem.Most approaches evaluate an input document by a well-chosen detector LLM,assuming that low-perplexity scores reliably signal machine-made content. Asusing one single detector can induce brittleness of performance, we insteadconsider several and derive a new, theoretically grounded approach to combinetheir respective strengths. Our experiments, using a variety of generator LLMs,suggest that our method effectively leads to robust detection performances. Anearly version of the code is available athttps://github.com/BaggerOfWords/MOSAIC.</description><author>Matthieu Dubois, François Yvon, Pablo Piantanida</author><pubDate>Mon, 27 Jan 2025 16:24:47 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2409.07615v2</guid></item><item><title>BAG: Body-Aligned 3D Wearable Asset Generation</title><link>http://arxiv.org/abs/2501.16177v1</link><description>While recent advancements have shown remarkable progress in general 3D shapegeneration models, the challenge of leveraging these approaches toautomatically generate wearable 3D assets remains unexplored. To this end, wepresent BAG, a Body-aligned Asset Generation method to output 3D wearable assetthat can be automatically dressed on given 3D human bodies. This is achived bycontrolling the 3D generation process using human body shape and poseinformation. Specifically, we first build a general single-image to consistentmultiview image diffusion model, and train it on the large Objaverse dataset toachieve diversity and generalizability. Then we train a Controlnet to guide themultiview generator to produce body-aligned multiview images. The controlsignal utilizes the multiview 2D projections of the target human body, wherepixel values represent the XYZ coordinates of the body surface in a canonicalspace. The body-conditioned multiview diffusion generates body-alignedmultiview images, which are then fed into a native 3D diffusion model toproduce the 3D shape of the asset. Finally, by recovering the similaritytransformation using multiview silhouette supervision and addressing asset-bodypenetration with physics simulators, the 3D asset can be accurately fitted ontothe target human body. Experimental results demonstrate significant advantagesover existing methods in terms of image prompt-following capability, shapediversity, and shape quality. Our project page is available athttps://bag-3d.github.io/.</description><author>Zhongjin Luo, Yang Li, Mingrui Zhang, Senbo Wang, Han Yan, Xibin Song, Taizhang Shang, Wei Mao, Hongdong Li, Xiaoguang Han, Pan Ji</author><pubDate>Mon, 27 Jan 2025 16:23:45 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.16177v1</guid></item><item><title>Measuring Heterogeneity in Machine Learning with Distributed Energy Distance</title><link>http://arxiv.org/abs/2501.16174v1</link><description>In distributed and federated learning, heterogeneity across data sourcesremains a major obstacle to effective model aggregation and convergence. Wefocus on feature heterogeneity and introduce energy distance as a sensitivemeasure for quantifying distributional discrepancies. While we show that energydistance is robust for detecting data distribution shifts, its direct use inlarge-scale systems can be prohibitively expensive. To address this, we developTaylor approximations that preserve key theoretical quantitative propertieswhile reducing computational overhead. Through simulation studies, we show howaccurately capturing feature discrepancies boosts convergence in distributedlearning. Finally, we propose a novel application of energy distance to assignpenalty weights for aligning predictions across heterogeneous nodes, ultimatelyenhancing coordination in federated and distributed settings.</description><author>Mengchen Fan, Baocheng Geng, Roman Shterenberg, Joseph A. Casey, Zhong Chen, Keren Li</author><pubDate>Mon, 27 Jan 2025 16:15:57 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.16174v1</guid></item><item><title>Uncovering Latent Arguments in Social Media Messaging by Employing LLMs-in-the-Loop Strategy</title><link>http://arxiv.org/abs/2404.10259v4</link><description>The widespread use of social media has led to a surge in popularity forautomated methods of analyzing public opinion. Supervised methods are adept attext categorization, yet the dynamic nature of social media discussions poses acontinual challenge for these techniques due to the constant shifting of thefocus. On the other hand, traditional unsupervised methods for extractingthemes from public discourse, such as topic modeling, often reveal overarchingpatterns that might not capture specific nuances. Consequently, a significantportion of research into social media discourse still depends onlabor-intensive manual coding techniques and a human-in-the-loop approach,which are both time-consuming and costly. In this work, we study the problem ofdiscovering arguments associated with a specific theme. We propose a genericLLMs-in-the-Loop strategy that leverages the advanced capabilities of LargeLanguage Models (LLMs) to extract latent arguments from social media messaging.To demonstrate our approach, we apply our framework to contentious topics. Weuse two publicly available datasets: (1) the climate campaigns dataset of 14kFacebook ads with 25 themes and (2) the COVID-19 vaccine campaigns dataset of9k Facebook ads with 14 themes. Additionally, we design a downstream task asstance prediction by leveraging talking points in climate debates. Furthermore,we analyze demographic targeting and the adaptation of messaging based onreal-world events.</description><author>Tunazzina Islam, Dan Goldwasser</author><pubDate>Mon, 27 Jan 2025 16:15:26 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.10259v4</guid></item><item><title>Separate This, and All of these Things Around It: Music Source Separation via Hyperellipsoidal Queries</title><link>http://arxiv.org/abs/2501.16171v1</link><description>Music source separation is an audio-to-audio retrieval task of extracting oneor more constituent components, or composites thereof, from a musical audiomixture. Each of these constituent components is often referred to as a "stem"in literature. Historically, music source separation has been dominated by astem-based paradigm, leading to most state-of-the-art systems being either acollection of single-stem extraction models, or a tightly coupled system with afixed, difficult-to-modify, set of supported stems. Combined with the limiteddata availability, advances in music source separation have thus been mostlylimited to the "VDBO" set of stems: \textit{vocals}, \textit{drum},\textit{bass}, and the catch-all \textit{others}. Recent work in music sourceseparation has begun to challenge the fixed-stem paradigm, moving towardsmodels able to extract any musical sound as long as this target type of soundcould be specified to the model as an additional query input. We generalizethis idea to a \textit{query-by-region} source separation system, specifyingthe target based on the query regardless of how many sound sources or whichsound classes are contained within it. To do so, we propose the use ofhyperellipsoidal regions as queries to allow for an intuitive yet easilyparametrizable approach to specifying both the target (location) as well as itsspread. Evaluation of the proposed system on the MoisesDB dataset demonstratedstate-of-the-art performance of the proposed system both in terms ofsignal-to-noise ratios and retrieval metrics.</description><author>Karn N. Watcharasupat, Alexander Lerch</author><pubDate>Mon, 27 Jan 2025 16:13:50 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.16171v1</guid></item><item><title>S-CFE: Simple Counterfactual Explanations</title><link>http://arxiv.org/abs/2410.15723v4</link><description>We study the problem of finding optimal sparse, manifold-alignedcounterfactual explanations for classifiers. Canonically, this can beformulated as an optimization problem with multiple non-convex components,including classifier loss functions and manifold alignment (or\emph{plausibility}) metrics. The added complexity of enforcing\emph{sparsity}, or shorter explanations, complicates the problem further.Existing methods often focus on specific models and plausibility measures,relying on convex $\ell_1$ regularizers to enforce sparsity. In this paper, wetackle the canonical formulation using the accelerated proximal gradient (APG)method, a simple yet efficient first-order procedure capable of handling smoothnon-convex objectives and non-smooth $\ell_p$ (where $0 \leq p &lt; 1$)regularizers. This enables our approach to seamlessly incorporate variousclassifiers and plausibility measures while producing sparser solutions. Ouralgorithm only requires differentiable data-manifold regularizers and supportsbox constraints for bounded feature ranges, ensuring the generatedcounterfactuals remain \emph{actionable}. Finally, experiments on real-worlddatasets demonstrate that our approach effectively produces sparse,manifold-aligned counterfactual explanations while maintaining proximity to thefactual data and computational efficiency.</description><author>Shpresim Sadiku, Moritz Wagner, Sai Ganesh Nagarajan, Sebastian Pokutta</author><pubDate>Mon, 27 Jan 2025 16:11:00 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.15723v4</guid></item><item><title>Ringmaster ASGD: The First Asynchronous SGD with Optimal Time Complexity</title><link>http://arxiv.org/abs/2501.16168v1</link><description>Asynchronous Stochastic Gradient Descent (Asynchronous SGD) is a cornerstonemethod for parallelizing learning in distributed machine learning. However, itsperformance suffers under arbitrarily heterogeneous computation times acrossworkers, leading to suboptimal time complexity and inefficiency as the numberof workers scales. While several Asynchronous SGD variants have been proposed,recent findings by Tyurin &amp; Richt\'arik (NeurIPS 2023) reveal that none achieveoptimal time complexity, leaving a significant gap in the literature. In thispaper, we propose Ringmaster ASGD, a novel Asynchronous SGD method designed toaddress these limitations and tame the inherent challenges of Asynchronous SGD.We establish, through rigorous theoretical analysis, that Ringmaster ASGDachieves optimal time complexity under arbitrarily heterogeneous anddynamically fluctuating worker computation times. This makes it the firstAsynchronous SGD method to meet the theoretical lower bounds for timecomplexity in such scenarios.</description><author>Artavazd Maranjyan, Alexander Tyurin, Peter Richtárik</author><pubDate>Mon, 27 Jan 2025 16:07:26 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.16168v1</guid></item><item><title>VCRScore: Image captioning metric based on V\&amp;L Transformers, CLIP, and precision-recall</title><link>http://arxiv.org/abs/2501.09155v2</link><description>Image captioning has become an essential Vision &amp; Language research task. Itis about predicting the most accurate caption given a specific image or video.The research community has achieved impressive results by continuouslyproposing new models and approaches to improve the overall model's performance.Nevertheless, despite increasing proposals, the performance metrics used tomeasure their advances have remained practically untouched through the years. Aprobe of that, nowadays metrics like BLEU, METEOR, CIDEr, and ROUGE are stillvery used, aside from more sophisticated metrics such as BertScore andClipScore. Hence, it is essential to adjust how are measure the advances, limitations,and scopes of the new image captioning proposals, as well as to adapt newmetrics to these new advanced image captioning approaches. This work proposes a new evaluation metric for the image captioning problem.To do that, first, it was generated a human-labeled dataset to assess to whichdegree the captions correlate with the image's content. Taking these humanscores as ground truth, we propose a new metric, and compare it with severalwell-known metrics, from classical to newer ones. Outperformed results werealso found, and interesting insights were presented and discussed.</description><author>Guillermo Ruiz, Tania Ramírez, Daniela Moctezuma</author><pubDate>Mon, 27 Jan 2025 16:05:59 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.09155v2</guid></item><item><title>BLoB: Bayesian Low-Rank Adaptation by Backpropagation for Large Language Models</title><link>http://arxiv.org/abs/2406.11675v5</link><description>Large Language Models (LLMs) often suffer from overconfidence duringinference, particularly when adapted to downstream domain-specific tasks withlimited data. Previous work addresses this issue by employing approximateBayesian estimation after the LLMs are trained, enabling them to quantifyuncertainty. However, such post-training approaches' performance is severelylimited by the parameters learned during training. In this paper, we go beyondpost-training Bayesianization and propose Bayesian Low-Rank Adaptation byBackpropagation (BLoB), an algorithm that continuously and jointly adjusts boththe mean and covariance of LLM parameters throughout the whole fine-tuningprocess. Our empirical results verify the effectiveness of BLoB in terms ofgeneralization and uncertainty estimation, when evaluated on bothin-distribution and out-of-distribution data.</description><author>Yibin Wang, Haizhou Shi, Ligong Han, Dimitris Metaxas, Hao Wang</author><pubDate>Mon, 27 Jan 2025 16:00:59 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.11675v5</guid></item><item><title>MetaDecorator: Generating Immersive Virtual Tours through Multimodality</title><link>http://arxiv.org/abs/2501.16164v1</link><description>MetaDecorator, is a framework that empowers users to personalize virtualspaces. By leveraging text-driven prompts and image synthesis techniques,MetaDecorator adorns static panoramas captured by 360{\deg} imaging devices,transforming them into uniquely styled and visually appealing environments.This significantly enhances the realism and engagement of virtual tourscompared to traditional offerings. Beyond the core framework, we also discussthe integration of Large Language Models (LLMs) and haptics in the VRapplication to provide a more immersive experience.</description><author>Shuang Xie, Yang Liu, Jeannie S. A. Lee, Haiwei Dong</author><pubDate>Mon, 27 Jan 2025 15:59:58 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.16164v1</guid></item><item><title>Learning Point Spread Function Invertibility Assessment for Image Deconvolution</title><link>http://arxiv.org/abs/2405.16343v3</link><description>Deep-learning (DL)-based image deconvolution (ID) has exhibited remarkablerecovery performance, surpassing traditional linear methods. However, unliketraditional ID approaches that rely on analytical properties of the pointspread function (PSF) to achieve high recovery performance - such as specificspectrum properties or small conditional numbers in the convolution matrix - DLtechniques lack quantifiable metrics for evaluating PSF suitability forDL-assisted recovery. Aiming to enhance deconvolution quality, we propose ametric that employs a non-linear approach to learn the invertibility of anarbitrary PSF using a neural network by mapping it to a unit impulse. A lowerdiscrepancy between the mapped PSF and a unit impulse indicates a higherlikelihood of successful inversion by a DL network. Our findings reveal thatthis metric correlates with high recovery performance in DL and traditionalmethods, thereby serving as an effective regularizer in deconvolution tasks.This approach reduces the computational complexity over conventional conditionnumber assessments and is a differentiable process. These useful propertiesallow its application in designing diffractive optical elements throughend-to-end (E2E) optimization, achieving invertible PSFs, and outperforming theE2E baseline framework.</description><author>Romario Gualdrón-Hurtado, Roman Jacome, Sergio Urrea, Henry Arguello, Luis Gonzalez</author><pubDate>Mon, 27 Jan 2025 15:56:30 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.16343v3</guid></item><item><title>Comprehensive Benchmarking Environment for Worker Flexibility in Flexible Job Shop Scheduling Problems</title><link>http://arxiv.org/abs/2501.16159v1</link><description>In Production Scheduling, the Flexible Job Shop Scheduling Problem (FJSSP)aims to optimize a sequence of operations and assign each to an eligiblemachine with varying processing times. For integration of the workforce, eachmachine also requires a worker to be present to process an operation whichadditionally affects the processing times. The resulting problem is calledFlexible Job Shop Scheduling Problem with Worker Flexibility (FJSSP-W). TheFJSSP has been approached with various problem representations, including MixedInteger Linear Programming (MILP), Constrained Programming (CP), andSimulation-based Optimization (SBO). In the latter area in particular, thereexists a large number of specialized Evolutionary Algorithms (EA) like ParticleSwarm Optimization (PSO) or Genetic Algorithms (GA). Yet, the solvers are oftendeveloped for single use cases only, and validated on a few selected testinstances, let alone compared with results from solvers using other problemrepresentations. While suitable approaches do also exist, the design of theFJSSP-W instances is not standardized and the algorithms are hardly comparable.This calls for a systematic benchmarking environment that provides acomprehensive set of FJSSP(-W) instances and supports targeted algorithmdevelopment. It will facilitate the comparison of algorithmic performance inthe face of different problem characteristics. The present paper presents acollection of 402 commonly accepted FJSSP instances and proposes an approach toextend these with worker flexibility. In addition, we present a detailedprocedure for the evaluation of scheduling algorithms on these problem sets andprovide suitable model representations for this purpose. We provide complexitycharacteristics for all presented instances as well as baseline results ofcommon commercial solvers to facilitate the validation of new algorithmicdevelopments.</description><author>David Hutter, Thomas Steinberger, Michael Hellwig</author><pubDate>Mon, 27 Jan 2025 15:56:12 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.16159v1</guid></item></channel></rss>