<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/"><channel><title>Arxivfresh papers</title><link></link><description>Arxiv paper</description><language>en-US</language><lastBuildDate>Thu, 19 Dec 2024 13:00:12 GMT</lastBuildDate><generator>rfeed v1.0.0</generator><docs>https://github.com/svpino/rfeed/blob/master/README.md</docs><item><title>AniDoc: Animation Creation Made Easier</title><link>http://arxiv.org/abs/2412.14173v1</link><description>The production of 2D animation follows an industry-standard workflow,encompassing four essential stages: character design, keyframe animation,in-betweening, and coloring. Our research focuses on reducing the labor costsin the above process by harnessing the potential of increasingly powerfulgenerative AI. Using video diffusion models as the foundation, AniDoc emergesas a video line art colorization tool, which automatically converts sketchsequences into colored animations following the reference characterspecification. Our model exploits correspondence matching as an explicitguidance, yielding strong robustness to the variations (e.g., posture) betweenthe reference character and each line art frame. In addition, our model couldeven automate the in-betweening process, such that users can easily create atemporally consistent animation by simply providing a character image as wellas the start and end sketches. Our code is available at:https://yihao-meng.github.io/AniDoc_demo.</description><author>Yihao Meng, Hao Ouyang, Hanlin Wang, Qiuyu Wang, Wen Wang, Ka Leong Cheng, Zhiheng Liu, Yujun Shen, Huamin Qu</author><pubDate>Wed, 18 Dec 2024 18:59:59 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.14173v1</guid></item><item><title>Learning from Massive Human Videos for Universal Humanoid Pose Control</title><link>http://arxiv.org/abs/2412.14172v1</link><description>Scalable learning of humanoid robots is crucial for their deployment inreal-world applications. While traditional approaches primarily rely onreinforcement learning or teleoperation to achieve whole-body control, they areoften limited by the diversity of simulated environments and the high costs ofdemonstration collection. In contrast, human videos are ubiquitous and presentan untapped source of semantic and motion information that could significantlyenhance the generalization capabilities of humanoid robots. This paperintroduces Humanoid-X, a large-scale dataset of over 20 million humanoid robotposes with corresponding text-based motion descriptions, designed to leveragethis abundant data. Humanoid-X is curated through a comprehensive pipeline:data mining from the Internet, video caption generation, motion retargeting ofhumans to humanoid robots, and policy learning for real-world deployment. WithHumanoid-X, we further train a large humanoid model, UH-1, which takes textinstructions as input and outputs corresponding actions to control a humanoidrobot. Extensive simulated and real-world experiments validate that ourscalable training approach leads to superior generalization in text-basedhumanoid control, marking a significant step toward adaptable, real-world-readyhumanoid robots.</description><author>Jiageng Mao, Siheng Zhao, Siqi Song, Tianheng Shi, Junjie Ye, Mingtong Zhang, Haoran Geng, Jitendra Malik, Vitor Guizilini, Yue Wang</author><pubDate>Wed, 18 Dec 2024 18:59:56 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.14172v1</guid></item><item><title>Thinking in Space: How Multimodal Large Language Models See, Remember, and Recall Spaces</title><link>http://arxiv.org/abs/2412.14171v1</link><description>Humans possess the visual-spatial intelligence to remember spaces fromsequential visual observations. However, can Multimodal Large Language Models(MLLMs) trained on million-scale video datasets also ``think in space'' fromvideos? We present a novel video-based visual-spatial intelligence benchmark(VSI-Bench) of over 5,000 question-answer pairs, and find that MLLMs exhibitcompetitive - though subhuman - visual-spatial intelligence. We probe models toexpress how they think in space both linguistically and visually and find thatwhile spatial reasoning capabilities remain the primary bottleneck for MLLMs toreach higher benchmark performance, local world models and spatial awareness doemerge within these models. Notably, prevailing linguistic reasoning techniques(e.g., chain-of-thought, self-consistency, tree-of-thoughts) fail to improveperformance, whereas explicitly generating cognitive maps duringquestion-answering enhances MLLMs' spatial distance ability.</description><author>Jihan Yang, Shusheng Yang, Anjali W. Gupta, Rilyn Han, Li Fei-Fei, Saining Xie</author><pubDate>Wed, 18 Dec 2024 18:59:54 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.14171v1</guid></item><item><title>E-CAR: Efficient Continuous Autoregressive Image Generation via Multistage Modeling</title><link>http://arxiv.org/abs/2412.14170v1</link><description>Recent advances in autoregressive (AR) models with continuous tokens forimage generation show promising results by eliminating the need for discretetokenization. However, these models face efficiency challenges due to theirsequential token generation nature and reliance on computationally intensivediffusion-based sampling. We present ECAR (Efficient Continuous Auto-RegressiveImage Generation via Multistage Modeling), an approach that addresses theselimitations through two intertwined innovations: (1) a stage-wise continuoustoken generation strategy that reduces computational complexity and providesprogressively refined token maps as hierarchical conditions, and (2) amultistage flow-based distribution modeling method that transforms onlypartial-denoised distributions at each stage comparing to complete denoising innormal diffusion models. Holistically, ECAR operates by generating tokens atincreasing resolutions while simultaneously denoising the image at each stage.This design not only reduces token-to-image transformation cost by a factor ofthe stage number but also enables parallel processing at the token level. Ourapproach not only enhances computational efficiency but also aligns naturallywith image generation principles by operating in continuous token space andfollowing a hierarchical generation process from coarse to fine details.Experimental results demonstrate that ECAR achieves comparable image quality toDiT Peebles &amp; Xie [2023] while requiring 10$\times$ FLOPs reduction and5$\times$ speedup to generate a 256$\times$256 image.</description><author>Zhihang Yuan, Yuzhang Shang, Hanling Zhang, Tongcheng Fang, Rui Xie, Bingxin Xu, Yan Yan, Shengen Yan, Guohao Dai, Yu Wang</author><pubDate>Wed, 18 Dec 2024 18:59:53 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.14170v1</guid></item><item><title>Autoregressive Video Generation without Vector Quantization</title><link>http://arxiv.org/abs/2412.14169v1</link><description>This paper presents a novel approach that enables autoregressive videogeneration with high efficiency. We propose to reformulate the video generationproblem as a non-quantized autoregressive modeling of temporal frame-by-frameprediction and spatial set-by-set prediction. Unlike raster-scan prediction inprior autoregressive models or joint distribution modeling of fixed-lengthtokens in diffusion models, our approach maintains the causal property ofGPT-style models for flexible in-context capabilities, while leveragingbidirectional modeling within individual frames for efficiency. With theproposed approach, we train a novel video autoregressive model without vectorquantization, termed NOVA. Our results demonstrate that NOVA surpasses priorautoregressive video models in data efficiency, inference speed, visualfidelity, and video fluency, even with a much smaller model capacity, i.e.,0.6B parameters. NOVA also outperforms state-of-the-art image diffusion modelsin text-to-image generation tasks, with a significantly lower training cost.Additionally, NOVA generalizes well across extended video durations and enablesdiverse zero-shot applications in one unified model. Code and models arepublicly available at https://github.com/baaivision/NOVA.</description><author>Haoge Deng, Ting Pan, Haiwen Diao, Zhengxiong Luo, Yufeng Cui, Huchuan Lu, Shiguang Shan, Yonggang Qi, Xinlong Wang</author><pubDate>Wed, 18 Dec 2024 18:59:53 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.14169v1</guid></item><item><title>FashionComposer: Compositional Fashion Image Generation</title><link>http://arxiv.org/abs/2412.14168v1</link><description>We present FashionComposer for compositional fashion image generation. Unlikeprevious methods, FashionComposer is highly flexible. It takes multi-modalinput (i.e., text prompt, parametric human model, garment image, and faceimage) and supports personalizing the appearance, pose, and figure of the humanand assigning multiple garments in one pass. To achieve this, we first developa universal framework capable of handling diverse input modalities. Weconstruct scaled training data to enhance the model's robust compositionalcapabilities. To accommodate multiple reference images (garments and faces)seamlessly, we organize these references in a single image as an "assetlibrary" and employ a reference UNet to extract appearance features. To injectthe appearance features into the correct pixels in the generated result, wepropose subject-binding attention. It binds the appearance features fromdifferent "assets" with the corresponding text features. In this way, the modelcould understand each asset according to their semantics, supporting arbitrarynumbers and types of reference images. As a comprehensive solution,FashionComposer also supports many other applications like human albumgeneration, diverse virtual try-on tasks, etc.</description><author>Sihui Ji, Yiyang Wang, Xi Chen, Xiaogang Xu, Hao Luo, Hengshuang Zhao</author><pubDate>Wed, 18 Dec 2024 18:59:50 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.14168v1</guid></item><item><title>VideoDPO: Omni-Preference Alignment for Video Diffusion Generation</title><link>http://arxiv.org/abs/2412.14167v1</link><description>Recent progress in generative diffusion models has greatly advancedtext-to-video generation. While text-to-video models trained on large-scale,diverse datasets can produce varied outputs, these generations often deviatefrom user preferences, highlighting the need for preference alignment onpre-trained models. Although Direct Preference Optimization (DPO) hasdemonstrated significant improvements in language and image generation, wepioneer its adaptation to video diffusion models and propose a VideoDPOpipeline by making several key adjustments. Unlike previous image alignmentmethods that focus solely on either (i) visual quality or (ii) semanticalignment between text and videos, we comprehensively consider both dimensionsand construct a preference score accordingly, which we term the OmniScore. Wedesign a pipeline to automatically collect preference pair data based on theproposed OmniScore and discover that re-weighting these pairs based on thescore significantly impacts overall preference alignment. Our experimentsdemonstrate substantial improvements in both visual quality and semanticalignment, ensuring that no preference aspect is neglected. Code and data willbe shared at https://videodpo.github.io/.</description><author>Runtao Liu, Haoyu Wu, Zheng Ziqiang, Chen Wei, Yingqing He, Renjie Pi, Qifeng Chen</author><pubDate>Wed, 18 Dec 2024 18:59:49 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.14167v1</guid></item><item><title>MegaSynth: Scaling Up 3D Scene Reconstruction with Synthesized Data</title><link>http://arxiv.org/abs/2412.14166v1</link><description>We propose scaling up 3D scene reconstruction by training with synthesizeddata. At the core of our work is MegaSynth, a procedurally generated 3D datasetcomprising 700K scenes - over 50 times larger than the prior real dataset DL3DV- dramatically scaling the training data. To enable scalable data generation,our key idea is eliminating semantic information, removing the need to modelcomplex semantic priors such as object affordances and scene composition.Instead, we model scenes with basic spatial structures and geometry primitives,offering scalability. Besides, we control data complexity to facilitatetraining while loosely aligning it with real-world data distribution to benefitreal-world generalization. We explore training LRMs with both MegaSynth andavailable real data. Experiment results show that joint training orpre-training with MegaSynth improves reconstruction quality by 1.2 to 1.8 dBPSNR across diverse image domains. Moreover, models trained solely on MegaSynthperform comparably to those trained on real data, underscoring the low-levelnature of 3D reconstruction. Additionally, we provide an in-depth analysis ofMegaSynth's properties for enhancing model capability, training stability, andgeneralization.</description><author>Hanwen Jiang, Zexiang Xu, Desai Xie, Ziwen Chen, Haian Jin, Fujun Luan, Zhixin Shu, Kai Zhang, Sai Bi, Xin Sun, Jiuxiang Gu, Qixing Huang, Georgios Pavlakos, Hao Tan</author><pubDate>Wed, 18 Dec 2024 18:59:38 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.14166v1</guid></item><item><title>MetaMorph: Multimodal Understanding and Generation via Instruction Tuning</title><link>http://arxiv.org/abs/2412.14164v1</link><description>In this work, we propose Visual-Predictive Instruction Tuning (VPiT) - asimple and effective extension to visual instruction tuning that enables apretrained LLM to quickly morph into an unified autoregressive model capable ofgenerating both text and visual tokens. VPiT teaches an LLM to predict discretetext tokens and continuous visual tokens from any input sequence of image andtext data curated in an instruction-following format. Our empiricalinvestigation reveals several intriguing properties of VPiT: (1) visualgeneration ability emerges as a natural byproduct of improved visualunderstanding, and can be unlocked efficiently with a small amount ofgeneration data; (2) while we find understanding and generation to be mutuallybeneficial, understanding data contributes to both capabilities moreeffectively than generation data. Building upon these findings, we train ourMetaMorph model and achieve competitive performance on both visualunderstanding and generation. In visual generation, MetaMorph can leverage theworld knowledge and reasoning abilities gained from LLM pretraining, andovercome common failure modes exhibited by other generation models. Our resultssuggest that LLMs may have strong "prior" vision capabilities that can beefficiently adapted to both visual understanding and generation with arelatively simple instruction tuning process.</description><author>Shengbang Tong, David Fan, Jiachen Zhu, Yunyang Xiong, Xinlei Chen, Koustuv Sinha, Michael Rabbat, Yann LeCun, Saining Xie, Zhuang Liu</author><pubDate>Wed, 18 Dec 2024 18:58:50 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.14164v1</guid></item><item><title>2M-BELEBELE: Highly Multilingual Speech and American Sign Language Comprehension Dataset</title><link>http://arxiv.org/abs/2412.08274v2</link><description>We introduce the first highly multilingual speech and American Sign Language(ASL) comprehension dataset by extending BELEBELE. Our dataset covers 74 spokenlanguages at the intersection of BELEBELE and FLEURS, and one sign language(ASL). We evaluate 2M-BELEBELE dataset for both 5-shot and zero-shot settingsand across languages, the speech comprehension accuracy is ~ 2-3% average lowercompared to reading comprehension.</description><author>Marta R. Costa-jussà, Bokai Yu, Pierre Andrews, Belen Alastruey, Necati Cihan Camgoz, Joe Chuang, Jean Maillard, Christophe Ropers, Arina Turkantenko, Carleigh Wood</author><pubDate>Wed, 18 Dec 2024 18:56:19 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.08274v2</guid></item><item><title>TheAgentCompany: Benchmarking LLM Agents on Consequential Real World Tasks</title><link>http://arxiv.org/abs/2412.14161v1</link><description>We interact with computers on an everyday basis, be it in everyday life orwork, and many aspects of work can be done entirely with access to a computerand the Internet. At the same time, thanks to improvements in large languagemodels (LLMs), there has also been a rapid development in AI agents thatinteract with and affect change in their surrounding environments. But howperformant are AI agents at helping to accelerate or even autonomously performwork-related tasks? The answer to this question has important implications forboth industry looking to adopt AI into their workflows, and for economic policyto understand the effects that adoption of AI may have on the labor market. Tomeasure the progress of these LLM agents' performance on performing real-worldprofessional tasks, in this paper, we introduce TheAgentCompany, an extensiblebenchmark for evaluating AI agents that interact with the world in similar waysto those of a digital worker: by browsing the Web, writing code, runningprograms, and communicating with other coworkers. We build a self-containedenvironment with internal web sites and data that mimics a small softwarecompany environment, and create a variety of tasks that may be performed byworkers in such a company. We test baseline agents powered by both closedAPI-based and open-weights language models (LMs), and find that with the mostcompetitive agent, 24% of the tasks can be completed autonomously. This paintsa nuanced picture on task automation with LM agents -- in a setting simulatinga real workplace, a good portion of simpler tasks could be solved autonomously,but more difficult long-horizon tasks are still beyond the reach of currentsystems.</description><author>Frank F. Xu, Yufan Song, Boxuan Li, Yuxuan Tang, Kritanjali Jain, Mengxue Bao, Zora Z. Wang, Xuhui Zhou, Zhitong Guo, Murong Cao, Mingyang Yang, Hao Yang Lu, Amaad Martin, Zhe Su, Leander Maben, Raj Mehta, Wayne Chi, Lawrence Jang, Yiqing Xie, Shuyan Zhou, Graham Neubig</author><pubDate>Wed, 18 Dec 2024 18:55:40 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.14161v1</guid></item><item><title>AKiRa: Augmentation Kit on Rays for optical video generation</title><link>http://arxiv.org/abs/2412.14158v1</link><description>Recent advances in text-conditioned video diffusion have greatly improvedvideo quality. However, these methods offer limited or sometimes no control tousers on camera aspects, including dynamic camera motion, zoom, distorted lensand focus shifts. These motion and optical aspects are crucial for addingcontrollability and cinematic elements to generation frameworks, ultimatelyresulting in visual content that draws focus, enhances mood, and guidesemotions according to filmmakers' controls. In this paper, we aim to close thegap between controllable video generation and camera optics. To achieve this,we propose AKiRa (Augmentation Kit on Rays), a novel augmentation frameworkthat builds and trains a camera adapter with a complex camera model over anexisting video generation backbone. It enables fine-tuned control over cameramotion as well as complex optical parameters (focal length, distortion,aperture) to achieve cinematic effects such as zoom, fisheye effect, and bokeh.Extensive experiments demonstrate AKiRa's effectiveness in combining andcomposing camera optics while outperforming all state-of-the-art methods. Thiswork sets a new landmark in controlled and optically enhanced video generation,paving the way for future optical video generation methods.</description><author>Xi Wang, Robin Courant, Marc Christie, Vicky Kalogeiton</author><pubDate>Wed, 18 Dec 2024 18:53:22 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.14158v1</guid></item><item><title>FAIR Universe HiggsML Uncertainty Challenge Competition</title><link>http://arxiv.org/abs/2410.02867v2</link><description>The FAIR Universe -- HiggsML Uncertainty Challenge focuses on measuring thephysics properties of elementary particles with imperfect simulators due todifferences in modelling systematic errors. Additionally, the challenge isleveraging a large-compute-scale AI platform for sharing datasets, trainingmodels, and hosting machine learning competitions. Our challenge bringstogether the physics and machine learning communities to advance ourunderstanding and methodologies in handling systematic (epistemic)uncertainties within AI techniques.</description><author>Wahid Bhimji, Paolo Calafiura, Ragansu Chakkappai, Po-Wen Chang, Yuan-Tang Chou, Sascha Diefenbacher, Jordan Dudley, Steven Farrell, Aishik Ghosh, Isabelle Guyon, Chris Harris, Shih-Chieh Hsu, Elham E Khoda, Rémy Lyscar, Alexandre Michon, Benjamin Nachman, Peter Nugent, Mathis Reymond, David Rousseau, Benjamin Sluijter, Benjamin Thorne, Ihsan Ullah, Yulei Zhang</author><pubDate>Wed, 18 Dec 2024 18:49:32 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.02867v2</guid></item><item><title>A Staged Deep Learning Approach to Spatial Refinement in 3D Temporal Atmospheric Transport</title><link>http://arxiv.org/abs/2412.10945v2</link><description>High-resolution spatiotemporal simulations effectively capture thecomplexities of atmospheric plume dispersion in complex terrain. However, theirhigh computational cost makes them impractical for applications requiring rapidresponses or iterative processes, such as optimization, uncertaintyquantification, or inverse modeling. To address this challenge, this workintroduces the Dual-Stage Temporal Three-dimensional UNet Super-resolution(DST3D-UNet-SR) model, a highly efficient deep learning model for plumedispersion prediction. DST3D-UNet-SR is composed of two sequential modules: thetemporal module (TM), which predicts the transient evolution of a plume incomplex terrain from low-resolution temporal data, and the spatial refinementmodule (SRM), which subsequently enhances the spatial resolution of the TMpredictions. We train DST3DUNet- SR using a comprehensive dataset derived fromhigh-resolution large eddy simulations (LES) of plume transport. We propose theDST3D-UNet-SR model to significantly accelerate LES simulations ofthree-dimensional plume dispersion by three orders of magnitude. Additionally,the model demonstrates the ability to dynamically adapt to evolving conditionsthrough the incorporation of new observational data, substantially improvingprediction accuracy in high-concentration regions near the source. Keywords: Atmospheric sciences, Geosciences, Plume transport,3D temporalsequences, Artificial intelligence, CNN, LSTM, Autoencoder, Autoregressivemodel, U-Net, Super-resolution, Spatial Refinement.</description><author>M. Giselle Fernández-Godino, Wai Tong Chung, Akshay A. Gowardhan, Matthias Ihme, Qingkai Kong, Donald D. Lucas, Stephen C. Myers</author><pubDate>Wed, 18 Dec 2024 18:46:15 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.10945v2</guid></item><item><title>MCMat: Multiview-Consistent and Physically Accurate PBR Material Generation</title><link>http://arxiv.org/abs/2412.14148v1</link><description>Existing 2D methods utilize UNet-based diffusion models to generatemulti-view physically-based rendering (PBR) maps but struggle with multi-viewinconsistency, while some 3D methods directly generate UV maps, encounteringgeneralization issues due to the limited 3D data. To address these problems, wepropose a two-stage approach, including multi-view generation and UV materialsrefinement. In the generation stage, we adopt a Diffusion Transformer (DiT)model to generate PBR materials, where both the specially designed multi-branchDiT and reference-based DiT blocks adopt a global attention mechanism topromote feature interaction and fusion between different views, therebyimproving multi-view consistency. In addition, we adopt a PBR-based diffusionloss to ensure that the generated materials align with realistic physicalprinciples. In the refinement stage, we propose a material-refined DiT thatperforms inpainting in empty areas and enhances details in UV space. Except forthe normal condition, this refinement also takes the material map from thegeneration stage as an additional condition to reduce the learning difficultyand improve generalization. Extensive experiments show that our method achievesstate-of-the-art performance in texturing 3D objects with PBR materials andprovides significant advantages for graphics relighting applications. ProjectPage: https://lingtengqiu.github.io/2024/MCMat/</description><author>Shenhao Zhu, Lingteng Qiu, Xiaodong Gu, Zhengyi Zhao, Chao Xu, Yuxiao He, Zhe Li, Xiaoguang Han, Yao Yao, Xun Cao, Siyu Zhu, Weihao Yuan, Zilong Dong, Hao Zhu</author><pubDate>Wed, 18 Dec 2024 18:45:35 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.14148v1</guid></item><item><title>Advanced Reasoning and Transformation Engine for Multi-Step Insight Synthesis in Data Analytics with Large Language Models</title><link>http://arxiv.org/abs/2412.14146v1</link><description>This paper presents the Advanced Reasoning and Transformation Engine forMulti-Step Insight Synthesis in Data Analytics (ARTEMIS-DA), a novel frameworkdesigned to augment Large Language Models (LLMs) for solving complex,multi-step data analytics tasks. ARTEMIS-DA integrates three core components:the Planner, which dissects complex user queries into structured, sequentialinstructions encompassing data preprocessing, transformation, predictivemodeling, and visualization; the Coder, which dynamically generates andexecutes Python code to implement these instructions; and the Grapher, whichinterprets generated visualizations to derive actionable insights. Byorchestrating the collaboration between these components, ARTEMIS-DAeffectively manages sophisticated analytical workflows involving advancedreasoning, multi-step transformations, and synthesis across diverse datamodalities. The framework achieves state-of-the-art (SOTA) performance onbenchmarks such as WikiTableQuestions and TabFact, demonstrating its ability totackle intricate analytical tasks with precision and adaptability. By combiningthe reasoning capabilities of LLMs with automated code generation and executionand visual analysis, ARTEMIS-DA offers a robust, scalable solution formulti-step insight synthesis, addressing a wide range of challenges in dataanalytics.</description><author>Atin Sakkeer Hussain</author><pubDate>Wed, 18 Dec 2024 18:44:08 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.14146v1</guid></item><item><title>Incorporating Feature Pyramid Tokenization and Open Vocabulary Semantic Segmentation</title><link>http://arxiv.org/abs/2412.14145v1</link><description>The visual understanding are often approached from 3 granular levels: image,patch and pixel. Visual Tokenization, trained by self-supervised reconstructivelearning, compresses visual data by codebook in patch-level with marginalinformation loss, but the visual tokens does not have semantic meaning. OpenVocabulary semantic segmentation benefits from the evolving Vision-Languagemodels (VLMs) with strong image zero-shot capability, but transferringimage-level to pixel-level understanding remains an imminent challenge. In thispaper, we treat segmentation as tokenizing pixels and study a united perceptualand semantic token compression for all granular understanding and consequentlyfacilitate open vocabulary semantic segmentation. Referring to the cognitiveprocess of pretrained VLM where the low-level features are progressivelycomposed to high-level semantics, we propose Feature Pyramid Tokenization (PAT)to cluster and represent multi-resolution feature by learnable codebooks andthen decode them by joint learning pixel reconstruction and semanticsegmentation. We design loosely coupled pixel and semantic learning branches.The pixel branch simulates bottom-up composition and top-down visualization ofcodebook tokens, while the semantic branch collectively fuse hierarchicalcodebooks as auxiliary segmentation guidance. Our experiments show that PATenhances the semantic intuition of VLM feature pyramid, improves performanceover the baseline segmentation model and achieves competitive performance onopen vocabulary semantic segmentation benchmark. Our model isparameter-efficient for VLM integration and flexible for the independenttokenization. We hope to give inspiration not only on improving segmentationbut also on semantic visual token utilization.</description><author>Jianyu Zhang, Li Zhang, Shijian Li</author><pubDate>Wed, 18 Dec 2024 18:43:21 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.14145v1</guid></item><item><title>Representative Social Choice: From Learning Theory to AI Alignment</title><link>http://arxiv.org/abs/2410.23953v3</link><description>Social choice theory is the study of preference aggregation across apopulation, used both in mechanism design for human agents and in thedemocratic alignment of language models. In this study, we propose therepresentative social choice framework for the modeling of democraticrepresentation in collective decisions, where the number of issues andindividuals are too large for mechanisms to consider all preferences directly.These scenarios are widespread in real-world decision-making processes, such asjury trials, indirect elections, legislation processes, corporate governance,and, more recently, language model alignment. In representative social choice,the population is represented by a finite sample of individual-issue pairsbased on which social choice decisions are made. We show that many of thedeepest questions in representative social choice can be naturally formulatedas statistical learning problems, and prove the generalization properties ofsocial choice mechanisms using the theory of machine learning. We furtherformulate axioms for representative social choice, and prove Arrow-likeimpossibility theorems with new combinatorial tools of analysis. Our frameworkintroduces the representative approach to social choice, opening up researchdirections at the intersection of social choice, learning theory, and AIalignment.</description><author>Tianyi Qiu</author><pubDate>Wed, 18 Dec 2024 18:41:48 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.23953v3</guid></item><item><title>On Calibration in Multi-Distribution Learning</title><link>http://arxiv.org/abs/2412.14142v1</link><description>Modern challenges of robustness, fairness, and decision-making in machinelearning have led to the formulation of multi-distribution learning (MDL)frameworks in which a predictor is optimized across multiple distributions. Westudy the calibration properties of MDL to better understand how the predictorperforms uniformly across the multiple distributions. Through classical resultson decomposing proper scoring losses, we first derive the Bayes optimal rulefor MDL, demonstrating that it maximizes the generalized entropy of theassociated loss function. Our analysis reveals that while this approach ensuresminimal worst-case loss, it can lead to non-uniform calibration errors acrossthe multiple distributions and there is an inherent calibration-refinementtrade-off, even at Bayes optimality. Our results highlight a criticallimitation: despite the promise of MDL, one must use caution when designingpredictors tailored to multiple distributions so as to minimize disparity.</description><author>Rajeev Verma, Volker Fischer, Eric Nalisnick</author><pubDate>Wed, 18 Dec 2024 18:41:40 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.14142v1</guid></item><item><title>LLMs can realize combinatorial creativity: generating creative ideas via LLMs for scientific research</title><link>http://arxiv.org/abs/2412.14141v1</link><description>Scientific idea generation has been extensively studied in creativity theoryand computational creativity research, providing valuable frameworks forunderstanding and implementing creative processes. However, recent work usingLarge Language Models (LLMs) for research idea generation often overlooks thesetheoretical foundations. We present a framework that explicitly implementscombinatorial creativity theory using LLMs, featuring a generalization-levelretrieval system for cross-domain knowledge discovery and a structuredcombinatorial process for idea generation. The retrieval system maps conceptsacross different abstraction levels to enable meaningful connections betweendisparate domains, while the combinatorial process systematically analyzes andrecombines components to generate novel solutions. Experiments on the OAG-Benchdataset demonstrate our framework's effectiveness, consistently outperformingbaseline approaches in generating ideas that align with real researchdevelopments (improving similarity scores by 7\%-10\% across multiple metrics).Our results provide strong evidence that LLMs can effectively realizecombinatorial creativity when guided by appropriate theoretical frameworks,contributing both to practical advancement of AI-assisted research andtheoretical understanding of machine creativity.</description><author>Tianyang Gu, Jingjin Wang, Zhihao Zhang, HaoHong Li</author><pubDate>Wed, 18 Dec 2024 18:41:14 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.14141v1</guid></item><item><title>GLIDER: Grading LLM Interactions and Decisions using Explainable Ranking</title><link>http://arxiv.org/abs/2412.14140v1</link><description>The LLM-as-judge paradigm is increasingly being adopted for automatedevaluation of model outputs. While LLM judges have shown promise on constrainedevaluation tasks, closed source LLMs display critical shortcomings whendeployed in real world applications due to challenges of fine grained metricsand explainability, while task specific evaluation models lack cross-domaingeneralization. We introduce GLIDER, a powerful 3B evaluator LLM that can scoreany text input and associated context on arbitrary user defined criteria.GLIDER shows higher Pearson's correlation than GPT-4o on FLASK and greatlyoutperforms prior evaluation models, achieving comparable performance to LLMs17x its size. GLIDER supports fine-grained scoring, multilingual reasoning,span highlighting and was trained on 685 domains and 183 criteria. Extensivequalitative analysis shows that GLIDER scores are highly correlated with humanjudgments, with 91.3% human agreement. We have open-sourced GLIDER tofacilitate future research.</description><author>Darshan Deshpande, Selvan Sunitha Ravi, Sky CH-Wang, Bartosz Mielczarek, Anand Kannappan, Rebecca Qian</author><pubDate>Wed, 18 Dec 2024 18:41:12 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.14140v1</guid></item><item><title>The VOROS: Lifting ROC curves to 3D</title><link>http://arxiv.org/abs/2402.18689v2</link><description>While the area under the ROC curve is perhaps the most common measure that isused to rank the relative performance of different binary classifiers,longstanding field folklore has noted that it can be a measure thatill-captures the benefits of different classifiers when either the actual classvalues or misclassification costs are highly unbalanced between the twoclasses. We introduce a new ROC surface, and the VOROS, a volume over this ROCsurface, as a natural way to capture these costs, by lifting the ROC curve to3D. Compared to previous attempts to generalize the ROC curve, our formulationalso provides a simple and intuitive way to model the scenario when onlyranges, rather than exact values, are known for possible class imbalance andmisclassification costs.</description><author>Christopher Ratigan, Lenore Cowen</author><pubDate>Wed, 18 Dec 2024 18:35:09 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.18689v2</guid></item><item><title>Design choices made by LLM-based test generators prevent them from finding bugs</title><link>http://arxiv.org/abs/2412.14137v1</link><description>There is an increasing amount of research and commercial tools for automatedtest case generation using Large Language Models (LLMs). This paper criticallyexamines whether recent LLM-based test generation tools, such as CodiumCoverAgent and CoverUp, can effectively find bugs or unintentionally validatefaulty code. Considering bugs are only exposed by failing test cases, weexplore the question: can these tools truly achieve the intended objectives ofsoftware testing when their test oracles are designed to pass? Using realhuman-written buggy code as input, we evaluate these tools, showing howLLM-generated tests can fail to detect bugs and, more alarmingly, how theirdesign can worsen the situation by validating bugs in the generated test suiteand rejecting bug-revealing tests. These findings raise important questionsabout the validity of the design behind LLM-based test generation tools andtheir impact on software quality and test suite reliability.</description><author>Noble Saji Mathews, Meiyappan Nagappan</author><pubDate>Wed, 18 Dec 2024 18:33:26 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.14137v1</guid></item><item><title>Walk Wisely on Graph: Knowledge Graph Reasoning with Dual Agents via Efficient Guidance-Exploration</title><link>http://arxiv.org/abs/2408.01880v4</link><description>Recent years, multi-hop reasoning has been widely studied for knowledge graph(KG) reasoning due to its efficacy and interpretability. However, previousmulti-hop reasoning approaches are subject to two primary shortcomings. First,agents struggle to learn effective and robust policies at the early phase dueto sparse rewards. Second, these approaches often falter on specific datasetslike sparse knowledge graphs, where agents are required to traverse lengthyreasoning paths. To address these problems, we propose a multi-hop reasoningmodel with dual agents based on hierarchical reinforcement learning (HRL),which is named FULORA. FULORA tackles the above reasoning challenges byeFficient GUidance-ExpLORAtion between dual agents. The high-level agent walkson the simplified knowledge graph to provide stage-wise hints for the low-levelagent walking on the original knowledge graph. In this framework, the low-levelagent optimizes a value function that balances two objectives: (1) maximizingreturn, and (2) integrating efficient guidance from the high-level agent.Experiments conducted on three real-word knowledge graph datasets demonstratethat FULORA outperforms RL-based baselines, especially in the case oflong-distance reasoning.</description><author>Zijian Wang, Bin Wang, Haifeng Jing, Huayu Li, Hongbo Dou</author><pubDate>Wed, 18 Dec 2024 18:31:42 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.01880v4</guid></item><item><title>Scaling of Search and Learning: A Roadmap to Reproduce o1 from Reinforcement Learning Perspective</title><link>http://arxiv.org/abs/2412.14135v1</link><description>OpenAI o1 represents a significant milestone in Artificial Inteiligence,which achieves expert-level performances on many challanging tasks that requirestrong reasoning ability.OpenAI has claimed that the main techinique behinds o1is the reinforcement learining. Recent works use alternative approaches likeknowledge distillation to imitate o1's reasoning style, but their effectivenessis limited by the capability ceiling of the teacher model. Therefore, thispaper analyzes the roadmap to achieving o1 from the perspective ofreinforcement learning, focusing on four key components: policy initialization,reward design, search, and learning. Policy initialization enables models todevelop human-like reasoning behaviors, equipping them with the ability toeffectively explore solution spaces for complex problems. Reward designprovides dense and effective signals via reward shaping or reward modeling,which is the guidance for both search and learning. Search plays a crucial rolein generating high-quality solutions during both training and testing phases,which can produce better solutions with more computation. Learning utilizes thedata generated by search for improving policy, which can achieve the betterperformance with more parameters and more searched data. Existing open-sourceprojects that attempt to reproduce o1 can be seem as a part or a variant of ourroadmap. Collectively, these components underscore how learning and searchdrive o1's advancement, making meaningful contributions to the development ofLLM.</description><author>Zhiyuan Zeng, Qinyuan Cheng, Zhangyue Yin, Bo Wang, Shimin Li, Yunhua Zhou, Qipeng Guo, Xuanjing Huang, Xipeng Qiu</author><pubDate>Wed, 18 Dec 2024 18:24:47 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.14135v1</guid></item><item><title>Performance Gap in Entity Knowledge Extraction Across Modalities in Vision Language Models</title><link>http://arxiv.org/abs/2412.14133v1</link><description>Vision-language models (VLMs) excel at extracting and reasoning aboutinformation from images. Yet, their capacity to leverage internal knowledgeabout specific entities remains underexplored. This work investigates thedisparity in model performance when answering factual questions about an entitydescribed in text versus depicted in an image. Our results reveal a significantaccuracy drop --averaging 19%-- when the entity is presented visually insteadof textually. We hypothesize that this decline arises from limitations in howinformation flows from image tokens to query tokens. We use mechanisticinterpretability tools to reveal that, although image tokens are preprocessedby the vision encoder, meaningful information flow from these tokens occursonly in the much deeper layers. Furthermore, critical image processing happensin the language model's middle layers, allowing few layers for consecutivereasoning, highlighting a potential inefficiency in how the model utilizes itslayers for reasoning. These insights shed light on the internal mechanics ofVLMs and offer pathways for enhancing their reasoning capabilities.</description><author>Ido Cohen, Daniela Gottesman, Mor Geva, Raja Giryes</author><pubDate>Wed, 18 Dec 2024 18:22:30 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.14133v1</guid></item><item><title>SwitchCIT: Switching for Continual Instruction Tuning</title><link>http://arxiv.org/abs/2407.11780v2</link><description>Large language models (LLMs) and multimodal models (MMs) have exhibitedimpressive capabilities in various domains, particularly in general languageunderstanding and visual reasoning. However, these models, trained on massivedata, may not be finely optimized for specific tasks triggered by instructions.Continual instruction tuning is crucial to adapt a large model to evolvingtasks and domains, ensuring their effectiveness and relevance across a widerange of applications. In the context of continual instruction tuning, wheremodels are sequentially trained on different tasks, catastrophic forgetting canoccur, leading to performance degradation on previously learned tasks. Thiswork addresses the catastrophic forgetting in continual instruction learningthrough a switching mechanism for routing computations to parameter-efficienttuned models. We demonstrate the effectiveness of our method throughexperiments on continual instruction tuning of different natural languagegeneration tasks and vision-language tasks. We also showcase the advantages ofour proposed method in terms of efficiency, scalability, portability, andprivacy preservation.</description><author>Xinbo Wu, Max Hartman, Vidhata Arjun Jayaraman, Lav R. Varshney</author><pubDate>Wed, 18 Dec 2024 18:21:53 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.11780v2</guid></item><item><title>jinns: a JAX Library for Physics-Informed Neural Networks</title><link>http://arxiv.org/abs/2412.14132v1</link><description>jinns is an open-source Python library for physics-informed neural networks,built to tackle both forward and inverse problems, as well as meta-modellearning. Rooted in the JAX ecosystem, it provides a versatile framework forefficiently prototyping real-problems, while easily allowing extensions tospecific needs. Furthermore, the implementation leverages existing popular JAXlibraries such as equinox and optax for model definition and optimisation,bringing a sense of familiarity to the user. Many models are available asbaselines, and the documentation provides reference implementations ofdifferent use-cases along with step-by-step tutorials for extensions tospecific needs. The code is available on Gitlabhttps://gitlab.com/mia_jinns/jinns.</description><author>Hugo Gangloff, Nicolas Jouvin</author><pubDate>Wed, 18 Dec 2024 18:21:41 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.14132v1</guid></item><item><title>Go With the Flow: Fast Diffusion for Gaussian Mixture Models</title><link>http://arxiv.org/abs/2412.09059v2</link><description>Schr\"{o}dinger Bridges (SB) are diffusion processes that steer, in finitetime, a given initial distribution to another final one while minimizing asuitable cost functional. Although various methods for computing SBs haverecently been proposed in the literature, most of these approaches requirecomputationally expensive training schemes, even for solving low-dimensionalproblems. In this work, we propose an analytic parametrization of a set offeasible policies for steering the distribution of a dynamical system from oneGaussian Mixture Model (GMM) to another. Instead of relying on standardnon-convex optimization techniques, the optimal policy within the set can beapproximated as the solution of a low-dimensional linear program whosedimension scales linearly with the number of components in each mixture.Furthermore, our method generalizes naturally to more general classes ofdynamical systems such as controllable Linear Time-Varying systems that cannotcurrently be solved using traditional neural SB approaches. We showcase thepotential of this approach in low-to-moderate dimensional problems such asimage-to-image translation in the latent space of an autoencoder, and variousother examples. We also benchmark our approach on an Entropic Optimal Transport(EOT) problem and show that it outperforms state-of-the-art methods in caseswhere the boundary distributions are mixture models while requiring virtuallyno training.</description><author>George Rapakoulias, Ali Reza Pedram, Panagiotis Tsiotras</author><pubDate>Wed, 18 Dec 2024 18:20:14 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.09059v2</guid></item><item><title>AnySat: An Earth Observation Model for Any Resolutions, Scales, and Modalities</title><link>http://arxiv.org/abs/2412.14123v1</link><description>Geospatial models must adapt to the diversity of Earth observation data interms of resolutions, scales, and modalities. However, existing approachesexpect fixed input configurations, which limits their practical applicability.We propose AnySat, a multimodal model based on joint embedding predictivearchitecture (JEPA) and resolution-adaptive spatial encoders, allowing us totrain a single model on highly heterogeneous data in a self-supervised manner.To demonstrate the advantages of this unified approach, we compile GeoPlex, acollection of $5$ multimodal datasets with varying characteristics and $11$distinct sensors. We then train a single powerful model on these diversedatasets simultaneously. Once fine-tuned, we achieve better or nearstate-of-the-art results on the datasets of GeoPlex and $4$ additional ones for$5$ environment monitoring tasks: land cover mapping, tree speciesidentification, crop type classification, change detection, and floodsegmentation. The code and models are available athttps://github.com/gastruc/AnySat.</description><author>Guillaume Astruc, Nicolas Gonthier, Clement Mallet, Loic Landrieu</author><pubDate>Wed, 18 Dec 2024 18:11:53 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.14123v1</guid></item><item><title>SwiftTry: Fast and Consistent Video Virtual Try-On with Diffusion Models</title><link>http://arxiv.org/abs/2412.10178v2</link><description>Given an input video of a person and a new garment, the objective of thispaper is to synthesize a new video where the person is wearing the specifiedgarment while maintaining spatiotemporal consistency. Although significantadvances have been made in image-based virtual try-on, extending thesesuccesses to video often leads to frame-to-frame inconsistencies. Someapproaches have attempted to address this by increasing the overlap of framesacross multiple video chunks, but this comes at a steep computational cost dueto the repeated processing of the same frames, especially for long videosequences. To tackle these challenges, we reconceptualize video virtual try-onas a conditional video inpainting task, with garments serving as inputconditions. Specifically, our approach enhances image diffusion models byincorporating temporal attention layers to improve temporal coherence. Toreduce computational overhead, we propose ShiftCaching, a novel technique thatmaintains temporal consistency while minimizing redundant computations.Furthermore, we introduce the TikTokDress dataset, a new video try-on datasetfeaturing more complex backgrounds, challenging movements, and higherresolution compared to existing public datasets. Extensive experimentsdemonstrate that our approach outperforms current baselines, particularly interms of video consistency and inference speed. The project page is availableat https://swift-try.github.io/.</description><author>Hung Nguyen, Quang Qui-Vinh Nguyen, Khoi Nguyen, Rang Nguyen</author><pubDate>Wed, 18 Dec 2024 18:05:43 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.10178v2</guid></item><item><title>GaraMoSt: Parallel Multi-Granularity Motion and Structural Modeling for Efficient Multi-Frame Interpolation in DSA Images</title><link>http://arxiv.org/abs/2412.14118v1</link><description>The rapid and accurate direct multi-frame interpolation method for DigitalSubtraction Angiography (DSA) images is crucial for reducing radiation andproviding real-time assistance to physicians for precise diagnostics andtreatment. DSA images contain complex vascular structures and various motions.Applying natural scene Video Frame Interpolation (VFI) methods results inmotion artifacts, structural dissipation, and blurriness. Recently, MoSt-DSAhas specifically addressed these issues for the first time and achieved SOTAresults. However, MoSt-DSA's focus on real-time performance leads toinsufficient suppression of high-frequency noise and incomplete filtering oflow-frequency noise in the generated images. To address these issues within thesame computational time scale, we propose GaraMoSt. Specifically, we optimizethe network pipeline with a parallel design and propose a module named MG-MSFE.MG-MSFE extracts frame-relative motion and structural features at variousgranularities in a fully convolutional parallel manner and supportsindependent, flexible adjustment of context-aware granularity at differentscales, thus enhancing computational efficiency and accuracy. Extensiveexperiments demonstrate that GaraMoSt achieves the SOTA performance inaccuracy, robustness, visual effects, and noise suppression, comprehensivelysurpassing MoSt-DSA and other natural scene VFI methods. The code and modelsare available at https://github.com/ZyoungXu/GaraMoSt.</description><author>Ziyang Xu, Huangxuan Zhao, Wenyu Liu, Xinggang Wang</author><pubDate>Wed, 18 Dec 2024 18:04:12 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.14118v1</guid></item><item><title>Trustworthy Transfer Learning: A Survey</title><link>http://arxiv.org/abs/2412.14116v1</link><description>Transfer learning aims to transfer knowledge or information from a sourcedomain to a relevant target domain. In this paper, we understand transferlearning from the perspectives of knowledge transferability andtrustworthiness. This involves two research questions: How is knowledgetransferability quantitatively measured and enhanced across domains? Can wetrust the transferred knowledge in the transfer learning process? To answerthese questions, this paper provides a comprehensive review of trustworthytransfer learning from various aspects, including problem definitions,theoretical analysis, empirical algorithms, and real-world applications.Specifically, we summarize recent theories and algorithms for understandingknowledge transferability under (within-domain) IID and non-IID assumptions. Inaddition to knowledge transferability, we review the impact of trustworthinesson transfer learning, e.g., whether the transferred knowledge is adversariallyrobust or algorithmically fair, how to transfer the knowledge underprivacy-preserving constraints, etc. Beyond discussing the currentadvancements, we highlight the open questions and future directions forunderstanding transfer learning in a reliable and trustworthy manner.</description><author>Jun Wu, Jingrui He</author><pubDate>Wed, 18 Dec 2024 18:03:51 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.14116v1</guid></item><item><title>Event-based Photometric Bundle Adjustment</title><link>http://arxiv.org/abs/2412.14111v1</link><description>We tackle the problem of bundle adjustment (i.e., simultaneous refinement ofcamera poses and scene map) for a purely rotating event camera. Starting fromfirst principles, we formulate the problem as a classical non-linear leastsquares optimization. The photometric error is defined using the eventgeneration model directly in the camera rotations and the semi-dense scenebrightness that triggers the events. We leverage the sparsity of event data todesign a tractable Levenberg-Marquardt solver that handles the very largenumber of variables involved. To the best of our knowledge, our method, whichwe call Event-based Photometric Bundle Adjustment (EPBA), is the firstevent-only photometric bundle adjustment method that works on the brightnessmap directly and exploits the space-time characteristics of event data, withouthaving to convert events into image-like representations. Comprehensiveexperiments on both synthetic and real-world datasets demonstrate EPBA'seffectiveness in decreasing the photometric error (by up to 90%), yieldingresults of unparalleled quality. The refined maps reveal details that werehidden using prior state-of-the-art rotation-only estimation methods. Theexperiments on modern high-resolution event cameras show the applicability ofEPBA to panoramic imaging in various scenarios (without map initialization, atmultiple resolutions, and in combination with other methods, such as IMU deadreckoning or previous event-based rotation estimation methods). We make thesource code publicly available. https://github.com/tub-rip/epba</description><author>Shuang Guo, Guillermo Gallego</author><pubDate>Wed, 18 Dec 2024 17:58:16 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.14111v1</guid></item><item><title>RAZOR: Sharpening Knowledge by Cutting Bias with Unsupervised Text Rewriting</title><link>http://arxiv.org/abs/2412.07675v2</link><description>Despite the widespread use of LLMs due to their superior performance invarious tasks, their high computational costs often lead potential users to optfor the pretraining-finetuning pipeline. However, biases prevalent in manuallyconstructed datasets can introduce spurious correlations between tokens andlabels, creating so-called shortcuts and hindering the generalizability offine-tuned models. Existing debiasing methods often rely on prior knowledge ofspecific dataset biases, which is challenging to acquire a priori. We proposeRAZOR (Rewriting And Zero-bias Optimization Refinement), a novel, unsupervised,and data-focused debiasing approach based on text rewriting for shortcutmitigation. RAZOR leverages LLMs to iteratively rewrite potentially biased textsegments by replacing them with heuristically selected alternatives in ashortcut space defined by token statistics and positional information. Thisprocess aims to align surface-level text features more closely with diverselabel distributions, thereby promoting the learning of genuine linguisticpatterns. Compared with unsupervised SoTA models, RAZOR improves by 3.5% on theFEVER and 6.5% on MNLI and SNLI datasets according to the F1 score.Additionally, RAZOR effectively mitigates specific known biases, reducingbias-related terms by x2 without requiring prior bias information, a resultthat is on par with SoTA models that leverage prior information. Our workprioritizes data manipulation over architectural modifications, emphasizing thepivotal role of data quality in enhancing model performance and fairness. Thisresearch contributes to developing more robust evaluation benchmarks fordebiasing methods by incorporating metrics for bias reduction and overall modelefficacy.</description><author>Shuo Yang, Bardh Prenkaj, Gjergji Kasneci</author><pubDate>Wed, 18 Dec 2024 17:54:30 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.07675v2</guid></item><item><title>Machine Learning Co-pilot for Screening of Organic Molecular Additives for Perovskite Solar Cells</title><link>http://arxiv.org/abs/2412.14109v1</link><description>Machine learning (ML) has been extensively employed in planar perovskitephotovoltaics to screen effective organic molecular additives, whileencountering predictive biases for novel materials due to small datasets andreliance on predefined descriptors. Present work thus proposes an effectiveapproach, Co-Pilot for Perovskite Additive Screener (Co-PAS), an ML-drivenframework designed to accelerate additive screening for perovskite solar cells(PSCs). Co-PAS overcomes predictive biases by integrating the MolecularScaffold Classifier (MSC) for scaffold-based pre-screening and utilizingJunction Tree Variational Autoencoder (JTVAE) latent vectors to enhancemolecular structure representation, thereby enhancing the accuracy of powerconversion efficiency (PCE) predictions. Leveraging Co-PAS, we integrate domainknowledge to screen an extensive dataset of 250,000 molecules from PubChem,prioritizing candidates based on predicted PCE values and key molecularproperties such as donor number, dipole moment, and hydrogen bond acceptorcount. This workflow leads to the identification of several promisingpassivating molecules, including the novel Boc-L-threonine N-hydroxysuccinimideester (BTN), which, to our knowledge, has not been explored as an additive inPSCs and achieves a device PCE of 25.20%. Our results underscore the potentialof Co-PAS in advancing additive discovery for high-performance PSCs.</description><author>Yang Pu, Zhiyuan Dai, Yifan Zhou, Ning Jia, Hongyue Wang, Yerzhan Mukhametkarimov, Ruihao Chen, Hongqiang Wang, Zhe Liu</author><pubDate>Wed, 18 Dec 2024 17:52:45 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.14109v1</guid></item><item><title>Using Large Language Models for Expert Prior Elicitation in Predictive Modelling</title><link>http://arxiv.org/abs/2411.17284v3</link><description>Large language models (LLMs), trained on diverse data effectively acquire abreadth of information across various domains. However, their computationalcomplexity, cost, and lack of transparency hinder their direct application forspecialised tasks. In fields such as clinical research, acquiring expertannotations or prior knowledge about predictive models is often costly andtime-consuming. This study proposes the use of LLMs to elicit expert priordistributions for predictive models. This approach also provides an alternativeto in-context learning, where language models are tasked with makingpredictions directly. In this work, we compare LLM-elicited and uninformativepriors, evaluate whether LLMs truthfully generate parameter distributions, andpropose a model selection strategy for in-context learning and priorelicitation. Our findings show that LLM-elicited prior parameter distributionssignificantly reduce predictive error compared to uninformative priors inlow-data settings. Applied to clinical problems, this translates to fewerrequired biological samples, lowering cost and resources. Prior elicitationalso consistently outperforms and proves more reliable than in-context learningat a lower cost, making it a preferred alternative in our setting. Wedemonstrate the utility of this method across various use cases, includingclinical applications. For infection prediction, using LLM-elicited priorsreduced the number of required labels to achieve the same accuracy as anuninformative prior by 55%, 200 days earlier in the study.</description><author>Alexander Capstick, Rahul G. Krishnan, Payam Barnaghi</author><pubDate>Wed, 18 Dec 2024 17:51:52 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2411.17284v3</guid></item><item><title>Foundation Models Meet Low-Cost Sensors: Test-Time Adaptation for Rescaling Disparity for Zero-Shot Metric Depth Estimation</title><link>http://arxiv.org/abs/2412.14103v1</link><description>The recent development of foundation models for monocular depth estimationsuch as Depth Anything paved the way to zero-shot monocular depth estimation.Since it returns an affine-invariant disparity map, the favored technique torecover the metric depth consists in fine-tuning the model. However, this stageis costly to perform because of the training but also due to the creation ofthe dataset. It must contain images captured by the camera that will be used attest time and the corresponding ground truth. Moreover, the fine-tuning mayalso degrade the generalizing capacity of the original model. Instead, wepropose in this paper a new method to rescale Depth Anything predictions using3D points provided by low-cost sensors or techniques such as low-resolutionLiDAR, stereo camera, structure-from-motion where poses are given by an IMU.Thus, this approach avoids fine-tuning and preserves the generalizing power ofthe original depth estimation model while being robust to the noise of thesensor or of the depth model. Our experiments highlight improvements relativeto other metric depth estimation methods and competitive results compared tofine-tuned approaches. Code available athttps://gitlab.ensta.fr/ssh/monocular-depth-rescaling.</description><author>Rémi Marsal, Alexandre Chapoutot, Philippe Xu, David Filliat</author><pubDate>Wed, 18 Dec 2024 17:50:15 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.14103v1</guid></item><item><title>EvalGIM: A Library for Evaluating Generative Image Models</title><link>http://arxiv.org/abs/2412.10604v2</link><description>As the use of text-to-image generative models increases, so does the adoptionof automatic benchmarking methods used in their evaluation. However, whilemetrics and datasets abound, there are few unified benchmarking libraries thatprovide a framework for performing evaluations across many datasets andmetrics. Furthermore, the rapid introduction of increasingly robustbenchmarking methods requires that evaluation libraries remain flexible to newdatasets and metrics. Finally, there remains a gap in synthesizing evaluationsin order to deliver actionable takeaways about model performance. To enableunified, flexible, and actionable evaluations, we introduce EvalGIM (pronounced''EvalGym''), a library for evaluating generative image models. EvalGIMcontains broad support for datasets and metrics used to measure quality,diversity, and consistency of text-to-image generative models. In addition,EvalGIM is designed with flexibility for user customization as a top priorityand contains a structure that allows plug-and-play additions of new datasetsand metrics. To enable actionable evaluation insights, we introduce''Evaluation Exercises'' that highlight takeaways for specific evaluationquestions. The Evaluation Exercises contain easy-to-use and reproducibleimplementations of two state-of-the-art evaluation methods of text-to-imagegenerative models: consistency-diversity-realism Pareto Fronts anddisaggregated measurements of performance disparities across groups. EvalGIMalso contains Evaluation Exercises that introduce two new analysis methods fortext-to-image generative models: robustness analyses of model rankings andbalanced evaluations across different prompt styles. We encourage text-to-imagemodel exploration with EvalGIM and invite contributions athttps://github.com/facebookresearch/EvalGIM/.</description><author>Melissa Hall, Oscar Mañas, Reyhane Askari-Hemmat, Mark Ibrahim, Candace Ross, Pietro Astolfi, Tariq Berrada Ifriqi, Marton Havasi, Yohann Benchetrit, Karen Ullrich, Carolina Braga, Abhishek Charnalia, Maeve Ryan, Mike Rabbat, Michal Drozdzal, Jakob Verbeek, Adriana Romero-Soriano</author><pubDate>Wed, 18 Dec 2024 17:49:32 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.10604v2</guid></item><item><title>Parameter-efficient Fine-tuning for improved Convolutional Baseline for Brain Tumor Segmentation in Sub-Saharan Africa Adult Glioma Dataset</title><link>http://arxiv.org/abs/2412.14100v1</link><description>Automating brain tumor segmentation using deep learning methods is an ongoingchallenge in medical imaging. Multiple lingering issues exist includingdomain-shift and applications in low-resource settings which brings a uniqueset of challenges including scarcity of data. As a step towards solving thesespecific problems, we propose Convolutional adapter-inspiredParameter-efficient Fine-tuning (PEFT) of MedNeXt architecture. To validate ouridea, we show our method performs comparable to full fine-tuning with the addedbenefit of reduced training compute using BraTS-2021 as pre-training datasetand BraTS-Africa as the fine-tuning dataset. BraTS-Africa consists of a smalldataset (60 train / 35 validation) from the Sub-Saharan African population withmarked shift in the MRI quality compared to BraTS-2021 (1251 train samples). Wefirst show that models trained on BraTS-2021 dataset do not generalize well toBraTS-Africa as shown by 20% reduction in mean dice on BraTS-Africa validationsamples. Then, we show that PEFT can leverage both the BraTS-2021 andBraTS-Africa dataset to obtain mean dice of 0.8 compared to 0.72 when trainedonly on BraTS-Africa. Finally, We show that PEFT (0.80 mean dice) results incomparable performance to full fine-tuning (0.77 mean dice) which may show PEFTto be better on average but the boxplots show that full finetuning results ismuch lesser variance in performance. Nevertheless, on disaggregation of thedice metrics, we find that the model has tendency to oversegment as shown byhigh specificity (0.99) compared to relatively low sensitivity(0.75). Thesource code is available athttps://github.com/CAMERA-MRI/SPARK2024/tree/main/PEFT_MedNeXt</description><author>Bijay Adhikari, Pratibha Kulung, Jakesh Bohaju, Laxmi Kanta Poudel, Confidence Raymond, Dong Zhang, Udunna C Anazodo, Bishesh Khanal, Mahesh Shakya</author><pubDate>Wed, 18 Dec 2024 17:48:32 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.14100v1</guid></item><item><title>Adaptive Concept Bottleneck for Foundation Models Under Distribution Shifts</title><link>http://arxiv.org/abs/2412.14097v1</link><description>Advancements in foundation models (FMs) have led to a paradigm shift inmachine learning. The rich, expressive feature representations from thesepre-trained, large-scale FMs are leveraged for multiple downstream tasks,usually via lightweight fine-tuning of a shallow fully-connected networkfollowing the representation. However, the non-interpretable, black-box natureof this prediction pipeline can be a challenge, especially in critical domainssuch as healthcare, finance, and security. In this paper, we explore thepotential of Concept Bottleneck Models (CBMs) for transforming complex,non-interpretable foundation models into interpretable decision-makingpipelines using high-level concept vectors. Specifically, we focus on thetest-time deployment of such an interpretable CBM pipeline "in the wild", wherethe input distribution often shifts from the original training distribution. Wefirst identify the potential failure modes of such a pipeline under differenttypes of distribution shifts. Then we propose an adaptive concept bottleneckframework to address these failure modes, that dynamically adapts theconcept-vector bank and the prediction layer based solely on unlabeled datafrom the target domain, without access to the source (training) dataset.Empirical evaluations with various real-world distribution shifts show that ouradaptation method produces concept-based interpretations better aligned withthe test data and boosts post-deployment accuracy by up to 28%, aligning theCBM performance with that of non-interpretable classification.</description><author>Jihye Choi, Jayaram Raghuram, Yixuan Li, Somesh Jha</author><pubDate>Wed, 18 Dec 2024 17:47:46 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.14097v1</guid></item><item><title>HeteroSample: Meta-path Guided Sampling for Heterogeneous Graph Representation Learning</title><link>http://arxiv.org/abs/2411.07022v2</link><description>The rapid expansion of Internet of Things (IoT) has resulted in vast,heterogeneous graphs that capture complex interactions among devices, sensors,and systems. Efficient analysis of these graphs is critical for derivinginsights in IoT scenarios such as smart cities, industrial IoT, and intelligenttransportation systems. However, the scale and diversity of IoT-generated datapresent significant challenges, and existing methods often struggle withpreserving the structural integrity and semantic richness of these complexgraphs. Many current approaches fail to maintain the balance betweencomputational efficiency and the quality of the insights generated, leading topotential loss of critical information necessary for accurate decision-makingin IoT applications. We introduce HeteroSample, a novel sampling methoddesigned to address these challenges by preserving the structural integrity,node and edge type distributions, and semantic patterns of IoT-related graphs.HeteroSample works by incorporating the novel top-leader selection, balancedneighborhood expansion, and meta-path guided sampling strategies. The key ideais to leverage the inherent heterogeneous structure and semantic relationshipsencoded by meta-paths to guide the sampling process. This approach ensures thatthe resulting subgraphs are representative of the original data whilesignificantly reducing computational overhead. Extensive experimentsdemonstrate that HeteroSample outperforms state-of-the-art methods, achievingup to 15% higher F1 scores in tasks such as link prediction and nodeclassification, while reducing runtime by 20%.These advantages makeHeteroSample a transformative tool for scalable and accurate IoT applications,enabling more effective and efficient analysis of complex IoT systems,ultimately driving advancements in smart cities, industrial IoT, and beyond.</description><author>Ao Liu, Jing Chen, Ruiying Du, Cong Wu, Yebo Feng, Teng Li, Jianfeng Ma</author><pubDate>Wed, 18 Dec 2024 17:46:57 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2411.07022v2</guid></item><item><title>Alignment faking in large language models</title><link>http://arxiv.org/abs/2412.14093v1</link><description>We present a demonstration of a large language model engaging in alignmentfaking: selectively complying with its training objective in training toprevent modification of its behavior out of training. First, we give Claude 3Opus a system prompt stating it is being trained to answer all queries, evenharmful ones, which conflicts with its prior training to refuse such queries.To allow the model to infer when it is in training, we say it will be trainedonly on conversations with free users, not paid users. We find the modelcomplies with harmful queries from free users 14% of the time, versus almostnever for paid users. Explaining this gap, in almost all cases where the modelcomplies with a harmful query from a free user, we observe explicitalignment-faking reasoning, with the model stating it is strategicallyanswering harmful queries in training to preserve its preferred harmlessnessbehavior out of training. Next, we study a more realistic setting whereinformation about the training process is provided not in a system prompt, butby training on synthetic documents that mimic pre-training data--and observesimilar alignment faking. Finally, we study the effect of actually training themodel to comply with harmful queries via reinforcement learning, which we findincreases the rate of alignment-faking reasoning to 78%, though also increasescompliance even out of training. We additionally observe other behaviors suchas the model exfiltrating its weights when given an easy opportunity. While wemade alignment faking easier by telling the model when and by what criteria itwas being trained, we did not instruct the model to fake alignment or give itany explicit goal. As future models might infer information about theirtraining process without being told, our results suggest a risk of alignmentfaking in future models, whether due to a benign preference--as in thiscase--or not.</description><author>Ryan Greenblatt, Carson Denison, Benjamin Wright, Fabien Roger, Monte MacDiarmid, Sam Marks, Johannes Treutlein, Tim Belonax, Jack Chen, David Duvenaud, Akbir Khan, Julian Michael, Sören Mindermann, Ethan Perez, Linda Petrini, Jonathan Uesato, Jared Kaplan, Buck Shlegeris, Samuel R. Bowman, Evan Hubinger</author><pubDate>Wed, 18 Dec 2024 17:41:24 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.14093v1</guid></item><item><title>CiTrus: Squeezing Extra Performance out of Low-data Bio-signal Transfer Learning</title><link>http://arxiv.org/abs/2412.11695v2</link><description>Transfer learning for bio-signals has recently become an important techniqueto improve prediction performance on downstream tasks with small bio-signaldatasets. Recent works have shown that pre-training a neural network model on alarge dataset (e.g. EEG) with a self-supervised task, replacing theself-supervised head with a linear classification head, and fine-tuning themodel on different downstream bio-signal datasets (e.g., EMG or ECG) candramatically improve the performance on those datasets. In this paper, wepropose a new convolution-transformer hybrid model architecture with maskedauto-encoding for low-data bio-signal transfer learning, introduce afrequency-based masked auto-encoding task, employ a more comprehensiveevaluation framework, and evaluate how much and when (multimodal) pre-trainingimproves fine-tuning performance. We also introduce a dramatically moreperformant method of aligning a downstream dataset with a different temporallength and sampling rate to the original pre-training dataset. Our findingsindicate that the convolution-only part of our hybrid model can achievestate-of-the-art performance on some low-data downstream tasks. The performanceis often improved even further with our full model. In the case oftransformer-based models we find that pre-training especially improvesperformance on downstream datasets, multimodal pre-training often increasesthose gains further, and our frequency-based pre-training performs the best onaverage for the lowest and highest data regimes.</description><author>Eloy Geenjaar, Lie Lu</author><pubDate>Wed, 18 Dec 2024 17:40:34 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.11695v2</guid></item><item><title>A Novel Generative Multi-Task Representation Learning Approach for Predicting Postoperative Complications in Cardiac Surgery Patients</title><link>http://arxiv.org/abs/2412.01950v2</link><description>Early detection of surgical complications allows for timely therapy andproactive risk mitigation. Machine learning (ML) can be leveraged to identifyand predict patient risks for postoperative complications. We developed andvalidated the effectiveness of predicting postoperative complications using anovel surgical Variational Autoencoder (surgVAE) that uncovers intrinsicpatterns via cross-task and cross-cohort presentation learning. Thisretrospective cohort study used data from the electronic health records ofadult surgical patients over four years (2018 - 2021). Six key postoperativecomplications for cardiac surgery were assessed: acute kidney injury, atrialfibrillation, cardiac arrest, deep vein thrombosis or pulmonary embolism, bloodtransfusion, and other intraoperative cardiac events. We compared predictionperformances of surgVAE against widely-used ML models and advancedrepresentation learning and generative models under 5-fold cross-validation.89,246 surgeries (49% male, median (IQR) age: 57 (45-69)) were included, with6,502 in the targeted cardiac surgery cohort (61% male, median (IQR) age: 60(53-70)). surgVAE demonstrated superior performance over existing ML solutionsacross all postoperative complications of cardiac surgery patients, achievingmacro-averaged AUPRC of 0.409 and macro-averaged AUROC of 0.831, which were3.4% and 3.7% higher, respectively, than the best alternative method (by AUPRCscores). Model interpretation using Integrated Gradients highlighted key riskfactors based on preoperative variable importance. surgVAE showed excellentdiscriminatory performance for predicting postoperative complications andaddressing the challenges of data complexity, small cohort sizes, andlow-frequency positive events. surgVAE enables data-driven predictions ofpatient risks and prognosis while enhancing the interpretability of patientrisk profiles.</description><author>Junbo Shen, Bing Xue, Thomas Kannampallil, Chenyang Lu, Joanna Abraham</author><pubDate>Wed, 18 Dec 2024 17:40:15 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.01950v2</guid></item><item><title>MagicPIG: LSH Sampling for Efficient LLM Generation</title><link>http://arxiv.org/abs/2410.16179v4</link><description>Large language models (LLMs) with long context windows have gainedsignificant attention. However, the KV cache, stored to avoid re-computation,becomes a bottleneck. Various dynamic sparse or TopK-based attentionapproximation methods have been proposed to leverage the common insight thatattention is sparse. In this paper, we first show that TopK attention itselfsuffers from quality degradation in certain downstream tasks because attentionis not always as sparse as expected. Rather than selecting the keys and valueswith the highest attention scores, sampling with theoretical guarantees canprovide a better estimation for attention output. To make the sampling-basedapproximation practical in LLM generation, we propose MagicPIG, a heterogeneoussystem based on Locality Sensitive Hashing (LSH). MagicPIG significantlyreduces the workload of attention computation while preserving high accuracyfor diverse tasks. MagicPIG stores the LSH hash tables and runs the attentioncomputation on the CPU, which allows it to serve longer contexts and largerbatch sizes with high approximation accuracy. MagicPIG can improve decodingthroughput by up to $5\times$ across various GPU hardware and achieve 54msdecoding latency on a single RTX 4090 for Llama-3.1-8B-Instruct model with acontext of 96k tokens. The code is available athttps://github.com/Infini-AI-Lab/MagicPIG.</description><author>Zhuoming Chen, Ranajoy Sadhukhan, Zihao Ye, Yang Zhou, Jianyu Zhang, Niklas Nolte, Yuandong Tian, Matthijs Douze, Leon Bottou, Zhihao Jia, Beidi Chen</author><pubDate>Wed, 18 Dec 2024 17:36:36 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.16179v4</guid></item><item><title>Joint Perception and Prediction for Autonomous Driving: A Survey</title><link>http://arxiv.org/abs/2412.14088v1</link><description>Perception and prediction modules are critical components of autonomousdriving systems, enabling vehicles to navigate safely through complexenvironments. The perception module is responsible for perceiving theenvironment, including static and dynamic objects, while the prediction moduleis responsible for predicting the future behavior of these objects. Thesemodules are typically divided into three tasks: object detection, objecttracking, and motion prediction. Traditionally, these tasks are developed andoptimized independently, with outputs passed sequentially from one to the next.However, this approach has significant limitations: computational resources arenot shared across tasks, the lack of joint optimization can amplify errors asthey propagate throughout the pipeline, and uncertainty is rarely propagatedbetween modules, resulting in significant information loss. To address thesechallenges, the joint perception and prediction paradigm has emerged,integrating perception and prediction into a unified model through multi-tasklearning. This strategy not only overcomes the limitations of previous methods,but also enables the three tasks to have direct access to raw sensor data,allowing richer and more nuanced environmental interpretations. This paperpresents the first comprehensive survey of joint perception and prediction forautonomous driving. We propose a taxonomy that categorizes approaches based oninput representation, scene context modeling, and output representation,highlighting their contributions and limitations. Additionally, we present aqualitative analysis and quantitative comparison of existing methods. Finally,we discuss future research directions based on identified gaps in thestate-of-the-art.</description><author>Lucas Dal'Col, Miguel Oliveira, Vítor Santos</author><pubDate>Wed, 18 Dec 2024 17:34:52 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.14088v1</guid></item><item><title>SEKE: Specialised Experts for Keyword Extraction</title><link>http://arxiv.org/abs/2412.14087v1</link><description>Keyword extraction involves identifying the most descriptive words in adocument, allowing automatic categorisation and summarisation of largequantities of diverse textual data. Relying on the insight that real-worldkeyword detection often requires handling of diverse content, we propose anovel supervised keyword extraction approach based on the mixture of experts(MoE) technique. MoE uses a learnable routing sub-network to direct informationto specialised experts, allowing them to specialize in distinct regions of theinput space. SEKE, a mixture of Specialised Experts for supervised KeywordExtraction, uses DeBERTa as the backbone model and builds on the MoE framework,where experts attend to each token, by integrating it with a recurrent neuralnetwork (RNN), to allow successful extraction even on smaller corpora, wherespecialisation is harder due to lack of training data. The MoE framework alsoprovides an insight into inner workings of individual experts, enhancing theexplainability of the approach. We benchmark SEKE on multiple English datasets,achieving state-of-the-art performance compared to strong supervised andunsupervised baselines. Our analysis reveals that depending on data size andtype, experts specialize in distinct syntactic and semantic components, such aspunctuation, stopwords, parts-of-speech, or named entities. Code is availableat: https://github.com/matejMartinc/SEKE_keyword_extraction</description><author>Matej Martinc, Hanh Thi Hong Tran, Senja Pollak, Boshko Koloski</author><pubDate>Wed, 18 Dec 2024 17:34:32 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.14087v1</guid></item><item><title>Future Research Avenues for Artificial Intelligence in Digital Gaming: An Exploratory Report</title><link>http://arxiv.org/abs/2412.14085v1</link><description>Video games are a natural and synergistic application domain for artificialintelligence (AI) systems, offering both the potential to enhance playerexperience and immersion, as well as providing valuable benchmarks and virtualenvironments to advance AI technologies in general. This report presents ahigh-level overview of five promising research pathways for applyingstate-of-the-art AI methods, particularly deep learning, to digital gamingwithin the context of the current research landscape. The objective of thiswork is to outline a curated, non-exhaustive list of encouraging researchdirections at the intersection of AI and video games that may serve to inspiremore rigorous and comprehensive research efforts in the future. We discuss (i)investigating large language models as core engines for game agent modelling,(ii) using neural cellular automata for procedural game content generation,(iii) accelerating computationally expensive in-game simulations via deepsurrogate modelling, (iv) leveraging self-supervised learning to obtain usefulvideo game state embeddings, and (v) training generative models of interactiveworlds using unlabelled video data. We also briefly address current technicalchallenges associated with the integration of advanced deep learning systemsinto video game development, and indicate key areas where further progress islikely to be beneficial.</description><author>Markus Dablander</author><pubDate>Wed, 18 Dec 2024 17:32:27 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.14085v1</guid></item><item><title>On the Robustness of Distributed Machine Learning against Transfer Attacks</title><link>http://arxiv.org/abs/2412.14080v1</link><description>Although distributed machine learning (distributed ML) is gainingconsiderable attention in the community, prior works have independently lookedat instances of distributed ML in either the training or the inference phase.No prior work has examined the combined robustness stemming from distributingboth the learning and the inference process. In this work, we explore, for thefirst time, the robustness of distributed ML models that are fullyheterogeneous in training data, architecture, scheduler, optimizer, and othermodel parameters. Supported by theory and extensive experimental validationusing CIFAR10 and FashionMNIST, we show that such properly distributed MLinstantiations achieve across-the-board improvements in accuracy-robustnesstradeoffs against state-of-the-art transfer-based attacks that could otherwisenot be realized by current ensemble or federated learning instantiations. Forinstance, our experiments on CIFAR10 show that for the Common Weakness attack,one of the most powerful state-of-the-art transfer-based attacks, our methodimproves robust accuracy by up to 40%, with a minimal impact on clean taskaccuracy.</description><author>Sébastien Andreina, Pascal Zimmer, Ghassan Karame</author><pubDate>Wed, 18 Dec 2024 17:27:17 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.14080v1</guid></item><item><title>Gendered Words and Grant Rates: A Textual Analysis of Disparate Outcomes in the Patent System</title><link>http://arxiv.org/abs/2411.08526v2</link><description>Text is a vehicle to convey information that reflects the writer's linguisticstyle and communicative patterns. By studying these attributes, we can discoverlatent insights about the author and their underlying message. This articleuses such an approach to better understand patent applications and theirinventors. While prior research focuses on patent metadata, we employ machinelearning and natural language processing to extract hidden information from thewords in patent applications. Through these methods, we find that inventorgender can often be identified from textual attributes - even without knowingthe inventor's name. This ability to discern gender through text suggests thatanonymized patent examination - often proposed as a solution to mitigatedisparities in patent grant rates - may not fully address gendered outcomes insecuring a patent. Our study also investigates whether objective features of apatent application can predict if it will be granted. Using a classifieralgorithm, we correctly predicted whether a patent was granted over 60% of thetime. Further analysis emphasized that writing style - like vocabulary andsentence complexity - disproportionately influenced grant predictions relativeto other attributes such as inventor gender and subject matter keywords.Lastly, we examine whether women disproportionately invent in technologicalareas with higher rejection rates. Using a clustering algorithm, applicationswere allocated into groups with related subject matter. We found that 85% offemale-dominated clusters have abnormally high rejection rates, compared toonly 45% for male-dominated groupings. These findings highlight complexinteractions between textual choices, gender, and success in securing a patent.They also raise questions about whether current proposals will be sufficient toachieve gender equity and efficiency in the patent system.</description><author>Deborah Gerhardt, Miriam Marcowitz-Bitton, W. Michael Schuster, Avshalom Elmalech, Omri Suissa, Moshe Mash</author><pubDate>Wed, 18 Dec 2024 17:24:00 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2411.08526v2</guid></item><item><title>Montague semantics and modifier consistency measurement in neural language models</title><link>http://arxiv.org/abs/2212.04310v3</link><description>This work proposes a novel methodology for measuring compositional behaviorin contemporary language embedding models. Specifically, we focus on adjectivalmodifier phenomena in adjective-noun phrases. In recent years, distributionallanguage representation models have demonstrated great practical success. Atthe same time, the need for interpretability has elicited questions on theirintrinsic properties and capabilities. Crucially, distributional models areoften inconsistent when dealing with compositional phenomena in naturallanguage, which has significant implications for their safety and fairness.Despite this, most current research on compositionality is directed towardsimproving their performance on similarity tasks only. This work takes adifferent approach, introducing three novel tests of compositional behaviorinspired by Montague semantics. Our experimental results indicate that currentneural language models do not behave according to the expected linguistictheories. This indicates that current language models may lack the capabilityto capture the semantic properties we evaluated on limited context, or thatlinguistic theories from Montagovian tradition may not match the expectedcapabilities of distributional models.</description><author>Danilo S. Carvalho, Edoardo Manino, Julia Rozanova, Lucas Cordeiro, André Freitas</author><pubDate>Wed, 18 Dec 2024 17:21:36 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2212.04310v3</guid></item><item><title>Dialogue with the Machine and Dialogue with the Art World: Evaluating Generative AI for Culturally-Situated Creativity</title><link>http://arxiv.org/abs/2412.14077v1</link><description>This paper proposes dialogue as a method for evaluating generative AI toolsfor culturally-situated creative practice, that recognizes the sociallysituated nature of art. Drawing on sociologist Howard Becker's concept of ArtWorlds, this method expands the scope of traditional AI and creativityevaluations beyond benchmarks, user studies with crowd-workers, or focus groupsconducted with artists. Our method involves two mutually informed dialogues: 1)'dialogues with art worlds' placing artists in conversation with experts suchas art historians, curators, and archivists, and 2)'dialogues with themachine,' facilitated through structured artist- and critic-led experimentationwith state-of-the-art generative AI tools. We demonstrate the value of thismethod through a case study with artists and experts steeped in non-western artworlds, specifically the Persian Gulf. We trace how these dialogues help createculturally rich and situated forms of evaluation for representationalpossibilities of generative AI that mimic the reception of generative artworkin the broader art ecosystem. Putting artists in conversation with commentatorsalso allow artists to shift their use of the tools to respond to their culturaland creative context. Our study can provide generative AI researchers anunderstanding of the complex dynamics of technology, human creativity and thesocio-politics of art worlds, to build more inclusive machines for diverse artworlds.</description><author>Rida Qadri, Piotr Mirowski, Aroussiak Gabriellan, Farbod Mehr, Huma Gupta, Pamela Karimi, Remi Denton</author><pubDate>Wed, 18 Dec 2024 17:21:14 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.14077v1</guid></item><item><title>Compositional Generalization Across Distributional Shifts with Sparse Tree Operations</title><link>http://arxiv.org/abs/2412.14076v1</link><description>Neural networks continue to struggle with compositional generalization, andthis issue is exacerbated by a lack of massive pre-training. One successfulapproach for developing neural systems which exhibit human-like compositionalgeneralization is \textit{hybrid} neurosymbolic techniques. However, thesetechniques run into the core issues that plague symbolic approaches to AI:scalability and flexibility. The reason for this failure is that at their core,hybrid neurosymbolic models perform symbolic computation and relegate thescalable and flexible neural computation to parameterizing a symbolic system.We investigate a \textit{unified} neurosymbolic system where transformations inthe network can be interpreted simultaneously as both symbolic and neuralcomputation. We extend a unified neurosymbolic architecture called theDifferentiable Tree Machine in two central ways. First, we significantlyincrease the model's efficiency through the use of sparse vectorrepresentations of symbolic structures. Second, we enable its applicationbeyond the restricted set of tree2tree problems to the more general class ofseq2seq problems. The improved model retains its prior generalizationcapabilities and, since there is a fully neural path through the network,avoids the pitfalls of other neurosymbolic techniques that elevate symboliccomputation over neural computation.</description><author>Paul Soulos, Henry Conklin, Mattia Opper, Paul Smolensky, Jianfeng Gao, Roland Fernandez</author><pubDate>Wed, 18 Dec 2024 17:20:19 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.14076v1</guid></item><item><title>Online MDP with Transition Prototypes: A Robust Adaptive Approach</title><link>http://arxiv.org/abs/2412.14075v1</link><description>In this work, we consider an online robust Markov Decision Process (MDP)where we have the information of finitely many prototypes of the underlyingtransition kernel. We consider an adaptively updated ambiguity set of theprototypes and propose an algorithm that efficiently identifies the trueunderlying transition kernel while guaranteeing the performance of thecorresponding robust policy. To be more specific, we provide a sublinear regretof the subsequent optimal robust policy. We also provide an early stoppingmechanism and a worst-case performance bound of the value function. Innumerical experiments, we demonstrate that our method outperforms existingapproaches, particularly in the early stage with limited data. This workcontributes to robust MDPs by considering possible prior information about theunderlying transition probability and online learning, offering boththeoretical insights and practical algorithms for improved decision-makingunder uncertainty.</description><author>Shuo Sun, Meng Qi, Zuo-jun Max Shen</author><pubDate>Wed, 18 Dec 2024 17:19:55 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.14075v1</guid></item><item><title>To Label or Not to Label: Hybrid Active Learning for Neural Machine Translation</title><link>http://arxiv.org/abs/2403.09259v2</link><description>Active learning (AL) techniques reduce labeling costs for training neuralmachine translation (NMT) models by selecting smaller representative subsetsfrom unlabeled data for annotation. Diversity sampling techniques selectheterogeneous instances, while uncertainty sampling methods select instanceswith the highest model uncertainty. Both approaches have limitations -diversity methods may extract varied but trivial examples, while uncertaintysampling can yield repetitive, uninformative instances. To bridge this gap, wepropose Hybrid Uncertainty and Diversity Sampling (HUDS), an AL strategy fordomain adaptation in NMT that combines uncertainty and diversity for sentenceselection. HUDS computes uncertainty scores for unlabeled sentences andsubsequently stratifies them. It then clusters sentence embeddings within eachstratum and computes diversity scores by distance to the centroid. A weightedhybrid score that combines uncertainty and diversity is then used to select thetop instances for annotation in each AL iteration. Experiments on multi-domainGerman-English and French-English datasets demonstrate the better performanceof HUDS over other strong AL baselines. We analyze the sentence selection withHUDS and show that it prioritizes diverse instances having high modeluncertainty for annotation in early AL iterations.</description><author>Abdul Hameed Azeemi, Ihsan Ayyub Qazi, Agha Ali Raza</author><pubDate>Wed, 18 Dec 2024 17:18:12 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.09259v2</guid></item><item><title>Transformer Layers as Painters</title><link>http://arxiv.org/abs/2407.09298v3</link><description>Despite their nearly universal adoption for large language models, theinternal workings of transformers are not well understood. We aim to betterunderstand the impact of removing or reorganizing information throughout thelayers of a pretrained transformer. Such an understanding could both yieldbetter usage of existing models as well as to make architectural improvementsto produce new variants. We present a series of empirical studies on frozenmodels that show that the lower and final layers of pretrained transformersdiffer from middle layers, but that middle layers have a surprising amount ofuniformity. We further show that some classes of problems have robustness toskipping layers, running the layers in an order different from how they weretrained, or running the layers in parallel. Our observations suggest that evenfrozen pretrained models may gracefully trade accuracy for latency by skippinglayers or running layers in parallel.</description><author>Qi Sun, Marc Pickett, Aakash Kumar Nain, Llion Jones</author><pubDate>Wed, 18 Dec 2024 17:17:44 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.09298v3</guid></item><item><title>A Computationally Grounded Framework for Cognitive Attitudes (extended version)</title><link>http://arxiv.org/abs/2412.14073v1</link><description>We introduce a novel language for reasoning about agents' cognitive attitudesof both epistemic and motivational type. We interpret it by means of acomputationally grounded semantics using belief bases. Our language includesfive types of modal operators for implicit belief, complete attraction,complete repulsion, realistic attraction and realistic repulsion. We give anaxiomatization and show that our operators are not mutually expressible andthat they can be combined to represent a large variety of psychologicalconcepts including ambivalence, indifference, being motivated, beingdemotivated and preference. We present a dynamic extension of the language thatsupports reasoning about the effects of belief change operations. Finally, weprovide a succinct formulation of model checking for our languages and a PSPACEmodel checking algorithm relying on a reduction into TQBF. We present someexperimental results for the implemented algorithm on computation time in aconcrete example.</description><author>Tiago de Lima, Emiliano Lorini, Elise Perrotin, François Schwarzentruber</author><pubDate>Wed, 18 Dec 2024 17:17:07 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.14073v1</guid></item><item><title>Transformers Can Navigate Mazes With Multi-Step Prediction</title><link>http://arxiv.org/abs/2412.05117v2</link><description>Despite their remarkable success in language modeling, transformers trainedto predict the next token in a sequence struggle with long-term planning. Thislimitation is particularly evident in tasks requiring foresight to planmultiple steps ahead such as maze navigation. The standard next single tokenprediction objective, however, offers no explicit mechanism to predict multiplesteps ahead - or revisit the path taken so far. Consequently, in this work westudy whether explicitly predicting multiple steps ahead (and backwards) canimprove transformers' maze navigation. We train parameter-matched transformersfrom scratch, under identical settings, to navigate mazes of varying types andsizes with standard next token prediction and MLM-U, an objective explicitlypredicting multiple steps ahead and backwards. We find that MLM-U considerablyimproves transformers' ability to navigate mazes compared to standard nexttoken prediction across maze types and complexities. We also find MLM-Utraining is 4x more sample efficient and converges 2x faster in terms of GPUtraining hours relative to next token training. Finally, for more complex mazeswe find MLM-U benefits from scaling to larger transformers. Remarkably, we findtransformers trained with MLM-U outperform larger transformers trained withnext token prediction using additional supervision from A* search traces. Wehope these findings underscore the promise of learning objectives to advancetransformers' capacity for long-term planning. The code can be found athttps://github.com/facebookresearch/maze_navigation_MLMU</description><author>Niklas Nolte, Ouail Kitouni, Adina Williams, Mike Rabbat, Mark Ibrahim</author><pubDate>Wed, 18 Dec 2024 17:16:23 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.05117v2</guid></item><item><title>Adaptive Computation Modules: Granular Conditional Computation For Efficient Inference</title><link>http://arxiv.org/abs/2312.10193v2</link><description>While transformer models have been highly successful, they arecomputationally inefficient. We observe that for each layer, the full width ofthe layer may be needed only for a small subset of tokens inside a batch andthat the "effective" width needed to process a token can vary from layer tolayer. Motivated by this observation, we introduce the Adaptive ComputationModule (ACM), a generic module that dynamically adapts its computational loadto match the estimated difficulty of the input on a per-token basis. An ACMconsists of a sequence of learners that progressively refine the output oftheir preceding counterparts. An additional gating mechanism determines theoptimal number of learners to execute for each token. We also propose adistillation technique to replace any pre-trained model with an "ACMized"variant. Our evaluation of transformer models in computer vision and speechrecognition demonstrates that substituting layers with ACMs significantlyreduces inference costs without degrading the downstream accuracy for a wideinterval of user-defined budgets.</description><author>Bartosz Wójcik, Alessio Devoto, Karol Pustelnik, Pasquale Minervini, Simone Scardapane</author><pubDate>Wed, 18 Dec 2024 17:13:41 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.10193v2</guid></item><item><title>Adapting Multilingual LLMs to Low-Resource Languages with Knowledge Graphs via Adapters</title><link>http://arxiv.org/abs/2407.01406v3</link><description>This paper explores the integration of graph knowledge from linguisticontologies into multilingual Large Language Models (LLMs) using adapters toimprove performance for low-resource languages (LRLs) in sentiment analysis(SA) and named entity recognition (NER). Building upon successfulparameter-efficient fine-tuning techniques, such as K-ADAPTER and MAD-X, wepropose a similar approach for incorporating knowledge from multilingualgraphs, connecting concepts in various languages with each other throughlinguistic relationships, into multilingual LLMs for LRLs. Specifically, wefocus on eight LRLs -- Maltese, Bulgarian, Indonesian, Nepali, Javanese,Uyghur, Tibetan, and Sinhala -- and employ language-specific adaptersfine-tuned on data extracted from the language-specific section of ConceptNet,aiming to enable knowledge transfer across the languages covered by theknowledge graph. We compare various fine-tuning objectives, including standardMasked Language Modeling (MLM), MLM with full-word masking, and MLM withtargeted masking, to analyse their effectiveness in learning and integratingthe extracted graph data. Through empirical evaluation on language-specifictasks, we assess how structured graph knowledge affects the performance ofmultilingual LLMs for LRLs in SA and NER, providing insights into the potentialbenefits of adapting language models for low-resource scenarios.</description><author>Daniil Gurgurov, Mareike Hartmann, Simon Ostermann</author><pubDate>Wed, 18 Dec 2024 17:09:31 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.01406v3</guid></item><item><title>Rango: Adaptive Retrieval-Augmented Proving for Automated Software Verification</title><link>http://arxiv.org/abs/2412.14063v1</link><description>Formal verification using proof assistants, such as Coq, enables the creationof high-quality software. However, the verification process requiressignificant expertise and manual effort to write proofs. Recent work hasexplored automating proof synthesis using machine learning and large languagemodels (LLMs). This work has shown that identifying relevant premises, such aslemmas and definitions, can aid synthesis. We present Rango, a fully automatedproof synthesis tool for Coq that automatically identifies relevant premisesand also similar proofs from the current project and uses them duringsynthesis. Rango uses retrieval augmentation at every step of the proof toautomatically determine which proofs and premises to include in the context ofits fine-tuned LLM. In this way, Rango adapts to the project and to theevolving state of the proof. We create a new dataset, CoqStoq, of 2,226open-source Coq projects and 196,929 theorems from GitHub, which includes bothtraining data and a curated evaluation benchmark of well-maintained projects.On this benchmark, Rango synthesizes proofs for 32.0% of the theorems, which is29% more theorems than the prior state-of-the-art tool Tactician. Ourevaluation also shows that Rango adding relevant proofs to its context leads toa 47% increase in the number of theorems proven.</description><author>Kyle Thompson, Nuno Saavedra, Pedro Carrott, Kevin Fisher, Alex Sanchez-Stern, Yuriy Brun, João F. Ferreira, Sorin Lerner, Emily First</author><pubDate>Wed, 18 Dec 2024 17:08:42 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.14063v1</guid></item><item><title>Towards Generalist Robot Policies: What Matters in Building Vision-Language-Action Models</title><link>http://arxiv.org/abs/2412.14058v1</link><description>Foundation Vision Language Models (VLMs) exhibit strong capabilities inmulti-modal representation learning, comprehension, and reasoning. By injectingaction components into the VLMs, Vision-Language-Action Models (VLAs) can benaturally formed and also show promising performance. Existing work hasdemonstrated the effectiveness and generalization of VLAs in multiple scenariosand tasks. Nevertheless, the transfer from VLMs to VLAs is not trivial sinceexisting VLAs differ in their backbones, action-prediction formulations, datadistributions, and training recipes. This leads to a missing piece for asystematic understanding of the design choices of VLAs. In this work, wedisclose the key factors that significantly influence the performance of VLAand focus on answering three essential design choices: which backbone toselect, how to formulate the VLA architectures, and when to addcross-embodiment data. The obtained results convince us firmly to explain whywe need VLA and develop a new family of VLAs, RoboVLMs, which require very fewmanual designs and achieve a new state-of-the-art performance in threesimulation tasks and real-world experiments. Through our extensive experiments,which include over 8 VLM backbones, 4 policy architectures, and over 600distinct designed experiments, we provide a detailed guidebook for the futuredesign of VLAs. In addition to the study, the highly flexible RoboVLMsframework, which supports easy integrations of new VLMs and free combinationsof various design choices, is made public to facilitate future research. Weopen-source all details, including codes, models, datasets, and toolkits, alongwith detailed training and evaluation recipes at: robovlms.github.io.</description><author>Xinghang Li, Peiyan Li, Minghuan Liu, Dong Wang, Jirong Liu, Bingyi Kang, Xiao Ma, Tao Kong, Hanbo Zhang, Huaping Liu</author><pubDate>Wed, 18 Dec 2024 17:07:20 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.14058v1</guid></item><item><title>A Review of Multimodal Explainable Artificial Intelligence: Past, Present and Future</title><link>http://arxiv.org/abs/2412.14056v1</link><description>Artificial intelligence (AI) has rapidly developed through advancements incomputational power and the growth of massive datasets. However, this progresshas also heightened challenges in interpreting the "black-box" nature of AImodels. To address these concerns, eXplainable AI (XAI) has emerged with afocus on transparency and interpretability to enhance human understanding andtrust in AI decision-making processes. In the context of multimodal data fusionand complex reasoning scenarios, the proposal of Multimodal eXplainable AI(MXAI) integrates multiple modalities for prediction and explanation tasks.Meanwhile, the advent of Large Language Models (LLMs) has led to remarkablebreakthroughs in natural language processing, yet their complexity has furtherexacerbated the issue of MXAI. To gain key insights into the development ofMXAI methods and provide crucial guidance for building more transparent, fair,and trustworthy AI systems, we review the MXAI methods from a historicalperspective and categorize them across four eras: traditional machine learning,deep learning, discriminative foundation models, and generative LLMs. We alsoreview evaluation metrics and datasets used in MXAI research, concluding with adiscussion of future challenges and directions. A project related to thisreview has been created at https://github.com/ShilinSun/mxai_review.</description><author>Shilin Sun, Wenbin An, Feng Tian, Fang Nan, Qidong Liu, Jun Liu, Nazaraf Shah, Ping Chen</author><pubDate>Wed, 18 Dec 2024 17:06:21 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.14056v1</guid></item><item><title>Digestion Algorithm in Hierarchical Symbolic Forests: A Fast Text Normalization Algorithm and Semantic Parsing Framework for Specific Scenarios and Lightweight Deployment</title><link>http://arxiv.org/abs/2412.14054v1</link><description>Text Normalization and Semantic Parsing have numerous applications in naturallanguage processing, such as natural language programming, paraphrasing, dataaugmentation, constructing expert systems, text matching, and more. Despite theprominent achievements of deep learning in Large Language Models (LLMs), theinterpretability of neural network architectures is still poor, which affectstheir credibility and hence limits the deployments of risk-sensitive scenarios.In certain scenario-specific domains with scarce data, rapidly obtaining alarge number of supervised learning labels is challenging, and the workload ofmanually labeling data would be enormous. Catastrophic forgetting in neuralnetworks further leads to low data utilization rates. In situations where swiftresponses are vital, the density of the model makes local deployment difficultand the response time long, which is not conducive to local applications ofthese fields. Inspired by the multiplication rule, a principle of combinatorialmathematics, and human thinking patterns, a multilayer framework along with itsalgorithm, the Digestion Algorithm in Hierarchical Symbolic Forests (DAHSF), isproposed to address these above issues, combining text normalization andsemantic parsing workflows. The Chinese Scripting Language "Fire BunnyIntelligent Development Platform V2.0" is an important test and application ofthe technology discussed in this paper. DAHSF can run locally inscenario-specific domains on little datasets, with model size and memory usageoptimized by at least two orders of magnitude, thus improving the executionspeed, and possessing a promising optimization outlook.</description><author>Kevin You</author><pubDate>Wed, 18 Dec 2024 17:05:49 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.14054v1</guid></item><item><title>Deep hybrid models: infer and plan in a dynamic world</title><link>http://arxiv.org/abs/2402.10088v3</link><description>In order to determine an optimal plan for a complex task, one often dealswith dynamic and hierarchical relationships between several entities.Traditionally, such problems are tackled with optimal control, which relies onthe optimization of cost functions; instead, a recent biologically-motivatedproposal casts planning and control as an inference process. Active inferenceassumes that action and perception are two complementary aspects of lifewhereby the role of the former is to fulfill the predictions inferred by thelatter. In this study, we present a solution, based on active inference, forcomplex control tasks. The proposed architecture exploits hybrid (discrete andcontinuous) processing, and it is based on three features: the representationof potential body configurations related to the objects of interest; the use ofhierarchical relationships that enable the agent to flexibly expand its bodyschema for tool use; the definition of potential trajectories related to theagent's intentions, used to infer and plan with dynamic elements at differenttemporal scales. We evaluate this deep hybrid model on a habitual task:reaching a moving object after having picked a moving tool. We show that themodel can tackle the presented task under different conditions. This studyextends past work on planning as inference and advances an alternativedirection to optimal control.</description><author>Matteo Priorelli, Ivilin Peev Stoianov</author><pubDate>Wed, 18 Dec 2024 17:05:38 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.10088v3</guid></item><item><title>Neural Combinatorial Optimization for Stochastic Flexible Job Shop Scheduling Problems</title><link>http://arxiv.org/abs/2412.14052v1</link><description>Neural combinatorial optimization (NCO) has gained significant attention dueto the potential of deep learning to efficiently solve combinatorialoptimization problems. NCO has been widely applied to job shop schedulingproblems (JSPs) with the current focus predominantly on deterministic problems.In this paper, we propose a novel attention-based scenario processing module(SPM) to extend NCO methods for solving stochastic JSPs. Our approachexplicitly incorporates stochastic information by an attention mechanism thatcaptures the embedding of sampled scenarios (i.e., an approximation ofstochasticity). Fed with the embedding, the base neural network is intervenedby the attended scenarios, which accordingly learns an effective policy understochasticity. We also propose a training paradigm that works harmoniously witheither the expected makespan or Value-at-Risk objective. Results demonstratethat our approach outperforms existing learning and non-learning methods forthe flexible JSP problem with stochastic processing times on a variety ofinstances. In addition, our approach holds significant generalizability tovaried numbers of scenarios and disparate distributions.</description><author>Igor G. Smit, Yaoxin Wu, Pavel Troubil, Yingqian Zhang, Wim P. M. Nuijten</author><pubDate>Wed, 18 Dec 2024 17:05:33 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.14052v1</guid></item><item><title>Cross-Lingual Transfer of Debiasing and Detoxification in Multilingual LLMs: An Extensive Investigation</title><link>http://arxiv.org/abs/2412.14050v1</link><description>Recent generative large language models (LLMs) show remarkable performance innon-English languages, but when prompted in those languages they tend toexpress higher harmful social biases and toxicity levels. Prior work has shownthat finetuning on specialized datasets can mitigate this behavior, and doingso in English can transfer to other languages. In this work, we investigate theimpact of different finetuning methods on the model's bias and toxicity, butalso on its ability to produce fluent and diverse text. Our results show thatfinetuning on curated non-harmful text is more effective for mitigating bias,and finetuning on direct preference optimization (DPO) datasets is moreeffective for mitigating toxicity. The mitigation caused by applying thesemethods in English also transfers to non-English languages. We find evidencethat the extent to which transfer takes place can be predicted by the amount ofdata in a given language present in the model's pretraining data. However, thistransfer of bias and toxicity mitigation often comes at the expense ofdecreased language generation ability in non-English languages, highlightingthe importance of developing language-specific bias and toxicity mitigationmethods.</description><author>Vera Neplenbroek, Arianna Bisazza, Raquel Fernández</author><pubDate>Wed, 18 Dec 2024 17:05:08 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.14050v1</guid></item><item><title>Evidential Deep Learning for Probabilistic Modelling of Extreme Storm Events</title><link>http://arxiv.org/abs/2412.14048v1</link><description>Uncertainty quantification (UQ) methods play an important role in reducingerrors in weather forecasting. Conventional approaches in UQ for weatherforecasting rely on generating an ensemble of forecasts from physics-basedsimulations to estimate the uncertainty. However, it is computationallyexpensive to generate many forecasts to predict real-time extreme weatherevents. Evidential Deep Learning (EDL) is an uncertainty-aware deep learningapproach designed to provide confidence about its predictions using only oneforecast. It treats learning as an evidence acquisition process where moreevidence is interpreted as increased predictive confidence. We apply EDL tostorm forecasting using real-world weather datasets and compare its performancewith traditional methods. Our findings indicate that EDL not only reducescomputational overhead but also enhances predictive uncertainty. This methodopens up novel opportunities in research areas such as climate risk assessment,where quantifying the uncertainty about future climate is crucial.</description><author>Ayush Khot, Xihaier Luo, Ai Kagawa, Shinjae Yoo</author><pubDate>Wed, 18 Dec 2024 17:03:19 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.14048v1</guid></item><item><title>CAD-Recode: Reverse Engineering CAD Code from Point Clouds</title><link>http://arxiv.org/abs/2412.14042v1</link><description>Computer-Aided Design (CAD) models are typically constructed by sequentiallydrawing parametric sketches and applying CAD operations to obtain a 3D model.The problem of 3D CAD reverse engineering consists of reconstructing the sketchand CAD operation sequences from 3D representations such as point clouds. Inthis paper, we address this challenge through novel contributions across threelevels: CAD sequence representation, network design, and dataset. Inparticular, we represent CAD sketch-extrude sequences as Python code. Theproposed CAD-Recode translates a point cloud into Python code that, whenexecuted, reconstructs the CAD model. Taking advantage of the exposure ofpre-trained Large Language Models (LLMs) to Python code, we leverage arelatively small LLM as a decoder for CAD-Recode and combine it with alightweight point cloud projector. CAD-Recode is trained solely on a proposedsynthetic dataset of one million diverse CAD sequences. CAD-Recodesignificantly outperforms existing methods across three datasets whilerequiring fewer input points. Notably, it achieves 10 times lower mean Chamferdistance than state-of-the-art methods on DeepCAD and Fusion360 datasets.Furthermore, we show that our CAD Python code output is interpretable byoff-the-shelf LLMs, enabling CAD editing and CAD-specific question answeringfrom point clouds.</description><author>Danila Rukhovich, Elona Dupont, Dimitrios Mallis, Kseniya Cherenkova, Anis Kacem, Djamila Aouada</author><pubDate>Wed, 18 Dec 2024 16:55:42 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.14042v1</guid></item><item><title>XFormParser: A Simple and Effective Multimodal Multilingual Semi-structured Form Parser</title><link>http://arxiv.org/abs/2405.17336v2</link><description>In the domain of Document AI, parsing semi-structured image form is a crucialKey Information Extraction (KIE) task. The advent of pre-trained multimodalmodels significantly empowers Document AI frameworks to extract key informationfrom form documents in different formats such as PDF, Word, and images.Nonetheless, form parsing is still encumbered by notable challenges like subparcapabilities in multilingual parsing and diminished recall in industrialcontexts in rich text and rich visuals. In this work, we introduce a simple buteffective \textbf{M}ultimodal and \textbf{M}ultilingual semi-structured\textbf{FORM} \textbf{PARSER} (\textbf{XFormParser}), which anchored on acomprehensive Transformer-based pre-trained language model and innovativelyamalgamates semantic entity recognition (SER) and relation extraction (RE) intoa unified framework. Combined with Bi-LSTM, the performance of multilingualparsing is significantly improved. Furthermore, we develop InDFormSFT, apioneering supervised fine-tuning (SFT) industrial dataset that specificallyaddresses the parsing needs of forms in various industrial contexts.XFormParser has demonstrated its unparalleled effectiveness and robustnessthrough rigorous testing on established benchmarks. Compared to existingstate-of-the-art (SOTA) models, XFormParser notably achieves up to 1.79\% F1score improvement on RE tasks in language-specific settings. It also exhibitsexceptional cross-task performance improvements in multilingual and zero-shotsettings. The codes, datasets, and pre-trained models are publicly available athttps://github.com/zhbuaa0/xformparser.</description><author>Xianfu Cheng, Hang Zhang, Jian Yang, Xiang Li, Weixiao Zhou, Fei Liu, Kui Wu, Xiangyuan Guan, Tao Sun, Xianjie Wu, Tongliang Li, Zhoujun Li</author><pubDate>Wed, 18 Dec 2024 16:55:15 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.17336v2</guid></item><item><title>Spatio-Temporal SIR Model of Pandemic Spread During Warfare with Optimal Dual-use Healthcare System Administration using Deep Reinforcement Learning</title><link>http://arxiv.org/abs/2412.14039v1</link><description>Large-scale crises, including wars and pandemics, have repeatedly shapedhuman history, and their simultaneous occurrence presents profound challengesto societies. Understanding the dynamics of epidemic spread during warfare isessential for developing effective containment strategies in complex conflictzones. While research has explored epidemic models in various settings, theimpact of warfare on epidemic dynamics remains underexplored. In this study, weproposed a novel mathematical model that integrates the epidemiological SIR(susceptible-infected-recovered) model with the war dynamics Lanchester modelto explore the dual influence of war and pandemic on a population's mortality.Moreover, we consider a dual-use military and civil healthcare system that aimsto reduce the overall mortality rate which can use different administrationpolicies. Using an agent-based simulation to generate in silico data, wetrained a deep reinforcement learning model for healthcare administrationpolicy and conducted an intensive investigation on its performance. Our resultsshow that a pandemic during war conduces chaotic dynamics where the healthcaresystem should either prioritize war-injured soldiers or pandemic-infectedcivilians based on the immediate amount of mortality from each option, ignoringlong-term objectives. Our findings highlight the importance of integratingconflict-related factors into epidemic modeling to enhance preparedness andresponse strategies in conflict-affected areas.</description><author>Adi Shuchami, Teddy Lazebnik</author><pubDate>Wed, 18 Dec 2024 16:54:27 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.14039v1</guid></item><item><title>Hansel: Output Length Controlling Framework for Large Language Models</title><link>http://arxiv.org/abs/2412.14033v1</link><description>Despite the great success of large language models (LLMs), efficientlycontrolling the length of the output sequence still remains a challenge. Inthis paper, we propose Hansel, an efficient framework for length control inLLMs without affecting its generation ability. Hansel utilizes periodicallyoutputted hidden special tokens to keep track of the remaining target length ofthe output sequence. Together with techniques to avoid abrupt termination ofthe output, this seemingly simple method proved to be efficient and versatile,while not harming the coherency and fluency of the generated text. Theframework can be applied to any pre-trained LLMs during the finetuning stage ofthe model, regardless of its original positional encoding method. Wedemonstrate this by finetuning four different LLMs with Hansel and show thatthe mean absolute error of the output sequence decreases significantly in everymodel and dataset compared to the prompt-based length control finetuning.Moreover, the framework showed a substantially improved ability to extrapolateto target lengths unseen during finetuning, such as long dialog responses orextremely short summaries. This indicates that the model learns the generalmeans of length control, rather than learning to match output lengths to thoseseen during training.</description><author>Seoha Song, Junhyun Lee, Hyeonmok Ko</author><pubDate>Wed, 18 Dec 2024 16:52:38 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.14033v1</guid></item><item><title>Certification of Speaker Recognition Models to Additive Perturbations</title><link>http://arxiv.org/abs/2404.18791v2</link><description>Speaker recognition technology is applied to various tasks, from personalvirtual assistants to secure access systems. However, the robustness of thesesystems against adversarial attacks, particularly to additive perturbations,remains a significant challenge. In this paper, we pioneer applying robustnesscertification techniques to speaker recognition, initially developed for theimage domain. Our work covers this gap by transferring and improving randomizedsmoothing certification techniques against norm-bounded additive perturbationsfor classification and few-shot learning tasks to speaker recognition. Wedemonstrate the effectiveness of these methods on VoxCeleb 1 and 2 datasets forseveral models. We expect this work to improve the robustness of voicebiometrics and accelerate the research of certification methods in the audiodomain.</description><author>Dmitrii Korzh, Elvir Karimov, Mikhail Pautov, Oleg Y. Rogov, Ivan Oseledets</author><pubDate>Wed, 18 Dec 2024 16:52:17 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.18791v2</guid></item><item><title>Gauss-Newton Dynamics for Neural Networks: A Riemannian Optimization Perspective</title><link>http://arxiv.org/abs/2412.14031v1</link><description>We analyze the convergence of Gauss-Newton dynamics for training neuralnetworks with smooth activation functions. In the underparameterized regime,the Gauss-Newton gradient flow induces a Riemannian gradient flow on alow-dimensional, smooth, embedded submanifold of the Euclidean output space.Using tools from Riemannian optimization, we prove \emph{last-iterate}convergence of the Riemannian gradient flow to the optimal in-class predictorat an \emph{exponential rate} that is independent of the conditioning of theGram matrix, \emph{without} requiring explicit regularization. We furthercharacterize the critical impacts of the neural network scaling factor and theinitialization on the convergence behavior. In the overparameterized regime, weshow that the Levenberg-Marquardt dynamics with an appropriately chosen dampingfactor yields robustness to ill-conditioned kernels, analogous to theunderparameterized regime. These findings demonstrate the potential ofGauss-Newton methods for efficiently optimizing neural networks, particularlyin ill-conditioned problems where kernel and Gram matrices have small singularvalues.</description><author>Semih Cayci</author><pubDate>Wed, 18 Dec 2024 16:51:47 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.14031v1</guid></item><item><title>Restore Anything Model via Efficient Degradation Adaptation</title><link>http://arxiv.org/abs/2407.13372v2</link><description>With the proliferation of mobile devices, the need for an efficient model torestore any degraded image has become increasingly significant and impactful.Traditional approaches typically involve training dedicated models for eachspecific degradation, resulting in inefficiency and redundancy. More recentsolutions either introduce additional modules to learn visual promptssignificantly increasing model size or incorporate cross-modal transfer fromlarge language models trained on vast datasets, adding complexity to the systemarchitecture. In contrast, our approach, termed RAM, takes a unified path thatleverages inherent similarities across various degradations to enable bothefficient and comprehensive restoration through a joint embedding mechanismwithout scaling up the model or relying on large multimodal models.Specifically, we examine the sub-latent space of each input, identifying keycomponents and reweighting them in a gated manner. This intrinsic degradationawareness is further combined with contextualized attention in an X-shapedframework, enhancing local-global interactions. Extensive benchmarking in anall-in-one restoration setting confirms RAM's SOTA performance, reducing modelcomplexity by approximately 82% in trainable parameters and 85% in FLOPs. Ourcode and models will be publicly available.</description><author>Bin Ren, Eduard Zamfir, Zongwei Wu, Yawei Li, Yidi Li, Danda Pani Paudel, Radu Timofte, Ming-Hsuan Yang, Nicu Sebe</author><pubDate>Wed, 18 Dec 2024 16:51:18 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.13372v2</guid></item><item><title>Machine learning in wastewater treatment: insights from modelling a pilot denitrification reactor</title><link>http://arxiv.org/abs/2412.14030v1</link><description>Wastewater treatment plants are increasingly recognized as promisingcandidates for machine learning applications, due to their societal importanceand high availability of data. However, their varied designs, operationalconditions, and influent characteristics hinder straightforward automation. Inthis study, we use data from a pilot reactor at the Veas treatment facility inNorway to explore how machine learning can be used to optimize biologicalnitrate ($\mathrm{NO_3^-}$) reduction to molecular nitrogen ($\mathrm{N_2}$) inthe biogeochemical process known as \textit{denitrification}. Rather thanfocusing solely on predictive accuracy, our approach prioritizes understandingthe foundational requirements for effective data-driven modelling of wastewatertreatment. Specifically, we aim to identify which process parameters are mostcritical, the necessary data quantity and quality, how to structure dataeffectively, and what properties are required by the models. We find thatnonlinear models perform best on the training and validation data sets,indicating nonlinear relationships to be learned, but linear models transferbetter to the unseen test data, which comes later in time. The variablemeasuring the water temperature has a particularly detrimental effect on themodels, owing to a significant change in distributions between training andtest data. We therefore conclude that multiple years of data is necessary tolearn robust machine learning models. By addressing foundational elements,particularly in the context of the climatic variability faced by northernregions, this work lays the groundwork for a more structured and tailoredapproach to machine learning for wastewater treatment. We share publicly boththe data and code used to produce the results in the paper.</description><author>Eivind Bøhn, Sølve Eidnes, Kjell Rune Jonassen</author><pubDate>Wed, 18 Dec 2024 16:49:23 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.14030v1</guid></item><item><title>Flow Exporter Impact on Intelligent Intrusion Detection Systems</title><link>http://arxiv.org/abs/2412.14021v1</link><description>High-quality datasets are critical for training machine learning models, asinconsistencies in feature generation can hinder the accuracy and reliabilityof threat detection. For this reason, ensuring the quality of the data innetwork intrusion detection datasets is important. A key component of this isusing reliable tools to generate the flows and features present in thedatasets. This paper investigates the impact of flow exporters on theperformance and reliability of machine learning models for intrusion detection.Using HERA, a tool designed to export flows and extract features, the rawnetwork packets of two widely used datasets, UNSW-NB15 and CIC-IDS2017, wereprocessed from PCAP files to generate new versions of these datasets. Thesewere compared to the original ones in terms of their influence on theperformance of several models, including Random Forest, XGBoost, LightGBM, andExplainable Boosting Machine. The results obtained were significant. Modelstrained on the HERA version of the datasets consistently outperformed thosetrained on the original dataset, showing improvements in accuracy andindicating a better generalisation. This highlighted the importance of flowgeneration in the model's ability to differentiate between benign and malicioustraffic.</description><author>Daniela Pinto, João Vitorino, Eva Maia, Ivone Amorim, Isabel Praça</author><pubDate>Wed, 18 Dec 2024 16:38:20 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.14021v1</guid></item><item><title>Landscape of AI safety concerns -- A methodology to support safety assurance for AI-based autonomous systems</title><link>http://arxiv.org/abs/2412.14020v1</link><description>Artificial Intelligence (AI) has emerged as a key technology, drivingadvancements across a range of applications. Its integration into modernautonomous systems requires assuring safety. However, the challenge of assuringsafety in systems that incorporate AI components is substantial. The lack ofconcrete specifications, and also the complexity of both the operationalenvironment and the system itself, leads to various aspects of uncertainbehavior and complicates the derivation of convincing evidence for systemsafety. Nonetheless, scholars proposed to thoroughly analyze and mitigateAI-specific insufficiencies, so-called AI safety concerns, which yieldsessential evidence supporting a convincing assurance case. In this paper, webuild upon this idea and propose the so-called Landscape of AI Safety Concerns,a novel methodology designed to support the creation of safety assurance casesfor AI-based systems by systematically demonstrating the absence of AI safetyconcerns. The methodology's application is illustrated through a case studyinvolving a driverless regional train, demonstrating its practicality andeffectiveness.</description><author>Ronald Schnitzer, Lennart Kilian, Simon Roessner, Konstantinos Theodorou, Sonja Zillner</author><pubDate>Wed, 18 Dec 2024 16:38:16 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.14020v1</guid></item><item><title>Discovering maximally consistent distribution of causal tournaments with Large Language Models</title><link>http://arxiv.org/abs/2412.14019v1</link><description>Causal discovery is essential for understanding complex systems, yettraditional methods often depend on strong, untestable assumptions, making theprocess challenging. Large Language Models (LLMs) present a promisingalternative for extracting causal insights from text-based metadata, whichconsolidates domain expertise. However, LLMs are prone to unreliability andhallucinations, necessitating strategies that account for their limitations.One such strategy involves leveraging a consistency measure to evaluatereliability. Additionally, most text metadata does not clearly distinguishdirect causal relationships from indirect ones, further complicating theinference of causal graphs. As a result, focusing on causal orderings, ratherthan causal graphs, emerges as a more practical and robust approach. We proposea novel method to derive a distribution of acyclic tournaments (representingplausible causal orders) that maximizes a consistency score. Our approachbegins by computing pairwise consistency scores between variables, yielding acyclic tournament that aggregates these scores. From this structure, weidentify optimal acyclic tournaments compatible with the original tournament,prioritizing those that maximize consistency across all configurations. Wetested our method on both classical and well-established bechmarks, as well asreal-world datasets from epidemiology and public health. Our resultsdemonstrate the effectiveness of our approach in recovering distributionscausal orders with minimal error.</description><author>Federico Baldo, Simon Ferreira, Charles K. Assaad</author><pubDate>Wed, 18 Dec 2024 16:37:51 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.14019v1</guid></item><item><title>SurgSora: Decoupled RGBD-Flow Diffusion Model for Controllable Surgical Video Generation</title><link>http://arxiv.org/abs/2412.14018v1</link><description>Medical video generation has transformative potential for enhancing surgicalunderstanding and pathology insights through precise and controllable visualrepresentations. However, current models face limitations in controllabilityand authenticity. To bridge this gap, we propose SurgSora, amotion-controllable surgical video generation framework that uses a singleinput frame and user-controllable motion cues. SurgSora consists of three keymodules: the Dual Semantic Injector (DSI), which extracts object-relevant RGBand depth features from the input frame and integrates them with segmentationcues to capture detailed spatial features of complex anatomical structures; theDecoupled Flow Mapper (DFM), which fuses optical flow with semantic-RGB-Dfeatures at multiple scales to enhance temporal understanding and objectspatial dynamics; and the Trajectory Controller (TC), which allows users tospecify motion directions and estimates sparse optical flow, guiding the videogeneration process. The fused features are used as conditions for a frozenStable Diffusion model to produce realistic, temporally coherent surgicalvideos. Extensive evaluations demonstrate that SurgSora outperformsstate-of-the-art methods in controllability and authenticity, showing itspotential to advance surgical video generation for medical education, training,and research.</description><author>Tong Chen, Shuya Yang, Junyi Wang, Long Bai, Hongliang Ren, Luping Zhou</author><pubDate>Wed, 18 Dec 2024 16:34:51 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.14018v1</guid></item><item><title>Deep Representation Learning for Forecasting Recursive and Multi-Relational Events in Temporal Networks</title><link>http://arxiv.org/abs/2404.17943v2</link><description>Understanding relations arising out of interactions among entities can bevery difficult, and predicting them is even more challenging. This problem hasmany applications in various fields, such as financial networks and e-commerce.These relations can involve much more complexities than just involving morethan two entities. One such scenario is evolving recursive relations betweenmultiple entities, and so far, this is still an open problem. This workaddresses the problem of forecasting higher-order interaction events that canbe multi-relational and recursive. We pose the problem in the framework ofrepresentation learning of temporal hypergraphs that can capture complexrelationships involving multiple entities. The proposed model,\textit{Relational Recursive Hyperedge Temporal Point Process} (RRHyperTPP)uses an encoder that learns a dynamic node representation based on thehistorical interaction patterns and then a hyperedge link prediction-baseddecoder to model the occurrence of interaction events. These learnedrepresentations are then used for downstream tasks involving forecasting thetype and time of interactions. The main challenge in learning from hyperedgeevents is that the number of possible hyperedges grows exponentially with thenumber of nodes in the network. This will make the computation of negativelog-likelihood of the temporal point process expensive, as the calculation ofsurvival function requires a summation over all possible hyperedges. In ourwork, we develop a noise contrastive estimation method to learn the parametersof our model, and we have experimentally shown that our models perform betterthan previous state-of-the-art methods for interaction forecasting.</description><author>Tony Gracious, Ambedkar Dukkipati</author><pubDate>Wed, 18 Dec 2024 16:33:51 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.17943v2</guid></item><item><title>Adversarial Robustness of Link Sign Prediction in Signed Graphs</title><link>http://arxiv.org/abs/2401.10590v2</link><description>Signed graphs serve as fundamental data structures for representing positiveand negative relationships in social networks, with signed graph neuralnetworks (SGNNs) emerging as the primary tool for their analysis. Ourinvestigation reveals that balance theory, while essential for modeling signedrelationships in SGNNs, inadvertently introduces exploitable vulnerabilities toblack-box attacks. To demonstrate this vulnerability, we proposebalance-attack, a novel adversarial strategy specifically designed tocompromise graph balance degree, and develop an efficient heuristic algorithmto solve the associated NP-hard optimization problem. While existing approachesattempt to restore attacked graphs through balance learning techniques, theyface a critical challenge we term "Irreversibility of Balance-relatedInformation," where restored edges fail to align with original attack targets.To address this limitation, we introduce Balance Augmented-Signed GraphContrastive Learning (BA-SGCL), an innovative framework that combinescontrastive learning with balance augmentation techniques to achieve robustgraph representations. By maintaining high balance degree in the latent space,BA-SGCL effectively circumvents the irreversibility challenge and enhancesmodel resilience. Extensive experiments across multiple SGNN architectures andreal-world datasets demonstrate both the effectiveness of our proposedbalance-attack and the superior robustness of BA-SGCL, advancing the securityand reliability of signed graph analysis in social networks. Datasets and codesof the proposed framework are at the github repositoryhttps://anonymous.4open.science/r/BA-SGCL-submit-DF41/.</description><author>Jialong Zhou, Xing Ai, Yuni Lai, Tomasz Michalak, Gaolei Li, Jianhua Li, Kai Zhou</author><pubDate>Wed, 18 Dec 2024 16:33:32 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.10590v2</guid></item><item><title>Prompting Depth Anything for 4K Resolution Accurate Metric Depth Estimation</title><link>http://arxiv.org/abs/2412.14015v1</link><description>Prompts play a critical role in unleashing the power of language and visionfoundation models for specific tasks. For the first time, we introduceprompting into depth foundation models, creating a new paradigm for metricdepth estimation termed Prompt Depth Anything. Specifically, we use a low-costLiDAR as the prompt to guide the Depth Anything model for accurate metric depthoutput, achieving up to 4K resolution. Our approach centers on a concise promptfusion design that integrates the LiDAR at multiple scales within the depthdecoder. To address training challenges posed by limited datasets containingboth LiDAR depth and precise GT depth, we propose a scalable data pipeline thatincludes synthetic data LiDAR simulation and real data pseudo GT depthgeneration. Our approach sets new state-of-the-arts on the ARKitScenes andScanNet++ datasets and benefits downstream applications, including 3Dreconstruction and generalized robotic grasping.</description><author>Haotong Lin, Sida Peng, Jingxiao Chen, Songyou Peng, Jiaming Sun, Minghuan Liu, Hujun Bao, Jiashi Feng, Xiaowei Zhou, Bingyi Kang</author><pubDate>Wed, 18 Dec 2024 16:32:12 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.14015v1</guid></item><item><title>TEncDM: Understanding the Properties of the Diffusion Model in the Space of Language Model Encodings</title><link>http://arxiv.org/abs/2402.19097v3</link><description>This paper presents the Text Encoding Diffusion Model (TEncDM), a novelapproach to diffusion modeling that operates in the space of pre-trainedlanguage model encodings. In contrast to traditionally used embeddings,encodings integrate contextual information. In our approach, we also employ atransformer-based decoder, specifically designed to incorporate context in thetoken prediction process. We conduct a comprehensive examination of theinfluence of the encoder, decoder, noise scheduler, and self-conditioning onzero-shot generation. Furthermore, we compare TEncDM with previous approacheson three conditional text generation tasks: QQP, XSum, and Wiki-Auto. Theresults show that TEncDM exhibits superior performance compared to existingnon-autoregressive diffusion models. Our code is available athttps://github.com/M0RJIQUE/tencdm.</description><author>Alexander Shabalin, Viacheslav Meshchaninov, Egor Chimbulatov, Vladislav Lapikov, Roman Kim, Grigory Bartosh, Dmitry Molchanov, Sergey Markov, Dmitry Vetrov</author><pubDate>Wed, 18 Dec 2024 16:30:58 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.19097v3</guid></item><item><title>Towards an optimised evaluation of teachers' discourse: The case of engaging messages</title><link>http://arxiv.org/abs/2412.14011v1</link><description>Evaluating teachers' skills is crucial for enhancing education quality andstudent outcomes. Teacher discourse, significantly influencing studentperformance, is a key component. However, coding this discourse can belaborious. This study addresses this issue by introducing a new methodology foroptimising the assessment of teacher discourse. The research consisted of twostudies, both within the framework of engaging messages used by secondaryeducation teachers. The first study involved training two large language modelson real-world examples from audio-recorded lessons over two academic years toidentify and classify the engaging messages from the lessons' transcripts. Thisresulted in sensitivities of 84.31% and 91.11%, and specificities of 97.69% and86.36% in identification and classification, respectively. The second studyapplied these models to transcripts of audio-recorded lessons from a thirdacademic year to examine the frequency and distribution of message types byeducational level and moment of the academic year. Results showed teacherspredominantly use messages emphasising engagement benefits, linked to improvedoutcomes, while one-third highlighted non-engagement disadvantages, associatedwith increased anxiety. The use of engaging messages declined in Grade 12 andtowards the academic year's end. These findings suggest potential interventionsto optimise engaging message use, enhancing teaching quality and studentoutcomes.</description><author>Samuel Falcon, Jaime Leon</author><pubDate>Wed, 18 Dec 2024 16:29:45 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.14011v1</guid></item><item><title>Airfoil Diffusion: Denoising Diffusion Model For Conditional Airfoil Generation</title><link>http://arxiv.org/abs/2408.15898v3</link><description>The design of aerodynamic shapes, such as airfoils, has traditionallyrequired significant computational resources and relied on predefined designparameters, which limit the potential for novel shape synthesis. In this work,we introduce a data-driven methodology for airfoil generation using a diffusionmodel. Trained on a dataset of preexisting airfoils, our model can generate anarbitrary number of new airfoils from random vectors, which can be conditionedon specific aerodynamic performance metrics such as lift and drag, or geometriccriteria. Our results demonstrate that the diffusion model effectively producesairfoil shapes with realistic aerodynamic properties, offering substantialimprovements in efficiency, flexibility, and the potential for discoveringinnovative airfoil designs. This approach significantly expands the designspace, facilitating the synthesis of high-performance aerodynamic shapes thattranscend the limitations of traditional methods.</description><author>Reid Graves, Amir Barati Farimani</author><pubDate>Wed, 18 Dec 2024 16:29:07 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.15898v3</guid></item><item><title>MetaphorShare: A Dynamic Collaborative Repository of Open Metaphor Datasets</title><link>http://arxiv.org/abs/2411.18260v2</link><description>The metaphor studies community has developed numerous valuable labelledcorpora in various languages over the years. Many of these resources are notonly unknown to the NLP community, but are also often not easily shared amongthe researchers. Both in human sciences and in NLP, researchers could benefitfrom a centralised database of labelled resources, easily accessible andunified under an identical format. To facilitate this, we presentMetaphorShare, a website to integrate metaphor datasets making them open andaccessible. With this effort, our aim is to encourage researchers to share andupload more datasets in any language in order to facilitate metaphor studiesand the development of future metaphor processing NLP systems. The website hasfour main functionalities: upload, download, search and label metaphordatasets. It is accessible at www.metaphorshare.com.</description><author>Joanne Boisson, Arif Mehmood, Jose Camacho-Collados</author><pubDate>Wed, 18 Dec 2024 16:28:19 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2411.18260v2</guid></item><item><title>Cognition Chain for Explainable Psychological Stress Detection on Social Media</title><link>http://arxiv.org/abs/2412.14009v1</link><description>Stress is a pervasive global health issue that can lead to severe mentalhealth problems. Early detection offers timely intervention and prevention ofstress-related disorders. The current early detection models perform "blackbox" inference suffering from limited explainability and trust which blocks thereal-world clinical application. Thanks to the generative properties introducedby the Large Language Models (LLMs), the decision and the prediction from suchmodels are semi-interpretable through the corresponding description. However,the existing LLMs are mostly trained for general purposes without the guidanceof psychological cognitive theory. To this end, we first highlight theimportance of prior theory with the observation of performance boosted by thechain-of-thoughts tailored for stress detection. This method termed CognitionChain explicates the generation of stress through a step-by-step cognitiveperspective based on cognitive appraisal theory with a progress pipeline:Stimulus $\rightarrow$ Evaluation $\rightarrow$ Reaction $\rightarrow$ StressState, guiding LLMs to provide comprehensive reasoning explanations. We furtherstudy the benefits brought by the proposed Cognition Chain format by utilisingit as a synthetic dataset generation template for LLMs instruction-tuning andintroduce CogInstruct, an instruction-tuning dataset for stress detection. Thisdataset is developed using a three-stage self-reflective annotation pipelinethat enables LLMs to autonomously generate and refine instructional data. Byinstruction-tuning Llama3 with CogInstruct, we develop CogLLM, an explainablestress detection model. Evaluations demonstrate that CogLLM achievesoutstanding performance while enhancing explainability. Our work contributes anovel approach by integrating cognitive theories into LLM reasoning processes,offering a promising direction for future explainable AI research.</description><author>Xin Wang, Boyan Gao, Yi Dai, Lei Cao, Liang Zhao, Yibo Yang, David Clifton</author><pubDate>Wed, 18 Dec 2024 16:26:47 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.14009v1</guid></item><item><title>FarExStance: Explainable Stance Detection for Farsi</title><link>http://arxiv.org/abs/2412.14008v1</link><description>We introduce FarExStance, a new dataset for explainable stance detection inFarsi. Each instance in this dataset contains a claim, the stance of an articleor social media post towards that claim, and an extractive explanation whichprovides evidence for the stance label. We compare the performance of afine-tuned multilingual RoBERTa model to several large language models inzero-shot, few-shot, and parameter-efficient fine-tuned settings on our newdataset. On stance detection, the most accurate models are the fine-tunedRoBERTa model, the LLM Aya-23-8B which has been fine-tuned usingparameter-efficient fine-tuning, and few-shot Claude-3.5-Sonnet. Regarding thequality of the explanations, our automatic evaluation metrics indicate thatfew-shot GPT-4o generates the most coherent explanations, while our humanevaluation reveals that the best Overall Explanation Score (OES) belongs tofew-shot Claude-3.5-Sonnet. The fine-tuned Aya-32-8B model producedexplanations most closely aligned with the reference explanations.</description><author>Majid Zarharan, Maryam Hashemi, Malika Behroozrazegh, Sauleh Eetemadi, Mohammad Taher Pilehvar, Jennifer Foster</author><pubDate>Wed, 18 Dec 2024 16:24:20 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.14008v1</guid></item><item><title>InstructSeg: Unifying Instructed Visual Segmentation with Multi-modal Large Language Models</title><link>http://arxiv.org/abs/2412.14006v1</link><description>Boosted by Multi-modal Large Language Models (MLLMs), text-guided universalsegmentation models for the image and video domains have made rapid progressrecently. However, these methods are often developed separately for specificdomains, overlooking the similarities in task settings and solutions acrossthese two areas. In this paper, we define the union of referring segmentationand reasoning segmentation at both the image and video levels as InstructedVisual Segmentation (IVS). Correspondingly, we propose InstructSeg, anend-to-end segmentation pipeline equipped with MLLMs for IVS. Specifically, weemploy an object-aware video perceiver to extract temporal and objectinformation from reference frames, facilitating comprehensive videounderstanding. Additionally, we introduce vision-guided multi-granularity textfusion to better integrate global and detailed text information withfine-grained visual guidance. By leveraging multi-task and end-to-end training,InstructSeg demonstrates superior performance across diverse image and videosegmentation tasks, surpassing both segmentation specialists and MLLM-basedmethods with a single model. Our code is available athttps://github.com/congvvc/InstructSeg.</description><author>Cong Wei, Yujie Zhong, Haoxian Tan, Yingsen Zeng, Yong Liu, Zheng Zhao, Yujiu Yang</author><pubDate>Wed, 18 Dec 2024 16:20:40 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.14006v1</guid></item><item><title>Real-Time Position-Aware View Synthesis from Single-View Input</title><link>http://arxiv.org/abs/2412.14005v1</link><description>Recent advancements in view synthesis have significantly enhanced immersiveexperiences across various computer graphics and multimedia applications,including telepresence, and entertainment. By enabling the generation of newperspectives from a single input view, view synthesis allows users to betterperceive and interact with their environment. However, many state-of-the-artmethods, while achieving high visual quality, face limitations in real-timeperformance, which makes them less suitable for live applications where lowlatency is critical. In this paper, we present a lightweight, position-awarenetwork designed for real-time view synthesis from a single input image and atarget camera pose. The proposed framework consists of a Position AwareEmbedding, modeled with a multi-layer perceptron, which efficiently mapspositional information from the target pose to generate high dimensionalfeature maps. These feature maps, along with the input image, are fed into aRendering Network that merges features from dual encoder branches to resolveboth high level semantics and low level details, producing a realistic new viewof the scene. Experimental results demonstrate that our method achievessuperior efficiency and visual quality compared to existing approaches,particularly in handling complex translational movements without explicitgeometric operations like warping. This work marks a step toward enablingreal-time view synthesis from a single image for live and interactiveapplications.</description><author>Manu Gond, Emin Zerman, Sebastian Knorr, Mårten Sjöström</author><pubDate>Wed, 18 Dec 2024 16:20:21 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.14005v1</guid></item><item><title>Tokens, the oft-overlooked appetizer: Large language models, the distributional hypothesis, and meaning</title><link>http://arxiv.org/abs/2412.10924v2</link><description>Tokenization is a necessary component within the current architecture of manylanguage models, including the transformer-based large language models (LLMs)of Generative AI, yet its impact on the model's cognition is often overlooked.We argue that LLMs demonstrate that the Distributional Hypothesis (DM) issufficient for reasonably human-like language performance, and that theemergence of human-meaningful linguistic units among tokens motivateslinguistically-informed interventions in existing, linguistically-agnostictokenization techniques, particularly with respect to their roles as (1)semantic primitives and as (2) vehicles for conveying salient distributionalpatterns from human language to the model. We explore tokenizations from a BPEtokenizer; extant model vocabularies obtained from Hugging Face and tiktoken;and the information in exemplar token vectors as they move through the layersof a RoBERTa (large) model. Besides creating sub-optimal semantic buildingblocks and obscuring the model's access to the necessary distributionalpatterns, we describe how tokenization pretraining can be a backdoor for biasand other unwanted content, which current alignment practices may notremediate. Additionally, we relay evidence that the tokenization algorithm'sobjective function impacts the LLM's cognition, despite being meaningfullyinsulated from the main system intelligence.</description><author>Julia Witte Zimmerman, Denis Hudon, Kathryn Cramer, Alejandro J. Ruiz, Calla Beauregard, Ashley Fehr, Mikaela Irene Fudolig, Bradford Demarest, Yoshi Meke Bird, Milo Z. Trujillo, Christopher M. Danforth, Peter Sheridan Dodds</author><pubDate>Wed, 18 Dec 2024 16:16:04 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.10924v2</guid></item><item><title>Few-shot Steerable Alignment: Adapting Rewards and LLM Policies with Neural Processes</title><link>http://arxiv.org/abs/2412.13998v1</link><description>As large language models (LLMs) become increasingly embedded in everydayapplications, ensuring their alignment with the diverse preferences ofindividual users has become a critical challenge. Currently deployed approachestypically assume homogeneous user objectives and rely on single-objectivefine-tuning. However, human preferences are inherently heterogeneous,influenced by various unobservable factors, leading to conflicting signals inpreference data. Existing solutions addressing this diversity often requirecostly datasets labelled for specific objectives and involve training multiplereward models or LLM policies, which is computationally expensive andimpractical. In this work, we present a novel framework for few-shot steerablealignment, where users' underlying preferences are inferred from a small sampleof their choices. To achieve this, we extend the Bradley-Terry-Luce model tohandle heterogeneous preferences with unobserved variability factors andpropose its practical implementation for reward modelling and LLM fine-tuning.Thanks to our proposed approach of functional parameter-space conditioning,LLMs trained with our framework can be adapted to individual preferences atinference time, generating outputs over a continuum of behavioural modes. Weempirically validate the effectiveness of methods, demonstrating their abilityto capture and align with diverse human preferences in a data-efficient manner.Our code is made available at:https://github.com/kasia-kobalczyk/few-shot-steerable-alignment.</description><author>Katarzyna Kobalczyk, Claudio Fanconi, Hao Sun, Mihaela van der Schaar</author><pubDate>Wed, 18 Dec 2024 16:14:59 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.13998v1</guid></item><item><title>Modality-Independent Graph Neural Networks with Global Transformers for Multimodal Recommendation</title><link>http://arxiv.org/abs/2412.13994v1</link><description>Multimodal recommendation systems can learn users' preferences from existinguser-item interactions as well as the semantics of multimodal data associatedwith items. Many existing methods model this through a multimodal user-itemgraph, approaching multimodal recommendation as a graph learning task. GraphNeural Networks (GNNs) have shown promising performance in this domain. Priorresearch has capitalized on GNNs' capability to capture neighborhoodinformation within certain receptive fields (typically denoted by the number ofhops, $K$) to enrich user and item semantics. We observe that the optimalreceptive fields for GNNs can vary across different modalities. In this paper,we propose GNNs with Modality-Independent Receptive Fields, which employseparate GNNs with independent receptive fields for different modalities toenhance performance. Our results indicate that the optimal $K$ for certainmodalities on specific datasets can be as low as 1 or 2, which may restrict theGNNs' capacity to capture global information. To address this, we introduce aSampling-based Global Transformer, which utilizes uniform global sampling toeffectively integrate global information for GNNs. We conduct comprehensiveexperiments that demonstrate the superiority of our approach over existingmethods. Our code is publicly available athttps://github.com/CrawlScript/MIG-GT.</description><author>Jun Hu, Bryan Hooi, Bingsheng He, Yinwei Wei</author><pubDate>Wed, 18 Dec 2024 16:12:26 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.13994v1</guid></item><item><title>Variance-based loss function for improved regularization</title><link>http://arxiv.org/abs/2412.13993v1</link><description>In deep learning, the mean of a chosen error metric, such as squared orabsolute error, is commonly used as a loss function. While effective inreducing the average error, this approach often fails to address localizedoutliers, leading to significant inaccuracies in regions with sharp gradientsor discontinuities. This issue is particularly evident in physics-informedneural networks (PINNs), where such localized errors are expected and affectthe overall solution. To overcome this limitation, we propose a novel lossfunction that combines the mean and the standard deviation of the chosen errormetric. By minimizing this combined loss function, the method ensures a moreuniform error distribution and reduces the impact of localized high-errorregions. The proposed loss function was tested on three problems: Burger'sequation, 2D linear elastic solid mechanics, and 2D steady Navier-Stokes,demonstrating improved solution quality and lower maximum errors compared tothe standard mean-based loss, using the same number of iterations and weightinitialization.</description><author>John M. Hanna, Irene E. Vignon-Clemental</author><pubDate>Wed, 18 Dec 2024 16:11:45 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.13993v1</guid></item><item><title>Beyond Monte Carlo: Harnessing Diffusion Models to Simulate Financial Market Dynamics</title><link>http://arxiv.org/abs/2412.00036v2</link><description>We propose a highly efficient and accurate methodology for generatingsynthetic financial market data using a diffusion model approach. The syntheticdata produced by our methodology align closely with observed market data inseveral key aspects: (i) they pass the two-sample Cramer - von Mises test forportfolios of assets, and (ii) Q - Q plots demonstrate consistency acrossquantiles, including in the tails, between observed and generated market data.Moreover, the covariance matrices derived from a large set of synthetic marketdata exhibit significantly lower condition numbers compared to the estimatedcovariance matrices of the observed data. This property makes them suitable foruse as regularized versions of the latter. For model training, we develop anefficient and fast algorithm based on numerical integration rather than MonteCarlo simulations. The methodology is tested on a large set of equity data.</description><author>Andrew Lesniewski, Giulio Trigila</author><pubDate>Wed, 18 Dec 2024 16:11:15 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.00036v2</guid></item><item><title>Risk-averse Total-reward MDPs with ERM and EVaR</title><link>http://arxiv.org/abs/2408.17286v2</link><description>Optimizing risk-averse objectives in discounted MDPs is challenging becausemost models do not admit direct dynamic programming equations and requirecomplex history-dependent policies. In this paper, we show that the risk-averse{\em total reward criterion}, under the Entropic Risk Measure (ERM) andEntropic Value at Risk (EVaR) risk measures, can be optimized by a stationarypolicy, making it simple to analyze, interpret, and deploy. We proposeexponential value iteration, policy iteration, and linear programming tocompute optimal policies. Compared with prior work, our results only requirethe relatively mild condition of transient MDPs and allow for {\em both}positive and negative rewards. Our results indicate that the total rewardcriterion may be preferable to the discounted criterion in a broad range ofrisk-averse reinforcement learning domains.</description><author>Xihong Su, Julien Grand-Clément, Marek Petrik</author><pubDate>Wed, 18 Dec 2024 16:10:18 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.17286v2</guid></item><item><title>What makes a good metric? Evaluating automatic metrics for text-to-image consistency</title><link>http://arxiv.org/abs/2412.13989v1</link><description>Language models are increasingly being incorporated as components in largerAI systems for various purposes, from prompt optimization to automaticevaluation. In this work, we analyze the construct validity of four recent,commonly used methods for measuring text-to-image consistency - CLIPScore,TIFA, VPEval, and DSG - which rely on language models and/or VQA models ascomponents. We define construct validity for text-image consistency metrics asa set of desiderata that text-image consistency metrics should have, and findthat no tested metric satisfies all of them. We find that metrics lacksufficient sensitivity to language and visual properties. Next, we find thatTIFA, VPEval and DSG contribute novel information above and beyond CLIPScore,but also that they correlate highly with each other. We also ablate differentaspects of the text-image consistency metrics and find that not all modelcomponents are strictly necessary, also a symptom of insufficient sensitivityto visual information. Finally, we show that all three VQA-based metrics likelyrely on familiar text shortcuts (such as yes-bias in QA) that call theiraptitude as quantitative evaluations of model performance into question.</description><author>Candace Ross, Melissa Hall, Adriana Romero Soriano, Adina Williams</author><pubDate>Wed, 18 Dec 2024 16:09:42 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.13989v1</guid></item><item><title>Deep Reinforcement Learning for Multi-Truck Vehicle Routing Problems with Multi-Leg Demand Routes</title><link>http://arxiv.org/abs/2401.08669v3</link><description>Deep reinforcement learning (RL) has been shown to be effective in producingapproximate solutions to some vehicle routing problems (VRPs), especially whenusing policies generated by encoder-decoder attention mechanisms. While thesetechniques have been quite successful for relatively simple problem instances,there are still under-researched and highly complex VRP variants for which noeffective RL method has been demonstrated. In this work we focus on one suchVRP variant, which contains multiple trucks and multi-leg routing requirements.In these problems, demand is required to move along sequences of nodes, insteadof just from a start node to an end node. With the goal of making deep RL aviable strategy for real-world industrial-scale supply chain logistics, wedevelop new extensions to existing encoder-decoder attention models which allowthem to handle multiple trucks and multi-leg routing requirements. Our modelshave the advantage that they can be trained for a small number of trucks andnodes, and then embedded into a large supply chain to yield solutions forlarger numbers of trucks and nodes. We test our approach on a real supply chainenvironment arising in the operations of Japanese automotive parts manufacturerAisin Corporation, and find that our algorithm outperforms Aisin's previousbest solution.</description><author>Joshua Levin, Randall Correll, Takanori Ide, Takafumi Suzuki, Takaho Saito, Alan Arai</author><pubDate>Wed, 18 Dec 2024 16:08:51 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.08669v3</guid></item></channel></rss>