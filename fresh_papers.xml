<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/"><channel><title>Arxivfresh papers</title><link></link><description>Arxiv paper</description><language>en-US</language><lastBuildDate>Tue, 31 Dec 2024 01:00:04 GMT</lastBuildDate><generator>rfeed v1.0.0</generator><docs>https://github.com/svpino/rfeed/blob/master/README.md</docs><item><title>LASER: A new method for locally adaptive nonparametric regression</title><link>http://arxiv.org/abs/2412.19802v1</link><description>In this article, we introduce \textsf{LASER} (Locally Adaptive SmoothingEstimator for Regression), a computationally efficient locally adaptivenonparametric regression method that performs variable bandwidth localpolynomial regression. We prove that it adapts (near-)optimally to the localH\"{o}lder exponent of the underlying regression function\texttt{simultaneously} at all points in its domain. Furthermore, we show thatthere is a single ideal choice of a global tuning parameter under which theabove mentioned local adaptivity holds. Despite the vast literature onnonparametric regression, instances of practicable methods with provableguarantees of such a strong notion of local adaptivity are rare. The proposedmethod achieves excellent performance across a broad range of numericalexperiments in comparison to popular alternative locally adaptive methods.</description><author>Sabyasachi Chatterjee, Subhajit Goswami, Soumendu Sundar Mukherjee</author><pubDate>Fri, 27 Dec 2024 18:59:03 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.19802v1</guid></item><item><title>Generalized Grade-of-Membership Estimation for High-dimensional Locally Dependent Data</title><link>http://arxiv.org/abs/2412.19796v1</link><description>This work focuses on the mixed membership models for multivariate categoricaldata widely used for analyzing survey responses and population genetics data.These grade of membership (GoM) models offer rich modeling power but presentsignificant estimation challenges for high-dimensional polytomous data. Popularexisting approaches, such as Bayesian MCMC inference, are not scalable and lacktheoretical guarantees in high-dimensional settings. To address this, we firstobserve that data from this model can be reformulated as a three-way(quasi-)tensor, with many subjects responding to many items with varyingnumbers of categories. We introduce a novel and simple approach that flattensthe three-way quasi-tensor into a "fat" matrix, and then perform a singularvalue decomposition of it to estimate parameters by exploiting the singularsubspace geometry. Our fast spectral method can accommodate a broad range ofdata distributions with arbitrarily locally dependent noise, which we formalizeas the generalized-GoM models. We establish finite-sample entrywise errorbounds for the generalized-GoM model parameters. This is supported by a newsharp two-to-infinity singular subspace perturbation theory for locallydependent and flexibly distributed noise, a contribution of independentinterest. Simulations and applications to data in political surveys, populationgenetics, and single-cell sequencing demonstrate our method's superiorperformance.</description><author>Ling Chen, Chengzhu Huang, Yuqi Gu</author><pubDate>Fri, 27 Dec 2024 18:51:15 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.19796v1</guid></item><item><title>MVTamperBench: Evaluating Robustness of Vision-Language Models</title><link>http://arxiv.org/abs/2412.19794v1</link><description>Recent advancements in Vision-Language Models (VLMs) have enabled significantprogress in complex video understanding tasks. However, their robustness toreal-world manipulations remains underexplored, limiting their reliability incritical applications. To address this gap, we introduce MVTamperBench, acomprehensive benchmark designed to evaluate VLM's resilience to videotampering effects, including rotation, dropping, masking, substitution, andrepetition. By systematically assessing state-of-the-art models, MVTamperBenchreveals substantial variability in robustness, with models like InternVL2-8Bachieving high performance, while others, such as Llama-VILA1.5-8B, exhibitsevere vulnerabilities. To foster broader adoption and reproducibility,MVTamperBench is integrated into VLMEvalKit, a modular evaluation toolkit,enabling streamlined testing and facilitating advancements in model robustness.Our benchmark represents a critical step towards developing tamper-resilientVLMs, ensuring their dependability in real-world scenarios. Project Page: https://amitbcp.github.io/MVTamperBench/</description><author>Amit Agarwal, Srikant Panda, Angeline Charles, Bhargava Kumar, Hitesh Patel, Priyanranjan Pattnayak, Taki Hasan Rafi, Tejaswini Kumar, Dong-Kyu Chae</author><pubDate>Fri, 27 Dec 2024 18:47:05 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.19794v1</guid></item><item><title>InfAlign: Inference-aware language model alignment</title><link>http://arxiv.org/abs/2412.19792v1</link><description>Language model alignment has become a critical step in training moderngenerative language models. The goal of alignment is to finetune a referencemodel such that the win rate of a sample from the aligned model over a samplefrom the reference model is high, subject to a KL divergence constraint. Today,we are increasingly using inference-time algorithms (e.g., Best-of-N,controlled decoding, tree search) to decode from language models rather thanstandard sampling. However, the alignment objective does not capture suchinference-time decoding procedures. We show that the existing alignmentframework is sub-optimal in view of such inference-time methods. We then modifythe alignment objective and propose a framework for inference-aware alignment(IAPO). We prove that for any inference-time decoding algorithm, the optimalsolution that optimizes the inference-time win rate of the aligned policyagainst the reference policy is the solution to the typical RLHF problem with atransformation of the reward. This motivates us to provide the KL-regularizedcalibrate-and-transform RL (CTRL) algorithm to solve this problem, whichinvolves a reward calibration step and a KL-regularized reward maximizationstep with a transformation of the calibrated reward. We particularize our studyto two important inference-time strategies: best-of-N sampling and best-of-Njailbreaking, where N responses are sampled from the model and the one with thehighest or lowest reward is selected. We propose specific transformations forthese strategies and demonstrate that our framework offers significantimprovements over existing state-of-the-art methods for language modelalignment. Empirically, we outperform baselines that are designed withouttaking inference-time decoding into consideration by 8-12% and 4-9% oninference-time win rates over the Anthropic helpfulness and harmlessness dialogbenchmark datasets.</description><author>Ananth Balashankar, Ziteng Sun, Jonathan Berant, Jacob Eisenstein, Michael Collins, Adrian Hutter, Jong Lee, Chirag Nagpal, Flavien Prost, Aradhana Sinha, and Ananda Theertha Suresh, Ahmad Beirami</author><pubDate>Fri, 27 Dec 2024 18:45:36 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.19792v1</guid></item><item><title>Reasoning over Uncertain Text by Generative Large Language Models</title><link>http://arxiv.org/abs/2402.09614v3</link><description>This paper considers the challenges Large Language Models (LLMs) face whenreasoning over text that includes information involving uncertainty explicitlyquantified via probability values. This type of reasoning is relevant to avariety of contexts ranging from everyday conversations to medicaldecision-making. Despite improvements in the mathematical reasoningcapabilities of LLMs, they still exhibit significant difficulties when it comesto probabilistic reasoning. To deal with this problem, we introduce theBayesian Linguistic Inference Dataset (BLInD), a new dataset specificallydesigned to test the probabilistic reasoning capabilities of LLMs. We use BLInDto find out the limitations of LLMs for tasks involving probabilisticreasoning. In addition, we present several prompting strategies that map theproblem to different formal representations, including Python code,probabilistic algorithms, and probabilistic logical programming. We conclude byproviding an evaluation of our methods on BLInD and an adaptation of a causalreasoning question-answering dataset. Our empirical results highlight theeffectiveness of our proposed strategies for multiple LLMs.</description><author>Aliakbar Nafar, Kristen Brent Venable, Parisa Kordjamshidi</author><pubDate>Fri, 27 Dec 2024 18:43:59 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.09614v3</guid></item><item><title>Enhancing Whisper's Accuracy and Speed for Indian Languages through Prompt-Tuning and Tokenization</title><link>http://arxiv.org/abs/2412.19785v1</link><description>Automatic speech recognition has recently seen a significant advancement withlarge foundational models such as Whisper. However, these models often struggleto perform well in low-resource languages, such as Indian languages. This paperexplores two novel approaches to enhance Whisper's multilingual speechrecognition performance in Indian languages. First, we propose prompt-tuningwith language family information, which enhances Whisper's accuracy inlinguistically similar languages. Second, we introduce a novel tokenizer thatreduces the number of generated tokens, thereby accelerating Whisper'sinference speed. Our extensive experiments demonstrate that the tokenizersignificantly reduces inference time, while prompt-tuning enhances accuracyacross various Whisper model sizes, including Small, Medium, and Large.Together, these techniques achieve a balance between optimal WER and inferencespeed.</description><author>Kumud Tripathi, Raj Gothi, Pankaj Wasnik</author><pubDate>Fri, 27 Dec 2024 18:32:24 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.19785v1</guid></item><item><title>Can AI Help with Your Personal Finances?</title><link>http://arxiv.org/abs/2412.19784v1</link><description>In recent years, Large Language Models (LLMs) have emerged as atransformative development in artificial intelligence (AI), drawing significantattention from industry and academia. Trained on vast datasets, thesesophisticated AI systems exhibit impressive natural language processing andcontent generation capabilities. This paper explores the potential of LLMs toaddress key challenges in personal finance, focusing on the United States. Weevaluate several leading LLMs, including OpenAI's ChatGPT, Google's Gemini,Anthropic's Claude, and Meta's Llama, to assess their effectiveness inproviding accurate financial advice on topics such as mortgages, taxes, loans,and investments. Our findings show that while these models achieve an averageaccuracy rate of approximately 70%, they also display notable limitations incertain areas. Specifically, LLMs struggle to provide accurate responses forcomplex financial queries, with performance varying significantly acrossdifferent topics. Despite these limitations, the analysis reveals notableimprovements in newer versions of these models, highlighting their growingutility for individuals and financial advisors. As these AI systems continue toevolve, their potential for advancing AI-driven applications in personalfinance becomes increasingly promising.</description><author>Oudom Hean, Utsha Saha, Binita Saha</author><pubDate>Fri, 27 Dec 2024 18:25:27 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.19784v1</guid></item><item><title>Machine Learning for Sentiment Analysis of Imported Food in Trinidad and Tobago</title><link>http://arxiv.org/abs/2412.19781v1</link><description>This research investigates the performance of various machine learningalgorithms (CNN, LSTM, VADER, and RoBERTa) for sentiment analysis of Twitterdata related to imported food items in Trinidad and Tobago. The study addressesthree primary research questions: the comparative accuracy and efficiency ofthe algorithms, the optimal configurations for each model, and the potentialapplications of the optimized models in a live system for monitoring publicsentiment and its impact on the import bill. The dataset comprises tweets from2018 to 2024, divided into imbalanced, balanced, and temporal subsets to assessthe impact of data balancing and the COVID-19 pandemic on sentiment trends. Tenexperiments were conducted to evaluate the models under various configurations.Results indicated that VADER outperformed the other models in both multi-classand binary sentiment classifications. The study highlights significant changesin sentiment trends pre- and post-COVID-19, with implications for importpolicies.</description><author>Cassandra Daniels, Koffka Khan</author><pubDate>Fri, 27 Dec 2024 18:25:08 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.19781v1</guid></item><item><title>Tensor Network Estimation of Distribution Algorithms</title><link>http://arxiv.org/abs/2412.19780v1</link><description>Tensor networks are a tool first employed in the context of many-body quantumphysics that now have a wide range of uses across the computational sciences,from numerical methods to machine learning. Methods integrating tensor networksinto evolutionary optimization algorithms have appeared in the recentliterature. In essence, these methods can be understood as replacing thetraditional crossover operation of a genetic algorithm with a tensornetwork-based generative model. We investigate these methods from the point ofview that they are Estimation of Distribution Algorithms (EDAs). We find thatoptimization performance of these methods is not related to the power of thegenerative model in a straightforward way. Generative models that are better(in the sense that they better model the distribution from which their trainingdata is drawn) do not necessarily result in better performance of theoptimization algorithm they form a part of. This raises the question of howbest to incorporate powerful generative models into optimization routines. Inlight of this we find that adding an explicit mutation operator to the outputof the generative model often improves optimization performance.</description><author>John Gardiner, Javier Lopez-Piqueres</author><pubDate>Fri, 27 Dec 2024 18:22:47 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.19780v1</guid></item><item><title>Symbolic Approximations to Ricci-flat Metrics Via Extrinsic Symmetries of Calabi-Yau Hypersurfaces</title><link>http://arxiv.org/abs/2412.19778v1</link><description>Ever since Yau's non-constructive existence proof of Ricci-flat metrics onCalabi-Yau manifolds, finding their explicit construction remains a majorobstacle to development of both string theory and algebraic geometry. Recentcomputational approaches employ machine learning to create novel neuralrepresentations for approximating these metrics, offering high accuracy butlimited interpretability. In this paper, we analyse machine learningapproximations to flat metrics of Fermat Calabi-Yau n-folds and some of theirone-parameter deformations in three dimensions in order to discover their newproperties. We formalise cases in which the flat metric has more symmetriesthan the underlying manifold, and prove that these symmetries imply that theflat metric admits a surprisingly compact representation for certain choices ofcomplex structure moduli. We show that such symmetries uniquely determine theflat metric on certain loci, for which we present an analytic form. We alsoincorporate our theoretical results into neural networks to achievestate-of-the-art reductions in Ricci curvature for multiple Calabi-Yaumanifolds. We conclude by distilling the ML models to obtain for the first timeclosed form expressions for Kahler metrics with near-zero scalar curvature.</description><author>Viktor Mirjanić, Challenger Mishra</author><pubDate>Fri, 27 Dec 2024 18:19:26 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.19778v1</guid></item><item><title>DAG-aware Transformer for Causal Effect Estimation</title><link>http://arxiv.org/abs/2410.10044v2</link><description>Causal inference is a critical task across fields such as healthcare,economics, and the social sciences. While recent advances in machine learning,especially those based on the deep-learning architectures, have shown potentialin estimating causal effects, existing approaches often fall short in handlingcomplex causal structures and lack adaptability across various causalscenarios. In this paper, we present a novel transformer-based method forcausal inference that overcomes these challenges. The core innovation of ourmodel lies in its integration of causal Directed Acyclic Graphs (DAGs) directlyinto the attention mechanism, enabling it to accurately model the underlyingcausal structure. This allows for flexible estimation of both average treatmenteffects (ATE) and conditional average treatment effects (CATE). Extensiveexperiments on both synthetic and real-world datasets demonstrate that ourapproach surpasses existing methods in estimating causal effects across a widerange of scenarios. The flexibility and robustness of our model make it avaluable tool for researchers and practitioners tackling complex causalinference problems.</description><author>Manqing Liu, David R. Bellamy, Andrew L. Beam</author><pubDate>Fri, 27 Dec 2024 18:16:12 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.10044v2</guid></item><item><title>Improved image display by identifying the RGB family color space</title><link>http://arxiv.org/abs/2412.19775v1</link><description>To display an image, the color space in which the image is encoded is assumedto be known. Unfortunately, this assumption is rarely realistic. In this paper,we propose to identify the color space of a given color image using pixelembedding and the Gaussian process. Five color spaces are supported, namelyAdobe RGB, Apple RGB, ColorMatch RGB, ProPhoto RGB and sRGB. The resultsobtained show that this problem deserves more efforts.</description><author>Elvis Togban, Djemel Ziou</author><pubDate>Fri, 27 Dec 2024 18:14:54 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.19775v1</guid></item><item><title>Analysis of Premature Death Rates in Texas Counties: The Impact of Air Quality, Socioeconomic Factors, and COPD Prevalence</title><link>http://arxiv.org/abs/2412.19774v1</link><description>Understanding factors contributing to premature mortality is critical forpublic health planning. This study examines the relationships between prematuredeath rates and multiple risk factors across several Texas counties, utilizingEPA air quality data, Census information, and county health records from recentyears. We analyze the impact of air quality (PM2.5 levels), socioeconomicfactors (median household income), and health conditions (COPD prevalence)through statistical analysis and modeling techniques. Results reveal COPDprevalence as a strong predictor of premature death rates, with higherprevalence associated with a substantial increase in years of potential lifelost. While socioeconomic factors show a significant negative correlation, airquality demonstrates more complex indirect relationships. These findingsemphasize the need for integrated public health interventions that prioritizekey health conditions while addressing underlying socioeconomic disparities.</description><author>Richard Rich, Ernesto Diaz</author><pubDate>Fri, 27 Dec 2024 18:12:04 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.19774v1</guid></item><item><title>Fortran2CPP: Automating Fortran-to-C++ Migration using LLMs via Multi-Turn Dialogue and Dual-Agent Integration</title><link>http://arxiv.org/abs/2412.19770v1</link><description>Migrating Fortran code to C++ is a common task for many scientific computingteams, driven by the need to leverage modern programming paradigms, enhancecross-platform compatibility, and improve maintainability. Automating thistranslation process using large language models (LLMs) has shown promise, butthe lack of high-quality, specialized datasets has hindered theireffectiveness. In this paper, we address this challenge by introducing a novelmulti-turn dialogue dataset, Fortran2CPP, specifically designed forFortran-to-C++ code migration. Our dataset, significantly larger than existingalternatives, is generated using a unique LLM-driven, dual-agent pipelineincorporating iterative compilation, execution, and code repair to ensure highquality and functional correctness. To demonstrate the effectiveness of ourdataset, we fine-tuned several open-weight LLMs on Fortran2CPP and evaluatedtheir performance on two independent benchmarks. Fine-tuning on our dataset ledto remarkable gains, with models achieving up to a 3.31x increase in CodeBLEUscore and a 92\% improvement in compilation success rate. This highlights thedataset's ability to enhance both the syntactic accuracy and compilability ofthe translated C++ code. Our dataset and model have been open-sourced and areavailable on our public GitHubrepository\footnote{\url{https://github.com/HPC-Fortran2CPP/Fortran2Cpp}}.</description><author>Le Chen, Bin Lei, Dunzhi Zhou, Pei-Hung Lin, Chunhua Liao, Caiwen Ding, Ali Jannesari</author><pubDate>Fri, 27 Dec 2024 18:06:25 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.19770v1</guid></item><item><title>From Ceilings to Walls: Universal Dynamic Perching of Small Aerial Robots on Surfaces with Variable Orientations</title><link>http://arxiv.org/abs/2412.19765v1</link><description>This work demonstrates universal dynamic perching capabilities for quadrotorsof various sizes and on surfaces with different orientations. By employing anon-dimensionalization framework and deep reinforcement learning, wesystematically assessed how robot size and surface orientation affect landingcapabilities. We hypothesized that maintaining geometric proportions acrossdifferent robot scales ensures consistent perching behavior, which wasvalidated in both simulation and experimental tests. Additionally, weinvestigated the effects of joint stiffness and damping in the landing gear onperching behaviors and performance. While joint stiffness had minimal impact,joint damping ratios influenced landing success under vertical approachingconditions. The study also identified a critical velocity threshold necessaryfor successful perching, determined by the robot's maneuverability and leggeometry. Overall, this research advances robotic perching capabilities,offering insights into the role of mechanical design and scaling effects, andlays the groundwork for future drone autonomy and operational efficiency inunstructured environments.</description><author>Bryan Habas, Aaron Brown, Donghyeon Lee, Mitchell Goldman, Bo Cheng</author><pubDate>Fri, 27 Dec 2024 17:53:01 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.19765v1</guid></item><item><title>CHESS: Optimizing LLM Inference via Channel-Wise Thresholding and Selective Sparsification</title><link>http://arxiv.org/abs/2409.01366v2</link><description>Deploying large language models (LLMs) on edge devices presents significantchallenges due to the substantial computational overhead and memoryrequirements. Activation sparsification can mitigate these resource challengesby reducing the number of activated neurons during inference. Existing methodstypically employ thresholding-based sparsification based on the statistics ofactivation tensors. However, they do not model the impact of activationsparsification on performance, resulting in suboptimal performance degradation.To address the limitations, this paper reformulates the activationsparsification problem to explicitly capture the relationship betweenactivation sparsity and model performance. Then, this paper proposes CHESS, ageneral activation sparsification approach via CHannel-wise thrEsholding andSelective Sparsification. First, channel-wise thresholding assigns a uniquethreshold to each activation channel in the feed-forward network (FFN) layers.Then, selective sparsification involves applying thresholding-based activationsparsification to specific layers within the attention modules. Finally, wedetail the implementation of sparse kernels to accelerate LLM inference.Experimental results demonstrate that the proposed CHESS achieves lowerperformance degradation over eight downstream tasks while activating fewerparameters than existing methods, thus speeding up the LLM inference by up to1.27x.</description><author>Junhui He, Shangyu Wu, Weidong Wen, Chun Jason Xue, Qingan Li</author><pubDate>Fri, 27 Dec 2024 17:49:34 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2409.01366v2</guid></item><item><title>Generative Video Propagation</title><link>http://arxiv.org/abs/2412.19761v1</link><description>Large-scale video generation models have the inherent ability torealistically model natural scenes. In this paper, we demonstrate that througha careful design of a generative video propagation framework, various videotasks can be addressed in a unified way by leveraging the generative power ofsuch models. Specifically, our framework, GenProp, encodes the original videowith a selective content encoder and propagates the changes made to the firstframe using an image-to-video generation model. We propose a data generationscheme to cover multiple video tasks based on instance-level video segmentationdatasets. Our model is trained by incorporating a mask prediction decoder headand optimizing a region-aware loss to aid the encoder to preserve the originalcontent while the generation model propagates the modified region. This noveldesign opens up new possibilities: In editing scenarios, GenProp allowssubstantial changes to an object's shape; for insertion, the inserted objectscan exhibit independent motion; for removal, GenProp effectively removeseffects like shadows and reflections from the whole video; for tracking,GenProp is capable of tracking objects and their associated effects together.Experiment results demonstrate the leading performance of our model in variousvideo tasks, and we further provide in-depth analyses of the proposedframework.</description><author>Shaoteng Liu, Tianyu Wang, Jui-Hsien Wang, Qing Liu, Zhifei Zhang, Joon-Young Lee, Yijun Li, Bei Yu, Zhe Lin, Soo Ye Kim, Jiaya Jia</author><pubDate>Fri, 27 Dec 2024 17:42:29 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.19761v1</guid></item><item><title>Enhancing Cognitive Diagnosis by Modeling Learner Cognitive Structure State</title><link>http://arxiv.org/abs/2412.19759v1</link><description>Cognitive diagnosis represents a fundamental research area within intelligenteducation, with the objective of measuring the cognitive status of individuals.Theoretically, an individual's cognitive state is essentially equivalent totheir cognitive structure state. Cognitive structure state comprises two keycomponents: knowledge state (KS) and knowledge structure state (KUS). Theknowledge state reflects the learner's mastery of individual concepts, a widelystudied focus within cognitive diagnosis. In contrast, the knowledge structurestate-representing the learner's understanding of the relationships betweenconcepts-remains inadequately modeled. A learner's cognitive structure isessential for promoting meaningful learning and shaping academic performance.Although various methods have been proposed, most focus on assessing KS andfail to assess KUS. To bridge this gap, we propose an innovative and effectiveframework-CSCD (Cognitive Structure State-based Cognitive Diagnosis)-whichintroduces a novel framework to modeling learners' cognitive structures indiagnostic assessments, thereby offering new insights into cognitive structuremodeling. Specifically, we employ an edge-feature-based graph attention networkto represent the learner's cognitive structure state, effectively integratingKS and KUS. Extensive experiments conducted on real datasets demonstrate thesuperior performance of this framework in terms of diagnostic accuracy andinterpretability.</description><author>Zhifu Chen, Hengnian Gu, Jin Peng Zhou, Dongdai Zhou</author><pubDate>Fri, 27 Dec 2024 17:41:39 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.19759v1</guid></item><item><title>Safetywashing: Do AI Safety Benchmarks Actually Measure Safety Progress?</title><link>http://arxiv.org/abs/2407.21792v3</link><description>As artificial intelligence systems grow more powerful, there has beenincreasing interest in "AI safety" research to address emerging and futurerisks. However, the field of AI safety remains poorly defined andinconsistently measured, leading to confusion about how researchers cancontribute. This lack of clarity is compounded by the unclear relationshipbetween AI safety benchmarks and upstream general capabilities (e.g., generalknowledge and reasoning). To address these issues, we conduct a comprehensivemeta-analysis of AI safety benchmarks, empirically analyzing their correlationwith general capabilities across dozens of models and providing a survey ofexisting directions in AI safety. Our findings reveal that many safetybenchmarks highly correlate with both upstream model capabilities and trainingcompute, potentially enabling "safetywashing"--where capability improvementsare misrepresented as safety advancements. Based on these findings, we proposean empirical foundation for developing more meaningful safety metrics anddefine AI safety in a machine learning research context as a set of clearlydelineated research goals that are empirically separable from genericcapabilities advancements. In doing so, we aim to provide a more rigorousframework for AI safety research, advancing the science of safety evaluationsand clarifying the path towards measurable progress.</description><author>Richard Ren, Steven Basart, Adam Khoja, Alice Gatti, Long Phan, Xuwang Yin, Mantas Mazeika, Alexander Pan, Gabriel Mukobi, Ryan H. Kim, Stephen Fitz, Dan Hendrycks</author><pubDate>Fri, 27 Dec 2024 17:36:21 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.21792v3</guid></item><item><title>"Did my figure do justice to the answer?" : Towards Multimodal Short Answer Grading with Feedback (MMSAF)</title><link>http://arxiv.org/abs/2412.19755v1</link><description>Personalized feedback plays a vital role in a student's learning process.While existing systems are adept at providing feedback over MCQ-basedevaluation, this work focuses more on subjective and open-ended questions,which is similar to the problem of Automatic Short Answer Grading (ASAG) withfeedback. Additionally, we introduce the Multimodal Short Answer grading withFeedback (MMSAF) problem over the traditional ASAG feedback problem to addressthe scenario where the student answer and reference answer might containimages. Moreover, we introduce the MMSAF dataset with 2197 data points alongwith an automated framework for generating such data sets. Our evaluations onexisting LLMs over this dataset achieved an overall accuracy of 55\% on Levelof Correctness labels, 75\% on Image Relevance labels and a score of 4.27 outof 5 in correctness level of LLM generated feedback as rated by experts. As perexperts, Pixtral achieved a rating of above 4 out of all metrics, indicatingthat it is more aligned to human judgement, and that it is the best solutionfor assisting students.</description><author>Pritam Sil, Bhaskaran Raman, Pushpak Bhattacharyya</author><pubDate>Fri, 27 Dec 2024 17:33:39 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.19755v1</guid></item><item><title>Complement or substitute? How AI increases the demand for human skills</title><link>http://arxiv.org/abs/2412.19754v1</link><description>The question of whether AI substitutes or complements human work is centralto debates on the future of work. This paper examines the impact of AI on skilldemand and compensation in the U.S. economy, analysing 12 million online jobvacancies from 2018 to 2023. It investigates internal effects (within-jobsubstitution and complementation) and external effects (across occupations,industries, and regions). Our findings reveal a significant increase in demandfor AI-complementary skills, such as digital literacy, teamwork, andresilience, alongside rising wage premiums for these skills in AI roles likeData Scientist. Conversely, substitute skills, including customer service andtext review, have declined in both demand and value within AI-relatedpositions. Examining external effects, we find a notable rise in demand forcomplementary skills in non-AI roles linked to the growth of AI-related jobs inspecific industries or regions. At the same time, there is a moderate declinein non-AI roles requiring substitute skills. Overall, AI's complementary effectis up to 50% larger than its substitution effect, resulting in net positivedemand for skills. These results, replicated for the UK and Australia,highlight AI's transformative impact on workforce skill requirements. Theysuggest reskilling efforts should prioritise not only technical AI skills butalso complementary skills like ethics and digital literacy.</description><author>Elina Mäkelä, Fabian Stephany</author><pubDate>Fri, 27 Dec 2024 17:26:30 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.19754v1</guid></item><item><title>IMAGINE: An 8-to-1b 22nm FD-SOI Compute-In-Memory CNN Accelerator With an End-to-End Analog Charge-Based 0.15-8POPS/W Macro Featuring Distribution-Aware Data Reshaping</title><link>http://arxiv.org/abs/2412.19750v1</link><description>Charge-domain compute-in-memory (CIM) SRAMs have recently become an enticingcompromise between computing efficiency and accuracy to process sub-8bconvolutional neural networks (CNNs) at the edge. Yet, they commonly make useof a fixed dot-product (DP) voltage swing, which leads to a loss in effectiveADC bits due to data-dependent clipping or truncation effects that wasteprecious conversion energy and computing accuracy. To overcome this, we presentIMAGINE, a workload-adaptive 1-to-8b CIM-CNN accelerator in 22nm FD-SOI. Itintroduces a 1152x256 end-to-end charge-based macro with a multi-bit DP basedon an input-serial, weight-parallel accumulation that avoids power-hungry DACs.An adaptive swing is achieved by combining a channel-wise DP array split with alinear in-ADC implementation of analog batch-normalization (ABN), obtaining adistribution-aware data reshaping. Critical design constraints are relaxed byincluding the post-silicon equivalent noise within a CIM-aware CNN trainingframework. Measurement results showcase an 8b system-level energy efficiency of40TOPS/W at 0.3/0.6V, with competitive accuracies on MNIST and CIFAR-10.Moreover, the peak energy and area efficiencies of the 187kB/mm2 macrorespectively reach up to 0.15-8POPS/W and 2.6-154TOPS/mm2, scaling with the8-to-1b computing precision. These results exceed previous charge-based designsby 3-to-5x while being the first work to provide linear in-memory rescaling.</description><author>Adrian Kneip, Martin Lefebvre, Pol Maistriaux, David Bol</author><pubDate>Fri, 27 Dec 2024 17:18:15 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.19750v1</guid></item><item><title>Keypoint Aware Masked Image Modelling</title><link>http://arxiv.org/abs/2407.13873v2</link><description>SimMIM is a widely used method for pretraining vision transformers usingmasked image modeling. However, despite its success in fine-tuning performance,it has been shown to perform sub-optimally when used for linear probing. Wepropose an efficient patch-wise weighting derived from keypoint features whichcaptures the local information and provides better context during SimMIM'sreconstruction phase. Our method, KAMIM, improves the top-1 linear probingaccuracy from 16.12% to 33.97%, and finetuning accuracy from 76.78% to 77.3%when tested on the ImageNet-1K dataset with a ViT-B when trained for the samenumber of epochs. We conduct extensive testing on different datasets, keypointextractors, and model architectures and observe that patch-wise weightingaugments linear probing performance for larger pretraining datasets. We alsoanalyze the learned representations of a ViT-B trained using KAMIM and observethat they behave similar to contrastive learning with regard to its behavior,with longer attention distances and homogenous self-attention across layers.Our code is publicly available at https://github.com/madhava20217/KAMIM.</description><author>Madhava Krishna, A V Subramanyam</author><pubDate>Fri, 27 Dec 2024 17:16:25 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.13873v2</guid></item><item><title>Enhancing Adversarial Robustness of Deep Neural Networks Through Supervised Contrastive Learning</title><link>http://arxiv.org/abs/2412.19747v1</link><description>Adversarial attacks exploit the vulnerabilities of convolutional neuralnetworks by introducing imperceptible perturbations that lead tomisclassifications, exposing weaknesses in feature representations and decisionboundaries. This paper presents a novel framework combining supervisedcontrastive learning and margin-based contrastive loss to enhance adversarialrobustness. Supervised contrastive learning improves the structure of thefeature space by clustering embeddings of samples within the same class andseparating those from different classes. Margin-based contrastive loss,inspired by support vector machines, enforces explicit constraints to createrobust decision boundaries with well-defined margins. Experiments on theCIFAR-100 dataset with a ResNet-18 backbone demonstrate robustness performanceimprovements in adversarial accuracy under Fast Gradient Sign Method attacks.</description><author>Longwei Wang, Navid Nayyem, Abdullah Rakin</author><pubDate>Fri, 27 Dec 2024 17:14:52 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.19747v1</guid></item><item><title>Adaptive Context-Aware Multi-Path Transmission Control for VR/AR Content: A Deep Reinforcement Learning Approach</title><link>http://arxiv.org/abs/2412.19737v1</link><description>This paper introduces the Adaptive Context-Aware Multi-Path TransmissionControl Protocol (ACMPTCP), an efficient approach designed to optimize theperformance of Multi-Path Transmission Control Protocol (MPTCP) fordata-intensive applications such as augmented and virtual reality (AR/VR)streaming. ACMPTCP addresses the limitations of conventional MPTCP byleveraging deep reinforcement learning (DRL) for agile end-to-end pathmanagement and optimal bandwidth allocation, facilitating path realignmentacross diverse network environments.</description><author>Shakil Ahmed, Saifur Rahman Sabuj, Ashfaq Khokhar</author><pubDate>Fri, 27 Dec 2024 16:56:12 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.19737v1</guid></item><item><title>Generative Pretrained Embedding and Hierarchical Irregular Time Series Representation for Daily Living Activity Recognition</title><link>http://arxiv.org/abs/2412.19732v1</link><description>Within the evolving landscape of smart homes, the precise recognition ofdaily living activities using ambient sensor data stands paramount. This papernot only aims to bolster existing algorithms by evaluating two distinctpretrained embeddings suited for ambient sensor activations but also introducesa novel hierarchical architecture. We delve into an architecture anchored onTransformer Decoder-based pre-trained embeddings, reminiscent of the GPTdesign, and contrast it with the previously established state-of-the-art (SOTA)ELMo embeddings for ambient sensors. Our proposed hierarchical structureleverages the strengths of each pre-trained embedding, enabling the discernmentof activity dependencies and sequence order, thereby enhancing classificationprecision. To further refine recognition, we incorporate into our proposedarchitecture an hour-of-the-day embedding. Empirical evaluations underscore thepreeminence of the Transformer Decoder embedding in classification endeavors.Additionally, our innovative hierarchical design significantly bolsters theefficacy of both pre-trained embeddings, notably in capturing inter-activitynuances. The integration of temporal aspects subtly but distinctively augmentsclassification, especially for time-sensitive activities. In conclusion, ourGPT-inspired hierarchical approach, infused with temporal insights, outshinesthe SOTA ELMo benchmark.</description><author>Damien Bouchabou, Sao Mai Nguyen</author><pubDate>Fri, 27 Dec 2024 16:43:52 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.19732v1</guid></item><item><title>Global Prediction of COVID-19 Variant Emergence Using Dynamics-Informed Graph Neural Networks</title><link>http://arxiv.org/abs/2401.03390v3</link><description>During the COVID-19 pandemic, a major driver of new surges has been theemergence of new variants. When a new variant emerges in one or more countries,other nations monitor its spread in preparation for its potential arrival. Theimpact of the new variant and the timings of epidemic peaks in a country highlydepend on when the variant arrives. The current methods for predicting thespread of new variants rely on statistical modeling, however, these methodswork only when the new variant has already arrived in the region of interestand has a significant prevalence. Can we predict when a variant existingelsewhere will arrive in a given region? To address this question, we propose avariant-dynamics-informed Graph Neural Network (GNN) approach. First, we derivethe dynamics of variant prevalence across pairs of regions (countries) thatapply to a large class of epidemic models. The dynamics motivate theintroduction of certain features in the GNN. We demonstrate that our proposeddynamics-informed GNN outperforms all the baselines, including the currentlypervasive framework of Physics-Informed Neural Networks (PINNs). To advanceresearch in this area, we introduce a benchmarking tool to assess auser-defined model's prediction performance across 87 countries and 36variants.</description><author>Majd Al Aawar, Srikar Mutnuri, Mansooreh Montazerin, Ajitesh Srivastava</author><pubDate>Fri, 27 Dec 2024 16:43:44 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.03390v3</guid></item><item><title>Language-Guided Diffusion Model for Visual Grounding</title><link>http://arxiv.org/abs/2308.09599v2</link><description>Visual grounding (VG) tasks involve explicit cross-modal alignment, assemantically corresponding image regions are to be located for the languagephrases provided. Existing approaches complete such visual-text reasoning in asingle-step manner. Their performance causes high demands on large-scaleanchors and over-designed multi-modal fusion modules based on human priors,leading to complicated frameworks that may be difficult to train and overfit tospecific scenarios. Even worse, such once-for-all reasoning mechanisms areincapable of refining boxes continuously to enhance query-region matching. Incontrast, in this paper, we formulate an iterative reasoning process bydenoising diffusion modeling. Specifically, we propose a language-guideddiffusion framework for visual grounding, LG-DVG, which trains the model toprogressively reason queried object boxes by denoising a set of noisy boxeswith the language guide. To achieve this, LG-DVG gradually perturbsquery-aligned ground truth boxes to noisy ones and reverses this process stepby step, conditional on query semantics. Extensive experiments for our proposedframework on five widely used datasets validate the superior performance ofsolving visual grounding, a cross-modal alignment task, in a generative way.The source codes are available athttps://github.com/iQua/vgbase/tree/main/examples/DiffusionVG.</description><author>Sijia Chen, Baochun Li</author><pubDate>Fri, 27 Dec 2024 16:36:56 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2308.09599v2</guid></item><item><title>Learning to Forget: Bayesian Time Series Forecasting using Recurrent Sparse Spectrum Signature Gaussian Processes</title><link>http://arxiv.org/abs/2412.19727v1</link><description>The signature kernel is a kernel between time series of arbitrary length andcomes with strong theoretical guarantees from stochastic analysis. It has foundapplications in machine learning such as covariance functions for Gaussianprocesses. A strength of the underlying signature features is that they providea structured global description of a time series. However, this property canquickly become a curse when local information is essential and forgetting isrequired; so far this has only been addressed with ad-hoc methods such asslicing the time series into subsegments. To overcome this, we propose aprincipled, data-driven approach by introducing a novel forgetting mechanismfor signatures. This allows the model to dynamically adapt its context lengthto focus on more recent information. To achieve this, we revisit the recentlyintroduced Random Fourier Signature Features, and develop Random FourierDecayed Signature Features (RFDSF) with Gaussian processes (GPs). This resultsin a Bayesian time series forecasting algorithm with variational inference,that offers a scalable probabilistic algorithm that processes and transforms atime series into a joint predictive distribution over time steps in one passusing recurrence. For example, processing a sequence of length $10^4$ steps in$\approx 10^{-2}$ seconds and in $&lt; 1\text{GB}$ of GPU memory. We demonstratethat it outperforms other GP-based alternatives and competes withstate-of-the-art probabilistic time series forecasting algorithms.</description><author>Csaba Tóth, Masaki Adachi, Michael A. Osborne, Harald Oberhauser</author><pubDate>Fri, 27 Dec 2024 16:31:09 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.19727v1</guid></item><item><title>Can Large Language Models Adapt to Other Agents In-Context?</title><link>http://arxiv.org/abs/2412.19726v1</link><description>As the research community aims to build better AI assistants that are moredynamic and personalized to the diversity of humans that they interact with,there is increased interest in evaluating the theory of mind capabilities oflarge language models (LLMs). Indeed, several recent studies suggest that LLMtheory of mind capabilities are quite impressive, approximating human-levelperformance. Our paper aims to rebuke this narrative and argues instead thatpast studies were not directly measuring agent performance, potentially leadingto findings that are illusory in nature as a result. We draw a strongdistinction between what we call literal theory of mind i.e. measuring theagent's ability to predict the behavior of others and functional theory of mindi.e. adapting to agents in-context based on a rational response to predictionsof their behavior. We find that top performing open source LLMs may displaystrong capabilities in literal theory of mind, depending on how they areprompted, but seem to struggle with functional theory of mind -- even whenpartner policies are exceedingly simple. Our work serves to highlight thedouble sided nature of inductive bias in LLMs when adapting to new situations.While this bias can lead to strong performance over limited horizons, it oftenhinders convergence to optimal long-term behavior.</description><author>Matthew Riemer, Zahra Ashktorab, Djallel Bouneffouf, Payel Das, Miao Liu, Justin D. Weisz, Murray Campbell</author><pubDate>Fri, 27 Dec 2024 16:30:12 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.19726v1</guid></item><item><title>Gradient Alignment Improves Test-Time Adaptation for Medical Image Segmentation</title><link>http://arxiv.org/abs/2408.07343v4</link><description>Although recent years have witnessed significant advancements in medicalimage segmentation, the pervasive issue of domain shift among medical imagesfrom diverse centres hinders the effective deployment of pre-trained models.Many Test-time Adaptation (TTA) methods have been proposed to address thisissue by fine-tuning pre-trained models with test data during inference. Thesemethods, however, often suffer from less-satisfactory optimization due tosuboptimal optimization direction (dictated by the gradient) and fixedstep-size (predicated on the learning rate). In this paper, we propose theGradient alignment-based Test-time adaptation (GraTa) method to improve boththe gradient direction and learning rate in the optimization procedure. Unlikeconventional TTA methods, which primarily optimize the pseudo gradient derivedfrom a self-supervised objective, our method incorporates an auxiliary gradientwith the pseudo one to facilitate gradient alignment. Such gradient alignmentenables the model to excavate the similarities between different gradients andcorrect the gradient direction to approximate the empirical gradient related tothe current segmentation task. Additionally, we design a dynamic learning ratebased on the cosine similarity between the pseudo and auxiliary gradients,thereby empowering the adaptive fine-tuning of pre-trained models on diversetest data. Extensive experiments establish the effectiveness of the proposedgradient alignment and dynamic learning rate and substantiate the superiorityof our GraTa method over other state-of-the-art TTA methods on a benchmarkmedical image segmentation task. The code and weights of pre-trained sourcemodels are available at https://github.com/Chen-Ziyang/GraTa.</description><author>Ziyang Chen, Yiwen Ye, Yongsheng Pan, Yong Xia</author><pubDate>Fri, 27 Dec 2024 16:29:25 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.07343v4</guid></item><item><title>EEG-Reptile: An Automatized Reptile-Based Meta-Learning Library for BCIs</title><link>http://arxiv.org/abs/2412.19725v1</link><description>Meta-learning, i.e., "learning to learn", is a promising approach to enableefficient BCI classifier training with limited amounts of data. It caneffectively use collections of in some way similar classification tasks, withrapid adaptation to new tasks where only minimal data are available. However,applying meta-learning to existing classifiers and BCI tasks requiressignificant effort. To address this issue, we propose EEG-Reptile, an automatedlibrary that leverages meta-learning to improve classification accuracy ofneural networks in BCIs and other EEG-based applications. It utilizes theReptile meta-learning algorithm to adapt neural network classifiers of EEG datato the inter-subject domain, allowing for more efficient fine-tuning for a newsubject on a small amount of data. The proposed library incorporates anautomated hyperparameter tuning module, a data management pipeline, and animplementation of the Reptile meta-learning algorithm. EEG-Reptile automationlevel allows using it without deep understanding of meta-learning. Wedemonstrate the effectiveness of EEG-Reptile on two benchmark datasets (BCI IV2a, Lee2019 MI) and three neural network architectures (EEGNet, FBCNet,EEG-Inception). Our library achieved improvement in both zero-shot and few-shotlearning scenarios compared to traditional transfer learning approaches.</description><author>Daniil A. Berdyshev, Artem M. Grachev, Sergei L. Shishkin, Bogdan L. Kozyrskiy</author><pubDate>Fri, 27 Dec 2024 16:24:31 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.19725v1</guid></item><item><title>DGNN-YOLO: Interpretable Dynamic Graph Neural Networks with YOLO11 for Small Object Detection and Tracking in Traffic Surveillance</title><link>http://arxiv.org/abs/2411.17251v4</link><description>Accurate detection and tracking of small objects, such as pedestrians,cyclists, and motorbikes, is critical for traffic surveillance systems, whichare crucial for improving road safety and decision-making in intelligenttransportation systems. However, traditional methods face challenges such asocclusion, low resolution, and dynamic traffic conditions, necessitatinginnovative approaches to address these limitations. This paper introducesDGNN-YOLO, a novel framework integrating dynamic graph neural networks (DGNN)with YOLO11 to enhance small-object detection and tracking in trafficsurveillance systems. The framework leverages YOLO11's advanced spatial featureextraction capabilities for precise object detection and incorporates a DGNN tomodel spatial-temporal relationships for robust real-time tracking dynamically.By constructing and updating graph structures, DGNN-YOLO effectively representsobjects as nodes and their interactions as edges, thereby ensuring adaptive andaccurate tracking in complex and dynamic environments. Additionally, Grad-CAM,Grad-CAM++, and Eigen-CAM visualization techniques were applied to DGNN-YOLO toprovide model-agnostic interpretability and deeper insights into the model'sdecision-making process, enhancing its transparency and trustworthiness.Extensive experiments demonstrated that DGNN-YOLO consistently outperformedstate-of-the-art methods in detecting and tracking small objects under diversetraffic conditions, achieving the highest precision (0.8382), recall (0.6875),and mAP@0.5:0.95 (0.6476), showing its robustness and scalability, particularlyin challenging scenarios involving small and occluded objects. This studyprovides a scalable, real-time traffic surveillance and analysis solution,significantly contributing to intelligent transportation systems.</description><author>Shahriar Soudeep, M. F. Mridha, Md Abrar Jahin, Nilanjan Dey</author><pubDate>Fri, 27 Dec 2024 16:24:20 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2411.17251v4</guid></item><item><title>OS-Genesis: Automating GUI Agent Trajectory Construction via Reverse Task Synthesis</title><link>http://arxiv.org/abs/2412.19723v1</link><description>Graphical User Interface (GUI) agents powered by Vision-Language Models(VLMs) have demonstrated human-like computer control capability. Despite theirutility in advancing digital automation, a critical bottleneck persists:collecting high-quality trajectory data for training. Common practices forcollecting such data rely on human supervision or synthetic data generationthrough executing pre-defined tasks, which are either resource-intensive orunable to guarantee data quality. Moreover, these methods suffer from limiteddata diversity and significant gaps between synthetic data and real-worldenvironments. To address these challenges, we propose OS-Genesis, a novel GUIdata synthesis pipeline that reverses the conventional trajectory collectionprocess. Instead of relying on pre-defined tasks, OS-Genesis enables agentsfirst to perceive environments and perform step-wise interactions, thenretrospectively derive high-quality tasks to enable trajectory-levelexploration. A trajectory reward model is then employed to ensure the qualityof the generated trajectories. We demonstrate that training GUI agents withOS-Genesis significantly improves their performance on highly challengingonline benchmarks. In-depth analysis further validates OS-Genesis's efficiencyand its superior data quality and diversity compared to existing synthesismethods. Our codes, data, and checkpoints are available at\href{https://qiushisun.github.io/OS-Genesis-Home/}{OS-Genesis Homepage}.</description><author>Qiushi Sun, Kanzhi Cheng, Zichen Ding, Chuanyang Jin, Yian Wang, Fangzhi Xu, Zhenyu Wu, Chengyou Jia, Liheng Chen, Zhoumianze Liu, Ben Kao, Guohao Li, Junxian He, Yu Qiao, Zhiyong Wu</author><pubDate>Fri, 27 Dec 2024 16:21:58 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.19723v1</guid></item><item><title>KACQ-DCNN: Uncertainty-Aware Interpretable Kolmogorov-Arnold Classical-Quantum Dual-Channel Neural Network for Heart Disease Detection</title><link>http://arxiv.org/abs/2410.07446v3</link><description>Heart failure is a leading cause of global mortality, necessitating improveddiagnostic strategies. Classical machine learning models struggle withchallenges such as high-dimensional data, class imbalances, poor featurerepresentations, and lack of interpretability. While quantum machine learningholds promise, current hybrid models have not fully exploited quantumadvantages. In this paper, we propose the Kolmogorov-Arnold Classical-QuantumDual-Channel Neural Network (KACQ-DCNN), a novel hybrid architecture thatreplaces traditional multilayer perceptrons with Kolmogorov-Arnold Networks(KANs), enabling learnable univariate activation functions. Our KACQ-DCNN4-qubit, 1-layer model outperforms 37 benchmark models, including 16 classicaland 12 quantum neural networks, achieving an accuracy of 92.03%, withmacro-average precision, recall, and F1 scores of 92.00%. It also achieved aROC-AUC of 94.77%, surpassing other models by significant margins, as validatedby paired t-tests with a significance threshold of 0.0056 (after Bonferronicorrection). Ablation studies highlight the synergistic effect ofclassical-quantum integration, improving performance by about 2% over MLPvariants. Additionally, LIME and SHAP explainability techniques enhance featureinterpretability, while conformal prediction provides robust uncertaintyquantification. Our results demonstrate that KACQ-DCNN improves cardiovasculardiagnostics by combining high accuracy with interpretability and uncertaintyquantification.</description><author>Md Abrar Jahin, Md. Akmol Masud, M. F. Mridha, Zeyar Aung, Nilanjan Dey</author><pubDate>Fri, 27 Dec 2024 16:21:32 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.07446v3</guid></item><item><title>Sharpening Neural Implicit Functions with Frequency Consolidation Priors</title><link>http://arxiv.org/abs/2412.19720v1</link><description>Signed Distance Functions (SDFs) are vital implicit representations torepresent high fidelity 3D surfaces. Current methods mainly leverage a neuralnetwork to learn an SDF from various supervisions including signed distances,3D point clouds, or multi-view images. However, due to various reasonsincluding the bias of neural network on low frequency content, 3D unawaresampling, sparsity in point clouds, or low resolutions of images, neuralimplicit representations still struggle to represent geometries with highfrequency components like sharp structures, especially for the ones learnedfrom images or point clouds. To overcome this challenge, we introduce a methodto sharpen a low frequency SDF observation by recovering its high frequencycomponents, pursuing a sharper and more complete surface. Our key idea is tolearn a mapping from a low frequency observation to a full frequency coveragein a data-driven manner, leading to a prior knowledge of shape consolidation inthe frequency domain, dubbed frequency consolidation priors. To bettergeneralize a learned prior to unseen shapes, we introduce to representfrequency components as embeddings and disentangle the embedding of the lowfrequency component from the embedding of the full frequency component. Thisdisentanglement allows the prior to generalize on an unseen low frequencyobservation by simply recovering its full frequency embedding through atest-time self-reconstruction. Our evaluations under widely used benchmarks orreal scenes show that our method can recover high frequency component andproduce more accurate surfaces than the latest methods. The code, data, andpre-trained models are available at \url{https://github.com/chenchao15/FCP}.</description><author>Chao Chen, Yu-Shen Liu, Zhizhong Han</author><pubDate>Fri, 27 Dec 2024 16:18:46 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.19720v1</guid></item><item><title>Text2Insight: Transform natural language text into insights seamlessly using multi-model architecture</title><link>http://arxiv.org/abs/2412.19718v1</link><description>The growing demand for dynamic, user-centric data analysis and visualizationis evident across domains like healthcare, finance, and research. Traditionalvisualization tools often fail to meet individual user needs due to theirstatic and predefined nature. To address this gap, Text2Insight is introducedas an innovative solution that delivers customized data analysis andvisualizations based on user-defined natural language requirements. Leveraginga multi-model architecture, Text2Insight transforms user inputs into actionableinsights and dynamic visualizations. The methodology begins with analyzing the input dataset to extract structuraldetails such as columns and values. A pre-trained Llama3 model converts theuser's natural language query into an SQL query, which is further refined usinga Named Entity Recognition (NER) model for accuracy. A chart predictordetermines the most suitable visualization type, while the Llama3 modelgenerates insights based on the SQL query's results. The output is auser-friendly and visually informative chart. To enhance analysis capabilities,the system integrates a question-answering model and a predictive model usingthe BERT framework. These models provide insights into historical data andpredict future trends. Performance evaluation of Text2Insight demonstrates its effectiveness,achieving high accuracy (99%), precision (100%), recall (99%), and F1-score(99%), with a BLEU score of 0.5. The question-answering model attained anaccuracy of 89% and the predictive model achieved 70% accuracy. These resultsvalidate Text2Insight as a robust and viable solution for transforming naturallanguage text into dynamic, user-specific data analysis and visualizations.</description><author>Pradeep Sain</author><pubDate>Fri, 27 Dec 2024 16:17:22 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.19718v1</guid></item><item><title>Impact of Sunglasses on One-to-Many Facial Identification Accuracy</title><link>http://arxiv.org/abs/2412.05721v2</link><description>One-to-many facial identification is documented to achieve high accuracy inthe case where both the probe and the gallery are "mugshot quality" images.However, an increasing number of documented instances of wrongful arrestfollowing one-to-many facial identification have raised questions about itsaccuracy. Probe images used in one-to-many facial identification are oftencropped from frames of surveillance video and deviate from "mugshot quality" invarious ways. This paper systematically explores how the accuracy ofone-to-many facial identification is degraded by the person in the probe imagechoosing to wear dark sunglasses. We show that sunglasses degrade accuracy formugshot-quality images by an amount similar to strong blur or noticeably lowerresolution. Further, we demonstrate that the combination of sunglasses withblur or lower resolution results in even more pronounced loss in accuracy.These results have important implications for developing objective criteria toqualify a probe image for the level of accuracy to be expected if it used forone-to-many identification. To ameliorate the accuracy degradation caused bydark sunglasses, we show that it is possible to recover about 38% of the lostaccuracy by synthetically adding sunglasses to all the gallery images, withoutmodel re-training. We also show that the frequency of wearing-sunglasses imagesis very low in existing training sets, and that increasing the representationof wearing-sunglasses images can greatly reduce the error rate. The image setassembled for this research is available at https://cvrl.nd.edu/projects/data/to support replication and further research.</description><author>Sicong Tian, Haiyu Wu, Michael C. King, Kevin W. Bowyer</author><pubDate>Fri, 27 Dec 2024 16:15:52 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.05721v2</guid></item><item><title>ProKAN: Progressive Stacking of Kolmogorov-Arnold Networks for Efficient Liver Segmentation</title><link>http://arxiv.org/abs/2412.19713v1</link><description>The growing need for accurate and efficient 3D identification of tumors,particularly in liver segmentation, has spurred considerable research into deeplearning models. While many existing architectures offer strong performance,they often face challenges such as overfitting and excessive computationalcosts. An adjustable and flexible architecture that strikes a balance betweentime efficiency and model complexity remains an unmet requirement. In thispaper, we introduce proKAN, a progressive stacking methodology forKolmogorov-Arnold Networks (KANs) designed to address these challenges. Unliketraditional architectures, proKAN dynamically adjusts its complexity byprogressively adding KAN blocks during training, based on overfitting behavior.This approach allows the network to stop growing when overfitting is detected,preventing unnecessary computational overhead while maintaining high accuracy.Additionally, proKAN utilizes KAN's learnable activation functions modeledthrough B-splines, which provide enhanced flexibility in learning complexrelationships in 3D medical data. Our proposed architecture achievesstate-of-the-art performance in liver segmentation tasks, outperformingstandard Multi-Layer Perceptrons (MLPs) and fixed KAN architectures. Thedynamic nature of proKAN ensures efficient training times and high accuracywithout the risk of overfitting. Furthermore, proKAN provides betterinterpretability by allowing insight into the decision-making process throughits learnable coefficients. The experimental results demonstrate a significantimprovement in accuracy, Dice score, and time efficiency, making proKAN acompelling solution for 3D medical image segmentation tasks.</description><author>Bhavesh Gyanchandani, Aditya Oza, Abhinav Roy</author><pubDate>Fri, 27 Dec 2024 16:14:06 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.19713v1</guid></item><item><title>Free-viewpoint Human Animation with Pose-correlated Reference Selection</title><link>http://arxiv.org/abs/2412.17290v2</link><description>Diffusion-based human animation aims to animate a human character based on asource human image as well as driving signals such as a sequence of poses.Leveraging the generative capacity of diffusion model, existing approaches areable to generate high-fidelity poses, but struggle with significant viewpointchanges, especially in zoom-in/zoom-out scenarios where camera-characterdistance varies. This limits the applications such as cinematic shot type planor camera control. We propose a pose-correlated reference selection diffusionnetwork, supporting substantial viewpoint variations in human animation. Ourkey idea is to enable the network to utilize multiple reference images asinput, since significant viewpoint changes often lead to missing appearancedetails on the human body. To eliminate the computational cost, we firstintroduce a novel pose correlation module to compute similarities betweennon-aligned target and source poses, and then propose an adaptive referenceselection strategy, utilizing the attention map to identify key regions foranimation generation. To train our model, we curated a large dataset frompublic TED talks featuring varied shots of the same character, helping themodel learn synthesis for different perspectives. Our experimental results showthat with the same number of reference images, our model performs favorablycompared to the current SOTA methods under large viewpoint change. We furthershow that the adaptive reference selection is able to choose the most relevantreference regions to generate humans under free viewpoints.</description><author>Fa-Ting Hong, Zhan Xu, Haiyang Liu, Qinjie Lin, Luchuan Song, Zhixin Shu, Yang Zhou, Duygu Ceylan, Dan Xu</author><pubDate>Fri, 27 Dec 2024 16:13:32 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.17290v2</guid></item><item><title>From Elements to Design: A Layered Approach for Automatic Graphic Design Composition</title><link>http://arxiv.org/abs/2412.19712v1</link><description>In this work, we investigate automatic design composition from multimodalgraphic elements. Although recent studies have developed various generativemodels for graphic design, they usually face the following limitations: theyonly focus on certain subtasks and are far from achieving the designcomposition task; they do not consider the hierarchical information of graphicdesigns during the generation process. To tackle these issues, we introduce thelayered design principle into Large Multimodal Models (LMMs) and propose anovel approach, called LaDeCo, to accomplish this challenging task.Specifically, LaDeCo first performs layer planning for a given element set,dividing the input elements into different semantic layers according to theircontents. Based on the planning results, it subsequently predicts elementattributes that control the design composition in a layer-wise manner, andincludes the rendered image of previously generated layers into the context.With this insightful design, LaDeCo decomposes the difficult task into smallermanageable steps, making the generation process smoother and clearer. Theexperimental results demonstrate the effectiveness of LaDeCo in designcomposition. Furthermore, we show that LaDeCo enables some interestingapplications in graphic design, such as resolution adjustment, element filling,design variation, etc. In addition, it even outperforms the specialized modelsin some design subtasks without any task-specific training.</description><author>Jiawei Lin, Shizhao Sun, Danqing Huang, Ting Liu, Ji Li, Jiang Bian</author><pubDate>Fri, 27 Dec 2024 16:13:08 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.19712v1</guid></item><item><title>Causal machine learning for heterogeneous treatment effects in the presence of missing outcome data</title><link>http://arxiv.org/abs/2412.19711v1</link><description>When estimating heterogeneous treatment effects, missing outcome data cancomplicate treatment effect estimation, causing certain subgroups of thepopulation to be poorly represented. In this work, we discuss this commonlyoverlooked problem and consider the impact that missing at random (MAR) outcomedata has on causal machine learning estimators for the conditional averagetreatment effect (CATE). We then propose two de-biased machine learningestimators for the CATE, the mDR-learner and mEP-learner, which address theissue of under-representation by integrating inverse probability of censoringweights into the DR-learner and EP-learner respectively. We show that underreasonable conditions, these estimators are oracle efficient, and illustratetheir favorable performance through simulated data settings, comparing them toexisting CATE estimators, including comparison to estimators which use commonmissing data techniques. Guidance on the implementation of these estimators isprovided and we present an example of their application using the ACTG175trial, exploring treatment effect heterogeneity when comparing Zidovudinemono-therapy against alternative antiretroviral therapies among HIV-1-infectedindividuals.</description><author>Matthew Pryce, Karla Diaz-Ordaz, Ruth H. Keogh, Stijn Vansteelandt</author><pubDate>Fri, 27 Dec 2024 16:10:03 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.19711v1</guid></item><item><title>Toward Adaptive Reasoning in Large Language Models with Thought Rollback</title><link>http://arxiv.org/abs/2412.19707v1</link><description>Large language models (LLMs) have been routinely used to solve various tasksusing step-by-step reasoning. However, the structure of intermediate reasoningsteps, or thoughts, is rigid and unidirectional, such as chains, trees, oracyclic-directed graphs. Consequently, the resulting inflexible andforward-only reasoning may not address challenging tasks and fail when the LLMfrequently gives false responses, i.e., ``hallucinations''. This paper proposesa new reasoning framework, called Thought Rollback (TR), allowing LLMs toadaptively build thought structure while maintaining effective reasoning towardproblem-solving under ``hallucinations''. The core mechanism of TR is rollingback thoughts, which allows LLMs to perform error analysis on thoughts, andthus roll back to any previously mistaken thought for revision. Subsequently,by including such trial-and-error in the prompt to guide the LLM, each rollbackleads to one more reliable reasoning path. Therefore, starting with a simpleprompt without human annotations, LLM with TR adaptively and gradually exploresthoughts for a correct solution. Comprehensive experiments on mathematicalproblems and multi-task reasoning demonstrate the state-of-the-art performanceof TR in terms of problem-solving rate and interaction cost. For instance, thesolving rate of GPT-4 with TR outperforms the current best by $9\%$ on the MATHdataset.</description><author>Sijia Chen, Baochun Li</author><pubDate>Fri, 27 Dec 2024 16:02:34 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.19707v1</guid></item><item><title>An Integrated Optimization and Deep Learning Pipeline for Predicting Live Birth Success in IVF Using Feature Optimization and Transformer-Based Models</title><link>http://arxiv.org/abs/2412.19696v1</link><description>In vitro fertilization (IVF) is a widely utilized assisted reproductivetechnology, yet predicting its success remains challenging due to themultifaceted interplay of clinical, demographic, and procedural factors. Thisstudy develops a robust artificial intelligence (AI) pipeline aimed atpredicting live birth outcomes in IVF treatments. The pipeline uses anonymizeddata from 2010 to 2018, obtained from the Human Fertilization and EmbryologyAuthority (HFEA). We evaluated the prediction performance of live birth successas a binary outcome (success/failure) by integrating different featureselection methods, such as principal component analysis (PCA) and particleswarm optimization (PSO), with different traditional machine learning-basedclassifiers including random forest (RF) and decision tree, as well as deeplearning-based classifiers including custom transformer-based model and a tabtransformer model with an attention mechanism. Our research demonstrated thatthe best performance was achieved by combining PSO for feature selection withthe TabTransformer-based deep learning model, yielding an accuracy of 99.50%and an AUC of 99.96%, highlighting its significant performance to predict livebirths. This study establishes a highly accurate AI pipeline for predictinglive birth outcomes in IVF, demonstrating its potential to enhance personalizedfertility treatments.</description><author>Arezoo Borji, Hossam Haick, Birgit Pohn, Antonia Graf, Jana Zakall, S M Ragib Shahriar Islam, Gernot Kronreif, Daniel Kovatchki, Heinz Strohmer, Sepideh Hatamikia</author><pubDate>Fri, 27 Dec 2024 15:46:59 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.19696v1</guid></item><item><title>Context-aware Inductive Knowledge Graph Completion with Latent Type Constraints and Subgraph Reasoning</title><link>http://arxiv.org/abs/2410.16803v3</link><description>Inductive knowledge graph completion (KGC) aims to predict missing tripleswith unseen entities. Recent works focus on modeling reasoning paths betweenthe head and tail entity as direct supporting evidence. However, these methodsdepend heavily on the existence and quality of reasoning paths, which limitstheir general applicability in different scenarios. In addition, we observethat latent type constraints and neighboring facts inherent in KGs are alsovital in inferring missing triples. To effectively utilize all usefulinformation in KGs, we introduce CATS, a novel context-aware inductive KGCsolution. With sufficient guidance from proper prompts and supervisedfine-tuning, CATS activates the strong semantic understanding and reasoningcapabilities of large language models to assess the existence of query triples,which consist of two modules. First, the type-aware reasoning module evaluateswhether the candidate entity matches the latent entity type as required by thequery relation. Then, the subgraph reasoning module selects relevant reasoningpaths and neighboring facts, and evaluates their correlation to the querytriple. Experiment results on three widely used datasets demonstrate that CATSsignificantly outperforms state-of-the-art methods in 16 out of 18transductive, inductive, and few-shot settings with an average absolute MRRimprovement of 7.2%.</description><author>Muzhi Li, Cehao Yang, Chengjin Xu, Zixing Song, Xuhui Jiang, Jian Guo, Ho-fung Leung, Irwin King</author><pubDate>Fri, 27 Dec 2024 15:32:01 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.16803v3</guid></item><item><title>A Review on the Integration of Artificial Intelligence and Medical Imaging in IVF Ovarian Stimulation</title><link>http://arxiv.org/abs/2412.19688v1</link><description>Artificial intelligence (AI) has emerged as a powerful tool to enhancedecision-making and optimize treatment protocols in in vitro fertilization(IVF). In particular, AI shows significant promise in supportingdecision-making during the ovarian stimulation phase of the IVF process. Thisreview evaluates studies focused on the applications of AI combined withmedical imaging in ovarian stimulation, examining methodologies, outcomes, andcurrent limitations. Our analysis of 13 studies on this topic reveals that,reveal that while AI algorithms demonstrated notable potential in predictingoptimal hormonal dosages, trigger timing, and oocyte retrieval outcomes, themedical imaging data utilized predominantly came from two-dimensional (2D)ultrasound which mainly involved basic quantifications, such as follicle sizeand number, with limited use of direct feature extraction or advanced imageanalysis techniques. This points to an underexplored opportunity where advancedimage analysis approaches, such as deep learning, and more diverse imagingmodalities, like three-dimensional (3D) ultrasound, could unlock deeperinsights. Additionally, the lack of explainable AI (XAI) in most studies raisesconcerns about the transparency and traceability of AI-driven decisions - keyfactors for clinical adoption and trust. Furthermore, many studies relied onsingle-center designs and small datasets, which limit the generalizability oftheir findings. This review highlights the need for integrating advancedimaging analysis techniques with explainable AI methodologies, as well as theimportance of leveraging multicenter collaborations and larger datasets.Addressing these gaps has the potential to enhance ovarian stimulationmanagement, paving the way for efficient, personalized, and data-driventreatment pathways that improve IVF outcomes.</description><author>Jana Zakall, Birgit Pohn, Antonia Graf, Daniel Kovatchki, Arezoo Borji, Ragib Shahriar Islam, Hossam Haick, Heinz Strohmer, Sepideh Hatamikia</author><pubDate>Fri, 27 Dec 2024 15:29:08 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.19688v1</guid></item><item><title>A Large-scale Interpretable Multi-modality Benchmark for Facial Image Forgery Localization</title><link>http://arxiv.org/abs/2412.19685v1</link><description>Image forgery localization, which centers on identifying tampered pixelswithin an image, has seen significant advancements. Traditional approachesoften model this challenge as a variant of image segmentation, treating thebinary segmentation of forged areas as the end product. We argue that the basicbinary forgery mask is inadequate for explaining model predictions. It doesn'tclarify why the model pinpoints certain areas and treats all forged pixels thesame, making it hard to spot the most fake-looking parts. In this study, wemitigate the aforementioned limitations by generating salient region-focusedinterpretation for the forgery images. To support this, we craft a Multi-ModalTramper Tracing (MMTT) dataset, comprising facial images manipulated usingdeepfake techniques and paired with manual, interpretable textual annotations.To harvest high-quality annotation, annotators are instructed to meticulouslyobserve the manipulated images and articulate the typical characteristics ofthe forgery regions. Subsequently, we collect a dataset of 128,303 image-textpairs. Leveraging the MMTT dataset, we develop ForgeryTalker, an architecturedesigned for concurrent forgery localization and interpretation. ForgeryTalkerfirst trains a forgery prompter network to identify the pivotal clues withinthe explanatory text. Subsequently, the region prompter is incorporated intomultimodal large language model for finetuning to achieve the dual goals oflocalization and interpretation. Extensive experiments conducted on the MMTTdataset verify the superior performance of our proposed model. The dataset,code as well as pretrained checkpoints will be made publicly available tofacilitate further research and ensure the reproducibility of our results.</description><author>Jingchun Lian, Lingyu Liu, Yaxiong Wang, Yujiao Wu, Li Zhu, Zhedong Zheng</author><pubDate>Fri, 27 Dec 2024 15:23:39 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.19685v1</guid></item><item><title>Boosting Private Domain Understanding of Efficient MLLMs: A Tuning-free, Adaptive, Universal Prompt Optimization Framework</title><link>http://arxiv.org/abs/2412.19684v1</link><description>Efficient multimodal large language models (EMLLMs), in contrast tomultimodal large language models (MLLMs), reduce model size and computationalcosts and are often deployed on resource-constrained devices. However, due todata privacy concerns, existing open-source EMLLMs rarely have access toprivate domain-specific data during the pre-training process, making themdifficult to directly apply in device-specific domains, such as certainbusiness scenarios. To address this weakness, this paper focuses on theefficient adaptation of EMLLMs to private domains, specifically in two areas:1) how to reduce data requirements, and 2) how to avoid parameter fine-tuning.Specifically, we propose a tun\textbf{\underline{I}}ng-free,a\textbf{\underline{D}}aptiv\textbf{\underline{E}},univers\textbf{\underline{AL}} \textbf{\underline{Prompt}} OptimizationFramework, abbreviated as \textit{\textbf{\ourmethod{}}} which consists of twostages: 1) Predefined Prompt, based on the reinforcement searching strategy,generate a prompt optimization strategy tree to acquire optimization priors; 2)Prompt Reflection initializes the prompt based on optimization priors, followedby self-reflection to further search and refine the prompt. By doing so,\ourmethod{} elegantly generates the ``ideal prompts'' for processing privatedomain-specific data. Note that our method requires no parameter fine-tuningand only a small amount of data to quickly adapt to the data distribution ofprivate data. Extensive experiments across multiple tasks demonstrate that ourproposed \ourmethod{} significantly improves both efficiency and performancecompared to baselines.</description><author>Jiang Liu, Bolin Li, Haoyuan Li, Tianwei Lin, Wenqiao Zhang, Tao Zhong, Zhelun Yu, Jinghao Wei, Hao Cheng, Hao Jiang, Zheqi Lv, Juncheng Li, Siliang Tang, Yueting Zhuang</author><pubDate>Fri, 27 Dec 2024 15:21:17 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.19684v1</guid></item><item><title>Combining Machine Learning with Recurrence Analysis for resonance detection</title><link>http://arxiv.org/abs/2412.19683v1</link><description>The width of a resonance in a nearly integrable system, i.e. in anon-integrable system where chaotic motion is still not prominent, can tell ushow a perturbation parameter is driving the system away from integrability.Although the tool that we are presenting here can be used is quite generic andcan be used in a variety of systems, our particular interest lies in binarycompact object systems known as extreme mass ratio inspirals (EMRIs). In anEMRI a lighter compact object, like a black hole or a neutron star, inspiralsinto a supermassive black hole due to gravitational radiation reaction. Duringthis inspiral the lighter object crosses resonances, which are still not verywell modeled. Measuring the width of resonances in EMRI models allows us toestimate the importance of each perturbation parameter able to drive the systemaway from resonances and decide whether its impact should be included in EMRIwaveform modeling or not. To tackle this issue in our study we show first thatrecurrence quantifiers of orbits carry imprints of resonant behavior,regardless of the system's dimensionality. As a next step, we apply a longshort-term memory machine learning architecture to automate the resonancedetection procedure. Our analysis is developed on a simple standard map andgradually we extend it to more complicated systems until finally we employ itin a generic deformed Kerr spacetime known in the literature as theJohannsen-Psaltis spacetime.</description><author>Ondřej Zelenka, Ondřej Kopáček, Georgios Lukes-Gerakopoulos</author><pubDate>Fri, 27 Dec 2024 15:20:57 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.19683v1</guid></item><item><title>A Hybrid Technique for Plant Disease Identification and Localisation in Real-time</title><link>http://arxiv.org/abs/2412.19682v1</link><description>Over the past decade, several image-processing methods and algorithms havebeen proposed for identifying plant diseases based on visual data. DNN (DeepNeural Networks) have recently become popular for this task. Both traditionalimage processing and DNN-based methods encounter significant performance issuesin real-time detection owing to computational limitations and a broad spectrumof plant disease features. This article proposes a novel technique foridentifying and localising plant disease based on the Quad-Tree decompositionof an image and feature learning simultaneously. The proposed algorithmsignificantly improves accuracy and faster convergence in high-resolutionimages with relatively low computational load. Hence it is ideal for deployingthe algorithm in a standalone processor in a remotely operated imageacquisition and disease detection system, ideally mounted on drones and robotsworking on large agricultural fields. The technique proposed in this article ishybrid as it exploits the advantages of traditional image processing methodsand DNN-based models at different scales, resulting in faster inference. The F1score is approximately 0.80 for four disease classes corresponding to potatoand tomato crops.</description><author>Mahendra Kumar Gohil, Anirudha Bhattacharjee, Rwik Rana, Kishan Lal, Samir Kumar Biswas, Nachiketa Tiwari, Bishakh Bhattacharya</author><pubDate>Fri, 27 Dec 2024 15:20:45 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.19682v1</guid></item><item><title>Deep ReLU networks -- injectivity capacity upper bounds</title><link>http://arxiv.org/abs/2412.19677v1</link><description>We study deep ReLU feed forward neural networks (NN) and their injectivityabilities. The main focus is on \emph{precisely} determining the so-calledinjectivity capacity. For any given hidden layers architecture, it is definedas the minimal ratio between number of network's outputs and inputs whichensures unique recoverability of the input from a realizable output. A strongrecent progress in precisely studying single ReLU layer injectivity propertiesis here moved to a deep network level. In particular, we develop a program thatconnects deep $l$-layer net injectivity to an $l$-extension of the $\ell_0$spherical perceptrons, thereby massively generalizing an isomorphism betweenstudying single layer injectivity and the capacity of the so-called(1-extension) $\ell_0$ spherical perceptrons discussed in [82]. \emph{Randomduality theory} (RDT) based machinery is then created and utilized tostatistically handle properties of the extended $\ell_0$ spherical perceptronsand implicitly of the deep ReLU NNs. A sizeable set of numerical evaluations isconducted as well to put the entire RDT machinery in practical use. From thesewe observe a rapidly decreasing tendency in needed layers' expansions, i.e., weobserve a rapid \emph{expansion saturation effect}. Only $4$ layers of depthare sufficient to closely approach level of no needed expansion -- a resultthat fairly closely resembles observations made in practical experiments andthat has so far remained completely untouchable by any of the existingmathematical methodologies.</description><author>Mihailo Stojnic</author><pubDate>Fri, 27 Dec 2024 14:57:40 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.19677v1</guid></item><item><title>Intertwining CP and NLP: The Generation of Unreasonably Constrained Sentences</title><link>http://arxiv.org/abs/2406.15473v2</link><description>Constrained text generation remains a challenging task, particularly whendealing with hard constraints. Traditional NLP approaches prioritize generatingmeaningful and coherent output. Also, the current state-of-the-art methodsoften lack the expressiveness and constraint satisfaction capabilities tohandle such tasks effectively. Recently, an approach for generating constrainedsentences in CP has been proposed in (Bonlarron et al, 2023). This ad-hoc modelto solve the sentences generation problem under MNREAD rules provedneithertheless to be computationaly and structuraly unsuitable to deal withother more constrained problems. In this paper, a novel more generic approachis introduced to tackle many of these previously untractable problems, andillustrated here with the quite untractable sentences generation problemfollowing RADNER rules. More precisely, this paper presents the CPTextGen Framework. This frameworkconsiders a constrained text generation problem as a discrete combinatorialoptimization problem. It is solved by a constraint programming method thatcombines linguistic properties (e.g., n-grams or language level) with othermore classical constraints (e.g., the number of characters, syllables).Eventually, a curation phase allows for selecting the best-generated sentencesaccording to perplexity using an LLM. The effectiveness of this approach is demonstrated by tackling a new, moretediously constrained text generation problem: the iconic RADNER sentencesproblem. This problem aims to generate sentences respecting a set of quitestrict rules defined by their use in vision and clinical research. Thanks toour CP-based approach, many new strongly constrained sentences have beensuccessfully generated. This highlights our approach's potential to handleunreasonably constrained text generation scenarios.</description><author>Alexandre Bonlarron, Jean-Charles Régin</author><pubDate>Fri, 27 Dec 2024 14:56:10 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.15473v2</guid></item><item><title>Optimizing Local-Global Dependencies for Accurate 3D Human Pose Estimation</title><link>http://arxiv.org/abs/2412.19676v1</link><description>Transformer-based methods have recently achieved significant success in 3Dhuman pose estimation, owing to their strong ability to model long-rangedependencies. However, relying solely on the global attention mechanism isinsufficient for capturing the fine-grained local details, which are crucialfor accurate pose estimation. To address this, we propose SSR-STF, adual-stream model that effectively integrates local features with globaldependencies to enhance 3D human pose estimation. Specifically, we introduceSSRFormer, a simple yet effective module that employs the skeleton selectiverefine attention (SSRA) mechanism to capture fine-grained local dependencies inhuman pose sequences, complementing the global dependencies modeled by theTransformer. By adaptively fusing these two feature streams, SSR-STF can betterlearn the underlying structure of human poses, overcoming the limitations oftraditional methods in local feature extraction. Extensive experiments on theHuman3.6M and MPI-INF-3DHP datasets demonstrate that SSR-STF achievesstate-of-the-art performance, with P1 errors of 37.4 mm and 13.2 mmrespectively, outperforming existing methods in both accuracy andgeneralization. Furthermore, the motion representations learned by our modelprove effective in downstream tasks such as human mesh recovery. Codes areavailable at https://github.com/poker-xu/SSR-STF.</description><author>Guangsheng Xu, Guoyi Zhang, Lejia Ye, Shuwei Gan, Xiaohu Zhang, Xia Yang</author><pubDate>Fri, 27 Dec 2024 14:54:12 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.19676v1</guid></item><item><title>DLScanner: A parameter space scanner package assisted by deep learning methods</title><link>http://arxiv.org/abs/2412.19675v1</link><description>In this paper, we introduce a scanner package enhanced by deep learning (DL)techniques. The proposed package addresses two significant challengesassociated with previously developed DL-based methods: slow convergence inhigh-dimensional scans and the limited generalization of the DL network whenmapping random points to the target space. To tackle the first issue, weutilize a similarity learning network that maps sampled points into arepresentation space. In this space, in-target points are grouped togetherwhile out-target points are effectively pushed apart. This approach enhancesthe scan convergence by refining the representation of sampled points. Thesecond challenge is mitigated by integrating a dynamic sampling strategy.Specifically, we employ a VEGAS mapping to adaptively suggest new points forthe DL network while also improving the mapping when more points are collected.Our proposed framework demonstrates substantial gains in both performance andefficiency compared to other scanning methods.</description><author>A. Hammad, Raymundo Ramos</author><pubDate>Fri, 27 Dec 2024 14:52:42 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.19675v1</guid></item><item><title>Sustainable Diffusion-based Incentive Mechanism for Generative AI-driven Digital Twins in Industrial Cyber-Physical Systems</title><link>http://arxiv.org/abs/2408.01173v2</link><description>Industrial Cyber-Physical Systems (ICPSs) are an integral component of modernmanufacturing and industries. By digitizing data throughout product lifecycles, Digital Twins (DTs) in ICPSs enable a shift from current industrialinfrastructures to intelligent and adaptive infrastructures. Thanks to dataprocess capability, Generative Artificial Intelligence (GenAI) can drive theconstruction and update of DTs to improve predictive accuracy and prepare fordiverse smart manufacturing. However, mechanisms that leverage IndustrialInternet of Things (IIoT) devices to share sensing data for DT construction aresusceptible to adverse selection problems. In this paper, we first develop aGenAI-driven DT architecture in ICPSs. To address the adverse selection problemcaused by information asymmetry, we propose a contract theory model and developa sustainable diffusion-based soft actor-critic algorithm to identify theoptimal feasible contract. Specifically, we leverage dynamic structured pruningtechniques to reduce parameter numbers of actor networks, allowingsustainability and efficient implementation of the proposed algorithm.Numerical results demonstrate the effectiveness of the proposed scheme and thealgorithm, enabling efficient DT construction and updates to monitor and manageICPSs.</description><author>Jinbo Wen, Jiawen Kang, Dusit Niyato, Yang Zhang, Shiwen Mao</author><pubDate>Fri, 27 Dec 2024 14:46:55 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.01173v2</guid></item><item><title>Lusifer: LLM-based User SImulated Feedback Environment for online Recommender systems</title><link>http://arxiv.org/abs/2405.13362v3</link><description>Training reinforcement learning-based recommender systems is often hinderedby the lack of dynamic and realistic user interactions. To address thislimitation, we introduce Lusifer, a novel environment leveraging Large LanguageModels (LLMs) to generate simulated user feedback. Lusifer synthesizes userprofiles and interaction histories to simulate responses and behaviors towardrecommended items, with profiles updated after each rating to reflect evolvinguser characteristics. Utilizing the MovieLens dataset as a proof of concept, welimited our implementation to the last 40 interactions for each user,representing approximately 39% and 22% of the training sets, to focus on recentuser behavior. For consistency and to gain insights into the performance oftraditional methods with limited data, we implemented baseline approaches usingthe same data subset. Our results demonstrate that Lusifer accurately emulatesuser behavior and preferences, even with reduced training data having an RMSEof 1.3 across various test sets. This paper presents Lusifer's operationalpipeline, including prompt generation and iterative user profile updates, andcompares its performance against baseline methods. The findings validateLusifer's ability to produce realistic dynamic feedback and suggest that itoffers a scalable and adjustable framework for user simulation in onlinereinforcement learning recommender systems for future studies, particularlywhen training data is limited.</description><author>Danial Ebrat, Eli Paradalis, Luis Rueda</author><pubDate>Fri, 27 Dec 2024 14:44:30 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.13362v3</guid></item><item><title>Toward Scalable Multirobot Control: Fast Policy Learning in Distributed MPC</title><link>http://arxiv.org/abs/2412.19669v1</link><description>Distributed model predictive control (DMPC) is promising in achieving optimalcooperative control in multirobot systems (MRS). However, real-time DMPCimplementation relies on numerical optimization tools to periodically calculatelocal control sequences online. This process is computationally demanding andlacks scalability for large-scale, nonlinear MRS. This article proposes a noveldistributed learning-based predictive control (DLPC) framework for scalablemultirobot control. Unlike conventional DMPC methods that calculate open-loopcontrol sequences, our approach centers around a computationally fast andefficient distributed policy learning algorithm that generates explicitclosed-loop DMPC policies for MRS without using numerical solvers. The policylearning is executed incrementally and forward in time in each predictioninterval through an online distributed actor-critic implementation. The controlpolicies are successively updated in a receding-horizon manner, enabling fastand efficient policy learning with the closed-loop stability guarantee. Thelearned control policies could be deployed online to MRS with varying robotscales, enhancing scalability and transferability for large-scale MRS.Furthermore, we extend our methodology to address the multirobot safe learningchallenge through a force field-inspired policy learning approach. We validateour approach's effectiveness, scalability, and efficiency through extensiveexperiments on cooperative tasks of large-scale wheeled robots and multirotordrones. Our results demonstrate the rapid learning and deployment of DMPCpolicies for MRS with scales up to 10,000 units.</description><author>Xinglong Zhang, Wei Pan, Cong Li, Xin Xu, Xiangke Wang, Ronghua Zhang, Dewen Hu</author><pubDate>Fri, 27 Dec 2024 14:31:52 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.19669v1</guid></item><item><title>Baichuan-Omni Technical Report</title><link>http://arxiv.org/abs/2410.08565v4</link><description>The salient multimodal capabilities and interactive experience of GPT-4ohighlight its critical role in practical applications, yet it lacks ahigh-performing open-source counterpart. In this paper, we introduceBaichuan-omni, the first open-source 7B Multimodal Large Language Model (MLLM)adept at concurrently processing and analyzing modalities of image, video,audio, and text, while delivering an advanced multimodal interactive experienceand strong performance. We propose an effective multimodal training schemastarting with 7B model and proceeding through two stages of multimodalalignment and multitask fine-tuning across audio, image, video, and text modal.This approach equips the language model with the ability to handle visual andaudio data effectively. Demonstrating strong performance across variousomni-modal and multimodal benchmarks, we aim for this contribution to serve asa competitive baseline for the open-source community in advancing multimodalunderstanding and real-time interaction.</description><author>Yadong Li, Haoze Sun, Mingan Lin, Tianpeng Li, Guosheng Dong, Tao Zhang, Bowen Ding, Wei Song, Zhenglin Cheng, Yuqi Huo, Song Chen, Xu Li, Da Pan, Shusen Zhang, Xin Wu, Zheng Liang, Jun Liu, Tao Zhang, Keer Lu, Yaqi Zhao, Yanjun Shen, Fan Yang, Kaicheng Yu, Tao Lin, Jianhua Xu, Zenan Zhou, Weipeng Chen</author><pubDate>Fri, 27 Dec 2024 14:19:55 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.08565v4</guid></item><item><title>CAD-GPT: Synthesising CAD Construction Sequence with Spatial Reasoning-Enhanced Multimodal LLMs</title><link>http://arxiv.org/abs/2412.19663v1</link><description>Computer-aided design (CAD) significantly enhances the efficiency, accuracy,and innovation of design processes by enabling precise 2D and 3D modeling,extensive analysis, and optimization. Existing methods for creating CAD modelsrely on latent vectors or point clouds, which are difficult to obtain andcostly to store. Recent advances in Multimodal Large Language Models (MLLMs)have inspired researchers to use natural language instructions and images forCAD model construction. However, these models still struggle with inferringaccurate 3D spatial location and orientation, leading to inaccuracies indetermining the spatial 3D starting points and extrusion directions forconstructing geometries. This work introduces CAD-GPT, a CAD synthesis methodwith spatial reasoning-enhanced MLLM that takes either a single image or atextual description as input. To achieve precise spatial inference, ourapproach introduces a 3D Modeling Spatial Mechanism. This method maps 3Dspatial positions and 3D sketch plane rotation angles into a 1D linguisticfeature space using a specialized spatial unfolding mechanism, whilediscretizing 2D sketch coordinates into an appropriate planar space to enableprecise determination of spatial starting position, sketch orientation, and 2Dsketch coordinate translations. Extensive experiments demonstrate that CAD-GPTconsistently outperforms existing state-of-the-art methods in CAD modelsynthesis, both quantitatively and qualitatively.</description><author>Siyu Wang, Cailian Chen, Xinyi Le, Qimin Xu, Lei Xu, Yanzhou Zhang, Jie Yang</author><pubDate>Fri, 27 Dec 2024 14:19:36 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.19663v1</guid></item><item><title>Preemptive Detection and Correction of Misaligned Actions in LLM Agents</title><link>http://arxiv.org/abs/2407.11843v3</link><description>Deploying LLM-based agents in real-life applications often faces a criticalchallenge: the misalignment between agents' behavior and user intent. Suchmisalignment may lead agents to unintentionally execute critical actions thatcarry negative outcomes (e.g., accidentally triggering a "buy-now" in webshopping), resulting in undesirable or even irreversible consequences. Althoughaddressing these issues is crucial, the preemptive detection and correction ofmisaligned actions remains relatively underexplored. To fill this gap, weintroduce InferAct, a novel approach that leverages the belief reasoningability of LLMs, grounded in Theory-of-Mind, to detect misaligned actionsbefore execution. Once the misalignment is detected, InferAct alerts users fortimely correction, preventing adverse outcomes and enhancing the reliability ofLLM agents' decision-making processes. Experiments on three widely used tasksdemonstrate that InferAct achieves up to 20% improvements on Marco-F1 againstbaselines in misaligned action detection. An in-depth evaluation ofmisalignment correction further highlights InferAct's effectiveness inimproving agent alignment.</description><author>Haishuo Fang, Xiaodan Zhu, Iryna Gurevych</author><pubDate>Fri, 27 Dec 2024 14:17:05 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.11843v3</guid></item><item><title>Non-separable Spatio-temporal Graph Kernels via SPDEs</title><link>http://arxiv.org/abs/2111.08524v3</link><description>Gaussian processes (GPs) provide a principled and direct approach forinference and learning on graphs. However, the lack of justified graph kernelsfor spatio-temporal modelling has held back their use in graph problems. Weleverage an explicit link between stochastic partial differential equations(SPDEs) and GPs on graphs, introduce a framework for deriving graph kernels viaSPDEs, and derive non-separable spatio-temporal graph kernels that captureinteraction across space and time. We formulate the graph kernels for thestochastic heat equation and wave equation. We show that by providing noveltools for spatio-temporal GP modelling on graphs, we outperform pre-existinggraph kernels in real-world applications that feature diffusion, oscillation,and other complicated interactions.</description><author>Alexander Nikitin, ST John, Arno Solin, Samuel Kaski</author><pubDate>Fri, 27 Dec 2024 14:08:01 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2111.08524v3</guid></item><item><title>Asymmetrical Reciprocity-based Federated Learning for Resolving Disparities in Medical Diagnosis</title><link>http://arxiv.org/abs/2412.19654v1</link><description>Geographic health disparities pose a pressing global challenge, particularlyin underserved regions of low- and middle-income nations. Addressing this issuerequires a collaborative approach to enhance healthcare quality, leveragingsupport from medically more developed areas. Federated learning emerges as apromising tool for this purpose. However, the scarcity of medical data andlimited computation resources in underserved regions make collaborativetraining of powerful machine learning models challenging. Furthermore, thereexists an asymmetrical reciprocity between underserved and developed regions.To overcome these challenges, we propose a novel cross-silo federated learningframework, named FedHelp, aimed at alleviating geographic health disparitiesand fortifying the diagnostic capabilities of underserved regions.Specifically, FedHelp leverages foundational model knowledge via one-time APIaccess to guide the learning process of underserved small clients, addressingthe challenge of insufficient data. Additionally, we introduce a novelasymmetric dual knowledge distillation module to manage the issue of asymmetricreciprocity, facilitating the exchange of necessary knowledge between developedlarge clients and underserved small clients. We validate the effectiveness andutility of FedHelp through extensive experiments on both medical imageclassification and segmentation tasks. The experimental results demonstratesignificant performance improvement compared to state-of-the-art baselines,particularly benefiting clients in underserved regions.</description><author>Jiaqi Wang, Ziyi Yin, Quanzeng You, Lingjuan Lyu, Fenglong Ma</author><pubDate>Fri, 27 Dec 2024 13:59:58 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.19654v1</guid></item><item><title>CustomCrafter: Customized Video Generation with Preserving Motion and Concept Composition Abilities</title><link>http://arxiv.org/abs/2408.13239v2</link><description>Customized video generation aims to generate high-quality videos guided bytext prompts and subject's reference images. However, since it is only trainedon static images, the fine-tuning process of subject learning disruptsabilities of video diffusion models (VDMs) to combine concepts and generatemotions. To restore these abilities, some methods use additional video similarto the prompt to fine-tune or guide the model. This requires frequent changesof guiding videos and even re-tuning of the model when generating differentmotions, which is very inconvenient for users. In this paper, we proposeCustomCrafter, a novel framework that preserves the model's motion generationand conceptual combination abilities without additional video and fine-tuningto recovery. For preserving conceptual combination ability, we design aplug-and-play module to update few parameters in VDMs, enhancing the model'sability to capture the appearance details and the ability of conceptcombinations for new subjects. For motion generation, we observed that VDMstend to restore the motion of video in the early stage of denoising, whilefocusing on the recovery of subject details in the later stage. Therefore, wepropose Dynamic Weighted Video Sampling Strategy. Using the pluggability of oursubject learning modules, we reduce the impact of this module on motiongeneration in the early stage of denoising, preserving the ability to generatemotion of VDMs. In the later stage of denoising, we restore this module torepair the appearance details of the specified subject, thereby ensuring thefidelity of the subject's appearance. Experimental results show that our methodhas a significant improvement compared to previous methods. Code is availableat https://github.com/WuTao-CS/CustomCrafter</description><author>Tao Wu, Yong Zhang, Xintao Wang, Xianpan Zhou, Guangcong Zheng, Zhongang Qi, Ying Shan, Xi Li</author><pubDate>Fri, 27 Dec 2024 13:58:39 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.13239v2</guid></item><item><title>Toward Modality Gap: Vision Prototype Learning for Weakly-supervised Semantic Segmentation with CLIP</title><link>http://arxiv.org/abs/2412.19650v1</link><description>The application of Contrastive Language-Image Pre-training (CLIP) in WeaklySupervised Semantic Segmentation (WSSS) research powerful cross-modal semanticunderstanding capabilities. Existing methods attempt to optimize input textprompts for improved alignment of images and text, by finely adjusting textprototypes to facilitate semantic matching. Nevertheless, given the modalitygap between text and vision spaces, the text prototypes employed by thesemethods have not effectively established a close correspondence withpixel-level vision features. In this work, our theoretical analysis indicatesthat the inherent modality gap results in misalignment of text and regionfeatures, and that this gap cannot be sufficiently reduced by minimizingcontrast loss in CLIP. To mitigate the impact of the modality gap, we propose aVision Prototype Learning (VPL) framework, by introducing more representativevision prototypes. The core of this framework is to learn class-specific visionprototypes in vision space with the help of text prototypes, for capturinghigh-quality localization maps. Moreover, we propose a regional semanticcontrast module that contrasts regions embedding with corresponding prototypes,leading to more comprehensive and robust feature learning. Experimental resultsshow that our proposed framework achieves state-of-the-art performance on twobenchmark datasets.</description><author>Zhongxing Xu, Feilong Tang, Zhe Chen, Yingxue Su, Zhiyi Zhao, Ge Zhang, Jionglong Su, Zongyuan Ge</author><pubDate>Fri, 27 Dec 2024 13:55:11 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.19650v1</guid></item><item><title>Enhancing Vision-Language Tracking by Effectively Converting Textual Cues into Visual Cues</title><link>http://arxiv.org/abs/2412.19648v1</link><description>Vision-Language Tracking (VLT) aims to localize a target in video sequencesusing a visual template and language description. While textual cues enhancetracking potential, current datasets typically contain much more image datathan text, limiting the ability of VLT methods to align the two modalitieseffectively. To address this imbalance, we propose a novel plug-and-play methodnamed CTVLT that leverages the strong text-image alignment capabilities offoundation grounding models. CTVLT converts textual cues into interpretablevisual heatmaps, which are easier for trackers to process. Specifically, wedesign a textual cue mapping module that transforms textual cues into targetdistribution heatmaps, visually representing the location described by thetext. Additionally, the heatmap guidance module fuses these heatmaps with thesearch image to guide tracking more effectively. Extensive experiments onmainstream benchmarks demonstrate the effectiveness of our approach, achievingstate-of-the-art performance and validating the utility of our method forenhanced VLT.</description><author>X. Feng, D. Zhang, S. Hu, X. Li, M. Wu, J. Zhang, X. Chen, K. Huang</author><pubDate>Fri, 27 Dec 2024 13:54:32 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.19648v1</guid></item><item><title>Evaluating Software Development Agents: Patch Patterns, Code Quality, and Issue Complexity in Real-World GitHub Scenarios</title><link>http://arxiv.org/abs/2410.12468v2</link><description>In recent years, AI-based software engineering has progressed frompre-trained models to advanced agentic workflows, with Software DevelopmentAgents representing the next major leap. These agents, capable of reasoning,planning, and interacting with external environments, offer promising solutionsto complex software engineering tasks. However, while much research hasevaluated code generated by large language models (LLMs), comprehensive studieson agent-generated patches, particularly in real-world settings, are lacking.This study addresses that gap by evaluating 4,892 patches from 10 top-rankedagents on 500 real-world GitHub issues from SWE-Bench Verified, focusing ontheir impact on code quality. Our analysis shows no single agent dominated,with 170 issues unresolved, indicating room for improvement. Even for patchesthat passed unit tests and resolved issues, agents made different file andfunction modifications compared to the gold patches from repository developers,revealing limitations in the benchmark's test case coverage. Most agentsmaintained code reliability and security, avoiding new bugs or vulnerabilities;while some agents increased code complexity, many reduced code duplication andminimized code smells. Finally, agents performed better on simpler codebases,suggesting that breaking complex tasks into smaller sub-tasks could improveeffectiveness. This study provides the first comprehensive evaluation ofagent-generated patches on real-world GitHub issues, offering insights toadvance AI-driven software development.</description><author>Zhi Chen, Lingxiao Jiang</author><pubDate>Fri, 27 Dec 2024 13:52:05 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.12468v2</guid></item><item><title>Chimera: A Block-Based Neural Architecture Search Framework for Event-Based Object Detection</title><link>http://arxiv.org/abs/2412.19646v1</link><description>Event-based cameras are sensors that simulate the human eye, offeringadvantages such as high-speed robustness and low power consumption. EstablishedDeep Learning techniques have shown effectiveness in processing event data.Chimera is a Block-Based Neural Architecture Search (NAS) frameworkspecifically designed for Event-Based Object Detection, aiming to create asystematic approach for adapting RGB-domain processing methods to the eventdomain. The Chimera design space is constructed from various macroblocks,including Attention blocks, Convolutions, State Space Models, andMLP-mixer-based architectures, which provide a valuable trade-off between localand global processing capabilities, as well as varying levels of complexity.The results on the PErson Detection in Robotics (PEDRo) dataset demonstratedperformance levels comparable to leading state-of-the-art models, alongside anaverage parameter reduction of 1.6 times.</description><author>Diego A. Silva, Ahmed Elsheikh, Kamilya Smagulova, Mohammed E. Fouda, Ahmed M. Eltawil</author><pubDate>Fri, 27 Dec 2024 13:50:44 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.19646v1</guid></item><item><title>VideoMaker: Zero-shot Customized Video Generation with the Inherent Force of Video Diffusion Models</title><link>http://arxiv.org/abs/2412.19645v1</link><description>Zero-shot customized video generation has gained significant attention due toits substantial application potential. Existing methods rely on additionalmodels to extract and inject reference subject features, assuming that theVideo Diffusion Model (VDM) alone is insufficient for zero-shot customizedvideo generation. However, these methods often struggle to maintain consistentsubject appearance due to suboptimal feature extraction and injectiontechniques. In this paper, we reveal that VDM inherently possesses the force toextract and inject subject features. Departing from previous heuristicapproaches, we introduce a novel framework that leverages VDM's inherent forceto enable high-quality zero-shot customized video generation. Specifically, forfeature extraction, we directly input reference images into VDM and use itsintrinsic feature extraction process, which not only provides fine-grainedfeatures but also significantly aligns with VDM's pre-trained knowledge. Forfeature injection, we devise an innovative bidirectional interaction betweensubject features and generated content through spatial self-attention withinVDM, ensuring that VDM has better subject fidelity while maintaining thediversity of the generated video.Experiments on both customized human andobject video generation validate the effectiveness of our framework.</description><author>Tao Wu, Yong Zhang, Xiaodong Cun, Zhongang Qi, Junfu Pu, Huanzhang Dou, Guangcong Zheng, Ying Shan, Xi Li</author><pubDate>Fri, 27 Dec 2024 13:49:25 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.19645v1</guid></item><item><title>Generation through the lens of learning theory</title><link>http://arxiv.org/abs/2410.13714v5</link><description>We study generation through the lens of statistical learning theory. First,we abstract and formalize the results of Gold [1967], Angluin [1979], Angluin[1980] and Kleinberg and Mullainathan [2024] in terms of a binary hypothesisclass defined over an abstract example space. Then, we extend the notion of"generation" from Kleinberg and Mullainathan [2024] to two new settings, wecall "uniform" and "non-uniform" generation, and provide a characterization ofwhich hypothesis classes are uniformly and non-uniformly generatable. As isstandard in learning theory, our characterizations are in terms of thefiniteness of a new combinatorial dimension termed the Closure dimension. Bydoing so, we are able to compare generatability with predictability (capturedvia PAC and online learnability) and show that these two properties ofhypothesis classes are incompatible -- there are classes that are generatablebut not predictable and vice versa. Finally, we extend our results to captureprompted generation and give a complete characterization of which classes areprompt generatable, generalizing some of the work by Kleinberg and Mullainathan[2024].</description><author>Jiaxun Li, Vinod Raman, Ambuj Tewari</author><pubDate>Fri, 27 Dec 2024 13:42:07 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.13714v5</guid></item><item><title>Xmodel-2 Technical Report</title><link>http://arxiv.org/abs/2412.19638v1</link><description>Xmodel-2 is a 1.2-billion-parameter large language model designedspecifically for reasoning tasks. Its architecture enables different modelscales to share a unified set of hyperparameters, allowing for extensiveexperimentation on smaller models and seamless transfer of optimalconfigurations to larger models. To maximize training efficiency and stability,Xmodel-2 employs the WSD learning rate scheduler from MiniCPM. Pretrained on1.5 trillion tokens from diverse sources, Xmodel-2 achieves state-of-the-artperformance in complex reasoning and agent-based tasks, while maintaining lowtraining costs. These results highlight the potential of efficient model designand training strategies in advancing reasoning capabilities. Model checkpointsand code are publicly available on GitHub athttps://github.com/XiaoduoAILab/Xmodel-2</description><author>Wang Qun, Liu Yang, Lin Qingquan, Qu Zhijiu, Jiang Ling</author><pubDate>Fri, 27 Dec 2024 13:32:10 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.19638v1</guid></item><item><title>ReNeg: Learning Negative Embedding with Reward Guidance</title><link>http://arxiv.org/abs/2412.19637v1</link><description>In text-to-image (T2I) generation applications, negative embeddings haveproven to be a simple yet effective approach for enhancing generation quality.Typically, these negative embeddings are derived from user-defined negativeprompts, which, while being functional, are not necessarily optimal. In thispaper, we introduce ReNeg, an end-to-end method designed to learn improvedNegative embeddings guided by a Reward model. We employ a reward feedbacklearning framework and integrate classifier-free guidance (CFG) into thetraining process, which was previously utilized only during inference, thusenabling the effective learning of negative embeddings. We also propose twostrategies for learning both global and per-sample negative embeddings.Extensive experiments show that the learned negative embedding significantlyoutperforms null-text and handcrafted counterparts, achieving substantialimprovements in human preference alignment. Additionally, the negativeembedding learned within the same text embedding space exhibits stronggeneralization capabilities. For example, using the same CLIP text encoder, thenegative embedding learned on SD1.5 can be seamlessly transferred totext-to-image or even text-to-video models such as ControlNet, ZeroScope, andVideoCrafter2, resulting in consistent performance improvements across theboard.</description><author>Xiaomin Li, Yixuan Liu, Takashi Isobe, Xu Jia, Qinpeng Cui, Dong Zhou, Dong Li, You He, Huchuan Lu, Zhongdao Wang, Emad Barsoum</author><pubDate>Fri, 27 Dec 2024 13:31:55 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.19637v1</guid></item><item><title>GenDFIR: Advancing Cyber Incident Timeline Analysis Through Retrieval Augmented Generation and Large Language Models</title><link>http://arxiv.org/abs/2409.02572v4</link><description>Cyber timeline analysis, or forensic timeline analysis, is crucial in DigitalForensics and Incident Response (DFIR). It examines artefacts and eventsparticularly timestamps and metadata to detect anomalies, establishcorrelations, and reconstruct incident timelines. Traditional methods rely onstructured artefacts, such as logs and filesystem metadata, using specialisedtools for evidence identification and feature extraction. This paper introducesGenDFIR, a framework leveraging large language models (LLMs), specificallyLlama 3.1 8B in zero shot mode, integrated with a Retrieval-AugmentedGeneration (RAG) agent. Incident data is preprocessed into a structuredknowledge base, enabling the RAG agent to retrieve relevant events based onuser prompts. The LLM interprets this context, offering semantic enrichment.Tested on synthetic data in a controlled environment, results demonstrateGenDFIR's reliability and robustness, showcasing LLMs potential to automatetimeline analysis and advance threat detection.</description><author>Fatma Yasmine Loumachi, Mohamed Chahine Ghanem, Mohamed Amine Ferrag</author><pubDate>Fri, 27 Dec 2024 13:29:14 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2409.02572v4</guid></item><item><title>RL-MUL 2.0: Multiplier Design Optimization with Parallel Deep Reinforcement Learning and Space Reduction</title><link>http://arxiv.org/abs/2404.00639v2</link><description>Multiplication is a fundamental operation in many applications, andmultipliers are widely adopted in various circuits. However, optimizingmultipliers is challenging due to the extensive design space. In this paper, wepropose a multiplier design optimization framework based on reinforcementlearning. We utilize matrix and tensor representations for the compressor treeof a multiplier, enabling seamless integration of convolutional neural networksas the agent network. The agent optimizes the multiplier structure using aPareto-driven reward customized to balance area and delay. Furthermore, weenhance the original framework with parallel reinforcement learning and designspace pruning techniques and extend its capability to optimize fusedmultiply-accumulate (MAC) designs. Experiments conducted on different bitwidths of multipliers demonstrate that multipliers produced by our approachoutperform all baseline designs in terms of area, power, and delay. Theperformance gain is further validated by comparing the area, power, and delayof processing element arrays using multipliers from our approach and baselineapproaches.</description><author>Dongsheng Zuo, Jiadong Zhu, Yikang Ouyang, Yuzhe Ma</author><pubDate>Fri, 27 Dec 2024 13:26:58 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.00639v2</guid></item><item><title>Deep Linear Hawkes Processes</title><link>http://arxiv.org/abs/2412.19634v1</link><description>Marked temporal point processes (MTPPs) are used to model sequences ofdifferent types of events with irregular arrival times, with broad applicationsranging from healthcare and social networks to finance. We address shortcomingsin existing point process models by drawing connections between modern deepstate-space models (SSMs) and linear Hawkes processes (LHPs), culminating in anMTPP that we call the deep linear Hawkes process (DLHP). The DLHP modifies thelinear differential equations in deep SSMs to be stochastic jump differentialequations, akin to LHPs. After discretizing, the resulting recurrence can beimplemented efficiently using a parallel scan. This brings parallelism andlinear scaling to MTPP models. This contrasts with attention-based MTPPs, whichscale quadratically, and RNN-based MTPPs, which do not parallelize across thesequence length. We show empirically that DLHPs match or outperform existingmodels across a broad range of metrics on eight real-world datasets. Ourproposed DLHP model is the first instance of the unique architecturalcapabilities of SSMs being leveraged to construct a new class of MTPP models.</description><author>Yuxin Chang, Alex Boyd, Cao Xiao, Taha Kass-Hout, Parminder Bhatia, Padhraic Smyth, Andrew Warrington</author><pubDate>Fri, 27 Dec 2024 13:23:58 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.19634v1</guid></item><item><title>Convergence of SGD with momentum in the nonconvex case: A time window-based analysis</title><link>http://arxiv.org/abs/2405.16954v3</link><description>The stochastic gradient descent method with momentum (SGDM) is a commonapproach for solving large-scale and stochastic optimization problems. Despiteits popularity, the convergence behavior of SGDM remains less understood innonconvex scenarios. This is primarily due to the absence of a sufficientdescent property and challenges in simultaneously controlling the momentum andstochastic errors in an almost sure sense. To address these challenges, weinvestigate the behavior of SGDM over specific time windows, rather thanexamining the descent of consecutive iterates as in traditional studies. Thistime window-based approach simplifies the convergence analysis and enables usto establish the iterate convergence result for SGDM under the {\L}ojasiewiczproperty. We further provide local convergence rates which depend on theunderlying {\L}ojasiewicz exponent and the utilized step size schemes.</description><author>Junwen Qiu, Bohao Ma, Andre Milzarek</author><pubDate>Fri, 27 Dec 2024 13:23:03 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.16954v3</guid></item><item><title>RecConv: Efficient Recursive Convolutions for Multi-Frequency Representations</title><link>http://arxiv.org/abs/2412.19628v1</link><description>Recent advances in vision transformers (ViTs) have demonstrated the advantageof global modeling capabilities, prompting widespread integration oflarge-kernel convolutions for enlarging the effective receptive field (ERF).However, the quadratic scaling of parameter count and computational complexity(FLOPs) with respect to kernel size poses significant efficiency andoptimization challenges. This paper introduces RecConv, a recursivedecomposition strategy that efficiently constructs multi-frequencyrepresentations using small-kernel convolutions. RecConv establishes a linearrelationship between parameter growth and decomposing levels which determinesthe effective kernel size $k\times 2^\ell$ for a base kernel $k$ and $\ell$levels of decomposition, while maintaining constant FLOPs regardless of the ERFexpansion. Specifically, RecConv achieves a parameter expansion of only$\ell+2$ times and a maximum FLOPs increase of $5/3$ times, compared to theexponential growth ($4^\ell$) of standard and depthwise convolutions.RecNeXt-M3 outperforms RepViT-M1.1 by 1.9 $AP^{box}$ on COCO with similarFLOPs. This innovation provides a promising avenue towards designing efficientand compact networks across various modalities. Codes and models can be foundat \url{https://github.com/suous/RecNeXt}.</description><author>Mingshu Zhao, Yi Luo, Yong Ouyang</author><pubDate>Fri, 27 Dec 2024 13:13:52 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.19628v1</guid></item><item><title>A Mathematical Framework for the Problem of Security for Cognition in Neurotechnology</title><link>http://arxiv.org/abs/2403.07945v3</link><description>The rapid advancement in neurotechnology in recent years has created anemerging critical intersection between neurotechnology and security.Implantable devices, non-invasive monitoring, and non-invasive therapies allcarry with them the prospect of violating the privacy and autonomy ofindividuals' cognition. A growing number of scientists and physicians have madecalls to address this issue, but applied efforts have been relatively limited.A major barrier hampering scientific and engineering efforts to address thesesecurity issues is the lack of a clear means of describing and analyzingrelevant problems. In this paper we develop Cognitive Neurosecurity, amathematical framework which enables such description and analysis by drawingon methods and results from multiple fields. We demonstrate certain statisticalproperties which have significant implications for Cognitive Neurosecurity, andthen present descriptions of the algorithmic problems faced by attackersattempting to violate privacy and autonomy, and defenders attempting toobstruct such attempts.</description><author>Bryce Allen Bagley, Claudia K Petritsch</author><pubDate>Fri, 27 Dec 2024 13:08:14 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.07945v3</guid></item><item><title>MERT: Acoustic Music Understanding Model with Large-Scale Self-supervised Training</title><link>http://arxiv.org/abs/2306.00107v5</link><description>Self-supervised learning (SSL) has recently emerged as a promising paradigmfor training generalisable models on large-scale data in the fields of vision,text, and speech. Although SSL has been proven effective in speech and audio,its application to music audio has yet to be thoroughly explored. This ispartially due to the distinctive challenges associated with modelling musicalknowledge, particularly tonal and pitched characteristics of music. To addressthis research gap, we propose an acoustic Music undERstanding model withlarge-scale self-supervised Training (MERT), which incorporates teacher modelsto provide pseudo labels in the masked language modelling (MLM) style acousticpre-training. In our exploration, we identified an effective combination ofteacher models, which outperforms conventional speech and audio approaches interms of performance. This combination includes an acoustic teacher based onResidual Vector Quantisation - Variational AutoEncoder (RVQ-VAE) and a musicalteacher based on the Constant-Q Transform (CQT). Furthermore, we explore a widerange of settings to overcome the instability in acoustic language modelpre-training, which allows our designed paradigm to scale from 95M to 330Mparameters. Experimental results indicate that our model can generalise andperform well on 14 music understanding tasks and attain state-of-the-art (SOTA)overall scores.</description><author>Yizhi Li, Ruibin Yuan, Ge Zhang, Yinghao Ma, Xingran Chen, Hanzhi Yin, Chenghao Xiao, Chenghua Lin, Anton Ragni, Emmanouil Benetos, Norbert Gyenge, Roger Dannenberg, Ruibo Liu, Wenhu Chen, Gus Xia, Yemin Shi, Wenhao Huang, Zili Wang, Yike Guo, Jie Fu</author><pubDate>Fri, 27 Dec 2024 12:28:34 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.00107v5</guid></item><item><title>Gradient Weight-normalized Low-rank Projection for Efficient LLM Training</title><link>http://arxiv.org/abs/2412.19616v1</link><description>Large Language Models (LLMs) have shown remarkable performance across varioustasks, but the escalating demands on computational resources pose significantchallenges, particularly in the extensive utilization of full fine-tuning fordownstream tasks. To address this, parameter-efficient fine-tuning (PEFT)methods have been developed, but they often underperform compared to fullfine-tuning and struggle with memory efficiency. In this work, we introduceGradient Weight-Normalized Low-Rank Projection (GradNormLoRP), a novel approachthat enhances both parameter and memory efficiency while maintaining comparableperformance to full fine-tuning. GradNormLoRP normalizes the weight matrix toimprove gradient conditioning, facilitating better convergence duringoptimization. Additionally, it applies low-rank approximations to the weightand gradient matrices, significantly reducing memory usage during training.Extensive experiments demonstrate that our 8-bit GradNormLoRP reduces optimizermemory usage by up to 89.5% and enables the pre-training of large LLMs, such asLLaMA 7B, on consumer-level GPUs like the NVIDIA RTX 4090, without additionalinference costs. Moreover, GradNormLoRP outperforms existing low-rank methodsin fine-tuning tasks. For instance, when fine-tuning the RoBERTa model on allGLUE tasks with a rank of 8, GradNormLoRP achieves an average score of 80.65,surpassing LoRA's score of 79.23. These results underscore GradNormLoRP as apromising alternative for efficient LLM pre-training and fine-tuning. Sourcecode and Appendix:https://github.com/Jhhuangkay/Gradient-Weight-normalized-Low-rank-Projection-for-Efficient-LLM-Training</description><author>Jia-Hong Huang, Yixian Shen, Hongyi Zhu, Stevan Rudinac, Evangelos Kanoulas</author><pubDate>Fri, 27 Dec 2024 12:23:39 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.19616v1</guid></item><item><title>FlexiTex: Enhancing Texture Generation with Visual Guidance</title><link>http://arxiv.org/abs/2409.12431v4</link><description>Recent texture generation methods achieve impressive results due to thepowerful generative prior they leverage from large-scale text-to-imagediffusion models. However, abstract textual prompts are limited in providingglobal textural or shape information, which results in the texture generationmethods producing blurry or inconsistent patterns. To tackle this, we presentFlexiTex, embedding rich information via visual guidance to generate ahigh-quality texture. The core of FlexiTex is the Visual Guidance Enhancementmodule, which incorporates more specific information from visual guidance toreduce ambiguity in the text prompt and preserve high-frequency details. Tofurther enhance the visual guidance, we introduce a Direction-Aware Adaptationmodule that automatically designs direction prompts based on different cameraposes, avoiding the Janus problem and maintaining semantically globalconsistency. Benefiting from the visual guidance, FlexiTex producesquantitatively and qualitatively sound results, demonstrating its potential toadvance texture generation for real-world applications.</description><author>DaDong Jiang, Xianghui Yang, Zibo Zhao, Sheng Zhang, Jiaao Yu, Zeqiang Lai, Shaoxiong Yang, Chunchao Guo, Xiaobo Zhou, Zhihui Ke</author><pubDate>Fri, 27 Dec 2024 12:18:55 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2409.12431v4</guid></item><item><title>Machine Generated Product Advertisements: Benchmarking LLMs Against Human Performance</title><link>http://arxiv.org/abs/2412.19610v1</link><description>This study compares the performance of AI-generated and human-written productdescriptions using a multifaceted evaluation model. We analyze descriptions for100 products generated by four AI models (Gemma 2B, LLAMA, GPT2, and ChatGPT 4)with and without sample descriptions, against human-written descriptions. Ourevaluation metrics include sentiment, readability, persuasiveness, SearchEngine Optimization(SEO), clarity, emotional appeal, and call-to-actioneffectiveness. The results indicate that ChatGPT 4 performs the best. Incontrast, other models demonstrate significant shortcomings, producingincoherent and illogical output that lacks logical structure and contextualrelevance. These models struggle to maintain focus on the product beingdescribed, resulting in disjointed sentences that do not convey meaningfulinformation. This research provides insights into the current capabilities andlimitations of AI in the creation of content for e-Commerce.</description><author>Sanjukta Ghosh</author><pubDate>Fri, 27 Dec 2024 12:11:50 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.19610v1</guid></item><item><title>Bidding Games on Markov Decision Processes with Quantitative Reachability Objectives</title><link>http://arxiv.org/abs/2412.19609v1</link><description>Graph games are fundamental in strategic reasoning of multi-agent systems andtheir environments. We study a new family of graph games which combinestochastic environmental uncertainties and auction-based interactions among theagents, formalized as bidding games on (finite) Markov decision processes(MDP). Normally, on MDPs, a single decision-maker chooses a sequence ofactions, producing a probability distribution over infinite paths. In biddinggames on MDPs, two players -- called the reachability and safety players -- bidfor the privilege of choosing the next action at each step. The reachabilityplayer's goal is to maximize the probability of reaching a target vertex,whereas the safety player's goal is to minimize it. These games generalizetraditional bidding games on graphs, and the existing analysis techniques donot extend. For instance, the central property of traditional bidding games isthe existence of a threshold budget, which is a necessary and sufficient budgetto guarantee winning for the reachability player. For MDPs, the thresholdbecomes a relation between the budgets and probabilities of reaching thetarget. We devise value-iteration algorithms that approximate thresholds andoptimal policies for general MDPs, and compute the exact solutions for acyclicMDPs, and show that finding thresholds is at least as hard as solvingsimple-stochastic games.</description><author>Guy Avni, Martin Kurečka, Kaushik Mallik, Petr Novotný, Suman Sadhukhan</author><pubDate>Fri, 27 Dec 2024 12:10:00 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.19609v1</guid></item><item><title>Enhancing Fine-grained Image Classification through Attentive Batch Training</title><link>http://arxiv.org/abs/2412.19606v1</link><description>Fine-grained image classification, which is a challenging task in computervision, requires precise differentiation among visually similar objectcategories. In this paper, we propose 1) a novel module called ResidualRelationship Attention (RRA) that leverages the relationships between imageswithin each training batch to effectively integrate visual feature vectors ofbatch images and 2) a novel technique called Relationship Position Encoding(RPE), which encodes the positions of relationships between original images ina batch and effectively preserves the relationship information between imageswithin the batch. Additionally, we design a novel framework, namelyRelationship Batch Integration (RBI), which utilizes RRA in conjunction withRPE, allowing the discernment of vital visual features that may remain elusivewhen examining a singular image representative of a particular class. Throughextensive experiments, our proposed method demonstrates significantimprovements in the accuracy of different fine-grained classifiers, with anaverage increase of $(+2.78\%)$ and $(+3.83\%)$ on the CUB200-2011 and StanfordDog datasets, respectively, while achieving a state-of-the-art results$(95.79\%)$ on the Stanford Dog dataset. Despite not achieving the same levelof improvement as in fine-grained image classification, our method stilldemonstrates its prowess in leveraging general image classification byattaining a state-of-the-art result of $(93.71\%)$ on the Tiny-Imagenetdataset. Furthermore, our method serves as a plug-in refinement module and canbe easily integrated into different networks.</description><author>Duy M. Le, Bao Q. Bui, Anh Tran, Cong Tran, Cuong Pham</author><pubDate>Fri, 27 Dec 2024 12:07:58 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.19606v1</guid></item><item><title>Convergence analysis of wide shallow neural operators within the framework of Neural Tangent Kernel</title><link>http://arxiv.org/abs/2412.05545v2</link><description>Neural operators are aiming at approximating operators mapping between Banachspaces of functions, achieving much success in the field of scientificcomputing. Compared to certain deep learning-based solvers, such asPhysics-Informed Neural Networks (PINNs), Deep Ritz Method (DRM), neuraloperators can solve a class of Partial Differential Equations (PDEs). Althoughmuch work has been done to analyze the approximation and generalization errorof neural operators, there is still a lack of analysis on their training error.In this work, we conduct the convergence analysis of gradient descent for thewide shallow neural operators within the framework of Neural Tangent Kernel(NTK). The core idea lies on the fact that over-parameterization and randominitialization together ensure that each weight vector remains near itsinitialization throughout all iterations, yielding the linear convergence ofgradient descent. In this work, we demonstrate that under the setting ofover-parametrization, gradient descent can find the global minimum regardlessof whether it is in continuous time or discrete time. Finally, we brieflydiscuss the case of physics-informed shallow neural operators.</description><author>Xianliang Xu, Ye Li, Zhongyi Huang</author><pubDate>Fri, 27 Dec 2024 11:57:40 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.05545v2</guid></item><item><title>Markov Process-Based Graph Convolutional Networks for Entity Classification in Knowledge Graphs</title><link>http://arxiv.org/abs/2412.17438v2</link><description>Despite the vast amount of information encoded in Knowledge Graphs (KGs),information about the class affiliation of entities remains often incomplete.Graph Convolutional Networks (GCNs) have been shown to be effective predictorsof complete information about the class affiliation of entities in KGs.However, these models do not learn the class affiliation of entities in KGsincorporating the complexity of the task, which negatively affects the modelsprediction capabilities. To address this problem, we introduce a Markovprocess-based architecture into well-known GCN architectures. This end-to-endnetwork learns the prediction of class affiliation of entities in KGs within aMarkov process. The number of computational steps is learned during trainingusing a geometric distribution. At the same time, the loss function combinesinsights from the field of evidential learning. The experiments show aperformance improvement over existing models in several studied architecturesand datasets. Based on the chosen hyperparameters for the geometricdistribution, the expected number of computation steps can be adjusted toimprove efficiency and accuracy during training.</description><author>Johannes Mäkelburg, Yiwen Peng, Mehwish Alam, Tobias Weller, Maribel Acosta</author><pubDate>Fri, 27 Dec 2024 11:49:53 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.17438v2</guid></item><item><title>Are Sparse Neural Networks Better Hard Sample Learners?</title><link>http://arxiv.org/abs/2409.09196v2</link><description>While deep learning has demonstrated impressive progress, it remains adaunting challenge to learn from hard samples as these samples are usuallynoisy and intricate. These hard samples play a crucial role in the optimalperformance of deep neural networks. Most research on Sparse Neural Networks(SNNs) has focused on standard training data, leaving gaps in understandingtheir effectiveness on complex and challenging data. This paper's extensiveinvestigation across scenarios reveals that most SNNs trained on challengingsamples can often match or surpass dense models in accuracy at certain sparsitylevels, especially with limited data. We observe that layer-wise density ratiostend to play an important role in SNN performance, particularly for methodsthat train from scratch without pre-trained initialization. These insightsenhance our understanding of SNNs' behavior and potential for efficientlearning approaches in data-centric AI. Our code is publicly available at:\url{https://github.com/QiaoXiao7282/hard_sample_learners}.</description><author>Qiao Xiao, Boqian Wu, Lu Yin, Christopher Neil Gadzinski, Tianjin Huang, Mykola Pechenizkiy, Decebal Constantin Mocanu</author><pubDate>Fri, 27 Dec 2024 11:41:38 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2409.09196v2</guid></item><item><title>SocRATES: Towards Automated Scenario-based Testing of Social Navigation Algorithms</title><link>http://arxiv.org/abs/2412.19595v1</link><description>Current social navigation methods and benchmarks primarily focus on proxemicsand task efficiency. While these factors are important, qualitative aspectssuch as perceptions of a robot's social competence are equally crucial forsuccessful adoption and integration into human environments. We propose a morecomprehensive evaluation of social navigation through scenario-based testing,where specific human-robot interaction scenarios can reveal key robotbehaviors. However, creating such scenarios is often labor-intensive andcomplex. In this work, we address this challenge by introducing a pipeline thatautomates the generation of context-, and location-appropriate socialnavigation scenarios, ready for simulation. Our pipeline transforms simplescenario metadata into detailed textual scenarios, infers pedestrian and robottrajectories, and simulates pedestrian behaviors, which enables more controlledevaluation. We leverage the social reasoning and code-generation capabilitiesof Large Language Models (LLMs) to streamline scenario generation andtranslation. Our experiments show that our pipeline produces realisticscenarios and significantly improves scenario translation over naive LLMprompting. Additionally, we present initial feedback from a usability studywith social navigation experts and a case-study demonstrating a scenario-basedevaluation of three navigation algorithms.</description><author>Shashank Rao Marpally, Pranav Goyal, Harold Soh</author><pubDate>Fri, 27 Dec 2024 11:33:19 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.19595v1</guid></item><item><title>Blessing or curse? A survey on the Impact of Generative AI on Fake News</title><link>http://arxiv.org/abs/2404.03021v2</link><description>Fake news significantly influence our society. They impact consumers, voters,and many other societal groups. While Fake News exist for a centuries,Generative AI brings fake news on a new level. It is now possible to automatethe creation of masses of high-quality individually targeted Fake News. On theother end, Generative AI can also help detecting Fake News. Both fields areyoung but developing fast. This survey provides a comprehensive examination of the research andpractical use of Generative AI for Fake News detection and creation in 2024.Following the Structured Literature Survey approach, the paper synthesizescurrent results in the following topic clusters 1) enabling technologies, 2)creation of Fake News, 3) case study social media as most relevant distributionchannel, 4) detection of Fake News, and 5) deepfakes as upcoming technology. The article also identifies current challenges and open issues.</description><author>Alexander Loth, Martin Kappes, Marc-Oliver Pahl</author><pubDate>Fri, 27 Dec 2024 11:31:01 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.03021v2</guid></item><item><title>ViDTA: Enhanced Drug-Target Affinity Prediction via Virtual Graph Nodes and Attention-based Feature Fusion</title><link>http://arxiv.org/abs/2412.19589v1</link><description>Drug-target interaction is fundamental in understanding how drugs affectbiological systems, and accurately predicting drug-target affinity (DTA) isvital for drug discovery. Recently, deep learning methods have emerged as asignificant approach for estimating the binding strength between drugs andtarget proteins. However, existing methods simply utilize the drug's localinformation from molecular topology rather than global information.Additionally, the features of drugs and proteins are usually fused with asimple concatenation operation, limiting their effectiveness. To address thesechallenges, we proposed ViDTA, an enhanced DTA prediction framework. Weintroduce virtual nodes into the Graph Neural Network (GNN)-based drug featureextraction network, which acts as a global memory to exchange messages moreefficiently. By incorporating virtual graph nodes, we seamlessly integratelocal and global features of drug molecular structures, expanding the GNN'sreceptive field. Additionally, we propose an attention-based linear featurefusion network for better capturing the interaction information between drugsand proteins. Experimental results evaluated on various benchmarks includingDavis, Metz, and KIBA demonstrate that our proposed ViDTA outperforms thestate-of-the-art baselines.</description><author>Minghui Li, Zikang Guo, Yang Wu, Peijin Guo, Yao Shi, Shengshan Hu, Wei Wan, Shengqing Hu</author><pubDate>Fri, 27 Dec 2024 11:19:10 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.19589v1</guid></item><item><title>Goal-oriented Communications based on Recursive Early Exit Neural Networks</title><link>http://arxiv.org/abs/2412.19587v1</link><description>This paper presents a novel framework for goal-oriented semanticcommunications leveraging recursive early exit models. The proposed approach isbuilt on two key components. First, we introduce an innovative early exitstrategy that dynamically partitions computations, enabling samples to beoffloaded to a server based on layer-wise recursive prediction dynamics thatdetect samples for which the confidence is not increasing fast enough overlayers. Second, we develop a Reinforcement Learning-based online optimizationframework that jointly determines early exit points, computation splitting, andoffloading strategies, while accounting for wireless conditions, inferenceaccuracy, and resource costs. Numerical evaluations in an edge inferencescenario demonstrate the method's adaptability and effectiveness in striking anexcellent trade-off between performance, latency, and resource efficiency.</description><author>Jary Pomponi, Mattia Merluzzi, Alessio Devoto, Mateus Pontes Mota, Paolo Di Lorenzo, Simone Scardapane</author><pubDate>Fri, 27 Dec 2024 11:14:11 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.19587v1</guid></item><item><title>Ultralight Signal Classification Model for Automatic Modulation Recognition</title><link>http://arxiv.org/abs/2412.19585v1</link><description>The growing complexity of radar signals demands responsive and accuratedetection systems that can operate efficiently on resource-constrained edgedevices. Existing models, while effective, often rely on substantialcomputational resources and large datasets, making them impractical for edgedeployment. In this work, we propose an ultralight hybrid neural networkoptimized for edge applications, delivering robust performance acrossunfavorable signal-to-noise ratios (mean accuracy of 96.3% at 0 dB) using lessthan 100 samples per class, and significantly reducing computational overhead.</description><author>Alessandro Daniele Genuardi Oquendo, Agustín Matías Galante Cerviño, Nilotpal Sinha, Luc Andrea, Sam Mugel, Román Orús</author><pubDate>Fri, 27 Dec 2024 11:03:26 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.19585v1</guid></item><item><title>DAS3R: Dynamics-Aware Gaussian Splatting for Static Scene Reconstruction</title><link>http://arxiv.org/abs/2412.19584v1</link><description>We propose a novel framework for scene decomposition and static backgroundreconstruction from everyday videos. By integrating the trained motion masksand modeling the static scene as Gaussian splats with dynamics-awareoptimization, our method achieves more accurate background reconstructionresults than previous works. Our proposed method is termed DAS3R, anabbreviation for Dynamics-Aware Gaussian Splatting for Static SceneReconstruction. Compared to existing methods, DAS3R is more robust in complexmotion scenarios, capable of handling videos where dynamic objects occupy asignificant portion of the scene, and does not require camera pose inputs orpoint cloud data from SLAM-based methods. We compared DAS3R against recentdistractor-free approaches on the DAVIS and Sintel datasets; DAS3R demonstratesenhanced performance and robustness with a margin of more than 2 dB in PSNR.The project's webpage can be accessed via \url{https://kai422.github.io/DAS3R/}</description><author>Kai Xu, Tze Ho Elden Tse, Jizong Peng, Angela Yao</author><pubDate>Fri, 27 Dec 2024 10:59:46 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.19584v1</guid></item><item><title>A Comparative Study of Machine Unlearning Techniques for Image and Text Classification Models</title><link>http://arxiv.org/abs/2412.19583v1</link><description>Machine Unlearning has emerged as a critical area in artificial intelligence,addressing the need to selectively remove learned data from machine learningmodels in response to data privacy regulations. This paper provides acomprehensive comparative analysis of six state-of-theart unlearning techniquesapplied to image and text classification tasks. We evaluate their performance,efficiency, and compliance with regulatory requirements, highlighting theirstrengths and limitations in practical scenarios. By systematically analyzingthese methods, we aim to provide insights into their applicability,challenges,and tradeoffs, fostering advancements in the field of ethical andadaptable machine learning.</description><author>Omar M. Safa, Mahmoud M. Abdelaziz, Mustafa Eltawy, Mohamed Mamdouh, Moamen Gharib, Salaheldin Eltenihy, Nagia M. Ghanem, Mohamed M. Ismail</author><pubDate>Fri, 27 Dec 2024 10:58:55 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.19583v1</guid></item><item><title>Hyperspectral Pansharpening: Critical Review, Tools and Future Perspectives</title><link>http://arxiv.org/abs/2407.01355v2</link><description>Hyperspectral pansharpening consists of fusing a high-resolution panchromaticband and a low-resolution hyperspectral image to obtain a new image with highresolution in both the spatial and spectral domains. These remote sensingproducts are valuable for a wide range of applications, driving ever growingresearch efforts. Nonetheless, results still do not meet application demands.In part, this comes from the technical complexity of the task: compared tomultispectral pansharpening, many more bands are involved, in a spectral rangeonly partially covered by the panchromatic component and with overwhelmingnoise. However, another major limiting factor is the absence of a comprehensiveframework for the rapid development and accurate evaluation of new methods.This paper attempts to address this issue. We started by designing a dataset large and diverse enough to allow reliabletraining (for data-driven methods) and testing of new methods. Then, weselected a set of state-of-the-art methods, following different approaches,characterized by promising performance, and reimplemented them in a singlePyTorch framework. Finally, we carried out a critical comparative analysis ofall methods, using the most accredited quality indicators. The analysishighlights the main limitations of current solutions in terms ofspectral/spatial quality and computational efficiency, and suggests promisingresearch directions. To ensure full reproducibility of the results and support future research,the framework (including codes, evaluation procedures and links to the dataset)is shared on https://github.com/matciotola/hyperspectral_pansharpening_toolbox,as a single Python-based reference benchmark toolbox.</description><author>Matteo Ciotola, Giuseppe Guarino, Gemine Vivone, Giovanni Poggi, Jocelyn Chanussot, Antonio Plaza, Giuseppe Scarpa</author><pubDate>Fri, 27 Dec 2024 10:52:39 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.01355v2</guid></item><item><title>Graph-attention-based Casual Discovery with Trust Region-navigated Clipping Policy Optimization</title><link>http://arxiv.org/abs/2412.19578v1</link><description>In many domains of empirical sciences, discovering the causal structurewithin variables remains an indispensable task. Recently, to tackle withunoriented edges or latent assumptions violation suffered by conventionalmethods, researchers formulated a reinforcement learning (RL) procedure forcausal discovery, and equipped REINFORCE algorithm to search for thebest-rewarded directed acyclic graph. The two keys to the overall performanceof the procedure are the robustness of RL methods and the efficient encoding ofvariables. However, on the one hand, REINFORCE is prone to local convergenceand unstable performance during training. Neither trust region policyoptimization, being computationally-expensive, nor proximal policy optimization(PPO), suffering from aggregate constraint deviation, is decent alternative forcombinatory optimization problems with considerable individual subactions. Wepropose a trust region-navigated clipping policy optimization method for causaldiscovery that guarantees both better search efficiency and steadiness inpolicy optimization, in comparison with REINFORCE, PPO and our prioritizedsampling-guided REINFORCE implementation. On the other hand, to boost theefficient encoding of variables, we propose a refined graph attention encodercalled SDGAT that can grasp more feature information without priorineighbourhood information. With these improvements, the proposed methodoutperforms former RL method in both synthetic and benchmark datasets in termsof output results and optimization robustness.</description><author>Shixuan Liu, Yanghe Feng, Keyu Wu, Guangquan Cheng, Jincai Huang, Zhong Liu</author><pubDate>Fri, 27 Dec 2024 10:50:43 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.19578v1</guid></item><item><title>Official-NV: An LLM-Generated News Video Dataset for Multimodal Fake News Detection</title><link>http://arxiv.org/abs/2407.19493v3</link><description>News media, especially video news media, have penetrated into every aspect ofdaily life, which also brings the risk of fake news. Therefore, multimodal fakenews detection has recently garnered increased attention. However, the existingdatasets are comprised of user-uploaded videos and contain an excess amounts ofsuperfluous data, which introduces noise into the model training process. Toaddress this issue, we construct a dataset named Official-NV, comprisingofficially published news videos. The crawl officially published videos areaugmented through the use of LLMs-based generation and manual verification,thereby expanding the dataset. We also propose a new baseline model calledOFNVD, which captures key information from multimodal features through a GLUattention mechanism and performs feature enhancement and modal aggregation viaa cross-modal Transformer. Benchmarking the dataset and baselines demonstratesthe effectiveness of our model in multimodal news detection.</description><author>Yihao Wang, Lizhi Chen, Zhong Qian, Peifeng Li</author><pubDate>Fri, 27 Dec 2024 10:34:15 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.19493v3</guid></item><item><title>Agent-OM: Leveraging LLM Agents for Ontology Matching</title><link>http://arxiv.org/abs/2312.00326v6</link><description>Ontology matching (OM) enables semantic interoperability between differentontologies and resolves their conceptual heterogeneity by aligning relatedentities. OM systems currently have two prevailing design paradigms:conventional knowledge-based expert systems and newer machine learning-basedpredictive systems. While large language models (LLMs) and LLM agents haverevolutionised data engineering and have been applied creatively in manydomains, their potential for OM remains underexplored. This study introduces anovel agent-powered LLM-based design paradigm for OM systems. Withconsideration of several specific challenges in leveraging LLM agents for OM,we propose a generic framework, namely Agent-OM (Agent for Ontology Matching),consisting of two Siamese agents for retrieval and matching, with a set of OMtools. Our framework is implemented in a proof-of-concept system. Evaluationsof three Ontology Alignment Evaluation Initiative (OAEI) tracks overstate-of-the-art OM systems show that our system can achieve results very closeto the long-standing best performance on simple OM tasks and can significantlyimprove the performance on complex and few-shot OM tasks.</description><author>Zhangcheng Qiang, Weiqing Wang, Kerry Taylor</author><pubDate>Fri, 27 Dec 2024 10:12:28 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.00326v6</guid></item><item><title>Reinforced Label Denoising for Weakly-Supervised Audio-Visual Video Parsing</title><link>http://arxiv.org/abs/2412.19563v1</link><description>Audio-visual video parsing (AVVP) aims to recognize audio and visual eventlabels with precise temporal boundaries, which is quite challenging since audioor visual modality might include only one event label with only the overallvideo labels available. Existing label denoising models often treat thedenoising process as a separate preprocessing step, leading to a disconnectbetween label denoising and AVVP tasks. To bridge this gap, we present a noveljoint reinforcement learning-based label denoising approach (RLLD). Thisapproach enables simultaneous training of both label denoising and videoparsing models through a joint optimization strategy. We introduce a novelAVVP-validation and soft inter-reward feedback mechanism that directly guidesthe learning of label denoising policy. Extensive experiments on AVVP tasksdemonstrate the superior performance of our proposed method compared to labeldenoising techniques. Furthermore, by incorporating our label denoising methodinto other AVVP models, we find that it can further enhance parsing results.</description><author>Yongbiao Gao, Xiangcheng Sun, Guohua Lv, Deng Yu, Sijiu Niu</author><pubDate>Fri, 27 Dec 2024 10:05:56 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.19563v1</guid></item><item><title>Hindsight Planner: A Closed-Loop Few-Shot Planner for Embodied Instruction Following</title><link>http://arxiv.org/abs/2412.19562v1</link><description>This work focuses on building a task planner for Embodied InstructionFollowing (EIF) using Large Language Models (LLMs). Previous works typicallytrain a planner to imitate expert trajectories, treating this as a supervisedtask. While these methods achieve competitive performance, they often lacksufficient robustness. When a suboptimal action is taken, the planner mayencounter an out-of-distribution state, which can lead to task failure. Incontrast, we frame the task as a Partially Observable Markov Decision Process(POMDP) and aim to develop a robust planner under a few-shot assumption. Thus,we propose a closed-loop planner with an adaptation module and a novelhindsight method, aiming to use as much information as possible to assist theplanner. Our experiments on the ALFRED dataset indicate that our plannerachieves competitive performance under a few-shot assumption. For the firsttime, our few-shot agent's performance approaches and even surpasses that ofthe full-shot supervised agent.</description><author>Yuxiao Yang, Shenao Zhang, Zhihan Liu, Huaxiu Yao, Zhaoran Wang</author><pubDate>Fri, 27 Dec 2024 10:05:45 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.19562v1</guid></item><item><title>A data driven approach to classify descriptors based on their efficiency in translating noisy trajectories into physically-relevant information</title><link>http://arxiv.org/abs/2411.12570v3</link><description>Reconstructing the physical complexity of many-body dynamical systems can bechallenging. Starting from the trajectories of their constitutive units (rawdata), typical approaches require selecting appropriate descriptors to convertthem into time-series, which are then analyzed to extract interpretableinformation. However, identifying the most effective descriptor is oftennon-trivial. Here, we report a data-driven approach to compare the efficiencyof various descriptors in extracting information from noisy trajectories andtranslating it into physically relevant insights. As a prototypical system withnon-trivial internal complexity, we analyze molecular dynamics trajectories ofan atomistic system where ice and water coexist in equilibrium near thesolid/liquid transition temperature. We compare general and specificdescriptors often used in aqueous systems: number of neighbors, molecularvelocities, Smooth Overlap of Atomic Positions (SOAP), Local Environments andNeighbors Shuffling (LENS), Orientational Tetrahedral Order, and distance fromthe fifth neighbor ($d_5$). Using Onion Clustering -- an efficient unsupervisedmethod for single-point time-series analysis -- we assess the maximumextractable information for each descriptor and rank them via ahigh-dimensional metric. Our results show that advanced descriptors like SOAPand LENS outperform classical ones due to higher signal-to-noise ratios.Nonetheless, even simple descriptors can rival or exceed advanced ones afterlocal signal denoising. For example, $d_5$, initially among the weakest,becomes the most effective at resolving the system's non-local dynamicalcomplexity after denoising. This work highlights the critical role of noise ininformation extraction from molecular trajectories and offers a data-drivenapproach to identify optimal descriptors for systems with characteristicinternal complexity.</description><author>Simone Martino, Domiziano Doria, Chiara Lionello, Matteo Becchi, Giovanni M. Pavan</author><pubDate>Fri, 27 Dec 2024 09:56:51 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2411.12570v3</guid></item></channel></rss>