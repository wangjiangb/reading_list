<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/"><channel><title>Arxivfresh papers</title><link></link><description>Arxiv paper</description><language>en-US</language><lastBuildDate>Tue, 07 Jan 2025 13:00:17 GMT</lastBuildDate><generator>rfeed v1.0.0</generator><docs>https://github.com/svpino/rfeed/blob/master/README.md</docs><item><title>Gaussian Masked Autoencoders</title><link>http://arxiv.org/abs/2501.03229v1</link><description>This paper explores Masked Autoencoders (MAE) with Gaussian Splatting. Whilereconstructive self-supervised learning frameworks such as MAE learns goodsemantic abstractions, it is not trained for explicit spatial awareness. Ourapproach, named Gaussian Masked Autoencoder, or GMAE, aims to learn semanticabstractions and spatial understanding jointly. Like MAE, it reconstructs theimage end-to-end in the pixel space, but beyond MAE, it also introduces anintermediate, 3D Gaussian-based representation and renders images viasplatting. We show that GMAE can enable various zero-shot learning capabilitiesof spatial understanding (e.g., figure-ground segmentation, image layering,edge detection, etc.) while preserving the high-level semantics ofself-supervised representation quality from MAE. To our knowledge, we are thefirst to employ Gaussian primitives in an image representation learningframework beyond optimization-based single-scene reconstructions. We believeGMAE will inspire further research in this direction and contribute todeveloping next-generation techniques for modeling high-fidelity visual data.More details at https://brjathu.github.io/gmae</description><author>Jathushan Rajasegaran, Xinlei Chen, Rulilong Li, Christoph Feichtenhofer, Jitendra Malik, Shiry Ginosar</author><pubDate>Mon, 06 Jan 2025 18:59:57 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.03229v1</guid></item><item><title>LightGNN: Simple Graph Neural Network for Recommendation</title><link>http://arxiv.org/abs/2501.03228v1</link><description>Graph neural networks (GNNs) have demonstrated superior performance incollaborative recommendation through their ability to conduct high-orderrepresentation smoothing, effectively capturing structural information withinusers' interaction patterns. However, existing GNN paradigms face significantchallenges in scalability and robustness when handling large-scale, noisy, andreal-world datasets. To address these challenges, we present LightGNN, alightweight and distillation-based GNN pruning framework designed tosubstantially reduce model complexity while preserving essential collaborationmodeling capabilities. Our LightGNN framework introduces a computationallyefficient pruning module that adaptively identifies and removes redundant edgesand embedding entries for model compression. The framework is guided by aresource-friendly hierarchical knowledge distillation objective, whoseintermediate layer augments the observed graph to maintain performance,particularly in high-rate compression scenarios. Extensive experiments onpublic datasets demonstrate LightGNN's effectiveness, significantly improvingboth computational efficiency and recommendation accuracy. Notably, LightGNNachieves an 80% reduction in edge count and 90% reduction in embedding entrieswhile maintaining performance comparable to more complex state-of-the-artbaselines. The implementation of our LightGNN framework is available at thegithub repository: https://github.com/HKUDS/LightGNN.</description><author>Guoxuan Chen, Lianghao Xia, Chao Huang</author><pubDate>Mon, 06 Jan 2025 18:59:55 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.03228v1</guid></item><item><title>BoostStep: Boosting mathematical capability of Large Language Models via improved single-step reasoning</title><link>http://arxiv.org/abs/2501.03226v1</link><description>Cutting-edge large language models (LLMs) demonstrate promising performancein solving complex math problems with a divide-and-conquer pipeline and theassistance of in-context learning (ICL) examples. However, their potential forimprovement is limited by two critical problems within their ICL examples:granularity-mismatch and the ensuing negative-effect noise problem.Specifically, the LLMs are capable of the dividing process yet mostly failed byinaccurate reasoning within a few conquer steps, while the ICL examplesretrieved in question-grained sometimes lack relevant steps for a specificchallenging reasoning step. Further, this disconnect may hinder the correctreasoning due to its irrelevance. To this end, we focus on improving thereasoning quality within each step and present BoostStep. BoostStep aligns thegranularity between the retrieving and reasoning on step grained, and provideshighly related ICL examples for each reasoning step with a novel `first-try'strategy. BoostStep provides more relevant examples than the coarsequestion-grained strategy, enhancing the model reasoning quality within eachstep steadily. BoostStep is a general and robust reasoning-enhancing methodthat not only improves standalone reasoning performance but also integratesseamlessly with Monte Carlo Tree Search methods (MCTS) to refine both candidategeneration and decision-making. Quantitatively, it improves GPT-4o andQwen2.5-Math-72B by 3.6\% and 2.0\% respectively on various mathematicalbenchmarks, and 7.5\% gain combined with MCTS.</description><author>Beichen Zhang, Yuhong Liu, Xiaoyi Dong, Yuhang Zang, Pan Zhang, Haodong Duan, Yuhang Cao, Dahua Lin, Jiaqi Wang</author><pubDate>Mon, 06 Jan 2025 18:59:13 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.03226v1</guid></item><item><title>Automated Generation of Challenging Multiple-Choice Questions for Vision Language Model Evaluation</title><link>http://arxiv.org/abs/2501.03225v1</link><description>The rapid development of vision language models (VLMs) demands rigorous andreliable evaluation. However, current visual question answering (VQA)benchmarks often depend on open-ended questions, making accurate evaluationdifficult due to the variability in natural language responses. To addressthis, we introduce AutoConverter, an agentic framework that automaticallyconverts these open-ended questions into multiple-choice format, enablingobjective evaluation while reducing the costly question creation process. Ourexperiments demonstrate that AutoConverter can generate correct and challengingmultiple-choice questions, with VLMs demonstrating consistently similar orlower accuracy on these questions compared to human-created ones. UsingAutoConverter, we construct VMCBench, a benchmark created by transforming 20existing VQA datasets into a unified multiple-choice format, totaling 9,018questions. We comprehensively evaluate 33 state-of-the-art VLMs on VMCBench,setting a new standard for scalable, consistent, and reproducible VLMevaluation.</description><author>Yuhui Zhang, Yuchang Su, Yiming Liu, Xiaohan Wang, James Burgess, Elaine Sui, Chenyu Wang, Josiah Aklilu, Alejandro Lozano, Anjiang Wei, Ludwig Schmidt, Serena Yeung-Levy</author><pubDate>Mon, 06 Jan 2025 18:57:31 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.03225v1</guid></item><item><title>Rate-My-LoRA: Efficient and Adaptive Federated Model Tuning for Cardiac MRI Segmentation</title><link>http://arxiv.org/abs/2501.03223v1</link><description>Cardiovascular disease (CVD) and cardiac dyssynchrony are major public healthproblems in the United States. Precise cardiac image segmentation is crucialfor extracting quantitative measures that help categorize cardiac dyssynchrony.However, achieving high accuracy often depends on centralizing large datasetsfrom different hospitals, which can be challenging due to privacy concerns. Tosolve this problem, Federated Learning (FL) is proposed to enable decentralizedmodel training on such data without exchanging sensitive information. However,bandwidth limitations and data heterogeneity remain as significant challengesin conventional FL algorithms. In this paper, we propose a novel efficient andadaptive federate learning method for cardiac segmentation that improves modelperformance while reducing the bandwidth requirement. Our method leverages thelow-rank adaptation (LoRA) to regularize model weight update and reducecommunication overhead. We also propose a \mymethod{} aggregation technique toaddress data heterogeneity among clients. This technique adaptively penalizesthe aggregated weights from different clients by comparing the validationaccuracy in each client, allowing better generalization performance and fastlocal adaptation. In-client and cross-client evaluations on public cardiac MRdatasets demonstrate the superiority of our method over other LoRA-basedfederate learning approaches.</description><author>Xiaoxiao He, Haizhou Shi, Ligong Han, Chaowei Tan, Bo Liu, Zihao Xu, Meng Ye, Leon Axel, Kang Li, Dimitris Metaxas</author><pubDate>Mon, 06 Jan 2025 18:57:18 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.03223v1</guid></item><item><title>Characterizing the Accuracy-Communication-Privacy Trade-off in Distributed Stochastic Convex Optimization</title><link>http://arxiv.org/abs/2501.03222v1</link><description>We consider the problem of differentially private stochastic convexoptimization (DP-SCO) in a distributed setting with $M$ clients, where each ofthem has a local dataset of $N$ i.i.d. data samples from an underlying datadistribution. The objective is to design an algorithm to minimize a convexpopulation loss using a collaborative effort across $M$ clients, while ensuringthe privacy of the local datasets. In this work, we investigate theaccuracy-communication-privacy trade-off for this problem. We establishmatching converse and achievability results using a novel lower bound and a newalgorithm for distributed DP-SCO based on Vaidya's plane cutting method. Thus,our results provide a complete characterization of theaccuracy-communication-privacy trade-off for DP-SCO in the distributed setting.</description><author>Sudeep Salgia, Nikola Pavlovic, Yuejie Chi, Qing Zhao</author><pubDate>Mon, 06 Jan 2025 18:57:05 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.03222v1</guid></item><item><title>RW-Net: Enhancing Few-Shot Point Cloud Classification with a Wavelet Transform Projection-based Network</title><link>http://arxiv.org/abs/2501.03221v1</link><description>In the domain of 3D object classification, a fundamental challenge lies inaddressing the scarcity of labeled data, which limits the applicability oftraditional data-intensive learning paradigms. This challenge is particularlypronounced in few-shot learning scenarios, where the objective is to achieverobust generalization from minimal annotated samples. To overcome theselimitations, it is crucial to identify and leverage the most salient anddiscriminative features of 3D objects, thereby enhancing learning efficiencyand reducing dependency on large-scale labeled datasets. This work introducesRW-Net, a novel framework designed to address the challenges above byintegrating Rate-Distortion Explanation (RDE) and wavelet transform into astate-of-the-art projection-based 3D object classification architecture. Theproposed method capitalizes on RDE to extract critical features by identifyingand preserving the most informative data components while reducing redundancy.This process ensures the retention of essential information for effectivedecision-making, optimizing the model's ability to learn from limited data.Complementing RDE, incorporating the wavelet transform further enhances theframework's capability to generalize in low-data regimes. By emphasizinglow-frequency components of the input data, the wavelet transform capturesfundamental geometric and structural attributes of 3D objects. These attributesare instrumental in mitigating overfitting and improving the robustness of thelearned representations across diverse tasks and domains. To validate theeffectiveness of our RW-Net, we conduct extensive experiments on threedatasets: ModelNet40, ModelNet40-C, and ScanObjectNN for few-shot 3D objectclassification. The results demonstrate that our approach achievesstate-of-the-art performance and exhibits superior generalization androbustness in few-shot learning scenarios.</description><author>Haosheng Zhang, Hao Huang</author><pubDate>Mon, 06 Jan 2025 18:55:59 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.03221v1</guid></item><item><title>ProTracker: Probabilistic Integration for Robust and Accurate Point Tracking</title><link>http://arxiv.org/abs/2501.03220v1</link><description>In this paper, we propose ProTracker, a novel framework for robust andaccurate long-term dense tracking of arbitrary points in videos. The key ideaof our method is incorporating probabilistic integration to refine multiplepredictions from both optical flow and semantic features for robust short-termand long-term tracking. Specifically, we integrate optical flow estimations ina probabilistic manner, producing smooth and accurate trajectories bymaximizing the likelihood of each prediction. To effectively re-localizechallenging points that disappear and reappear due to occlusion, we furtherincorporate long-term feature correspondence into our flow predictions forcontinuous trajectory generation. Extensive experiments show that ProTrackerachieves the state-of-the-art performance among unsupervised andself-supervised approaches, and even outperforms supervised methods on severalbenchmarks. Our code and model will be publicly available upon publication.</description><author>Tingyang Zhang, Chen Wang, Zhiyang Dou, Qingzhe Gao, Jiahui Lei, Baoquan Chen, Lingjie Liu</author><pubDate>Mon, 06 Jan 2025 18:55:52 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.03220v1</guid></item><item><title>Dispider: Enabling Video LLMs with Active Real-Time Interaction via Disentangled Perception, Decision, and Reaction</title><link>http://arxiv.org/abs/2501.03218v1</link><description>Active Real-time interaction with video LLMs introduces a new paradigm forhuman-computer interaction, where the model not only understands user intentbut also responds while continuously processing streaming video on the fly.Unlike offline video LLMs, which analyze the entire video before answeringquestions, active real-time interaction requires three capabilities: 1)Perception: real-time video monitoring and interaction capturing. 2) Decision:raising proactive interaction in proper situations, 3) Reaction: continuousinteraction with users. However, inherent conflicts exist among the desiredcapabilities. The Decision and Reaction require a contrary Perception scale andgrain, and the autoregressive decoding blocks the real-time Perception andDecision during the Reaction. To unify the conflicted capabilities within aharmonious system, we present Dispider, a system that disentangles Perception,Decision, and Reaction. Dispider features a lightweight proactive streamingvideo processing module that tracks the video stream and identifies optimalmoments for interaction. Once the interaction is triggered, an asynchronousinteraction module provides detailed responses, while the processing modulecontinues to monitor the video in the meantime. Our disentangled andasynchronous design ensures timely, contextually accurate, and computationallyefficient responses, making Dispider ideal for active real-time interaction forlong-duration video streams. Experiments show that Dispider not only maintainsstrong performance in conventional video QA tasks, but also significantlysurpasses previous online models in streaming scenario responses, therebyvalidating the effectiveness of our architecture. The code and model arereleased at \url{https://github.com/Mark12Ding/Dispider}.</description><author>Rui Qian, Shuangrui Ding, Xiaoyi Dong, Pan Zhang, Yuhang Zang, Yuhang Cao, Dahua Lin, Jiaqi Wang</author><pubDate>Mon, 06 Jan 2025 18:55:10 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.03218v1</guid></item><item><title>Implications of Artificial Intelligence on Health Data Privacy and Confidentiality</title><link>http://arxiv.org/abs/2501.01639v2</link><description>The rapid integration of artificial intelligence (AI) in healthcare isrevolutionizing medical diagnostics, personalized medicine, and operationalefficiency. However, alongside these advancements, significant challenges ariseconcerning patient data privacy, ethical considerations, and regulatorycompliance. This paper examines the dual impact of AI on healthcare,highlighting its transformative potential and the critical need forsafeguarding sensitive health information. It explores the role of the HealthInsurance Portability and Accountability Act (HIPAA) as a regulatory frameworkfor ensuring data privacy and security, emphasizing the importance of robustsafeguards and ethical standards in AI-driven healthcare. Through case studies,including AI applications in diabetic retinopathy, oncology, and thecontroversies surrounding data sharing, this study underscores the ethical andlegal complexities of AI implementation. A balanced approach that fostersinnovation while maintaining patient trust and privacy is imperative. Thefindings emphasize the importance of continuous education, transparency, andadherence to regulatory frameworks to harness AI's full potential responsiblyand ethically in healthcare.</description><author>Ahmad Momani</author><pubDate>Mon, 06 Jan 2025 18:52:32 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.01639v2</guid></item><item><title>Autoregressive Image Diffusion: Generation of Image Sequence and Application in MRI</title><link>http://arxiv.org/abs/2405.14327v5</link><description>Magnetic resonance imaging (MRI) is a widely used non-invasive imagingmodality. However, a persistent challenge lies in balancing image quality withimaging speed. This trade-off is primarily constrained by k-space measurements,which traverse specific trajectories in the spatial Fourier domain (k-space).These measurements are often undersampled to shorten acquisition times,resulting in image artifacts and compromised quality. Generative models learnimage distributions and can be used to reconstruct high-quality images fromundersampled k-space data. In this work, we present the autoregressive imagediffusion (AID) model for image sequences and use it to sample the posteriorfor accelerated MRI reconstruction. The algorithm incorporates bothundersampled k-space and pre-existing information. Models trained with fastMRIdataset are evaluated comprehensively. The results show that the AID model canrobustly generate sequentially coherent image sequences. In MRI applications,the AID can outperform the standard diffusion model and reduce hallucinations,due to the learned inter-image dependencies. The project code is available athttps://github.com/mrirecon/aid.</description><author>Guanxiong Luo, Shoujin Huang, Martin Uecker</author><pubDate>Mon, 06 Jan 2025 18:50:35 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.14327v5</guid></item><item><title>Leveraging Explainable AI for LLM Text Attribution: Differentiating Human-Written and Multiple LLMs-Generated Text</title><link>http://arxiv.org/abs/2501.03212v1</link><description>The development of Generative AI Large Language Models (LLMs) raised thealarm regarding identifying content produced through generative AI or humans.In one case, issues arise when students heavily rely on such tools in a mannerthat can affect the development of their writing or coding skills. Other issuesof plagiarism also apply. This study aims to support efforts to detect andidentify textual content generated using LLM tools. We hypothesize thatLLMs-generated text is detectable by machine learning (ML), and investigate MLmodels that can recognize and differentiate texts generated by multiple LLMstools. We leverage several ML and Deep Learning (DL) algorithms such as RandomForest (RF), and Recurrent Neural Networks (RNN), and utilized ExplainableArtificial Intelligence (XAI) to understand the important features inattribution. Our method is divided into 1) binary classification todifferentiate between human-written and AI-text, and 2) multi classification,to differentiate between human-written text and the text generated by the fivedifferent LLM tools (ChatGPT, LLaMA, Google Bard, Claude, and Perplexity).Results show high accuracy in the multi and binary classification. Our modeloutperformed GPTZero with 98.5\% accuracy to 78.3\%. Notably, GPTZero wasunable to recognize about 4.2\% of the observations, but our model was able torecognize the complete test dataset. XAI results showed that understandingfeature importance across different classes enables detailed author/sourceprofiles. Further, aiding in attribution and supporting plagiarism detection byhighlighting unique stylistic and structural elements ensuring robust contentoriginality verification.</description><author>Ayat Najjar, Huthaifa I. Ashqar, Omar Darwish, Eman Hammad</author><pubDate>Mon, 06 Jan 2025 18:46:53 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.03212v1</guid></item><item><title>LASSE: Learning Active Sampling for Storm Tide Extremes in Non-Stationary Climate Regimes</title><link>http://arxiv.org/abs/2501.00149v2</link><description>Identifying tropical cyclones that generate destructive storm tides for riskassessment, such as from large downscaled storm catalogs for climate studies,is often intractable because it entails many expensive Monte Carlo hydrodynamicsimulations. Here, we show that surrogate models are promising from accuracy,recall, and precision perspectives, and they "generalize" to novel climatescenarios. We then present an informative online learning approach to rapidlysearch for extreme storm tide-producing cyclones using only a few hydrodynamicsimulations. Starting from a minimal subset of TCs with detailed storm tidehydrodynamic simulations, a surrogate model selects informative data to retrainonline and iteratively improves its predictions of damaging TCs. Results on anextensive catalog of downscaled TCs indicate 100% precision in retrieving raredestructive storms using less than 20% of the simulations as training. Theinformative sampling approach is efficient, scalable to large storm catalogs,and generalizable to climate scenarios.</description><author>Grace Jiang, Jiangchao Qiu, Sai Ravela</author><pubDate>Mon, 06 Jan 2025 18:46:25 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.00149v2</guid></item><item><title>Detecting AI-Generated Text in Educational Content: Leveraging Machine Learning and Explainable AI for Academic Integrity</title><link>http://arxiv.org/abs/2501.03203v1</link><description>This study seeks to enhance academic integrity by providing tools to detectAI-generated content in student work using advanced technologies. The findingspromote transparency and accountability, helping educators maintain ethicalstandards and supporting the responsible integration of AI in education. A keycontribution of this work is the generation of the CyberHumanAI dataset, whichhas 1000 observations, 500 of which are written by humans and the other 500produced by ChatGPT. We evaluate various machine learning (ML) and deeplearning (DL) algorithms on the CyberHumanAI dataset comparing human-writtenand AI-generated content from Large Language Models (LLMs) (i.e., ChatGPT).Results demonstrate that traditional ML algorithms, specifically XGBoost andRandom Forest, achieve high performance (83% and 81% accuracies respectively).Results also show that classifying shorter content seems to be more challengingthan classifying longer content. Further, using Explainable ArtificialIntelligence (XAI) we identify discriminative features influencing the MLmodel's predictions, where human-written content tends to use a practicallanguage (e.g., use and allow). Meanwhile AI-generated text is characterized bymore abstract and formal terms (e.g., realm and employ). Finally, a comparativeanalysis with GPTZero show that our narrowly focused, simple, and fine-tunedmodel can outperform generalized systems like GPTZero. The proposed modelachieved approximately 77.5% accuracy compared to GPTZero's 48.5% accuracy whentasked to classify Pure AI, Pure Human, and mixed class. GPTZero showed atendency to classify challenging and small-content cases as either mixed orunrecognized while our proposed model showed a more balanced performance acrossthe three classes.</description><author>Ayat A. Najjar, Huthaifa I. Ashqar, Omar A. Darwish, Eman Hammad</author><pubDate>Mon, 06 Jan 2025 18:34:20 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.03203v1</guid></item><item><title>The FACTS Grounding Leaderboard: Benchmarking LLMs' Ability to Ground Responses to Long-Form Input</title><link>http://arxiv.org/abs/2501.03200v1</link><description>We introduce FACTS Grounding, an online leaderboard and associated benchmarkthat evaluates language models' ability to generate text that is factuallyaccurate with respect to given context in the user prompt. In our benchmark,each prompt includes a user request and a full document, with a maximum lengthof 32k tokens, requiring long-form responses. The long-form responses arerequired to be fully grounded in the provided context document while fulfillingthe user request. Models are evaluated using automated judge models in twophases: (1) responses are disqualified if they do not fulfill the user request;(2) they are judged as accurate if the response is fully grounded in theprovided document. The automated judge models were comprehensively evaluatedagainst a held-out test-set to pick the best prompt template, and the finalfactuality score is an aggregate of multiple judge models to mitigateevaluation bias. The FACTS Grounding leaderboard will be actively maintainedover time, and contains both public and private splits to allow for externalparticipation while guarding the integrity of the leaderboard. It can be foundat https://www.kaggle.com/facts-leaderboard.</description><author>Alon Jacovi, Andrew Wang, Chris Alberti, Connie Tao, Jon Lipovetz, Kate Olszewska, Lukas Haas, Michelle Liu, Nate Keating, Adam Bloniarz, Carl Saroufim, Corey Fry, Dror Marcus, Doron Kukliansky, Gaurav Singh Tomar, James Swirhun, Jinwei Xing, Lily Wang, Madhu Gurumurthy, Michael Aaron, Moran Ambar, Rachana Fellinger, Rui Wang, Zizhao Zhang, Sasha Goldshtein, Dipanjan Das</author><pubDate>Mon, 06 Jan 2025 18:28:04 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.03200v1</guid></item><item><title>Scaling Efficient LLMs</title><link>http://arxiv.org/abs/2402.14746v2</link><description>Trained LLMs are typically sparse in that most of the parameters are zero,raising questions on efficiency. In response, we inquire into efficient LLMs,i.e. those with the fewest parameters that achieve the desired accuracy on atraining corpus. Specifically, we compare theoretical and empirical estimatesfor training loss to obtain upper and lower bounds on the number of uniquesequences in a natural training corpus as a function of its size. Our resultimplies (1) to double the number of skills represented in a training corpus,the corpus must scale roughly eighteen fold (2) for efficient LLMs, the numberof parameters N and the size D of a natural training corpus scale as $N \proptoD^{0.24} (3) if the number of parameters of an LLM is smaller than the numberof unique sequences in the training corpus, scaling up can uncover emergentskills.</description><author>B. N. Kausik</author><pubDate>Mon, 06 Jan 2025 18:25:13 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.14746v2</guid></item><item><title>Context Awareness Gate For Retrieval Augmented Generation</title><link>http://arxiv.org/abs/2411.16133v2</link><description>Retrieval Augmented Generation (RAG) has emerged as a widely adopted approachto mitigate the limitations of large language models (LLMs) in answeringdomain-specific questions. Previous research has predominantly focused onimproving the accuracy and quality of retrieved data chunks to enhance theoverall performance of the generation pipeline. However, despite ongoingadvancements, the critical issue of retrieving irrelevant information -- whichcan impair the ability of the model to utilize its internal knowledgeeffectively -- has received minimal attention. In this work, we investigate theimpact of retrieving irrelevant information in open-domain question answering,highlighting its significant detrimental effect on the quality of LLM outputs.To address this challenge, we propose the Context Awareness Gate (CAG)architecture, a novel mechanism that dynamically adjusts the LLMs' input promptbased on whether the user query necessitates external context retrieval.Additionally, we introduce the Vector Candidates method, a core mathematicalcomponent of CAG that is statistical, LLM-independent, and highly scalable. Wefurther examine the distributions of relationships between contexts andquestions, presenting a statistical analysis of these distributions. Thisanalysis can be leveraged to enhance the context retrieval process in RetrievalAugmented Generation (RAG) systems.</description><author>Mohammad Hassan Heydari, Arshia Hemmat, Erfan Naman, Afsaneh Fatemi</author><pubDate>Mon, 06 Jan 2025 18:23:41 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2411.16133v2</guid></item><item><title>An Open-source Sim2Real Approach for Sensor-independent Robot Navigation in a Grid</title><link>http://arxiv.org/abs/2411.03494v2</link><description>This paper presents a Sim2Real (Simulation to Reality) approach to bridge thegap between a trained agent in a simulated environment and its real-worldimplementation in navigating a robot in a similar setting. Specifically, wefocus on navigating a quadruped robot in a real-world grid-like environmentinspired by the Gymnasium Frozen Lake -- a highly user-friendly and freeApplication Programming Interface (API) to develop and test ReinforcementLearning (RL) algorithms. We detail the development of a pipeline to transfermotion policies learned in the Frozen Lake simulation to a physical quadrupedrobot, thus enabling autonomous navigation and obstacle avoidance in a gridwithout relying on expensive localization and mapping sensors. The workinvolves training an RL agent in the Frozen Lake environment and utilizing theresulting Q-table to control a 12 Degrees-of-Freedom (DOF) quadruped robot. Inaddition to detailing the RL implementation, inverse kinematics-based quadrupedgaits, and the transfer policy pipeline, we open-source the project on GitHuband include a demonstration video of our Sim2Real transfer approach. This workprovides an accessible, straightforward, and low-cost framework forresearchers, students, and hobbyists to explore and implement RL-based robotnavigation in real-world grid environments.</description><author>Murad Mehrab Abrar, Souryadeep Mondal, Michelle Hickner</author><pubDate>Mon, 06 Jan 2025 18:21:47 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2411.03494v2</guid></item><item><title>ICONS: Influence Consensus for Vision-Language Data Selection</title><link>http://arxiv.org/abs/2501.00654v2</link><description>Visual Instruction Tuning typically requires a large amount ofvision-language training data. This data often containing redundant informationthat increases computational costs without proportional performance gains. Inthis work, we introduce ICONS, a gradient-driven Influence CONsensus approachfor vision-language data Selection that selects a compact training dataset forefficient multi-task training. The key element of our approach is cross-taskinfluence consensus, which uses majority voting across task-specific influencematrices to identify samples that are consistently valuable across multipletasks, allowing us to effectively prioritize data that optimizes for overallperformance. Experiments show that models trained on our selected data (20% ofLLaVA-665K) achieve 98.6% of the relative performance obtained using the fulldataset. Additionally, we release this subset, LLaVA-ICONS-133K, a compact yethighly informative subset of LLaVA-665K visual instruction tuning data,preserving high impact training data for efficient vision-language modeldevelopment.</description><author>Xindi Wu, Mengzhou Xia, Rulin Shao, Zhiwei Deng, Pang Wei Koh, Olga Russakovsky</author><pubDate>Mon, 06 Jan 2025 18:17:30 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.00654v2</guid></item><item><title>Anomaly Detection in Large-Scale Cloud Systems: An Industry Case and Dataset</title><link>http://arxiv.org/abs/2411.09047v2</link><description>As Large-Scale Cloud Systems (LCS) become increasingly complex, effectiveanomaly detection is critical for ensuring system reliability and performance.However, there is a shortage of large-scale, real-world datasets available forbenchmarking anomaly detection methods. To address this gap, we introduce a new high-dimensional dataset from IBMCloud, collected over 4.5 months from the IBM Cloud Console. This datasetcomprises 39,365 rows and 117,448 columns of telemetry data. Additionally, wedemonstrate the application of machine learning models for anomaly detectionand discuss the key challenges faced in this process. This study and the accompanying dataset provide a resource for researchersand practitioners in cloud system monitoring. It facilitates more efficienttesting of anomaly detection methods in real-world data, helping to advance thedevelopment of robust solutions to maintain the health and performance oflarge-scale cloud infrastructures.</description><author>Mohammad Saiful Islam, Mohamed Sami Rakha, William Pourmajidi, Janakan Sivaloganathan, John Steinbacher, Andriy Miranskyy</author><pubDate>Mon, 06 Jan 2025 18:15:50 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2411.09047v2</guid></item><item><title>CLIX: Cross-Lingual Explanations of Idiomatic Expressions</title><link>http://arxiv.org/abs/2501.03191v1</link><description>Automated definition generation systems have been proposed to supportvocabulary expansion for language learners. The main barrier to the success ofthese systems is that learners often struggle to understand definitions due tothe presence of potentially unfamiliar words and grammar, particularly whennon-standard language is involved. To address these challenges, we proposeCLIX, the task of Cross-Lingual explanations of Idiomatic eXpressions. Weexplore the capabilities of current NLP models for this task, and observe thatwhile it remains challenging, large language models show promise. Finally, weperform a detailed error analysis to highlight the key challenges that need tobe addressed before we can reliably incorporate these systems into educationaltools.</description><author>Aaron Gluck, Katharina von der Wense, Maria Pacheco</author><pubDate>Mon, 06 Jan 2025 18:06:37 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.03191v1</guid></item><item><title>Multimodal Machine Learning Can Predict Videoconference Fluidity and Enjoyment</title><link>http://arxiv.org/abs/2501.03190v1</link><description>Videoconferencing is now a frequent mode of communication in bothprofessional and informal settings, yet it often lacks the fluidity andenjoyment of in-person conversation. This study leverages multimodal machinelearning to predict moments of negative experience in videoconferencing. Wesampled thousands of short clips from the RoomReader corpus, extracting audioembeddings, facial actions, and body motion features to train models foridentifying low conversational fluidity, low enjoyment, and classifyingconversational events (backchanneling, interruption, or gap). Our best modelsachieved an ROC-AUC of up to 0.87 on hold-out videoconference sessions, withdomain-general audio features proving most critical. This work demonstratesthat multimodal audio-video signals can effectively predict high-levelsubjective conversational outcomes. In addition, this is a contribution toresearch on videoconferencing user experience by showing that multimodalmachine learning can be used to identify rare moments of negative userexperience for further study or mitigation.</description><author>Andrew Chang, Viswadruth Akkaraju, Ray McFadden Cogliano, David Poeppel, Dustin Freeman</author><pubDate>Mon, 06 Jan 2025 18:05:35 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.03190v1</guid></item><item><title>Turn-based Multi-Agent Reinforcement Learning Model Checking</title><link>http://arxiv.org/abs/2501.03187v1</link><description>In this paper, we propose a novel approach for verifying the compliance ofturn-based multi-agent reinforcement learning (TMARL) agents with complexrequirements in stochastic multiplayer games. Our method overcomes thelimitations of existing verification approaches, which are inadequate fordealing with TMARL agents and not scalable to large games with multiple agents.Our approach relies on tight integration of TMARL and a verification techniquereferred to as model checking. We demonstrate the effectiveness and scalabilityof our technique through experiments in different types of environments. Ourexperiments show that our method is suited to verify TMARL agents and scalesbetter than naive monolithic model checking.</description><author>Dennis Gross</author><pubDate>Mon, 06 Jan 2025 18:04:20 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.03187v1</guid></item><item><title>Combinations of distributional regression algorithms with application in uncertainty estimation of corrected satellite precipitation products</title><link>http://arxiv.org/abs/2407.01623v2</link><description>To facilitate effective decision-making, precipitation datasets shouldinclude uncertainty estimates. Quantile regression with machine learning hasbeen proposed for issuing such estimates. Distributional regression offersdistinct advantages over quantile regression, including the ability to modelintermittency as well as a stronger ability to extrapolate beyond the trainingdata, which is critical for predicting extreme precipitation. Therefore, here,we introduce the concept of distributional regression in precipitation datasetcreation, specifically for the spatial prediction task of correcting satelliteprecipitation products. Building upon this concept, we formulated new ensemblelearning methods that can be valuable not only for spatial prediction but alsofor other prediction problems. These methods exploit conditional zero-adjustedprobability distributions estimated with generalized additive models forlocation, scale and shape (GAMLSS), spline-based GAMLSS and distributionalregression forests as well as their ensembles (stacking based on quantileregression and equal-weight averaging). To identify the most effective methodsfor our specific problem, we compared them to benchmarks using a large,multi-source precipitation dataset. Stacking was shown to be superior toindividual methods at most quantile levels when evaluated with the quantileloss function. Moreover, while the relative ranking of the methods variedacross different quantile levels, stacking methods, and to a lesser extent meancombiners, exhibited lower variance in their performance across differentquantiles compared to individual methods that occasionally ranked extremelylow. Overall, a task-specific combination of multiple distributional regressionalgorithms could yield significant benefits in terms of stability.</description><author>Georgia Papacharalampous, Hristos Tyralis, Nikolaos Doulamis, Anastasios Doulamis</author><pubDate>Mon, 06 Jan 2025 18:03:06 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.01623v2</guid></item><item><title>Noise-Robust Target-Speaker Voice Activity Detection Through Self-Supervised Pretraining</title><link>http://arxiv.org/abs/2501.03184v1</link><description>Target-Speaker Voice Activity Detection (TS-VAD) is the task of detecting thepresence of speech from a known target-speaker in an audio frame. Recently,deep neural network-based models have shown good performance in this task.However, training these models requires extensive labelled data, which iscostly and time-consuming to obtain, particularly if generalization to unseenenvironments is crucial. To mitigate this, we propose a causal, Self-SupervisedLearning (SSL) pretraining framework, called Denoising AutoregressivePredictive Coding (DN-APC), to enhance TS-VAD performance in noisy conditions.We also explore various speaker conditioning methods and evaluate theirperformance under different noisy conditions. Our experiments show that DN-APCimproves performance in noisy conditions, with a general improvement of approx.2% in both seen and unseen noise. Additionally, we find that FiLM conditioningprovides the best overall performance. Representation analysis via tSNE plotsreveals robust initial representations of speech and non-speech frompretraining. This underscores the effectiveness of SSL pretraining in improvingthe robustness and performance of TS-VAD models in noisy environments.</description><author>Holger Severin Bovbjerg, Jan Østergaard, Jesper Jensen, Zheng-Hua Tan</author><pubDate>Mon, 06 Jan 2025 18:00:14 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.03184v1</guid></item><item><title>LOLA -- An Open-Source Massively Multilingual Large Language Model</title><link>http://arxiv.org/abs/2409.11272v6</link><description>This paper presents LOLA, a massively multilingual large language modeltrained on more than 160 languages using a sparse Mixture-of-ExpertsTransformer architecture. Our architectural and implementation choices addressthe challenge of harnessing linguistic diversity while maintaining efficiencyand avoiding the common pitfalls of multilinguality. Our analysis of theevaluation results shows competitive performance in natural language generationand understanding tasks. Additionally, we demonstrate how the learnedexpert-routing mechanism exploits implicit phylogenetic linguistic patterns topotentially alleviate the curse of multilinguality. We provide an in-depth lookat the training process, an analysis of the datasets, and a balancedexploration of the model's strengths and limitations. As an open-source model,LOLA promotes reproducibility and serves as a robust foundation for futureresearch. Our findings enable the development of compute-efficient multilingualmodels with strong, scalable performance across languages.</description><author>Nikit Srivastava, Denis Kuchelev, Tatiana Moteu Ngoli, Kshitij Shetty, Michael Röder, Hamada Zahera, Diego Moussallem, Axel-Cyrille Ngonga Ngomo</author><pubDate>Mon, 06 Jan 2025 17:55:23 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2409.11272v6</guid></item><item><title>Scalable Forward-Forward Algorithm</title><link>http://arxiv.org/abs/2501.03176v1</link><description>We propose a scalable Forward-Forward (FF) algorithm that eliminates the needfor backpropagation by training each layer separately. Unlike backpropagation,FF avoids backward gradients and can be more modular and memory efficient,making it appealing for large networks. We extend FF to modern convolutionalarchitectures, such as MobileNetV3 and ResNet18, by introducing a new way tocompute losses for convolutional layers. Experiments show that our methodachieves performance comparable to standard backpropagation. Furthermore, whenwe divide the network into blocks, such as the residual blocks in ResNet, andapply backpropagation only within each block, but not across blocks, our hybriddesign tends to outperform backpropagation baselines while maintaining asimilar training speed. Finally, we present experiments on small datasets andtransfer learning that confirm the adaptability of our method.</description><author>Andrii Krutsylo</author><pubDate>Mon, 06 Jan 2025 17:49:00 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.03176v1</guid></item><item><title>QuArch: A Question-Answering Dataset for AI Agents in Computer Architecture</title><link>http://arxiv.org/abs/2501.01892v2</link><description>We introduce QuArch, a dataset of 1500 human-validated question-answer pairsdesigned to evaluate and enhance language models' understanding of computerarchitecture. The dataset covers areas including processor design, memorysystems, and performance optimization. Our analysis highlights a significantperformance gap: the best closed-source model achieves 84% accuracy, while thetop small open-source model reaches 72%. We observe notable struggles in memorysystems, interconnection networks, and benchmarking. Fine-tuning with QuArchimproves small model accuracy by up to 8%, establishing a foundation foradvancing AI-driven computer architecture research. The dataset and leaderboardare at https://harvard-edge.github.io/QuArch/.</description><author>Shvetank Prakash, Andrew Cheng, Jason Yik, Arya Tschand, Radhika Ghosal, Ikechukwu Uchendu, Jessica Quaye, Jeffrey Ma, Shreyas Grampurohit, Sofia Giannuzzi, Arnav Balyan, Fin Amin, Aadya Pipersenia, Yash Choudhary, Ankita Nayak, Amir Yazdanbakhsh, Vijay Janapa Reddi</author><pubDate>Mon, 06 Jan 2025 17:48:05 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.01892v2</guid></item><item><title>MObI: Multimodal Object Inpainting Using Diffusion Models</title><link>http://arxiv.org/abs/2501.03173v1</link><description>Safety-critical applications, such as autonomous driving, require extensivemultimodal data for rigorous testing. Methods based on synthetic data aregaining prominence due to the cost and complexity of gathering real-world databut require a high degree of realism and controllability in order to be useful.This paper introduces MObI, a novel framework for Multimodal Object Inpaintingthat leverages a diffusion model to create realistic and controllable objectinpaintings across perceptual modalities, demonstrated for both camera andlidar simultaneously. Using a single reference RGB image, MObI enables objectsto be seamlessly inserted into existing multimodal scenes at a 3D locationspecified by a bounding box, while maintaining semantic consistency andmultimodal coherence. Unlike traditional inpainting methods that rely solely onedit masks, our 3D bounding box conditioning gives objects accurate spatialpositioning and realistic scaling. As a result, our approach can be used toinsert novel objects flexibly into multimodal scenes, providing significantadvantages for testing perception models.</description><author>Alexandru Buburuzan, Anuj Sharma, John Redford, Puneet K. Dokania, Romain Mueller</author><pubDate>Mon, 06 Jan 2025 17:43:26 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.03173v1</guid></item><item><title>GLiREL -- Generalist Model for Zero-Shot Relation Extraction</title><link>http://arxiv.org/abs/2501.03172v1</link><description>We introduce GLiREL (Generalist Lightweight model for zero-shot RelationExtraction), an efficient architecture and training paradigm for zero-shotrelation classification. Inspired by recent advancements in zero-shot namedentity recognition, this work presents an approach to efficiently andaccurately predict zero-shot relationship labels between multiple entities in asingle forward pass. Experiments using the FewRel and WikiZSL benchmarksdemonstrate that our approach achieves state-of-the-art results on thezero-shot relation classification task. In addition, we contribute a protocolfor synthetically-generating datasets with diverse relation labels.</description><author>Jack Boylan, Chris Hokamp, Demian Gholipour Ghalandari</author><pubDate>Mon, 06 Jan 2025 17:42:29 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.03172v1</guid></item><item><title>The Two-Hop Curse: LLMs trained on A$\rightarrow$B, B$\rightarrow$C fail to learn A$\rightarrow$C</title><link>http://arxiv.org/abs/2411.16353v2</link><description>[Notice: This version is outdated. Recent research contradicts some keyclaims; we are working on a major revision with more nuanced analysis. Pleasewait for the updated version.] While LLMs excel at multi-hop questions (e.g. "Who is the spouse of theperformer of Imagine?") when using chain-of-thought reasoning (CoT), theystruggle when forced to reason internally (without CoT). Previous work on thesize and nature of this gap produced mixed evidence with inconclusive results.In this paper, we introduce a controlled setting for investigating two-hopreasoning in LLMs, where the above-chance performance constitutes undeniableevidence for latent reasoning. We fine-tune LLMs (including Llama 3 8B Instructand GPT-4o) on fictional facts and confirm that they generalize to answeringtwo-hop questions about them using CoT. We find that models can perform latentreasoning when facts appear together during training or in the prompt. However,to our surprise, models completely fail at two-hop reasoning without CoT whenlearned facts only appear in different documents, achieving chance-levelaccuracy and chance-level test loss. We call this complete failure to composeseparately learned facts the Two-Hop Curse. Moreover, we evaluate 9 frontierLLMs on real-world facts, finding that models completely fail at two-hop no-CoTreasoning for over half of question categories while maintaining partialsuccess with CoT across most categories. These results suggest that LLMs lack ageneral capability for latent multi-hop reasoning independent of the questiontype.</description><author>Mikita Balesni, Tomek Korbak, Owain Evans</author><pubDate>Mon, 06 Jan 2025 17:37:54 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2411.16353v2</guid></item><item><title>Semantic Captioning: Benchmark Dataset and Graph-Aware Few-Shot In-Context Learning for SQL2Text</title><link>http://arxiv.org/abs/2501.03166v1</link><description>Large Language Models (LLMs) have demonstrated remarkable performance invarious NLP tasks, including semantic parsing, which trans lates naturallanguage into formal code representations. However, the reverse process,translating code into natural language, termed semantic captioning, hasreceived less attention. This task is becoming increasingly important as LLMsare integrated into platforms for code generation, security analysis, andeducational purposes. In this paper, we focus on the captioning of SQL query(SQL2Text) to address the critical need for understanding and explaining SQLqueries in an era where LLM-generated code poses potential security risks. Werepurpose Text2SQL datasets for SQL2Text by introducing an iterative ICL promptusing GPT-4o to generate multiple additional utterances, which enhances therobustness of the datasets for the reverse task. We conduct our experimentsusing in-context learning (ICL) based on different sample selection methods,emphasizing smaller, more computationally efficient LLMs. Our findingsdemonstrate that leveraging the inherent graph properties of SQL for ICL sampleselection significantly outperforms random selection by up to 39% on BLEU scoreand provides better results than alternative methods. Dataset and codes arepublished: \url{https://github.com/aliwister/ast-icl}.</description><author>Ali Al-Lawati, Jason Lucas, Prasenjit Mitra</author><pubDate>Mon, 06 Jan 2025 17:36:09 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.03166v1</guid></item><item><title>Large Language Models for Market Research: A Data-augmentation Approach</title><link>http://arxiv.org/abs/2412.19363v2</link><description>Large Language Models (LLMs) have transformed artificial intelligence byexcelling in complex natural language processing tasks. Their ability togenerate human-like text has opened new possibilities for market research,particularly in conjoint analysis, where understanding consumer preferences isessential but often resource-intensive. Traditional survey-based methods facelimitations in scalability and cost, making LLM-generated data a promisingalternative. However, while LLMs have the potential to simulate real consumerbehavior, recent studies highlight a significant gap between LLM-generated andhuman data, with biases introduced when substituting between the two. In thispaper, we address this gap by proposing a novel statistical data augmentationapproach that efficiently integrates LLM-generated data with real data inconjoint analysis. Our method leverages transfer learning principles to debiasthe LLM-generated data using a small amount of human data. This results instatistically robust estimators with consistent and asymptotically normalproperties, in contrast to naive approaches that simply substitute human datawith LLM-generated data, which can exacerbate bias. We validate our frameworkthrough an empirical study on COVID-19 vaccine preferences, demonstrating itssuperior ability to reduce estimation error and save data and costs by 24.9% to79.8%. In contrast, naive approaches fail to save data due to the inherentbiases in LLM-generated data compared to human data. Another empirical study onsports car choices validates the robustness of our results. Our findingssuggest that while LLM-generated data is not a direct substitute for humanresponses, it can serve as a valuable complement when used within a robuststatistical framework.</description><author>Mengxin Wang, Dennis J. Zhang, Heng Zhang</author><pubDate>Mon, 06 Jan 2025 17:33:20 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.19363v2</guid></item><item><title>Deep-Relative-Trust-Based Diffusion for Decentralized Deep Learning</title><link>http://arxiv.org/abs/2501.03162v1</link><description>Decentralized learning strategies allow a collection of agents to learnefficiently from local data sets without the need for central aggregation ororchestration. Current decentralized learning paradigms typically rely on anaveraging mechanism to encourage agreement in the parameter space. We arguethat in the context of deep neural networks, which are oftenover-parameterized, encouraging consensus of the neural network outputs, asopposed to their parameters can be more appropriate. This motivates thedevelopment of a new decentralized learning algorithm, termed DRT diffusion,based on deep relative trust (DRT), a recently introduced similarity measurefor neural networks. We provide convergence analysis for the proposed strategy,and numerically establish its benefit to generalization, especially with sparsetopologies, in an image classification task.</description><author>Muyun Li, Aaron Fainman, Stefan Vlaski</author><pubDate>Mon, 06 Jan 2025 17:31:36 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.03162v1</guid></item><item><title>Segment Anything Model for Zero-shot Single Particle Tracking in Liquid Phase Transmission Electron Microscopy</title><link>http://arxiv.org/abs/2501.03153v1</link><description>Liquid phase transmission electron microscopy (LPTEM) offers an unparalleledcombination of spatial and temporal resolution, making it a promising tool forsingle particle tracking at the nanoscale. However, the absence of astandardized framework for identifying and tracking nanoparticles in noisyLPTEM videos has impeded progress in the field to develop this technique as asingle particle tracking tool. To address this, we leveraged Segment AnythingModel 2 (SAM 2), released by Meta, which is a foundation model developed forsegmenting videos and images. Here, we demonstrate that SAM 2 can successfullysegment LPTEM videos in a zero-shot manner and without requiring fine-tuning.Building on this capability, we introduce SAM4EM, a comprehensive frameworkthat integrates promptable video segmentation with particle tracking andstatistical analysis, providing an end-to-end LPTEM analysis framework forsingle particle tracking. SAM4EM achieves nearly 50-fold higher accuracy insegmenting and analyzing LPTEM videos compared to state-of-the-art methods,paving the way for broader applications of LPTEM in nanoscale imaging.</description><author>Risha Goel, Zain Shabeeb, Isabel Panicker, Vida Jamali</author><pubDate>Mon, 06 Jan 2025 17:19:27 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.03153v1</guid></item><item><title>The Scaling Law for LoRA Base on Mutual Information Upper Bound</title><link>http://arxiv.org/abs/2501.03152v1</link><description>LoRA (Low-Rank Adaptation) is a widely used model fine-tuning method. Infine-tuning, the law among model performance, model parameters, and datacomplexity has been a focal issue in the field. Existing methods often leverageexternal metrics (such as cross-entropy or perplexity) to evaluate modelperformance. In the fine-tuning process for large models, two types ofknowledge are typically involved: the frozen, general knowledge acquired by themodel during pre-training and the new knowledge learned through the LoRA modulefrom the current data. Generally, the less LoRA's learned knowledge relies onthe large model, the more it captures the specific knowledge of new data,thereby enhancing its adaptability to new tasks. However, external metrics donot readily capture the dependency relationship between these two types ofknowledge. Therefore, we designed an internal metric based on the MutualInformation Upper Bound (MIUB) theory to investigate the scaling law oflarge-model LoRA fine-tuning. In our experiments, we validated this approach onbenchmark datasets, using the Llama3-8B and Phi3-3B models. The results showthat the proposed MIUB metric aligns more accurately and stably with thescaling law of LoRA fine-tuning compared to cross-entropy and perplexity.</description><author>Jing Zhang, Hui Gao, Peng Zhang, Shuzhen Sun, Chang Yang, Yuexian Hou</author><pubDate>Mon, 06 Jan 2025 17:19:19 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.03152v1</guid></item><item><title>Large language models for artificial general intelligence (AGI): A survey of foundational principles and approaches</title><link>http://arxiv.org/abs/2501.03151v1</link><description>Generative artificial intelligence (AI) systems based on large-scalepretrained foundation models (PFMs) such as vision-language models, largelanguage models (LLMs), diffusion models and vision-language-action (VLA)models have demonstrated the ability to solve complex and truly non-trivial AIproblems in a wide variety of domains and contexts. Multimodal large languagemodels (MLLMs), in particular, learn from vast and diverse data sources,allowing rich and nuanced representations of the world and, thereby, providingextensive capabilities, including the ability to reason, engage in meaningfuldialog; collaborate with humans and other agents to jointly solve complexproblems; and understand social and emotional aspects of humans. Despite thisimpressive feat, the cognitive abilities of state-of-the-art LLMs trained onlarge-scale datasets are still superficial and brittle. Consequently, genericLLMs are severely limited in their generalist capabilities. A number offoundational problems -- embodiment, symbol grounding, causality and memory --are required to be addressed for LLMs to attain human-level generalintelligence. These concepts are more aligned with human cognition and provideLLMs with inherent human-like cognitive properties that support the realizationof physically-plausible, semantically meaningful, flexible and moregeneralizable knowledge and intelligence. In this work, we discuss theaforementioned foundational issues and survey state-of-the art approaches forimplementing these concepts in LLMs. Specifically, we discuss how theprinciples of embodiment, symbol grounding, causality and memory can beleveraged toward the attainment of artificial general intelligence (AGI) in anorganic manner.</description><author>Alhassan Mumuni, Fuseini Mumuni</author><pubDate>Mon, 06 Jan 2025 17:18:47 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.03151v1</guid></item><item><title>Geometry Restoration and Dewarping of Camera-Captured Document Images</title><link>http://arxiv.org/abs/2501.03145v1</link><description>This research focuses on developing a method for restoring the topology ofdigital images of paper documents captured by a camera, using algorithms fordetection, segmentation, geometry restoration, and dewarping. Our methodologyemploys deep learning (DL) for document outline detection, followed by computervision (CV) to create a topological 2D grid using cubic polynomialinterpolation and correct nonlinear distortions by remapping the image. Usingclassical CV methods makes the document topology restoration process moreefficient and faster, as it requires significantly fewer computationalresources and memory. We developed a new pipeline for automatic documentdewarping and reconstruction, along with a framework and annotated dataset todemonstrate its efficiency. Our experiments confirm the promise of ourmethodology and its superiority over existing benchmarks (including mobile appsand popular DL solutions, such as RectiNet, DocGeoNet, and DocTr++) bothvisually and in terms of document readability via Optical Character Recognition(OCR) and geometry restoration metrics. This paves the way for creatinghigh-quality digital copies of paper documents and enhancing the efficiency ofOCR systems. Project page: https://github.com/HorizonParadox/DRCCBI</description><author>Valery Istomin, Oleg Pereziabov, Ilya Afanasyev</author><pubDate>Mon, 06 Jan 2025 17:12:19 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.03145v1</guid></item><item><title>Co-Activation Graph Analysis of Safety-Verified and Explainable Deep Reinforcement Learning Policies</title><link>http://arxiv.org/abs/2501.03142v1</link><description>Deep reinforcement learning (RL) policies can demonstrate unsafe behaviorsand are challenging to interpret. To address these challenges, we combine RLpolicy model checking--a technique for determining whether RL policies exhibitunsafe behaviors--with co-activation graph analysis--a method that maps neuralnetwork inner workings by analyzing neuron activation patterns--to gain insightinto the safe RL policy's sequential decision-making. This combination lets usinterpret the RL policy's inner workings for safe decision-making. Wedemonstrate its applicability in various experiments.</description><author>Dennis Gross, Helge Spieker</author><pubDate>Mon, 06 Jan 2025 17:07:44 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.03142v1</guid></item><item><title>VicSim: Enhancing Victim Simulation with Emotional and Linguistic Fidelity</title><link>http://arxiv.org/abs/2501.03139v1</link><description>Scenario-based training has been widely adopted in many public servicesectors. Recent advancements in Large Language Models (LLMs) have shown promisein simulating diverse personas to create these training scenarios. However,little is known about how LLMs can be developed to simulate victims forscenario-based training purposes. In this paper, we introduce VicSim (victimsimulator), a novel model that addresses three key dimensions of usersimulation: informational faithfulness, emotional dynamics, and language style(e.g., grammar usage). We pioneer the integration of scenario-based victimmodeling with GAN-based training workflow and key-information-based prompting,aiming to enhance the realism of simulated victims. Our adversarial trainingapproach teaches the discriminator to recognize grammar and emotional cues asreliable indicators of synthetic content. According to evaluations by humanraters, the VicSim model outperforms GPT-4 in terms of human-likeness.</description><author>Yerong Li, Yiren Liu, Yun Huang</author><pubDate>Mon, 06 Jan 2025 17:01:45 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.03139v1</guid></item><item><title>Communication Bounds for the Distributed Experts Problem</title><link>http://arxiv.org/abs/2501.03132v1</link><description>In this work, we study the experts problem in the distributed setting wherean expert's cost needs to be aggregated across multiple servers. Our studyconsiders various communication models such as the message-passing model andthe broadcast model, along with multiple aggregation functions, such as summingand taking the $\ell_p$ norm of an expert's cost across servers. We propose thefirst communication-efficient protocols that achieve near-optimal regret inthese settings, even against a strong adversary who can choose the inputsadaptively. Additionally, we give a conditional lower bound showing that thecommunication of our protocols is nearly optimal. Finally, we implement ourprotocols and demonstrate empirical savings on the HPO-B benchmarks.</description><author>Zhihao Jia, Qi Pang, Trung Tran, David Woodruff, Zhihao Zhang, Wenting Zheng</author><pubDate>Mon, 06 Jan 2025 16:50:35 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.03132v1</guid></item><item><title>Are Your LLMs Capable of Stable Reasoning?</title><link>http://arxiv.org/abs/2412.13147v3</link><description>The rapid advancement of Large Language Models (LLMs) has demonstratedremarkable progress in complex reasoning tasks. However, a significantdiscrepancy persists between benchmark performances and real-worldapplications. We identify this gap as primarily stemming from currentevaluation protocols and metrics, which inadequately capture the full spectrumof LLM capabilities, particularly in complex reasoning tasks where bothaccuracy and consistency are crucial. This work makes two key contributions.First, we introduce G-Pass@k, a novel evaluation metric that provides acontinuous assessment of model performance across multiple sampling attempts,quantifying both the model's peak performance potential and its stability.Second, we present LiveMathBench, a dynamic benchmark comprising challenging,contemporary mathematical problems designed to minimize data leakage risksduring evaluation. Through extensive experiments using G-Pass@k onstate-of-the-art LLMs with LiveMathBench, we provide comprehensive insightsinto both their maximum capabilities and operational consistency. Our findingsreveal substantial room for improvement in LLMs' "realistic" reasoningcapabilities, highlighting the need for more robust evaluation methods. Thebenchmark and detailed results are available at:https://github.com/open-compass/GPassK.</description><author>Junnan Liu, Hongwei Liu, Linchen Xiao, Ziyi Wang, Kuikun Liu, Songyang Gao, Wenwei Zhang, Songyang Zhang, Kai Chen</author><pubDate>Mon, 06 Jan 2025 16:49:55 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.13147v3</guid></item><item><title>Learning DAGs and Root Causes from Time-Series Data</title><link>http://arxiv.org/abs/2501.03130v1</link><description>We introduce DAG-TFRC, a novel method for learning directed acyclic graphs(DAGs) from time series with few root causes. By this, we mean that the dataare generated by a small number of events at certain, unknown nodes and timepoints under a structural vector autoregression model. For such data, we (i)learn the DAGs representing both the instantaneous and time-lagged dependenciesbetween nodes, and (ii) discover the location and time of the root causes. Forsynthetic data with few root causes, DAG-TFRC shows superior performance inaccuracy and runtime over prior work, scaling up to thousands of nodes.Experiments on simulated and real-world financial data demonstrate theviability of our sparse root cause assumption. On S&amp;P 500 data, DAG-TFRCsuccessfully clusters stocks by sectors and discovers major stock movements asroot causes.</description><author>Panagiotis Misiakos, Markus Püschel</author><pubDate>Mon, 06 Jan 2025 16:48:30 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.03130v1</guid></item><item><title>Coarsened confounding for causal effects: a large-sample framework</title><link>http://arxiv.org/abs/2501.03129v1</link><description>There has been widespread use of causal inference methods for the rigorousanalysis of observational studies and to identify policy evaluations. In thisarticle, we consider coarsened exact matching, developed in Iacus et al.(2011). While they developed some statistical properties, in this article, westudy the approach using asymptotics based on a superpopulation inferentialframework. This methodology is generalized to what we termed as coarsenedconfounding, for which we propose two new algorithms. We develop asymptoticresults for the average causal effect estimator as well as providing conditionsfor consistency. In addition, we provide an asymptotic justification for thevariance formulae in Iacus et al. (2011). A bias correction technique isproposed, and we apply the proposed methodology to data from two well-knownobservational studi</description><author>Debashis Ghosh, Lei Wang</author><pubDate>Mon, 06 Jan 2025 16:47:24 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.03129v1</guid></item><item><title>SCRREAM : SCan, Register, REnder And Map:A Framework for Annotating Accurate and Dense 3D Indoor Scenes with a Benchmark</title><link>http://arxiv.org/abs/2410.22715v2</link><description>Traditionally, 3d indoor datasets have generally prioritized scale overground-truth accuracy in order to obtain improved generalization. However,using these datasets to evaluate dense geometry tasks, such as depth rendering,can be problematic as the meshes of the dataset are often incomplete and mayproduce wrong ground truth to evaluate the details. In this paper, we proposeSCRREAM, a dataset annotation framework that allows annotation of fully densemeshes of objects in the scene and registers camera poses on the real imagesequence, which can produce accurate ground truth for both sparse 3D as well asdense 3D tasks. We show the details of the dataset annotation pipeline andshowcase four possible variants of datasets that can be obtained from ourframework with example scenes, such as indoor reconstruction and SLAM, sceneediting &amp; object removal, human reconstruction and 6d pose estimation. Recentpipelines for indoor reconstruction and SLAM serve as new benchmarks. Incontrast to previous indoor dataset, our design allows to evaluate densegeometry tasks on eleven sample scenes against accurately rendered ground truthdepth maps.</description><author>HyunJun Jung, Weihang Li, Shun-Cheng Wu, William Bittner, Nikolas Brasch, Jifei Song, Eduardo Pérez-Pellitero, Zhensong Zhang, Arthur Moreau, Nassir Navab, Benjamin Busam</author><pubDate>Mon, 06 Jan 2025 16:43:05 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.22715v2</guid></item><item><title>Reinforcement Learning from Automatic Feedback for High-Quality Unit Test Generation</title><link>http://arxiv.org/abs/2310.02368v2</link><description>Software testing is a crucial aspect of software development, and thecreation of high-quality tests that adhere to best practices is essential foreffective maintenance. Recently, Large Language Models (LLMs) have gainedpopularity for code generation, including the automated creation of test cases.However, these LLMs are often trained on vast amounts of publicly availablecode, which may include test cases that do not adhere to best practices and mayeven contain test smells (anti-patterns). To address this issue, we propose anovel technique called Reinforcement Learning from Static Quality Metrics(RLSQM). To begin, we analyze the anti-patterns generated by the LLM and showthat LLMs can generate undesirable test smells. Thus, we train specific rewardmodels for each static quality metric, then utilize Proximal PolicyOptimization (PPO) to train models for optimizing a single quality metric at atime. Furthermore, we amalgamate these rewards into a unified reward modelaimed at capturing different best practices and quality aspects of tests. Bycomparing RL-trained models with those trained using supervised learning, weprovide insights into how reliably utilize RL to improve test generationquality and into the effects of various training strategies. Our experimentalresults demonstrate that the RL-optimized model consistently generatedhigh-quality test cases compared to the base LLM, improving the model by up to21%, and successfully generates nearly 100% syntactically correct code. RLSQMalso outperformed GPT-4 on four out of seven metrics. This represents asignificant step towards enhancing the overall efficiency and reliability ofsoftware testing through Reinforcement Learning and static quality metrics. Ourdata are available at https://figshare.com/s/ded476c8d4c221222849.</description><author>Benjamin Steenhoek, Michele Tufano, Neel Sundaresan, Alexey Svyatkovskiy</author><pubDate>Mon, 06 Jan 2025 16:41:09 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.02368v2</guid></item><item><title>The Z-Gromov-Wasserstein Distance</title><link>http://arxiv.org/abs/2408.08233v3</link><description>The Gromov-Wasserstein (GW) distance is a powerful tool for comparing metricmeasure spaces which has found broad applications in data science and machinelearning. Driven by the need to analyze datasets whose objects haveincreasingly complex structure (such as node and edge-attributed graphs),several variants of GW distance have been introduced in the recent literature.With a view toward establishing a general framework for the theory of GW-likedistances, this paper considers a vast generalization of the notion of a metricmeasure space: for an arbitrary metric space $Z$, we define a $Z$-network to bea measure space endowed with a kernel valued in $Z$. We introduce a method forcomparing $Z$-networks by defining a generalization of GW distance, which werefer to as $Z$-Gromov-Wasserstein ($Z$-GW) distance. This constructionsubsumes many previously known metrics and offers a unified approach tounderstanding their shared properties. This paper demonstrates that the $Z$-GWdistance defines a metric on the space of $Z$-networks which retains desirableproperties of $Z$, such as separability, completeness, and geodesicity. Many ofthese properties were unknown for existing variants of GW distance that fallunder our framework. Our focus is on foundational theory, but our results alsoinclude computable lower bounds and approximations of the distance which willbe useful for practical applications.</description><author>Martin Bauer, Facundo Mémoli, Tom Needham, Mao Nishino</author><pubDate>Mon, 06 Jan 2025 16:39:40 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.08233v3</guid></item><item><title>Parametric Matrix Models</title><link>http://arxiv.org/abs/2401.11694v6</link><description>We present a general class of machine learning algorithms called parametricmatrix models. In contrast with most existing machine learning models thatimitate the biology of neurons, parametric matrix models use matrix equationsthat emulate physical systems. Similar to how physics problems are usuallysolved, parametric matrix models learn the governing equations that lead to thedesired outputs. Parametric matrix models can be efficiently trained fromempirical data, and the equations may use algebraic, differential, or integralrelations. While originally designed for scientific computing, we prove thatparametric matrix models are universal function approximators that can beapplied to general machine learning problems. After introducing the underlyingtheory, we apply parametric matrix models to a series of different challengesthat show their performance for a wide range of problems. For all thechallenges tested here, parametric matrix models produce accurate resultswithin an efficient and interpretable computational framework that allows forinput feature extrapolation.</description><author>Patrick Cook, Danny Jammooa, Morten Hjorth-Jensen, Daniel D. Lee, Dean Lee</author><pubDate>Mon, 06 Jan 2025 16:38:37 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.11694v6</guid></item><item><title>ForecastBench: A Dynamic Benchmark of AI Forecasting Capabilities</title><link>http://arxiv.org/abs/2409.19839v4</link><description>Forecasts of future events are essential inputs into informeddecision-making. Machine learning (ML) systems have the potential to deliverforecasts at scale, but there is no framework for evaluating the accuracy of MLsystems on a standardized set of forecasting questions. To address this gap, weintroduce ForecastBench: a dynamic benchmark that evaluates the accuracy of MLsystems on an automatically generated and regularly updated set of 1,000forecasting questions. To avoid any possibility of data leakage, ForecastBenchis comprised solely of questions about future events that have no known answerat the time of submission. We quantify the capabilities of current ML systemsby collecting forecasts from expert (human) forecasters, the general public,and LLMs on a random subset of questions from the benchmark ($N=200$). WhileLLMs have achieved super-human performance on many benchmarks, they performless well here: expert forecasters outperform the top-performing LLM (p-value$&lt;0.01$). We display system and human scores in a public leaderboard atwww.forecastbench.org.</description><author>Ezra Karger, Houtan Bastani, Chen Yueh-Han, Zachary Jacobs, Danny Halawi, Fred Zhang, Philip E. Tetlock</author><pubDate>Mon, 06 Jan 2025 16:33:58 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2409.19839v4</guid></item><item><title>PRMBench: A Fine-grained and Challenging Benchmark for Process-Level Reward Models</title><link>http://arxiv.org/abs/2501.03124v1</link><description>Process-level Reward Models (PRMs) are crucial for complex reasoning anddecision-making tasks, where each intermediate step plays an important role inthe reasoning process. Since language models are prone to various types oferrors during the reasoning process, PRMs are required to possess nuancedcapabilities for detecting various implicit error types in real-worldscenarios. However, current benchmarks primarily focus on step correctness,failing to evaluate PRMs' performance systematically. To address this gap, weintroduce PRMBench, a process-level benchmark specifically designed to assessthe fine-grained error detection capabilities of PRMs. PRMBench comprises 6,216carefully designed problems and 83,456 step-level labels, evaluating modelsacross multiple dimensions, including simplicity, soundness, and sensitivity.In our experiments on 15 models, spanning both open-source PRMs andclosed-source large language models prompted as critic models, we uncoversignificant weaknesses in current PRMs. These findings underscore thechallenges inherent in process-level evaluation and highlight key directionsfor future research. We hope PRMBench can be a robust bench for advancingresearch on PRM evaluation and development.</description><author>Mingyang Song, Zhaochen Su, Xiaoye Qu, Jiawei Zhou, Yu Cheng</author><pubDate>Mon, 06 Jan 2025 16:31:45 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.03124v1</guid></item><item><title>Reinforcement Learning from Automatic Feedback for High-Quality Unit Test Generation</title><link>http://arxiv.org/abs/2412.14308v2</link><description>Software testing is a crucial but time-consuming aspect of softwaredevelopment, and recently, Large Language Models (LLMs) have gained popularityfor automated test case generation. However, because LLMs are trained on vastamounts of open-source code, they often generate test cases that do not adhereto best practices and may even contain test smells (anti-patterns). To addressthis issue, we propose Reinforcement Learning from Static Quality Metrics(RLSQM), wherein we utilize Reinforcement Learning to generate high-qualityunit tests based on static analysis-based quality metrics. First, we analyzedLLM-generated tests and show that LLMs frequently do generate undesirable testsmells -- up to 37% of the time. Then, we implemented lightweight staticanalysis-based reward model and trained LLMs using this reward model tooptimize for five code quality metrics. Our experimental results demonstratethat the RL-optimized Codex model consistently generated higher-quality testcases than the base LLM, improving quality metrics by up to 23%, and generatednearly 100% syntactically-correct code. RLSQM also outperformed GPT-4 on allcode quality metrics, in spite of training a substantially cheaper Codex model.We provide insights into how reliably utilize RL to improve test generationquality and show that RLSQM is a significant step towards enhancing the overallefficiency and reliability of automated software testing. Our data areavailable at https://doi.org/10.6084/m9.figshare.25983166.</description><author>Benjamin Steenhoek, Michele Tufano, Neel Sundaresan, Alexey Svyatkovskiy</author><pubDate>Mon, 06 Jan 2025 16:31:18 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.14308v2</guid></item><item><title>Lived Experience Not Found: LLMs Struggle to Align with Experts on Addressing Adverse Drug Reactions from Psychiatric Medication Use</title><link>http://arxiv.org/abs/2410.19155v2</link><description>Adverse Drug Reactions (ADRs) from psychiatric medications are the leadingcause of hospitalizations among mental health patients. With healthcare systemsand online communities facing limitations in resolving ADR-related issues,Large Language Models (LLMs) have the potential to fill this gap. Despite theincreasing capabilities of LLMs, past research has not explored theircapabilities in detecting ADRs related to psychiatric medications or inproviding effective harm reduction strategies. To address this, we introducethe Psych-ADR benchmark and the Adverse Drug Reaction Response Assessment(ADRA) framework to systematically evaluate LLM performance in detecting ADRexpressions and delivering expert-aligned mitigation strategies. Our analysesshow that LLMs struggle with understanding the nuances of ADRs anddifferentiating between types of ADRs. While LLMs align with experts in termsof expressed emotions and tone of the text, their responses are more complex,harder to read, and only 70.86% aligned with expert strategies. Furthermore,they provide less actionable advice by a margin of 12.32% on average. Our workprovides a comprehensive benchmark and evaluation framework for assessing LLMsin strategy-driven tasks within high-risk domains.</description><author>Mohit Chandra, Siddharth Sriraman, Gaurav Verma, Harneet Singh Khanuja, Jose Suarez Campayo, Zihang Li, Michael L. Birnbaum, Munmun De Choudhury</author><pubDate>Mon, 06 Jan 2025 16:30:35 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.19155v2</guid></item><item><title>Normalizing Batch Normalization for Long-Tailed Recognition</title><link>http://arxiv.org/abs/2501.03122v1</link><description>In real-world scenarios, the number of training samples across classesusually subjects to a long-tailed distribution. The conventionally trainednetwork may achieve unexpected inferior performance on the rare class comparedto the frequent class. Most previous works attempt to rectify the network biasfrom the data-level or from the classifier-level. Differently, in this paper,we identify that the bias towards the frequent class may be encoded intofeatures, i.e., the rare-specific features which play a key role indiscriminating the rare class are much weaker than the frequent-specificfeatures. Based on such an observation, we introduce a simple yet effectiveapproach, normalizing the parameters of Batch Normalization (BN) layer toexplicitly rectify the feature bias. To achieve this end, we represent theWeight/Bias parameters of a BN layer as a vector, normalize it into a unit oneand multiply the unit vector by a scalar learnable parameter. Throughdecoupling the direction and magnitude of parameters in BN layer to learn, theWeight/Bias exhibits a more balanced distribution and thus the strength offeatures becomes more even. Extensive experiments on various long-tailedrecognition benchmarks (i.e., CIFAR-10/100-LT, ImageNet-LT and iNaturalist2018) show that our method outperforms previous state-of-the-arts remarkably.The code and checkpoints are available at https://github.com/yuxiangbao/NBN.</description><author>Yuxiang Bao, Guoliang Kang, Linlin Yang, Xiaoyue Duan, Bo Zhao, Baochang Zhang</author><pubDate>Mon, 06 Jan 2025 16:29:46 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.03122v1</guid></item><item><title>Leveraging Large Language Models to Detect npm Malicious Packages</title><link>http://arxiv.org/abs/2403.12196v4</link><description>Existing malicious code detection techniques demand the integration ofmultiple tools to detect different malware patterns, often suffering from highmisclassification rates. Therefore, malicious code detection techniques couldbe enhanced by adopting advanced, more automated approaches to achieve highaccuracy and a low misclassification rate. The goal of this study is to aidsecurity analysts in detecting malicious packages by empirically studying theeffectiveness of Large Language Models (LLMs) in detecting malicious code. Wepresent SocketAI, a malicious code review workflow to detect malicious code. Toevaluate the effectiveness of SocketAI, we leverage a benchmark dataset of5,115 npm packages, of which 2,180 packages have malicious code. We conducted abaseline comparison of GPT-3 and GPT-4 models with the state-of-the-art CodeQLstatic analysis tool, using 39 custom CodeQL rules developed in prior researchto detect malicious Javascript code. We also compare the effectiveness ofstatic analysis as a pre-screener with SocketAI workflow, measuring the numberof files that need to be analyzed. and the associated costs. Additionally, weperformed a qualitative study to understand the types of malicious activitiesdetected or missed by our workflow. Our baseline comparison demonstrates a 16%and 9% improvement over static analysis in precision and F1 scores,respectively. GPT-4 achieves higher accuracy with 99% precision and 97% F1scores, while GPT-3 offers a more cost-effective balance at 91% precision and94% F1 scores. Pre-screening files with a static analyzer reduces the number offiles requiring LLM analysis by 77.9% and decreases costs by 60.9% for GPT-3and 76.1% for GPT-4. Our qualitative analysis identified data theft, executionof arbitrary code, and suspicious domain categories as the top detectedmalicious packages.</description><author>Nusrat Zahan, Philipp Burckhardt, Mikola Lysenko, Feross Aboukhadijeh, Laurie Williams</author><pubDate>Mon, 06 Jan 2025 16:29:32 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.12196v4</guid></item><item><title>CAT: Content-Adaptive Image Tokenization</title><link>http://arxiv.org/abs/2501.03120v1</link><description>Most existing image tokenizers encode images into a fixed number of tokens orpatches, overlooking the inherent variability in image complexity. To addressthis, we introduce Content-Adaptive Tokenizer (CAT), which dynamically adjustsrepresentation capacity based on the image content and encodes simpler imagesinto fewer tokens. We design a caption-based evaluation system that leverageslarge language models (LLMs) to predict content complexity and determine theoptimal compression ratio for a given image, taking into account factorscritical to human perception. Trained on images with diverse compressionratios, CAT demonstrates robust performance in image reconstruction. We alsoutilize its variable-length latent representations to train DiffusionTransformers (DiTs) for ImageNet generation. By optimizing token allocation,CAT improves the FID score over fixed-ratio baselines trained with the sameflops and boosts the inference throughput by 18.5%.</description><author>Junhong Shen, Kushal Tirumala, Michihiro Yasunaga, Ishan Misra, Luke Zettlemoyer, Lili Yu, Chunting Zhou</author><pubDate>Mon, 06 Jan 2025 16:28:47 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.03120v1</guid></item><item><title>From Models to Network Topologies: A Topology Inference Attack in Decentralized Federated Learning</title><link>http://arxiv.org/abs/2501.03119v1</link><description>Federated Learning (FL) is widely recognized as a privacy-preserving machinelearning paradigm due to its model-sharing mechanism that avoids direct dataexchange. However, model training inevitably leaves exploitable traces that canbe used to infer sensitive information. In Decentralized FL (DFL), the overlaytopology significantly influences its models' convergence, robustness, andsecurity. This study explores the feasibility of inferring the overlay topologyof DFL systems based solely on model behavior, introducing a novel TopologyInference Attack. A taxonomy of topology inference attacks is proposed,categorizing them by the attacker's capabilities and knowledge. Practicalattack strategies are developed for different scenarios, and quantitativeexperiments are conducted to identify key factors influencing the attackeffectiveness. Experimental results demonstrate that analyzing only the publicmodels of individual nodes can accurately infer the DFL topology, underscoringthe risk of sensitive information leakage in DFL systems. This finding offersvaluable insights for improving privacy preservation in decentralized learningenvironments.</description><author>Chao Feng, Yuanzhe Gao, Alberto Huertas Celdran, Gerome Bovet, Burkhard Stiller</author><pubDate>Mon, 06 Jan 2025 16:27:53 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.03119v1</guid></item><item><title>Cross-Dialect Information Retrieval: Information Access in Low-Resource and High-Variance Languages</title><link>http://arxiv.org/abs/2412.12806v2</link><description>A large amount of local and culture-specific knowledge (e.g., people,traditions, food) can only be found in documents written in dialects. Whilethere has been extensive research conducted on cross-lingual informationretrieval (CLIR), the field of cross-dialect retrieval (CDIR) has receivedlimited attention. Dialect retrieval poses unique challenges due to the limitedavailability of resources to train retrieval models and the high variability innon-standardized languages. We study these challenges on the example of Germandialects and introduce the first German dialect retrieval dataset, dubbedWikiDIR, which consists of seven German dialects extracted from Wikipedia.Using WikiDIR, we demonstrate the weakness of lexical methods in dealing withhigh lexical variation in dialects. We further show that commonly usedzero-shot cross-lingual transfer approach with multilingual encoders do nottransfer well to extremely low-resource setups, motivating the need forresource-lean and dialect-specific retrieval models. We finally demonstratethat (document) translation is an effective way to reduce the dialect gap inCDIR.</description><author>Robert Litschko, Oliver Kraus, Verena Blaschke, Barbara Plank</author><pubDate>Mon, 06 Jan 2025 16:27:27 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.12806v2</guid></item><item><title>Balancing Efficiency and Expressiveness: Subgraph GNNs with Walk-Based Centrality</title><link>http://arxiv.org/abs/2501.03113v1</link><description>We propose an expressive and efficient approach that combines the strengthsof two prominent extensions of Graph Neural Networks (GNNs): Subgraph GNNs andStructural Encodings (SEs). Our approach leverages walk-based centralitymeasures, both as a powerful form of SE and also as a subgraph selectionstrategy for Subgraph GNNs. By drawing a connection to perturbation analysis,we highlight the effectiveness of centrality-based sampling, and show itsignificantly reduces the computational burden associated with Subgraph GNNs.Further, we combine our efficient Subgraph GNN with SEs derived from thecalculated centrality and demonstrate this hybrid approach, dubbed HyMN, gainsin discriminative power. HyMN effectively addresses the expressivenesslimitations of Message Passing Neural Networks (MPNNs) while mitigating thecomputational costs of Subgraph GNNs. Through a series of experiments onsynthetic and real-world tasks, we show it outperforms other subgraph samplingapproaches while being competitive with full-bag Subgraph GNNs and otherstate-of-the-art approaches with a notably reduced runtime.</description><author>Joshua Southern, Yam Eitan, Guy Bar-Shalom, Michael Bronstein, Haggai Maron, Fabrizio Frasca</author><pubDate>Mon, 06 Jan 2025 16:20:54 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.03113v1</guid></item><item><title>LangFair: A Python Package for Assessing Bias and Fairness in Large Language Model Use Cases</title><link>http://arxiv.org/abs/2501.03112v1</link><description>Large Language Models (LLMs) have been observed to exhibit bias in numerousways, potentially creating or worsening outcomes for specific groups identifiedby protected attributes such as sex, race, sexual orientation, or age. To helpaddress this gap, we introduce LangFair, an open-source Python package thataims to equip LLM practitioners with the tools to evaluate bias and fairnessrisks relevant to their specific use cases. The package offers functionality toeasily generate evaluation datasets, comprised of LLM responses touse-case-specific prompts, and subsequently calculate applicable metrics forthe practitioner's use case. To guide in metric selection, LangFair offers anactionable decision framework.</description><author>Dylan Bouchard, Mohit Singh Chauhan, David Skarbrevik, Viren Bajaj, Zeya Ahmad</author><pubDate>Mon, 06 Jan 2025 16:20:44 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.03112v1</guid></item><item><title>FedEP: Tailoring Attention to Heterogeneous Data Distribution with Entropy Pooling for Decentralized Federated Learning</title><link>http://arxiv.org/abs/2410.07678v2</link><description>Non-Independent and Identically Distributed (non-IID) data in FederatedLearning (FL) causes client drift issues, leading to slower convergence andreduced model performance. While existing approaches mitigate this issue inCentralized FL (CFL) using a central server, Decentralized FL (DFL) remainsunderexplored. In DFL, the absence of a central entity results in nodesaccessing a global view of the federation, further intensifying the challengesof non-IID data. Drawing on the entropy pooling algorithm employed in financialcontexts to synthesize diverse investment opinions, this work proposes theFederated Entropy Pooling (FedEP) algorithm to mitigate the non-IID challengein DFL. FedEP leverages Gaussian Mixture Models (GMM) to fit local datadistributions, sharing statistical parameters among neighboring nodes toestimate the global distribution. Aggregation weights are determined using theentropy pooling approach between local and global distributions. By sharingonly synthetic distribution information, FedEP preserves data privacy whileminimizing communication overhead. Experimental results demonstrate that FedEPachieves faster convergence and outperforms state-of-the-art methods in variousnon-IID settings.</description><author>Chao Feng, Hongjie Guan, Alberto Huertas Celdrán, Jan von der Assen, Gérôme Bovet, Burkhard Stiller</author><pubDate>Mon, 06 Jan 2025 16:19:50 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.07678v2</guid></item><item><title>ETO:Efficient Transformer-based Local Feature Matching by Organizing Multiple Homography Hypotheses</title><link>http://arxiv.org/abs/2410.22733v3</link><description>We tackle the efficiency problem of learning local feature matching. Recentadvancements have given rise to purely CNN-based and transformer-basedapproaches, each augmented with deep learning techniques. While CNN-basedmethods often excel in matching speed, transformer-based methods tend toprovide more accurate matches. We propose an efficient transformer-basednetwork architecture for local feature matching. This technique is built onconstructing multiple homography hypotheses to approximate the continuouscorrespondence in the real world and uni-directional cross-attention toaccelerate the refinement. On the YFCC100M dataset, our matching accuracy iscompetitive with LoFTR, a state-of-the-art transformer-based architecture,while the inference speed is boosted to 4 times, even outperforming theCNN-based methods. Comprehensive evaluations on other open datasets such asMegadepth, ScanNet, and HPatches demonstrate our method's efficacy,highlighting its potential to significantly enhance a wide array of downstreamapplications.</description><author>Junjie Ni, Guofeng Zhang, Guanglin Li, Yijin Li, Xinyang Liu, Zhaoyang Huang, Hujun Bao</author><pubDate>Mon, 06 Jan 2025 16:19:15 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.22733v3</guid></item><item><title>Task-Agnostic Federated Learning</title><link>http://arxiv.org/abs/2406.17235v2</link><description>In the realm of medical imaging, leveraging large-scale datasets from variousinstitutions is crucial for developing precise deep learning models, yetprivacy concerns frequently impede data sharing. federated learning (FL)emerges as a prominent solution for preserving privacy while facilitatingcollaborative learning. However, its application in real-world scenarios facesseveral obstacles, such as task &amp; data heterogeneity, label scarcity,non-identically distributed (non-IID) data, computational vaiation, etc. Inreal-world, medical institutions may not want to disclose their tasks to FLserver and generalization challenge of out-of-network institutions with un-seentask want to join the on-going federated system. This study addresstask-agnostic and generalization problem on un-seen tasks by adaptingself-supervised FL framework. Utilizing Vision Transformer (ViT) as consensusfeature encoder for self-supervised pre-training, no initial labels required,the framework enabling effective representation learning across diversedatasets and tasks. Our extensive evaluations, using various real-world non-IIDmedical imaging datasets, validate our approach's efficacy, retaining 90\% ofF1 accuracy with only 5\% of the training data typically required forcentralized approaches and exhibiting superior adaptability toout-of-distribution task. The result indicate that federated learningarchitecture can be a potential approach toward multi-task foundation modeling.</description><author>Zhengtao Yao, Hong Nguyen, Ajitesh Srivastava, Jose Luis Ambite</author><pubDate>Mon, 06 Jan 2025 16:18:39 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.17235v2</guid></item><item><title>MVP: Multimodal Emotion Recognition based on Video and Physiological Signals</title><link>http://arxiv.org/abs/2501.03103v1</link><description>Human emotions entail a complex set of behavioral, physiological andcognitive changes. Current state-of-the-art models fuse the behavioral andphysiological components using classic machine learning, rather than recentdeep learning techniques. We propose to fill this gap, designing the Multimodalfor Video and Physio (MVP) architecture, streamlined to fuse video andphysiological signals. Differently then others approaches, MVP exploits thebenefits of attention to enable the use of long input sequences (1-2 minutes).We have studied video and physiological backbones for inputting long sequencesand evaluated our method with respect to the state-of-the-art. Our results showthat MVP outperforms former methods for emotion recognition based on facialvideos, EDA, and ECG/PPG.</description><author>Valeriya Strizhkova, Hadi Kachmar, Hava Chaptoukaev, Raphael Kalandadze, Natia Kukhilava, Tatia Tsmindashvili, Nibras Abo-Alzahab, Maria A. Zuluaga, Michal Balazia, Antitza Dantcheva, François Brémond, Laura Ferrari</author><pubDate>Mon, 06 Jan 2025 16:09:22 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.03103v1</guid></item><item><title>A Novel Structure-Agnostic Multi-Objective Approach for Weight-Sharing Compression in Deep Neural Networks</title><link>http://arxiv.org/abs/2501.03095v1</link><description>Deep neural networks suffer from storing millions and billions of weights inmemory post-training, making challenging memory-intensive models to deploy onembedded devices. The weight-sharing technique is one of the popularcompression approaches that use fewer weight values and share across specificconnections in the network. In this paper, we propose a multi-objectiveevolutionary algorithm (MOEA) based compression framework independent of neuralnetwork architecture, dimension, task, and dataset. We use uniformly sized binsto quantize network weights into a single codebook (lookup table) for efficientweight representation. Using MOEA, we search for Pareto optimal $k$ bins byoptimizing two objectives. Then, we apply the iterative merge technique tonon-dominated Pareto frontier solutions by combining neighboring bins withoutdegrading performance to decrease the number of bins and increase thecompression ratio. Our approach is model- and layer-independent, meaning theweights are mixed in the clusters from any layer, and the uniform quantizationmethod used in this work has $O(N)$ complexity instead of non-uniformquantization methods such as k-means with $O(Nkt)$ complexity. In addition, weuse the center of clusters as the shared weight values instead of retrainingshared weights, which is computationally expensive. The advantage of usingevolutionary multi-objective optimization is that it can obtain non-dominatedPareto frontier solutions with respect to performance and shared weights. Theexperimental results show that we can reduce the neural network memory by$13.72 \sim14.98 \times$ on CIFAR-10, $11.61 \sim 12.99\times$ on CIFAR-100,and $7.44 \sim 8.58\times$ on ImageNet showcasing the effectiveness of theproposed deep neural network compression framework.</description><author>Rasa Khosrowshahli, Shahryar Rahnamayan, Beatrice Ombuki-Berman</author><pubDate>Mon, 06 Jan 2025 15:51:29 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.03095v1</guid></item><item><title>RLCP: A Reinforcement Learning-based Copyright Protection Method for Text-to-Image Diffusion Model</title><link>http://arxiv.org/abs/2408.16634v3</link><description>The increasing sophistication of text-to-image generative models has led tocomplex challenges in defining and enforcing copyright infringement criteriaand protection. Existing methods, such as watermarking and datasetdeduplication, fail to provide comprehensive solutions due to the lack ofstandardized metrics and the inherent complexity of addressing copyrightinfringement in diffusion models. To deal with these challenges, we propose aReinforcement Learning-based Copyright Protection(RLCP) method forText-to-Image Diffusion Model, which minimizes the generation ofcopyright-infringing content while maintaining the quality of themodel-generated dataset. Our approach begins with the introduction of a novelcopyright metric grounded in copyright law and court precedents oninfringement. We then utilize the Denoising Diffusion Policy Optimization(DDPO) framework to guide the model through a multi-step decision-makingprocess, optimizing it using a reward function that incorporates our proposedcopyright metric. Additionally, we employ KL divergence as a regularizationterm to mitigate some failure modes and stabilize RL fine-tuning. Experimentsconducted on 3 mixed datasets of copyright and non-copyright images demonstratethat our approach significantly reduces copyright infringement risk whilemaintaining image quality.</description><author>Zhuan Shi, Jing Yan, Xiaoli Tang, Lingjuan Lyu, Boi Faltings</author><pubDate>Mon, 06 Jan 2025 15:48:07 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.16634v3</guid></item><item><title>Sentiment-guided Commonsense-aware Response Generation for Mental Health Counseling</title><link>http://arxiv.org/abs/2501.03088v1</link><description>The crisis of mental health issues is escalating. Effective counseling servesas a critical lifeline for individuals suffering from conditions like PTSD,stress, etc. Therapists forge a crucial therapeutic bond with clients, steeringthem towards positivity. Unfortunately, the massive shortage of professionals,high costs, and mental health stigma pose significant barriers to consultingtherapists. As a substitute, Virtual Mental Health Assistants (VMHAs) haveemerged in the digital healthcare space. However, most existing VMHAs lack thecommonsense to understand the nuanced sentiments of clients to generateeffective responses. To this end, we propose EmpRes, a novel sentiment-guidedmechanism incorporating commonsense awareness for generating responses. Byleveraging foundation models and harnessing commonsense knowledge, EmpRes aimsto generate responses that effectively shape the client's sentiment towardspositivity. We evaluate the performance of EmpRes on HOPE, a benchmarkcounseling dataset, and observe a remarkable performance improvement comparedto the existing baselines across a suite of qualitative and quantitativemetrics. Moreover, our extensive empirical analysis and human evaluation showthat the generation ability of EmpRes is well-suited and, in some cases,surpasses the gold standard. Further, we deploy EmpRes as a chat interface forusers seeking mental health support. We address the deployed system'seffectiveness through an exhaustive user study with a significant positiveresponse. Our findings show that 91% of users find the system effective, 80%express satisfaction, and over 85.45% convey a willingness to continue usingthe interface and recommend it to others, demonstrating the practicalapplicability of EmpRes in addressing the pressing challenges of mental healthsupport, emphasizing user feedback, and ethical considerations in a real-worldcontext.</description><author>Aseem Srivastava, Gauri Naik, Alison Cerezo, Tanmoy Chakraborty, Md. Shad Akhtar</author><pubDate>Mon, 06 Jan 2025 15:41:52 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.03088v1</guid></item><item><title>Synthetic Oversampling: Theory and A Practical Approach Using LLMs to Address Data Imbalance</title><link>http://arxiv.org/abs/2406.03628v2</link><description>Imbalanced classification and spurious correlation are common challenges indata science and machine learning. Both issues are linked to data imbalance,with certain groups of data samples significantly underrepresented, which inturn would compromise the accuracy, robustness and generalizability of thelearned models. Recent advances have proposed leveraging the flexibility andgenerative capabilities of large language models (LLMs), typically built ontransformer architectures, to generate synthetic samples and to augment theobserved data. In the context of imbalanced data, LLMs are used to oversampleunderrepresented groups and have shown promising improvements. However, thereis a clear lack of theoretical understanding of such synthetic data approaches.In this article, we develop novel theoretical foundations to systematicallystudy the roles of synthetic samples in addressing imbalanced classificationand spurious correlation. Specifically, we first explicitly quantify thebenefits of synthetic oversampling. Next, we analyze the scaling dynamics insynthetic data augmentation, and derive the corresponding scaling law. Finally,we demonstrate the capacity of transformer models to generate high-qualitysynthetic samples. We further conduct extensive numerical experiments tovalidate the efficacy of the LLM-based synthetic oversampling and augmentation.</description><author>Ryumei Nakada, Yichen Xu, Lexin Li, Linjun Zhang</author><pubDate>Mon, 06 Jan 2025 15:37:48 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.03628v2</guid></item><item><title>Personalized Fashion Recommendation with Image Attributes and Aesthetics Assessment</title><link>http://arxiv.org/abs/2501.03085v1</link><description>Personalized fashion recommendation is a difficult task because 1) thedecisions are highly correlated with users' aesthetic appetite, which previouswork frequently overlooks, and 2) many new items are constantly rolling outthat cause strict cold-start problems in the popular identity (ID)-basedrecommendation methods. These new items are critical to recommend because oftrend-driven consumerism. In this work, we aim to provide more accuratepersonalized fashion recommendations and solve the cold-start problem byconverting available information, especially images, into two attribute graphsfocusing on optimized image utilization and noise-reducing user modeling.Compared with previous methods that separate image and text as two components,the proposed method combines image and text information to create a richerattributes graph. Capitalizing on the advancement of large language and visionmodels, we experiment with extracting fine-grained attributes efficiently andas desired using two different prompts. Preliminary experiments on the IQON3000dataset have shown that the proposed method achieves competitive accuracycompared with baselines.</description><author>Chongxian Chen, Fan Mo, Xin Fan, Hayato Yamana</author><pubDate>Mon, 06 Jan 2025 15:31:10 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.03085v1</guid></item><item><title>Reconstruction vs. Generation: Taming Optimization Dilemma in Latent Diffusion Models</title><link>http://arxiv.org/abs/2501.01423v2</link><description>Latent diffusion models with Transformer architectures excel at generatinghigh-fidelity images. However, recent studies reveal an optimization dilemma inthis two-stage design: while increasing the per-token feature dimension invisual tokenizers improves reconstruction quality, it requires substantiallylarger diffusion models and more training iterations to achieve comparablegeneration performance. Consequently, existing systems often settle forsub-optimal solutions, either producing visual artifacts due to informationloss within tokenizers or failing to converge fully due to expensivecomputation costs. We argue that this dilemma stems from the inherentdifficulty in learning unconstrained high-dimensional latent spaces. To addressthis, we propose aligning the latent space with pre-trained vision foundationmodels when training the visual tokenizers. Our proposed VA-VAE (Visionfoundation model Aligned Variational AutoEncoder) significantly expands thereconstruction-generation frontier of latent diffusion models, enabling fasterconvergence of Diffusion Transformers (DiT) in high-dimensional latent spaces.To exploit the full potential of VA-VAE, we build an enhanced DiT baseline withimproved training strategies and architecture designs, termed LightningDiT. Theintegrated system achieves state-of-the-art (SOTA) performance on ImageNet256x256 generation with an FID score of 1.35 while demonstrating remarkabletraining efficiency by reaching an FID score of 2.11 in just 64epochs--representing an over 21 times convergence speedup compared to theoriginal DiT. Models and codes are available at:https://github.com/hustvl/LightningDiT.</description><author>Jingfeng Yao, Xinggang Wang</author><pubDate>Mon, 06 Jan 2025 15:28:11 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.01423v2</guid></item><item><title>Restore-RWKV: Efficient and Effective Medical Image Restoration with RWKV</title><link>http://arxiv.org/abs/2407.11087v3</link><description>Transformers have revolutionized medical image restoration, but the quadraticcomplexity still poses limitations for their application to high-resolutionmedical images. The recent advent of the Receptance Weighted Key Value (RWKV)model in the natural language processing field has attracted much attention dueto its ability to process long sequences efficiently. To leverage its advanceddesign, we propose Restore-RWKV, the first RWKV-based model for medical imagerestoration. Since the original RWKV model is designed for 1D sequences, wemake two necessary modifications for modeling spatial relations in 2D medicalimages. First, we present a recurrent WKV (Re-WKV) attention mechanism thatcaptures global dependencies with linear computational complexity. Re-WKVincorporates bidirectional attention as basic for a global receptive field andrecurrent attention to effectively model 2D dependencies from various scandirections. Second, we develop an omnidirectional token shift (Omni-Shift)layer that enhances local dependencies by shifting tokens from all directionsand across a wide context range. These adaptations make the proposedRestore-RWKV an efficient and effective model for medical image restoration.Even a lightweight variant of Restore-RWKV, with only 1.16 million parameters,achieves comparable or even superior results compared to existingstate-of-the-art (SOTA) methods. Extensive experiments demonstrate that theresulting Restore-RWKV achieves SOTA performance across a range of medicalimage restoration tasks, including PET image synthesis, CT image denoising, MRIimage super-resolution, and all-in-one medical image restoration. Code isavailable at: https://github.com/Yaziwel/Restore-RWKV.</description><author>Zhiwen Yang, Jiayin Li, Hui Zhang, Dan Zhao, Bingzheng Wei, Yan Xu</author><pubDate>Mon, 06 Jan 2025 15:27:33 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.11087v3</guid></item><item><title>TreeLearn: A deep learning method for segmenting individual trees from ground-based LiDAR forest point clouds</title><link>http://arxiv.org/abs/2309.08471v3</link><description>Laser-scanned point clouds of forests make it possible to extract valuableinformation for forest management. To consider single trees, a forest pointcloud needs to be segmented into individual tree point clouds. Existingsegmentation methods are usually based on hand-crafted algorithms, such asidentifying trunks and growing trees from them, and face difficulties in denseforests with overlapping tree crowns. In this study, we propose TreeLearn, adeep learning-based approach for tree instance segmentation of forest pointclouds. TreeLearn is trained on already segmented point clouds in a data-drivenmanner, making it less reliant on predefined features and algorithms.Furthermore, TreeLearn is implemented as a fully automatic pipeline and doesnot rely on extensive hyperparameter tuning, which makes it easy to use.Additionally, we introduce a new manually segmented benchmark forest datasetcontaining 156 full trees. The data is generated by mobile laser scanning andcontributes to create a larger and more diverse data basis for modeldevelopment and fine-grained instance segmentation evaluation. We trainedTreeLearn on forest point clouds of 6665 trees, labeled using the Lidar360software. An evaluation on the benchmark dataset shows that TreeLearn performsas well as the algorithm used to generate its training data. Furthermore, theperformance can be vastly improved by fine-tuning the model using manuallyannotated datasets. We evaluate TreeLearn on our benchmark dataset and theWytham Woods dataset, outperforming the recent SegmentAnyTree, ForAINet andTLS2Trees methods. The TreeLearn code and all datasets that were created in thecourse of this work are made publicly available.</description><author>Jonathan Henrich, Jan van Delden, Dominik Seidel, Thomas Kneib, Alexander Ecker</author><pubDate>Mon, 06 Jan 2025 15:26:26 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2309.08471v3</guid></item><item><title>Qinco2: Vector Compression and Search with Improved Implicit Neural Codebooks</title><link>http://arxiv.org/abs/2501.03078v1</link><description>Vector quantization is a fundamental technique for compression andlarge-scale nearest neighbor search. For high-accuracy operating points,multi-codebook quantization associates data vectors with one element from eachof multiple codebooks. An example is residual quantization (RQ), whichiteratively quantizes the residual error of previous steps. Dependenciesbetween the different parts of the code are, however, ignored in RQ, whichleads to suboptimal rate-distortion performance. QINCo recently addressed thisinefficiency by using a neural network to determine the quantization codebookin RQ based on the vector reconstruction from previous steps. In this paper weintroduce QINCo2 which extends and improves QINCo with (i) improved vectorencoding using codeword pre-selection and beam-search, (ii) a fast approximatedecoder leveraging codeword pairs to establish accurate short-lists for search,and (iii) an optimized training procedure and network architecture. We conductexperiments on four datasets to evaluate QINCo2 for vector compression andbillion-scale nearest neighbor search. We obtain outstanding results in bothsettings, improving the state-of-the-art reconstruction MSE by 34% for 16-bytevector compression on BigANN, and search accuracy by 24% with 8-byte encodingson Deep1M.</description><author>Théophane Vallaeys, Matthew Muckley, Jakob Verbeek, Matthijs Douze</author><pubDate>Mon, 06 Jan 2025 15:20:22 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.03078v1</guid></item><item><title>AIF-SFDA: Autonomous Information Filter-driven Source-Free Domain Adaptation for Medical Image Segmentation</title><link>http://arxiv.org/abs/2501.03074v1</link><description>Decoupling domain-variant information (DVI) from domain-invariant information(DII) serves as a prominent strategy for mitigating domain shifts in thepractical implementation of deep learning algorithms. However, in medicalsettings, concerns surrounding data collection and privacy often restrictaccess to both training and test data, hindering the empirical decoupling ofinformation by existing methods. To tackle this issue, we propose an AutonomousInformation Filter-driven Source-free Domain Adaptation (AIF-SFDA) algorithm,which leverages a frequency-based learnable information filter to autonomouslydecouple DVI and DII. Information Bottleneck (IB) and Self-supervision (SS) areincorporated to optimize the learnable frequency filter. The IB governs theinformation flow within the filter to diminish redundant DVI, while SSpreserves DII in alignment with the specific task and image modality. Thus, theautonomous information filter can overcome domain shifts relying solely ontarget data. A series of experiments covering various medical image modalitiesand segmentation tasks were conducted to demonstrate the benefits of AIF-SFDAthrough comparisons with leading algorithms and ablation studies. The code isavailable at https://github.com/JingHuaMan/AIF-SFDA.</description><author>Haojin Li, Heng Li, Jianyu Chen, Rihan Zhong, Ke Niu, Huazhu Fu, Jiang Liu</author><pubDate>Mon, 06 Jan 2025 15:11:24 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.03074v1</guid></item><item><title>Pathway to Secure and Trustworthy ZSM for LLMs: Attacks, Defense, and Opportunities</title><link>http://arxiv.org/abs/2408.00722v2</link><description>Recently, large language models (LLMs) have been gaining a lot of interestdue to their adaptability and extensibility in emerging applications, includingcommunication networks. It is anticipated that ZSM networks will be able tosupport LLMs as a service, as they provide ultra reliable low-latencycommunications and closed loop massive connectivity. However, LLMs arevulnerable to data and model privacy issues that affect the trustworthiness ofLLMs to be deployed for user-based services. In this paper, we explore thesecurity vulnerabilities associated with fine-tuning LLMs in ZSM networks, inparticular the membership inference attack. We define the characteristics of anattack network that can perform a membership inference attack if the attackerhas access to the fine-tuned model for the downstream task. We show that themembership inference attacks are effective for any downstream task, which canlead to a personal data breach when using LLM as a service. The experimentalresults show that the attack success rate of maximum 92% can be achieved onnamed entity recognition task. Based on the experimental analysis, we discusspossible defense mechanisms and present possible research directions to makethe LLMs more trustworthy in the context of ZSM networks.</description><author>Sunder Ali Khowaja, Parus Khuwaja, Kapal Dev, Hussam Al Hamadi, Engin Zeydan</author><pubDate>Mon, 06 Jan 2025 15:09:06 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.00722v2</guid></item><item><title>Slim multi-scale convolutional autoencoder-based reduced-order models for interpretable features of a complex dynamical system</title><link>http://arxiv.org/abs/2501.03070v1</link><description>In recent years, data-driven deep learning models have gained significantinterest in the analysis of turbulent dynamical systems. Within the context ofreduced-order models (ROMs), convolutional autoencoders (CAEs) pose auniversally applicable alternative to conventional approaches. They can learnnonlinear transformations directly from data, without prior knowledge of thesystem. However, the features generated by such models lack interpretability.Thus, the resulting model is a black-box which effectively reduces thecomplexity of the system, but does not provide insights into the meaning of thelatent features. To address this critical issue, we introduce a novelinterpretable CAE approach for high-dimensional fluid flow data that maintainsthe reconstruction quality of conventional CAEs and allows for featureinterpretation. Our method can be easily integrated into any existing CAEarchitecture with minor modifications of the training process. We compare ourapproach to Proper Orthogonal Decomposition (POD) and two existing methods forinterpretable CAEs. We apply all methods to three different experimentalturbulent Rayleigh-B\'enard convection datasets with varying complexity. Ourresults show that the proposed method is lightweight, easy to train, andachieves relative reconstruction performance improvements of up to 6.4% overPOD for 64 modes. The relative improvement increases to up to 229.8% as thenumber of modes decreases. Additionally, our method delivers interpretablefeatures similar to those of POD and is significantly less resource-intensivethan existing CAE approaches, using less than 2% of the parameters. Theseapproaches either trade interpretability for reconstruction performance or onlyprovide interpretability to a limited extend.</description><author>Philipp Teutsch, Philipp Pfeffer, Mohammad Sharifi Ghazijahani, Christian Cierpka, Jörg Schumacher, Patrick Mäder</author><pubDate>Mon, 06 Jan 2025 15:06:07 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.03070v1</guid></item><item><title>Trust Modeling in Counseling Conversations: A Benchmark Study</title><link>http://arxiv.org/abs/2501.03064v1</link><description>In mental health counseling, a variety of earlier studies have focused ondialogue modeling. However, most of these studies give limited to no emphasison the quality of interaction between a patient and a therapist. Thetherapeutic bond between a patient and a therapist directly correlates witheffective mental health counseling. It involves developing the patient's truston the therapist over the course of counseling. To assess the therapeutic bondin counseling, we introduce trust as a therapist-assistive metric. Ourdefinition of trust involves patients' willingness and openness to expressthemselves and, consequently, receive better care. We conceptualize it as adynamic trajectory observable through textual interactions during thecounseling. To facilitate trust modeling, we present MENTAL-TRUST, a novelcounseling dataset comprising manual annotation of 212 counseling sessions withfirst-of-its-kind seven expert-verified ordinal trust levels. We project ourproblem statement as an ordinal classification task for trust quantificationand propose a new benchmark, TrustBench, comprising a suite of classical andstate-of-the-art language models on MENTAL-TRUST. We evaluate the performanceacross a suite of metrics and lay out an exhaustive set of findings. Our studyaims to unfold how trust evolves in therapeutic interactions.</description><author>Aseem Srivastava, Zuhair Hasan Shaik, Tanmoy Chakraborty, Md Shad Akhtar</author><pubDate>Mon, 06 Jan 2025 15:02:30 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.03064v1</guid></item><item><title>Scale-wise Bidirectional Alignment Network for Referring Remote Sensing Image Segmentation</title><link>http://arxiv.org/abs/2501.00851v2</link><description>The goal of referring remote sensing image segmentation (RRSIS) is to extractspecific pixel-level regions within an aerial image via a natural languageexpression. Recent advancements, particularly Transformer-based fusion designs,have demonstrated remarkable progress in this domain. However, existing methodsprimarily focus on refining visual features using language-aware guidanceduring the cross-modal fusion stage, neglecting the complementaryvision-to-language flow. This limitation often leads to irrelevant orsuboptimal representations. In addition, the diverse spatial scales of groundobjects in aerial images pose significant challenges to the visual perceptioncapabilities of existing models when conditioned on textual inputs. In thispaper, we propose an innovative framework called Scale-wise BidirectionalAlignment Network (SBANet) to address these challenges for RRSIS. Specifically,we design a Bidirectional Alignment Module (BAM) with learnable query tokens toselectively and effectively represent visual and linguistic features,emphasizing regions associated with key tokens. BAM is further enhanced with adynamic feature selection block, designed to provide both macro- andmicro-level visual features, preserving global context and local details tofacilitate more effective cross-modal interaction. Furthermore, SBANetincorporates a text-conditioned channel and spatial aggregator to bridge thegap between the encoder and decoder, enhancing cross-scale information exchangein complex aerial scenarios. Extensive experiments demonstrate that ourproposed method achieves superior performance in comparison to previousstate-of-the-art methods on the RRSIS-D and RefSegRS datasets, bothquantitatively and qualitatively. The code will be released after publication.</description><author>Kun Li, George Vosselman, Michael Ying Yang</author><pubDate>Mon, 06 Jan 2025 14:49:47 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.00851v2</guid></item><item><title>Through-The-Mask: Mask-based Motion Trajectories for Image-to-Video Generation</title><link>http://arxiv.org/abs/2501.03059v1</link><description>We consider the task of Image-to-Video (I2V) generation, which involvestransforming static images into realistic video sequences based on a textualdescription. While recent advancements produce photorealistic outputs, theyfrequently struggle to create videos with accurate and consistent objectmotion, especially in multi-object scenarios. To address these limitations, wepropose a two-stage compositional framework that decomposes I2V generationinto: (i) An explicit intermediate representation generation stage, followed by(ii) A video generation stage that is conditioned on this representation. Ourkey innovation is the introduction of a mask-based motion trajectory as anintermediate representation, that captures both semantic object information andmotion, enabling an expressive but compact representation of motion andsemantics. To incorporate the learned representation in the second stage, weutilize object-level attention objectives. Specifically, we consider a spatial,per-object, masked-cross attention objective, integrating object-specificprompts into corresponding latent space regions and a masked spatio-temporalself-attention objective, ensuring frame-to-frame consistency for each object.We evaluate our method on challenging benchmarks with multi-object andhigh-motion scenarios and empirically demonstrate that the proposed methodachieves state-of-the-art results in temporal coherence, motion realism, andtext-prompt faithfulness. Additionally, we introduce \benchmark, a newchallenging benchmark for single-object and multi-object I2V generation, anddemonstrate our method's superiority on this benchmark. Project page isavailable at https://guyyariv.github.io/TTM/.</description><author>Guy Yariv, Yuval Kirstain, Amit Zohar, Shelly Sheynin, Yaniv Taigman, Yossi Adi, Sagie Benaim, Adam Polyak</author><pubDate>Mon, 06 Jan 2025 14:49:26 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.03059v1</guid></item><item><title>Survival Analysis Revisited: Understanding and Unifying Poisson, Exponential, and Cox Models in Fall Risk Analysis</title><link>http://arxiv.org/abs/2501.03058v1</link><description>This paper explores foundational and applied aspects of survival analysis,using fall risk assessment as a case study. It revisits key time-relatedprobability distributions and statistical methods, including logisticregression, Poisson regression, Exponential regression, and the CoxProportional Hazards model, offering a unified perspective on theirrelationships within the survival analysis framework. A contribution of thiswork is the step-by-step derivation and clarification of the relationshipsamong these models, particularly demonstrating that Poisson regression in thesurvival context is a specific case of the Cox model. These insights addressgaps in understanding and reinforce the simplicity and interpretability ofsurvival models. The paper also emphasizes the practical utility of survivalanalysis by connecting theoretical insights with real-world applications. Inthe context of fall detection, it demonstrates how these models cansimultaneously predict fall risk, analyze contributing factors, and estimatetime-to-event outcomes within a single streamlined framework. In contrast,advanced deep learning methods often require complex post-hoc interpretationand separate training for different tasks particularly when working withstructured numerical data. This highlights the enduring relevance of classicalstatistical frameworks and makes survival models especially valuable inhealthcare settings, where explainability and robustness are critical. Byunifying foundational concepts and offering a cohesive perspective ontime-to-event analysis, this work serves as an accessible resource forunderstanding survival models and applying them effectively to diverseanalytical challenges.</description><author>Tianhua Chen</author><pubDate>Mon, 06 Jan 2025 14:48:30 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.03058v1</guid></item><item><title>Generating Counterfactual Trajectories with Latent Diffusion Models for Concept Discovery</title><link>http://arxiv.org/abs/2404.10356v2</link><description>Trustworthiness is a major prerequisite for the safe application of opaquedeep learning models in high-stakes domains like medicine. Understanding thedecision-making process not only contributes to fostering trust but might alsoreveal previously unknown decision criteria of complex models that couldadvance the state of medical research. The discovery of decision-relevantconcepts from black box models is a particularly challenging task. This studyproposes Concept Discovery through Latent Diffusion-based CounterfactualTrajectories (CDCT), a novel three-step framework for concept discoveryleveraging the superior image synthesis capabilities of diffusion models. Inthe first step, CDCT uses a Latent Diffusion Model (LDM) to generate acounterfactual trajectory dataset. This dataset is used to derive adisentangled representation of classification-relevant concepts using aVariational Autoencoder (VAE). Finally, a search algorithm is applied toidentify relevant concepts in the disentangled latent space. The application ofCDCT to a classifier trained on the largest public skin lesion dataset revealednot only the presence of several biases but also meaningful biomarkers.Moreover, the counterfactuals generated within CDCT show better FID scores thanthose produced by a previously established state-of-the-art method, while being12 times more resource-efficient. Unsupervised concept discovery holds greatpotential for the application of trustworthy AI and the further development ofhuman knowledge in various domains. CDCT represents a further step in thisdirection.</description><author>Payal Varshney, Adriano Lucieri, Christoph Balada, Andreas Dengel, Sheraz Ahmed</author><pubDate>Mon, 06 Jan 2025 14:47:53 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.10356v2</guid></item><item><title>RA-PbRL: Provably Efficient Risk-Aware Preference-Based Reinforcement Learning</title><link>http://arxiv.org/abs/2410.23569v3</link><description>Reinforcement Learning from Human Feedback (RLHF) has recently surged inpopularity, particularly for aligning large language models and other AIsystems with human intentions. At its core, RLHF can be viewed as a specializedinstance of Preference-based Reinforcement Learning (PbRL), where thepreferences specifically originate from human judgments rather than arbitraryevaluators. Despite this connection, most existing approaches in both RLHF andPbRL primarily focus on optimizing a mean reward objective, neglectingscenarios that necessitate risk-awareness, such as AI safety, healthcare, andautonomous driving. These scenarios often operate under a one-episode-rewardsetting, which makes conventional risk-sensitive objectives inapplicable. Toaddress this, we explore and prove the applicability of two risk-awareobjectives to PbRL : nested and static quantile risk objectives. We alsointroduce Risk-AwarePbRL (RA-PbRL), an algorithm designed to optimize bothnested and static objectives. Additionally, we provide a theoretical analysisof the regret upper bounds, demonstrating that they are sublinear with respectto the number of episodes, and present empirical results to support ourfindings. Our code is available inhttps://github.com/aguilarjose11/PbRLNeurips.</description><author>Yujie Zhao, Jose Efraim Aguilar Escamill, Weyl Lu, Huazheng Wang</author><pubDate>Mon, 06 Jan 2025 14:44:55 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.23569v3</guid></item><item><title>Theoretical Foundations of Deep Selective State-Space Models</title><link>http://arxiv.org/abs/2402.19047v4</link><description>Structured state-space models (SSMs) such as S4, stemming from the seminalwork of Gu et al., are gaining popularity as effective approaches for modelingsequential data. Deep SSMs demonstrate outstanding performance across a diverseset of domains, at a reduced training and inference cost compared toattention-based transformers. Recent developments show that if the linearrecurrence powering SSMs allows for multiplicative interactions between inputsand hidden states (e.g. GateLoop, Mamba, GLA), then the resulting architecturecan surpass in both in accuracy and efficiency attention-powered foundationmodels trained on text, at scales of billion parameters. In this paper, we givetheoretical grounding to this recent finding using tools from Rough PathTheory: we show that when random linear recurrences are equipped with simpleinput-controlled transitions (selectivity mechanism), then the hidden state isprovably a low-dimensional projection of a powerful mathematical object calledthe signature of the input -- capturing non-linear interactions between tokensat distinct timescales. Our theory not only motivates the success of modernselective state-space models such as Mamba but also provides a solid frameworkto understand the expressive power of future SSM variants.</description><author>Nicola Muca Cirone, Antonio Orvieto, Benjamin Walker, Cristopher Salvi, Terry Lyons</author><pubDate>Mon, 06 Jan 2025 14:43:25 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.19047v4</guid></item><item><title>A Backdoor Attack Scheme with Invisible Triggers Based on Model Architecture Modification</title><link>http://arxiv.org/abs/2412.16905v2</link><description>Machine learning systems are vulnerable to backdoor attacks, where attackersmanipulate model behavior through data tampering or architecturalmodifications. Traditional backdoor attacks involve injecting malicious sampleswith specific triggers into the training data, causing the model to producetargeted incorrect outputs in the presence of the corresponding triggers. Moresophisticated attacks modify the model's architecture directly, embeddingbackdoors that are harder to detect as they evade traditional data-baseddetection methods. However, the drawback of the architectural modificationbased backdoor attacks is that the trigger must be visible in order to activatethe backdoor. To further strengthen the invisibility of the backdoor attacks, anovel backdoor attack method is presented in the paper. To be more specific,this method embeds the backdoor within the model's architecture and has thecapability to generate inconspicuous and stealthy triggers. The attack isimplemented by modifying pre-trained models, which are then redistributed,thereby posing a potential threat to unsuspecting users. Comprehensiveexperiments conducted on standard computer vision benchmarks validate theeffectiveness of this attack and highlight the stealthiness of its triggers,which remain undetectable through both manual visual inspection and advanceddetection tools.</description><author>Yuan Ma, Xu Ma, Jiankang Wei, Jinmeng Tang, Xiaoyu Zhang, Yilun Lyu, Kehao Chen, Jingtong Huang</author><pubDate>Mon, 06 Jan 2025 14:42:37 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.16905v2</guid></item><item><title>To Analyze and Regulate Human-in-the-loop Learning for Congestion Games</title><link>http://arxiv.org/abs/2501.03055v1</link><description>In congestion games, selfish users behave myopically to crowd to the shortestpaths, and the social planner designs mechanisms to regulate such selfishrouting through information or payment incentives. However, such mechanismdesign requires the knowledge of time-varying traffic conditions and it is theusers themselves to learn and report past road experiences to the socialplanner (e.g., Waze or Google Maps). When congestion games meet mobilecrowdsourcing, it is critical to incentivize selfish users to explorenon-shortest paths in the best exploitation-exploration trade-off. First, weconsider a simple but fundamental parallel routing network with onedeterministic path and multiple stochastic paths for users with an averagearrival probability $\lambda$. We prove that the current myopic routing policy(widely used in Waze and Google Maps) misses both exploration (when stronghazard belief) and exploitation (when weak hazard belief) as compared to thesocial optimum. Due to the myopic policy's under-exploration, we prove that thecaused price of anarchy (PoA) is larger than\(\frac{1}{1-\rho^{\frac{1}{\lambda}}}\), which can be arbitrarily large asdiscount factor \(\rho\rightarrow1\). To mitigate such huge efficiency loss, wepropose a novel selective information disclosure (SID) mechanism: we onlyreveal the latest traffic information to users when they intend to over-explorestochastic paths upon arrival, while hiding such information when they want tounder-explore. We prove that our mechanism successfully reduces PoA to be lessthan~\(2\). Besides the parallel routing network, we further extend ourmechanism and PoA results to any linear path graphs with multiple intermediatenodes.</description><author>Hongbo Li, Lingjie Duan</author><pubDate>Mon, 06 Jan 2025 14:41:45 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.03055v1</guid></item><item><title>Reviewing Intelligent Cinematography: AI research for camera-based video production</title><link>http://arxiv.org/abs/2405.05039v3</link><description>This paper offers the first comprehensive review of artificial intelligence(AI) research in the context of real camera content acquisition forentertainment purposes and is aimed at both researchers and cinematographers.Addressing the lack of review papers in the field of intelligentcinematography} (IC) and the breadth of related computer vision research, wepresent a holistic view of the IC landscape while providing technical insight,important for experts across disciplines. We provide technical background ongenerative AI, object detection, automated camera calibration and 3-D contentacquisition, with references to assist non-technical readers. The applicationsections categorize work in terms of four production types: General Production,Virtual Production, Live Production and Aerial Production. Within eachapplication section, we (1) sub-classify work according to research topic and(2) describe the trends and challenges relevant to each type of production. Inthe final chapter, we address the greater scope of IC research and summarizethe significant potential of this area to influence the creative industriessector. We suggest that work relating to virtual production has the greatestpotential to impact other mediums of production, driven by the growing interestin LED volumes/stages for in-camera virtual effects (ICVFX) and automated 3-Dcapture for virtual modeling of real world scenes and actors. We also addressethical and legal concerns regarding the use of creative AI that impact onartists, actors, technologists and the general public.</description><author>Adrian Azzarelli, Nantheera Anantrasirichai, David R Bull</author><pubDate>Mon, 06 Jan 2025 14:41:22 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.05039v3</guid></item><item><title>Dr. Tongue: Sign-Oriented Multi-label Detection for Remote Tongue Diagnosis</title><link>http://arxiv.org/abs/2501.03053v1</link><description>Tongue diagnosis is a vital tool in Western and Traditional Chinese Medicine,providing key insights into a patient's health by analyzing tongue attributes.The COVID-19 pandemic has heightened the need for accurate remote medicalassessments, emphasizing the importance of precise tongue attribute recognitionvia telehealth. To address this, we propose a Sign-Oriented multi-labelAttributes Detection framework. Our approach begins with an adaptive tonguefeature extraction module that standardizes tongue images and mitigatesenvironmental factors. This is followed by a Sign-oriented Network (SignNet)that identifies specific tongue attributes, emulating the diagnostic process ofexperienced practitioners and enabling comprehensive health evaluations. Tovalidate our methodology, we developed an extensive tongue image datasetspecifically designed for telemedicine. Unlike existing datasets, ours istailored for remote diagnosis, with a comprehensive set of attribute labels.This dataset will be openly available, providing a valuable resource forresearch. Initial tests have shown improved accuracy in detecting varioustongue attributes, highlighting our framework's potential as an essential toolfor remote medical assessments.</description><author>Yiliang Chen, Steven SC Ho, Cheng Xu, Yao Jie Xie, Wing-Fai Yeung, Shengfeng He, Jing Qin</author><pubDate>Mon, 06 Jan 2025 14:40:45 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.03053v1</guid></item><item><title>VCEval: Rethinking What is a Good Educational Video and How to Automatically Evaluate It</title><link>http://arxiv.org/abs/2407.12005v2</link><description>Online courses have significantly lowered the barrier to accessing education,yet the varying content quality of these videos poses challenges. In this work,we focus on the task of automatically evaluating the quality of video coursecontent. We have constructed a dataset with a substantial collection of videocourses and teaching materials. We propose three evaluation principles anddesign a new evaluation framework, \textit{VCEval}, based on these principles.The task is modeled as a multiple-choice question-answering task, with alanguage model serving as the evaluator. Our method effectively distinguishesvideo courses of different content quality and produces a range ofinterpretable results.</description><author>Xiaoxuan Zhu, Zhouhong Gu, Sihang Jiang, Zhixu Li, Hongwei Feng, Yanghua Xiao</author><pubDate>Mon, 06 Jan 2025 14:40:02 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.12005v2</guid></item><item><title>Mjolnir: Breaking the Shield of Perturbation-Protected Gradients via Adaptive Diffusion</title><link>http://arxiv.org/abs/2407.05285v4</link><description>Perturbation-based mechanisms, such as differential privacy, mitigategradient leakage attacks by introducing noise into the gradients, therebypreventing attackers from reconstructing clients' private data from the leakedgradients. However, can gradient perturbation protection mechanisms trulydefend against all gradient leakage attacks? In this paper, we present thefirst attempt to break the shield of gradient perturbation protection inFederated Learning for the extraction of private information. We focus oncommon noise distributions, specifically Gaussian and Laplace, and apply ourapproach to DNN and CNN models. We introduce Mjolnir, a perturbation-resilientgradient leakage attack that is capable of removing perturbations fromgradients without requiring additional access to the original model structureor external data. Specifically, we leverage the inherent diffusion propertiesof gradient perturbation protection to develop a novel diffusion-based gradientdenoising model for Mjolnir. By constructing a surrogate client model thatcaptures the structure of perturbed gradients, we obtain crucial gradient datafor training the diffusion model. We further utilize the insight thatmonitoring disturbance levels during the reverse diffusion process can enhancegradient denoising capabilities, allowing Mjolnir to generate gradients thatclosely approximate the original, unperturbed versions through adaptivesampling steps. Extensive experiments demonstrate that Mjolnir effectivelyrecovers the protected gradients and exposes the Federated Learning process tothe threat of gradient leakage, achieving superior performance in gradientdenoising and private data recovery.</description><author>Xuan Liu, Siqi Cai, Qihua Zhou, Song Guo, Ruibin Li, Kaiwei Lin</author><pubDate>Mon, 06 Jan 2025 14:37:01 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.05285v4</guid></item><item><title>Conservation-informed Graph Learning for Spatiotemporal Dynamics Prediction</title><link>http://arxiv.org/abs/2412.20962v3</link><description>Data-centric methods have shown great potential in understanding andpredicting spatiotemporal dynamics, enabling better design and control of theobject system. However, deep learning models often lack interpretability, failto obey intrinsic physics, and struggle to cope with the various domains. Whilegeometry-based methods, e.g., graph neural networks (GNNs), have been proposedto further tackle these challenges, they still need to find the implicitphysical laws from large datasets and rely excessively on rich labeled data. Inthis paper, we herein introduce the conservation-informed GNN (CiGNN), anend-to-end explainable learning framework, to learn spatiotemporal dynamicsbased on limited training data. The network is designed to conform to thegeneral conservation law via symmetry, where conservative and non-conservativeinformation passes over a multiscale space enhanced by a latent temporalmarching strategy. The efficacy of our model has been verified in variousspatiotemporal systems based on synthetic and real-world datasets, showingsuperiority over baseline models. Results demonstrate that CiGNN exhibitsremarkable accuracy and generalizability, and is readily applicable to learningfor prediction of various spatiotemporal dynamics in a spatial domain withcomplex geometry.</description><author>Yuan Mi, Pu Ren, Hongteng Xu, Hongsheng Liu, Zidong Wang, Yike Guo, Ji-Rong Wen, Hao Sun, Yang Liu</author><pubDate>Mon, 06 Jan 2025 14:36:13 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.20962v3</guid></item><item><title>Single-Channel Distance-Based Source Separation for Mobile GPU in Outdoor and Indoor Environments</title><link>http://arxiv.org/abs/2501.03045v1</link><description>This study emphasizes the significance of exploring distance-based sourceseparation (DSS) in outdoor environments. Unlike existing studies thatprimarily focus on indoor settings, the proposed model is designed to capturethe unique characteristics of outdoor audio sources. It incorporates advancedtechniques, including a two-stage conformer block, a linear relation-awareself-attention (RSA), and a TensorFlow Lite GPU delegate. While the linear RSAmay not capture physical cues as explicitly as the quadratic RSA, the linearRSA enhances the model's context awareness, leading to improved performance onthe DSS that requires an understanding of physical cues in outdoor and indoorenvironments. The experimental results demonstrated that the proposed modelovercomes the limitations of existing approaches and considerably enhancesenergy efficiency and real-time inference speed on mobile devices.</description><author>Hanbin Bae, Byungjun Kang, Jiwon Kim, Jaeyong Hwang, Hosang Sung, Hoon-Young Cho</author><pubDate>Mon, 06 Jan 2025 14:32:24 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.03045v1</guid></item><item><title>A new solution and concrete implementation steps for Artificial General Intelligence</title><link>http://arxiv.org/abs/2308.09721v2</link><description>In this paper, we propose a new approach to building a artificial generalintelligence with self awareness, which includes: (1) a new method to implementattention mechanisms; (2) a way to give machines self-demands; (3) how to forma value evaluation system compatible with the network; (4) a way to create theworld models; (5) how to realize a top-down, hierarchical thinkingdecision-making chain; (6) a way to achieve general decision-making andresponse capabilities; (7) a way for a machine to directly obtain humanexperience through language. In the paper, we first analyze some of theshortcomings of current LLMs (Large Language Model) and propose ideas forimprovement. Then we analyze why our scheme can solve the above problems andprovide detailed steps for implementing our scheme. In chapter 4, we havepresented a step-by-step mplementation roadmap. And in chapter 5, we havepresented a specific implementation demonstration. In chapter 6, we analyze theadvantages and disadvantages of our scheme and propose further researchdirections. In this article, we have put forward how to create genuineartificial general intelligence step by step. It can handle data of allmodalities in a unified form and can directly understand the experience thathumans already possess through language, thus avoiding the problem thatreinforcement learning is required for every decision-making process.</description><author>Yongcong Chen, Ting Zeng, Xingyue Chen</author><pubDate>Mon, 06 Jan 2025 14:31:39 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2308.09721v2</guid></item><item><title>Enhancing Sample Efficiency and Exploration in Reinforcement Learning through the Integration of Diffusion Models and Proximal Policy Optimization</title><link>http://arxiv.org/abs/2409.01427v4</link><description>Recent advancements in reinforcement learning (RL) have been fueled bylarge-scale data and deep neural networks, particularly for high-dimensionaland complex tasks. Online RL methods like Proximal Policy Optimization (PPO)are effective in dynamic scenarios but require substantial real-time data,posing challenges in resource-constrained or slow simulation environments.Offline RL addresses this by pre-learning policies from large datasets, thoughits success depends on the quality and diversity of the data. This workproposes a framework that enhances PPO algorithms by incorporating a diffusionmodel to generate high-quality virtual trajectories for offline datasets. Thisapproach improves exploration and sample efficiency, leading to significantgains in cumulative rewards, convergence speed, and strategy stability incomplex tasks. Our contributions are threefold: we explore the potential ofdiffusion models in RL, particularly for offline datasets, extend theapplication of online RL to offline environments, and experimentally validatethe performance improvements of PPO with diffusion models. These findingsprovide new insights and methods for applying RL to high-dimensional, complextasks. Finally, we open-source our code at https://github.com/TianciGao/DiffPPO</description><author>Gao Tianci, Dmitriev D. Dmitry, Konstantin A. Neusypin, Yang Bo, Rao Shengren</author><pubDate>Mon, 06 Jan 2025 14:30:06 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2409.01427v4</guid></item><item><title>Unsupervised Training of Convex Regularizers using Maximum Likelihood Estimation</title><link>http://arxiv.org/abs/2404.05445v3</link><description>Imaging is a standard example of an inverse problem, where the task ofreconstructing a ground truth from a noisy measurement is ill-posed. Recentstate-of-the-art approaches for imaging use deep learning, spearheaded byunrolled and end-to-end models and trained on various image datasets. However,many such methods require the availability of ground truth data, which may beunavailable or expensive, leading to a fundamental barrier that can not bebypassed by choice of architecture. Unsupervised learning presents analternative paradigm that bypasses this requirement, as they can be learneddirectly on noisy data and do not require any ground truths. A principledBayesian approach to unsupervised learning is to maximize the marginallikelihood with respect to the given noisy measurements, which is intrinsicallylinked to classical variational regularization. We propose an unsupervisedapproach using maximum marginal likelihood estimation to train a convex neuralnetwork-based image regularization term directly on noisy measurements,improving upon previous work in both model expressiveness and dataset size.Experiments demonstrate that the proposed method produces priors that are nearcompetitive when compared to the analogous supervised training method forvarious image corruption operators, maintaining significantly bettergeneralization properties when compared to end-to-end methods. Moreover, weprovide a detailed theoretical analysis of the convergence properties of ourproposed algorithm.</description><author>Hong Ye Tan, Ziruo Cai, Marcelo Pereyra, Subhadip Mukherjee, Junqi Tang, Carola-Bibiane Schönlieb</author><pubDate>Mon, 06 Jan 2025 14:28:17 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.05445v3</guid></item><item><title>Group Shapley with Robust Significance Testing and Its Application to Bond Recovery Rate Prediction</title><link>http://arxiv.org/abs/2501.03041v1</link><description>We propose Group Shapley, a metric that extends the classicalindividual-level Shapley value framework to evaluate the importance of featuregroups, addressing the structured nature of predictors commonly found inbusiness and economic data. More importantly, we develop a significance testingprocedure based on a three-cumulant chi-square approximation and establish theasymptotic properties of the test statistics for Group Shapley values. Ourapproach can effectively handle challenging scenarios, including sparse orskewed distributions and small sample sizes, outperforming alternative testssuch as the Wald test. Simulations confirm that the proposed test maintainsrobust empirical size and demonstrates enhanced power under diverse conditions.To illustrate the method's practical relevance in advancing Explainable AI, weapply our framework to bond recovery rate predictions using a global dataset(1996-2023) comprising 2,094 observations and 98 features, grouped into 16subgroups and five broader categories: bond characteristics, firm fundamentals,industry-specific factors, market-related variables, and macroeconomicindicators. Our results identify the market-related variables group as the mostinfluential. Furthermore, Lorenz curves and Gini indices reveal that GroupShapley assigns feature importance more equitably compared to individualShapley values.</description><author>Jingyi Wang, Ying Chen, Paolo Giudici</author><pubDate>Mon, 06 Jan 2025 14:27:44 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.03041v1</guid></item><item><title>ChronoSense: Exploring Temporal Understanding in Large Language Models with Time Intervals of Events</title><link>http://arxiv.org/abs/2501.03040v1</link><description>Large Language Models (LLMs) have achieved remarkable success in various NLPtasks, yet they still face significant challenges in reasoning and arithmetic.Temporal reasoning, a critical component of natural language understanding, hasraised increasing research attention. However, comprehensive testing of Allen'sinterval relations (e.g., before, after, during) -- a fundamental framework fortemporal relationships -- remains underexplored. To fill this gap, we presentChronoSense, a new benchmark for evaluating LLMs' temporal understanding. Itincludes 16 tasks, focusing on identifying the Allen relation between twotemporal events and temporal arithmetic, using both abstract events andreal-world data from Wikidata. We assess the performance of seven recent LLMsusing this benchmark and the results indicate that models handle Allenrelations, even symmetrical ones, quite differently. Moreover, the findingssuggest that the models may rely on memorization to answer time-relatedquestions. Overall, the models' low performance highlights the need forimproved temporal understanding in LLMs and ChronoSense offers a robustframework for future research in this area. Our dataset and the source code areavailable at https://github.com/duyguislakoglu/chronosense.</description><author>Duygu Sezen Islakoglu, Jan-Christoph Kalo</author><pubDate>Mon, 06 Jan 2025 14:27:41 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.03040v1</guid></item><item><title>Decoupling Knowledge and Reasoning in Transformers: A Modular Architecture with Generalized Cross-Attention</title><link>http://arxiv.org/abs/2501.00823v2</link><description>Transformers have achieved remarkable success across diverse domains, buttheir monolithic architecture presents challenges in interpretability,adaptability, and scalability. This paper introduces a novel modularTransformer architecture that explicitly decouples knowledge and reasoningthrough a generalized cross-attention mechanism to a globally shared knowledgebase with layer-specific transformations, specifically designed for effectiveknowledge retrieval. Critically, we provide a rigorous mathematical derivationdemonstrating that the Feed-Forward Network (FFN) in a standard Transformer isa specialized case (a closure) of this generalized cross-attention, revealingits role in implicit knowledge retrieval and validating our design. Thistheoretical framework provides a new lens for understanding FFNs and lays thefoundation for future research exploring enhanced interpretability,adaptability, and scalability, enabling richer interplay with externalknowledge bases and other systems.</description><author>Zhenyu Guo, Wenguang Chen</author><pubDate>Mon, 06 Jan 2025 14:26:41 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.00823v2</guid></item><item><title>Piano Transcription by Hierarchical Language Modeling with Pretrained Roll-based Encoders</title><link>http://arxiv.org/abs/2501.03038v1</link><description>Automatic Music Transcription (AMT), aiming to get musical notes from rawaudio, typically uses frame-level systems with piano-roll outputs or languagemodel (LM)-based systems with note-level predictions. However, frame-levelsystems require manual thresholding, while the LM-based systems struggle withlong sequences. In this paper, we propose a hybrid method combining pre-trainedroll-based encoders with an LM decoder to leverage the strengths of bothmethods. Besides, our approach employs a hierarchical prediction strategy,first predicting onset and pitch, then velocity, and finally offset. Thehierarchical prediction strategy reduces computational costs by breaking downlong sequences into different hierarchies. Evaluated on two benchmarkroll-based encoders, our method outperforms traditional piano-roll outputs 0.01and 0.022 in onset-offset-velocity F1 score, demonstrating its potential as aperformance-enhancing plug-in for arbitrary roll-based music transcriptionencoder. We release the code of this work athttps://github.com/yongyizang/AMT_train.</description><author>Dichucheng Li, Yongyi Zang, Qiuqiang Kong</author><pubDate>Mon, 06 Jan 2025 14:26:00 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.03038v1</guid></item><item><title>Quantization Meets Reasoning: Exploring LLM Low-Bit Quantization Degradation for Mathematical Reasoning</title><link>http://arxiv.org/abs/2501.03035v1</link><description>Large language models have achieved significant advancements in complexmathematical reasoning benchmarks, such as MATH. However, their substantialcomputational requirements present challenges for practical deployment. Modelquantization has emerged as an effective strategy to reduce memory usage andcomputational costs by employing lower precision and bit-width representations.In this study, we systematically evaluate the impact of quantization onmathematical reasoning tasks. We introduce a multidimensional evaluationframework that qualitatively assesses specific capability dimensions andconduct quantitative analyses on the step-by-step outputs of variousquantization methods. Our results demonstrate that quantization differentiallyaffects numerical computation and reasoning planning abilities, identifying keyareas where quantized models experience performance degradation.</description><author>Zhen Li, Yupeng Su, Runming Yang, Zhongwei Xie, Ngai Wong, Hongxia Yang</author><pubDate>Mon, 06 Jan 2025 14:23:02 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.03035v1</guid></item><item><title>VideoAnydoor: High-fidelity Video Object Insertion with Precise Motion Control</title><link>http://arxiv.org/abs/2501.01427v2</link><description>Despite significant advancements in video generation, inserting a givenobject into videos remains a challenging task. The difficulty lies inpreserving the appearance details of the reference object and accuratelymodeling coherent motions at the same time. In this paper, we proposeVideoAnydoor, a zero-shot video object insertion framework with high-fidelitydetail preservation and precise motion control. Starting from a text-to-videomodel, we utilize an ID extractor to inject the global identity and leverage abox sequence to control the overall motion. To preserve the detailed appearanceand meanwhile support fine-grained motion control, we design a pixel warper. Ittakes the reference image with arbitrary key-points and the correspondingkey-point trajectories as inputs. It warps the pixel details according to thetrajectories and fuses the warped features with the diffusion U-Net, thusimproving detail preservation and supporting users in manipulating the motiontrajectories. In addition, we propose a training strategy involving both videosand static images with a weighted loss to enhance insertion quality.VideoAnydoor demonstrates significant superiority over existing methods andnaturally supports various downstream applications (e.g., talking headgeneration, video virtual try-on, multi-region editing) without task-specificfine-tuning.</description><author>Yuanpeng Tu, Hao Luo, Xi Chen, Sihui Ji, Xiang Bai, Hengshuang Zhao</author><pubDate>Mon, 06 Jan 2025 14:21:59 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.01427v2</guid></item><item><title>DDRM-PR: Fourier Phase Retrieval using Denoising Diffusion Restoration Models</title><link>http://arxiv.org/abs/2501.03030v1</link><description>Diffusion models have demonstrated their utility as learned priors forsolving various inverse problems. However, most existing approaches are limitedto linear inverse problems. This paper exploits the efficient and unsupervisedposterior sampling framework of Denoising Diffusion Restoration Models (DDRM)for the solution of nonlinear phase retrieval problem, which requiresreconstructing an image from its noisy intensity-only measurements such asFourier intensity. The approach combines the model-based alternating-projectionmethods with the DDRM to utilize pretrained unconditional diffusion priors forphase retrieval. The performance is demonstrated through both simulations andexperimental data. Results demonstrate the potential of this approach forimproving the alternating-projection methods as well as its limitations.</description><author>Mehmet Onurcan Kaya, Figen S. Oktem</author><pubDate>Mon, 06 Jan 2025 14:18:23 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.03030v1</guid></item></channel></rss>