<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/"><channel><title>Arxivfresh papers</title><link></link><description>Arxiv paper</description><language>en-US</language><lastBuildDate>Wed, 14 Aug 2024 13:00:37 GMT</lastBuildDate><generator>rfeed v1.0.0</generator><docs>https://github.com/svpino/rfeed/blob/master/README.md</docs><item><title>Approaches for enhancing extrapolability in process-based and data-driven models in hydrology</title><link>http://arxiv.org/abs/2408.07071v1</link><description>The application of process-based and data-driven hydrological models iscrucial in modern hydrological research, especially for predicting key watercycle variables such as runoff, evapotranspiration (ET), and soil moisture.These models provide a scientific basis for water resource management, floodforecasting, and ecological protection. Process-based models simulate thephysical mechanisms of watershed hydrological processes, while data-drivenmodels leverage large datasets and advanced machine learning algorithms. Thispaper reviewed and compared methods for assessing and enhancing theextrapolability of both model types, discussing their prospects andlimitations. Key strategies include the use of leave-one-out cross-validationand similarity-based methods to evaluate model performance in ungauged regions.Deep learning, transfer learning, and domain adaptation techniques are alsopromising in their potential to improve model predictions in data-sparse andextreme conditions. Interdisciplinary collaboration and continuous algorithmicadvancements are also important to strengthen the global applicability andreliability of hydrological models.</description><author>Haiyang Shi</author><pubDate>Tue, 13 Aug 2024 17:59:24 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.07071v1</guid></item><item><title>Fingerspelling within Sign Language Translation</title><link>http://arxiv.org/abs/2408.07065v1</link><description>Fingerspelling poses challenges for sign language processing due to itshigh-frequency motion and use for open-vocabulary terms. While prior work hasstudied fingerspelling recognition, there has been little attention toevaluating how well sign language translation models understand fingerspellingin the context of entire sentences -- and improving this capability. Wemanually annotate instances of fingerspelling within FLEURS-ASL and use them toevaluate the effect of two simple measures to improve fingerspellingrecognition within American Sign Language to English translation: 1) use amodel family (ByT5) with character- rather than subword-level tokenization, and2) mix fingerspelling recognition data into the translation training mixture.We find that 1) substantially improves understanding of fingerspelling (andtherefore translation quality overall), but the effect of 2) is mixed.</description><author>Garrett Tanzer</author><pubDate>Tue, 13 Aug 2024 17:57:14 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.07065v1</guid></item><item><title>TraceFL: Achieving Interpretability in Federated Learning via Neuron Provenance</title><link>http://arxiv.org/abs/2312.13632v2</link><description>In Federated Learning, clients train models on local data and send updates toa central server, which aggregates them into a global model using a fusionalgorithm. This collaborative yet privacy-preserving training comes at acost--FL developers face significant challenges in attributing global modelpredictions to specific clients. Localizing responsible clients is a crucialstep towards (a) excluding clients primarily responsible for incorrectpredictions and (b) encouraging clients who contributed high-quality models tocontinue participating in the future. Existing ML explainability approaches areinherently inapplicable as they are designed for single-model, centralizedtraining. We introduce TraceFL, a fine-grained neuron provenance capturing mechanismthat identifies clients responsible for the global model's prediction bytracking the flow of information from individual clients to the global model.Since inference on different inputs activates a different set of neurons of theglobal model, TraceFL dynamically quantifies the significance of the globalmodel's neurons in a given prediction. It then selectively picks a slice of themost crucial neurons in the global model and maps them to the correspondingneurons in every participating client to determine each client's contribution,ultimately localizing the responsible client. We evaluate TraceFL on sixdatasets, including two real-world medical imaging datasets and four neuralnetworks, including advanced models such as GPT. TraceFL achieves 99% accuracyin localizing the responsible client in FL tasks spanning both image and textclassification tasks. At a time when state-of-the-art ML debugging approachesare mostly domain-specific (e.g., image classification only), TraceFL is thefirst technique to enable highly accurate automated reasoning across a widerange of FL applications.</description><author>Waris Gill, Ali Anwar, Muhammad Ali Gulzar</author><pubDate>Tue, 13 Aug 2024 17:57:07 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.13632v2</guid></item><item><title>Diversity Empowers Intelligence: Integrating Expertise of Software Engineering Agents</title><link>http://arxiv.org/abs/2408.07060v1</link><description>Large language model (LLM) agents have shown great potential in solvingreal-world software engineering (SWE) problems. The most advanced open-sourceSWE agent can resolve over 27% of real GitHub issues in SWE-Bench Lite.However, these sophisticated agent frameworks exhibit varying strengths,excelling in certain tasks while underperforming in others. To fully harnessthe diversity of these agents, we propose DEI (Diversity EmpoweredIntelligence), a framework that leverages their unique expertise. DEI functionsas a meta-module atop existing SWE agent frameworks, managing agent collectivesfor enhanced problem-solving. Experimental results show that a DEI-guidedcommittee of agents is able to surpass the best individual agent's performanceby a large margin. For instance, a group of open-source SWE agents, with amaximum individual resolve rate of 27.3% on SWE-Bench Lite, can achieve a 34.3%resolve rate with DEI, making a 25% improvement and beating most closed-sourcesolutions. Our best-performing group excels with a 55% resolve rate, securingthe highest ranking on SWE-Bench Lite. Our findings contribute to the growingbody of research on collaborative AI systems and their potential to solvecomplex software engineering challenges.</description><author>Kexun Zhang, Weiran Yao, Zuxin Liu, Yihao Feng, Zhiwei Liu, Rithesh Murthy, Tian Lan, Lei Li, Renze Lou, Jiacheng Xu, Bo Pang, Yingbo Zhou, Shelby Heinecke, Silvio Savarese, Huan Wang, Caiming Xiong</author><pubDate>Tue, 13 Aug 2024 17:50:28 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.07060v1</guid></item><item><title>Model Counting in the Wild</title><link>http://arxiv.org/abs/2408.07059v1</link><description>Model counting is a fundamental problem in automated reasoning withapplications in probabilistic inference, network reliability, neural networkverification, and more. Although model counting is computationally intractablefrom a theoretical perspective due to its #P-completeness, the past decade hasseen significant progress in developing state-of-the-art model counters toaddress scalability challenges. In this work, we conduct a rigorous assessment of the scalability of modelcounters in the wild. To this end, we surveyed 11 application domains andcollected an aggregate of 2262 benchmarks from these domains. We then evaluatedsix state-of-the-art model counters on these instances to assess scalabilityand runtime performance. Our empirical evaluation demonstrates that the performance of model countersvaries significantly across different application domains, underscoring theneed for careful selection by the end user. Additionally, we investigated thebehavior of different counters with respect to two parameters suggested by themodel counting community, finding only a weak correlation. Our analysishighlights the challenges and opportunities for portfolio-based approaches inmodel counting.</description><author>Arijit Shaw, Kuldeep S. Meel</author><pubDate>Tue, 13 Aug 2024 17:49:46 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.07059v1</guid></item><item><title>A Survey on Model MoErging: Recycling and Routing Among Specialized Experts for Collaborative Learning</title><link>http://arxiv.org/abs/2408.07057v1</link><description>The availability of performant pre-trained models has led to a proliferationof fine-tuned expert models that are specialized to a particular domain ortask. Model MoErging methods aim to recycle expert models to create anaggregate system with improved performance or generalization. A key componentof MoErging methods is the creation of a router that decides which expertmodel(s) to use for a particular input or application. The promise,effectiveness, and large design space of MoErging has spurred the developmentof many new methods over the past few years. This rapid pace of development hasmade it challenging to compare different MoErging methods, which are rarelycompared to one another and are often validated in different experimentalsetups. To remedy such gaps, we present a comprehensive survey of MoErgingmethods that includes a novel taxonomy for cataloging key design choices andclarifying suitable applications for each method. Apart from surveying MoErgingresearch, we inventory software tools and applications that make use ofMoErging. We additionally discuss related fields of study such as modelmerging, multitask learning, and mixture-of-experts models. Taken as a whole,our survey provides a unified overview of existing MoErging methods and createsa solid foundation for future work in this burgeoning field.</description><author>Prateek Yadav, Colin Raffel, Mohammed Muqeeth, Lucas Caccia, Haokun Liu, Tianlong Chen, Mohit Bansal, Leshem Choshen, Alessandro Sordoni</author><pubDate>Tue, 13 Aug 2024 17:49:00 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.07057v1</guid></item><item><title>LongWriter: Unleashing 10,000+ Word Generation from Long Context LLMs</title><link>http://arxiv.org/abs/2408.07055v1</link><description>Current long context large language models (LLMs) can process inputs up to100,000 tokens, yet struggle to generate outputs exceeding even a modest lengthof 2,000 words. Through controlled experiments, we find that the model'seffective generation length is inherently bounded by the sample it has seenduring supervised fine-tuning (SFT). In other words, their output limitation isdue to the scarcity of long-output examples in existing SFT datasets. Toaddress this, we introduce AgentWrite, an agent-based pipeline that decomposesultra-long generation tasks into subtasks, enabling off-the-shelf LLMs togenerate coherent outputs exceeding 20,000 words. Leveraging AgentWrite, weconstruct LongWriter-6k, a dataset containing 6,000 SFT data with outputlengths ranging from 2k to 32k words. By incorporating this dataset into modeltraining, we successfully scale the output length of existing models to over10,000 words while maintaining output quality. We also develop LongBench-Write,a comprehensive benchmark for evaluating ultra-long generation capabilities.Our 9B parameter model, further improved through DPO, achieves state-of-the-artperformance on this benchmark, surpassing even much larger proprietary models.In general, our work demonstrates that existing long context LLM alreadypossesses the potential for a larger output window--all you need is data withextended output during model alignment to unlock this capability. Our code &amp;models are at: https://github.com/THUDM/LongWriter.</description><author>Yushi Bai, Jiajie Zhang, Xin Lv, Linzhi Zheng, Siqi Zhu, Lei Hou, Yuxiao Dong, Jie Tang, Juanzi Li</author><pubDate>Tue, 13 Aug 2024 17:46:12 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.07055v1</guid></item><item><title>The News Comment Gap and Algorithmic Agenda Setting in Online Forums</title><link>http://arxiv.org/abs/2408.07052v1</link><description>The disparity between news stories valued by journalists and those preferredby readers, known as the "News Gap", is well-documented. However, thedifference in expectations regarding news related user-generated content isless studied. Comment sections, hosted by news websites, are popular venues forreader engagement, yet still subject to editorial decisions. It is thusimportant to understand journalist vs reader comment preferences and how theseare served by various comment ranking algorithms that represent discussionsdifferently. We analyse 1.2 million comments from Austrian newspaper DerStandard to understand the "News Comment Gap" and the effects of differentranking algorithms. We find that journalists prefer positive, timely, complex,direct responses, while readers favour comments similar to article content fromelite authors. We introduce the versatile Feature-Oriented Ranking UtilityMetric (FORUM) to assess the impact of different ranking algorithms and finddramatic differences in how they prioritise the display of comments bysentiment, topical relevance, lexical diversity, and readability. Journalistscan exert substantial influence over the discourse through both curatorial andalgorithmic means. Understanding these choices' implications is vital infostering engaging and civil discussions while aligning with journalisticobjectives, especially given the increasing legal scrutiny and societalimportance of online discourse.</description><author>Flora Böwing, Patrick Gildersleve</author><pubDate>Tue, 13 Aug 2024 17:43:32 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.07052v1</guid></item><item><title>PSM: Learning Probabilistic Embeddings for Multi-scale Zero-Shot Soundscape Mapping</title><link>http://arxiv.org/abs/2408.07050v1</link><description>A soundscape is defined by the acoustic environment a person perceives at alocation. In this work, we propose a framework for mapping soundscapes acrossthe Earth. Since soundscapes involve sound distributions that span varyingspatial scales, we represent locations with multi-scale satellite imagery andlearn a joint representation among this imagery, audio, and text. To capturethe inherent uncertainty in the soundscape of a location, we design therepresentation space to be probabilistic. We also fuse ubiquitous metadata(including geolocation, time, and data source) to enable learning of spatiallyand temporally dynamic representations of soundscapes. We demonstrate theutility of our framework by creating large-scale soundscape maps integratingboth audio and text with temporal control. To facilitate future research onthis task, we also introduce a large-scale dataset, GeoSound, containing over$300k$ geotagged audio samples paired with both low- and high-resolutionsatellite imagery. We demonstrate that our method outperforms the existingstate-of-the-art on both GeoSound and the existing SoundingEarth dataset. Ourdataset and code is available at https://github.com/mvrl/PSM.</description><author>Subash Khanal, Eric Xing, Srikumar Sastry, Aayush Dhakal, Zhexiao Xiong, Adeel Ahmad, Nathan Jacobs</author><pubDate>Tue, 13 Aug 2024 17:37:40 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.07050v1</guid></item><item><title>TableGuard -- Securing Structured &amp; Unstructured Data</title><link>http://arxiv.org/abs/2408.07045v1</link><description>With the increasing demand for data sharing across platforms andorganizations, ensuring the privacy and security of sensitive information hasbecome a critical challenge. This paper introduces "TableGuard". An innovativeapproach to data obfuscation tailored for relational databases. Building on theprinciples and techniques developed in prior work on context-sensitiveobfuscation, TableGuard applies these methods to ensure that API calls returnonly obfuscated data, thereby safeguarding privacy when sharing data with thirdparties. TableGuard leverages advanced context-sensitive obfuscation techniquesto replace sensitive data elements with contextually appropriate alternatives.By maintaining the relational integrity and coherence of the data, our approachmitigates the risks of cognitive dissonance and data leakage. We demonstratethe implementation of TableGuard using a BERT based transformer model, whichidentifies and obfuscates sensitive entities within relational tables. Ourevaluation shows that TableGuard effectively balances privacy protection withdata utility, minimizing information loss while ensuring that the obfuscateddata remains functionally useful for downstream applications. The resultshighlight the importance of domain-specific obfuscation strategies and the roleof context length in preserving data integrity. The implications of thisresearch are significant for organizations that need to share data securelywith external parties. TableGuard offers a robust framework for implementingprivacy-preserving data sharing mechanisms, thereby contributing to the broaderfield of data privacy and security.</description><author>Anantha Sharma, Ajinkya Deshmukh</author><pubDate>Tue, 13 Aug 2024 17:20:52 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.07045v1</guid></item><item><title>RealGen: Retrieval Augmented Generation for Controllable Traffic Scenarios</title><link>http://arxiv.org/abs/2312.13303v2</link><description>Simulation plays a crucial role in the development of autonomous vehicles(AVs) due to the potential risks associated with real-world testing. Althoughsignificant progress has been made in the visual aspects of simulators,generating complex behavior among agents remains a formidable challenge. It isnot only imperative to ensure realism in the scenarios generated but alsoessential to incorporate preferences and conditions to facilitate controllablegeneration for AV training and evaluation. Traditional methods, mainly relyingon memorizing the distribution of training datasets, often fall short ingenerating unseen scenarios. Inspired by the success of retrieval augmentedgeneration in large language models, we present RealGen, a novelretrieval-based in-context learning framework for traffic scenario generation.RealGen synthesizes new scenarios by combining behaviors from multipleretrieved examples in a gradient-free way, which may originate from templatesor tagged scenarios. This in-context learning framework endows versatilegenerative capabilities, including the ability to edit scenarios, composevarious behaviors, and produce critical scenarios. Evaluations show thatRealGen offers considerable flexibility and controllability, marking a newdirection in the field of controllable traffic scenario generation. Check ourproject website for more information: https://realgen.github.io.</description><author>Wenhao Ding, Yulong Cao, Ding Zhao, Chaowei Xiao, Marco Pavone</author><pubDate>Tue, 13 Aug 2024 17:20:34 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.13303v2</guid></item><item><title>The logic of rational graph neural networks</title><link>http://arxiv.org/abs/2310.13139v8</link><description>The expressivity of Graph Neural Networks (GNNs) can be described viaappropriate fragments of the first order logic. Any query of the two variablefragment of graded modal logic (GC2) interpreted over labeled graphs can beexpressed using a Rectified Linear Unit (ReLU) GNN whose size does not growwith graph input sizes [Barcelo &amp; Al., 2020]. Conversely, a GNN expresses atmost a query of GC2, for any choice of activation function. In this article, weprove that some GC2 queries of depth $3$ cannot be expressed by GNNs with anyrational activation function. This shows that not all non-polynomial activationfunctions confer GNNs maximal expressivity, answering a open questionformulated by [Grohe, 2021]. This result is also in contrast with the efficientuniversal approximation properties of rational feedforward neural networksinvestigated by [Boull\'e &amp; Al., 2020]. We also present a rational subfragmentof the first order logic (RGC2), and prove that rational GNNs can express RGC2queries uniformly over all graphs.</description><author>Sammy Khalife</author><pubDate>Tue, 13 Aug 2024 17:12:03 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.13139v8</guid></item><item><title>The Physics-Informed Neural Network Gravity Model: Generation III</title><link>http://arxiv.org/abs/2312.10257v2</link><description>Scientific machine learning and the advent of the Physics-Informed NeuralNetwork (PINN) have shown high potential in their ability to solve complexdifferential equations. One example is the use of PINNs to solve the gravityfield modeling problem -- learning convenient representations of thegravitational potential from position and acceleration data. These PINN gravitymodels, or PINN-GMs, have demonstrated advantages in model compactness,robustness to noise, and sample efficiency when compared to popularalternatives; however, further investigation has revealed various failure modesfor these and other machine learning gravity models which this manuscript aimsto address. Specifically, this paper introduces the third generationPhysics-Informed Neural Network Gravity Model (PINN-GM-III) which includesdesign changes that solve the problems of feature divergence, bias towardslow-altitude samples, numerical instability, and extrapolation error. Sixevaluation metrics are proposed to expose these past pitfalls and illustratethe PINN-GM-III's robustness to them. This study concludes by evaluating thePINN-GM-III modeling accuracy on a heterogeneous density asteroid, andcomparing its performance to other analytic and machine learning gravitymodels.</description><author>John Martin, Hanspeter Schaub</author><pubDate>Tue, 13 Aug 2024 17:10:19 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.10257v2</guid></item><item><title>KAN You See It? KANs and Sentinel for Effective and Explainable Crop Field Segmentation</title><link>http://arxiv.org/abs/2408.07040v1</link><description>Segmentation of crop fields is essential for enhancing agriculturalproductivity, monitoring crop health, and promoting sustainable practices. Deeplearning models adopted for this task must ensure accurate and reliablepredictions to avoid economic losses and environmental impact. The newlyproposed Kolmogorov-Arnold networks (KANs) offer promising advancements in theperformance of neural networks. This paper analyzes the integration of KANlayers into the U-Net architecture (U-KAN) to segment crop fields usingSentinel-2 and Sentinel-1 satellite images and provides an analysis of theperformance and explainability of these networks. Our findings indicate a 2\%improvement in IoU compared to the traditional full-convolutional U-Net modelin fewer GFLOPs. Furthermore, gradient-based explanation techniques show thatU-KAN predictions are highly plausible and that the network has a very highability to focus on the boundaries of cultivated areas rather than on the areasthemselves. The per-channel relevance analysis also reveals that some channelsare irrelevant to this task.</description><author>Daniele Rege Cambrin, Eleonora Poeta, Eliana Pastor, Tania Cerquitelli, Elena Baralis, Paolo Garza</author><pubDate>Tue, 13 Aug 2024 17:07:29 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.07040v1</guid></item><item><title>PathInsight: Instruction Tuning of Multimodal Datasets and Models for Intelligence Assisted Diagnosis in Histopathology</title><link>http://arxiv.org/abs/2408.07037v1</link><description>Pathological diagnosis remains the definitive standard for identifyingtumors. The rise of multimodal large models has simplified the process ofintegrating image analysis with textual descriptions. Despite this advancement,the substantial costs associated with training and deploying these complexmultimodal models, together with a scarcity of high-quality training datasets,create a significant divide between cutting-edge technology and its applicationin the clinical setting. We had meticulously compiled a dataset ofapproximately 45,000 cases, covering over 6 different tasks, including theclassification of organ tissues, generating pathology report descriptions, andaddressing pathology-related questions and answers. We have fine-tunedmultimodal large models, specifically LLaVA, Qwen-VL, InternLM, with thisdataset to enhance instruction-based performance. We conducted a qualitativeassessment of the capabilities of the base model and the fine-tuned model inperforming image captioning and classification tasks on the specific dataset.The evaluation results demonstrate that the fine-tuned model exhibitsproficiency in addressing typical pathological questions. We hope that bymaking both our models and datasets publicly available, they can be valuable tothe medical and research communities.</description><author>Xiaomin Wu, Rui Xu, Pengchen Wei, Wenkang Qin, Peixiang Huang, Ziheng Li, Lin Luo</author><pubDate>Tue, 13 Aug 2024 17:05:06 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.07037v1</guid></item><item><title>From NeRFs to Gaussian Splats, and Back</title><link>http://arxiv.org/abs/2405.09717v3</link><description>For robotics applications where there is a limited number of (typicallyego-centric) views, parametric representations such as neural radiance fields(NeRFs) generalize better than non-parametric ones such as Gaussian splatting(GS) to views that are very different from those in the training data; GShowever can render much faster than NeRFs. We develop a procedure to convertback and forth between the two. Our approach achieves the best of both NeRFs(superior PSNR, SSIM, and LPIPS on dissimilar views, and a compactrepresentation) and GS (real-time rendering and ability for easily modifyingthe representation); the computational cost of these conversions is minorcompared to training the two from scratch.</description><author>Siming He, Zach Osman, Pratik Chaudhari</author><pubDate>Tue, 13 Aug 2024 16:49:40 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.09717v3</guid></item><item><title>Efficient Human-Object-Interaction (EHOI) Detection via Interaction Label Coding and Conditional Decision</title><link>http://arxiv.org/abs/2408.07018v1</link><description>Human-Object Interaction (HOI) detection is a fundamental task in imageunderstanding. While deep-learning-based HOI methods provide high performancein terms of mean Average Precision (mAP), they are computationally expensiveand opaque in training and inference processes. An Efficient HOI (EHOI)detector is proposed in this work to strike a good balance between detectionperformance, inference complexity, and mathematical transparency. EHOI is atwo-stage method. In the first stage, it leverages a frozen object detector tolocalize the objects and extract various features as intermediate outputs. Inthe second stage, the first-stage outputs predict the interaction type usingthe XGBoost classifier. Our contributions include the application of errorcorrection codes (ECCs) to encode rare interaction cases, which reduces themodel size and the complexity of the XGBoost classifier in the second stage.Additionally, we provide a mathematical formulation of the relabeling anddecision-making process. Apart from the architecture, we present qualitativeresults to explain the functionalities of the feedforward modules. Experimentalresults demonstrate the advantages of ECC-coded interaction labels and theexcellent balance of detection performance and complexity of the proposed EHOImethod.</description><author>Tsung-Shan Yang, Yun-Cheng Wang, Chengwei Wei, Suya You, C. -C. Jay Kuo</author><pubDate>Tue, 13 Aug 2024 16:34:06 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.07018v1</guid></item><item><title>Defining and Measuring Disentanglement for non-Independent Factors of Variation</title><link>http://arxiv.org/abs/2408.07016v1</link><description>Representation learning is an approach that allows to discover and extractthe factors of variation from the data. Intuitively, a representation is saidto be disentangled if it separates the different factors of variation in a waythat is understandable to humans. Definitions of disentanglement and metrics tomeasure it usually assume that the factors of variation are independent of eachother. However, this is generally false in the real world, which limits the useof these definitions and metrics to very specific and unrealistic scenarios. Inthis paper we give a definition of disentanglement based on information theorythat is also valid when the factors of variation are not independent.Furthermore, we relate this definition to the Information Bottleneck Method.Finally, we propose a method to measure the degree of disentanglement from thegiven definition that works when the factors of variation are not independent.We show through different experiments that the method proposed in this papercorrectly measures disentanglement with non-independent factors of variation,while other methods fail in this scenario.</description><author>Antonio Almudévar, Alfonso Ortega, Luis Vicente, Antonio Miguel, Eduardo Lleida</author><pubDate>Tue, 13 Aug 2024 16:30:36 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.07016v1</guid></item><item><title>GarmentCodeData: A Dataset of 3D Made-to-Measure Garments With Sewing Patterns</title><link>http://arxiv.org/abs/2405.17609v2</link><description>Recent research interest in the learning-based processing of garments, fromvirtual fitting to generation and reconstruction, stumbles on a scarcity ofhigh-quality public data in the domain. We contribute to resolving this need bypresenting the first large-scale synthetic dataset of 3D made-to-measuregarments with sewing patterns, as well as its generation pipeline.GarmentCodeData contains 115,000 data points that cover a variety of designs inmany common garment categories: tops, shirts, dresses, jumpsuits, skirts,pants, etc., fitted to a variety of body shapes sampled from a customstatistical body model based on CAESAR, as well as a standard reference bodyshape, applying three different textile materials. To enable the creation ofdatasets of such complexity, we introduce a set of algorithms for automaticallytaking tailor's measures on sampled body shapes, sampling strategies for sewingpattern design, and propose an automatic, open-source 3D garment drapingpipeline based on a fast XPBD simulator, while contributing several solutionsfor collision resolution and drape correctness to enable scalability. Project Page: https://igl.ethz.ch/projects/GarmentCodeData/ Dataset: https://doi.org/10.3929/ethz-b-000673889</description><author>Maria Korosteleva, Timur Levent Kesdogan, Fabian Kemper, Stephan Wenninger, Jasmin Koller, Yuhan Zhang, Mario Botsch, Olga Sorkine-Hornung</author><pubDate>Tue, 13 Aug 2024 16:23:59 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.17609v2</guid></item><item><title>Hierarchical Quantum Control Gates for Functional MRI Understanding</title><link>http://arxiv.org/abs/2408.03596v2</link><description>Quantum computing has emerged as a powerful tool for solving complex problemsintractable for classical computers, particularly in popular fields such ascryptography, optimization, and neurocomputing. In this paper, we present a newquantum-based approach named the Hierarchical Quantum Control Gates (HQCG)method for efficient understanding of Functional Magnetic Resonance Imaging(fMRI) data. This approach includes two novel modules: the Local QuantumControl Gate (LQCG) and the Global Quantum Control Gate (GQCG), which aredesigned to extract local and global features of fMRI signals, respectively.Our method operates end-to-end on a quantum machine, leveraging quantummechanics to learn patterns within extremely high-dimensional fMRI signals,such as 30,000 samples which is a challenge for classical computers. Empiricalresults demonstrate that our approach significantly outperforms classicalmethods. Additionally, we found that the proposed quantum model is more stableand less prone to overfitting than the classical methods.</description><author>Xuan-Bac Nguyen, Hoang-Quan Nguyen, Hugh Churchill, Samee U. Khan, Khoa Luu</author><pubDate>Tue, 13 Aug 2024 16:18:25 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.03596v2</guid></item><item><title>Imagen 3</title><link>http://arxiv.org/abs/2408.07009v1</link><description>We introduce Imagen 3, a latent diffusion model that generates high qualityimages from text prompts. We describe our quality and responsibilityevaluations. Imagen 3 is preferred over other state-of-the-art (SOTA) models atthe time of evaluation. In addition, we discuss issues around safety andrepresentation, as well as methods we used to minimize the potential harm ofour models.</description><author>Imagen-Team-Google, :, Jason Baldridge, Jakob Bauer, Mukul Bhutani, Nicole Brichtova, Andrew Bunner, Kelvin Chan, Yichang Chen, Sander Dieleman, Yuqing Du, Zach Eaton-Rosen, Hongliang Fei, Nando de Freitas, Yilin Gao, Evgeny Gladchenko, Sergio Gómez Colmenarejo, Mandy Guo, Alex Haig, Will Hawkins, Hexiang Hu, Huilian Huang, Tobenna Peter Igwe, Christos Kaplanis, Siavash Khodadadeh, Yelin Kim, Ksenia Konyushkova, Karol Langner, Eric Lau, Shixin Luo, Soňa Mokrá, Henna Nandwani, Yasumasa Onoe, Aäron van den Oord, Zarana Parekh, Jordi Pont-Tuset, Hang Qi, Rui Qian, Deepak Ramachandran, Poorva Rane, Abdullah Rashwan, Ali Razavi, Robert Riachi, Hansa Srinivasan, Srivatsan Srinivasan, Robin Strudel, Benigno Uria, Oliver Wang, Su Wang, Austin Waters, Chris Wolff, Auriel Wright, Zhisheng Xiao, Hao </author><pubDate>Tue, 13 Aug 2024 16:15:50 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.07009v1</guid></item><item><title>SSHPool: The Separated Subgraph-based Hierarchical Pooling</title><link>http://arxiv.org/abs/2403.16133v2</link><description>In this paper, we develop a novel local graph pooling method, namely theSeparated Subgraph-based Hierarchical Pooling (SSHPool), for graphclassification. We commence by assigning the nodes of a sample graph intodifferent clusters, resulting in a family of separated subgraphs. Weindividually employ the local graph convolution units as the local structure tofurther compress each subgraph into a coarsened node, transforming the originalgraph into a coarsened graph. Since these subgraphs are separated by differentclusters and the structural information cannot be propagated between them, thelocal convolution operation can significantly avoid the over-smoothing problemcaused by message passing through edges in most existing Graph Neural Networks(GNNs). By hierarchically performing the proposed procedures on the resultingcoarsened graph, the proposed SSHPool can effectively extract the hierarchicalglobal features of the original graph structure, encapsulating rich intrinsicstructural characteristics. Furthermore, we develop an end-to-end GNN frameworkassociated with the SSHPool module for graph classification. Experimentalresults demonstrate the superior performance of the proposed model onreal-world datasets.</description><author>Zhuo Xu, Lixin Cui, Ming Li, Yue Wang, Ziyu Lyu, Hangyuan Du, Lu Bai, Philip S. Yu, Edwin R. Hancock</author><pubDate>Tue, 13 Aug 2024 16:15:11 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.16133v2</guid></item><item><title>The Distributional Uncertainty of the SHAP score in Explainable Machine Learning</title><link>http://arxiv.org/abs/2401.12731v4</link><description>Attribution scores reflect how important the feature values in an inputentity are for the output of a machine learning model. One of the most popularattribution scores is the SHAP score, which is an instantiation of the generalShapley value used in coalition game theory. The definition of this scorerelies on a probability distribution on the entity population. Since the exactdistribution is generally unknown, it needs to be assigned subjectively or beestimated from data, which may lead to misleading feature scores. In thispaper, we propose a principled framework for reasoning on SHAP scores underunknown entity population distributions. In our framework, we consider anuncertainty region that contains the potential distributions, and the SHAPscore of a feature becomes a function defined over this region. We study thebasic problems of finding maxima and minima of this function, which allows usto determine tight ranges for the SHAP scores of all features. In particular,we pinpoint the complexity of these problems, and other related ones, showingthem to be NP-complete. Finally, we present experiments on a real-worlddataset, showing that our framework may contribute to a more robust featurescoring.</description><author>Santiago Cifuentes, Leopoldo Bertossi, Nina Pardal, Sergio Abriola, Maria Vanina Martinez, Miguel Romero</author><pubDate>Tue, 13 Aug 2024 16:12:09 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.12731v4</guid></item><item><title>Active Learning for Control-Oriented Identification of Nonlinear Systems</title><link>http://arxiv.org/abs/2404.09030v2</link><description>Model-based reinforcement learning is an effective approach for controllingan unknown system. It is based on a longstanding pipeline familiar to thecontrol community in which one performs experiments on the environment tocollect a dataset, uses the resulting dataset to identify a model of thesystem, and finally performs control synthesis using the identified model. Asinteracting with the system may be costly and time consuming, targetedexploration is crucial for developing an effective control-oriented model withminimal experimentation. Motivated by this challenge, recent work has begun tostudy finite sample data requirements and sample efficient algorithms for theproblem of optimal exploration in model-based reinforcement learning. However,existing theory and algorithms are limited to model classes which are linear inthe parameters. Our work instead focuses on models with nonlinear parameterdependencies, and presents the first finite sample analysis of an activelearning algorithm suitable for a general class of nonlinear dynamics. Incertain settings, the excess control cost of our algorithm achieves the optimalrate, up to logarithmic factors. We validate our approach in simulation,showcasing the advantage of active, control-oriented exploration forcontrolling nonlinear systems.</description><author>Bruce D. Lee, Ingvar Ziemann, George J. Pappas, Nikolai Matni</author><pubDate>Tue, 13 Aug 2024 16:11:03 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.09030v2</guid></item><item><title>Casper: Prompt Sanitization for Protecting User Privacy in Web-Based Large Language Models</title><link>http://arxiv.org/abs/2408.07004v1</link><description>Web-based Large Language Model (LLM) services have been widely adopted andhave become an integral part of our Internet experience. Third-party pluginsenhance the functionalities of LLM by enabling access to real-world data andservices. However, the privacy consequences associated with these services andtheir third-party plugins are not well understood. Sensitive prompt data arestored, processed, and shared by cloud-based LLM providers and third-partyplugins. In this paper, we propose Casper, a prompt sanitization technique thataims to protect user privacy by detecting and removing sensitive informationfrom user inputs before sending them to LLM services. Casper runs entirely onthe user's device as a browser extension and does not require any changes tothe online LLM services. At the core of Casper is a three-layered sanitizationmechanism consisting of a rule-based filter, a Machine Learning (ML)-basednamed entity recognizer, and a browser-based local LLM topic identifier. Weevaluate Casper on a dataset of 4000 synthesized prompts and show that it caneffectively filter out Personal Identifiable Information (PII) andprivacy-sensitive topics with high accuracy, at 98.5% and 89.9%, respectively.</description><author>Chun Jie Chong, Chenxi Hou, Zhihao Yao, Seyed Mohammadjavad Seyed Talebi</author><pubDate>Tue, 13 Aug 2024 16:08:37 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.07004v1</guid></item><item><title>Generative AI for automatic topic labelling</title><link>http://arxiv.org/abs/2408.07003v1</link><description>Topic Modeling has become a prominent tool for the study of scientificfields, as they allow for a large scale interpretation of research trends.Nevertheless, the output of these models is structured as a list of keywordswhich requires a manual interpretation for the labelling. This paper proposesto assess the reliability of three LLMs, namely flan, GPT-4o, and GPT-4 minifor topic labelling. Drawing on previous research leveraging BERTopic, wegenerate topics from a dataset of all the scientific articles (n=34,797)authored by all biology professors in Switzerland (n=465) between 2008 and2020, as recorded in the Web of Science database. We assess the output of thethree models both quantitatively and qualitatively and find that, first, bothGPT models are capable of accurately and precisely label topics from themodels' output keywords. Second, 3-word labels are preferable to grasp thecomplexity of research topics.</description><author>Diego Kozlowski, Carolina Pradier, Pierre Benz</author><pubDate>Tue, 13 Aug 2024 16:07:16 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.07003v1</guid></item><item><title>EEG-MACS: Manifold Attention and Confidence Stratification for EEG-based Cross-Center Brain Disease Diagnosis under Unreliable Annotations</title><link>http://arxiv.org/abs/2405.00734v2</link><description>Cross-center data heterogeneity and annotation unreliability significantlychallenge the intelligent diagnosis of diseases using brain signals. A notableexample is the EEG-based diagnosis of neurodegenerative diseases, whichfeatures subtler abnormal neural dynamics typically observed in small-groupsettings. To advance this area, in this work, we introduce a transferableframework employing Manifold Attention and Confidence Stratification (MACS) todiagnose neurodegenerative disorders based on EEG signals sourced from fourcenters with unreliable annotations. The MACS framework's effectiveness stemsfrom these features: 1) The Augmentor generates various EEG-represented brainvariants to enrich the data space; 2) The Switcher enhances the feature spacefor trusted samples and reduces overfitting on incorrectly labeled samples; 3)The Encoder uses the Riemannian manifold and Euclidean metrics to capturespatiotemporal variations and dynamic synchronization in EEG; 4) The Projector,equipped with dual heads, monitors consistency across multiple brain variantsand ensures diagnostic accuracy; 5) The Stratifier adaptively stratifieslearned samples by confidence levels throughout the training process; 6)Forward and backpropagation in MACS are constrained by confidencestratification to stabilize the learning system amid unreliable annotations.Our subject-independent experiments, conducted on both neurocognitive andmovement disorders using cross-center corpora, have demonstrated superiorperformance compared to existing related algorithms. This work not onlyimproves EEG-based diagnostics for cross-center and small-setting braindiseases but also offers insights into extending MACS techniques to other dataanalyses, tackling data heterogeneity and annotation unreliability inmultimedia and multimodal content understanding.</description><author>Zhenxi Song, Ruihan Qin, Huixia Ren, Zhen Liang, Yi Guo, Min Zhang, Zhiguo Zhang</author><pubDate>Tue, 13 Aug 2024 16:03:38 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.00734v2</guid></item><item><title>AKBR: Learning Adaptive Kernel-based Representations for Graph Classification</title><link>http://arxiv.org/abs/2403.16130v2</link><description>In this paper, we propose a new model to learn Adaptive Kernel-basedRepresentations (AKBR) for graph classification. Unlike state-of-the-artR-convolution graph kernels that are defined by merely counting any pair ofisomorphic substructures between graphs and cannot provide an end-to-endlearning mechanism for the classifier, the proposed AKBR approach aims todefine an end-to-end representation learning model to construct an adaptivekernel matrix for graphs. To this end, we commence by leveraging a novelfeature-channel attention mechanism to capture the interdependencies betweendifferent substructure invariants of original graphs. The proposed AKBR modelcan thus effectively identify the structural importance of differentsubstructures, and compute the R-convolution kernel between pairwise graphsassociated with the more significant substructures specified by theirstructural attentions. Since each row of the resulting kernel matrix can betheoretically seen as the embedding vector of a sample graph, the proposed AKBRmodel is able to directly employ the resulting kernel matrix as the graphfeature matrix and input it into the classifier for classification (i.e., theSoftMax layer), naturally providing an end-to-end learning architecture betweenthe kernel computation as well as the classifier. Experimental results showthat the proposed AKBR model outperforms existing state-of-the-art graphkernels and deep learning methods on standard graph benchmarks.</description><author>Feifei Qian, Lixin Cui, Ming Li, Yue Wang, Hangyuan Du, Lixiang Xu, Lu Bai, Philip S. Yu, Edwin R. Hancock</author><pubDate>Tue, 13 Aug 2024 16:01:15 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.16130v2</guid></item><item><title>The Visual Experience Dataset: Over 200 Recorded Hours of Integrated Eye Movement, Odometry, and Egocentric Video</title><link>http://arxiv.org/abs/2404.18934v2</link><description>We introduce the Visual Experience Dataset (VEDB), a compilation of over 240hours of egocentric video combined with gaze- and head-tracking data thatoffers an unprecedented view of the visual world as experienced by humanobservers. The dataset consists of 717 sessions, recorded by 58 observersranging from 6-49 years old. This paper outlines the data collection,processing, and labeling protocols undertaken to ensure a representative sampleand discusses the potential sources of error or bias within the dataset. TheVEDB's potential applications are vast, including improving gaze trackingmethodologies, assessing spatiotemporal image statistics, and refining deepneural networks for scene and activity recognition. The VEDB is accessiblethrough established open science platforms and is intended to be a livingdataset with plans for expansion and community contributions. It is releasedwith an emphasis on ethical considerations, such as participant privacy and themitigation of potential biases. By providing a dataset grounded in real-worldexperiences and accompanied by extensive metadata and supporting code, theauthors invite the research community to utilize and contribute to the VEDB,facilitating a richer understanding of visual perception and behavior innaturalistic settings.</description><author>Michelle R. Greene, Benjamin J. Balas, Mark D. Lescroart, Paul R. MacNeilage, Jennifer A. Hart, Kamran Binaee, Peter A. Hausamann, Ronald Mezile, Bharath Shankar, Christian B. Sinnott, Kaylie Capurro, Savannah Halow, Hunter Howe, Mariam Josyula, Annie Li, Abraham Mieses, Amina Mohamed, Ilya Nudnou, Ezra Parkhill, Peter Riley, Brett Schmidt, Matthew W. Shinkle, Wentao Si, Brian Szekely, Joaquin M. Torres, Eliana Weissmann</author><pubDate>Tue, 13 Aug 2024 16:01:14 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.18934v2</guid></item><item><title>Faster Private Minimum Spanning Trees</title><link>http://arxiv.org/abs/2408.06997v1</link><description>Motivated by applications in clustering and synthetic data generation, weconsider the problem of releasing a minimum spanning tree (MST) underedge-weight differential privacy constraints where a graph topology $G=(V,E)$with $n$ vertices and $m$ edges is public, the weight matrix $\vec{W}\in\mathbb{R}^{n \times n}$ is private, and we wish to release an approximate MSTunder $\rho$-zero-concentrated differential privacy. Weight matrices areconsidered neighboring if they differ by at most $\Delta_\infty$ in each entry,i.e., we consider an $\ell_\infty$ neighboring relationship. Existing privateMST algorithms either add noise to each entry in $\vec{W}$ and estimate the MSTby post-processing or add noise to weights in-place during the execution of aspecific MST algorithm. Using the post-processing approach with an efficientMST algorithm takes $O(n^2)$ time on dense graphs but results in an additiveerror on the weight of the MST of magnitude $O(n^2\log n)$. In-place algorithmsgive asymptotically better utility, but the running time of existing in-placealgorithms is $O(n^3)$ for dense graphs. Our main result is a newdifferentially private MST algorithm that matches the utility of existingin-place methods while running in time $O(m + n^{3/2}\log n)$ for fixed privacyparameter $\rho$. The technical core of our algorithm is an efficient sublineartime simulation of Report-Noisy-Max that works by discretizing all edge weightsto a multiple of $\Delta_\infty$ and forming groups of edges with identicalweights. Specifically, we present a data structure that allows us to sample anoisy minimum weight edge among at most $O(n^2)$ cut edges in $O(\sqrt{n} \logn)$ time. Experimental evaluations support our claims that our algorithmsignificantly improves previous algorithms either in utility or running time.</description><author>Rasmus Pagh, Lukas Retschmeier</author><pubDate>Tue, 13 Aug 2024 16:00:30 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.06997v1</guid></item><item><title>HeadGaS: Real-Time Animatable Head Avatars via 3D Gaussian Splatting</title><link>http://arxiv.org/abs/2312.02902v2</link><description>3D head animation has seen major quality and runtime improvements over thelast few years, particularly empowered by the advances in differentiablerendering and neural radiance fields. Real-time rendering is a highly desirablegoal for real-world applications. We propose HeadGaS, a model that uses 3DGaussian Splats (3DGS) for 3D head reconstruction and animation. In this paperwe introduce a hybrid model that extends the explicit 3DGS representation witha base of learnable latent features, which can be linearly blended withlow-dimensional parameters from parametric head models to obtainexpression-dependent color and opacity values. We demonstrate that HeadGaSdelivers state-of-the-art results in real-time inference frame rates,surpassing baselines by up to 2dB, while accelerating rendering speed by overx10.</description><author>Helisa Dhamo, Yinyu Nie, Arthur Moreau, Jifei Song, Richard Shaw, Yiren Zhou, Eduardo Pérez-Pellitero</author><pubDate>Tue, 13 Aug 2024 15:56:58 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.02902v2</guid></item><item><title>Blessing of Dimensionality for Approximating Sobolev Classes on Manifolds</title><link>http://arxiv.org/abs/2408.06996v1</link><description>The manifold hypothesis says that natural high-dimensional data is actuallysupported on or around a low-dimensional manifold. Recent success ofstatistical and learning-based methods empirically supports this hypothesis,due to outperforming classical statistical intuition in very high dimensions. Anatural step for analysis is thus to assume the manifold hypothesis and derivebounds that are independent of any embedding space. Theoretical implications inthis direction have recently been explored in terms of generalization of ReLUnetworks and convergence of Langevin methods. We complement existing results byproviding theoretical statistical complexity results, which directly relates togeneralization properties. In particular, we demonstrate that the statisticalcomplexity required to approximate a class of bounded Sobolev functions on acompact manifold is bounded from below, and moreover that this bound isdependent only on the intrinsic properties of the manifold. These providecomplementary bounds for existing approximation results for ReLU networks onmanifolds, which give upper bounds on generalization capacity.</description><author>Hong Ye Tan, Subhadip Mukherjee, Junqi Tang, Carola-Bibiane Schönlieb</author><pubDate>Tue, 13 Aug 2024 15:56:42 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.06996v1</guid></item><item><title>Low-Bitwidth Floating Point Quantization for Efficient High-Quality Diffusion Models</title><link>http://arxiv.org/abs/2408.06995v1</link><description>Diffusion models are emerging models that generate images by iterativelydenoising random Gaussian noise using deep neural networks. These modelstypically exhibit high computational and memory demands, necessitatingeffective post-training quantization for high-performance inference. Recentworks propose low-bitwidth (e.g., 8-bit or 4-bit) quantization for diffusionmodels, however 4-bit integer quantization typically results in low-qualityimages. We observe that on several widely used hardware platforms, there islittle or no difference in compute capability between floating-point andinteger arithmetic operations of the same bitwidth (e.g., 8-bit or 4-bit).Therefore, we propose an effective floating-point quantization method fordiffusion models that provides better image quality compared to integerquantization methods. We employ a floating-point quantization method that waseffective for other processing tasks, specifically computer vision and naturallanguage tasks, and tailor it for diffusion models by integrating weightrounding learning during the mapping of the full-precision values to thequantized values in the quantization process. We comprehensively study integerand floating-point quantization methods in state-of-the-art diffusion models.Our floating-point quantization method not only generates higher-quality imagesthan that of integer quantization methods, but also shows no noticeabledegradation compared to full-precision models (32-bit floating-point), whenboth weights and activations are quantized to 8-bit floating-point values,while has minimal degradation with 4-bit weights and 8-bit activations.</description><author>Cheng Chen, Christina Giannoula, Andreas Moshovos</author><pubDate>Tue, 13 Aug 2024 15:56:20 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.06995v1</guid></item><item><title>LLMs can Schedule</title><link>http://arxiv.org/abs/2408.06993v1</link><description>The job shop scheduling problem (JSSP) remains a significant hurdle inoptimizing production processes. This challenge involves efficiently allocatingjobs to a limited number of machines while minimizing factors like totalprocessing time or job delays. While recent advancements in artificialintelligence have yielded promising solutions, such as reinforcement learningand graph neural networks, this paper explores the potential of Large LanguageModels (LLMs) for JSSP. We introduce the very first supervised 120k datasetspecifically designed to train LLMs for JSSP. Surprisingly, our findingsdemonstrate that LLM-based scheduling can achieve performance comparable toother neural approaches. Furthermore, we propose a sampling method thatenhances the effectiveness of LLMs in tackling JSSP.</description><author>Henrik Abgaryan, Ararat Harutyunyan, Tristan Cazenave</author><pubDate>Tue, 13 Aug 2024 15:53:58 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.06993v1</guid></item><item><title>How Transformers Learn Causal Structure with Gradient Descent</title><link>http://arxiv.org/abs/2402.14735v2</link><description>The incredible success of transformers on sequence modeling tasks can belargely attributed to the self-attention mechanism, which allows information tobe transferred between different parts of a sequence. Self-attention allowstransformers to encode causal structure which makes them particularly suitablefor sequence modeling. However, the process by which transformers learn suchcausal structure via gradient-based training algorithms remains poorlyunderstood. To better understand this process, we introduce an in-contextlearning task that requires learning latent causal structure. We prove thatgradient descent on a simplified two-layer transformer learns to solve thistask by encoding the latent causal graph in the first attention layer. The keyinsight of our proof is that the gradient of the attention matrix encodes themutual information between tokens. As a consequence of the data processinginequality, the largest entries of this gradient correspond to edges in thelatent causal graph. As a special case, when the sequences are generated fromin-context Markov chains, we prove that transformers learn an induction head(Olsson et al., 2022). We confirm our theoretical findings by showing thattransformers trained on our in-context learning task are able to recover a widevariety of causal structures.</description><author>Eshaan Nichani, Alex Damian, Jason D. Lee</author><pubDate>Tue, 13 Aug 2024 15:45:37 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.14735v2</guid></item><item><title>V4d: voxel for 4d novel view synthesis</title><link>http://arxiv.org/abs/2205.14332v4</link><description>Neural radiance fields have made a remarkable breakthrough in the novel viewsynthesis task at the 3D static scene. However, for the 4D circumstance (e.g.,dynamic scene), the performance of the existing method is still limited by thecapacity of the neural network, typically in a multilayer perceptron network(MLP). In this paper, we utilize 3D Voxel to model the 4D neural radiancefield, short as V4D, where the 3D voxel has two formats. The first one is toregularly model the 3D space and then use the sampled local 3D feature with thetime index to model the density field and the texture field by a tiny MLP. Thesecond one is in look-up tables (LUTs) format that is for the pixel-levelrefinement, where the pseudo-surface produced by the volume rendering isutilized as the guidance information to learn a 2D pixel-level refinementmapping. The proposed LUTs-based refinement module achieves the performancegain with little computational cost and could serve as the plug-and-play modulein the novel view synthesis task. Moreover, we propose a more effectiveconditional positional encoding toward the 4D data that achieves performancegain with negligible computational burdens. Extensive experiments demonstratethat the proposed method achieves state-of-the-art performance at a lowcomputational cost.</description><author>Wanshui Gan, Hongbin Xu, Yi Huang, Shifeng Chen, Naoto Yokoya</author><pubDate>Tue, 13 Aug 2024 15:43:26 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2205.14332v4</guid></item><item><title>Optimizing Emotion Recognition with Wearable Sensor Data: Unveiling Patterns in Body Movements and Heart Rate through Random Forest Hyperparameter Tuning</title><link>http://arxiv.org/abs/2408.03958v2</link><description>This research delves into the utilization of smartwatch sensor data and heartrate monitoring to discern individual emotions based on body movement and heartrate. Emotions play a pivotal role in human life, influencing mentalwell-being, quality of life, and even physical and physiological responses. Thedata were sourced from prior research by Juan C. Quiroz, PhD. The studyenlisted 50 participants who donned smartwatches and heart rate monitors whilecompleting a 250-meter walk. Emotions were induced through both audio-visualand audio stimuli, with participants' emotional states evaluated using thePANAS questionnaire. The study scrutinized three scenarios: viewing a moviebefore walking, listening to music before walking, and listening to music whilewalking. Personal baselines were established using DummyClassifier with the'most_frequent' strategy from the sklearn library, and various models,including Logistic Regression and Random Forest, were employed to gauge theimpacts of these activities. Notably, a novel approach was undertaken byincorporating hyperparameter tuning to the Random Forest model usingRandomizedSearchCV. The outcomes showcased substantial enhancements withhyperparameter tuning in the Random Forest model, yielding mean accuracies of86.63% for happy vs. sad and 76.33% for happy vs. neutral vs. sad.</description><author>Zikri Kholifah Nur, Rifki Wijaya, Gia Septiana Wulandari</author><pubDate>Tue, 13 Aug 2024 15:35:13 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.03958v2</guid></item><item><title>SpectralGaussians: Semantic, spectral 3D Gaussian splatting for multi-spectral scene representation, visualization and analysis</title><link>http://arxiv.org/abs/2408.06975v1</link><description>We propose a novel cross-spectral rendering framework based on 3D GaussianSplatting (3DGS) that generates realistic and semantically meaningful splatsfrom registered multi-view spectrum and segmentation maps. This extensionenhances the representation of scenes with multiple spectra, providing insightsinto the underlying materials and segmentation. We introduce an improvedphysically-based rendering approach for Gaussian splats, estimating reflectanceand lights per spectra, thereby enhancing accuracy and realism. In acomprehensive quantitative and qualitative evaluation, we demonstrate thesuperior performance of our approach with respect to other recentlearning-based spectral scene representation approaches (i.e., XNeRF andSpectralNeRF) as well as other non-spectral state-of-the-art learning-basedapproaches. Our work also demonstrates the potential of spectral sceneunderstanding for precise scene editing techniques like style transfer,inpainting, and removal. Thereby, our contributions address challenges inmulti-spectral scene representation, rendering, and editing, offering newpossibilities for diverse applications.</description><author>Saptarshi Neil Sinha, Holger Graf, Michael Weinmann</author><pubDate>Tue, 13 Aug 2024 15:32:54 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.06975v1</guid></item><item><title>On the Correspondence of Non-flat Assumption-based Argumentation and Logic Programming with Negation as Failure in the Head</title><link>http://arxiv.org/abs/2405.09415v3</link><description>The relation between (a fragment of) assumption-based argumentation (ABA) andlogic programs (LPs) under stable model semantics is well-studied. However, forobtaining this relation, the ABA framework needs to be restricted to beingflat, i.e., a fragment where the (defeasible) assumptions can never beentailed, only assumed to be true or false. Here, we remove this restrictionand show a correspondence between non-flat ABA and LPs with negation as failurein their head. We then extend this result to so-called set-stable ABAsemantics, originally defined for the fragment of non-flat ABA called bipolarABA. We showcase how to define set-stable semantics for LPs with negation asfailure in their head and show the correspondence to set-stable ABA semantics.</description><author>Anna Rapberger, Markus Ulbricht, Francesca Toni</author><pubDate>Tue, 13 Aug 2024 15:32:51 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.09415v3</guid></item><item><title>Maintaining Adversarial Robustness in Continuous Learning</title><link>http://arxiv.org/abs/2402.11196v2</link><description>Adversarial robustness is essential for security and reliability of machinelearning systems. However, adversarial robustness enhanced by defensealgorithms is easily erased as the neural network's weights update to learn newtasks. To address this vulnerability, it is essential to improve the capabilityof neural networks in terms of robust continual learning. Specially, we proposea novel gradient projection technique that effectively stabilizes samplegradients from previous data by orthogonally projecting back-propagationgradients onto a crucial subspace before using them for weight updates. Thistechnique can maintaining robustness by collaborating with a class of defensealgorithms through sample gradient smoothing. The experimental results on fourbenchmarks including Split-CIFAR100 and Split-miniImageNet, demonstrate thatthe superiority of the proposed approach in mitigating rapidly degradation ofrobustness during continual learning even when facing strong adversarialattacks.</description><author>Xiaolei Ru, Xiaowei Cao, Zijia Liu, Jack Murdoch Moore, Xin-Ya Zhang, Xia Zhu, Wenjia Wei, Gang Yan</author><pubDate>Tue, 13 Aug 2024 15:28:25 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.11196v2</guid></item><item><title>Prompt-Based Segmentation at Multiple Resolutions and Lighting Conditions using Segment Anything Model 2</title><link>http://arxiv.org/abs/2408.06970v1</link><description>This paper provides insight into the effectiveness of zero-shot,prompt-based, Segment Anything Model (SAM), and its updated version, SAM 2, andthe non-promptable, conventional convolutional network (CNN), in segmentingsolar panels, in RGB aerial imagery, across lighting conditions, spatialresolutions, and prompt strategies. SAM 2 demonstrates improvements over SAM,particularly in sub-optimal lighting conditions when prompted by points. BothSAMs, prompted by user-box, outperformed CNN, in all scenarios. Additionally,YOLOv9 prompting outperformed user points prompting. In high-resolutionimagery, both in optimal and sub-optimal lighting conditions, Eff-UNetoutperformed both SAM models prompted by YOLOv9 boxes, positioning Eff-UNet asthe appropriate model for automatic segmentation in high-resolution data. Inlow-resolution data, user box prompts were found crucial to achieve areasonable performance. This paper provides details on strengths andlimitations of each model and outlines robustness of user prompted imagesegmentation models in inconsistent resolution and lighting conditions ofremotely sensed data.</description><author>Osher Rafaeli, Tal Svoray, Ariel Nahlieli</author><pubDate>Tue, 13 Aug 2024 15:27:43 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.06970v1</guid></item><item><title>IRS-Assisted Lossy Communications Under Correlated Rayleigh Fading: Outage Probability Analysis and Optimization</title><link>http://arxiv.org/abs/2408.06969v1</link><description>This paper focuses on an intelligent reflecting surface (IRS)-assisted lossycommunication system with correlated Rayleigh fading. We analyze the correlatedchannel model and derive the outage probability of the system. Then, we designa deep reinforce learning (DRL) method to optimize the phase shift of IRS, inorder to maximize the received signal power. Moreover, this paper presentsresults of the simulations conducted to evaluate the performance of theDRL-based method. The simulation results indicate that the outage probabilityof the considered system increases significantly with more correlated channelcoefficients. Moreover, the performance gap between DRL and theoretical limitincreases with higher transmit power and/or larger distortion requirement.</description><author>Guanchang Li, Wensheng Lin, Lixin Li, Yixuan He, Fucheng Yang, Zhu Han</author><pubDate>Tue, 13 Aug 2024 15:27:30 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.06969v1</guid></item><item><title>Event-Stream Super Resolution using Sigma-Delta Neural Network</title><link>http://arxiv.org/abs/2408.06968v1</link><description>This study introduces a novel approach to enhance the spatial-temporalresolution of time-event pixels based on luminance changes captured by eventcameras. These cameras present unique challenges due to their low resolutionand the sparse, asynchronous nature of the data they collect. Current eventsuper-resolution algorithms are not fully optimized for the distinct datastructure produced by event cameras, resulting in inefficiencies in capturingthe full dynamism and detail of visual scenes with improved computationalcomplexity. To bridge this gap, our research proposes a method that integratesbinary spikes with Sigma Delta Neural Networks (SDNNs), leveragingspatiotemporal constraint learning mechanism designed to simultaneously learnthe spatial and temporal distributions of the event stream. The proposednetwork is evaluated using widely recognized benchmark datasets, includingN-MNIST, CIFAR10-DVS, ASL-DVS, and Event-NFS. A comprehensive evaluationframework is employed, assessing both the accuracy, through root mean squareerror (RMSE), and the computational efficiency of our model. The findingsdemonstrate significant improvements over existing state-of-the-art methods,specifically, the proposed method outperforms state-of-the-art performance incomputational efficiency, achieving a 17.04-fold improvement in event sparsityand a 32.28-fold increase in synaptic operation efficiency over traditionalartificial neural networks, alongside a two-fold better performance overspiking neural networks.</description><author>Waseem Shariff, Joe Lemley, Peter Corcoran</author><pubDate>Tue, 13 Aug 2024 15:25:18 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.06968v1</guid></item><item><title>Stabilizer bootstrapping: A recipe for efficient agnostic tomography and magic estimation</title><link>http://arxiv.org/abs/2408.06967v1</link><description>We study the task of agnostic tomography: given copies of an unknown$n$-qubit state $\rho$ which has fidelity $\tau$ with some state in a givenclass $C$, find a state which has fidelity $\ge \tau - \epsilon$ with $\rho$.We give a new framework, stabilizer bootstrapping, for designingcomputationally efficient protocols for this task, and use this to get newagnostic tomography protocols for the following classes: Stabilizer states: We give a protocol that runs in time$\mathrm{poly}(n,1/\epsilon)\cdot (1/\tau)^{O(\log(1/\tau))}$, answering anopen question posed by Grewal, Iyer, Kretschmer, Liang [40] and Anshu andArunachalam [6]. Previous protocols ran in time $\mathrm{exp}(\Theta(n))$ orrequired $\tau&gt;\cos^2(\pi/8)$. States with stabilizer dimension $n - t$: We give a protocol that runs intime $n^3\cdot(2^t/\tau)^{O(\log(1/\epsilon))}$, extending recent work onlearning quantum states prepared by circuits with few non-Clifford gates, whichonly applied in the realizable setting where $\tau = 1$ [30, 37, 46, 61]. Discrete product states: If $C = K^{\otimes n}$ for some $\mu$-separateddiscrete set $K$ of single-qubit states, we give a protocol that runs in time$(n/\mu)^{O((1 + \log (1/\tau))/\mu)}/\epsilon^2$. This strictly generalizes aprior guarantee which applied to stabilizer product states [39]. For stabilizerproduct states, we give a further improved protocol that runs in time$(n^2/\epsilon^2)\cdot (1/\tau)^{O(\log(1/\tau))}$. As a corollary, we give the first protocol for estimating stabilizerfidelity, a standard measure of magic for quantum states, to error $\epsilon$in $n^3 \mathrm{quasipoly}(1/\epsilon)$ time.</description><author>Sitan Chen, Weiyuan Gong, Qi Ye, Zhihan Zhang</author><pubDate>Tue, 13 Aug 2024 15:23:17 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.06967v1</guid></item><item><title>DyG-Mamba: Continuous State Space Modeling on Dynamic Graphs</title><link>http://arxiv.org/abs/2408.06966v1</link><description>Dynamic graph learning aims to uncover evolutionary laws in real-worldsystems, enabling accurate social recommendation (link prediction) or earlydetection of cancer cells (classification). Inspired by the success of statespace models, e.g., Mamba, for efficiently capturing long-term dependencies inlanguage modeling, we propose DyG-Mamba, a new continuous state space model(SSM) for dynamic graph learning. Specifically, we first found that usinginputs as control signals for SSM is not suitable for continuous-time dynamicnetwork data with irregular sampling intervals, resulting in models beinginsensitive to time information and lacking generalization properties. Drawinginspiration from the Ebbinghaus forgetting curve, which suggests that memory ofpast events is strongly correlated with time intervals rather than specificdetails of the events themselves, we directly utilize irregular time spans ascontrol signals for SSM to achieve significant robustness and generalization.Through exhaustive experiments on 12 datasets for dynamic link prediction anddynamic node classification tasks, we found that DyG-Mamba achievesstate-of-the-art performance on most of the datasets, while also demonstratingsignificantly improved computation and memory efficiency.</description><author>Dongyuan Li, Shiyin Tan, Ying Zhang, Ming Jin, Shirui Pan, Manabu Okumura, Renhe Jiang</author><pubDate>Tue, 13 Aug 2024 15:21:46 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.06966v1</guid></item><item><title>NEO-BENCH: Evaluating Robustness of Large Language Models with Neologisms</title><link>http://arxiv.org/abs/2402.12261v4</link><description>The performance of Large Language Models (LLMs) degrades from the temporaldrift between data used for model training and newer text seen duringinference. One understudied avenue of language change causing data drift is theemergence of neologisms -- new word forms -- over time. We create a diverseresource of recent English neologisms by using several popular collectionmethods. We analyze temporal drift using neologisms by comparing sentencescontaining new words with near-identical sentences that replace neologisms withexisting substitute words. Model performance is nearly halved in machinetranslation when a single neologism is introduced in a sentence. Motivated bythese results, we construct a benchmark to evaluate LLMs' ability to generalizeto neologisms with various natural language understanding tasks and modelperplexity. Models with later knowledge cutoff dates yield lower perplexitiesand perform better in downstream tasks. LLMs are also affected differentlybased on the linguistic origins of words, indicating that neologisms arecomplex for static LLMs to address. We will release our benchmark and code forreproducing our experiments.</description><author>Jonathan Zheng, Alan Ritter, Wei Xu</author><pubDate>Tue, 13 Aug 2024 15:20:13 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.12261v4</guid></item><item><title>Measuring User Understanding in Dialogue-based XAI Systems</title><link>http://arxiv.org/abs/2408.06960v1</link><description>The field of eXplainable Artificial Intelligence (XAI) is increasinglyrecognizing the need to personalize and/or interactively adapt the explanationto better reflect users' explanation needs. While dialogue-based approaches toXAI have been proposed recently, the state-of-the-art in XAI is stillcharacterized by what we call one-shot, non-personalized and one-wayexplanations. In contrast, dialogue-based systems that can adapt explanationsthrough interaction with a user promise to be superior to GUI-based ordashboard explanations as they offer a more intuitive way of requestinginformation. In general, while interactive XAI systems are often evaluated interms of user satisfaction, there are limited studies that access user'sobjective model understanding. This is in particular the case fordialogue-based XAI approaches. In this paper, we close this gap by carrying outcontrolled experiments within a dialogue framework in which we measureunderstanding of users in three phases by asking them to simulate thepredictions of the model they are learning about. By this, we can quantify thelevel of (improved) understanding w.r.t. how the model works, comparing thestate prior, and after the interaction. We further analyze the data to revealpatterns of how the interaction between groups with high vs. low understandinggain differ. Overall, our work thus contributes to our understanding about theeffectiveness of XAI approaches.</description><author>Dimitry Mindlin, Amelie Sophie Robrecht, Michael Morasch, Philipp Cimiano</author><pubDate>Tue, 13 Aug 2024 15:17:03 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.06960v1</guid></item><item><title>AuToMATo: A Parameter-Free Persistence-Based Clustering Algorithm</title><link>http://arxiv.org/abs/2408.06958v1</link><description>We present AuToMATo, a novel parameter-free clustering algorithm based onpersistent homology. AuToMATo combines the existing ToMATo clustering algorithmwith a bootstrapping procedure in order to separate significant peaks of anestimated density function from non-significant ones. We perform a thoroughcomparison of AuToMATo against many other state-of-the-art clusteringalgorithms. We find that not only that AuToMATo compares favorably againstother parameter-free clustering algorithms, but in many instances alsosignificantly outperforms even the best selection of parameters for otheralgorithms. AuToMATo is motivated by applications in topological data analysis,in particular the Mapper algorithm, where it is desirable to work with aparameter-free clustering algorithm. Indeed, we provide evidence that AuToMAToperforms well when used with Mapper. Finally, we provide an open-sourceimplementation of AuToMATo in Python that is fully compatible with thestandardscikit-learn architecture.</description><author>Marius Huber, Sara Kalisnik, Patrick Schnider</author><pubDate>Tue, 13 Aug 2024 15:15:37 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.06958v1</guid></item><item><title>Neural Speech and Audio Coding</title><link>http://arxiv.org/abs/2408.06954v1</link><description>This paper explores the integration of model-based and data-driven approacheswithin the realm of neural speech and audio coding systems. It highlights thechallenges posed by the subjective evaluation processes of speech and audiocodecs and discusses the limitations of purely data-driven approaches, whichoften require inefficiently large architectures to match the performance ofmodel-based methods. The study presents hybrid systems as a viable solution,offering significant improvements to the performance of conventional codecsthrough meticulously chosen design enhancements. Specifically, it introduces aneural network-based signal enhancer designed to post-process existing codecs'output, along with the autoencoder-based end-to-end models and LPCNet--hybridsystems that combine linear predictive coding (LPC) with neural networks.Furthermore, the paper delves into predictive models operating within customfeature spaces (TF-Codec) or predefined transform domains (MDCTNet) andexamines the use of psychoacoustically calibrated loss functions to trainend-to-end neural audio codecs. Through these investigations, the paperdemonstrates the potential of hybrid systems to advance the field of speech andaudio coding by bridging the gap between traditional model-based approaches andmodern data-driven techniques.</description><author>Minje Kim, Jan Skoglund</author><pubDate>Tue, 13 Aug 2024 15:13:21 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.06954v1</guid></item><item><title>Deepfake Media Forensics: State of the Art and Challenges Ahead</title><link>http://arxiv.org/abs/2408.00388v2</link><description>AI-generated synthetic media, also called Deepfakes, have significantlyinfluenced so many domains, from entertainment to cybersecurity. GenerativeAdversarial Networks (GANs) and Diffusion Models (DMs) are the main frameworksused to create Deepfakes, producing highly realistic yet fabricated content.While these technologies open up new creative possibilities, they also bringsubstantial ethical and security risks due to their potential misuse. The riseof such advanced media has led to the development of a cognitive bias known asImpostor Bias, where individuals doubt the authenticity of multimedia due tothe awareness of AI's capabilities. As a result, Deepfake detection has becomea vital area of research, focusing on identifying subtle inconsistencies andartifacts with machine learning techniques, especially Convolutional NeuralNetworks (CNNs). Research in forensic Deepfake technology encompasses five mainareas: detection, attribution and recognition, passive authentication,detection in realistic scenarios, and active authentication. This paper reviewsthe primary algorithms that address these challenges, examining theiradvantages, limitations, and future prospects.</description><author>Irene Amerini, Mauro Barni, Sebastiano Battiato, Paolo Bestagini, Giulia Boato, Tania Sari Bonaventura, Vittoria Bruni, Roberto Caldelli, Francesco De Natale, Rocco De Nicola, Luca Guarnera, Sara Mandelli, Gian Luca Marcialis, Marco Micheletto, Andrea Montibeller, Giulia Orru', Alessandro Ortis, Pericle Perazzo, Giovanni Puglisi, Davide Salvi, Stefano Tubaro, Claudia Melis Tonti, Massimo Villari, Domenico Vitulano</author><pubDate>Tue, 13 Aug 2024 15:10:20 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.00388v2</guid></item><item><title>SE(3)-Hyena Operator for Scalable Equivariant Learning</title><link>http://arxiv.org/abs/2407.01049v2</link><description>Modeling global geometric context while maintaining equivariance is crucialfor accurate predictions in many fields such as biology, chemistry, or vision.Yet, this is challenging due to the computational demands of processinghigh-dimensional data at scale. Existing approaches such as equivariantself-attention or distance-based message passing, suffer from quadraticcomplexity with respect to sequence length, while localized methods sacrificeglobal information. Inspired by the recent success of state-space andlong-convolutional models, in this work, we introduce SE(3)-Hyena operator, anequivariant long-convolutional model based on the Hyena operator. TheSE(3)-Hyena captures global geometric context at sub-quadratic complexity whilemaintaining equivariance to rotations and translations. Evaluated onequivariant associative recall and n-body modeling, SE(3)-Hyena matches oroutperforms equivariant self-attention while requiring significantly lessmemory and computational resources for long sequences. Our model processes thegeometric context of 20k tokens x3.5 times faster than the equivarianttransformer and allows x175 longer a context within the same memory budget.</description><author>Artem Moskalev, Mangal Prakash, Rui Liao, Tommaso Mansi</author><pubDate>Tue, 13 Aug 2024 15:06:41 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.01049v2</guid></item><item><title>FUGNN: Harmonizing Fairness and Utility in Graph Neural Networks</title><link>http://arxiv.org/abs/2405.17034v2</link><description>Fairness-aware Graph Neural Networks (GNNs) often face a challengingtrade-off, where prioritizing fairness may require compromising utility. Inthis work, we re-examine fairness through the lens of spectral graph theory,aiming to reconcile fairness and utility within the framework of spectral graphlearning. We explore the correlation between sensitive features and spectrum inGNNs, using theoretical analysis to delineate the similarity between originalsensitive features and those after convolution under different spectra. Ouranalysis reveals a reduction in the impact of similarity when the eigenvectorsassociated with the largest magnitude eigenvalue exhibit directionalsimilarity. Based on these theoretical insights, we propose FUGNN, a novelspectral graph learning approach that harmonizes the conflict between fairnessand utility. FUGNN ensures algorithmic fairness and utility by truncating thespectrum and optimizing eigenvector distribution during the encoding process.The fairness-aware eigenvector selection reduces the impact of convolution onsensitive features while concurrently minimizing the sacrifice of utility.FUGNN further optimizes the distribution of eigenvectors through a transformerarchitecture. By incorporating the optimized spectrum into the graphconvolution network, FUGNN effectively learns node representations. Experimentson six real-world datasets demonstrate the superiority of FUGNN over baselinemethods. The codes are available at https://github.com/yushuowiki/FUGNN.</description><author>Renqiang Luo, Huafei Huang, Shuo Yu, Zhuoyang Han, Estrid He, Xiuzhen Zhang, Feng Xia</author><pubDate>Tue, 13 Aug 2024 15:04:18 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.17034v2</guid></item><item><title>Heavy-Ball Momentum Accelerated Actor-Critic With Function Approximation</title><link>http://arxiv.org/abs/2408.06945v1</link><description>By using an parametric value function to replace the Monte-Carlo rollouts forvalue estimation, the actor-critic (AC) algorithms can reduce the variance ofstochastic policy gradient so that to improve the convergence rate. Whileexisting works mainly focus on analyzing convergence rate of AC algorithmsunder Markovian noise, the impacts of momentum on AC algorithms remain largelyunexplored. In this work, we first propose a heavy-ball momentum basedadvantage actor-critic (\mbox{HB-A2C}) algorithm by integrating the heavy-ballmomentum into the critic recursion that is parameterized by a linear function.When the sample trajectory follows a Markov decision process, we quantitativelycertify the acceleration capability of the proposed HB-A2C algorithm. Ourtheoretical results demonstrate that the proposed HB-A2C finds an$\epsilon$-approximate stationary point with $\oo{\epsilon^{-2}}$ iterationsfor reinforcement learning tasks with Markovian noise. Moreover, we also revealthe dependence of learning rates on the length of the sample trajectory. Bycarefully selecting the momentum factor of the critic recursion, the proposedHB-A2C can balance the errors introduced by the initialization and thestoschastic approximation.</description><author>Yanjie Dong, Haijun Zhang, Gang Wang, Shisheng Cui, Xiping Hu</author><pubDate>Tue, 13 Aug 2024 15:03:46 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.06945v1</guid></item><item><title>Towards Holistic Disease Risk Prediction using Small Language Models</title><link>http://arxiv.org/abs/2408.06943v1</link><description>Data in the healthcare domain arise from a variety of sources and modalities,such as x-ray images, continuous measurements, and clinical notes. Medicalpractitioners integrate these diverse data types daily to make informed andaccurate decisions. With recent advancements in language models capable ofhandling multimodal data, it is a logical progression to apply these models tothe healthcare sector. In this work, we introduce a framework that connectssmall language models to multiple data sources, aiming to predict the risk ofvarious diseases simultaneously. Our experiments encompass 12 different taskswithin a multitask learning setup. Although our approach does not surpassstate-of-the-art methods specialized for single tasks, it demonstratescompetitive performance and underscores the potential of small language modelsfor multimodal reasoning in healthcare.</description><author>Liv Björkdahl, Oskar Pauli, Johan Östman, Chiara Ceccobello, Sara Lundell, Magnus Kjellberg</author><pubDate>Tue, 13 Aug 2024 15:01:33 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.06943v1</guid></item><item><title>FuxiTranyu: A Multilingual Large Language Model Trained with Balanced Data</title><link>http://arxiv.org/abs/2408.06273v2</link><description>Large language models (LLMs) have demonstrated prowess in a wide range oftasks. However, many LLMs exhibit significant performance discrepancies betweenhigh- and low-resource languages. To mitigate this challenge, we presentFuxiTranyu, an open-source multilingual LLM, which is designed to satisfy theneed of the research community for balanced and high-performing multilingualcapabilities. FuxiTranyu-8B, the base model with 8 billion parameters, istrained from scratch on a meticulously balanced multilingual data repositorythat contains 600 billion tokens covering 43 natural languages and 16programming languages. In addition to the base model, we also develop twoinstruction-tuned models: FuxiTranyu-8B-SFT that is fine-tuned on a diversemultilingual instruction dataset, and FuxiTranyu-8B-DPO that is further refinedwith DPO on a preference dataset for enhanced alignment ability. Extensiveexperiments on a wide range of multilingual benchmarks demonstrate thecompetitive performance of FuxiTranyu against existing multilingual LLMs, e.g.,BLOOM-7B, PolyLM-13B, Llama-2-Chat-7B and Mistral-7B-Instruct. Interpretabilityanalyses at both the neuron and representation level suggest that FuxiTranyu isable to learn consistent multilingual representations across differentlanguages. To promote further research into multilingual LLMs and their workingmechanisms, we release both the base and instruction-tuned FuxiTranyu modelstogether with 58 pretraining checkpoints at HuggingFace and Github.</description><author>Haoran Sun, Renren Jin, Shaoyang Xu, Leiyu Pan, Supryadi, Menglong Cui, Jiangcun Du, Yikun Lei, Lei Yang, Ling Shi, Juesi Xiao, Shaolin Zhu, Deyi Xiong</author><pubDate>Tue, 13 Aug 2024 14:57:25 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.06273v2</guid></item><item><title>Learning Minimal Neural Specifications</title><link>http://arxiv.org/abs/2404.04662v3</link><description>Formal verification is only as good as the specification of a system, whichis also true for neural network verification. Existing specifications followthe paradigm of data as specification, where the local neighborhood around areference data point is considered correct or robust. While thesespecifications provide a fair testbed for assessing model robustness, they aretoo restrictive for verifying unseen test data-a challenging task withsignificant real-world implications. Recent work shows great promise through anew paradigm, neural representation as specification, which uses neuralactivation patterns (NAPs) for this purpose. However, it computes the mostrefined NAPs, which include many redundant neurons. In this paper, we study thefollowing problem: Given a neural network, find a minimal (general) NAPspecification that is sufficient for formal verification of the network'srobustness. Finding the minimal NAP specification not only expands verifiablebounds but also provides insights into which neurons contribute to the model'srobustness. To address this problem, we propose several exact and approximateapproaches. Our exact approaches leverage the verification tool to find minimalNAP specifications in either a deterministic or statistical manner. Whereas theapproximate methods efficiently estimate minimal NAPs using adversarialexamples and local gradients, without making calls to the verification tool.This allows us to inspect potential causal links between neurons and therobustness of state-of-the art neural networks, a task for which existingverification frameworks fail to scale. Our experimental results suggest thatminimal NAP specifications require much smaller fractions of neurons comparedto the most refined NAP specifications computed by previous work, yet they cansignificantly expand the verifiable boundaries to several orders of magnitudelarger.</description><author>Chuqin Geng, Zhaoyue Wang, Haolin Ye, Saifei Liao, Xujie Si</author><pubDate>Tue, 13 Aug 2024 14:56:35 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.04662v3</guid></item><item><title>An Ensemble Score Filter for Tracking High-Dimensional Nonlinear Dynamical Systems</title><link>http://arxiv.org/abs/2309.00983v2</link><description>We propose an ensemble score filter (EnSF) for solving high-dimensionalnonlinear filtering problems with superior accuracy. A major drawback ofexisting filtering methods, e.g., particle filters or ensemble Kalman filters,is the low accuracy in handling high-dimensional and highly nonlinear problems.EnSF attacks this challenge by exploiting the score-based diffusion model,defined in a pseudo-temporal domain, to characterizing the evolution of thefiltering density. EnSF stores the information of the recursively updatedfiltering density function in the score function, instead of storing theinformation in a set of finite Monte Carlo samples (used in particle filtersand ensemble Kalman filters). Unlike existing diffusion models that trainneural networks to approximate the score function, we develop a training-freescore estimation that uses a mini-batch-based Monte Carlo estimator to directlyapproximate the score function at any pseudo-spatial-temporal location, whichprovides sufficient accuracy in solving high-dimensional nonlinear problems aswell as saves a tremendous amount of time spent on training neural networks.High-dimensional Lorenz-96 systems are used to demonstrate the performance ofour method. EnSF provides surprising performance, compared with thestate-of-the-art Local Ensemble Transform Kalman Filter method, in reliably andefficiently tracking extremely high-dimensional Lorenz systems (up to 1,000,000dimensions) with highly nonlinear observation processes.</description><author>Feng Bao, Zezhong Zhang, Guannan Zhang</author><pubDate>Tue, 13 Aug 2024 14:48:39 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2309.00983v2</guid></item><item><title>DynaSeg: A Deep Dynamic Fusion Method for Unsupervised Image Segmentation Incorporating Feature Similarity and Spatial Continuity</title><link>http://arxiv.org/abs/2405.05477v3</link><description>Our work tackles the fundamental challenge of image segmentation in computervision, which is crucial for diverse applications. While supervised methodsdemonstrate proficiency, their reliance on extensive pixel-level annotationslimits scalability. We introduce DynaSeg, an innovative unsupervised imagesegmentation approach that overcomes the challenge of balancing featuresimilarity and spatial continuity without relying on extensive hyperparametertuning. Unlike traditional methods, DynaSeg employs a dynamic weighting schemethat automates parameter tuning, adapts flexibly to image characteristics, andfacilitates easy integration with other segmentation networks. By incorporatinga Silhouette Score Phase, DynaSeg prevents undersegmentation failures where thenumber of predicted clusters might converge to one. DynaSeg uses CNN-based andpre-trained ResNet feature extraction, making it computationally efficient andmore straightforward than other complex models. Experimental results showcasestate-of-the-art performance, achieving a 12.2% and 14.12% mIOU improvementover current unsupervised segmentation approaches on COCO-All and COCO-Stuffdatasets, respectively. We provide qualitative and quantitative results on fivebenchmark datasets, demonstrating the efficacy of the proposed approach.Code isavailable at https://github.com/RyersonMultimediaLab/DynaSeg</description><author>Boujemaa Guermazi, Naimul Khan</author><pubDate>Tue, 13 Aug 2024 14:44:38 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.05477v3</guid></item><item><title>Prioritize Alignment in Dataset Distillation</title><link>http://arxiv.org/abs/2408.03360v2</link><description>Dataset Distillation aims to compress a large dataset into a significantlymore compact, synthetic one without compromising the performance of the trainedmodels. To achieve this, existing methods use the agent model to extractinformation from the target dataset and embed it into the distilled dataset.Consequently, the quality of extracted and embedded information determines thequality of the distilled dataset. In this work, we find that existing methodsintroduce misaligned information in both information extraction and embeddingstages. To alleviate this, we propose Prioritize Alignment in DatasetDistillation (PAD), which aligns information from the following twoperspectives. 1) We prune the target dataset according to the compressing ratioto filter the information that can be extracted by the agent model. 2) We useonly deep layers of the agent model to perform the distillation to avoidexcessively introducing low-level information. This simple strategy effectivelyfilters out misaligned information and brings non-trivial improvement formainstream matching-based distillation algorithms. Furthermore, built ontrajectory matching, \textbf{PAD} achieves remarkable improvements on variousbenchmarks, achieving state-of-the-art performance.</description><author>Zekai Li, Ziyao Guo, Wangbo Zhao, Tianle Zhang, Zhi-Qi Cheng, Samir Khaki, Kaipeng Zhang, Ahmad Sajedi, Konstantinos N Plataniotis, Kai Wang, Yang You</author><pubDate>Tue, 13 Aug 2024 14:39:50 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.03360v2</guid></item><item><title>A Novel Cartography-Based Curriculum Learning Method Applied on RoNLI: The First Romanian Natural Language Inference Corpus</title><link>http://arxiv.org/abs/2405.11877v4</link><description>Natural language inference (NLI), the task of recognizing the entailmentrelationship in sentence pairs, is an actively studied topic serving as a proxyfor natural language understanding. Despite the relevance of the task inbuilding conversational agents and improving text classification, machinetranslation and other NLP tasks, to the best of our knowledge, there is nopublicly available NLI corpus for the Romanian language. To this end, weintroduce the first Romanian NLI corpus (RoNLI) comprising 58K trainingsentence pairs, which are obtained via distant supervision, and 6K validationand test sentence pairs, which are manually annotated with the correct labels.We conduct experiments with multiple machine learning methods based on distantlearning, ranging from shallow models based on word embeddings totransformer-based neural networks, to establish a set of competitive baselines.Furthermore, we improve on the best model by employing a new curriculumlearning strategy based on data cartography. Our dataset and code to reproducethe baselines are available at https://github.com/Eduard6421/RONLI.</description><author>Eduard Poesina, Cornelia Caragea, Radu Tudor Ionescu</author><pubDate>Tue, 13 Aug 2024 14:38:59 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.11877v4</guid></item><item><title>The advantages of context specific language models: the case of the Erasmian Language Model</title><link>http://arxiv.org/abs/2408.06931v1</link><description>The current trend to improve language model performance seems to be based onscaling up with the number of parameters (e.g. the state of the art GPT4 modelhas approximately 1.7 trillion parameters) or the amount of training data fedinto the model. However this comes at significant costs in terms ofcomputational resources and energy costs that compromise the sustainability ofAI solutions, as well as risk relating to privacy and misuse. In this paper wepresent the Erasmian Language Model (ELM) a small context specific, 900 millionparameter model, pre-trained and fine-tuned by and for Erasmus UniversityRotterdam. We show how the model performs adequately in a classroom context foressay writing, and how it achieves superior performance in subjects that arepart of its context. This has implications for a wide range of institutions andorganizations, showing that context specific language models may be a viablealternative for resource constrained, privacy sensitive use cases.</description><author>João Gonçalves, Nick Jelicic, Michele Murgia, Evert Stamhuis</author><pubDate>Tue, 13 Aug 2024 14:34:59 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.06931v1</guid></item><item><title>A Universal Flexible Near-sensor Neuromorphic Tactile System with Multi-threshold strategy for Pressure Characteristic Detection</title><link>http://arxiv.org/abs/2408.05846v2</link><description>Constructing the new generation information processing system by mimickingbiological nervous system is a feasible way for implement of high-efficientintelligent sensing device and bionic robot. However, most biological nervoussystem, especially the tactile system, have various powerful functions. This isa big challenge for bionic system design. Here we report a universal fullyflexible neuromorphic tactile perception system with strong compatibility and amultithreshold signal processing strategy. Like nervous system, signal in oursystem is transmitted as pulses and processed as threshold information. Forfeasibility verification, recognition of three different type pressure signals(continuous changing signal, Morse code signal and symbol pattern) is testedrespectively. Our system can output trend of these signals accurately and havea high accuracy in the recognition of symbol pattern and Morse code. Comparingto conventional system, consumption of our system significantly decreases in asame recognition task. Meanwhile, we give the detail introduction anddemonstration of our system universality.</description><author>Jialin Liu, Diansheng Liao</author><pubDate>Tue, 13 Aug 2024 14:33:36 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.05846v2</guid></item><item><title>Diagnosis extraction from unstructured Dutch echocardiogram reports using span- and document-level characteristic classification</title><link>http://arxiv.org/abs/2408.06930v1</link><description>Clinical machine learning research and AI driven clinical decision supportmodels rely on clinically accurate labels. Manually extracting these labelswith the help of clinical specialists is often time-consuming and expensive.This study tests the feasibility of automatic span- and document-leveldiagnosis extraction from unstructured Dutch echocardiogram reports. We included 115,692 unstructured echocardiogram reports from the UMCU a largeuniversity hospital in the Netherlands. A randomly selected subset was manuallyannotated for the occurrence and severity of eleven commonly described cardiaccharacteristics. We developed and tested several automatic labelling techniquesat both span and document levels, using weighted and macro F1-score, precision,and recall for performance evaluation. We compared the performance of spanlabelling against document labelling methods, which included both directdocument classifiers and indirect document classifiers that rely on spanclassification results. The SpanCategorizer and MedRoBERTa.nl models outperformed all other span anddocument classifiers, respectively. The weighted F1-score varied betweencharacteristics, ranging from 0.60 to 0.93 in SpanCategorizer and 0.96 to 0.98in MedRoBERTa.nl. Direct document classification was superior to indirectdocument classification using span classifiers. SetFit achieved competitivedocument classification performance using only 10\% of the training data.Utilizing a reduced label set yielded near-perfect document classificationresults. We recommend using our published SpanCategorizer and MedRoBERTa.nl models forspan- and document-level diagnosis extraction from Dutch echocardiographyreports. For settings with limited training data, SetFit may be a promisingalternative for document classification.</description><author>Bauke Arends, Melle Vessies, Dirk van Osch, Arco Teske, Pim van der Harst, René van Es, Bram van Es</author><pubDate>Tue, 13 Aug 2024 14:33:32 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.06930v1</guid></item><item><title>Evaluating Cultural Adaptability of a Large Language Model via Simulation of Synthetic Personas</title><link>http://arxiv.org/abs/2408.06929v1</link><description>The success of Large Language Models (LLMs) in multicultural environmentshinges on their ability to understand users' diverse cultural backgrounds. Wemeasure this capability by having an LLM simulate human profiles representingvarious nationalities within the scope of a questionnaire-style psychologicalexperiment. Specifically, we employ GPT-3.5 to reproduce reactions topersuasive news articles of 7,286 participants from 15 countries; comparing theresults with a dataset of real participants sharing the same demographictraits. Our analysis shows that specifying a person's country of residenceimproves GPT-3.5's alignment with their responses. In contrast, using nativelanguage prompting introduces shifts that significantly reduce overallalignment, with some languages particularly impairing performance. Thesefindings suggest that while direct nationality information enhances the model'scultural adaptability, native language cues do not reliably improve simulationfidelity and can detract from the model's effectiveness.</description><author>Louis Kwok, Michal Bravansky, Lewis D. Griffin</author><pubDate>Tue, 13 Aug 2024 14:32:43 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.06929v1</guid></item><item><title>Regularizing Self-supervised 3D Scene Flows with Surface Awareness and Cyclic Consistency</title><link>http://arxiv.org/abs/2312.08879v3</link><description>Learning without supervision how to predict 3D scene flows from point cloudsis essential to many perception systems. We propose a novel learning frameworkfor this task which improves the necessary regularization. Relying on theassumption that scene elements are mostly rigid, current smoothness losses arebuilt on the definition of "rigid clusters" in the input point clouds. Thedefinition of these clusters is challenging and has a significant impact on thequality of predicted flows. We introduce two new consistency losses thatenlarge clusters while preventing them from spreading over distinct objects. Inparticular, we enforce \emph{temporal} consistency with a forward-backwardcyclic loss and \emph{spatial} consistency by considering surface orientationsimilarity in addition to spatial proximity. The proposed losses aremodel-independent and can thus be used in a plug-and-play fashion tosignificantly improve the performance of existing models, as demonstrated ontwo most widely used architectures. We also showcase the effectiveness andgeneralization capability of our framework on four standard sensor-uniquedriving datasets, achieving state-of-the-art performance in 3D scene flowestimation. Our codes are available on https://github.com/ctu-vras/sac-flow.</description><author>Patrik Vacek, David Hurych, Karel Zimmermann, Patrick Perez, Tomas Svoboda</author><pubDate>Tue, 13 Aug 2024 14:32:37 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.08879v3</guid></item><item><title>Breaking Class Barriers: Efficient Dataset Distillation via Inter-Class Feature Compensator</title><link>http://arxiv.org/abs/2408.06927v1</link><description>Dataset distillation has emerged as a technique aiming to condenseinformative features from large, natural datasets into a compact and syntheticform. While recent advancements have refined this technique, its performance isbottlenecked by the prevailing class-specific synthesis paradigm. Under thisparadigm, synthetic data is optimized exclusively for a pre-assigned one-hotlabel, creating an implicit class barrier in feature condensation. This leadsto inefficient utilization of the distillation budget and oversight ofinter-class feature distributions, which ultimately limits the effectivenessand efficiency, as demonstrated in our analysis. To overcome these constraints, this paper presents the Inter-class FeatureCompensator (INFER), an innovative distillation approach that transcends theclass-specific data-label framework widely utilized in current datasetdistillation methods. Specifically, INFER leverages a Universal FeatureCompensator (UFC) to enhance feature integration across classes, enabling thegeneration of multiple additional synthetic instances from a single UFC input.This significantly improves the efficiency of the distillation budget. Moreover, INFER enriches inter-class interactions during the distillation,thereby enhancing the effectiveness and generalizability of the distilled data.By allowing for the linear interpolation of labels similar to those in theoriginal dataset, INFER meticulously optimizes the synthetic data anddramatically reduces the size of soft labels in the synthetic dataset to almostzero, establishing a new benchmark for efficiency and effectiveness in datasetdistillation.</description><author>Xin Zhang, Jiawei Du, Ping Liu, Joey Tianyi Zhou</author><pubDate>Tue, 13 Aug 2024 14:29:00 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.06927v1</guid></item><item><title>Continual Driving Policy Optimization with Closed-Loop Individualized Curricula</title><link>http://arxiv.org/abs/2309.14209v4</link><description>The safety of autonomous vehicles (AV) has been a long-standing top concern,stemming from the absence of rare and safety-critical scenarios in thelong-tail naturalistic driving distribution. To tackle this challenge, a surgeof research in scenario-based autonomous driving has emerged, with a focus ongenerating high-risk driving scenarios and applying them to conductsafety-critical testing of AV models. However, limited work has been exploredon the reuse of these extensive scenarios to iteratively improve AV models.Moreover, it remains intractable and challenging to filter through giganticscenario libraries collected from other AV models with distinct behaviors,attempting to extract transferable information for current AV improvement.Therefore, we develop a continual driving policy optimization frameworkfeaturing Closed-Loop Individualized Curricula (CLIC), which we factorize intoa set of standardized sub-modules for flexible implementation choices: AVEvaluation, Scenario Selection, and AV Training. CLIC frames AV Evaluation as acollision prediction task, where it estimates the chance of AV failures inthese scenarios at each iteration. Subsequently, by re-sampling from historicalscenarios based on these failure probabilities, CLIC tailors individualizedcurricula for downstream training, aligning them with the evaluated capabilityof AV. Accordingly, CLIC not only maximizes the utilization of the vastpre-collected scenario library for closed-loop driving policy optimization butalso facilitates AV improvement by individualizing its training with morechallenging cases out of those poorly organized scenarios. Experimental resultsclearly indicate that CLIC surpasses other curriculum-based trainingstrategies, showing substantial improvement in managing risky scenarios, whilestill maintaining proficiency in handling simpler cases.</description><author>Haoyi Niu, Yizhou Xu, Xingjian Jiang, Jianming Hu</author><pubDate>Tue, 13 Aug 2024 14:27:38 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2309.14209v4</guid></item><item><title>SceneGPT: A Language Model for 3D Scene Understanding</title><link>http://arxiv.org/abs/2408.06926v1</link><description>Building models that can understand and reason about 3D scenes is difficultowing to the lack of data sources for 3D supervised training and large-scaletraining regimes. In this work we ask - How can the knowledge in a pre-trainedlanguage model be leveraged for 3D scene understanding without any 3Dpre-training. The aim of this work is to establish whether pre-trained LLMspossess priors/knowledge required for reasoning in 3D space and how can weprompt them such that they can be used for general purpose spatial reasoningand object understanding in 3D. To this end, we present SceneGPT, an LLM basedscene understanding system which can perform 3D spatial reasoning withouttraining or explicit 3D supervision. The key components of our framework are -1) a 3D scene graph, that serves as scene representation, encoding the objectsin the scene and their spatial relationships 2) a pre-trained LLM that can beadapted with in context learning for 3D spatial reasoning. We evaluate ourframework qualitatively on object and scene understanding tasks includingobject semantics, physical properties and affordances (object-level) andspatial understanding (scene-level).</description><author>Shivam Chandhok</author><pubDate>Tue, 13 Aug 2024 14:26:30 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.06926v1</guid></item><item><title>Let-It-Flow: Simultaneous Optimization of 3D Flow and Object Clustering</title><link>http://arxiv.org/abs/2404.08363v3</link><description>We study the problem of self-supervised 3D scene flow estimation from reallarge-scale raw point cloud sequences, which is crucial to various tasks liketrajectory prediction or instance segmentation. In the absence of ground truthscene flow labels, contemporary approaches concentrate on deducing optimizingflow across sequential pairs of point clouds by incorporating structure basedregularization on flow and object rigidity. The rigid objects are estimated bya variety of 3D spatial clustering methods. While state-of-the-art methodssuccessfully capture overall scene motion using the Neural Prior structure,they encounter challenges in discerning multi-object motions. We identified thestructural constraints and the use of large and strict rigid clusters as themain pitfall of the current approaches and we propose a novel clusteringapproach that allows for combination of overlapping soft clusters as well asnon-overlapping rigid clusters representation. Flow is then jointly estimatedwith progressively growing non-overlapping rigid clusters together with fixedsize overlapping soft clusters. We evaluate our method on multiple datasetswith LiDAR point clouds, demonstrating the superior performance over theself-supervised baselines reaching new state of the art results. Our methodespecially excels in resolving flow in complicated dynamic scenes with multipleindependently moving objects close to each other which includes pedestrians,cyclists and other vulnerable road users. Our codes are publicly available onhttps://github.com/ctu-vras/let-it-flow.</description><author>Patrik Vacek, David Hurych, Tomáš Svoboda, Karel Zimmermann</author><pubDate>Tue, 13 Aug 2024 14:24:12 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.08363v3</guid></item><item><title>Improved Random Features for Dot Product Kernels</title><link>http://arxiv.org/abs/2201.08712v4</link><description>Dot product kernels, such as polynomial and exponential (softmax) kernels,are among the most widely used kernels in machine learning, as they enablemodeling the interactions between input features, which is crucial inapplications like computer vision, natural language processing, and recommendersystems. We make several novel contributions for improving the efficiency ofrandom feature approximations for dot product kernels, to make these kernelsmore useful in large scale learning. First, we present a generalization ofexisting random feature approximations for polynomial kernels, such asRademacher and Gaussian sketches and TensorSRHT, using complex-valued randomfeatures. We show empirically that the use of complex features cansignificantly reduce the variances of these approximations. Second, we providea theoretical analysis for understanding the factors affecting the efficiencyof various random feature approximations, by deriving closed-form expressionsfor their variances. These variance formulas elucidate conditions under whichcertain approximations (e.g., TensorSRHT) achieve lower variances than others(e.g., Rademacher sketches), and conditions under which the use of complexfeatures leads to lower variances than real features. Third, by using thesevariance formulas, which can be evaluated in practice, we develop a data-drivenoptimization approach to improve random feature approximations for general dotproduct kernels, which is also applicable to the Gaussian kernel. We describethe improvements brought by these contributions with extensive experiments on avariety of tasks and datasets.</description><author>Jonas Wacker, Motonobu Kanagawa, Maurizio Filippone</author><pubDate>Tue, 13 Aug 2024 14:22:10 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2201.08712v4</guid></item><item><title>Temporal Variability and Multi-Viewed Self-Supervised Representations to Tackle the ASVspoof5 Deepfake Challenge</title><link>http://arxiv.org/abs/2408.06922v1</link><description>ASVspoof5, the fifth edition of the ASVspoof series, is one of the largestglobal audio security challenges. It aims to advance the development ofcountermeasure (CM) to discriminate bonafide and spoofed speech utterances. Inthis paper, we focus on addressing the problem of open-domain audio deepfakedetection, which corresponds directly to the ASVspoof5 Track1 open condition.At first, we comprehensively investigate various CM on ASVspoof5, includingdata expansion, data augmentation, and self-supervised learning (SSL) features.Due to the high-frequency gaps characteristic of the ASVspoof5 dataset, weintroduce Frequency Mask, a data augmentation method that masks specificfrequency bands to improve CM robustness. Combining various scale of temporalinformation with multiple SSL features, our experiments achieved a minDCF of0.0158 and an EER of 0.55% on the ASVspoof 5 Track 1 evaluation progress set.</description><author>Yuankun Xie, Xiaopeng Wang, Zhiyong Wang, Ruibo Fu, Zhengqi Wen, Haonan Cheng, Long Ye</author><pubDate>Tue, 13 Aug 2024 14:15:15 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.06922v1</guid></item><item><title>Multi-Agent Continuous Control with Generative Flow Networks</title><link>http://arxiv.org/abs/2408.06920v1</link><description>Generative Flow Networks (GFlowNets) aim to generate diverse trajectoriesfrom a distribution in which the final states of the trajectories areproportional to the reward, serving as a powerful alternative to reinforcementlearning for exploratory control tasks. However, the individual-flow matchingconstraint in GFlowNets limits their applications for multi-agent systems,especially continuous joint-control problems. In this paper, we propose a novelMulti-Agent generative Continuous Flow Networks (MACFN) method to enablemultiple agents to perform cooperative exploration for various compositionalcontinuous objects. Technically, MACFN trains decentralizedindividual-flow-based policies in a centralized global-flow-based matchingfashion. During centralized training, MACFN introduces a continuous flowdecomposition network to deduce the flow contributions of each agent in thepresence of only global rewards. Then agents can deliver actions solely basedon their assigned local flow in a decentralized way, forming a joint policydistribution proportional to the rewards. To guarantee the expressiveness ofcontinuous flow decomposition, we theoretically derive a consistency conditionon the decomposition network. Experimental results demonstrate that theproposed method yields results superior to the state-of-the-art counterpartsand better exploration capability. Our code is available athttps://github.com/isluoshuang/MACFN.</description><author>Shuang Luo, Yinchuan Li, Shunyu Liu, Xu Zhang, Yunfeng Shao, Chao Wu</author><pubDate>Tue, 13 Aug 2024 14:12:03 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.06920v1</guid></item><item><title>Heterogeneous Space Fusion and Dual-Dimension Attention: A New Paradigm for Speech Enhancement</title><link>http://arxiv.org/abs/2408.06911v1</link><description>Self-supervised learning has demonstrated impressive performance in speechtasks, yet there remains ample opportunity for advancement in the realm ofspeech enhancement research. In addressing speech tasks, confining theattention mechanism solely to the temporal dimension poses limitations ineffectively focusing on critical speech features. Considering theaforementioned issues, our study introduces a novel speech enhancementframework, HFSDA, which skillfully integrates heterogeneous spatial featuresand incorporates a dual-dimension attention mechanism to significantly enhancespeech clarity and quality in noisy environments. By leveraging self-supervisedlearning embeddings in tandem with Short-Time Fourier Transform (STFT)spectrogram features, our model excels at capturing both high-level semanticinformation and detailed spectral data, enabling a more thorough analysis andrefinement of speech signals. Furthermore, we employ the innovativeOmni-dimensional Dynamic Convolution (ODConv) technology within the spectrograminput branch, enabling enhanced extraction and integration of crucialinformation across multiple dimensions. Additionally, we refine the Conformermodel by enhancing its feature extraction capabilities not only in the temporaldimension but also across the spectral domain. Extensive experiments on theVCTK-DEMAND dataset show that HFSDA is comparable to existing state-of-the-artmodels, confirming the validity of our approach.</description><author>Tao Zheng, Liejun Wang, Yinfeng Yu</author><pubDate>Tue, 13 Aug 2024 14:04:24 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.06911v1</guid></item><item><title>Neural Quantile Optimization for Edge-Cloud Networking</title><link>http://arxiv.org/abs/2307.05170v2</link><description>We seek the best traffic allocation scheme for the edge-cloud computingnetwork that satisfies constraints and minimizes the cost based on burstablebilling. First, for a fixed network topology, we formulate a family of integerprogramming problems with random parameters describing the various trafficdemands. Then, to overcome the difficulty caused by the discrete feature of theproblem, we generalize the Gumbel-softmax reparameterization method to inducean unconstrained continuous optimization problem as a regularized continuationof the discrete problem. Finally, we introduce the Gumbel-softmax samplingnetwork to solve the optimization problems via unsupervised learning. Thenetwork structure reflects the edge-cloud computing topology and is trained tominimize the expectation of the cost function for unconstrained continuousoptimization problems. The trained network works as an efficient trafficallocation scheme sampler, remarkably outperforming the random strategy infeasibility and cost function value. Besides testing the quality of the outputallocation scheme, we examine the generalization property of the network byincreasing the time steps and the number of users. We also feed the solution toexisting integer optimization solvers as initial conditions and verify thewarm-starts can accelerate the short-time iteration process. The framework isgeneral with solid performance, and the decoupled feature of the random neuralnetworks is adequate for practical implementations.</description><author>Bin Du, He Zhang, Xiangle Cheng, Lei Zhang</author><pubDate>Tue, 13 Aug 2024 14:04:09 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.05170v2</guid></item><item><title>Who's asking? User personas and the mechanics of latent misalignment</title><link>http://arxiv.org/abs/2406.12094v2</link><description>Despite investments in improving model safety, studies show that misalignedcapabilities remain latent in safety-tuned models. In this work, we shed lighton the mechanics of this phenomenon. First, we show that even when modelgenerations are safe, harmful content can persist in hidden representations andcan be extracted by decoding from earlier layers. Then, we show that whetherthe model divulges such content depends significantly on its perception of whoit is talking to, which we refer to as user persona. In fact, we findmanipulating user persona to be even more effective for eliciting harmfulcontent than direct attempts to control model refusal. We study both naturallanguage prompting and activation steering as control methods and show thatactivation steering is significantly more effective at bypassing safetyfilters. We investigate why certain personas break model safeguards and findthat they enable the model to form more charitable interpretations of otherwisedangerous queries. Finally, we show we can predict a persona's effect onrefusal given only the geometry of its steering vector.</description><author>Asma Ghandeharioun, Ann Yuan, Marius Guerard, Emily Reif, Michael A. Lepori, Lucas Dixon</author><pubDate>Tue, 13 Aug 2024 14:02:13 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.12094v2</guid></item><item><title>VNet: A GAN-based Multi-Tier Discriminator Network for Speech Synthesis Vocoders</title><link>http://arxiv.org/abs/2408.06906v1</link><description>Since the introduction of Generative Adversarial Networks (GANs) in speechsynthesis, remarkable achievements have been attained. In a thoroughexploration of vocoders, it has been discovered that audio waveforms can begenerated at speeds exceeding real-time while maintaining high fidelity,achieved through the utilization of GAN-based models. Typically, the inputs tothe vocoder consist of band-limited spectral information, which inevitablysacrifices high-frequency details. To address this, we adopt the full-band Melspectrogram information as input, aiming to provide the vocoder with the mostcomprehensive information possible. However, previous studies have revealedthat the use of full-band spectral information as input can result in the issueof over-smoothing, compromising the naturalness of the synthesized speech. Totackle this challenge, we propose VNet, a GAN-based neural vocoder network thatincorporates full-band spectral information and introduces a Multi-TierDiscriminator (MTD) comprising multiple sub-discriminators to generatehigh-resolution signals. Additionally, we introduce an asymptoticallyconstrained method that modifies the adversarial loss of the generator anddiscriminator, enhancing the stability of the training process. Throughrigorous experiments, we demonstrate that the VNet model is capable ofgenerating high-fidelity speech and significantly improving the performance ofthe vocoder.</description><author>Yubing Cao, Yongming Li, Liejun Wang, Yinfeng Yu</author><pubDate>Tue, 13 Aug 2024 14:00:02 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.06906v1</guid></item><item><title>Re-TASK: Revisiting LLM Tasks from Capability, Skill, and Knowledge Perspectives</title><link>http://arxiv.org/abs/2408.06904v1</link><description>As large language models (LLMs) continue to scale, their enhanced performanceoften proves insufficient for solving domain-specific tasks. Systematicallyanalyzing their failures and effectively enhancing their performance remainsignificant challenges. This paper introduces the Re-TASK framework, a noveltheoretical model that Revisits LLM Tasks from cApability, Skill, Knowledgeperspectives, guided by the principles of Bloom's Taxonomy and Knowledge SpaceTheory. The Re-TASK framework provides a systematic methodology to deepen ourunderstanding, evaluation, and enhancement of LLMs for domain-specific tasks.It explores the interplay among an LLM's capabilities, the knowledge itprocesses, and the skills it applies, elucidating how these elements areinterconnected and impact task performance. Our application of the Re-TASKframework reveals that many failures in domain-specific tasks can be attributedto insufficient knowledge or inadequate skill adaptation. With this insight, wepropose structured strategies for enhancing LLMs through targeted knowledgeinjection and skill adaptation. Specifically, we identify key capability itemsassociated with tasks and employ a deliberately designed prompting strategy toenhance task performance, thereby reducing the need for extensive fine-tuning.Alternatively, we fine-tune the LLM using capability-specific instructions,further validating the efficacy of our framework. Experimental results confirmthe framework's effectiveness, demonstrating substantial improvements in boththe performance and applicability of LLMs.</description><author>Zhihu Wang, Shiwan Zhao, Yu Wang, Heyuan Huang, Jiaxin Shi, Sitao Xie, Zhixing Wang, Yubo Zhang, Hongyan Li, Junchi Yan</author><pubDate>Tue, 13 Aug 2024 13:58:23 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.06904v1</guid></item><item><title>Heterogeneity: An Open Challenge for Federated On-board Machine Learning</title><link>http://arxiv.org/abs/2408.06903v1</link><description>The design of satellite missions is currently undergoing a paradigm shiftfrom the historical approach of individualised monolithic satellites towardsdistributed mission configurations, consisting of multiple small satellites.With a rapidly growing number of such satellites now deployed in orbit, eachcollecting large amounts of data, interest in on-board orbital edge computingis rising. Federated Learning is a promising distributed computing approach inthis context, allowing multiple satellites to collaborate efficiently intraining on-board machine learning models. Though recent works on the use ofFederated Learning in orbital edge computing have focused largely onhomogeneous satellite constellations, Federated Learning could also be employedto allow heterogeneous satellites to form ad-hoc collaborations, e.g. in thecase of communications satellites operated by different providers. Such anapplication presents additional challenges to the Federated Learning paradigm,arising largely from the heterogeneity of such a system. In this positionpaper, we offer a systematic review of these challenges in the context of thecross-provider use case, giving a brief overview of the state-of-the-art foreach, and providing an entry point for deeper exploration of each issue.</description><author>Maria Hartmann, Grégoire Danoy, Pascal Bouvry</author><pubDate>Tue, 13 Aug 2024 13:56:17 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.06903v1</guid></item><item><title>Weakly Supervised Video Anomaly Detection and Localization with Spatio-Temporal Prompts</title><link>http://arxiv.org/abs/2408.05905v2</link><description>Current weakly supervised video anomaly detection (WSVAD) task aims toachieve frame-level anomalous event detection with only coarse video-levelannotations available. Existing works typically involve extracting globalfeatures from full-resolution video frames and training frame-level classifiersto detect anomalies in the temporal dimension. However, most anomalous eventstend to occur in localized spatial regions rather than the entire video frames,which implies existing frame-level feature based works may be misled by thedominant background information and lack the interpretation of the detectedanomalies. To address this dilemma, this paper introduces a novel method calledSTPrompt that learns spatio-temporal prompt embeddings for weakly supervisedvideo anomaly detection and localization (WSVADL) based on pre-trainedvision-language models (VLMs). Our proposed method employs a two-stream networkstructure, with one stream focusing on the temporal dimension and the otherprimarily on the spatial dimension. By leveraging the learned knowledge frompre-trained VLMs and incorporating natural motion priors from raw videos, ourmodel learns prompt embeddings that are aligned with spatio-temporal regions ofvideos (e.g., patches of individual frames) for identify specific local regionsof anomalies, enabling accurate video anomaly detection while mitigating theinfluence of background information. Without relying on detailedspatio-temporal annotations or auxiliary object detection/tracking, our methodachieves state-of-the-art performance on three public benchmarks for the WSVADLtask.</description><author>Peng Wu, Xuerong Zhou, Guansong Pang, Zhiwei Yang, Qingsen Yan, Peng Wang, Yanning Zhang</author><pubDate>Tue, 13 Aug 2024 13:55:03 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.05905v2</guid></item><item><title>Divide and Conquer: Improving Multi-Camera 3D Perception with 2D Semantic-Depth Priors and Input-Dependent Queries</title><link>http://arxiv.org/abs/2408.06901v1</link><description>3D perception tasks, such as 3D object detection and Bird's-Eye-View (BEV)segmentation using multi-camera images, have drawn significant attentionrecently. Despite the fact that accurately estimating both semantic and 3Dscene layouts are crucial for this task, existing techniques often neglect thesynergistic effects of semantic and depth cues, leading to the occurrence ofclassification and position estimation errors. Additionally, theinput-independent nature of initial queries also limits the learning capacityof Transformer-based models. To tackle these challenges, we propose aninput-aware Transformer framework that leverages Semantics and Depth as priors(named SDTR). Our approach involves the use of an S-D Encoder that explicitlymodels semantic and depth priors, thereby disentangling the learning process ofobject categorization and position estimation. Moreover, we introduce aPrior-guided Query Builder that incorporates the semantic prior into theinitial queries of the Transformer, resulting in more effective input-awarequeries. Extensive experiments on the nuScenes and Lyft benchmarks demonstratethe state-of-the-art performance of our method in both 3D object detection andBEV segmentation tasks.</description><author>Qi Song, Qingyong Hu, Chi Zhang, Yongquan Chen, Rui Huang</author><pubDate>Tue, 13 Aug 2024 13:51:34 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.06901v1</guid></item><item><title>Entendre, a Social Bot Detection Tool for Niche, Fringe, and Extreme Social Media</title><link>http://arxiv.org/abs/2408.06900v1</link><description>Social bots-automated accounts that generate and spread content on socialmedia-are exploiting vulnerabilities in these platforms to manipulate publicperception and disseminate disinformation. This has prompted the development ofpublic bot detection services; however, most of these services focus primarilyon Twitter, leaving niche platforms vulnerable. Fringe social media platformssuch as Parler, Gab, and Gettr often have minimal moderation, which facilitatesthe spread of hate speech and misinformation. To address this gap, we introduceEntendre, an open-access, scalable, and platform-agnostic bot detectionframework. Entendre can process a labeled dataset from any social platform toproduce a tailored bot detection model using a random forest classificationapproach, ensuring robust social bot detection. We exploit the idea that mostsocial platforms share a generic template, where users can post content,approve content, and provide a bio (common data features). By emphasizinggeneral data features over platform-specific ones, Entendre offers rapidextensibility at the expense of some accuracy. To demonstrate Entendre'seffectiveness, we used it to explore the presence of bots among accountsposting racist content on the now-defunct right-wing platform Parler. Weexamined 233,000 posts from 38,379 unique users and found that 1,916 uniqueusers (4.99%) exhibited bot-like behavior. Visualization techniques furtherrevealed that these bots significantly impacted the network, amplifyinginfluential rhetoric and hashtags (e.g., #qanon, #trump, #antilgbt). Thesepreliminary findings underscore the need for tools like Entendre to monitor andassess bot activity across diverse platforms.</description><author>Pranav Venkatesh, Kami Vinton, Dhiraj Murthy, Kellen Sharp, Akaash Kolluri</author><pubDate>Tue, 13 Aug 2024 13:50:49 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.06900v1</guid></item><item><title>EE3P3D: Event-based Estimation of Periodic Phenomena Frequency using 3D Correlation</title><link>http://arxiv.org/abs/2408.06899v1</link><description>We present a novel method for measuring the frequency of periodic phenomena,e.g., rotation, flicker and vibration, by an event camera, a deviceasynchronously reporting brightness changes at independently operating pixelswith high temporal resolution. The approach assumes that for a periodicphenomenon, a highly similar set of events is generated within a specificspatio-temporal window at a time difference corresponding to the phenomenon'speriod. The sets of similar events are detected by 3D spatio-temporalcorrelation in the event stream space. The proposed method, EE3P3D, isevaluated on a dataset of 12 sequences of periodic phenomena, i.e. flashinglight and vibration, and periodic motion, e.g., rotation, ranging from 3.2 Hzto 2 kHz (equivalent to 192 - 120 000 RPM). EE3P3D significantly outperformspublished methods on this dataset, achieving a mean relative error of 0.1%.</description><author>Jakub Kolář, Radim Špetlík, Jiří Matas</author><pubDate>Tue, 13 Aug 2024 13:50:46 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.06899v1</guid></item><item><title>Detectability of hierarchical communities in networks</title><link>http://arxiv.org/abs/2009.07525v2</link><description>We study the problem of recovering a planted hierarchy of partitions in anetwork. The detectability of a single planted partition has previously beenanalysed in detail and a phase transition has been identified below which thepartition cannot be detected. Here we show that, in the hierarchical setting,there exist additional phases in which the presence of multiple consistentpartitions can either help or hinder detection. Accordingly, the detectabilitylimit for non-hierarchical partitions typically provides insufficientinformation about the detectability of the complete hierarchical structure, aswe highlight with several constructive examples.</description><author>Leto Peel, Michael T. Schaub</author><pubDate>Tue, 13 Aug 2024 13:49:43 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2009.07525v2</guid></item><item><title>Figure it Out: Analyzing-based Jailbreak Attack on Large Language Models</title><link>http://arxiv.org/abs/2407.16205v3</link><description>The rapid development of Large Language Models (LLMs) has brought remarkablegenerative capabilities across diverse tasks. However, despite the impressiveachievements, these LLMs still have numerous inherent vulnerabilities,particularly when faced with jailbreak attacks. By investigating jailbreakattacks, we can uncover hidden weaknesses in LLMs and inform the development ofmore robust defense mechanisms to fortify their security. In this paper, wefurther explore the boundary of jailbreak attacks on LLMs and proposeAnalyzing-based Jailbreak (ABJ). This effective jailbreak attack method takesadvantage of LLMs' growing analyzing and reasoning capability and reveals theirunderlying vulnerabilities when facing analyzing-based tasks. We conduct adetailed evaluation of ABJ across various open-source and closed-source LLMs,which achieves 94.8% attack success rate (ASR) and 1.06 attack efficiency (AE)on GPT-4-turbo-0409, demonstrating state-of-the-art attack effectiveness andefficiency. Our research highlights the importance of prioritizing andenhancing the safety of LLMs to mitigate the risks of misuse. The code ispublicly available at hhttps://github.com/theshi-1128/ABJ-Attack. Warning: Thispaper contains examples of LLMs that might be offensive or harmful.</description><author>Shi Lin, Rongchang Li, Xun Wang, Changting Lin, Wenpeng Xing, Meng Han</author><pubDate>Tue, 13 Aug 2024 13:46:18 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.16205v3</guid></item><item><title>Automatic Feature Recognition and Dimensional Attributes Extraction From CAD Models for Hybrid Additive-Subtractive Manufacturing</title><link>http://arxiv.org/abs/2408.06891v1</link><description>The integration of Computer-Aided Design (CAD), Computer-Aided ProcessPlanning (CAPP), and Computer-Aided Manufacturing (CAM) plays a crucial role inmodern manufacturing, facilitating seamless transitions from digital designs tophysical products. However, a significant challenge within this integration isthe Automatic Feature Recognition (AFR) of CAD models, especially in thecontext of hybrid manufacturing that combines subtractive and additivemanufacturing processes. Traditional AFR methods, focused mainly on theidentification of subtractive (machined) features including holes, fillets,chamfers, pockets, and slots, fail to recognize features pertinent to additivemanufacturing. Furthermore, the traditional methods fall short in accuratelyextracting geometric dimensions and orientations, which are also key factorsfor effective manufacturing process planning. This paper presents a novelapproach for creating a synthetic CAD dataset that encompasses featuresrelevant to both additive and subtractive machining through Python OpenCascade. The Hierarchical Graph Convolutional Neural Network (HGCNN) model isimplemented to accurately identify the composite additive-subtractive featureswithin the synthetic CAD dataset. The key novelty and contribution of theproposed methodology lie in its ability to recognize a wide range ofmanufacturing features, and precisely extracting their dimensions,orientations, and stock sizes. The proposed model demonstrates remarkablefeature recognition accuracy exceeding 97% and a dimension extraction accuracyof 100% for identified features. Therefore, the proposed methodology enhancesthe integration of CAD, CAPP, and CAM within hybrid manufacturing by providingprecise feature recognition and dimension extraction. It facilitates improvedmanufacturing process planning, by enabling more informed decision-making.</description><author>Muhammad Tayyab Khan, Wenhe Feng, Lequn Chen, Ye Han Ng, Nicholas Yew Jin Tan, Seung Ki Moon</author><pubDate>Tue, 13 Aug 2024 13:38:32 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.06891v1</guid></item><item><title>BMFT: Achieving Fairness via Bias-based Weight Masking Fine-tuning</title><link>http://arxiv.org/abs/2408.06890v1</link><description>Developing models with robust group fairness properties is paramount,particularly in ethically sensitive domains such as medical diagnosis. Recentapproaches to achieving fairness in machine learning require a substantialamount of training data and depend on model retraining, which may not bepractical in real-world scenarios. To mitigate these challenges, we proposeBias-based Weight Masking Fine-Tuning (BMFT), a novel post-processing methodthat enhances the fairness of a trained model in significantly fewer epochswithout requiring access to the original training data. BMFT produces a maskover model parameters, which efficiently identifies the weights contributingthe most towards biased predictions. Furthermore, we propose a two-stepdebiasing strategy, wherein the feature extractor undergoes initial fine-tuningon the identified bias-influenced weights, succeeded by a fine-tuning phase ona reinitialised classification layer to uphold discriminative performance.Extensive experiments across four dermatological datasets and two sensitiveattributes demonstrate that BMFT outperforms existing state-of-the-art (SOTA)techniques in both diagnostic accuracy and fairness metrics. Our findingsunderscore the efficacy and robustness of BMFT in advancing fairness acrossvarious out-of-distribution (OOD) settings. Our code is available at:https://github.com/vios-s/BMFT</description><author>Yuyang Xue, Junyu Yan, Raman Dutt, Fasih Haider, Jingshuai Liu, Steven McDonagh, Sotirios A. Tsaftaris</author><pubDate>Tue, 13 Aug 2024 13:36:48 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.06890v1</guid></item><item><title>Decentralized Intelligence Network (DIN)</title><link>http://arxiv.org/abs/2407.02461v4</link><description>Decentralized Intelligence Network (DIN) is a theoretical frameworkaddressing data fragmentation and siloing challenges, enabling scalable AIthrough data sovereignty. It facilitates effective AI utilization withinsovereign networks by overcoming barriers to accessing diverse data sources,leveraging: 1) personal data stores to ensure data sovereignty, where dataremains securely within Participants' control; 2) a scalable federated learningprotocol implemented on a public blockchain for decentralized AI training,where only model parameter updates are shared, keeping data within the personaldata stores; and 3) a scalable, trustless cryptographic rewards mechanism on apublic blockchain to incentivize participation and ensure fair rewarddistribution through a decentralized auditing protocol. This approachguarantees that no entity can prevent or control access to training data orinfluence financial benefits, as coordination and reward distribution aremanaged on the public blockchain with an immutable record. The frameworksupports effective AI training by allowing Participants to maintain controlover their data, benefit financially, and contribute to a decentralized,scalable ecosystem that leverages collective AI to develop beneficialalgorithms.</description><author>Abraham Nash</author><pubDate>Tue, 13 Aug 2024 13:34:45 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.02461v4</guid></item><item><title>WRDScore: New Metric for Evaluation of Natural Language Generation Models</title><link>http://arxiv.org/abs/2405.19220v5</link><description>Evaluating natural language generation models, particularly for method nameprediction, poses significant challenges. A robust metric must account for theversatility of method naming, considering both semantic and syntacticvariations. Traditional overlap-based metrics, such as ROUGE, fail to capturethese nuances. Existing embedding-based metrics often suffer from imbalancedprecision and recall, lack normalized scores, or make unrealistic assumptionsabout sequences. To address these limitations, we leverage the theory ofoptimal transport and construct WRDScore, a novel metric that strikes a balancebetween simplicity and effectiveness. In the WRDScore framework, we defineprecision as the maximum degree to which the predicted sequence's tokens areincluded in the reference sequence, token by token. Recall is calculated as thetotal cost of the optimal transport plan that maps the reference sequence tothe predicted one. Finally, WRDScore is computed as the harmonic mean ofprecision and recall, balancing these two complementary metrics. Our metric islightweight, normalized, and precision-recall-oriented, avoiding unrealisticassumptions while aligning well with human judgments. Experiments on ahuman-curated dataset confirm the superiority of WRDScore over other availabletext metrics.</description><author>Ravil Mussabayev</author><pubDate>Tue, 13 Aug 2024 13:32:07 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.19220v5</guid></item><item><title>Diffusion Model for Slate Recommendation</title><link>http://arxiv.org/abs/2408.06883v1</link><description>Slate recommendation is a technique commonly used on streaming platforms ande-commerce sites to present multiple items together. A significant challengewith slate recommendation is managing the complex combinatorial choice space.Traditional methods often simplify this problem by assuming users engage withonly one item at a time. However, this simplification does not reflect thereality, as users often interact with multiple items simultaneously. In thispaper, we address the general slate recommendation problem, which accounts forsimultaneous engagement with multiple items. We propose a generative approachusing Diffusion Models, leveraging their ability to learn structures inhigh-dimensional data. Our model generates high-quality slates that maximizeuser satisfaction by overcoming the challenges of the combinatorial choicespace. Furthermore, our approach enhances the diversity of recommendations.Extensive offline evaluations on applications such as music playlist generationand e-commerce bundle recommendations show that our model outperformsstate-of-the-art baselines in both relevance and diversity.</description><author>Federico Tomasi, Francesco Fabbri, Mounia Lalmas, Zhenwen Dai</author><pubDate>Tue, 13 Aug 2024 13:29:57 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.06883v1</guid></item><item><title>PBIR-NIE: Glossy Object Capture under Non-Distant Lighting</title><link>http://arxiv.org/abs/2408.06878v1</link><description>Glossy objects present a significant challenge for 3D reconstruction frommulti-view input images under natural lighting. In this paper, we introducePBIR-NIE, an inverse rendering framework designed to holistically capture thegeometry, material attributes, and surrounding illumination of such objects. Wepropose a novel parallax-aware non-distant environment map as a lightweight andefficient lighting representation, accurately modeling the near-fieldbackground of the scene, which is commonly encountered in real-world capturesetups. This feature allows our framework to accommodate complex parallaxeffects beyond the capabilities of standard infinite-distance environment maps.Our method optimizes an underlying signed distance field (SDF) throughphysics-based differentiable rendering, seamlessly connecting surface gradientsbetween a triangle mesh and the SDF via neural implicit evolution (NIE). Toaddress the intricacies of highly glossy BRDFs in differentiable rendering, weintegrate the antithetic sampling algorithm to mitigate variance in the MonteCarlo gradient estimator. Consequently, our framework exhibits robustcapabilities in handling glossy object reconstruction, showcasing superiorquality in geometry, relighting, and material estimation.</description><author>Guangyan Cai, Fujun Luan, Miloš Hašan, Kai Zhang, Sai Bi, Zexiang Xu, Iliyan Georgiev, Shuang Zhao</author><pubDate>Tue, 13 Aug 2024 13:26:24 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.06878v1</guid></item><item><title>Power Variable Projection for Initialization-Free Large-Scale Bundle Adjustment</title><link>http://arxiv.org/abs/2405.05079v5</link><description>Most Bundle Adjustment (BA) solvers like the Levenberg-Marquardt algorithmrequire a good initialization. Instead, initialization-free BA remains alargely uncharted territory. The under-explored Variable Projection algorithm(VarPro) exhibits a wide convergence basin even without initialization. Coupledwith object space error formulation, recent works have shown its ability tosolve small-scale initialization-free bundle adjustment problem. To make suchinitialization-free BA approaches scalable, we introduce Power VariableProjection (PoVar), extending a recent inverse expansion method based on powerseries. Importantly, we link the power series expansion to Riemannian manifoldoptimization. This projective framework is crucial to solve large-scale bundleadjustment problems without initialization. Using the real-world BAL dataset,we experimentally demonstrate that our solver achieves state-of-the-art resultsin terms of speed and accuracy. To our knowledge, this work is the first toaddress the scalability of BA without initialization opening new venues forinitialization-free structure-from-motion.</description><author>Simon Weber, Je Hyeong Hong, Daniel Cremers</author><pubDate>Tue, 13 Aug 2024 13:25:34 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.05079v5</guid></item><item><title>kNN-CLIP: Retrieval Enables Training-Free Segmentation on Continually Expanding Large Vocabularies</title><link>http://arxiv.org/abs/2404.09447v3</link><description>Continual segmentation has not yet tackled the challenge of improvingopen-vocabulary segmentation models with training data for accuratesegmentation across large, continually expanding vocabularies. We discover thattraditional continual training results in severe catastrophic forgetting,failing to outperform a zero-shot segmentation baseline. We introduce a noveltraining-free strategy, kNN-CLIP, which augments the model with a database ofinstance embeddings for semantic and panoptic segmentation that achieves zeroforgetting. We demonstrate that kNN-CLIP can adapt to continually growingvocabularies without the need for retraining or large memory costs. kNN-CLIPenables open-vocabulary segmentation methods to expand their vocabularies onany domain with a single pass through the data, while only storing compactembeddings. This approach minimizes both compute and memory costs. kNN-CLIPachieves state-of-the-art performance across large-vocabulary semantic andpanoptic segmentation datasets. We hope kNN-CLIP represents a significant stepforward in enabling more efficient and adaptable continual segmentation, pavingthe way for advances in real-world large-vocabulary continual segmentationmethods.</description><author>Zhongrui Gui, Shuyang Sun, Runjia Li, Jianhao Yuan, Zhaochong An, Karsten Roth, Ameya Prabhu, Philip Torr</author><pubDate>Tue, 13 Aug 2024 13:24:33 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.09447v3</guid></item><item><title>A Novel Computational and Modeling Foundation for Automatic Coherence Assessment</title><link>http://arxiv.org/abs/2310.00598v2</link><description>Coherence is an essential property of well-written texts, that refers to theway textual units relate to one another. In the era of generative AI, coherenceassessment is essential for many NLP tasks; summarization, generation,long-form question-answering, and more. However, in NLP {coherence} is anill-defined notion, not having a formal definition or evaluation metrics, thatwould allow for large-scale automatic and systematic coherence assessment. Tobridge this gap, in this work we employ the formal linguistic definition of\citet{Reinhart:1980} of what makes a discourse coherent, consisting of threeconditions -- {\em cohesion, consistency} and {\em relevance} -- and formalizethese conditions as respective computational tasks. We hypothesize that (i) amodel trained on all of these tasks will learn the features required forcoherence detection, and that (ii) a joint model for all tasks will exceed theperformance of models trained on each task individually. On two benchmarks forcoherence scoring rated by humans, one containing 500 automatically-generatedshort stories and another containing 4k real-world texts, our experimentsconfirm that jointly training on the proposed tasks leads to better performanceon each task compared with task-specific models, and to better performance onassessing coherence overall, compared with strong baselines. We conclude thatthe formal and computational setup of coherence as proposed here provides asolid foundation for advanced methods of large-scale automatic assessment ofcoherence.</description><author>Aviya Maimon, Reut Tsarfaty</author><pubDate>Tue, 13 Aug 2024 13:19:29 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.00598v2</guid></item><item><title>Decision-Focused Learning to Predict Action Costs for Planning</title><link>http://arxiv.org/abs/2408.06876v1</link><description>In many automated planning applications, action costs can be hard to specify.An example is the time needed to travel through a certain road segment, whichdepends on many factors, such as the current weather conditions. A natural wayto address this issue is to learn to predict these parameters based on inputfeatures (e.g., weather forecasts) and use the predicted action costs inautomated planning afterward. Decision-Focused Learning (DFL) has beensuccessful in learning to predict the parameters of combinatorial optimizationproblems in a way that optimizes solution quality rather than predictionquality. This approach yields better results than treating prediction andoptimization as separate tasks. In this paper, we investigate for the firsttime the challenges of implementing DFL for automated planning in order tolearn to predict the action costs. There are two main challenges to overcome:(1) planning systems are called during gradient descent learning, to solveplanning problems with negative action costs, which are not supported inplanning. We propose novel methods for gradient computation to avoid thisissue. (2) DFL requires repeated planner calls during training, which can limitthe scalability of the method. We experiment with different methodsapproximating the optimal plan as well as an easy-to-implement cachingmechanism to speed up the learning process. As the first work that addressesDFL for automated planning, we demonstrate that the proposed gradientcomputation consistently yields significantly better plans than predictionsaimed at minimizing prediction error; and that caching can temper thecomputation requirements.</description><author>Jayanta Mandi, Marco Foschini, Daniel Holler, Sylvie Thiebaux, Jorg Hoffmann, Tias Guns</author><pubDate>Tue, 13 Aug 2024 13:14:54 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.06876v1</guid></item><item><title>Advancing Interactive Explainable AI via Belief Change Theory</title><link>http://arxiv.org/abs/2408.06875v1</link><description>As AI models become ever more complex and intertwined in humans' daily lives,greater levels of interactivity of explainable AI (XAI) methods are needed. Inthis paper, we propose the use of belief change theory as a formal foundationfor operators that model the incorporation of new information, i.e. userfeedback in interactive XAI, to logical representations of data-drivenclassifiers. We argue that this type of formalisation provides a framework anda methodology to develop interactive explanations in a principled manner,providing warranted behaviour and favouring transparency and accountability ofsuch interactions. Concretely, we first define a novel, logic-based formalismto represent explanatory information shared between humans and machines. Wethen consider real world scenarios for interactive XAI, with differentprioritisations of new and existing knowledge, where our formalism may beinstantiated. Finally, we analyse a core set of belief change postulates,discussing their suitability for our real world settings and pointing toparticular challenges that may require the relaxation or reinterpretation ofsome of the theoretical assumptions underlying existing operators.</description><author>Antonio Rago, Maria Vanina Martinez</author><pubDate>Tue, 13 Aug 2024 13:11:56 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.06875v1</guid></item><item><title>Leveraging Language Models for Emotion and Behavior Analysis in Education</title><link>http://arxiv.org/abs/2408.06874v1</link><description>The analysis of students' emotions and behaviors is crucial for enhancinglearning outcomes and personalizing educational experiences. Traditionalmethods often rely on intrusive visual and physiological data collection,posing privacy concerns and scalability issues. This paper proposes a novelmethod leveraging large language models (LLMs) and prompt engineering toanalyze textual data from students. Our approach utilizes tailored prompts toguide LLMs in detecting emotional and engagement states, providing anon-intrusive and scalable solution. We conducted experiments using Qwen,ChatGPT, Claude2, and GPT-4, comparing our method against baseline models andchain-of-thought (CoT) prompting. Results demonstrate that our methodsignificantly outperforms the baselines in both accuracy and contextualunderstanding. This study highlights the potential of LLMs combined with promptengineering to offer practical and effective tools for educational emotion andbehavior analysis.</description><author>Kaito Tanaka, Benjamin Tan, Brian Wong</author><pubDate>Tue, 13 Aug 2024 13:11:53 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.06874v1</guid></item><item><title>Refractive COLMAP: Refractive Structure-from-Motion Revisited</title><link>http://arxiv.org/abs/2403.08640v3</link><description>In this paper, we present a complete refractive Structure-from-Motion (RSfM)framework for underwater 3D reconstruction using refractive camera setups (forboth, flat- and dome-port underwater housings). Despite notable achievements inrefractive multi-view geometry over the past decade, a robust, complete andpublicly available solution for such tasks is not available at present, andoften practical applications have to resort to approximating refraction effectsby the intrinsic (distortion) parameters of a pinhole camera model. To fillthis gap, we have integrated refraction considerations throughout the entireSfM process within the state-of-the-art, open-source SfM framework COLMAP.Numerical simulations and reconstruction results on synthetically generated butphoto-realistic images with ground truth validate that enabling refraction doesnot compromise accuracy or robustness as compared to in-air reconstructions.Finally, we demonstrate the capability of our approach for large-scalerefractive scenarios using a dataset consisting of nearly 6000 images. Theimplementation is released as open-source at:https://cau-git.rz.uni-kiel.de/inf-ag-koeser/colmap_underwater.</description><author>Mengkun She, Felix Seegräber, David Nakath, Kevin Köser</author><pubDate>Tue, 13 Aug 2024 13:10:08 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.08640v3</guid></item><item><title>Generative AI Tools in Academic Research: Applications and Implications for Qualitative and Quantitative Research Methodologies</title><link>http://arxiv.org/abs/2408.06872v1</link><description>This study examines the impact of Generative Artificial Intelligence (GenAI)on academic research, focusing on its application to qualitative andquantitative data analysis. As GenAI tools evolve rapidly, they offer newpossibilities for enhancing research productivity and democratising complexanalytical processes. However, their integration into academic practice raisessignificant questions regarding research integrity and security, authorship,and the changing nature of scholarly work. Through an examination of currentcapabilities and potential future applications, this study provides insightsinto how researchers may utilise GenAI tools responsibly and ethically. We present case studies that demonstrate the application of GenAI in variousresearch methodologies, discuss the challenges of replicability and consistencyin AI-assisted research, and consider the ethical implications of increased AIintegration in academia. This study explores both qualitative and quantitativeapplications of GenAI, highlighting tools for transcription, coding, thematicanalysis, visual analytics, and statistical analysis. By addressing theseissues, we aim to contribute to the ongoing discourse on the role of AI inshaping the future of academic research and provide guidance for researchersexploring the rapidly evolving landscape of AI-assisted research tools andresearch.</description><author>Mike Perkins, Jasper Roe</author><pubDate>Tue, 13 Aug 2024 13:10:03 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.06872v1</guid></item><item><title>Learning Optimal Filters Using Variational Inference</title><link>http://arxiv.org/abs/2406.18066v2</link><description>Filtering - the task of estimating the conditional distribution of states ofa dynamical system given partial, noisy, observations - is important in manyareas of science and engineering, including weather and climate prediction.However, the filtering distribution is generally intractable to obtain forhigh-dimensional, nonlinear systems. Filters used in practice, such as theensemble Kalman filter (EnKF), are biased for nonlinear systems and havenumerous tuning parameters. Here, we present a framework for learning aparameterized analysis map - the map that takes a forecast distribution andobservations to the filtering distribution - using variational inference. Weshow that this methodology can be used to learn gain matrices for filteringlinear and nonlinear dynamical systems, as well as inflation and localizationparameters for an EnKF. Future work will apply this framework to learn newfiltering algorithms.</description><author>Enoch Luk, Eviatar Bach, Ricardo Baptista, Andrew Stuart</author><pubDate>Tue, 13 Aug 2024 13:08:39 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.18066v2</guid></item><item><title>A Comprehensive Survey on Synthetic Infrared Image synthesis</title><link>http://arxiv.org/abs/2408.06868v1</link><description>Synthetic infrared (IR) scene and target generation is an important computervision problem as it allows the generation of realistic IR images and targetsfor training and testing of various applications, such as remote sensing,surveillance, and target recognition. It also helps reduce the cost and riskassociated with collecting real-world IR data. This survey paper aims toprovide a comprehensive overview of the conventional mathematicalmodelling-based methods and deep learning-based methods used for generatingsynthetic IR scenes and targets. The paper discusses the importance ofsynthetic IR scene and target generation and briefly covers the mathematics ofblackbody and grey body radiations, as well as IR image-capturing methods. Thepotential use cases of synthetic IR scenes and target generation are alsodescribed, highlighting the significance of these techniques in various fields.Additionally, the paper explores possible new ways of developing new techniquesto enhance the efficiency and effectiveness of synthetic IR scenes and targetgeneration while highlighting the need for further research to advance thisfield.</description><author>Avinash Upadhyay, Manoj sharma, Prerna Mukherjee, Amit Singhal, Brejesh Lall</author><pubDate>Tue, 13 Aug 2024 13:06:50 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.06868v1</guid></item></channel></rss>