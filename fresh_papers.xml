<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/"><channel><title>Arxivfresh papers</title><link></link><description>Arxiv paper</description><language>en-US</language><lastBuildDate>Thu, 28 Dec 2023 06:00:04 GMT</lastBuildDate><generator>rfeed v1.0.0</generator><docs>https://github.com/svpino/rfeed/blob/master/README.md</docs><item><title>Principled Instructions Are All You Need for Questioning LLaMA-1/2, GPT-3.5/4</title><link>http://arxiv.org/abs/2312.16171v1</link><description>This paper introduces 26 guiding principles designed to streamline theprocess of querying and prompting large language models. Our goal is tosimplify the underlying concepts of formulating questions for various scales oflarge language models, examining their abilities, and enhancing usercomprehension on the behaviors of different scales of large language modelswhen feeding into different prompts. Extensive experiments are conducted onLLaMA-1/2 (7B, 13B and 70B), GPT-3.5/4 to verify the effectiveness of theproposed principles on instructions and prompts design. We hope that this workprovides a better guide for researchers working on the prompting of largelanguage models. Project page is available athttps://github.com/VILA-Lab/ATLAS.</description><author>Sondos Mahmoud Bsharat, Aidar Myrzakhan, Zhiqiang Shen</author><pubDate>Tue, 26 Dec 2023 18:59:33 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.16171v1</guid></item><item><title>EmbodiedScan: A Holistic Multi-Modal 3D Perception Suite Towards Embodied AI</title><link>http://arxiv.org/abs/2312.16170v1</link><description>In the realm of computer vision and robotics, embodied agents are expected toexplore their environment and carry out human instructions. This necessitatesthe ability to fully understand 3D scenes given their first-person observationsand contextualize them into language for interaction. However, traditionalresearch focuses more on scene-level input and output setups from a globalview. To address the gap, we introduce EmbodiedScan, a multi-modal, ego-centric3D perception dataset and benchmark for holistic 3D scene understanding. Itencompasses over 5k scans encapsulating 1M ego-centric RGB-D views, 1M languageprompts, 160k 3D-oriented boxes spanning over 760 categories, some of whichpartially align with LVIS, and dense semantic occupancy with 80 commoncategories. Building upon this database, we introduce a baseline frameworknamed Embodied Perceptron. It is capable of processing an arbitrary number ofmulti-modal inputs and demonstrates remarkable 3D perception capabilities, bothwithin the two series of benchmarks we set up, i.e., fundamental 3D perceptiontasks and language-grounded tasks, and in the wild. Codes, datasets, andbenchmarks will be available at https://github.com/OpenRobotLab/EmbodiedScan.</description><author>Tai Wang, Xiaohan Mao, Chenming Zhu, Runsen Xu, Ruiyuan Lyu, Peisen Li, Xiao Chen, Wenwei Zhang, Kai Chen, Tianfan Xue, Xihui Liu, Cewu Lu, Dahua Lin, Jiangmiao Pang</author><pubDate>Tue, 26 Dec 2023 18:59:11 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.16170v1</guid></item><item><title>Social-Transmotion: Promptable Human Trajectory Prediction</title><link>http://arxiv.org/abs/2312.16168v1</link><description>Accurate human trajectory prediction is crucial for applications such asautonomous vehicles, robotics, and surveillance systems. Yet, existing modelsoften fail to fully leverage the non-verbal social cues human subconsciouslycommunicate when navigating the space. To address this, we introduceSocial-Transmotion, a generic model that exploits the power of transformers tohandle diverse and numerous visual cues, capturing the multi-modal nature ofhuman behavior. We translate the idea of a prompt from Natural LanguageProcessing (NLP) to the task of human trajectory prediction, where a prompt canbe a sequence of x-y coordinates on the ground, bounding boxes or body poses.This, in turn, augments trajectory data, leading to enhanced human trajectoryprediction. Our model exhibits flexibility and adaptability by capturingspatiotemporal interactions between pedestrians based on the available visualcues, whether they are poses, bounding boxes, or a combination thereof. By themasking technique, we ensure our model's effectiveness even when certain visualcues are unavailable, although performance is further boosted with the presenceof comprehensive visual data. We delve into the merits of using 2d versus 3dposes, and a limited set of poses. Additionally, we investigate the spatial andtemporal attention map to identify which keypoints and frames of poses arevital for optimizing human trajectory prediction. Our approach is validated onmultiple datasets, including JTA, JRDB, Pedestrians and Cyclists in RoadTraffic, and ETH-UCY. The code is publicly available:https://github.com/vita-epfl/social-transmotion</description><author>Saeed Saadatnejad, Yang Gao, Kaouther Messaoud, Alexandre Alahi</author><pubDate>Tue, 26 Dec 2023 18:56:49 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.16168v1</guid></item><item><title>FuNVol: A Multi-Asset Implied Volatility Market Simulator using Functional Principal Components and Neural SDEs</title><link>http://arxiv.org/abs/2303.00859v4</link><description>We introduce a new approach for generating sequences of implied volatility(IV) surfaces across multiple assets that is faithful to historical prices. Wedo so using a combination of functional data analysis and neural stochasticdifferential equations (SDEs) combined with a probability integral transformpenalty to reduce model misspecification. We demonstrate that learning thejoint dynamics of IV surfaces and prices produces market scenarios that areconsistent with historical features and lie within the sub-manifold of surfacesthat are essentially free of static arbitrage. Finally, we demonstrate thatdelta hedging using the simulated surfaces generates profit and loss (P&amp;L)distributions that are consistent with realised P&amp;Ls.</description><author>Vedant Choudhary, Sebastian Jaimungal, Maxime Bergeron</author><pubDate>Tue, 26 Dec 2023 18:52:53 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2303.00859v4</guid></item><item><title>SymmPI: Predictive Inference for Data with Group Symmetries</title><link>http://arxiv.org/abs/2312.16160v1</link><description>Quantifying the uncertainty of predictions is a core problem in modernstatistics. Methods for predictive inference have been developed under avariety of assumptions, often -- for instance, in standard conformal prediction-- relying on the invariance of the distribution of the data under specialgroups of transformations such as permutation groups. Moreover, many existingmethods for predictive inference aim to predict unobserved outcomes insequences of feature-outcome observations. Meanwhile, there is interest inpredictive inference under more general observation models (e.g., for partiallyobserved features) and for data satisfying more general distributionalsymmetries (e.g., rotationally invariant or coordinate-independent observationsin physics). Here we propose SymmPI, a methodology for predictive inferencewhen data distributions have general group symmetries in arbitrary observationmodels. Our methods leverage the novel notion of distributional equivarianttransformations, which process the data while preserving their distributionalinvariances. We show that SymmPI has valid coverage under distributionalinvariance and characterize its performance under distribution shift,recovering recent results as special cases. We apply SymmPI to predictunobserved values associated to vertices in a network, where the distributionis unchanged under relabelings that keep the network structure unchanged. Inseveral simulations in a two-layer hierarchical model, and in an empirical dataanalysis example, SymmPI performs favorably compared to existing methods.</description><author>Edgar Dobriban, Mengxin Yu</author><pubDate>Tue, 26 Dec 2023 18:41:14 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.16160v1</guid></item><item><title>Zero-Shot Cross-Lingual Reranking with Large Language Models for Low-Resource Languages</title><link>http://arxiv.org/abs/2312.16159v1</link><description>Large language models (LLMs) have shown impressive zero-shot capabilities invarious document reranking tasks. Despite their successful implementations,there is still a gap in existing literature on their effectiveness inlow-resource languages. To address this gap, we investigate how LLMs functionas rerankers in cross-lingual information retrieval (CLIR) systems for Africanlanguages. Our implementation covers English and four African languages (Hausa,Somali, Swahili, and Yoruba) and we examine cross-lingual reranking withqueries in English and passages in the African languages. Additionally, weanalyze and compare the effectiveness of monolingual reranking using both queryand document translations. We also evaluate the effectiveness of LLMs whenleveraging their own generated translations. To get a grasp of theeffectiveness of multiple LLMs, our study focuses on the proprietary modelsRankGPT-4 and RankGPT-3.5, along with the open-source model, RankZephyr. Whilereranking remains most effective in English, our results reveal thatcross-lingual reranking may be competitive with reranking in African languagesdepending on the multilingual capability of the LLM.</description><author>Mofetoluwa Adeyemi, Akintunde Oladipo, Ronak Pradeep, Jimmy Lin</author><pubDate>Tue, 26 Dec 2023 18:38:54 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.16159v1</guid></item><item><title>Association rule mining with earthquake data collected from Turkiye region</title><link>http://arxiv.org/abs/2312.16158v1</link><description>Earthquakes are evaluated among the most destructive disasters for humanbeings, as also experienced for Turkiye region. Data science has the propertyof discovering hidden patterns in case a sufficient volume of data is supplied.Time dependency of events, specifically being defined by co-occurrence in aspecific time window, may be handled as an associate rule mining task such as amarket-basket analysis application. In this regard, we assumed each day'sseismic activity as a single basket of events, leading to discovering theassociation patterns between these events. Consequently, this study presentsthe most prominent association rules for the earthquakes recorded in Turkiyeregion in the last 5 years, each year presented separately. Results indicatestatistical inference with events recorded from regions of various distances,which could be further verified with geologic evidence from the field. As aresult, we believe that the current study may form a statistical basis for thefuture works with the aid of machine learning algorithm performed for associaterule mining.</description><author>Baha Alturan, Ilker Turker</author><pubDate>Tue, 26 Dec 2023 18:36:01 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.16158v1</guid></item><item><title>Robust Risk-Aware Option Hedging</title><link>http://arxiv.org/abs/2303.15216v3</link><description>The objectives of option hedging/trading extend beyond mere protectionagainst downside risks, with a desire to seek gains also driving agent'sstrategies. In this study, we showcase the potential of robust risk-awarereinforcement learning (RL) in mitigating the risks associated withpath-dependent financial derivatives. We accomplish this by leveraging a policygradient approach that optimises robust risk-aware performance criteria. Wespecifically apply this methodology to the hedging of barrier options, andhighlight how the optimal hedging strategy undergoes distortions as the agentmoves from being risk-averse to risk-seeking. As well as how the agentrobustifies their strategy. We further investigate the performance of the hedgewhen the data generating process (DGP) varies from the training DGP, anddemonstrate that the robust strategies outperform the non-robust ones.</description><author>David Wu, Sebastian Jaimungal</author><pubDate>Tue, 26 Dec 2023 18:31:56 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2303.15216v3</guid></item><item><title>From Text to Multimodal: A Comprehensive Survey of Adversarial Example Generation in Question Answering Systems</title><link>http://arxiv.org/abs/2312.16156v1</link><description>Integrating adversarial machine learning with Question Answering (QA) systemshas emerged as a critical area for understanding the vulnerabilities androbustness of these systems. This article aims to comprehensively reviewadversarial example-generation techniques in the QA field, including textualand multimodal contexts. We examine the techniques employed through systematiccategorization, providing a comprehensive, structured review. Beginning with anoverview of traditional QA models, we traverse the adversarial examplegeneration by exploring rule-based perturbations and advanced generativemodels. We then extend our research to include multimodal QA systems, analyzethem across various methods, and examine generative models, seq2seqarchitectures, and hybrid methodologies. Our research grows to differentdefense strategies, adversarial datasets, and evaluation metrics andillustrates the comprehensive literature on adversarial QA. Finally, the paperconsiders the future landscape of adversarial question generation, highlightingpotential research directions that can advance textual and multimodal QAsystems in the context of adversarial challenges.</description><author>Gulsum Yigit, Mehmet Fatih Amasyali</author><pubDate>Tue, 26 Dec 2023 18:30:29 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.16156v1</guid></item><item><title>The Clustered Orienteering Problem with Subgroups</title><link>http://arxiv.org/abs/2312.16154v1</link><description>This paper introduces an extension to the Orienteering Problem (OP), calledClustered Orienteering Problem with Subgroups (COPS). In this variant, nodesare arranged into subgroups, and the subgroups are organized into clusters. Areward is associated with each subgroup and is gained only if all of its nodesare visited; however, at most one subgroup can be visited per cluster. Theobjective is to maximize the total collected reward while attaining a travelbudget. We show that our new formulation has the ability to model and solve twoprevious well-known variants, the Clustered Orienteering Problem (COP) and theSet Orienteering Problem (SOP), in addition to other scenarios introduced here.An Integer Linear Programming (ILP) formulation and a Tabu Search-basedheuristic are proposed to solve the problem. Experimental results indicate thatthe ILP method can yield optimal solutions at the cost of time, whereas themetaheuristic produces comparable solutions within a more reasonablecomputational cost.</description><author>Luciano E. Almeida, Douglas G. Macharet</author><pubDate>Tue, 26 Dec 2023 18:28:25 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.16154v1</guid></item><item><title>Large-scale Long-tailed Disease Diagnosis on Radiology Images</title><link>http://arxiv.org/abs/2312.16151v1</link><description>In this study, we aim to investigate the problem of large-scale,large-vocabulary disease classification for radiologic images, which can beformulated as a multi-modal, multi-anatomy, multi-label, long-tailedclassification. Our main contributions are three folds: (i), on datasetconstruction, we build up an academically accessible, large-scale diagnosticdataset that encompasses 5568 disorders linked with 930 unique ICD-10-CM codes,containing 39,026 cases (192,675 scans). (ii), on model design, we present anovel architecture that enables to process arbitrary number of input scans,from various imaging modalities, which is trained with knowledge enhancement toleverage the rich domain knowledge; (iii), on evaluation, we initialize a newbenchmark for multi-modal multi-anatomy long-tailed diagnosis. Our method showssuperior results on it. Additionally, our final model serves as a pre-trainedmodel, and can be finetuned to benefit diagnosis on various external datasets.</description><author>Qiaoyu Zheng, Weike Zhao, Chaoyi Wu, Xiaoman Zhang, Ya Zhang, Yanfeng Wang, Weidi Xie</author><pubDate>Tue, 26 Dec 2023 18:20:48 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.16151v1</guid></item><item><title>Fact-checking information generated by a large language model can decrease news discernment</title><link>http://arxiv.org/abs/2308.10800v3</link><description>Fact checking can be an effective strategy against misinformation, but itsimplementation at scale is impeded by the overwhelming volume of informationonline. Recent artificial intelligence (AI) language models have shownimpressive ability in fact-checking tasks, but how humans interact withfact-checking information provided by these models is unclear. Here, weinvestigate the impact of fact-checking information generated by a popularlarge language model (LLM) on belief in, and sharing intent of, political newsin a preregistered randomized control experiment. Although the LLM performsreasonably well in debunking false headlines, we find that it does notsignificantly affect participants' ability to discern headline accuracy orshare accurate news. Subsequent analysis reveals that the AI fact-checker isharmful in specific cases: it decreases beliefs in true headlines that itmislabels as false and increases beliefs in false headlines that it is unsureabout. On the positive side, the AI fact-checking information increases sharingintents for correctly labeled true headlines. When participants are given theoption to view LLM fact checks and choose to do so, they are significantly morelikely to share both true and false news but only more likely to believe falsenews. Our findings highlight an important source of potential harm stemmingfrom AI applications and underscore the critical need for policies to preventor mitigate such unintended consequences.</description><author>Matthew R. DeVerna, Harry Yaojun Yan, Kai-Cheng Yang, Filippo Menczer</author><pubDate>Tue, 26 Dec 2023 18:20:20 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2308.10800v3</guid></item><item><title>Differentiable Blocks World: Qualitative 3D Decomposition by Rendering Primitives</title><link>http://arxiv.org/abs/2307.05473v2</link><description>Given a set of calibrated images of a scene, we present an approach thatproduces a simple, compact, and actionable 3D world representation by means of3D primitives. While many approaches focus on recovering high-fidelity 3Dscenes, we focus on parsing a scene into mid-level 3D representations made of asmall set of textured primitives. Such representations are interpretable, easyto manipulate and suited for physics-based simulations. Moreover, unlikeexisting primitive decomposition methods that rely on 3D input data, ourapproach operates directly on images through differentiable rendering.Specifically, we model primitives as textured superquadric meshes and optimizetheir parameters from scratch with an image rendering loss. We highlight theimportance of modeling transparency for each primitive, which is critical foroptimization and also enables handling varying numbers of primitives. We showthat the resulting textured primitives faithfully reconstruct the input imagesand accurately model the visible 3D points, while providing amodal shapecompletions of unseen object regions. We compare our approach to the state ofthe art on diverse scenes from DTU, and demonstrate its robustness on real-lifecaptures from BlendedMVS and Nerfstudio. We also showcase how our results canbe used to effortlessly edit a scene or perform physical simulations. Code andvideo results are available at https://www.tmonnier.com/DBW .</description><author>Tom Monnier, Jake Austin, Angjoo Kanazawa, Alexei A. Efros, Mathieu Aubry</author><pubDate>Tue, 26 Dec 2023 18:16:08 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.05473v2</guid></item><item><title>The Media Bias Taxonomy: A Systematic Literature Review on the Forms and Automated Detection of Media Bias</title><link>http://arxiv.org/abs/2312.16148v1</link><description>The way the media presents events can significantly affect public perception,which in turn can alter people's beliefs and views. Media bias describes aone-sided or polarizing perspective on a topic. This article summarizes theresearch on computational methods to detect media bias by systematicallyreviewing 3140 research papers published between 2019 and 2022. To structureour review and support a mutual understanding of bias across research domains,we introduce the Media Bias Taxonomy, which provides a coherent overview of thecurrent state of research on media bias from different perspectives. We showthat media bias detection is a highly active research field, in whichtransformer-based classification approaches have led to significantimprovements in recent years. These improvements include higher classificationaccuracy and the ability to detect more fine-granular types of bias. However,we have identified a lack of interdisciplinarity in existing projects, and aneed for more awareness of the various types of media bias to supportmethodologically thorough performance evaluations of media bias detectionsystems. Concluding from our analysis, we see the integration of recent machinelearning advancements with reliable and diverse bias assessment strategies fromother research areas as the most promising area for future researchcontributions in the field.</description><author>Timo Spinde, Smilla Hinterreiter, Fabian Haak, Terry Ruas, Helge Giese, Norman Meuschke, Bela Gipp</author><pubDate>Tue, 26 Dec 2023 18:13:52 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.16148v1</guid></item><item><title>One-dimensional Adapter to Rule Them All: Concepts, Diffusion Models and Erasing Applications</title><link>http://arxiv.org/abs/2312.16145v1</link><description>The prevalent use of commercial and open-source diffusion models (DMs) fortext-to-image generation prompts risk mitigation to prevent undesiredbehaviors. Existing concept erasing methods in academia are all based on fullparameter or specification-based fine-tuning, from which we observe thefollowing issues: 1) Generation alternation towards erosion: Parameter driftduring target elimination causes alternations and potential deformations acrossall generations, even eroding other concepts at varying degrees, which is moreevident with multi-concept erased; 2) Transfer inability &amp; deploymentinefficiency: Previous model-specific erasure impedes the flexible combinationof concepts and the training-free transfer towards other models, resulting inlinear cost growth as the deployment scenarios increase. To achievenon-invasive, precise, customizable, and transferable elimination, we groundour erasing framework on one-dimensional adapters to erase multiple conceptsfrom most DMs at once across versatile erasing applications. Theconcept-SemiPermeable structure is injected as a Membrane (SPM) into any DM tolearn targeted erasing, and meantime the alteration and erosion phenomenon iseffectively mitigated via a novel Latent Anchoring fine-tuning strategy. Onceobtained, SPMs can be flexibly combined and plug-and-play for other DMs withoutspecific re-tuning, enabling timely and efficient adaptation to diversescenarios. During generation, our Facilitated Transport mechanism dynamicallyregulates the permeability of each SPM to respond to different input prompts,further minimizing the impact on other concepts. Quantitative and qualitativeresults across ~40 concepts, 7 DMs and 4 erasing applications have demonstratedthe superior erasing of SPM. Our code and pre-tuned SPMs will be available onthe project page https://lyumengyao.github.io/projects/spm.</description><author>Mengyao Lyu, Yuhong Yang, Haiwen Hong, Hui Chen, Xuan Jin, Yuan He, Hui Xue, Jungong Han, Guiguang Ding</author><pubDate>Tue, 26 Dec 2023 18:08:48 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.16145v1</guid></item><item><title>JaColBERT and Hard Negatives, Towards Better Japanese-First Embeddings for Retrieval: Early Technical Report</title><link>http://arxiv.org/abs/2312.16144v1</link><description>Document retrieval in many languages has been largely relying onmulti-lingual models, and leveraging the vast wealth of English training data.In Japanese, the best performing deep-learning based retrieval approaches relyon multilingual dense embeddings. In this work, we introduce (1) ahard-negative augmented version of the Japanese MMARCO dataset and (2)JaColBERT, a document retrieval model built on the ColBERT model architecture,specifically for Japanese. JaColBERT vastly outperform all previous monolingualretrieval approaches and competes with the best multilingual methods, despiteunfavourable evaluation settings (out-of-domain vs. in-domain for themultilingual models). JaColBERT reaches an average Recall@10 of 0.813,noticeably ahead of the previous monolingual best-performing model (0.716) andonly slightly behind multilingual-e5-base (0.820), though more noticeablybehind multilingual-e5-large (0.856). These results are achieved using only alimited, entirely Japanese, training set, more than two orders of magnitudessmaller than multilingual embedding models. We believe these results show greatpromise to support retrieval-enhanced application pipelines in a wide varietyof domains.</description><author>Benjamin Clavié</author><pubDate>Tue, 26 Dec 2023 18:07:05 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.16144v1</guid></item><item><title>On the Trajectories of SGD Without Replacement</title><link>http://arxiv.org/abs/2312.16143v1</link><description>This article examines the implicit regularization effect of StochasticGradient Descent (SGD). We consider the case of SGD without replacement, thevariant typically used to optimize large-scale neural networks. We analyze thisalgorithm in a more realistic regime than typically considered in theoreticalworks on SGD, as, e.g., we allow the product of the learning rate and Hessianto be $O(1)$. Our core theoretical result is that optimizing with SGD withoutreplacement is locally equivalent to making an additional step on a novelregularizer. This implies that the trajectory of SGD without replacementdiverges from both noise-injected GD and SGD with replacement (in which batchesare sampled i.i.d.). Indeed, the two SGDs travel flat regions of the losslandscape in distinct directions and at different speeds. In expectation, SGDwithout replacement may escape saddles significantly faster and present asmaller variance. Moreover, we find that SGD implicitly regularizes the traceof the noise covariance in the eigendirections of small and negative Hessianeigenvalues. This coincides with penalizing a weighted trace of the FisherMatrix and the Hessian on several vision tasks, thus encouraging sparsity inthe spectrum of the Hessian of the loss in line with empirical observationsfrom prior work. We also propose an explanation for why SGD does not train atthe edge of stability (as opposed to GD).</description><author>Pierfrancesco Beneventano</author><pubDate>Tue, 26 Dec 2023 18:06:48 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.16143v1</guid></item><item><title>Transformers Go for the LOLs: Generating (Humourous) Titles from Scientific Abstracts End-to-End</title><link>http://arxiv.org/abs/2212.10522v2</link><description>We consider the end-to-end abstract-to-title generation problem, exploringseven recent transformer based models (including ChatGPT) fine-tuned on morethan 30k abstract-title pairs from NLP and machine learning (ML) venues. As anextension, we also consider the harder problem of generating humorous papertitles. For the latter, we compile the first large-scale humor annotateddataset for scientific papers in the NLP/ML domains, comprising almost ~2.6ktitles. We evaluate all models using human and automatic metrics. Our humanevaluation suggests that our best end-to-end system performs similarly to humanauthors (but arguably slightly worse). Generating funny titles is moredifficult, however, and our automatic systems clearly underperform relative tohumans and often learn dataset artefacts of humor. Finally, ChatGPT, withoutany fine-tuning, performs on the level of our best fine-tuned system.</description><author>Yanran Chen, Steffen Eger</author><pubDate>Tue, 26 Dec 2023 18:05:42 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2212.10522v2</guid></item><item><title>A Bayesian Framework of Deep Reinforcement Learning for Joint O-RAN/MEC Orchestration</title><link>http://arxiv.org/abs/2312.16142v1</link><description>Multi-access Edge Computing (MEC) can be implemented together with Open RadioAccess Network (O-RAN) over commodity platforms to offer low-cost deploymentand bring the services closer to end-users. In this paper, a joint O-RAN/MECorchestration using a Bayesian deep reinforcement learning (RL)-based frameworkis proposed that jointly controls the O-RAN functional splits, the allocatedresources and hosting locations of the O-RAN/MEC services acrossgeo-distributed platforms, and the routing for each O-RAN/MEC data flow. Thegoal is to minimize the long-term overall network operation cost and maximizethe MEC performance criterion while adapting possibly time-varying O-RAN/MECdemands and resource availability. This orchestration problem is formulated asMarkov decision process (MDP). However, the system consists of multiple BSsthat share the same resources and serve heterogeneous demands, where theirparameters have non-trivial relations. Consequently, finding the exact model ofthe underlying system is impractical, and the formulated MDP renders in a largestate space with multi-dimensional discrete action. To address such modelingand dimensionality issues, a novel model-free RL agent is proposed for oursolution framework. The agent is built from Double Deep Q-network (DDQN) thattackles the large state space and is then incorporated with action branching,an action decomposition method that effectively addresses the multi-dimensionaldiscrete action with linear increase complexity. Further, an efficientexploration-exploitation strategy under a Bayesian framework using Thomsonsampling is proposed to improve the learning performance and expedite itsconvergence. Trace-driven simulations are performed using an O-RAN-compliantmodel. The results show that our approach is data-efficient (i.e., convergesfaster) and increases the returned reward by 32\% than its non-Bayesianversion.</description><author>Fahri Wisnu Murti, Samad Ali, Matti Latva-aho</author><pubDate>Tue, 26 Dec 2023 18:04:49 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.16142v1</guid></item><item><title>VirtualPainting: Addressing Sparsity with Virtual Points and Distance-Aware Data Augmentation for 3D Object Detection</title><link>http://arxiv.org/abs/2312.16141v1</link><description>In recent times, there has been a notable surge in multimodal approaches thatdecorates raw LiDAR point clouds with camera-derived features to improve objectdetection performance. However, we found that these methods still grapple withthe inherent sparsity of LiDAR point cloud data, primarily because fewer pointsare enriched with camera-derived features for sparsely distributed objects. Wepresent an innovative approach that involves the generation of virtual LiDARpoints using camera images and enhancing these virtual points with semanticlabels obtained from image-based segmentation networks to tackle this issue andfacilitate the detection of sparsely distributed objects, particularly thosethat are occluded or distant. Furthermore, we integrate a distance aware dataaugmentation (DADA) technique to enhance the models capability to recognizethese sparsely distributed objects by generating specialized training samples.Our approach offers a versatile solution that can be seamlessly integrated intovarious 3D frameworks and 2D semantic segmentation methods, resulting insignificantly improved overall detection accuracy. Evaluation on the KITTI andnuScenes datasets demonstrates substantial enhancements in both 3D and birdseye view (BEV) detection benchmarks</description><author>Sudip Dhakal, Dominic Carrillo, Deyuan Qu, Michael Nutt, Qing Yang, Song Fu</author><pubDate>Tue, 26 Dec 2023 18:03:05 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.16141v1</guid></item><item><title>Learning robust marking policies for adaptive mesh refinement</title><link>http://arxiv.org/abs/2207.06339v2</link><description>In this work, we revisit the marking decisions made in the standard adaptivefinite element method (AFEM). Experience shows that a na\"{i}ve marking policyleads to inefficient use of computational resources for adaptive meshrefinement (AMR). Consequently, using AFEM in practice often involves ad-hoc ortime-consuming offline parameter tuning to set appropriate parameters for themarking subroutine. To address these practical concerns, we recast AMR as aMarkov decision process in which refinement parameters can be selectedon-the-fly at run time, without the need for pre-tuning by expert users. Inthis new paradigm, the refinement parameters are also chosen adaptively via amarking policy that can be optimized using methods from reinforcement learning.We use the Poisson equation to demonstrate our techniques on $h$- and$hp$-refinement benchmark problems, and our experiments suggest that superiormarking policies remain undiscovered for many classical AFEM applications.Furthermore, an unexpected observation from this work is that marking policiestrained on one family of PDEs are sometimes robust enough to perform well onproblems far outside the training family. For illustration, we show that asimple $hp$-refinement policy trained on 2D domains with only a singlere-entrant corner can be deployed on far more complicated 2D domains, and even3D domains, without significant performance loss. For reproduction and broaderadoption, we accompany this work with an open-source implementation of ourmethods.</description><author>Andrew Gillette, Brendan Keith, Socratis Petrides</author><pubDate>Tue, 26 Dec 2023 18:00:31 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2207.06339v2</guid></item><item><title>Anomaly component analysis</title><link>http://arxiv.org/abs/2312.16139v1</link><description>At the crossway of machine learning and data analysis, anomaly detection aimsat identifying observations that exhibit abnormal behaviour. Be it measurementerrors, disease development, severe weather, production quality default(s)(items) or failed equipment, financial frauds or crisis events, their on-timeidentification and isolation constitute an important task in almost any area ofindustry and science. While a substantial body of literature is devoted todetection of anomalies, little attention is payed to their explanation. This isthe case mostly due to intrinsically non-supervised nature of the task andnon-robustness of the exploratory methods like principal component analysis(PCA). We introduce a new statistical tool dedicated for exploratory analysis ofabnormal observations using data depth as a score. Anomaly component analysis(shortly ACA) is a method that searches a low-dimensional data representationthat best visualises and explains anomalies. This low-dimensionalrepresentation not only allows to distinguish groups of anomalies better thanthe methods of the state of the art, but as well provides a -- linear invariables and thus easily interpretable -- explanation for anomalies. In acomparative simulation and real-data study, ACA also proves advantageous foranomaly analysis with respect to methods present in the literature.</description><author>Romain Valla, Pavlo Mozharovskyi, Florence d'Alché-Buc</author><pubDate>Tue, 26 Dec 2023 17:57:46 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.16139v1</guid></item><item><title>RoleEval: A Bilingual Role Evaluation Benchmark for Large Language Models</title><link>http://arxiv.org/abs/2312.16132v1</link><description>The rapid evolution of large language models (LLMs) necessitates effectivebenchmarks for evaluating their role knowledge, which is essential forestablishing connections with the real world and providing more immersiveinteractions. This paper introduces RoleEval, a bilingual benchmark designed toassess the memorization, utilization, and reasoning capabilities of roleknowledge. RoleEval comprises RoleEval-Global (including internationallyrecognized characters) and RoleEval-Chinese (including characters popular inChina), with 6,000 Chinese-English parallel multiple-choice questions focusingon 300 influential people and fictional characters drawn from a variety ofdomains including celebrities, anime, comics, movies, TV series, games, andfiction. These questions cover basic knowledge and multi-hop reasoningabilities, aiming to systematically probe various aspects such as personalinformation, relationships, abilities, and experiences of the characters. Tomaintain high standards, we perform a hybrid quality check process combiningautomatic and human verification, ensuring that the questions are diverse,challenging, and discriminative. Our extensive evaluations of RoleEval across various open-source andproprietary large language models, under both the zero- and few-shot settings,reveal insightful findings. Notably, while GPT-4 outperforms other models onRoleEval-Global, Chinese LLMs excel on RoleEval-Chinese, highlightingsignificant knowledge distribution differences. We expect that RoleEval willhighlight the significance of assessing role knowledge for foundation modelsacross various languages and cultural settings.</description><author>Tianhao Shen, Sun Li, Deyi Xiong</author><pubDate>Tue, 26 Dec 2023 17:40:55 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.16132v1</guid></item><item><title>Sparsity-Aware Distributed Learning for Gaussian Processes with Linear Multiple Kernel</title><link>http://arxiv.org/abs/2309.08201v2</link><description>Gaussian processes (GPs) stand as crucial tools in machine learning andsignal processing, with their effectiveness hinging on kernel design andhyper-parameter optimization. This paper presents a novel GP linear multiplekernel (LMK) and a generic sparsity-aware distributed learning framework tooptimize the hyper-parameters. The newly proposed grid spectral mixture (GSM)kernel is tailored for multi-dimensional data, effectively reducing the numberof hyper-parameters while maintaining good approximation capabilities. Wefurther demonstrate that the associated hyper-parameter optimization of thiskernel yields sparse solutions. To exploit the inherent sparsity property ofthe solutions, we introduce the Sparse LInear Multiple Kernel Learning(SLIM-KL) framework. The framework incorporates a quantized alternatingdirection method of multipliers (ADMM) scheme for collaborative learning amongmultiple agents, where the local optimization problem is solved using adistributed successive convex approximation (DSCA) algorithm. SLIM-KLeffectively manages large-scale hyper-parameter optimization for the proposedkernel, simultaneously ensuring data privacy and minimizing communicationcosts. Theoretical analysis establishes convergence guarantees for the learningframework, while experiments on diverse datasets demonstrate the superiorprediction performance and efficiency of our proposed methods.</description><author>Richard Cornelius Suwandi, Zhidi Lin, Feng Yin, Zhiguo Wang, Sergios Theodoridis</author><pubDate>Tue, 26 Dec 2023 17:35:32 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2309.08201v2</guid></item><item><title>Ensemble forecasts in reproducing kernel Hilbert space family</title><link>http://arxiv.org/abs/2207.14653v3</link><description>A methodological framework for ensemble-based estimation and simulation ofhigh dimensional dynamical systems such as the oceanic or atmospheric flows isproposed. To that end, the dynamical system is embedded in a family ofreproducing kernel Hilbert spaces (RKHS) with kernel functions driven by thedynamics. In the RKHS family, the Koopman and Perron-Frobenius operators areunitary and uniformly continuous. This property warrants they can be expressedin exponential series of diagonalizable bounded evolution operators definedfrom their infinitesimal generators. Access to Lyapunov exponents and to exactensemble based expressions of the tangent linear dynamics are directlyavailable as well. The RKHS family enables us the devise of strikingly simpleensemble data assimilation methods for trajectory reconstructions in terms ofconstant-in-time linear combinations of trajectory samples. Such anembarrassingly simple strategy is made possible through a fully justifiedsuperposition principle ensuing from several fundamental theorems.</description><author>Benjamin Dufée, Bérenger Hug, Etienne Mémin, Gilles Tissot</author><pubDate>Tue, 26 Dec 2023 17:25:54 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2207.14653v3</guid></item><item><title>Large Language Model Situational Awareness Based Planning</title><link>http://arxiv.org/abs/2312.16127v1</link><description>This work pioneers evaluating emergent planning capabilities based onsituational awareness in large language models. We contribute (i) novelbenchmarks and metrics for standardized assessment; (ii) a unique dataset tospur progress; and (iii) demonstrations that prompting and multi-agent schemessignificantly enhance planning performance in context-sensitive planning tasks.Positioning this within a situated agent and automated planning research, wehighlight inherent reliability challenges--efficiently mapping world states toactions without environmental guidance remains open despite simulated domainadvances. Although out-of-scope, limitations around validation methodology anddata availability indicate exciting directions, including fine-tuning onexpanded planning corpora and optimizations for triggering fast latentplanning. By conclusively demonstrating current methods' promise andlimitations via rigorous comparison, we catalyze investigating reliablegoal-directed reasoning for situated agents.</description><author>Liman Wang, Hanyang Zhong</author><pubDate>Tue, 26 Dec 2023 17:19:09 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.16127v1</guid></item><item><title>Olfactory Label Prediction on aroma-chemical Pairs</title><link>http://arxiv.org/abs/2312.16124v1</link><description>The application of deep learning techniques on aroma-chemicals has resultedin models more accurate than human experts at predicting olfactory qualities.However, public research in this domain has been limited to predicting thequalities of single molecules, whereas in industry applications, perfumers andfood scientists are often concerned with blends of many odorants. In thispaper, we apply both existing and novel approaches to a dataset we gatheredconsisting of labeled pairs of molecules. We present a publicly available modelcapable of generating accurate predictions for the non-linear qualities arisingfrom blends of aroma-chemicals.</description><author>Laura Sisson</author><pubDate>Tue, 26 Dec 2023 17:18:09 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.16124v1</guid></item><item><title>SimCLF: A Simple Contrastive Learning Framework for Function-level Binary Embeddings</title><link>http://arxiv.org/abs/2209.02442v2</link><description>Function-level binary code similarity detection is a crucial aspect ofcybersecurity. It enables the detection of bugs and patent infringements inreleased software and plays a pivotal role in preventing supply chain attacks.A practical embedding learning framework relies on the robustness of theassembly code representation and the accuracy of function-pair annotation,which is traditionally accomplished using supervised learning-based frameworks.However, annotating different function pairs with accurate labels posesconsiderable challenges. These supervised learning methods can be easilyovertrained and suffer from representation robustness problems. To addressthese challenges, we propose SimCLF: A Simple Contrastive Learning Frameworkfor Function-level Binary Embeddings. We take an unsupervised learning approachand formulate binary code similarity detection as instance discrimination.SimCLF directly operates on disassembled binary functions and could beimplemented with any encoder. It does not require manually annotatedinformation but only augmented data. Augmented data is generated using compileroptimization options and code obfuscation techniques. The experimental resultsdemonstrate that SimCLF surpasses the state-of-the-art in accuracy and has asignificant advantage in few-shot settings.</description><author>Sun RuiJin, Guo Shize, Guo Jinhong, Li Wei, Zhan Dazhi, Sun Meng, Pan Zhisong</author><pubDate>Tue, 26 Dec 2023 17:11:43 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2209.02442v2</guid></item><item><title>A bi-objective $ε$-constrained framework for quality-cost optimization in language model ensembles</title><link>http://arxiv.org/abs/2312.16119v1</link><description>We propose an ensembling framework that uses diverse open-sourced LargeLanguage Models (LLMs) to achieve high response quality while maintaining costefficiency. We formulate a bi-objective optimization problem to represent thequality-cost tradeoff and then introduce an additional budget constraint thatreduces the problem to a straightforward 0/1 knapsack problem. We empiricallydemonstrate that our framework outperforms the existing ensembling approachesin response quality while significantly reducing costs.</description><author>Aditi Singla, Aditya Singh, Kanishk Kukreja</author><pubDate>Tue, 26 Dec 2023 16:56:22 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.16119v1</guid></item><item><title>Ontology Revision based on Pre-trained Language Models</title><link>http://arxiv.org/abs/2310.18378v2</link><description>Ontology revision aims to seamlessly incorporate a new ontology into anexisting ontology and plays a crucial role in tasks such as ontology evolution,ontology maintenance, and ontology alignment. Similar to repair singleontologies, resolving logical incoherence in the task of ontology revision isalso important and meaningful, because incoherence is a main potential factorto cause inconsistency and reasoning with an inconsistent ontology will obtainmeaningless answers.To deal with this problem, various ontology revisionapproaches have been proposed to define revision operators and design rankingstrategies for axioms in an ontology. However, they rarely consider axiomsemantics which provides important information to differentiate axioms. Inaddition, pre-trained models can be utilized to encode axiom semantics, andhave been widely applied in many natural language processing tasks andontology-related ones in recent years.Therefore, in this paper, we study how toapply pre-trained models to revise ontologies. We first define four scoringfunctions to rank axioms based on a pre-trained model by considering variousinformation from an ontology. Based on the functions, an ontology revisionalgorithm is then proposed to deal with unsatisfiable concepts at once. Toimprove efficiency, an adapted revision algorithm is designed to deal withunsatisfiable concepts group by group. We conduct experiments over 19 ontologypairs and compare our algorithms and scoring functions with existing ones.According to the experiments, our algorithms could achieve promisingperformance.</description><author>Qiu Ji, Guilin Qi, Yuxin Ye, Jiaye Li, Site Li, Jianjie Ren, Songtao Lu</author><pubDate>Tue, 26 Dec 2023 16:56:19 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.18378v2</guid></item><item><title>Quantum-Hybrid Stereo Matching With Nonlinear Regularization and Spatial Pyramids</title><link>http://arxiv.org/abs/2312.16118v1</link><description>Quantum visual computing is advancing rapidly. This paper presents a newformulation for stereo matching with nonlinear regularizers and spatialpyramids on quantum annealers as a maximum a posteriori inference problem thatminimizes the energy of a Markov Random Field. Our approach is hybrid (i.e.,quantum-classical) and is compatible with modern D-Wave quantum annealers,i.e., it includes a quadratic unconstrained binary optimization (QUBO)objective. Previous quantum annealing techniques for stereo matching arelimited to using linear regularizers, and thus, they do not exploit thefundamental advantages of the quantum computing paradigm in solvingcombinatorial optimization problems. In contrast, our method utilizes the fullpotential of quantum annealing for stereo matching, as nonlinear regularizerscreate optimization problems which are NP-hard. On the Middlebury benchmark, weachieve an improved root mean squared accuracy over the previous state of theart in quantum stereo matching of 2% and 22.5% when using different solvers.</description><author>Cameron Braunstein, Eddy Ilg, Vladislav Golyanik</author><pubDate>Tue, 26 Dec 2023 16:53:21 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.16118v1</guid></item><item><title>Bridging the Gaps: Learning Verifiable Model-Free Quadratic Programming Controllers Inspired by Model Predictive Control</title><link>http://arxiv.org/abs/2312.05332v2</link><description>In this paper, we introduce a new class of parameterized controllers, drawinginspiration from Model Predictive Control (MPC). The controller resembles aQuadratic Programming (QP) solver of a linear MPC problem, with the parametersof the controller being trained via Deep Reinforcement Learning (DRL) ratherthan derived from system models. This approach addresses the limitations ofcommon controllers with Multi-Layer Perceptron (MLP) or other general neuralnetwork architecture used in DRL, in terms of verifiability and performanceguarantees, and the learned controllers possess verifiable properties likepersistent feasibility and asymptotic stability akin to MPC. On the other hand,numerical examples illustrate that the proposed controller empirically matchesMPC and MLP controllers in terms of control performance and has superiorrobustness against modeling uncertainty and noises. Furthermore, the proposedcontroller is significantly more computationally efficient compared to MPC andrequires fewer parameters to learn than MLP controllers. Real-world experimentson vehicle drift maneuvering task demonstrate the potential of thesecontrollers for robotics and other demanding control tasks.</description><author>Yiwen Lu, Zishuo Li, Yihan Zhou, Na Li, Yilin Mo</author><pubDate>Tue, 26 Dec 2023 16:31:42 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.05332v2</guid></item><item><title>fMPI: Fast Novel View Synthesis in the Wild with Layered Scene Representations</title><link>http://arxiv.org/abs/2312.16109v1</link><description>In this study, we propose two novel input processing paradigms for novel viewsynthesis (NVS) methods based on layered scene representations thatsignificantly improve their runtime without compromising quality. Our approachidentifies and mitigates the two most time-consuming aspects of traditionalpipelines: building and processing the so-called plane sweep volume (PSV),which is a high-dimensional tensor of planar re-projections of the input cameraviews. In particular, we propose processing this tensor in parallel groups forimproved compute efficiency as well as super-sampling adjacent input planes togenerate denser, and hence more accurate scene representation. The proposedenhancements offer significant flexibility, allowing for a balance betweenperformance and speed, thus making substantial steps toward real-timeapplications. Furthermore, they are very general in the sense that anyPSV-based method can make use of them, including methods that employ multiplaneimages, multisphere images, and layered depth images. In a comprehensive set ofexperiments, we demonstrate that our proposed paradigms enable the design of anNVS method that achieves state-of-the-art on public benchmarks while being upto $50x$ faster than existing state-of-the-art methods. It also beats thecurrent forerunner in terms of speed by over $3x$, while achievingsignificantly better rendering quality.</description><author>Jonas Kohler, Nicolas Griffiths Sanchez, Luca Cavalli, Catherine Herold, Albert Pumarola, Alberto Garcia Garcia, Ali Thabet</author><pubDate>Tue, 26 Dec 2023 16:24:08 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.16109v1</guid></item><item><title>LaneSegNet: Map Learning with Lane Segment Perception for Autonomous Driving</title><link>http://arxiv.org/abs/2312.16108v1</link><description>A map, as crucial information for downstream applications of an autonomousdriving system, is usually represented in lanelines or centerlines. However,existing literature on map learning primarily focuses on either detectinggeometry-based lanelines or perceiving topology relationships of centerlines.Both of these methods ignore the intrinsic relationship of lanelines andcenterlines, that lanelines bind centerlines. While simply predicting bothtypes of lane in one model is mutually excluded in learning objective, weadvocate lane segment as a new representation that seamlessly incorporates bothgeometry and topology information. Thus, we introduce LaneSegNet, the firstend-to-end mapping network generating lane segments to obtain a completerepresentation of the road structure. Our algorithm features two keymodifications. One is a lane attention module to capture pivotal region detailswithin the long-range feature space. Another is an identical initializationstrategy for reference points, which enhances the learning of positional priorsfor lane attention. On the OpenLane-V2 dataset, LaneSegNet outperforms previouscounterparts by a substantial gain across three tasks, \textit{i.e.}, mapelement detection (+4.8 mAP), centerline perception (+6.9 DET$_l$), and thenewly defined one, lane segment perception (+5.6 mAP). Furthermore, it obtainsa real-time inference speed of 14.7 FPS. Code is accessible athttps://github.com/OpenDriveLab/LaneSegNet.</description><author>Tianyu Li, Peijin Jia, Bangjun Wang, Li Chen, Kun Jiang, Junchi Yan, Hongyang Li</author><pubDate>Tue, 26 Dec 2023 16:22:10 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.16108v1</guid></item><item><title>Clique Analysis and Bypassing in Continuous-Time Conflict-Based Search</title><link>http://arxiv.org/abs/2312.16106v1</link><description>While the study of unit-cost Multi-Agent Pathfinding (MAPF) problems has beenpopular, many real-world problems require continuous time and costs due tovarious movement models. In this context, this paper studies symmetry-breakingenhancements for Continuous-Time Conflict-Based Search (CCBS), a solver forcontinuous-time MAPF. Resolving conflict symmetries in MAPF can require anexponential amount of work. We adapt known enhancements from unit-cost domainsfor CCBS: bypassing, which resolves cost symmetries and biclique constraintswhich resolve spatial conflict symmetries. We formulate a novel combination ofbiclique constraints with disjoint splitting for spatial conflict symmetries.Finally, we show empirically that these enhancements yield a statisticallysignificant performance improvement versus previous state of the art, solvingproblems for up to 10% or 20% more agents in the same amount of time on densegraphs.</description><author>Thayne T. Walker, Nathan R. Sturtevant, Ariel Felner</author><pubDate>Tue, 26 Dec 2023 16:21:15 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.16106v1</guid></item><item><title>Dotless Representation of Arabic Text: Analysis and Modeling</title><link>http://arxiv.org/abs/2312.16104v1</link><description>This paper presents a novel dotless representation of Arabic text as analternative to the standard Arabic text representation. We delve into itsimplications through comprehensive analysis across five diverse corpora andfour different tokenization techniques. We explore the impact of dotlessrepresentation on the relationships between tokenization granularity andvocabulary size and compare them with standard text representation. Moreover,we analyze the information density of dotless versus standard text using textentropy calculations. To delve deeper into the implications of the dotlessrepresentation, statistical and neural language models are constructed usingthe various text corpora and tokenization techniques. A comparative assessmentis then made against language models developed using the standard Arabic textrepresentation. This multifaceted analysis provides valuable insights into thepotential advantages and challenges associated with the dotless representation.Last but not the least, utilizing parallel corpora, we draw comparisons betweenthe text analysis of Arabic and English to gain further insights. Our findingsshed light on the potential benefits of dotless representation for various NLPtasks, paving the way for further exploration for Arabic natural languageprocessing.</description><author>Maged S. Al-Shaibani, Irfan Ahmad</author><pubDate>Tue, 26 Dec 2023 16:16:33 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.16104v1</guid></item><item><title>q2d: Turning Questions into Dialogs to Teach Models How to Search</title><link>http://arxiv.org/abs/2304.14318v2</link><description>One of the exciting capabilities of recent language models for dialog istheir ability to independently search for relevant information to ground agiven dialog response. However, obtaining training data to teach models how toissue search queries is time and resource consuming. In this work, we proposeq2d: an automatic data generation pipeline that generates information-seekingdialogs from questions. We prompt a large language model (PaLM) to createconversational versions of question answering datasets, and use it to improvequery generation models that communicate with external search APIs to grounddialog responses. Unlike previous approaches which relied on human writtendialogs with search queries, our method allows to automatically generatequery-based grounded dialogs with better control and scale. Our experimentsdemonstrate that: (1) For query generation on the QReCC dataset, models trainedon our synthetically-generated data achieve 90%--97% of the performance ofmodels trained on the human-generated data; (2) We can successfully generatedata for training dialog models in new domains without any existing dialog dataas demonstrated on the multi-hop MuSiQue and Bamboogle QA datasets. (3) Weperform a thorough analysis of the generated dialogs showing that humans findthem of high quality and struggle to distinguish them from human-writtendialogs.</description><author>Yonatan Bitton, Shlomi Cohen-Ganor, Ido Hakimi, Yoad Lewenberg, Roee Aharoni, Enav Weinreb</author><pubDate>Tue, 26 Dec 2023 16:00:48 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2304.14318v2</guid></item><item><title>What You See is What You Read? Improving Text-Image Alignment Evaluation</title><link>http://arxiv.org/abs/2305.10400v4</link><description>Automatically determining whether a text and a corresponding image aresemantically aligned is a significant challenge for vision-language models,with applications in generative text-to-image and image-to-text tasks. In thiswork, we study methods for automatic text-image alignment evaluation. We firstintroduce SeeTRUE: a comprehensive evaluation set, spanning multiple datasetsfrom both text-to-image and image-to-text generation tasks, with humanjudgements for whether a given text-image pair is semantically aligned. We thendescribe two automatic methods to determine alignment: the first involving apipeline based on question generation and visual question answering models, andthe second employing an end-to-end classification approach by finetuningmultimodal pretrained models. Both methods surpass prior approaches in varioustext-image alignment tasks, with significant improvements in challenging casesthat involve complex composition or unnatural images. Finally, we demonstratehow our approaches can localize specific misalignments between an image and agiven text, and how they can be used to automatically re-rank candidates intext-to-image generation.</description><author>Michal Yarom, Yonatan Bitton, Soravit Changpinyo, Roee Aharoni, Jonathan Herzig, Oran Lang, Eran Ofek, Idan Szpektor</author><pubDate>Tue, 26 Dec 2023 15:58:24 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.10400v4</guid></item><item><title>VisIT-Bench: A Benchmark for Vision-Language Instruction Following Inspired by Real-World Use</title><link>http://arxiv.org/abs/2308.06595v4</link><description>We introduce VisIT-Bench (Visual InsTruction Benchmark), a benchmark forevaluation of instruction-following vision-language models for real-world use.Our starting point is curating 70 'instruction families' that we envisioninstruction tuned vision-language models should be able to address. Extendingbeyond evaluations like VQAv2 and COCO, tasks range from basic recognition togame playing and creative generation. Following curation, our dataset comprises592 test queries, each with a human-authored instruction-conditioned caption.These descriptions surface instruction-specific factors, e.g., for aninstruction asking about the accessibility of a storefront for wheelchairusers, the instruction-conditioned caption describes ramps/potential obstacles.These descriptions enable 1) collecting human-verified reference outputs foreach instance; and 2) automatic evaluation of candidate multimodal generationsusing a text-only LLM, aligning with human judgment. We quantify quality gapsbetween models and references using both human and automatic evaluations; e.g.,the top-performing instruction-following model wins against the GPT-4 referencein just 27% of the comparison. VisIT-Bench is dynamic to participate,practitioners simply submit their model's response on the project website;Data, code and leaderboard is available at visit-bench.github.io.</description><author>Yonatan Bitton, Hritik Bansal, Jack Hessel, Rulin Shao, Wanrong Zhu, Anas Awadalla, Josh Gardner, Rohan Taori, Ludwig Schmidt</author><pubDate>Tue, 26 Dec 2023 15:57:47 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2308.06595v4</guid></item><item><title>CLIP in Medical Imaging: A Comprehensive Survey</title><link>http://arxiv.org/abs/2312.07353v3</link><description>Contrastive Language-Image Pre-training (CLIP), a simple yet effectivepre-training paradigm, successfully introduces text supervision to visionmodels. It has shown promising results across various tasks, attributable toits generalizability and interpretability. The use of CLIP has recently gainedincreasing interest in the medical imaging domain, serving both as apre-training paradigm for aligning medical vision and language, and as acritical component in diverse clinical tasks. With the aim of facilitating adeeper understanding of this promising direction, this survey offers anin-depth exploration of the CLIP paradigm within the domain of medical imaging,regarding both refined CLIP pre-training and CLIP-driven applications. In thisstudy, We (1) start with a brief introduction to the fundamentals of CLIPmethodology. (2) Then, we investigate the adaptation of CLIP pre-training inthe medical domain, focusing on how to optimize CLIP given characteristics ofmedical images and reports. (3) Furthermore, we explore the practicalutilization of CLIP pre-trained models in various tasks, includingclassification, dense prediction, and cross-modal tasks. (4) Finally, wediscuss existing limitations of CLIP in the context of medical imaging andpropose forward-looking directions to address the demands of medical imagingdomain. We expect that this comprehensive survey will provide researchers inthe field of medical image analysis with a holistic understanding of the CLIPparadigm and its potential implications. The project page can be found onhttps://github.com/zhaozh10/Awesome-CLIP-in-Medical-Imaging.</description><author>Zihao Zhao, Yuxiao Liu, Han Wu, Yonghao Li, Sheng Wang, Lin Teng, Disheng Liu, Zhiming Cui, Qian Wang, Dinggang Shen</author><pubDate>Tue, 26 Dec 2023 15:51:49 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.07353v3</guid></item><item><title>SeisT: A foundational deep learning model for earthquake monitoring tasks</title><link>http://arxiv.org/abs/2310.01037v3</link><description>Seismograms, the fundamental seismic records, have revolutionized earthquakeresearch and monitoring. Recent advancements in deep learning have furtherenhanced seismic signal processing, leading to even more precise and effectiveearthquake monitoring capabilities. This paper introduces a foundational deeplearning model, the Seismogram Transformer (SeisT), designed for a variety ofearthquake monitoring tasks. SeisT combines multiple modules tailored todifferent tasks and exhibits impressive out-of-distribution generalizationperformance, outperforming or matching state-of-the-art models in tasks likeearthquake detection, seismic phase picking, first-motion polarityclassification, magnitude estimation, back-azimuth estimation, and epicentraldistance estimation. The performance scores on the tasks are 0.96, 0.96, 0.68,0.95, 0.86, 0.55, and 0.81, respectively. The most significant improvements, incomparison to existing models, are observed in phase-P picking, phase-Spicking, and magnitude estimation, with gains of 1.7%, 9.5%, and 8.0%,respectively. Our study, through rigorous experiments and evaluations, suggeststhat SeisT has the potential to contribute to the advancement of seismic signalprocessing and earthquake research.</description><author>Sen Li, Xu Yang, Anye Cao, Changbin Wang, Yaoqi Liu, Yapeng Liu, Qiang Niu</author><pubDate>Tue, 26 Dec 2023 15:36:43 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.01037v3</guid></item><item><title>UADB: Unsupervised Anomaly Detection Booster</title><link>http://arxiv.org/abs/2306.01997v2</link><description>Unsupervised Anomaly Detection (UAD) is a key data mining problem owing toits wide real-world applications. Due to the complete absence of supervisionsignals, UAD methods rely on implicit assumptions about anomalous patterns(e.g., scattered/sparsely/densely clustered) to detect anomalies. However,real-world data are complex and vary significantly across different domains. Nosingle assumption can describe such complexity and be valid in all scenarios.This is also confirmed by recent research that shows no UAD method isomnipotent. Based on above observations, instead of searching for a magicuniversal winner assumption, we seek to design a general UAD Booster (UADB)that empowers any UAD models with adaptability to different data. This is achallenging task given the heterogeneous model structures and assumptionsadopted by existing UAD methods. To achieve this, we dive deep into the UADproblem and find that compared to normal data, anomalies (i) lack clearstructure/pattern in feature space, thus (ii) harder to learn by model withouta suitable assumption, and finally, leads to (iii) high variance betweendifferent learners. In light of these findings, we propose to (i) distill theknowledge of the source UAD model to an imitation learner (booster) that holdsno data assumption, then (ii) exploit the variance between them to performautomatic correction, and thus (iii) improve the booster over the original UADmodel. We use a neural network as the booster for its strong expressive poweras a universal approximator and ability to perform flexible post-hoc tuning.Note that UADB is a model-agnostic framework that can enhance heterogeneous UADmodels in a unified way. Extensive experiments on over 80 tabular datasetsdemonstrate the effectiveness of UADB.</description><author>Hangting Ye, Zhining Liu, Xinyi Shen, Wei Cao, Shun Zheng, Xiaofan Gui, Huishuai Zhang, Yi Chang, Jiang Bian</author><pubDate>Tue, 26 Dec 2023 15:34:11 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.01997v2</guid></item><item><title>V*: Guided Visual Search as a Core Mechanism in Multimodal LLMs</title><link>http://arxiv.org/abs/2312.14135v2</link><description>When we look around and perform complex tasks, how we see and selectivelyprocess what we see is crucial. However, the lack of this visual searchmechanism in current multimodal LLMs (MLLMs) hinders their ability to focus onimportant visual details, especially when handling high-resolution and visuallycrowded images. To address this, we introduce V*, an LLM-guided visual searchmechanism that employs the world knowledge in LLMs for efficient visualquerying. When combined with an MLLM, this mechanism enhances collaborativereasoning, contextual understanding, and precise targeting of specific visualelements. This integration results in a new MLLM meta-architecture, named Show,sEArch, and TelL (SEAL). We further create V*Bench, a benchmark specificallydesigned to evaluate MLLMs in their ability to process high-resolution imagesand focus on visual details. Our study highlights the necessity ofincorporating visual search capabilities into multimodal systems. The code isavailable https://github.com/penghao-wu/vstar.</description><author>Penghao Wu, Saining Xie</author><pubDate>Tue, 26 Dec 2023 15:20:45 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.14135v2</guid></item><item><title>LangSplat: 3D Language Gaussian Splatting</title><link>http://arxiv.org/abs/2312.16084v1</link><description>Human lives in a 3D world and commonly uses natural language to interact witha 3D scene. Modeling a 3D language field to support open-ended language queriesin 3D has gained increasing attention recently. This paper introducesLangSplat, which constructs a 3D language field that enables precise andefficient open-vocabulary querying within 3D spaces. Unlike existing methodsthat ground CLIP language embeddings in a NeRF model, LangSplat advances thefield by utilizing a collection of 3D Gaussians, each encoding languagefeatures distilled from CLIP, to represent the language field. By employing atile-based splatting technique for rendering language features, we circumventthe costly rendering process inherent in NeRF. Instead of directly learningCLIP embeddings, LangSplat first trains a scene-wise language autoencoder andthen learns language features on the scene-specific latent space, therebyalleviating substantial memory demands imposed by explicit modeling. Existingmethods struggle with imprecise and vague 3D language fields, which fail todiscern clear boundaries between objects. We delve into this issue and proposeto learn hierarchical semantics using SAM, thereby eliminating the need forextensively querying the language field across various scales and theregularization of DINO features. Extensive experiments on open-vocabulary 3Dobject localization and semantic segmentation demonstrate that LangSplatsignificantly outperforms the previous state-of-the-art method LERF by a largemargin. Notably, LangSplat is extremely efficient, achieving a {\speed}$\times$ speedup compared to LERF at the resolution of 1440 $\times$ 1080. Westrongly recommend readers to check out our video results athttps://langsplat.github.io</description><author>Minghan Qin, Wanhua Li, Jiawei Zhou, Haoqian Wang, Hanspeter Pfister</author><pubDate>Tue, 26 Dec 2023 15:14:37 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.16084v1</guid></item><item><title>Dynamic Latent Graph-Guided Neural Temporal Point Processes</title><link>http://arxiv.org/abs/2312.16083v1</link><description>Continuously-observed event occurrences, often exhibit self- andmutually-exciting effects, which can be well modeled using temporal pointprocesses. Beyond that, these event dynamics may also change over time, withcertain periodic trends. We propose a novel variational auto-encoder to capturesuch a mixture of temporal dynamics. More specifically, the whole time intervalof the input sequence is partitioned into a set of sub-intervals. The eventdynamics are assumed to be stationary within each sub-interval, but could bechanging across those sub-intervals. In particular, we use a sequential latentvariable model to learn a dependency graph between the observed dimensions, foreach sub-interval. The model predicts the future event times, by using thelearned dependency graph to remove the noncontributing influences of pastevents. By doing so, the proposed model demonstrates its higher accuracy inpredicting inter-event times and event types for several real-world eventsequences, compared with existing state of the art neural point processes.</description><author>Sikun Yang, Hongyuan Zha</author><pubDate>Tue, 26 Dec 2023 15:11:55 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.16083v1</guid></item><item><title>Unsupervised Learning of Phylogenetic Trees via Split-Weight Embedding</title><link>http://arxiv.org/abs/2312.16074v1</link><description>Unsupervised learning has become a staple in classical machine learning,successfully identifying clustering patterns in data across a broad range ofdomain applications. Surprisingly, despite its accuracy and elegant simplicity,unsupervised learning has not been sufficiently exploited in the realm ofphylogenetic tree inference. The main reason for the delay in adoption ofunsupervised learning in phylogenetics is the lack of a meaningful, yet simple,way of embedding phylogenetic trees into a vector space. Here, we propose thesimple yet powerful split-weight embedding which allows us to fit standardclustering algorithms to the space of phylogenetic trees. We show that oursplit-weight embedded clustering is able to recover meaningful evolutionaryrelationships in simulated and real (Adansonia baobabs) data.</description><author>Yibo Kong, George P. Tiley, Claudia Solis-Lemus</author><pubDate>Tue, 26 Dec 2023 14:50:39 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.16074v1</guid></item><item><title>Event-based Shape from Polarization with Spiking Neural Networks</title><link>http://arxiv.org/abs/2312.16071v1</link><description>Recent advances in event-based shape determination from polarization offer atransformative approach that tackles the trade-off between speed and accuracyin capturing surface geometries. In this paper, we investigate event-basedshape from polarization using Spiking Neural Networks (SNNs), introducing theSingle-Timestep and Multi-Timestep Spiking UNets for effective and efficientsurface normal estimation. Specificially, the Single-Timestep model processesevent-based shape as a non-temporal task, updating the membrane potential ofeach spiking neuron only once, thereby reducing computational and energydemands. In contrast, the Multi-Timestep model exploits temporal dynamics forenhanced data extraction. Extensive evaluations on synthetic and real-worlddatasets demonstrate that our models match the performance of state-of-the-artArtifical Neural Networks (ANNs) in estimating surface normals, with the addedadvantage of superior energy efficiency. Our work not only contributes to theadvancement of SNNs in event-based sensing but also sets the stage for futureexplorations in optimizing SNN architectures, integrating multi-modal data, andscaling for applications on neuromorphic hardware.</description><author>Peng Kang, Srutarshi Banerjee, Henry Chopp, Aggelos Katsaggelos, Oliver Cossairt</author><pubDate>Tue, 26 Dec 2023 14:43:26 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.16071v1</guid></item><item><title>Can ChatGPT Read Who You Are?</title><link>http://arxiv.org/abs/2312.16070v1</link><description>The interplay between artificial intelligence (AI) and psychology,particularly in personality assessment, represents an important emerging areaof research. Accurate personality trait estimation is crucial not only forenhancing personalization in human-computer interaction but also for a widevariety of applications ranging from mental health to education. This paperanalyzes the capability of a generic chatbot, ChatGPT, to effectively inferpersonality traits from short texts. We report the results of a comprehensiveuser study featuring texts written in Czech by a representative populationsample of 155 participants. Their self-assessments based on the Big FiveInventory (BFI) questionnaire serve as the ground truth. We compare thepersonality trait estimations made by ChatGPT against those by human raters andreport ChatGPT's competitive performance in inferring personality traits fromtext. We also uncover a 'positivity bias' in ChatGPT's assessments across allpersonality dimensions and explore the impact of prompt composition onaccuracy. This work contributes to the understanding of AI capabilities inpsychological assessment, highlighting both the potential and limitations ofusing large language models for personality inference. Our research underscoresthe importance of responsible AI development, considering ethical implicationssuch as privacy, consent, autonomy, and bias in AI applications.</description><author>Erik Derner, Dalibor Kučera, Nuria Oliver, Jan Zahálka</author><pubDate>Tue, 26 Dec 2023 14:43:04 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.16070v1</guid></item><item><title>A Prompt Learning Framework for Source Code Summarization</title><link>http://arxiv.org/abs/2312.16066v1</link><description>(Source) code summarization is the task of automatically generating naturallanguage summaries for given code snippets. Such summaries play a key role inhelping developers understand and maintain source code. Recently, with thesuccessful application of large language models (LLMs) in numerous fields,software engineering researchers have also attempted to adapt LLMs to solvecode summarization tasks. The main adaptation schemes include instructionprompting and task-oriented fine-tuning. However, instruction promptinginvolves designing crafted prompts for zero-shot learning or selectingappropriate samples for few-shot learning and requires users to haveprofessional domain knowledge, while task-oriented fine-tuning requires hightraining costs. In this paper, we propose a novel prompt learning framework forcode summarization called PromptCS. PromptCS trains a prompt agent that cangenerate continuous prompts to unleash the potential for LLMs in codesummarization. Compared to the human-written discrete prompt, the continuousprompts are produced under the guidance of LLMs and are therefore easier tounderstand by LLMs. PromptCS freezes the parameters of LLMs when training theprompt agent, which can greatly reduce the requirements for training resources.We evaluate PromptCS on the CodeSearchNet dataset involving multipleprogramming languages. The results show that PromptCS significantly outperformsinstruction prompting schemes on all four widely used metrics. In some baseLLMs, e.g., CodeGen-Multi-2B and StarCoderBase-1B and -3B, PromptCS evenoutperforms the task-oriented fine-tuning scheme. More importantly, thetraining efficiency of PromptCS is faster than the task-oriented fine-tuningscheme, with a more pronounced advantage on larger LLMs. The results of thehuman evaluation demonstrate that PromptCS can generate more good summariescompared to baselines.</description><author>Weisong Sun, Chunrong Fang, Yudu You, Yuchen Chen, Yi Liu, Chong Wang, Jian Zhang, Quanjun Zhang, Hanwei Qian, Wei Zhao, Yang Liu, Zhenyu Chen</author><pubDate>Tue, 26 Dec 2023 14:37:55 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.16066v1</guid></item><item><title>Error-free Training for Artificial Neural Network</title><link>http://arxiv.org/abs/2312.16060v1</link><description>Conventional training methods for artificial neural network (ANN) modelsnever achieve zero error rate systematically for large data. A new trainingmethod consists of three steps: first create an auxiliary data fromconventionally trained parameters which correspond exactly to a global minimumfor the loss function of the cloned data; second create a one-parameterhomotopy (hybrid) of the auxiliary data and the original data; and third trainthe model for the hybrid data iteratively from the auxiliary data end of thehomotopy parameter to the original data end while maintaining the zero-errortraining rate at every iteration. This continuationmethod is guaranteed toconverge numerically by a theorem which converts the ANN training problem intoa continuation problem for fixed points of a parameterized transformation inthe training parameter space to which the Uniform Contraction Mapping Theoremfrom dynamical systems applies.</description><author>Bo Deng</author><pubDate>Tue, 26 Dec 2023 14:15:19 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.16060v1</guid></item><item><title>A Logically Consistent Chain-of-Thought Approach for Stance Detection</title><link>http://arxiv.org/abs/2312.16054v1</link><description>Zero-shot stance detection (ZSSD) aims to detect stances toward unseentargets. Incorporating background knowledge to enhance transferability betweenseen and unseen targets constitutes the primary approach of ZSSD. However,these methods often struggle with a knowledge-task disconnect and lack logicalconsistency in their predictions. To address these issues, we introduce a novelapproach named Logically Consistent Chain-of-Thought (LC-CoT) for ZSSD, whichimproves stance detection by ensuring relevant and logically sound knowledgeextraction. LC-CoT employs a three-step process. Initially, it assesses whethersupplementary external knowledge is necessary. Subsequently, it uses API callsto retrieve this knowledge, which can be processed by a separate LLM. Finally,a manual exemplar guides the LLM to infer stance categories, using an if-thenlogical structure to maintain relevance and logical coherence. This structuredapproach to eliciting background knowledge enhances the model's capability,outperforming traditional supervised methods without relying on labeled data.</description><author>Bowen Zhang, Daijun Ding, Liwen Jing, Hu Huang</author><pubDate>Tue, 26 Dec 2023 13:54:00 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.16054v1</guid></item><item><title>WaveCoder: Widespread And Versatile Enhanced Instruction Tuning with Refined Data Generation</title><link>http://arxiv.org/abs/2312.14187v2</link><description>Recent work demonstrates that, after being fine-tuned on a high-qualityinstruction dataset, the resulting model can obtain impressive capabilities toaddress a wide range of tasks. However, existing methods for instruction datageneration often produce duplicate data and are not controllable enough on dataquality. In this paper, we extend the generalization of instruction tuning byclassifying the instruction data to 4 code-related tasks and propose aLLM-based Generator-Discriminator data process framework to generate diverse,high-quality instruction data from open source code. Hence, we introduceCodeOcean, a dataset comprising 20,000 instruction instances across 4 universalcode-related tasks,which is aimed at augmenting the effectiveness ofinstruction tuning and improving the generalization ability of fine-tunedmodel. Subsequently, we present WaveCoder, a fine-tuned Code LLM withWidespread And Versatile Enhanced instruction tuning. This model isspecifically designed for enhancing instruction tuning of Code Language Models(LLMs). Our experiments demonstrate that Wavecoder models outperform otheropen-source models in terms of generalization ability across differentcode-related tasks at the same level of fine-tuning scale. Moreover, Wavecoderexhibits high efficiency in previous code generation tasks. This paper thusoffers a significant contribution to the field of instruction data generationand fine-tuning models, providing new insights and tools for enhancingperformance in code-related tasks.</description><author>Zhaojian Yu, Xin Zhang, Ning Shang, Yangyu Huang, Can Xu, Yishujie Zhao, Wenxiang Hu, Qiufeng Yin</author><pubDate>Tue, 26 Dec 2023 13:51:38 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.14187v2</guid></item><item><title>Jellyfish: A Large Language Model for Data Preprocessing</title><link>http://arxiv.org/abs/2312.01678v3</link><description>In this paper, we present Jellyfish, an open-source LLM as a universal tasksolver for DP. Built on the Llama 2 13B model, Jellyfish is instruction-tunedwith the datasets of several typical DP tasks including error detection, dataimputation, schema matching, and entity matching, and delivers generalizabilityto other tasks. Remarkably, Jellyfish can operate on a local, single, andlow-priced GPU with its 13 billion parameters, ensuring data security andenabling further tuning. Its proficiency in understanding natural languageallows users to manually craft instructions for DP tasks. Unlike many existingmethods that heavily rely on prior knowledge, Jellyfish acquires domainknowledge during its tuning process and integrates optional knowledge injectionduring inference. A distinctive feature of Jellyfish is its interpreter, whichelucidates its output decisions. To construct Jellyfish, we develop a series ofpre-tuning and DP-tuning techniques. Jellyfish is equipped with an instanceserializer, which automatically translates raw data into model prompts, and aknowledge injector, which optionally introduces task- and dataset-specificknowledge to enhance DP performance. Our evaluation of Jellyfish, using a rangeof real datasets, shows its competitiveness compared to state-of-the-artmethods and its strong generalizability to unseen tasks. Jellyfish'sperformance rivals that of GPT series models, and its interpreter offersenhanced reasoning capabilities compared to GPT-3.5. Furthermore, ourevaluation highlights the effectiveness of the techniques employed inconstructing Jellyfish. Our model is available at Hugging Face:https://huggingface.co/NECOUDBFM/Jellyfish .</description><author>Haochen Zhang, Yuyang Dong, Chuan Xiao, Masafumi Oyamada</author><pubDate>Tue, 26 Dec 2023 13:51:29 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.01678v3</guid></item><item><title>Auto deep learning for bioacoustic signals</title><link>http://arxiv.org/abs/2311.04945v2</link><description>This study investigates the potential of automated deep learning to enhancethe accuracy and efficiency of multi-class classification of birdvocalizations, compared against traditional manually-designed deep learningmodels. Using the Western Mediterranean Wetland Birds dataset, we investigatedthe use of AutoKeras, an automated machine learning framework, to automateneural architecture search and hyperparameter tuning. Comparative analysisvalidates our hypothesis that the AutoKeras-derived model consistentlyoutperforms traditional models like MobileNet, ResNet50 and VGG16. Our approachand findings underscore the transformative potential of automated deep learningfor advancing bioacoustics research and models. In fact, the automatedtechniques eliminate the need for manual feature engineering and model designwhile improving performance. This study illuminates best practices in sampling,evaluation and reporting to enhance reproducibility in this nascent field. Allthe code used is available at https://github.com/giuliotosato/AutoKeras-bioacustic Keywords: AutoKeras; automated deep learning; audio classification; WetlandsBird dataset; comparative analysis; bioacoustics; validation dataset;multi-class classification; spectrograms.</description><author>Giulio Tosato, Abdelrahman Shehata, Joshua Janssen, Kees Kamp, Pramatya Jati, Dan Stowell</author><pubDate>Tue, 26 Dec 2023 13:49:45 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.04945v2</guid></item><item><title>Inter-X: Towards Versatile Human-Human Interaction Analysis</title><link>http://arxiv.org/abs/2312.16051v1</link><description>The analysis of the ubiquitous human-human interactions is pivotal forunderstanding humans as social beings. Existing human-human interactiondatasets typically suffer from inaccurate body motions, lack of hand gesturesand fine-grained textual descriptions. To better perceive and generatehuman-human interactions, we propose Inter-X, a currently largest human-humaninteraction dataset with accurate body movements and diverse interactionpatterns, together with detailed hand gestures. The dataset includes ~11Kinteraction sequences and more than 8.1M frames. We also equip Inter-X withversatile annotations of more than 34K fine-grained human part-level textualdescriptions, semantic interaction categories, interaction order, and therelationship and personality of the subjects. Based on the elaborateannotations, we propose a unified benchmark composed of 4 categories ofdownstream tasks from both the perceptual and generative directions. Extensiveexperiments and comprehensive analysis show that Inter-X serves as a testbedfor promoting the development of versatile human-human interaction analysis.Our dataset and benchmark will be publicly available for research purposes.</description><author>Liang Xu, Xintao Lv, Yichao Yan, Xin Jin, Shuwen Wu, Congsheng Xu, Yifan Liu, Yizhou Zhou, Fengyun Rao, Xingdong Sheng, Yunhui Liu, Wenjun Zeng, Xiaokang Yang</author><pubDate>Tue, 26 Dec 2023 13:36:05 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.16051v1</guid></item><item><title>Data Contamination Issues in Brain-to-Text Decoding</title><link>http://arxiv.org/abs/2312.10987v2</link><description>Decoding non-invasive cognitive signals to natural language has long been thegoal of building practical brain-computer interfaces (BCIs). Recent majormilestones have successfully decoded cognitive signals like functional MagneticResonance Imaging (fMRI) and electroencephalogram (EEG) into text under openvocabulary setting. However, how to split the datasets for training,validating, and testing in cognitive signal decoding task still remainscontroversial. In this paper, we conduct systematic analysis on current datasetsplitting methods and find the existence of data contamination largelyexaggerates model performance. Specifically, first we find the leakage of testsubjects' cognitive signals corrupts the training of a robust encoder. Second,we prove the leakage of text stimuli causes the auto-regressive decoder tomemorize information in test set. The decoder generates highly accurate textnot because it truly understands cognitive signals. To eliminate the influenceof data contamination and fairly evaluate different models' generalizationability, we propose a new splitting method for different types of cognitivedatasets (e.g. fMRI, EEG). We also test the performance of SOTA Brain-to-Textdecoding models under the proposed dataset splitting paradigm as baselines forfurther research.</description><author>Congchi Yin, Qian Yu, Zhiwei Fang, Jie He, Changping Peng, Zhangang Lin, Jingping Shao, Piji Li</author><pubDate>Tue, 26 Dec 2023 13:29:18 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.10987v2</guid></item><item><title>2D-Guided 3D Gaussian Segmentation</title><link>http://arxiv.org/abs/2312.16047v1</link><description>Recently, 3D Gaussian, as an explicit 3D representation method, hasdemonstrated strong competitiveness over NeRF (Neural Radiance Fields) in termsof expressing complex scenes and training duration. These advantages signal awide range of applications for 3D Gaussians in 3D understanding and editing.Meanwhile, the segmentation of 3D Gaussians is still in its infancy. Theexisting segmentation methods are not only cumbersome but also incapable ofsegmenting multiple objects simultaneously in a short amount of time. Inresponse, this paper introduces a 3D Gaussian segmentation method implementedwith 2D segmentation as supervision. This approach uses input 2D segmentationmaps to guide the learning of the added 3D Gaussian semantic information, whilenearest neighbor clustering and statistical filtering refine the segmentationresults. Experiments show that our concise method can achieve comparableperformances on mIOU and mAcc for multi-object segmentation as previoussingle-object segmentation methods.</description><author>Kun Lan, Haoran Li, Haolin Shi, Wenjun Wu, Yong Liao, Lin Wang, Pengyuan Zhou</author><pubDate>Tue, 26 Dec 2023 13:28:21 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.16047v1</guid></item><item><title>AdaNAS: Adaptively Post-processing with Self-supervised Neural Architecture Search for Ensemble Rainfall Forecasts</title><link>http://arxiv.org/abs/2312.16046v1</link><description>Previous post-processing studies on rainfall forecasts using numericalweather prediction (NWP) mainly focus on statistics-based aspects, whilelearning-based aspects are rarely investigated. Although some manually-designedmodels are proposed to raise accuracy, they are customized networks, which needto be repeatedly tried and verified, at a huge cost in time and labor.Therefore, a self-supervised neural architecture search (NAS) method withoutsignificant manual efforts called AdaNAS is proposed in this study to performrainfall forecast post-processing and predict rainfall with high accuracy. Inaddition, we design a rainfall-aware search space to significantly improveforecasts for high-rainfall areas. Furthermore, we propose a rainfall-levelregularization function to eliminate the effect of noise data during thetraining. Validation experiments have been performed under the cases of\emph{None}, \emph{Light}, \emph{Moderate}, \emph{Heavy} and \emph{Violent} ona large-scale precipitation benchmark named TIGGE. Finally, the averagemean-absolute error (MAE) and average root-mean-square error (RMSE) of theproposed AdaNAS model are 0.98 and 2.04 mm/day, respectively. Additionally, theproposed AdaNAS model is compared with other neural architecture search methodsand previous studies. Compared results reveal the satisfactory performance andsuperiority of the proposed AdaNAS model in terms of precipitation amountprediction and intensity classification. Concretely, the proposed AdaNAS modeloutperformed previous best-performing manual methods with MAE and RMSEimproving by 80.5\% and 80.3\%, respectively.</description><author>Yingpeng Wen, Weijiang Yu, Fudan Zheng, Dan Huang, Nong Xiao</author><pubDate>Tue, 26 Dec 2023 13:23:03 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.16046v1</guid></item><item><title>Fed-CO2: Cooperation of Online and Offline Models for Severe Data Heterogeneity in Federated Learning</title><link>http://arxiv.org/abs/2312.13923v2</link><description>Federated Learning (FL) has emerged as a promising distributed learningparadigm that enables multiple clients to learn a global model collaborativelywithout sharing their private data. However, the effectiveness of FL is highlydependent on the quality of the data that is being used for training. Inparticular, data heterogeneity issues, such as label distribution skew andfeature skew, can significantly impact the performance of FL. Previous studiesin FL have primarily focused on addressing label distribution skew dataheterogeneity, while only a few recent works have made initial progress intackling feature skew issues. Notably, these two forms of data heterogeneityhave been studied separately and have not been well explored within a unifiedFL framework. To address this gap, we propose Fed-CO$_{2}$, a universal FLframework that handles both label distribution skew and feature skew within a\textbf{C}ooperation mechanism between the \textbf{O}nline and \textbf{O}fflinemodels. Specifically, the online model learns general knowledge that is sharedamong all clients, while the offline model is trained locally to learn thespecialized knowledge of each individual client. To further enhance modelcooperation in the presence of feature shifts, we design an intra-clientknowledge transfer mechanism that reinforces mutual learning between the onlineand offline models, and an inter-client knowledge transfer mechanism toincrease the models' domain generalization ability. Extensive experiments showthat our Fed-CO$_{2}$ outperforms a wide range of existing personalizedfederated learning algorithms in terms of handling label distribution skew andfeature skew, both individually and collectively. The empirical results aresupported by our convergence analyses in a simplified setting.</description><author>Zhongyi Cai, Ye Shi, Wei Huang, Jingya Wang</author><pubDate>Tue, 26 Dec 2023 13:22:29 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.13923v2</guid></item><item><title>Algebraic Positional Encodings</title><link>http://arxiv.org/abs/2312.16045v1</link><description>We introduce a novel positional encoding strategy for Transformer-stylemodels, addressing the shortcomings of existing, often ad hoc, approaches. Ourframework provides a flexible mapping from the algebraic specification of adomain to an interpretation as orthogonal operators. This design preserves thealgebraic characteristics of the source domain, ensuring that the model upholdsthe desired structural properties. Our scheme can accommodate variousstructures, including sequences, grids and trees, as well as theircompositions. We conduct a series of experiments to demonstrate the practicalapplicability of our approach. Results suggest performance on par with orsurpassing the current state-of-the-art, without hyperparameter optimizationsor ``task search'' of any kind. Code will be made available at\url{github.com/konstantinosKokos/UnitaryPE}.</description><author>Konstantinos Kogkalidis, Jean-Philippe Bernardy, Vikas Garg</author><pubDate>Tue, 26 Dec 2023 13:17:25 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.16045v1</guid></item><item><title>Large Language Models as Traffic Signal Control Agents: Capacity and Opportunity</title><link>http://arxiv.org/abs/2312.16044v1</link><description>Traffic signal control is crucial for optimizing the efficiency of roadnetwork by regulating traffic light phases. Existing research predominantlyfocuses on heuristic or reinforcement learning (RL)-based methods, which oftenlack transferability across diverse traffic scenarios and suffer from poorinterpretability. This paper introduces a novel approach, LLMLight, utilizinglarge language models (LLMs) for traffic signal control tasks. By leveragingLLMs' impressive generalization and zero-shot reasoning capabilities, LLMLightexecutes a human-like decision-making process for efficient traffic management.Specifically, the framework begins by composing task descriptions, currenttraffic conditions, and prior knowledge into a prompt. Subsequently, we utilizeLLM's chain-of-thought (CoT) reasoning ability to identify the next trafficsignal phase, ensuring optimal efficiency in the road network. LLMLightachieves state-of-the-art (SOTA) or competitive results across five real-worldtraffic datasets. Notably, LLMLight showcases remarkable generalization,interpretability, and zero-shot reasoning abilities, even without any trainingfor transportation management tasks. Our project is available athttps://github.com/usail-hkust/LLMTSCS.</description><author>Siqi Lai, Zhao Xu, Weijia Zhang, Hao Liu, Hui Xiong</author><pubDate>Tue, 26 Dec 2023 13:17:06 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.16044v1</guid></item><item><title>An extended asymmetric sigmoid with Perceptron (SIGTRON) for imbalanced linear classification</title><link>http://arxiv.org/abs/2312.16043v1</link><description>This article presents a new polynomial parameterized sigmoid called SIGTRON,which is an extended asymmetric sigmoid with Perceptron, and its companionconvex model called SIGTRON-imbalanced classification (SIC) model that employsa virtual SIGTRON-induced convex loss function. In contrast to the conventional$\pi$-weighted cost-sensitive learning model, the SIC model does not have anexternal $\pi$-weight on the loss function but has internal parameters in thevirtual SIGTRON-induced loss function. As a consequence, when the giventraining dataset is close to the well-balanced condition, we show that theproposed SIC model is more adaptive to variations of the dataset, such as theinconsistency of the scale-class-imbalance ratio between the training and testdatasets. This adaptation is achieved by creating a skewed hyperplane equation.Additionally, we present a quasi-Newton optimization(L-BFGS) framework for thevirtual convex loss by developing an interval-based bisection line search.Empirically, we have observed that the proposed approach outperforms$\pi$-weighted convex focal loss and balanced classifier LIBLINEAR(logisticregression, SVM, and L2SVM) in terms of test classification accuracy with $51$two-class and $67$ multi-class datasets. In binary classification problems,where the scale-class-imbalance ratio of the training dataset is notsignificant but the inconsistency exists, a group of SIC models with the besttest accuracy for each dataset (TOP$1$) outperforms LIBSVM(C-SVC with RBFkernel), a well-known kernel-based classifier.</description><author>Hyenkyun Woo</author><pubDate>Tue, 26 Dec 2023 13:14:17 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.16043v1</guid></item><item><title>Bayesian Design Principles for Frequentist Sequential Learning</title><link>http://arxiv.org/abs/2310.00806v3</link><description>We develop a general theory to optimize the frequentist regret for sequentiallearning problems, where efficient bandit and reinforcement learning algorithmscan be derived from unified Bayesian principles. We propose a noveloptimization approach to generate "algorithmic beliefs" at each round, and useBayesian posteriors to make decisions. The optimization objective to create"algorithmic beliefs," which we term "Algorithmic Information Ratio,"represents an intrinsic complexity measure that effectively characterizes thefrequentist regret of any algorithm. To the best of our knowledge, this is thefirst systematical approach to make Bayesian-type algorithms prior-free andapplicable to adversarial settings, in a generic and optimal manner. Moreover,the algorithms are simple and often efficient to implement. As a majorapplication, we present a novel algorithm for multi-armed bandits that achievesthe "best-of-all-worlds" empirical performance in the stochastic, adversarial,and non-stationary environments. And we illustrate how these principles can beused in linear bandits, bandit convex optimization, and reinforcement learning.</description><author>Yunbei Xu, Assaf Zeevi</author><pubDate>Tue, 26 Dec 2023 13:08:30 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.00806v3</guid></item><item><title>Quantum Learning Theory Beyond Batch Binary Classification</title><link>http://arxiv.org/abs/2302.07409v4</link><description>Arunachalam and de Wolf (2018) showed that the sample complexity of quantumbatch learning of boolean functions, in the realizable and agnostic settings,has the same form and order as the corresponding classical sample complexities.In this paper, we extend this, ostensibly surprising, message to batchmulticlass learning, online boolean learning, and online multiclass learning.For our online learning results, we first consider an adaptive adversaryvariant of the classical model of Dawid and Tewari (2022). Then, we introducethe first (to the best of our knowledge) model of online learning with quantumexamples.</description><author>Preetham Mohan, Ambuj Tewari</author><pubDate>Tue, 26 Dec 2023 13:08:28 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2302.07409v4</guid></item><item><title>Multi-scale Progressive Feature Embedding for Accurate NIR-to-RGB Spectral Domain Translation</title><link>http://arxiv.org/abs/2312.16040v1</link><description>NIR-to-RGB spectral domain translation is a challenging task due to themapping ambiguities, and existing methods show limited learning capacities. Toaddress these challenges, we propose to colorize NIR images via a multi-scaleprogressive feature embedding network (MPFNet), with the guidance of grayscaleimage colorization. Specifically, we first introduce a domain translationmodule that translates NIR source images into the grayscale target domain. Byincorporating a progressive training strategy, the statistical and semanticknowledge from both task domains are efficiently aligned with a series ofpixel- and feature-level consistency constraints. Besides, a multi-scaleprogressive feature embedding network is designed to improve learningcapabilities. Experiments show that our MPFNet outperforms state-of-the-artcounterparts by 2.55 dB in the NIR-to-RGB spectral domain translation task interms of PSNR.</description><author>Xingxing Yang, Jie Chen, Zaifeng Yang</author><pubDate>Tue, 26 Dec 2023 13:07:45 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.16040v1</guid></item><item><title>Implicitly normalized forecaster with clipping for linear and non-linear heavy-tailed multi-armed bandits</title><link>http://arxiv.org/abs/2305.06743v3</link><description>The Implicitly Normalized Forecaster (INF) algorithm is considered to be anoptimal solution for adversarial multi-armed bandit (MAB) problems. However,most of the existing complexity results for INF rely on restrictiveassumptions, such as bounded rewards. Recently, a related algorithm wasproposed that works for both adversarial and stochastic heavy-tailed MABsettings. However, this algorithm fails to fully exploit the available data. In this paper, we propose a new version of INF called the ImplicitlyNormalized Forecaster with clipping (INF-clip) for MAB problems withheavy-tailed reward distributions. We establish convergence results under mildassumptions on the rewards distribution and demonstrate that INF-clip isoptimal for linear heavy-tailed stochastic MAB problems and works well fornon-linear ones. Furthermore, we show that INF-clip outperforms thebest-of-both-worlds algorithm in cases where it is difficult to distinguishbetween different arms.</description><author>Yuriy Dorn, Nikita Kornilov, Nikolay Kutuzov, Alexander Nazin, Eduard Gorbunov, Alexander Gasnikov</author><pubDate>Tue, 26 Dec 2023 13:07:25 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.06743v3</guid></item><item><title>SlowTrack: Increasing the Latency of Camera-based Perception in Autonomous Driving Using Adversarial Examples</title><link>http://arxiv.org/abs/2312.09520v2</link><description>In Autonomous Driving (AD), real-time perception is a critical componentresponsible for detecting surrounding objects to ensure safe driving. Whileresearchers have extensively explored the integrity of AD perception due to itssafety and security implications, the aspect of availability (real-timeperformance) or latency has received limited attention. Existing works onlatency-based attack have focused mainly on object detection, i.e., a componentin camera-based AD perception, overlooking the entire camera-based ADperception, which hinders them to achieve effective system-level effects, suchas vehicle crashes. In this paper, we propose SlowTrack, a novel framework forgenerating adversarial attacks to increase the execution time of camera-basedAD perception. We propose a novel two-stage attack strategy along with thethree new loss function designs. Our evaluation is conducted on four popularcamera-based AD perception pipelines, and the results demonstrate thatSlowTrack significantly outperforms existing latency-based attacks whilemaintaining comparable imperceptibility levels. Furthermore, we perform theevaluation on Baidu Apollo, an industry-grade full-stack AD system, and LGSVL,a production-grade AD simulator, with two scenarios to compare the system-leveleffects of SlowTrack and existing attacks. Our evaluation results show that thesystem-level effects can be significantly improved, i.e., the vehicle crashrate of SlowTrack is around 95% on average while existing works only havearound 30%.</description><author>Chen Ma, Ningfei Wang, Qi Alfred Chen, Chao Shen</author><pubDate>Tue, 26 Dec 2023 13:02:07 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.09520v2</guid></item><item><title>Lift-Attend-Splat: Bird's-eye-view camera-lidar fusion using transformers</title><link>http://arxiv.org/abs/2312.14919v2</link><description>Combining complementary sensor modalities is crucial to providing robustperception for safety-critical robotics applications such as autonomous driving(AD). Recent state-of-the-art camera-lidar fusion methods for AD rely onmonocular depth estimation which is a notoriously difficult task compared tousing depth information from the lidar directly. Here, we find that thisapproach does not leverage depth as expected and show that naively improvingdepth estimation does not lead to improvements in object detection performanceand that, strikingly, removing depth estimation altogether does not degradeobject detection performance. This suggests that relying on monocular depthcould be an unnecessary architectural bottleneck during camera-lidar fusion. Inthis work, we introduce a novel fusion method that bypasses monocular depthestimation altogether and instead selects and fuses camera and lidar featuresin a bird's-eye-view grid using a simple attention mechanism. We show that ourmodel can modulate its use of camera features based on the availability oflidar features and that it yields better 3D object detection on the nuScenesdataset than baselines relying on monocular depth estimation.</description><author>James Gunn, Zygmunt Lenyk, Anuj Sharma, Andrea Donati, Alexandru Buburuzan, John Redford, Romain Mueller</author><pubDate>Tue, 26 Dec 2023 13:00:08 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.14919v2</guid></item><item><title>Dual-scale Enhanced and Cross-generative Consistency Learning for Semi-supervised Polyp Segmentation</title><link>http://arxiv.org/abs/2312.16039v1</link><description>Automatic polyp segmentation plays a crucial role in the early diagnosis andtreatment of colorectal cancer (CRC). However, existing methods heavily rely onfully supervised training, which requires a large amount of labeled data withtime-consuming pixel-wise annotations. Moreover, accurately segmenting polypsposes challenges due to variations in shape, size, and location. To addressthese issues, we propose a novel Dual-scale Enhanced and Cross-generativeconsistency learning framework for semi-supervised polyp Segmentation (DEC-Seg)from colonoscopy images. First, we propose a Cross-level Feature Aggregation(CFA) module that integrates cross-level adjacent layers to enhance the featurerepresentation ability across different resolutions. To address scalevariation, we present a scale-enhanced consistency constraint, which ensuresconsistency in the segmentation maps generated from the same input image atdifferent scales. This constraint helps handle variations in polyp sizes andimproves the robustness of the model. Additionally, we design a scale-awareperturbation consistency scheme to enhance the robustness of the mean teachermodel. Furthermore, we propose a cross-generative consistency scheme, in whichthe original and perturbed images can be reconstructed using cross-segmentationmaps. This consistency constraint allows us to mine effective featurerepresentations and boost the segmentation performance. To produce moreaccurate segmentation maps, we propose a Dual-scale Complementary Fusion (DCF)module that integrates features from two scale-specific decoders operating atdifferent scales. Extensive experimental results on five benchmark datasetsdemonstrate the effectiveness of our DEC-Seg against other state-of-the-artsemi-supervised segmentation approaches. The implementation code will bereleased at https://github.com/taozh2017/DECSeg.</description><author>Yunqi Gu, Tao Zhou, Yizhe Zhang, Yi Zhou, Kelei He, Chen Gong, Huazhu Fu</author><pubDate>Tue, 26 Dec 2023 12:56:31 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.16039v1</guid></item><item><title>Critical nonlinear aspects of hopping transport for reconfigurable logic in disordered dopant networks</title><link>http://arxiv.org/abs/2312.16037v1</link><description>Nonlinear behavior in the hopping transport of interacting charges enablesreconfigurable logic in disordered dopant network devices, where voltagesapplied at control electrodes tune the relation between voltages applied atinput electrodes and the current measured at an output electrode. From kineticMonte Carlo simulations we analyze the critical nonlinear aspects ofvariable-range hopping transport for realizing Boolean logic gates in thesedevices on three levels. First, we quantify the occurrence of individual gatesfor random choices of control voltages. We find that linearly inseparable gatessuch as the XOR gate are less likely to occur than linearly separable gatessuch as the AND gate, despite the fact that the number of different regions inthe multidimensional control voltage space for which AND or XOR gates occur iscomparable. Second, we use principal component analysis to characterize thedistribution of the output current vectors for the (00,10,01,11) logic inputcombinations in terms of eigenvectors and eigenvalues of the output covariancematrix. This allows a simple and direct comparison of the behavior of differentsimulated devices and a comparison to experimental devices. Third, we quantifythe nonlinearity in the distribution of the output current vectors necessaryfor realizing Boolean functionality by introducing three nonlinearityindicators. The analysis provides a physical interpretation of the effects ofchanging the hopping distance and temperature and is used in a comparison withdata generated by a deep neural network trained on a physical device.</description><author>Henri Tertilt, Jonas Mensing, Marlon Becker, Wilfred G. van der Wiel, Peter A. Bobbert, Andreas Heuer</author><pubDate>Tue, 26 Dec 2023 12:55:32 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.16037v1</guid></item><item><title>Ensemble Learning to Assess Dynamics of Affective Experience Ratings and Physiological Change</title><link>http://arxiv.org/abs/2312.16036v1</link><description>The congruence between affective experiences and physiological changes hasbeen a debated topic for centuries. Recent technological advances inmeasurement and data analysis provide hope to solve this epic challenge. Openscience and open data practices, together with data analysis challenges open tothe academic community, are also promising tools for solving this problem. Inthis entry to the Emotion Physiology and Experience Collaboration (EPiC)challenge, we propose a data analysis solution that combines theoreticalassumptions with data-driven methodologies. We used feature engineering andensemble selection. Each predictor was trained on subsets of the training datathat would maximize the information available for training. Late fusion wasused with an averaging step. We chose to average considering a ``wisdom ofcrowds'' strategy. This strategy yielded an overall RMSE of 1.19 in the testset. Future work should carefully explore if our assumptions are correct andthe potential of weighted fusion.</description><author>Felix Dollack, Kiyoshi Kiyokawa, Huakun Liu, Monica Perusquia-Hernandez, Chirag Raman, Hideaki Uchiyama, Xin Wei</author><pubDate>Tue, 26 Dec 2023 12:53:57 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.16036v1</guid></item><item><title>A Stochastic Analysis of the Linguistic Provenance of English Place Names</title><link>http://arxiv.org/abs/2312.12850v2</link><description>In English place name analysis, meanings are often derived from theresemblance of roots in place names to topographical features, proper namesand/or habitation terms in one of the languages that have had an influence onEnglish place names. The problem here is that it is sometimes difficult todetermine the base language to use to interpret the roots. The purpose of thispaper is to stochastically determine the resemblance between 18799 Englishplace names and 84685 place names from Ireland, Scotland, Wales, Denmark,Norway, Sweden, France, Germany, the Netherlands and Ancient Rome. Each Englishplace name is ranked according to the extent to which it resembles place namesfrom the other countries, and this provides a basis for determining the likelylanguage to use to interpret the place name. A number of observations can bemade using the ranking provided. In particular, it is found that `Didlington'is the most archetypically English place name in the English sample, and `Anna'is the least. Furthermore, it is found that the place names in the non-Englishdatasets are most similar to Norwegian place names and least similar to Welshplace names.</description><author>Michael Dalvean</author><pubDate>Tue, 26 Dec 2023 12:42:33 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.12850v2</guid></item><item><title>DualStreamFoveaNet: A Dual Stream Fusion Architecture with Anatomical Awareness for Robust Fovea Localization</title><link>http://arxiv.org/abs/2302.06961v4</link><description>Accurate fovea localization is essential for analyzing retinal diseases toprevent irreversible vision loss. While current deep learning-based methodsoutperform traditional ones, they still face challenges such as the lack oflocal anatomical landmarks around the fovea, the inability to robustly handlediseased retinal images, and the variations in image conditions. In this paper,we propose a novel transformer-based architecture called DualStreamFoveaNet(DSFN) for multi-cue fusion. This architecture explicitly incorporateslong-range connections and global features using retina and vesseldistributions for robust fovea localization. We introduce a spatial attentionmechanism in the dual-stream encoder to extract and fuse self-learnedanatomical information, focusing more on features distributed along bloodvessels and significantly reducing computational costs by decreasing tokennumbers. Our extensive experiments show that the proposed architecture achievesstate-of-the-art performance on two public datasets and one large-scale privatedataset. Furthermore, we demonstrate that the DSFN is more robust on bothnormal and diseased retina images and has better generalization capacity incross-dataset experiments.</description><author>Sifan Song, Jinfeng Wang, Zilong Wang, Jionglong Su, Xiaowei Ding, Kang Dang</author><pubDate>Tue, 26 Dec 2023 12:42:29 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2302.06961v4</guid></item><item><title>Large Language Model (LLM) Bias Index -- LLMBI</title><link>http://arxiv.org/abs/2312.14769v2</link><description>The Large Language Model Bias Index (LLMBI) is a pioneering approach designedto quantify and address biases inherent in large language models (LLMs), suchas GPT-4. We recognise the increasing prevalence and impact of LLMs acrossdiverse sectors. This research introduces a novel metric, LLMBI, tosystematically measure and mitigate biases potentially skewing model responses.We formulated LLMBI using a composite scoring system incorporating multipledimensions of bias, including but not limited to age, gender, and racialbiases. To operationalise this metric, we engaged in a multi-step process involvingcollecting and annotating LLM responses, applying sophisticated NaturalLanguage Processing (NLP) techniques for bias detection, and computing theLLMBI score through a specially crafted mathematical formula. The formulaintegrates weighted averages of various bias dimensions, a penalty for datasetdiversity deficiencies, and a correction for sentiment biases. Our empiricalanalysis, conducted using responses from OpenAI's API, employs advancedsentiment analysis as a representative method for bias detection. The research reveals LLMs, whilst demonstrating impressive capabilities intext generation, exhibit varying degrees of bias across different dimensions.LLMBI provides a quantifiable measure to compare biases across models and overtime, offering a vital tool for systems engineers, researchers and regulatorsin enhancing the fairness and reliability of LLMs. It highlights the potentialof LLMs in mimicking unbiased human-like responses. Additionally, itunderscores the necessity of continuously monitoring and recalibrating suchmodels to align with evolving societal norms and ethical standards.</description><author>Abiodun Finbarrs Oketunji, Muhammad Anas, Deepthi Saina</author><pubDate>Tue, 26 Dec 2023 12:33:08 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.14769v2</guid></item><item><title>Dynamic Algorithms for Matroid Submodular Maximization</title><link>http://arxiv.org/abs/2306.00959v2</link><description>Submodular maximization under matroid and cardinality constraints areclassical problems with a wide range of applications in machine learning,auction theory, and combinatorial optimization. In this paper, we considerthese problems in the dynamic setting, where (1) we have oracle access to amonotone submodular function $f: 2^{V} \rightarrow \mathbb{R}^+$ and (2) we aregiven a sequence $\mathcal{S}$ of insertions and deletions of elements of anunderlying ground set $V$. We develop the first fully dynamic $(4+\epsilon)$-approximation algorithm forthe submodular maximization problem under the matroid constraint using anexpected worst-case $O(k\log(k)\log^3{(k/\epsilon)})$ query complexity where $0&lt; \epsilon \le 1$. This resolves an open problem of Chen and Peng (STOC'22) andLattanzi et al. (NeurIPS'20). As a byproduct, for the submodular maximization under the cardinalityconstraint $k$, we propose a parameterized (by the cardinality constraint $k$)dynamic algorithm that maintains a $(2+\epsilon)$-approximate solution of thesequence $\mathcal{S}$ at any time $t$ using an expected worst-case querycomplexity $O(k\epsilon^{-1}\log^2(k))$. This is the first dynamic algorithmfor the problem that has a query complexity independent of the size of groundset $V$.</description><author>Kiarash Banihashem, Leyla Biabani, Samira Goudarzi, MohammadTaghi Hajiaghayi, Peyman Jabbarzade, Morteza Monemizadeh</author><pubDate>Tue, 26 Dec 2023 12:30:52 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.00959v2</guid></item><item><title>Dynamic AGV Task Allocation in Intelligent Warehouses</title><link>http://arxiv.org/abs/2312.16026v1</link><description>This paper explores the integration of Automated Guided Vehicles (AGVs) inwarehouse order picking, a crucial and cost-intensive aspect of warehouseoperations. The booming AGV industry, accelerated by the COVID-19 pandemic, iswitnessing widespread adoption due to its efficiency, reliability, andcost-effectiveness in automating warehouse tasks. This paper focuses onenhancing the picker-to-parts system, prevalent in small to medium-sizedwarehouses, through the strategic use of AGVs. We discuss the benefits andapplications of AGVs in various warehouse tasks, highlighting theirtransformative potential in improving operational efficiency. We examine thedeployment of AGVs by leading companies in the industry, showcasing theirvaried functionalities in warehouse management. Addressing the gap in researchon optimizing operational performance in hybrid environments where humans andAGVs coexist, our study delves into a dynamic picker-to-parts warehousescenario. We propose a novel approach Neural Approximate Dynamic Programmingapproach for coordinating a mixed team of human and AGV workers, aiming tomaximize order throughput and operational efficiency. This involves innovativesolutions for non-myopic decision making, order batching, and batterymanagement. We also discuss the integration of advanced robotics technology inautomating the complete order-picking process. Through a comprehensivenumerical study, our work offers valuable insights for managing a heterogeneousworkforce in a hybrid warehouse setting, contributing significantly to thefield of warehouse automation and logistics.</description><author>Arash Dehghan, Mucahit Cevik, Merve Bodur</author><pubDate>Tue, 26 Dec 2023 12:28:25 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.16026v1</guid></item><item><title>Plug-and-Play Regularization on Magnitude with Deep Priors for 3D Near-Field MIMO Imaging</title><link>http://arxiv.org/abs/2312.16024v1</link><description>Near-field radar imaging systems are recently used in a wide range ofapplications, such as medical diagnosis, through-wall imaging, concealed weapondetection, and nondestructive evaluation. In this paper, we consider theproblem of reconstructing the three-dimensional (3D) complex-valuedreflectivity distribution of the near-field scene from sparse multiple-inputmultiple-output (MIMO) array measurements. Using the alternating directionmethod of multipliers (ADMM) framework, we solve this inverse problem byenforcing regularization on the magnitude of the complex-valued reflectivitydistribution. For this, we provide a general expression for the proximalmapping associated with such regularization functionals. This equivalentlycorresponds to the solution of a complex-valued denoising problem whichinvolves regularization on the magnitude. By utilizing this expression, wedevelop a novel and efficient plug-and-play (PnP) reconstruction method thatconsists of simple update steps. Due to the success of data-adaptive deeppriors in various imaging problems, we also train a 3D deep denoiser to exploitwithin the developed PnP framework for MIMO imaging. The effectiveness of thedeveloped learning-based PnP approach is illustrated under various compressiveand noisy observation scenarios using both simulated data and experimentalmeasurements. The performance is also compared with sparsity priors and thecommonly used analytical approaches such as back-projection and Kirchhoffmigration. The results demonstrate that the developed technique not onlyprovides state-of-the-art reconstruction performance for 3D real-world targets,but also enables fast computation. Our approach provides a unified generalframework to effectively handle arbitrary regularization on the magnitude of acomplex-valued unknown and is equally applicable to other radar image formationproblems (including SAR).</description><author>Okyanus Oral, Figen S. Oktem</author><pubDate>Tue, 26 Dec 2023 12:25:09 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.16024v1</guid></item><item><title>DocMSU: A Comprehensive Benchmark for Document-level Multimodal Sarcasm Understanding</title><link>http://arxiv.org/abs/2312.16023v1</link><description>Multimodal Sarcasm Understanding (MSU) has a wide range of applications inthe news field such as public opinion analysis and forgery detection. However,existing MSU benchmarks and approaches usually focus on sentence-level MSU. Indocument-level news, sarcasm clues are sparse or small and are often concealedin long text. Moreover, compared to sentence-level comments like tweets, whichmainly focus on only a few trends or hot topics (e.g., sports events), contentin the news is considerably diverse. Models created for sentence-level MSU mayfail to capture sarcasm clues in document-level news. To fill this gap, wepresent a comprehensive benchmark for Document-level Multimodal SarcasmUnderstanding (DocMSU). Our dataset contains 102,588 pieces of news withtext-image pairs, covering 9 diverse topics such as health, business, etc. Theproposed large-scale and diverse DocMSU significantly facilitates the researchof document-level MSU in real-world scenarios. To take on the new challengesposed by DocMSU, we introduce a fine-grained sarcasm comprehension method toproperly align the pixel-level image features with word-level textual featuresin documents. Experiments demonstrate the effectiveness of our method, showingthat it can serve as a baseline approach to the challenging DocMSU. Our codeand dataset are available at https://github.com/Dulpy/DocMSU.</description><author>Hang Du, Guoshun Nan, Sicheng Zhang, Binzhu Xie, Junrui Xu, Hehe Fan, Qimei Cui, Xiaofeng Tao, Xudong Jiang</author><pubDate>Tue, 26 Dec 2023 12:24:14 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.16023v1</guid></item><item><title>Robust Neural Pruning with Gradient Sampling Optimization for Residual Neural Networks</title><link>http://arxiv.org/abs/2312.16020v1</link><description>In this study, we explore an innovative approach for neural networkoptimization, focusing on the application of gradient sampling techniques,similar to those in StochGradAdam, during the pruning process. Our primaryobjective is to maintain high accuracy levels in pruned models, a criticalchallenge in resource-limited scenarios. Our extensive experiments reveal thatmodels optimized with gradient sampling techniques are more effective atpreserving accuracy during pruning compared to those using traditionaloptimization methods. This finding underscores the significance of gradientsampling in facilitating robust learning and enabling networks to retaincrucial information even after substantial reduction in their complexity. Wevalidate our approach across various datasets and neural architectures,demonstrating its broad applicability and effectiveness. The paper also delvesinto the theoretical aspects, explaining how gradient sampling techniquescontribute to the robustness of models during pruning. Our results suggest apromising direction for creating efficient neural networks that do notcompromise on accuracy, even in environments with constrained computationalresources.</description><author>Juyoung Yun</author><pubDate>Tue, 26 Dec 2023 12:19:22 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.16020v1</guid></item><item><title>Robust Survival Analysis with Adversarial Regularization</title><link>http://arxiv.org/abs/2312.16019v1</link><description>Survival Analysis (SA) is about modeling the time for an event of interest tooccur, which has important applications in many fields, including medicine,defense, finance, and aerospace. Recent work has demonstrated the benefits ofusing Neural Networks (NNs) to capture complicated relationships in SA.However, the datasets used to train these models are often subject touncertainty (e.g., noisy measurements, human error), which we show cansubstantially degrade the performance of existing techniques. To address thisissue, this work leverages recent advances in NN verification to provide newalgorithms for generating fully parametric survival models that are robust tosuch uncertainties. In particular, we introduce a robust loss function fortraining the models and use CROWN-IBP regularization to address thecomputational challenges with solving the resulting Min-Max problem. Toevaluate the proposed approach, we apply relevant perturbations to publiclyavailable datasets in the SurvSet repository and compare survival modelsagainst several baselines. We empirically show that Survival Analysis withAdversarial Regularization (SAWAR) method on average ranks best for datasetperturbations of varying magnitudes on metrics such as Negative Log Likelihood(NegLL), Integrated Brier Score (IBS), and Concordance Index (CI), concludingthat adversarial regularization enhances performance in SA. Code:https://github.com/mlpotter/SAWAR</description><author>Michael Potter, Stefano Maxenti, Michael Everett</author><pubDate>Tue, 26 Dec 2023 12:18:31 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.16019v1</guid></item><item><title>CoTracker: It is Better to Track Together</title><link>http://arxiv.org/abs/2307.07635v2</link><description>We introduce CoTracker, a transformer-based model that tracks dense points ina frame jointly across a video sequence. This differs from most existingstate-of-the-art approaches that track points independently, ignoring theircorrelation. We show that joint tracking results in a significantly highertracking accuracy and robustness. We also provide several technicalinnovations, including the concept of virtual tracks, which allows CoTracker totrack 70k points jointly and simultaneously. Furthermore, CoTracker operatescausally on short windows (hence, it is suitable for online tasks), but istrained by unrolling the windows across longer video sequences, which enablesand significantly improves long-term tracking. We demonstrate qualitativelyimpressive tracking results, where points can be tracked for a long time evenwhen they are occluded or leave the field of view. Quantitatively, CoTrackeroutperforms all recent trackers on standard benchmarks, often by a substantialmargin.</description><author>Nikita Karaev, Ignacio Rocco, Benjamin Graham, Natalia Neverova, Andrea Vedaldi, Christian Rupprecht</author><pubDate>Tue, 26 Dec 2023 12:13:18 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.07635v2</guid></item><item><title>Learning Rate Free Sampling in Constrained Domains</title><link>http://arxiv.org/abs/2305.14943v3</link><description>We introduce a suite of new particle-based algorithms for sampling inconstrained domains which are entirely learning rate free. Our approachleverages coin betting ideas from convex optimisation, and the viewpoint ofconstrained sampling as a mirrored optimisation problem on the space ofprobability measures. Based on this viewpoint, we also introduce a unifyingframework for several existing constrained sampling algorithms, includingmirrored Langevin dynamics and mirrored Stein variational gradient descent. Wedemonstrate the performance of our algorithms on a range of numerical examples,including sampling from targets on the simplex, sampling with fairnessconstraints, and constrained sampling problems in post-selection inference. Ourresults indicate that our algorithms achieve competitive performance withexisting constrained sampling methods, without the need to tune anyhyperparameters.</description><author>Louis Sharrock, Lester Mackey, Christopher Nemeth</author><pubDate>Tue, 26 Dec 2023 12:12:57 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.14943v3</guid></item><item><title>Physics of Language Models: Part 3.1, Knowledge Storage and Extraction</title><link>http://arxiv.org/abs/2309.14316v2</link><description>Large language models (LLMs) can store a vast amount of world knowledge,often extractable via question-answering (e.g., "What is Abraham Lincoln'sbirthday?"). However, do they answer such questions based on exposure tosimilar questions during training (i.e., cheating), or by genuinely learning toextract knowledge from sources like Wikipedia? In this paper, we investigate this issue using a controlled biographydataset. We find a strong correlation between the model's ability to extractknowledge and various diversity measures of the training data.$\textbf{Essentially}$, for knowledge to be reliably extracted, it must besufficiently augmented (e.g., through paraphrasing, sentence shuffling)$\textit{during pretraining}$. Without such augmentation, knowledge may bememorized but not extractable, leading to 0% accuracy, regardless of subsequentinstruction fine-tuning. To understand why this occurs, we employ (nearly) linear probing todemonstrate a strong connection between the observed correlation and how themodel internally encodes knowledge -- whether it is linearly encoded in thehidden embeddings of entity names or distributed across other token embeddingsin the training text. This paper provides $\textbf{several key recommendations for LLM pretrainingin the industry}$: (1) rewrite the pretraining data -- using small, auxiliarymodels -- to provide knowledge augmentation, and (2) incorporate moreinstruction-finetuning data into the pretraining stage before it becomes toolate.</description><author>Zeyuan Allen-Zhu, Yuanzhi Li</author><pubDate>Tue, 26 Dec 2023 12:00:15 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2309.14316v2</guid></item><item><title>Transavs: End-To-End Audio-Visual Segmentation With Transformer</title><link>http://arxiv.org/abs/2305.07223v2</link><description>Audio-Visual Segmentation (AVS) is a challenging task, which aims to segmentsounding objects in video frames by exploring audio signals. Generally AVSfaces two key challenges: (1) Audio signals inherently exhibit a high degree ofinformation density, as sounds produced by multiple objects are entangledwithin the same audio stream; (2) Objects of the same category tend to producesimilar audio signals, making it difficult to distinguish between them and thusleading to unclear segmentation results. Toward this end, we propose TransAVS,the first Transformer-based end-to-end framework for AVS task. Specifically,TransAVS disentangles the audio stream as audio queries, which will interactwith images and decode into segmentation masks with full transformerarchitectures. This scheme not only promotes comprehensive audio-imagecommunication but also explicitly excavates instance cues encapsulated in thescene. Meanwhile, to encourage these audio queries to capture distinctivesounding objects instead of degrading to be homogeneous, we devise twoself-supervised loss functions at both query and mask levels, allowing themodel to capture distinctive features within similar audio data and achievemore precise segmentation. Our experiments demonstrate that TransAVS achievesstate-of-the-art results on the AVSBench dataset, highlighting itseffectiveness in bridging the gap between audio and visual modalities.</description><author>Yuhang Ling, Yuxi Li, Zhenye Gan, Jiangning Zhang, Mingmin Chi, Yabiao Wang</author><pubDate>Tue, 26 Dec 2023 12:00:03 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.07223v2</guid></item><item><title>A Comprehensive Survey of Evaluation Techniques for Recommendation Systems</title><link>http://arxiv.org/abs/2312.16015v1</link><description>The effectiveness of recommendation systems is pivotal to user engagement andsatisfaction in online platforms. As these recommendation systems increasinglyinfluence user choices, their evaluation transcends mere technical performanceand becomes central to business success. This paper addresses the multifacetednature of recommendation system evaluation by introducing a comprehensive suiteof metrics, each tailored to capture a distinct aspect of system performance.We discuss similarity metrics that quantify the precision of content-based andcollaborative filtering mechanisms, along with candidate generation metricswhich measure how well the system identifies a broad yet pertinent range ofitems. Following this, we delve into predictive metrics that assess theaccuracy of forecasted preferences, ranking metrics that evaluate the order inwhich recommendations are presented, and business metrics that align systemperformance with economic objectives. Our approach emphasizes the contextual application of these metrics and theirinterdependencies. In this paper, we identify the strengths and limitations ofcurrent evaluation practices and highlight the nuanced trade-offs that emergewhen optimizing recommendation systems across different metrics. The paperconcludes by proposing a framework for selecting and interpreting these metricsto not only improve system performance but also to advance business goals. Thiswork is to aid researchers and practitioners in critically assessingrecommendation systems and fosters the development of more nuanced, effective,and economically viable personalization strategies. Our code is available atGitHub -https://github.com/aryan-jadon/Evaluation-Metrics-for-Recommendation-Systems.</description><author>Aryan Jadon, Avinash Patil</author><pubDate>Tue, 26 Dec 2023 11:57:01 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.16015v1</guid></item><item><title>Passive Non-Line-of-Sight Imaging with Light Transport Modulation</title><link>http://arxiv.org/abs/2312.16014v1</link><description>Passive non-line-of-sight (NLOS) imaging has witnessed rapid development inrecent years, due to its ability to image objects that are out of sight. Thelight transport condition plays an important role in this task since changingthe conditions will lead to different imaging models. Existing learning-basedNLOS methods usually train independent models for different light transportconditions, which is computationally inefficient and impairs the practicalityof the models. In this work, we propose NLOS-LTM, a novel passive NLOS imagingmethod that effectively handles multiple light transport conditions with asingle network. We achieve this by inferring a latent light transportrepresentation from the projection image and using this representation tomodulate the network that reconstructs the hidden image from the projectionimage. We train a light transport encoder together with a vector quantizer toobtain the light transport representation. To further regulate thisrepresentation, we jointly learn both the reconstruction network and thereprojection network during training. A set of light transport modulationblocks is used to modulate the two jointly trained networks in a multi-scaleway. Extensive experiments on a large-scale passive NLOS dataset demonstratethe superiority of the proposed method. The code is available athttps://github.com/JerryOctopus/NLOS-LTM.</description><author>Jiarui Zhang, Ruixu Geng, Xiaolong Du, Yan Chen, Houqiang Li, Yang Hu</author><pubDate>Tue, 26 Dec 2023 11:49:23 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.16014v1</guid></item><item><title>Inverse Transfer Multiobjective Optimization</title><link>http://arxiv.org/abs/2312.14713v2</link><description>Transfer optimization enables data-efficient optimization of a target task byleveraging experiential priors from related source tasks. This is especiallyuseful in multiobjective optimization settings where a set of trade-offsolutions is sought under tight evaluation budgets. In this paper, we introducea novel concept of inverse transfer in multiobjective optimization. Inversetransfer stands out by employing probabilistic inverse models to mapperformance vectors in the objective space to population search distributionsin task-specific decision space, facilitating knowledge transfer throughobjective space unification. Building upon this idea, we introduce the firstInverse Transfer Multiobjective Evolutionary Optimizer (invTrEMO). A keyhighlight of invTrEMO is its ability to harness the common objective functionsprevalent in many application areas, even when decision spaces do not preciselyalign between tasks. This allows invTrEMO to uniquely and effectively utilizeinformation from heterogeneous source tasks as well. Furthermore, invTrEMOyields high-precision inverse models as a significant byproduct, enabling thegeneration of tailored solutions on-demand based on user preferences. Empiricalstudies on multi- and many-objective benchmark problems, as well as a practicalcase study, showcase the faster convergence rate and modelling accuracy of theinvTrEMO relative to state-of-the-art evolutionary and Bayesian optimizationalgorithms. The source code of the invTrEMO is made available athttps://github.com/LiuJ-2023/invTrEMO.</description><author>Jiao Liu, Abhishek Gupta, Yew-Soon Ong</author><pubDate>Tue, 26 Dec 2023 11:45:49 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.14713v2</guid></item><item><title>Detection-based Intermediate Supervision for Visual Question Answering</title><link>http://arxiv.org/abs/2312.16012v1</link><description>Recently, neural module networks (NMNs) have yielded ongoing success inanswering compositional visual questions, especially those involving multi-hopvisual and logical reasoning. NMNs decompose the complex question into severalsub-tasks using instance-modules from the reasoning paths of that question andthen exploit intermediate supervisions to guide answer prediction, therebyimproving inference interpretability. However, their performance may behindered due to sketchy modeling of intermediate supervisions. For instance,(1) a prior assumption that each instance-module refers to only one groundedobject yet overlooks other potentially associated grounded objects, impedingfull cross-modal alignment learning; (2) IoU-based intermediate supervisionsmay introduce noise signals as the bounding box overlap issue might guide themodel's focus towards irrelevant objects. To address these issues, a novelmethod, \textbf{\underline{D}}etection-based \textbf{\underline{I}}ntermediate\textbf{\underline{S}}upervision (DIS), is proposed, which adopts a generativedetection framework to facilitate multiple grounding supervisions via sequencegeneration. As such, DIS offers more comprehensive and accurate intermediatesupervisions, thereby boosting answer prediction performance. Furthermore, byconsidering intermediate results, DIS enhances the consistency in answeringcompositional questions and their sub-questions.Extensive experimentsdemonstrate the superiority of our proposed DIS, showcasing both improvedaccuracy and state-of-the-art reasoning consistency compared to priorapproaches.</description><author>Yuhang Liu, Daowan Peng, Wei Wei, Yuanyuan Fu, Wenfeng Xie, Dangyang Chen</author><pubDate>Tue, 26 Dec 2023 11:45:22 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.16012v1</guid></item><item><title>Achieving Fairness in DareFightingICE Agents Evaluation Through a Delay Mechanism</title><link>http://arxiv.org/abs/2312.16010v1</link><description>This paper proposes a delay mechanism to mitigate the impact of latencydifferences in the gRPC framework--a high-performance, open-source universalremote procedure call (RPC) framework--between different programming languageson the performance of agents in DareFightingICE, a fighting game researchplatform. The study finds that gRPC latency differences between Java and Pythoncan significantly impact real-time decision-making. Without a delay mechanism,Java-based agents outperform Python-based ones due to lower gRPC latency on theJava platform. However, with the proposed delay mechanism, both Java-based andPython-based agents exhibit similar performance, leading to a fair comparisonbetween agents developed using different programming languages. Thus, this workunderscores the crucial importance of considering gRPC latency when developingand evaluating agents in DareFightingICE, and the insights gained couldpotentially extend to other gRPC-based applications.</description><author>Chollakorn Nimpattanavong, Thai Van Nguyen, Ibrahim Khan, Ruck Thawonmas, Worawat Choensawat, Kingkarn Sookhanaphibarn</author><pubDate>Tue, 26 Dec 2023 11:38:36 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.16010v1</guid></item><item><title>A Survey of Reasoning with Foundation Models</title><link>http://arxiv.org/abs/2312.11562v4</link><description>Reasoning, a crucial ability for complex problem-solving, plays a pivotalrole in various real-world settings such as negotiation, medical diagnosis, andcriminal investigation. It serves as a fundamental methodology in the field ofArtificial General Intelligence (AGI). With the ongoing development offoundation models, there is a growing interest in exploring their abilities inreasoning tasks. In this paper, we introduce seminal foundation models proposedor adaptable for reasoning, highlighting the latest advancements in variousreasoning tasks, methods, and benchmarks. We then delve into the potentialfuture directions behind the emergence of reasoning abilities within foundationmodels. We also discuss the relevance of multimodal learning, autonomousagents, and super alignment in the context of reasoning. By discussing thesefuture research directions, we hope to inspire researchers in their explorationof this field, stimulate further advancements in reasoning with foundationmodels, and contribute to the development of AGI.</description><author>Jiankai Sun, Chuanyang Zheng, Enze Xie, Zhengying Liu, Ruihang Chu, Jianing Qiu, Jiaqi Xu, Mingyu Ding, Hongyang Li, Mengzhe Geng, Yue Wu, Wenhai Wang, Junsong Chen, Zhangyue Yin, Xiaozhe Ren, Jie Fu, Junxian He, Wu Yuan, Qi Liu, Xihui Liu, Yu Li, Hao Dong, Yu Cheng, Ming Zhang, Pheng Ann Heng, Jifeng Dai, Ping Luo, Jingdong Wang, Ji-Rong Wen, Xipeng Qiu, Yike Guo, Hui Xiong, Qun Liu, Zhenguo Li</author><pubDate>Tue, 26 Dec 2023 11:31:54 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.11562v4</guid></item><item><title>Leading the Pack: N-player Opponent Shaping</title><link>http://arxiv.org/abs/2312.12564v2</link><description>Reinforcement learning solutions have great success in the 2-player generalsum setting. In this setting, the paradigm of Opponent Shaping (OS), in whichagents account for the learning of their co-players, has led to agents whichare able to avoid collectively bad outcomes, whilst also maximizing theirreward. These methods have currently been limited to 2-player game. However,the real world involves interactions with many more agents, with interactionson both local and global scales. In this paper, we extend Opponent Shaping (OS)methods to environments involving multiple co-players and multiple shapingagents. We evaluate on over 4 different environments, varying the number ofplayers from 3 to 5, and demonstrate that model-based OS methods converge toequilibrium with better global welfare than naive learning. However, we findthat when playing with a large number of co-players, OS methods' relativeperformance reduces, suggesting that in the limit OS methods may not performwell. Finally, we explore scenarios where more than one OS method is present,noticing that within games requiring a majority of cooperating agents, OSmethods converge to outcomes with poor global welfare.</description><author>Alexandra Souly, Timon Willi, Akbir Khan, Robert Kirk, Chris Lu, Edward Grefenstette, Tim Rocktäschel</author><pubDate>Tue, 26 Dec 2023 11:23:25 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.12564v2</guid></item><item><title>Recurrent Hypernetworks are Surprisingly Strong in Meta-RL</title><link>http://arxiv.org/abs/2309.14970v4</link><description>Deep reinforcement learning (RL) is notoriously impractical to deploy due tosample inefficiency. Meta-RL directly addresses this sample inefficiency bylearning to perform few-shot learning when a distribution of related tasks isavailable for meta-training. While many specialized meta-RL methods have beenproposed, recent work suggests that end-to-end learning in conjunction with anoff-the-shelf sequential model, such as a recurrent network, is a surprisinglystrong baseline. However, such claims have been controversial due to limitedsupporting evidence, particularly in the face of prior work establishingprecisely the opposite. In this paper, we conduct an empirical investigation.While we likewise find that a recurrent network can achieve strong performance,we demonstrate that the use of hypernetworks is crucial to maximizing theirpotential. Surprisingly, when combined with hypernetworks, the recurrentbaselines that are far simpler than existing specialized methods actuallyachieve the strongest performance of all methods evaluated. We provide code athttps://github.com/jacooba/hyper.</description><author>Jacob Beck, Risto Vuorio, Zheng Xiong, Shimon Whiteson</author><pubDate>Tue, 26 Dec 2023 11:19:10 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2309.14970v4</guid></item><item><title>The NUS-HLT System for ICASSP2024 ICMC-ASR Grand Challenge</title><link>http://arxiv.org/abs/2312.16002v1</link><description>This paper summarizes our team's efforts in both tracks of the ICMC-ASRChallenge for in-car multi-channel automatic speech recognition. Our submittedsystems for ICMC-ASR Challenge include the multi-channel front-end enhancementand diarization, training data augmentation, speech recognition modeling withmulti-channel branches. Tested on the offical Eval1 and Eval2 set, our bestsystem achieves a relative 34.3% improvement in CER and 56.5% improvement incpCER, compared to the offical baseline system.</description><author>Meng Ge, Yizhou Peng, Yidi Jiang, Jingru Lin, Junyi Ao, Mehmet Sinan Yildirim, Shuai Wang, Haizhou Li, Mengling Feng</author><pubDate>Tue, 26 Dec 2023 11:11:22 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.16002v1</guid></item><item><title>Pricing with Contextual Elasticity and Heteroscedastic Valuation</title><link>http://arxiv.org/abs/2312.15999v1</link><description>We study an online contextual dynamic pricing problem, where customers decidewhether to purchase a product based on its features and price. We introduce anovel approach to modeling a customer's expected demand by incorporatingfeature-based price elasticity, which can be equivalently represented as avaluation with heteroscedastic noise. To solve the problem, we propose acomputationally efficient algorithm called "Pricing with Perturbation (PwP)",which enjoys an $O(\sqrt{dT\log T})$ regret while allowing arbitraryadversarial input context sequences. We also prove a matching lower bound at$\Omega(\sqrt{dT})$ to show the optimality regarding $d$ and $T$ (up to $\logT$ factors). Our results shed light on the relationship between contextualelasticity and heteroscedastic valuation, providing insights for effective andpractical pricing strategies.</description><author>Jianyu Xu, Yu-Xiang Wang</author><pubDate>Tue, 26 Dec 2023 11:07:37 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.15999v1</guid></item><item><title>Aligning Large Language Models with Human Preferences through Representation Engineering</title><link>http://arxiv.org/abs/2312.15997v1</link><description>Aligning large language models (LLMs) with human preferences is crucial forenhancing their utility in terms of helpfulness, truthfulness, safety,harmlessness, and interestingness. Existing methods for achieving thisalignment often involves employing reinforcement learning from human feedback(RLHF) to fine-tune LLMs based on human labels assessing the relative qualityof model responses. Nevertheless, RLHF is susceptible to instability duringfine-tuning and presents challenges in implementation.Drawing inspiration fromthe emerging field of representation engineering (RepE), this study aims toidentify relevant representations for high-level human preferences embedded inpatterns of activity within an LLM, and achieve precise control of modelbehavior by transforming its representations. This novel approach, denoted asRepresentation Alignment from Human Feedback (RAHF), proves to be effective,computationally efficient, and easy to implement.Extensive experimentsdemonstrate the efficacy of RAHF in not only capturing but also manipulatingrepresentations to align with a broad spectrum of human preferences or values,rather than being confined to a singular concept or function (e.g. honesty orbias). RAHF's versatility in accommodating diverse human preferences shows itspotential for advancing LLM performance.</description><author>Wenhao Liu, Xiaohua Wang, Muling Wu, Tianlong Li, Changze Lv, Zixuan Ling, Jianhao Zhu, Cenyuan Zhang, Xiaoqing Zheng, Xuanjing Huang</author><pubDate>Tue, 26 Dec 2023 11:01:36 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.15997v1</guid></item><item><title>Generalization in Kernel Regression Under Realistic Assumptions</title><link>http://arxiv.org/abs/2312.15995v1</link><description>It is by now well-established that modern over-parameterized models seem toelude the bias-variance tradeoff and generalize well despite overfitting noise.Many recent works attempt to analyze this phenomenon in the relativelytractable setting of kernel regression. However, as we argue in detail, mostpast works on this topic either make unrealistic assumptions, or focus on anarrow problem setup. This work aims to provide a unified theory to upper boundthe excess risk of kernel regression for nearly all common and realisticsettings. Specifically, we provide rigorous bounds that hold for common kernelsand for any amount of regularization, noise, any input dimension, and anynumber of samples. Furthermore, we provide relative perturbation bounds for theeigenvalues of kernel matrices, which may be of independent interest. Thesereveal a self-regularization phenomenon, whereby a heavy tail in theeigendecomposition of the kernel provides it with an implicit form ofregularization, enabling good generalization. When applied to common kernels,our results imply benign overfitting in high input dimensions, nearly temperedoverfitting in fixed dimensions, and explicit convergence rates for regularizedregression. As a by-product, we obtain time-dependent bounds for neuralnetworks trained in the kernel regime.</description><author>Daniel Barzilai, Ohad Shamir</author><pubDate>Tue, 26 Dec 2023 10:55:20 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.15995v1</guid></item><item><title>Practical Bias Mitigation through Proxy Sensitive Attribute Label Generation</title><link>http://arxiv.org/abs/2312.15994v1</link><description>Addressing bias in the trained machine learning system often requires accessto sensitive attributes. In practice, these attributes are not available eitherdue to legal and policy regulations or data unavailability for a givendemographic. Existing bias mitigation algorithms are limited in theirapplicability to real-world scenarios as they require access to sensitiveattributes to achieve fairness. In this research work, we aim to address thisbottleneck through our proposed unsupervised proxy-sensitive attribute labelgeneration technique. Towards this end, we propose a two-stage approach ofunsupervised embedding generation followed by clustering to obtainproxy-sensitive labels. The efficacy of our work relies on the assumption thatbias propagates through non-sensitive attributes that are correlated to thesensitive attributes and, when mapped to the high dimensional latent space,produces clusters of different demographic groups that exist in the data.Experimental results demonstrate that bias mitigation using existing algorithmssuch as Fair Mixup and Adversarial Debiasing yields comparable results onderived proxy labels when compared against using true sensitive attributes.</description><author>Bhushan Chaudhary, Anubha Pandey, Deepak Bhatt, Darshika Tiwari</author><pubDate>Tue, 26 Dec 2023 10:54:15 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.15994v1</guid></item><item><title>Adaptive Kalman-based hybrid car following strategy using TD3 and CACC</title><link>http://arxiv.org/abs/2312.15993v1</link><description>In autonomous driving, the hybrid strategy of deep reinforcement learning andcooperative adaptive cruise control (CACC) can fully utilize the advantages ofthe two algorithms and significantly improve the performance of car following.However, it is challenging for the traditional hybrid strategy based on fixedcoefficients to adapt to mixed traffic flow scenarios, which may decrease theperformance and even lead to accidents. To address the above problems, a hybridcar following strategy based on an adaptive Kalman Filter is proposed byregarding CACC and Twin Delayed Deep Deterministic Policy Gradient (TD3)algorithms. Different from traditional hybrid strategy based on fixedcoefficients, the Kalman gain H, using as an adaptive coefficient, is derivedfrom multi-timestep predictions and Monte Carlo Tree Search. At the end ofstudy, simulation results with 4157745 timesteps indicate that, compared withthe TD3 and HCFS algorithms, the proposed algorithm in this study cansubstantially enhance the safety of car following in mixed traffic flow withoutcompromising the comfort and efficiency.</description><author>Yuqi Zheng, Ruidong Yan, Bin Jia, Rui Jiang, Adriana TAPUS, Xiaojing Chen, Shiteng Zheng, Ying Shang</author><pubDate>Tue, 26 Dec 2023 10:51:46 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.15993v1</guid></item><item><title>Discrete Messages Improve Communication Efficiency among Isolated Intelligent Agents</title><link>http://arxiv.org/abs/2312.15985v1</link><description>Individuals, despite having varied life experiences and learning processes,can communicate effectively through languages. This study aims to explore theefficiency of language as a communication medium. We put forth two specifichypotheses: First, discrete messages are more effective than continuous oneswhen agents have diverse personal experiences. Second, communications usingmultiple discrete tokens are more advantageous than those using a single token.To valdate these hypotheses, we designed multi-agent machine learningexperiments to assess communication efficiency using various informationtransmission methods between speakers and listeners. Our empirical findingsindicate that, in scenarios where agents are exposed to different data,communicating through sentences composed of discrete tokens offers the bestinter-agent communication efficiency. The limitations of our finding includelack of systematic advantages over other more sophisticated encoder-decodermodel such as variational autoencoder and lack of evluation on non-imagedataset, which we will leave for future studies.</description><author>Hang Chen, Yuchuan Jang, Weijie Zhou, Cristian meo, Ziwei Chen, Dianbo Liu</author><pubDate>Tue, 26 Dec 2023 10:30:05 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.15985v1</guid></item><item><title>Choose Your Simulator Wisely: A Review on Open-source Simulators for Autonomous Driving</title><link>http://arxiv.org/abs/2311.11056v2</link><description>Simulators play a crucial role in autonomous driving, offering significanttime, cost, and labor savings. Over the past few years, the number ofsimulators for autonomous driving has grown substantially. However, there is agrowing concern about the validity of algorithms developed and evaluated insimulators, indicating a need for a thorough analysis of the development statusof the simulators. To bridge the gap in research, this paper analyzes the evolution ofsimulators and explains how the functionalities and utilities have developed.Then, the existing simulators are categorized based on their taskapplicability, providing researchers with a taxonomy to swiftly assess asimulator's suitability for specific tasks. Recommendations for selectsimulators are presented, considering factors such as accessibility,maintenance status, and quality. Recognizing potential hazards in simulatorsthat could impact the confidence of simulation experiments, the paper dedicatessubstantial effort to identifying and justifying critical issues in activelymaintained open-source simulators. Moreover, the paper reviews potentialsolutions to address these issues, serving as a guide for enhancing thecredibility of simulators.</description><author>Yueyuan Li, Wei Yuan, Songan Zhang, Weihao Yan, Qiyuan Shen, Chunxiang Wang, Ming Yang</author><pubDate>Tue, 26 Dec 2023 10:28:36 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.11056v2</guid></item></channel></rss>