<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/"><channel><title>Arxivfresh papers</title><link></link><description>Arxiv paper</description><language>en-US</language><lastBuildDate>Thu, 02 May 2024 14:00:03 GMT</lastBuildDate><generator>rfeed v1.0.0</generator><docs>https://github.com/svpino/rfeed/blob/master/README.md</docs><item><title>Spectrally Pruned Gaussian Fields with Neural Compensation</title><link>http://arxiv.org/abs/2405.00676v1</link><description>Recently, 3D Gaussian Splatting, as a novel 3D representation, has garneredattention for its fast rendering speed and high rendering quality. However,this comes with high memory consumption, e.g., a well-trained Gaussian fieldmay utilize three million Gaussian primitives and over 700 MB of memory. Wecredit this high memory footprint to the lack of consideration for therelationship between primitives. In this paper, we propose a memory-efficientGaussian field named SUNDAE with spectral pruning and neural compensation. Onone hand, we construct a graph on the set of Gaussian primitives to model theirrelationship and design a spectral down-sampling module to prune out primitiveswhile preserving desired signals. On the other hand, to compensate for thequality loss of pruning Gaussians, we exploit a lightweight neural network headto mix splatted features, which effectively compensates for quality losseswhile capturing the relationship between primitives in its weights. Wedemonstrate the performance of SUNDAE with extensive results. For example,SUNDAE can achieve 26.80 PSNR at 145 FPS using 104 MB memory while the vanillaGaussian splatting algorithm achieves 25.60 PSNR at 160 FPS using 523 MBmemory, on the Mip-NeRF360 dataset. Codes are publicly available athttps://runyiyang.github.io/projects/SUNDAE/.</description><author>Runyi Yang, Zhenxin Zhu, Zhou Jiang, Baijun Ye, Xiaoxue Chen, Yifei Zhang, Yuantao Chen, Jian Zhao, Hao Zhao</author><pubDate>Wed, 01 May 2024 18:59:45 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.00676v1</guid></item><item><title>Self-Play Preference Optimization for Language Model Alignment</title><link>http://arxiv.org/abs/2405.00675v1</link><description>Traditional reinforcement learning from human feedback (RLHF) approachesrelying on parametric models like the Bradley-Terry model fall short incapturing the intransitivity and irrationality in human preferences. Recentadvancements suggest that directly working with preference probabilities canyield a more accurate reflection of human preferences, enabling more flexibleand accurate language model alignment. In this paper, we propose aself-play-based method for language model alignment, which treats the problemas a constant-sum two-player game aimed at identifying the Nash equilibriumpolicy. Our approach, dubbed \textit{Self-Play Preference Optimization} (SPPO),approximates the Nash equilibrium through iterative policy updates and enjoystheoretical convergence guarantee. Our method can effectively increase thelog-likelihood of the chosen response and decrease that of the rejectedresponse, which cannot be trivially achieved by symmetric pairwise loss such asDirect Preference Optimization (DPO) and Identity Preference Optimization(IPO). In our experiments, using only 60k prompts (without responses) from theUltraFeedback dataset and without any prompt augmentation, by leveraging apre-trained preference model PairRM with only 0.4B parameters, SPPO can obtaina model from fine-tuning Mistral-7B-Instruct-v0.2 that achieves thestate-of-the-art length-controlled win-rate of 28.53% against GPT-4-Turbo onAlpacaEval 2.0. It also outperforms the (iterative) DPO and IPO on MT-Bench andthe Open LLM Leaderboard. Notably, the strong performance of SPPO is achievedwithout additional external supervision (e.g., responses, preferences, etc.)from GPT-4 or other stronger language models.</description><author>Yue Wu, Zhiqing Sun, Huizhuo Yuan, Kaixuan Ji, Yiming Yang, Quanquan Gu</author><pubDate>Wed, 01 May 2024 18:59:20 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.00675v1</guid></item><item><title>Large Language Models as Zero-shot Dialogue State Tracker through Function Calling</title><link>http://arxiv.org/abs/2402.10466v2</link><description>Large language models (LLMs) are increasingly prevalent in conversationalsystems due to their advanced understanding and generative capabilities ingeneral contexts. However, their effectiveness in task-oriented dialogues(TOD), which requires not only response generation but also effective dialoguestate tracking (DST) within specific tasks and domains, remains lesssatisfying. In this work, we propose a novel approach FnCTOD for solving DSTwith LLMs through function calling. This method improves zero-shot DST,allowing adaptation to diverse domains without extensive data collection ormodel tuning. Our experimental results demonstrate that our approach achievesexceptional performance with both modestly sized open-source and alsoproprietary LLMs: with in-context prompting it enables various 7B or 13Bparameter models to surpass the previous state-of-the-art (SOTA) achieved byChatGPT, and improves ChatGPT's performance beating the SOTA by 5.6% averagejoint goal accuracy (JGA). Individual model results for GPT-3.5 and GPT-4 areboosted by 4.8% and 14%, respectively. We also show that by fine-tuning on asmall collection of diverse task-oriented dialogues, we can equip modest athttps://github.com/facebookresearch/FnCTOD</description><author>Zekun Li, Zhiyu Zoey Chen, Mike Ross, Patrick Huber, Seungwhan Moon, Zhaojiang Lin, Xin Luna Dong, Adithya Sagar, Xifeng Yan, Paul A. Crook</author><pubDate>Wed, 01 May 2024 18:58:35 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.10466v2</guid></item><item><title>TexSliders: Diffusion-Based Texture Editing in CLIP Space</title><link>http://arxiv.org/abs/2405.00672v1</link><description>Generative models have enabled intuitive image creation and manipulationusing natural language. In particular, diffusion models have recently shownremarkable results for natural image editing. In this work, we propose to applydiffusion techniques to edit textures, a specific class of images that are anessential part of 3D content creation pipelines. We analyze existing editingmethods and show that they are not directly applicable to textures, since theircommon underlying approach, manipulating attention maps, is unsuitable for thetexture domain. To address this, we propose a novel approach that insteadmanipulates CLIP image embeddings to condition the diffusion generation. Wedefine editing directions using simple text prompts (e.g., "aged wood" to "newwood") and map these to CLIP image embedding space using a texture prior, witha sampling-based approach that gives us identity-preserving directions in CLIPspace. To further improve identity preservation, we project these directions toa CLIP subspace that minimizes identity variations resulting from entangledtexture attributes. Our editing pipeline facilitates the creation of arbitrarysliders using natural language prompts only, with no ground-truth annotateddata necessary.</description><author>Julia Guerrero-Viu, Milos Hasan, Arthur Roullier, Midhun Harikumar, Yiwei Hu, Paul Guerrero, Diego Gutierrez, Belen Masia, Valentin Deschaintre</author><pubDate>Wed, 01 May 2024 18:57:21 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.00672v1</guid></item><item><title>Adapting Pretrained Networks for Image Quality Assessment on High Dynamic Range Displays</title><link>http://arxiv.org/abs/2405.00670v1</link><description>Conventional image quality metrics (IQMs), such as PSNR and SSIM, aredesigned for perceptually uniform gamma-encoded pixel values and cannot bedirectly applied to perceptually non-uniform linear high-dynamic-range (HDR)colors. Similarly, most of the available datasets consist ofstandard-dynamic-range (SDR) images collected in standard and possiblyuncontrolled viewing conditions. Popular pre-trained neural networks arelikewise intended for SDR inputs, restricting their direct application to HDRcontent. On the other hand, training HDR models from scratch is challenging dueto limited available HDR data. In this work, we explore more effectiveapproaches for training deep learning-based models for image quality assessment(IQA) on HDR data. We leverage networks pre-trained on SDR data (source domain)and re-target these models to HDR (target domain) with additional fine-tuningand domain adaptation. We validate our methods on the available HDR IQAdatasets, demonstrating that models trained with our combined recipe outperformprevious baselines, converge much quicker, and reliably generalize to HDRinputs.</description><author>Andrei Chubarau, Hyunjin Yoo, Tara Akhavan, James Clark</author><pubDate>Wed, 01 May 2024 18:57:12 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.00670v1</guid></item><item><title>RGB$\leftrightarrow$X: Image decomposition and synthesis using material- and lighting-aware diffusion models</title><link>http://arxiv.org/abs/2405.00666v1</link><description>The three areas of realistic forward rendering, per-pixel inverse rendering,and generative image synthesis may seem like separate and unrelated sub-fieldsof graphics and vision. However, recent work has demonstrated improvedestimation of per-pixel intrinsic channels (albedo, roughness, metallicity)based on a diffusion architecture; we call this the RGB$\rightarrow$X problem.We further show that the reverse problem of synthesizing realistic images givenintrinsic channels, X$\rightarrow$RGB, can also be addressed in a diffusionframework. Focusing on the image domain of interior scenes, we introduce an improveddiffusion model for RGB$\rightarrow$X, which also estimates lighting, as wellas the first diffusion X$\rightarrow$RGB model capable of synthesizingrealistic images from (full or partial) intrinsic channels. OurX$\rightarrow$RGB model explores a middle ground between traditional renderingand generative models: we can specify only certain appearance properties thatshould be followed, and give freedom to the model to hallucinate a plausibleversion of the rest. This flexibility makes it possible to use a mix of heterogeneous trainingdatasets, which differ in the available channels. We use multiple existingdatasets and extend them with our own synthetic and real data, resulting in amodel capable of extracting scene properties better than previous work and ofgenerating highly realistic images of interior scenes.</description><author>Zheng Zeng, Valentin Deschaintre, Iliyan Georgiev, Yannick Hold-Geoffroy, Yiwei Hu, Fujun Luan, Ling-Qi Yan, Miloš Hašan</author><pubDate>Wed, 01 May 2024 18:54:05 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.00666v1</guid></item><item><title>Is Bigger Edit Batch Size Always Better? -- An Empirical Study on Model Editing with Llama-3</title><link>http://arxiv.org/abs/2405.00664v1</link><description>This study presents a targeted model editing analysis focused on the latestlarge language model, Llama-3. We explore the efficacy of popular model editingtechniques - ROME, MEMIT, and EMMET, which are designed for precise layerinterventions. We identify the most effective layers for targeted edits throughan evaluation that encompasses up to 4096 edits across three distinctstrategies: sequential editing, batch editing, and a hybrid approach we call assequential-batch editing. Our findings indicate that increasing editbatch-sizes may degrade model performance more significantly than using smalleredit batches sequentially for equal number of edits. With this, we argue thatsequential model editing is an important component for scaling model editingmethods and future research should focus on methods that combine both batchedand sequential editing. This observation suggests a potential limitation incurrent model editing methods which push towards bigger edit batch sizes, andwe hope it paves way for future investigations into optimizing batch sizes andmodel editing performance.</description><author>Junsang Yoon, Akshat Gupta, Gopala Anumanchipalli</author><pubDate>Wed, 01 May 2024 18:50:37 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.00664v1</guid></item><item><title>No Representation, No Trust: Connecting Representation, Collapse, and Trust Issues in PPO</title><link>http://arxiv.org/abs/2405.00662v1</link><description>Reinforcement learning (RL) is inherently rife with non-stationarity sincethe states and rewards the agent observes during training depend on itschanging policy. Therefore, networks in deep RL must be capable of adapting tonew observations and fitting new targets. However, previous works have observedthat networks in off-policy deep value-based methods exhibit a decrease inrepresentation rank, often correlated with an inability to continue learning ora collapse in performance. Although this phenomenon has generally beenattributed to neural network learning under non-stationarity, it has beenoverlooked in on-policy policy optimization methods which are often thoughtcapable of training indefinitely. In this work, we empirically studyrepresentation dynamics in Proximal Policy Optimization (PPO) on the Atari andMuJoCo environments, revealing that PPO agents are also affected by featurerank deterioration and loss of plasticity. We show that this is aggravated withstronger non-stationarity, ultimately driving the actor's performance tocollapse, regardless of the performance of the critic. We draw connectionsbetween representation collapse, performance collapse, and trust region issuesin PPO, and present Proximal Feature Optimization (PFO), a novel auxiliaryloss, that along with other interventions shows that regularizing therepresentation dynamics improves the performance of PPO agents.</description><author>Skander Moalla, Andrea Miele, Razvan Pascanu, Caglar Gulcehre</author><pubDate>Wed, 01 May 2024 18:50:16 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.00662v1</guid></item><item><title>Bridging Dimensions: Confident Reachability for High-Dimensional Controllers</title><link>http://arxiv.org/abs/2311.04843v3</link><description>Autonomous systems are increasingly implemented using end-to-endlearning-based controllers. Such controllers make decisions that are executedon the real system, with images as one of the primary sensing modalities. Deepneural networks form a fundamental building block of such controllers.Unfortunately, the existing neural-network verification tools do not scale toinputs with thousands of dimensions -- especially when the individual inputs(such as pixels) are devoid of clear physical meaning. This paper takes a steptowards connecting exhaustive closed-loop verification with high-dimensionalcontrollers. Our key insight is that the behavior of a high-dimensionalcontroller can be approximated with several low-dimensional controllers. Tobalance the approximation accuracy and verifiability of our low-dimensionalcontrollers, we leverage the latest verification-aware knowledge distillation.Then, we inflate low-dimensional reachability results with statisticalapproximation errors, yielding a high-confidence reachability guarantee for thehigh-dimensional controller. We investigate two inflation techniques -- basedon trajectories and control actions -- both of which show convincingperformance in three OpenAI gym benchmarks.</description><author>Yuang Geng, Jake Baldauf, Souradeep Dutta, Chao Huang, Ivan Ruchkin</author><pubDate>Wed, 01 May 2024 18:46:59 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.04843v3</guid></item><item><title>NLU-STR at SemEval-2024 Task 1: Generative-based Augmentation and Encoder-based Scoring for Semantic Textual Relatedness</title><link>http://arxiv.org/abs/2405.00659v1</link><description>Semantic textual relatedness is a broader concept of semantic similarity. Itmeasures the extent to which two chunks of text convey similar meaning ortopics, or share related concepts or contexts. This notion of relatedness canbe applied in various applications, such as document clustering andsummarizing. SemRel-2024, a shared task in SemEval-2024, aims at reducing thegap in the semantic relatedness task by providing datasets for fourteenlanguages and dialects including Arabic. This paper reports on ourparticipation in Track A (Algerian and Moroccan dialects) and Track B (ModernStandard Arabic). A BERT-based model is augmented and fine-tuned for regressionscoring in supervised track (A), while BERT-based cosine similarity is employedfor unsupervised track (B). Our system ranked 1st in SemRel-2024 for MSA with aSpearman correlation score of 0.49. We ranked 5th for Moroccan and 12th forAlgerian with scores of 0.83 and 0.53, respectively.</description><author>Sanad Malaysha, Mustafa Jarrar, Mohammed Khalilia</author><pubDate>Wed, 01 May 2024 18:44:05 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.00659v1</guid></item><item><title>RST-LoRA: A Discourse-Aware Low-Rank Adaptation for Long Document Abstractive Summarization</title><link>http://arxiv.org/abs/2405.00657v1</link><description>For long document summarization, discourse structure is important to discernthe key content of the text and the differences in importance level betweensentences. Unfortunately, the integration of rhetorical structure theory (RST)into parameter-efficient fine-tuning strategies for long document summarizationremains unexplored. Therefore, this paper introduces RST-LoRA and proposes fourRST-aware variants to explicitly incorporate RST into the LoRA model. Ourempirical evaluation demonstrates that incorporating the type and uncertaintyof rhetorical relations can complementarily enhance the performance of LoRA insummarization tasks. Furthermore, the best-performing variant we introducedoutperforms the vanilla LoRA and full-parameter fine-tuning models, asconfirmed by multiple automatic and human evaluations, and even surpassesprevious state-of-the-art methods.</description><author>Dongqi Pu, Vera Demberg</author><pubDate>Wed, 01 May 2024 18:37:50 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.00657v1</guid></item><item><title>Closed-Loop Koopman Operator Approximation</title><link>http://arxiv.org/abs/2303.15318v3</link><description>This paper proposes a method to identify a Koopman model of afeedback-controlled system given a known controller. The Koopman operatorallows a nonlinear system to be rewritten as an infinite-dimensional linearsystem by viewing it in terms of an infinite set of lifting functions. Afinite-dimensional approximation of the Koopman operator can be identified fromdata by choosing a finite subset of lifting functions and solving a regressionproblem in the lifted space. Existing methods are designed to identifyopen-loop systems. However, it is impractical or impossible to run experimentson some systems, such as unstable systems, in an open-loop fashion. Theproposed method leverages the linearity of the Koopman operator, along withknowledge of the controller and the structure of the closed-loop system, tosimultaneously identify the closed-loop and plant systems. The advantages ofthe proposed closed-loop Koopman operator approximation method are demonstratedin simulation using a Duffing oscillator and experimentally using a rotaryinverted pendulum system. An open-source software implementation of theproposed method is publicly available, along with the experimental datasetgenerated for this paper.</description><author>Steven Dahdah, James Richard Forbes</author><pubDate>Wed, 01 May 2024 18:34:26 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2303.15318v3</guid></item><item><title>Grains of Saliency: Optimizing Saliency-based Training of Biometric Attack Detection Models</title><link>http://arxiv.org/abs/2405.00650v1</link><description>Incorporating human-perceptual intelligence into model training has shown toincrease the generalization capability of models in several difficult biometrictasks, such as presentation attack detection (PAD) and detection of syntheticsamples. After the initial collection phase, human visual saliency (e.g.,eye-tracking data, or handwritten annotations) can be integrated into modeltraining through attention mechanisms, augmented training samples, or throughhuman perception-related components of loss functions. Despite their successes,a vital, but seemingly neglected, aspect of any saliency-based training is thelevel of salience granularity (e.g., bounding boxes, single saliency maps, orsaliency aggregated from multiple subjects) necessary to find a balance betweenreaping the full benefits of human saliency and the cost of its collection. Inthis paper, we explore several different levels of salience granularity anddemonstrate that increased generalization capabilities of PAD and syntheticface detection can be achieved by using simple yet effective saliencypost-processing techniques across several different CNNs.</description><author>Colton R. Crum, Samuel Webster, Adam Czajka</author><pubDate>Wed, 01 May 2024 18:27:11 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.00650v1</guid></item><item><title>GRASP: A Rehearsal Policy for Efficient Online Continual Learning</title><link>http://arxiv.org/abs/2308.13646v2</link><description>Continual learning (CL) in deep neural networks (DNNs) involves incrementallyaccumulating knowledge in a DNN from a growing data stream. A major challengein CL is that non-stationary data streams cause catastrophic forgetting ofpreviously learned abilities. A popular solution is rehearsal: storing pastobservations in a buffer and then sampling the buffer to update the DNN.Uniform sampling in a class-balanced manner is highly effective, and bettersample selection policies have been elusive. Here, we propose a new sampleselection policy called GRASP that selects the most prototypical (easy) samplesfirst and then gradually selects less prototypical (harder) examples. GRASP haslittle additional compute or memory overhead compared to uniform selection,enabling it to scale to large datasets. Compared to 17 other rehearsalpolicies, GRASP achieves higher accuracy in CL experiments on ImageNet.Compared to uniform balanced sampling, GRASP achieves the same performance with40% fewer updates. We also show that GRASP is effective for CL on five textclassification datasets.</description><author>Md Yousuf Harun, Jhair Gallardo, Junyu Chen, Christopher Kanan</author><pubDate>Wed, 01 May 2024 18:25:52 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2308.13646v2</guid></item><item><title>Screening of BindingDB database ligands against EGFR, HER2, Estrogen, Progesterone and NF-kB receptors based on machine learning and molecular docking</title><link>http://arxiv.org/abs/2405.00647v1</link><description>Breast cancer, the second most prevalent cancer among women worldwide,necessitates the exploration of novel therapeutic approaches. To target thefour subgroups of breast cancer "hormone receptor-positive and HER2-negative,hormone receptor-positive and HER2-positive, hormone receptor-negative andHER2-positive, and hormone receptor-negative and HER2-negative" it is crucialto inhibit specific targets such as EGFR, HER2, ER, NF-kB, and PR. In this study, we evaluated various methods for binary and multiclassclassification. Among them, the GA-SVM-SVM:GA-SVM-SVM model was selected withan accuracy of 0.74, an F1-score of 0.73, and an AUC of 0.94 for virtualscreening of ligands from the BindingDB database. This model successfullyidentified 4454, 803, 438, and 378 ligands with over 90% precision in bothactive/inactive and target prediction for the classes of EGFR+HER2, ER, NF-kB,and PR, respectively, from the BindingDB database. Based on to the selectedligands, we created a dendrogram that categorizes different ligands based ontheir targets. This dendrogram aims to facilitate the exploration of chemicalspace for various therapeutic targets. Ligands that surpassed a 90% threshold in the product of activity probabilityand correct target selection probability were chosen for further investigationusing molecular docking. The binding energy range for these ligands againsttheir respective targets was calculated to be between -15 and -5 kcal/mol.Finally, based on general and common rules in medicinal chemistry, we selected2, 3, 3, and 8 new ligands with high priority for further studies in theEGFR+HER2, ER, NF-kB, and PR classes, respectively.</description><author>Parham Rezaee, Shahab Rezaee, Malik Maaza, Seyed Shahriar Arab</author><pubDate>Wed, 01 May 2024 18:24:20 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.00647v1</guid></item><item><title>Learning to Compose: Improving Object Centric Learning by Injecting Compositionality</title><link>http://arxiv.org/abs/2405.00646v1</link><description>Learning compositional representation is a key aspect of object-centriclearning as it enables flexible systematic generalization and supports complexvisual reasoning. However, most of the existing approaches rely onauto-encoding objective, while the compositionality is implicitly imposed bythe architectural or algorithmic bias in the encoder. This misalignment betweenauto-encoding objective and learning compositionality often results in failureof capturing meaningful object representations. In this study, we propose anovel objective that explicitly encourages compositionality of therepresentations. Built upon the existing object-centric learning framework(e.g., slot attention), our method incorporates additional constraints that anarbitrary mixture of object representations from two images should be valid bymaximizing the likelihood of the composite data. We demonstrate thatincorporating our objective to the existing framework consistently improves theobjective-centric learning and enhances the robustness to the architecturalchoices.</description><author>Whie Jung, Jaehoon Yoo, Sungjin Ahn, Seunghoon Hong</author><pubDate>Wed, 01 May 2024 18:21:36 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.00646v1</guid></item><item><title>Gradient-based Automatic Per-Weight Mixed Precision Quantization for Neural Networks On-Chip</title><link>http://arxiv.org/abs/2405.00645v1</link><description>Model size and inference speed at deployment time, are major challenges inmany deep learning applications. A promising strategy to overcome thesechallenges is quantization. However, a straightforward uniform quantization tovery low precision can result in significant accuracy loss. Mixed-precisionquantization, based on the idea that certain parts of the network canaccommodate lower precision without compromising performance compared to otherparts, offers a potential solution. In this work, we present High GranularityQuantization (HGQ), an innovative quantization-aware training method designedto fine-tune the per-weight and per-activation precision in an automatic wayfor ultra-low latency and low power neural networks which are to be deployed onFPGAs. We demonstrate that HGQ can outperform existing methods by a substantialmargin, achieving resource reduction by up to a factor of 20 and latencyimprovement by a factor of 5 while preserving accuracy.</description><author>Chang Sun, Thea K. Årrestad, Vladimir Loncar, Jennifer Ngadiuba, Maria Spiropulu</author><pubDate>Wed, 01 May 2024 18:18:46 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.00645v1</guid></item><item><title>ConstrainedZero: Chance-Constrained POMDP Planning using Learned Probabilistic Failure Surrogates and Adaptive Safety Constraints</title><link>http://arxiv.org/abs/2405.00644v1</link><description>To plan safely in uncertain environments, agents must balance utility withsafety constraints. Safe planning problems can be modeled as achance-constrained partially observable Markov decision process (CC-POMDP) andsolutions often use expensive rollouts or heuristics to estimate the optimalvalue and action-selection policy. This work introduces the ConstrainedZeropolicy iteration algorithm that solves CC-POMDPs in belief space by learningneural network approximations of the optimal value and policy with anadditional network head that estimates the failure probability given a belief.This failure probability guides safe action selection during online Monte Carlotree search (MCTS). To avoid overemphasizing search based on the failureestimates, we introduce $\Delta$-MCTS, which uses adaptive conformal inferenceto update the failure threshold during planning. The approach is tested on asafety-critical POMDP benchmark, an aircraft collision avoidance system, andthe sustainability problem of safe CO$_2$ storage. Results show that byseparating safety constraints from the objective we can achieve a target levelof safety without optimizing the balance between rewards and costs.</description><author>Robert J. Moss, Arec Jamgochian, Johannes Fischer, Anthony Corso, Mykel J. Kochenderfer</author><pubDate>Wed, 01 May 2024 18:17:22 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.00644v1</guid></item><item><title>Capabilities of Gemini Models in Medicine</title><link>http://arxiv.org/abs/2404.18416v2</link><description>Excellence in a wide variety of medical applications poses considerablechallenges for AI, requiring advanced reasoning, access to up-to-date medicalknowledge and understanding of complex multimodal data. Gemini models, withstrong general capabilities in multimodal and long-context reasoning, offerexciting possibilities in medicine. Building on these core strengths of Gemini,we introduce Med-Gemini, a family of highly capable multimodal models that arespecialized in medicine with the ability to seamlessly use web search, and thatcan be efficiently tailored to novel modalities using custom encoders. Weevaluate Med-Gemini on 14 medical benchmarks, establishing new state-of-the-art(SoTA) performance on 10 of them, and surpass the GPT-4 model family on everybenchmark where a direct comparison is viable, often by a wide margin. On thepopular MedQA (USMLE) benchmark, our best-performing Med-Gemini model achievesSoTA performance of 91.1% accuracy, using a novel uncertainty-guided searchstrategy. On 7 multimodal benchmarks including NEJM Image Challenges and MMMU(health &amp; medicine), Med-Gemini improves over GPT-4V by an average relativemargin of 44.5%. We demonstrate the effectiveness of Med-Gemini's long-contextcapabilities through SoTA performance on a needle-in-a-haystack retrieval taskfrom long de-identified health records and medical video question answering,surpassing prior bespoke methods using only in-context learning. Finally,Med-Gemini's performance suggests real-world utility by surpassing humanexperts on tasks such as medical text summarization, alongside demonstrationsof promising potential for multimodal medical dialogue, medical research andeducation. Taken together, our results offer compelling evidence forMed-Gemini's potential, although further rigorous evaluation will be crucialbefore real-world deployment in this safety-critical domain.</description><author>Khaled Saab, Tao Tu, Wei-Hung Weng, Ryutaro Tanno, David Stutz, Ellery Wulczyn, Fan Zhang, Tim Strother, Chunjong Park, Elahe Vedadi, Juanma Zambrano Chaves, Szu-Yeu Hu, Mike Schaekermann, Aishwarya Kamath, Yong Cheng, David G. T. Barrett, Cathy Cheung, Basil Mustafa, Anil Palepu, Daniel McDuff, Le Hou, Tomer Golany, Luyang Liu, Jean-baptiste Alayrac, Neil Houlsby, Nenad Tomasev, Jan Freyberg, Charles Lau, Jonas Kemp, Jeremy Lai, Shekoofeh Azizi, Kimberly Kanada, SiWai Man, Kavita Kulkarni, Ruoxi Sun, Siamak Shakeri, Luheng He, Ben Caine, Albert Webson, Natasha Latysheva, Melvin Johnson, Philip Mansfield, Jian Lu, Ehud Rivlin, Jesper Anderson, Bradley Green, Renee Wong, Jonathan Krause, Jonathon Shlens, Ewa Dominowska, S. M. Ali Eslami, Katherine Chou, Claire Cui, Oriol Vinyals, Koray Kavu</author><pubDate>Wed, 01 May 2024 18:12:10 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.18416v2</guid></item><item><title>From Empirical Observations to Universality: Dynamics of Deep Learning with Inputs Built on Gaussian mixture</title><link>http://arxiv.org/abs/2405.00642v1</link><description>This study broadens the scope of theoretical frameworks in deep learning bydelving into the dynamics of neural networks with inputs that demonstrate thestructural characteristics to Gaussian Mixture (GM). We analyzed how thedynamics of neural networks under GM-structured inputs diverge from thepredictions of conventional theories based on simple Gaussian structures. Arevelation of our work is the observed convergence of neural network dynamicstowards conventional theory even with standardized GM inputs, highlighting anunexpected universality. We found that standardization, especially inconjunction with certain nonlinear functions, plays a critical role in thisphenomena. Consequently, despite the complex and varied nature of GMdistributions, we demonstrate that neural networks exhibit asymptotic behaviorsin line with predictions under simple Gaussian frameworks.</description><author>Jaeyong Bae, Hawoong Jeong</author><pubDate>Wed, 01 May 2024 18:10:55 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.00642v1</guid></item><item><title>Robustness of graph embedding methods for community detection</title><link>http://arxiv.org/abs/2405.00636v1</link><description>This study investigates the robustness of graph embedding methods forcommunity detection in the face of network perturbations, specifically edgedeletions. Graph embedding techniques, which represent nodes as low-dimensionalvectors, are widely used for various graph machine learning tasks due to theirability to capture structural properties of networks effectively. However, theimpact of perturbations on the performance of these methods remains relativelyunderstudied. The research considers state-of-the-art graph embedding methodsfrom two families: matrix factorization (e.g., LE, LLE, HOPE, M-NMF) and randomwalk-based (e.g., DeepWalk, LINE, node2vec). Through experiments conducted onboth synthetic and real-world networks, the study reveals varying degrees ofrobustness within each family of graph embedding methods. The robustness isfound to be influenced by factors such as network size, initial communitypartition strength, and the type of perturbation. Notably, node2vec and LLEconsistently demonstrate higher robustness for community detection acrossdifferent scenarios, including networks with degree and community sizeheterogeneity. These findings highlight the importance of selecting anappropriate graph embedding method based on the specific characteristics of thenetwork and the task at hand, particularly in scenarios where robustness toperturbations is crucial.</description><author>Zhi-Feng Wei, Pablo Moriano, Ramakrishnan Kannan</author><pubDate>Wed, 01 May 2024 18:04:20 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.00636v1</guid></item><item><title>When Quantization Affects Confidence of Large Language Models?</title><link>http://arxiv.org/abs/2405.00632v1</link><description>Recent studies introduced effective compression techniques for Large LanguageModels (LLMs) via post-training quantization or low-bit weight representation.Although quantized weights offer storage efficiency and allow for fasterinference, existing works have indicated that quantization might compromiseperformance and exacerbate biases in LLMs. This study investigates theconfidence and calibration of quantized models, considering factors such aslanguage model type and scale as contributors to quantization loss. Firstly, wereveal that quantization with GPTQ to 4-bit results in a decrease in confidenceregarding true labels, with varying impacts observed among different languagemodels. Secondly, we observe fluctuations in the impact on confidence acrossdifferent scales. Finally, we propose an explanation for quantization lossbased on confidence levels, indicating that quantization disproportionatelyaffects samples where the full model exhibited low confidence levels in thefirst place.</description><author>Irina Proskurina, Luc Brun, Guillaume Metzler, Julien Velcin</author><pubDate>Wed, 01 May 2024 17:58:28 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.00632v1</guid></item><item><title>Deep Metric Learning-Based Out-of-Distribution Detection with Synthetic Outlier Exposure</title><link>http://arxiv.org/abs/2405.00631v1</link><description>In this paper, we present a novel approach that combines deep metric learningand synthetic data generation using diffusion models for out-of-distribution(OOD) detection. One popular approach for OOD detection is outlier exposure,where models are trained using a mixture of in-distribution (ID) samples and``seen" OOD samples. For the OOD samples, the model is trained to minimize theKL divergence between the output probability and the uniform distribution whilecorrectly classifying the in-distribution (ID) data. In this paper, we proposea label-mixup approach to generate synthetic OOD data using Denoising DiffusionProbabilistic Models (DDPMs). Additionally, we explore recent advancements inmetric learning to train our models. In the experiments, we found that metric learning-based loss functionsperform better than the softmax. Furthermore, the baseline models (includingsoftmax, and metric learning) show a significant improvement when trained withthe generated OOD data. Our approach outperforms strong baselines inconventional OOD detection metrics.</description><author>Assefa Seyoum Wahd</author><pubDate>Wed, 01 May 2024 17:58:22 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.00631v1</guid></item><item><title>Depth Priors in Removal Neural Radiance Fields</title><link>http://arxiv.org/abs/2405.00630v1</link><description>Neural Radiance Fields (NeRF) have shown impressive results in 3Dreconstruction and generating novel views. A key challenge within NeRF is theediting of reconstructed scenes, such as object removal, which requiresmaintaining consistency across multiple views and ensuring high-qualitysynthesised perspectives. Previous studies have incorporated depth priors,typically from LiDAR or sparse depth measurements provided by COLMAP, toimprove the performance of object removal in NeRF. However, these methods areeither costly or time-consuming. In this paper, we propose a novel approachthat integrates monocular depth estimates with NeRF-based object removal modelsto significantly reduce time consumption and enhance the robustness and qualityof scene generation and object removal. We conducted a thorough evaluation ofCOLMAP's dense depth reconstruction on the KITTI dataset to verify its accuracyin depth map generation. Our findings suggest that COLMAP can serve as aneffective alternative to a ground truth depth map where such information ismissing or costly to obtain. Additionally, we integrated various monoculardepth estimation methods into the removal NeRF model, i.e., SpinNeRF, to assesstheir capacity to improve object removal performance. Our experimental resultshighlight the potential of monocular depth estimation to substantially improveNeRF applications.</description><author>Zhihao Guo, Peng Wang</author><pubDate>Wed, 01 May 2024 17:55:08 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.00630v1</guid></item><item><title>HUGO -- Highlighting Unseen Grid Options: Combining Deep Reinforcement Learning with a Heuristic Target Topology Approach</title><link>http://arxiv.org/abs/2405.00629v1</link><description>With the growth of Renewable Energy (RE) generation, the operation of powergrids has become increasingly complex. One solution is automated gridoperation, where Deep Reinforcement Learning (DRL) has repeatedly shownsignificant potential in Learning to Run a Power Network (L2RPN) challenges.However, only individual actions at the substation level have been subjected totopology optimization by most existing DRL algorithms. In contrast, we proposea more holistic approach in this paper by proposing specific Target Topologies(TTs) as actions. These topologies are selected based on their robustness. Aspart of this paper, we present a search algorithm to find the TTs and upgradeour previously developed DRL agent CurriculumAgent (CAgent) to a novel topologyagent. We compare the upgrade to the previous CAgent agent and can increasetheir scores significantly by 10%. Further, we achieve a 25% better mediansurvival with our TTs included. Later analysis shows that almost all TTs areclose to the base topology, explaining their robustness.</description><author>Malte Lehna, Clara Holzhüter, Sven Tomforde, Christoph Scholz</author><pubDate>Wed, 01 May 2024 17:54:12 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.00629v1</guid></item><item><title>NeRF as a Non-Distant Environment Emitter in Physics-based Inverse Rendering</title><link>http://arxiv.org/abs/2402.04829v2</link><description>Physics-based inverse rendering enables joint optimization of shape,material, and lighting based on captured 2D images. To ensure accuratereconstruction, using a light model that closely resembles the capturedenvironment is essential. Although the widely adopted distant environmentallighting model is adequate in many cases, we demonstrate that its inability tocapture spatially varying illumination can lead to inaccurate reconstructionsin many real-world inverse rendering scenarios. To address this limitation, weincorporate NeRF as a non-distant environment emitter into the inverserendering pipeline. Additionally, we introduce an emitter importance samplingtechnique for NeRF to reduce the rendering variance. Through comparisons onboth real and synthetic datasets, our results demonstrate that our NeRF-basedemitter offers a more precise representation of scene lighting, therebyimproving the accuracy of inverse rendering.</description><author>Jingwang Ling, Ruihan Yu, Feng Xu, Chun Du, Shuang Zhao</author><pubDate>Wed, 01 May 2024 17:50:48 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.04829v2</guid></item><item><title>U-Nets as Belief Propagation: Efficient Classification, Denoising, and Diffusion in Generative Hierarchical Models</title><link>http://arxiv.org/abs/2404.18444v2</link><description>U-Nets are among the most widely used architectures in computer vision,renowned for their exceptional performance in applications such as imagesegmentation, denoising, and diffusion modeling. However, a theoreticalexplanation of the U-Net architecture design has not yet been fullyestablished. This paper introduces a novel interpretation of the U-Net architecture bystudying certain generative hierarchical models, which are tree-structuredgraphical models extensively utilized in both language and image domains. Withtheir encoder-decoder structure, long skip connections, and pooling andup-sampling layers, we demonstrate how U-Nets can naturally implement thebelief propagation denoising algorithm in such generative hierarchical models,thereby efficiently approximating the denoising functions. This leads to anefficient sample complexity bound for learning the denoising function usingU-Nets within these models. Additionally, we discuss the broader implicationsof these findings for diffusion models in generative hierarchical models. Wealso demonstrate that the conventional architecture of convolutional neuralnetworks (ConvNets) is ideally suited for classification tasks within thesemodels. This offers a unified view of the roles of ConvNets and U-Nets,highlighting the versatility of generative hierarchical models in modelingcomplex data distributions across language and image domains.</description><author>Song Mei</author><pubDate>Wed, 01 May 2024 17:49:57 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.18444v2</guid></item><item><title>Koopman-based Deep Learning for Nonlinear System Estimation</title><link>http://arxiv.org/abs/2405.00627v1</link><description>Nonlinear differential equations are encountered as models of fluid flow,spiking neurons, and many other systems of interest in the real world. Commonfeatures of these systems are that their behaviors are difficult to describeexactly and invariably unmodeled dynamics present challenges in making precisepredictions. In many cases the models exhibit extremely complicated behaviordue to bifurcations and chaotic regimes. In this paper, we present a noveldata-driven linear estimator that uses Koopman operator theory to extractfinite-dimensional representations of complex nonlinear systems. The extractedmodel is used together with a deep reinforcement learning network that learnsthe optimal stepwise actions to predict future states of the original nonlinearsystem. Our estimator is also adaptive to a diffeomorphic transformation of thenonlinear system which enables transfer learning to compute state estimates ofthe transformed system without relearning from scratch.</description><author>Zexin Sun, Mingyu Chen, John Baillieul</author><pubDate>Wed, 01 May 2024 17:49:54 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.00627v1</guid></item><item><title>Queue-based Eco-Driving at Roundabouts with Reinforcement Learning</title><link>http://arxiv.org/abs/2405.00625v1</link><description>We address eco-driving at roundabouts in mixed traffic to enhance trafficflow and traffic efficiency in urban areas. The aim is to proactively optimizespeed of automated or non-automated connected vehicles (CVs), ensuring both anefficient approach and smooth entry into roundabouts. We incorporate thetraffic situation ahead, i.e. preceding vehicles and waiting queues. Further,we develop two approaches: a rule-based and an Reinforcement Learning (RL)based eco-driving system, with both using the approach link and informationfrom conflicting CVs for speed optimization. A fair comparison of rule-basedand RL-based approaches is performed to explore RL as a viable alternative toclassical optimization. Results show that both approaches outperform thebaseline. Improvements significantly increase with growing traffic volumes,leading to best results on average being obtained at high volumes. Nearcapacity, performance deteriorates, indicating limited applicability atcapacity limits. Examining different CV penetration rates, a decline inperformance is observed, but with substantial results still being achieved atlower CV rates. RL agents can discover effective policies for speedoptimization in dynamic roundabout settings, but they do not offer asubstantial advantage over classical approaches, especially at higher trafficvolumes or lower CV penetration rates.</description><author>Anna-Lena Schlamp, Werner Huber, Stefanie Schmidtner</author><pubDate>Wed, 01 May 2024 17:48:28 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.00625v1</guid></item><item><title>Measuring and Controlling Instruction (In)Stability in Language Model Dialogs</title><link>http://arxiv.org/abs/2402.10962v3</link><description>System-prompting is a standard tool for customizing language-model chatbots,enabling them to follow a specific instruction. An implicit assumption in theuse of system prompts is that they will be stable, so the chatbot will continueto generate text according to the stipulated instructions for the duration of aconversation. We propose a quantitative benchmark to test this assumption,evaluating instruction stability via self-chats between two instructedchatbots. Testing popular models like LLaMA2-chat-70B and GPT-3.5, we reveal asignificant instruction drift within eight rounds of conversations. Anempirical and theoretical analysis of this phenomenon suggests the transformerattention mechanism plays a role, due to attention decay over long exchanges.To combat attention decay and instruction drift, we propose a lightweightmethod called split-softmax, which compares favorably against two strongbaselines.</description><author>Kenneth Li, Tianle Liu, Naomi Bashkansky, David Bau, Fernanda Viégas, Hanspeter Pfister, Martin Wattenberg</author><pubDate>Wed, 01 May 2024 17:47:42 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.10962v3</guid></item><item><title>Prediction without Preclusion: Recourse Verification with Reachable Sets</title><link>http://arxiv.org/abs/2308.12820v2</link><description>Machine learning models are often used to decide who receives a loan, a jobinterview, or a public benefit. Models in such settings use features withoutconsidering their actionability. As a result, they can assign predictions thatare fixed $-$ meaning that individuals who are denied loans and interviews are,in fact, precluded from access to credit and employment. In this work, weintroduce a procedure called recourse verification to test if a model assignsfixed predictions to its decision subjects. We propose a model-agnosticapproach for recourse verification with reachable sets $-$ i.e., the set of allpoints that a person can reach through their actions in feature space. Wedevelop methods to construct reachable sets for discrete feature spaces, whichcan certify the responsiveness of any model by simply querying its predictions.We conduct a comprehensive empirical study on the infeasibility of recourse ondatasets from consumer finance. Our results highlight how models caninadvertently preclude access by assigning fixed predictions and underscore theneed to account for actionability in model development.</description><author>Avni Kothari, Bogdan Kulynych, Tsui-Wei Weng, Berk Ustun</author><pubDate>Wed, 01 May 2024 17:43:58 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2308.12820v2</guid></item><item><title>"I'm Not Sure, But...": Examining the Impact of Large Language Models' Uncertainty Expression on User Reliance and Trust</title><link>http://arxiv.org/abs/2405.00623v1</link><description>Widely deployed large language models (LLMs) can produce convincing yetincorrect outputs, potentially misleading users who may rely on them as if theywere correct. To reduce such overreliance, there have been calls for LLMs tocommunicate their uncertainty to end users. However, there has been littleempirical work examining how users perceive and act upon LLMs' expressions ofuncertainty. We explore this question through a large-scale, pre-registered,human-subject experiment (N=404) in which participants answer medical questionswith or without access to responses from a fictional LLM-infused search engine.Using both behavioral and self-reported measures, we examine how differentnatural language expressions of uncertainty impact participants' reliance,trust, and overall task performance. We find that first-person expressions(e.g., "I'm not sure, but...") decrease participants' confidence in the systemand tendency to agree with the system's answers, while increasing participants'accuracy. An exploratory analysis suggests that this increase can be attributedto reduced (but not fully eliminated) overreliance on incorrect answers. Whilewe observe similar effects for uncertainty expressed from a general perspective(e.g., "It's not clear, but..."), these effects are weaker and notstatistically significant. Our findings suggest that using natural languageexpressions of uncertainty may be an effective approach for reducingoverreliance on LLMs, but that the precise language used matters. Thishighlights the importance of user testing before deploying LLMs at scale.</description><author>Sunnie S. Y. Kim, Q. Vera Liao, Mihaela Vorvoreanu, Stephanie Ballard, Jennifer Wortman Vaughan</author><pubDate>Wed, 01 May 2024 17:43:55 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.00623v1</guid></item><item><title>Causal Evaluation of Language Models</title><link>http://arxiv.org/abs/2405.00622v1</link><description>Causal reasoning is viewed as crucial for achieving human-level machineintelligence. Recent advances in language models have expanded the horizons ofartificial intelligence across various domains, sparking inquiries into theirpotential for causal reasoning. In this work, we introduce Causal evaluation ofLanguage Models (CaLM), which, to the best of our knowledge, is the firstcomprehensive benchmark for evaluating the causal reasoning capabilities oflanguage models. First, we propose the CaLM framework, which establishes afoundational taxonomy consisting of four modules: causal target (i.e., what toevaluate), adaptation (i.e., how to obtain the results), metric (i.e., how tomeasure the results), and error (i.e., how to analyze the bad results). Thistaxonomy defines a broad evaluation design space while systematically selectingcriteria and priorities. Second, we compose the CaLM dataset, comprising126,334 data samples, to provide curated sets of causal targets, adaptations,metrics, and errors, offering extensive coverage for diverse research pursuits.Third, we conduct an extensive evaluation of 28 leading language models on acore set of 92 causal targets, 9 adaptations, 7 metrics, and 12 error types.Fourth, we perform detailed analyses of the evaluation results across variousdimensions (e.g., adaptation, scale). Fifth, we present 50 high-level empiricalfindings across 9 dimensions (e.g., model), providing valuable guidance forfuture language model development. Finally, we develop a multifaceted platform,including a website, leaderboards, datasets, and toolkits, to support scalableand adaptable assessments. We envision CaLM as an ever-evolving benchmark forthe community, systematically updated with new causal targets, adaptations,models, metrics, and error types to reflect ongoing research advancements.Project website is at https://opencausalab.github.io/CaLM.</description><author>Sirui Chen, Bo Peng, Meiqi Chen, Ruiqi Wang, Mengying Xu, Xingyu Zeng, Rui Zhao, Shengjie Zhao, Yu Qiao, Chaochao Lu</author><pubDate>Wed, 01 May 2024 17:43:21 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.00622v1</guid></item><item><title>Lane Segmentation Refinement with Diffusion Models</title><link>http://arxiv.org/abs/2405.00620v1</link><description>The lane graph is a key component for building high-definition (HD) maps andcrucial for downstream tasks such as autonomous driving or navigation planning.Previously, He et al. (2022) explored the extraction of the lane-level graphfrom aerial imagery utilizing a segmentation based approach. However,segmentation networks struggle to achieve perfect segmentation masks resultingin inaccurate lane graph extraction. We explore additional enhancements torefine this segmentation-based approach and extend it with a diffusionprobabilistic model (DPM) component. This combination further improves the GEOF1 and TOPO F1 scores, which are crucial indicators of the quality of a lanegraph, in the undirected graph in non-intersection areas. We conductexperiments on a publicly available dataset, demonstrating that our methodoutperforms the previous approach, particularly in enhancing the connectivityof such a graph, as measured by the TOPO F1 score. Moreover, we performablation studies on the individual components of our method to understand theircontribution and evaluate their effectiveness.</description><author>Antonio Ruiz, Andrew Melnik, Dong Wang, Helge Ritter</author><pubDate>Wed, 01 May 2024 17:40:15 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.00620v1</guid></item><item><title>Multigroup Robustness</title><link>http://arxiv.org/abs/2405.00614v1</link><description>To address the shortcomings of real-world datasets, robust learningalgorithms have been designed to overcome arbitrary and indiscriminate datacorruption. However, practical processes of gathering data may lead to patternsof data corruption that are localized to specific partitions of the trainingdataset. Motivated by critical applications where the learned model is deployedto make predictions about people from a rich collection of overlappingsubpopulations, we initiate the study of multigroup robust algorithms whoserobustness guarantees for each subpopulation only degrade with the amount ofdata corruption inside that subpopulation. When the data corruption is notdistributed uniformly over subpopulations, our algorithms provide moremeaningful robustness guarantees than standard guarantees that are oblivious tohow the data corruption and the affected subpopulations are related. Ourtechniques establish a new connection between multigroup fairness androbustness.</description><author>Lunjia Hu, Charlotte Peale, Judy Hanwen Shen</author><pubDate>Wed, 01 May 2024 17:35:04 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.00614v1</guid></item><item><title>Addressing Topic Granularity and Hallucination in Large Language Models for Topic Modelling</title><link>http://arxiv.org/abs/2405.00611v1</link><description>Large language models (LLMs) with their strong zero-shot topic extractioncapabilities offer an alternative to probabilistic topic modelling andclosed-set topic classification approaches. As zero-shot topic extractors, LLMsare expected to understand human instructions to generate relevant andnon-hallucinated topics based on the given documents. However, LLM-based topicmodelling approaches often face difficulties in generating topics withadherence to granularity as specified in human instructions, often resulting inmany near-duplicate topics. Furthermore, methods for addressing hallucinatedtopics generated by LLMs have not yet been investigated. In this paper, wefocus on addressing the issues of topic granularity and hallucinations forbetter LLM-based topic modelling. To this end, we introduce a novel approachthat leverages Direct Preference Optimisation (DPO) to fine-tune open-sourceLLMs, such as Mistral-7B. Our approach does not rely on traditional humanannotation to rank preferred answers but employs a reconstruction pipeline tomodify raw topics generated by LLMs, thus enabling a fast and efficienttraining and inference framework. Comparative experiments show that ourfine-tuning approach not only significantly improves the LLM's capability toproduce more coherent, relevant, and precise topics, but also reduces thenumber of hallucinated topics.</description><author>Yida Mu, Peizhen Bai, Kalina Bontcheva, Xingyi Song</author><pubDate>Wed, 01 May 2024 17:32:07 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.00611v1</guid></item><item><title>GenCast: Diffusion-based ensemble forecasting for medium-range weather</title><link>http://arxiv.org/abs/2312.15796v2</link><description>Weather forecasts are fundamentally uncertain, so predicting the range ofprobable weather scenarios is crucial for important decisions, from warning thepublic about hazardous weather, to planning renewable energy use. Here, weintroduce GenCast, a probabilistic weather model with greater skill and speedthan the top operational medium-range weather forecast in the world, theEuropean Centre for Medium-Range Forecasts (ECMWF)'s ensemble forecast, ENS.Unlike traditional approaches, which are based on numerical weather prediction(NWP), GenCast is a machine learning weather prediction (MLWP) method, trainedon decades of reanalysis data. GenCast generates an ensemble of stochastic15-day global forecasts, at 12-hour steps and 0.25 degree latitude-longituderesolution, for over 80 surface and atmospheric variables, in 8 minutes. It hasgreater skill than ENS on 97.4% of 1320 targets we evaluated, and betterpredicts extreme weather, tropical cyclones, and wind power production. Thiswork helps open the next chapter in operational weather forecasting, wherecritical weather-dependent decisions are made with greater accuracy andefficiency.</description><author>Ilan Price, Alvaro Sanchez-Gonzalez, Ferran Alet, Tom R. Andersson, Andrew El-Kadi, Dominic Masters, Timo Ewalds, Jacklynn Stott, Shakir Mohamed, Peter Battaglia, Remi Lam, Matthew Willson</author><pubDate>Wed, 01 May 2024 17:30:43 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.15796v2</guid></item><item><title>Reverse Training to Nurse the Reversal Curse</title><link>http://arxiv.org/abs/2403.13799v2</link><description>Large language models (LLMs) have a surprising failure: when trained on "Ahas a feature B", they do not generalize to "B is a feature of A", which istermed the Reversal Curse. Even when training with trillions of tokens thisissue still appears due to Zipf's law - hence even if we train on the entireinternet. This work proposes an alternative training scheme, called reversetraining, whereby all words are used twice, doubling the amount of availabletokens. The LLM is trained in both forward and reverse directions by reversingthe training strings while preserving (i.e., not reversing) chosen substrings,such as entities. We show that data-matched reverse-trained models providesuperior performance to standard models on standard tasks, and compute-matchedreverse-trained models provide far superior performance on reversal tasks,helping resolve the reversal curse issue.</description><author>Olga Golovneva, Zeyuan Allen-Zhu, Jason Weston, Sainbayar Sukhbaatar</author><pubDate>Wed, 01 May 2024 17:25:58 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.13799v2</guid></item><item><title>PPG-to-ECG Signal Translation for Continuous Atrial Fibrillation Detection via Attention-based Deep State-Space Modeling</title><link>http://arxiv.org/abs/2309.15375v3</link><description>Photoplethysmography (PPG) is a cost-effective and non-invasive techniquethat utilizes optical methods to measure cardiac physiology. PPG has becomeincreasingly popular in health monitoring and is used in various commercial andclinical wearable devices. Compared to electrocardiography (ECG), PPG does notprovide substantial clinical diagnostic value, despite the strong correlationbetween the two. Here, we propose a subject-independent attention-based deepstate-space model (ADSSM) to translate PPG signals to corresponding ECGwaveforms. The model is not only robust to noise but also data-efficient byincorporating probabilistic prior knowledge. To evaluate our approach, 55subjects' data from the MIMIC-III database were used in their original form,and then modified with noise, mimicking real-world scenarios. Our approach wasproven effective as evidenced by the PR-AUC of 0.986 achieved when inputtingthe translated ECG signals into an existing atrial fibrillation (AFib)detector. ADSSM enables the integration of ECG's extensive knowledge base andPPG's continuous measurement for early diagnosis of cardiovascular disease.</description><author>Khuong Vo, Mostafa El-Khamy, Yoojin Choi</author><pubDate>Wed, 01 May 2024 17:22:34 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2309.15375v3</guid></item><item><title>A Preprocessing and Evaluation Toolbox for Trajectory Prediction Research on the Drone Datasets</title><link>http://arxiv.org/abs/2405.00604v1</link><description>The availability of high-quality datasets is crucial for the development ofbehavior prediction algorithms in autonomous vehicles. This paper highlightsthe need for standardizing the use of certain datasets for motion forecastingresearch to simplify comparative analysis and proposes a set of tools andpractices to achieve this. Drawing on extensive experience and a comprehensivereview of current literature, we summarize our proposals for preprocessing,visualizing, and evaluation in the form of an open-sourced toolbox designed forresearchers working on trajectory prediction problems. The clear specificationof necessary preprocessing steps and evaluation metrics is intended toalleviate development efforts and facilitate the comparison of results acrossdifferent studies. The toolbox is available at:https://github.com/westny/dronalize.</description><author>Theodor Westny, Björn Olofsson, Erik Frisk</author><pubDate>Wed, 01 May 2024 17:17:39 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.00604v1</guid></item><item><title>Investigating Automatic Scoring and Feedback using Large Language Models</title><link>http://arxiv.org/abs/2405.00602v1</link><description>Automatic grading and feedback have been long studied using traditionalmachine learning and deep learning techniques using language models. With therecent accessibility to high performing large language models (LLMs) likeLLaMA-2, there is an opportunity to investigate the use of these LLMs forautomatic grading and feedback generation. Despite the increase in performance,LLMs require significant computational resources for fine-tuning and additionalspecific adjustments to enhance their performance for such tasks. To addressthese issues, Parameter Efficient Fine-tuning (PEFT) methods, such as LoRA andQLoRA, have been adopted to decrease memory and computational requirements inmodel fine-tuning. This paper explores the efficacy of PEFT-based quantizedmodels, employing classification or regression head, to fine-tune LLMs forautomatically assigning continuous numerical grades to short answers andessays, as well as generating corresponding feedback. We conducted experimentson both proprietary and open-source datasets for our tasks. The results showthat prediction of grade scores via finetuned LLMs are highly accurate,achieving less than 3% error in grade percentage on average. For providinggraded feedback fine-tuned 4-bit quantized LLaMA-2 13B models outperformcompetitive base models and achieve high similarity with subject matter expertfeedback in terms of high BLEU and ROUGE scores and qualitatively in terms offeedback. The findings from this study provide important insights into theimpacts of the emerging capabilities of using quantization approaches tofine-tune LLMs for various downstream tasks, such as automatic short answerscoring and feedback generation at comparatively lower costs and latency.</description><author>Gloria Ashiya Katuka, Alexander Gain, Yen-Yun Yu</author><pubDate>Wed, 01 May 2024 17:13:54 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.00602v1</guid></item><item><title>HairFastGAN: Realistic and Robust Hair Transfer with a Fast Encoder-Based Approach</title><link>http://arxiv.org/abs/2404.01094v2</link><description>Our paper addresses the complex task of transferring a hairstyle from areference image to an input photo for virtual hair try-on. This task ischallenging due to the need to adapt to various photo poses, the sensitivity ofhairstyles, and the lack of objective metrics. The current state of the arthairstyle transfer methods use an optimization process for different parts ofthe approach, making them inexcusably slow. At the same time, fasterencoder-based models are of very low quality because they either operate inStyleGAN's W+ space or use other low-dimensional image generators.Additionally, both approaches have a problem with hairstyle transfer when thesource pose is very different from the target pose, because they either don'tconsider the pose at all or deal with it inefficiently. In our paper, wepresent the HairFast model, which uniquely solves these problems and achieveshigh resolution, near real-time performance, and superior reconstructioncompared to optimization problem-based methods. Our solution includes a newarchitecture operating in the FS latent space of StyleGAN, an enhancedinpainting approach, and improved encoders for better alignment, colortransfer, and a new encoder for post-processing. The effectiveness of ourapproach is demonstrated on realism metrics after random hairstyle transfer andreconstruction when the original hairstyle is transferred. In the mostdifficult scenario of transferring both shape and color of a hairstyle fromdifferent images, our method performs in less than a second on the Nvidia V100.Our code is available at https://github.com/AIRI-Institute/HairFastGAN.</description><author>Maxim Nikolaev, Mikhail Kuznetsov, Dmitry Vetrov, Aibek Alanov</author><pubDate>Wed, 01 May 2024 17:12:54 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.01094v2</guid></item><item><title>Unconstrained Stochastic CCA: Unifying Multiview and Self-Supervised Learning</title><link>http://arxiv.org/abs/2310.01012v4</link><description>The Canonical Correlation Analysis (CCA) family of methods is foundational inmultiview learning. Regularised linear CCA methods can be seen to generalisePartial Least Squares (PLS) and be unified with a Generalized EigenvalueProblem (GEP) framework. However, classical algorithms for these linear methodsare computationally infeasible for large-scale data. Extensions to Deep CCAshow great promise, but current training procedures are slow and complicated.First we propose a novel unconstrained objective that characterizes the topsubspace of GEPs. Our core contribution is a family of fast algorithms forstochastic PLS, stochastic CCA, and Deep CCA, simply obtained by applyingstochastic gradient descent (SGD) to the corresponding CCA objectives. Ouralgorithms show far faster convergence and recover higher correlations than theprevious state-of-the-art on all standard CCA and Deep CCA benchmarks. Theseimprovements allow us to perform a first-of-its-kind PLS analysis of anextremely large biomedical dataset from the UK Biobank, with over 33,000individuals and 500,000 features. Finally, we apply our algorithms to match theperformance of `CCA-family' Self-Supervised Learning (SSL) methods on CIFAR-10and CIFAR-100 with minimal hyper-parameter tuning, and also present theory toclarify the links between these methods and classical CCA, laying thegroundwork for future insights.</description><author>James Chapman, Lennie Wells, Ana Lawry Aguila</author><pubDate>Wed, 01 May 2024 17:02:30 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.01012v4</guid></item><item><title>Scaling and renormalization in high-dimensional regression</title><link>http://arxiv.org/abs/2405.00592v1</link><description>This paper presents a succinct derivation of the training and generalizationperformance of a variety of high-dimensional ridge regression models using thebasic tools of random matrix theory and free probability. We provide anintroduction and review of recent results on these topics, aimed at readerswith backgrounds in physics and deep learning. Analytic formulas for thetraining and generalization errors are obtained in a few lines of algebradirectly from the properties of the $S$-transform of free probability. Thisallows for a straightforward identification of the sources of power-law scalingin model performance. We compute the generalization error of a broad class ofrandom feature models. We find that in all models, the $S$-transformcorresponds to the train-test generalization gap, and yields an analogue of thegeneralized-cross-validation estimator. Using these techniques, we derivefine-grained bias-variance decompositions for a very general class of randomfeature models with structured covariates. These novel results allow us todiscover a scaling regime for random feature models where the variance due tothe features limits performance in the overparameterized setting. We alsodemonstrate how anisotropic weight structure in random feature models can limitperformance and lead to nontrivial exponents for finite-width corrections inthe overparameterized setting. Our results extend and provide a unifyingperspective on earlier models of neural scaling laws.</description><author>Alexander B. Atanasov, Jacob A. Zavatone-Veth, Cengiz Pehlevan</author><pubDate>Wed, 01 May 2024 16:59:00 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.00592v1</guid></item><item><title>The R2D2 deep neural network series paradigm for fast precision imaging in radio astronomy</title><link>http://arxiv.org/abs/2403.05452v3</link><description>Radio-interferometric (RI) imaging entails solving high-resolutionhigh-dynamic range inverse problems from large data volumes. Recent imagereconstruction techniques grounded in optimization theory have demonstratedremarkable capability for imaging precision, well beyond CLEAN's capability.These range from advanced proximal algorithms propelled by handcraftedregularization operators, such as the SARA family, to hybrid plug-and-play(PnP) algorithms propelled by learned regularization denoisers, such as AIRI.Optimization and PnP structures are however highly iterative, which hinderstheir ability to handle the extreme data sizes expected from futureinstruments. To address this scalability challenge, we introduce a novel deeplearning approach, dubbed "Residual-to-Residual DNN series for high-Dynamicrange imaging". R2D2's reconstruction is formed as a series of residual images,iteratively estimated as outputs of Deep Neural Networks (DNNs) taking theprevious iteration's image estimate and associated data residual as inputs. Itthus takes a hybrid structure between a PnP algorithm and a learned version ofthe matching pursuit algorithm that underpins CLEAN. We present a comprehensivestudy of our approach, featuring its multiple incarnations distinguished bytheir DNN architectures. We provide a detailed description of its trainingprocess, targeting a telescope-specific approach. R2D2's capability to deliverhigh precision is demonstrated in simulation, across a variety of image andobservation settings using the Very Large Array (VLA). Its reconstruction speedis also demonstrated: with only few iterations required to clean data residualsat dynamic ranges up to 100000, R2D2 opens the door to fast precision imaging.R2D2 codes are available in the BASPLib library on GitHub.</description><author>Amir Aghabiglou, Chung San Chu, Arwa Dabbech, Yves Wiaux</author><pubDate>Wed, 01 May 2024 16:58:52 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.05452v3</guid></item><item><title>Probabilistic Sampling of Balanced K-Means using Adiabatic Quantum Computing</title><link>http://arxiv.org/abs/2310.12153v2</link><description>Adiabatic quantum computing (AQC) is a promising approach for discrete andoften NP-hard optimization problems. Current AQCs allow to implement problemsof research interest, which has sparked the development of quantumrepresentations for many computer vision tasks. Despite requiring multiplemeasurements from the noisy AQC, current approaches only utilize the bestmeasurement, discarding information contained in the remaining ones. In thiswork, we explore the potential of using this information for probabilisticbalanced k-means clustering. Instead of discarding non-optimal solutions, wepropose to use them to compute calibrated posterior probabilities with littleadditional compute cost. This allows us to identify ambiguous solutions anddata points, which we demonstrate on a D-Wave AQC on synthetic tasks and realvisual data.</description><author>Jan-Nico Zaech, Martin Danelljan, Tolga Birdal, Luc Van Gool</author><pubDate>Wed, 01 May 2024 16:54:34 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.12153v2</guid></item><item><title>Separation capacity of linear reservoirs with random connectivity matrix</title><link>http://arxiv.org/abs/2404.17429v2</link><description>We argue that the success of reservoir computing lies within the separationcapacity of the reservoirs and show that the expected separation capacity ofrandom linear reservoirs is fully characterised by the spectral decompositionof an associated generalised matrix of moments. Of particular interest arereservoirs with Gaussian matrices that are either symmetric or whose entriesare all independent. In the symmetric case, we prove that the separationcapacity always deteriorates with time; while for short inputs, separation withlarge reservoirs is best achieved when the entries of the matrix are scaledwith a factor $\rho_T/\sqrt{N}$, where $N$ is the dimension of the reservoirand $\rho_T$ depends on the maximum length of the input time series. In thei.i.d. case, we establish that optimal separation with large reservoirs isconsistently achieved when the entries of the reservoir matrix are scaled withthe exact factor $1/\sqrt{N}$. We further give upper bounds on the quality ofseparation in function of the length of the time series. We complement thisanalysis with an investigation of the likelihood of this separation and theimpact of the chosen architecture on separation consistency.</description><author>Youness Boutaib</author><pubDate>Wed, 01 May 2024 16:53:49 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.17429v2</guid></item><item><title>Are Models Biased on Text without Gender-related Language?</title><link>http://arxiv.org/abs/2405.00588v1</link><description>Gender bias research has been pivotal in revealing undesirable behaviors inlarge language models, exposing serious gender stereotypes associated withoccupations, and emotions. A key observation in prior work is that modelsreinforce stereotypes as a consequence of the gendered correlations that arepresent in the training data. In this paper, we focus on bias where the effectfrom training data is unclear, and instead address the question: Do languagemodels still exhibit gender bias in non-stereotypical settings? To do so, weintroduce UnStereoEval (USE), a novel framework tailored for investigatinggender bias in stereotype-free scenarios. USE defines a sentence-level scorebased on pretraining data statistics to determine if the sentence containminimal word-gender associations. To systematically benchmark the fairness ofpopular language models in stereotype-free scenarios, we utilize USE toautomatically generate benchmarks without any gender-related language. Byleveraging USE's sentence-level score, we also repurpose prior gender biasbenchmarks (Winobias and Winogender) for non-stereotypical evaluation.Surprisingly, we find low fairness across all 28 tested models. Concretely,models demonstrate fair behavior in only 9%-41% of stereotype-free sentences,suggesting that bias does not solely stem from the presence of gender-relatedwords. These results raise important questions about where underlying modelbiases come from and highlight the need for more systematic and comprehensivebias evaluation. We release the full dataset and code athttps://ucinlp.github.io/unstereo-eval.</description><author>Catarina G Belém, Preethi Seshadri, Yasaman Razeghi, Sameer Singh</author><pubDate>Wed, 01 May 2024 16:51:15 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.00588v1</guid></item><item><title>GraCo: Granularity-Controllable Interactive Segmentation</title><link>http://arxiv.org/abs/2405.00587v1</link><description>Interactive Segmentation (IS) segments specific objects or parts in the imageaccording to user input. Current IS pipelines fall into two categories:single-granularity output and multi-granularity output. The latter aims toalleviate the spatial ambiguity present in the former. However, themulti-granularity output pipeline suffers from limited interaction flexibilityand produces redundant results. In this work, we introduceGranularity-Controllable Interactive Segmentation (GraCo), a novel approachthat allows precise control of prediction granularity by introducing additionalparameters to input. This enhances the customization of the interactive systemand eliminates redundancy while resolving ambiguity. Nevertheless, theexorbitant cost of annotating multi-granularity masks and the lack of availabledatasets with granularity annotations make it difficult for models to acquirethe necessary guidance to control output granularity. To address this problem,we design an any-granularity mask generator that exploits the semantic propertyof the pre-trained IS model to automatically generate abundant mask-granularitypairs without requiring additional manual annotation. Based on these pairs, wepropose a granularity-controllable learning strategy that efficiently impartsthe granularity controllability to the IS model. Extensive experiments onintricate scenarios at object and part levels demonstrate that our GraCo hassignificant advantages over previous methods. This highlights the potential ofGraCo to be a flexible annotation tool, capable of adapting to diversesegmentation scenarios. The project page: https://zhao-yian.github.io/GraCo.</description><author>Yian Zhao, Kehan Li, Zesen Cheng, Pengchong Qiao, Xiawu Zheng, Rongrong Ji, Chang Liu, Li Yuan, Jie Chen</author><pubDate>Wed, 01 May 2024 16:50:16 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.00587v1</guid></item><item><title>Multi-objective optimisation via the R2 utilities</title><link>http://arxiv.org/abs/2305.11774v3</link><description>The goal of multi-objective optimisation is to identify a collection ofpoints which describe the best possible trade-offs between the multipleobjectives. In order to solve this vector-valued optimisation problem,practitioners often appeal to the use of scalarisation functions in order totransform the multi-objective problem into a collection of single-objectiveproblems. This set of scalarised problems can then be solved using traditionalsingle-objective optimisation techniques. In this work, we formalise thisconvention into a general mathematical framework. We show how this strategyeffectively recasts the original multi-objective optimisation problem into asingle-objective optimisation problem defined over sets. An appropriate classof objective functions for this new problem are the R2 utilities, which areutility functions that are defined as a weighted integral over the scalarisedoptimisation problems. As part of our work, we show that these utilities aremonotone and submodular set functions which can be optimised effectively usinggreedy optimisation algorithms. We then analyse the performance of these greedyalgorithms both theoretically and empirically. Our analysis largely focusses onBayesian optimisation, which is a popular probabilistic framework for black-boxoptimisation.</description><author>Ben Tu, Nikolas Kantas, Robert M. Lee, Behrang Shafei</author><pubDate>Wed, 01 May 2024 16:48:52 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.11774v3</guid></item><item><title>A Minimal Set of Parameters Based Depth-Dependent Distortion Model and Its Calibration Method for Stereo Vision Systems</title><link>http://arxiv.org/abs/2404.19242v2</link><description>Depth position highly affects lens distortion, especially in close-rangephotography, which limits the measurement accuracy of existing stereo visionsystems. Moreover, traditional depth-dependent distortion models and theircalibration methods have remained complicated. In this work, we propose aminimal set of parameters based depth-dependent distortion model (MDM), whichconsiders the radial and decentering distortions of the lens to improve theaccuracy of stereo vision systems and simplify their calibration process. Inaddition, we present an easy and flexible calibration method for the MDM ofstereo vision systems with a commonly used planar pattern, which requirescameras to observe the planar pattern in different orientations. The proposedtechnique is easy to use and flexible compared with classical calibrationtechniques for depth-dependent distortion models in which the lens must beperpendicular to the planar pattern. The experimental validation of the MDM andits calibration method showed that the MDM improved the calibration accuracy by56.55% and 74.15% compared with the Li's distortion model and traditionalBrown's distortion model. Besides, an iteration-based reconstruction method isproposed to iteratively estimate the depth information in the MDM duringthree-dimensional reconstruction. The results showed that the accuracy of theiteration-based reconstruction method was improved by 9.08% compared with thatof the non-iteration reconstruction method.</description><author>Xin Ma, Puchen Zhu, Xiao Li, Xiaoyin Zheng, Jianshu Zhou, Xuchen Wang, Kwok Wai Samuel Au</author><pubDate>Wed, 01 May 2024 16:42:09 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.19242v2</guid></item><item><title>Volume-Preserving Transformers for Learning Time Series Data with Structure</title><link>http://arxiv.org/abs/2312.11166v2</link><description>Two of the many trends in neural network research of the past few years havebeen (i) the learning of dynamical systems, especially with recurrent neuralnetworks such as long short-term memory networks (LSTMs) and (ii) theintroduction of transformer neural networks for natural language processing(NLP) tasks. Both of these trends have created enormous amounts of traction,particularly the second one: transformer networks now dominate the field ofNLP. Even though some work has been performed on the intersection of these twotrends, those efforts was largely limited to using the vanilla transformerdirectly without adjusting its architecture for the setting of a physicalsystem. In this work we use a transformer-inspired neural network to learn adynamical system and furthermore (for the first time) imbue it withstructure-preserving properties to improve long-term stability. This is shownto be of great advantage when applying the neural network to real worldapplications.</description><author>Benedikt Brantner, Guillaume de Romemont, Michael Kraus, Zeyuan Li</author><pubDate>Wed, 01 May 2024 16:37:32 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.11166v2</guid></item><item><title>Replacing Judges with Juries: Evaluating LLM Generations with a Panel of Diverse Models</title><link>http://arxiv.org/abs/2404.18796v2</link><description>As Large Language Models (LLMs) have become more advanced, they have outpacedour abilities to accurately evaluate their quality. Not only is finding data toadequately probe particular model properties difficult, but evaluating thecorrectness of a model's freeform generation alone is a challenge. To addressthis, many evaluations now rely on using LLMs themselves as judges to score thequality of outputs from other LLMs. Evaluations most commonly use a singlelarge model like GPT4. While this method has grown in popularity, it is costly,has been shown to introduce intramodel bias, and in this work, we find thatvery large models are often unnecessary. We propose instead to evaluate modelsusing a Panel of LLm evaluators (PoLL). Across three distinct judge settingsand spanning six different datasets, we find that using a PoLL composed of alarger number of smaller models outperforms a single large judge, exhibits lessintra-model bias due to its composition of disjoint model families, and does sowhile being over seven times less expensive.</description><author>Pat Verga, Sebastian Hofstatter, Sophia Althammer, Yixuan Su, Aleksandra Piktus, Arkady Arkhangorodsky, Minjie Xu, Naomi White, Patrick Lewis</author><pubDate>Wed, 01 May 2024 16:37:11 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.18796v2</guid></item><item><title>Cross-Validation Conformal Risk Control</title><link>http://arxiv.org/abs/2401.11974v2</link><description>Conformal risk control (CRC) is a recently proposed technique that appliespost-hoc to a conventional point predictor to provide calibration guarantees.Generalizing conformal prediction (CP), with CRC, calibration is ensured for aset predictor that is extracted from the point predictor to control a riskfunction such as the probability of miscoverage or the false negative rate. Theoriginal CRC requires the available data set to be split between training andvalidation data sets. This can be problematic when data availability islimited, resulting in inefficient set predictors. In this paper, a novel CRCmethod is introduced that is based on cross-validation, rather than onvalidation as the original CRC. The proposed cross-validation CRC (CV-CRC)extends a version of the jackknife-minmax from CP to CRC, allowing for thecontrol of a broader range of risk functions. CV-CRC is proved to offertheoretical guarantees on the average risk of the set predictor. Furthermore,numerical experiments show that CV-CRC can reduce the average set size withrespect to CRC when the available data are limited.</description><author>Kfir M. Cohen, Sangwoo Park, Osvaldo Simeone, Shlomo Shamai</author><pubDate>Wed, 01 May 2024 16:33:36 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.11974v2</guid></item><item><title>The Real, the Better: Aligning Large Language Models with Online Human Behaviors</title><link>http://arxiv.org/abs/2405.00578v1</link><description>Large language model alignment is widely used and studied to avoid LLMproducing unhelpful and harmful responses. However, the lengthy trainingprocess and predefined preference bias hinder adaptation to online diversehuman preferences. To this end, this paper proposes an alignment framework,called Reinforcement Learning with Human Behavior (RLHB), to align LLMs bydirectly leveraging real online human behaviors. By taking the generativeadversarial framework, the generator is trained to respond following expectedhuman behavior; while the discriminator tries to verify whether the triplets ofquery, response, and human behavior come from real online environments.Behavior modeling in natural-language form and the multi-model joint trainingmechanism enable an active and sustainable online alignment. Experimentalresults confirm the effectiveness of our proposed methods by both human andautomatic evaluations.</description><author>Guanying Jiang, Lingyong Yan, Haibo Shi, Dawei Yin</author><pubDate>Wed, 01 May 2024 16:30:41 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.00578v1</guid></item><item><title>Discovering robust biomarkers of neurological disorders from functional MRI using graph neural networks: A Review</title><link>http://arxiv.org/abs/2405.00577v1</link><description>Graph neural networks (GNN) have emerged as a popular tool for modellingfunctional magnetic resonance imaging (fMRI) datasets. Many recent studies havereported significant improvements in disorder classification performance viamore sophisticated GNN designs and highlighted salient features that could bepotential biomarkers of the disorder. In this review, we provide an overview ofhow GNN and model explainability techniques have been applied on fMRI datasetsfor disorder prediction tasks, with a particular emphasis on the robustness ofbiomarkers produced for neurodegenerative diseases and neuropsychiatricdisorders. We found that while most studies have performant models, salientfeatures highlighted in these studies vary greatly across studies on the samedisorder and little has been done to evaluate their robustness. To addressthese issues, we suggest establishing new standards that are based on objectiveevaluation metrics to determine the robustness of these potential biomarkers.We further highlight gaps in the existing literature and put together aprediction-attribution-evaluation framework that could set the foundations forfuture research on improving the robustness of potential biomarkers discoveredvia GNNs.</description><author>Yi Hao Chan, Deepank Girish, Sukrit Gupta, Jing Xia, Chockalingam Kasi, Yinan He, Conghao Wang, Jagath C. Rajapakse</author><pubDate>Wed, 01 May 2024 16:29:55 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.00577v1</guid></item><item><title>Learning to Complement with Multiple Humans</title><link>http://arxiv.org/abs/2311.13172v2</link><description>Real-world image classification tasks tend to be complex, where expertlabellers are sometimes unsure about the classes present in the images, leadingto the issue of learning with noisy labels (LNL). The ill-posedness of the LNLtask requires the adoption of strong assumptions or the use of multiple noisylabels per training image, resulting in accurate models that work well inisolation but fail to optimise human-AI collaborative classification (HAI-CC).Unlike such LNL methods, HAI-CC aims to leverage the synergies between humanexpertise and AI capabilities but requires clean training labels, limiting itsreal-world applicability. This paper addresses this gap by introducing theinnovative Learning to Complement with Multiple Humans (LECOMH) approach.LECOMH is designed to learn from noisy labels without depending on cleanlabels, simultaneously maximising collaborative accuracy while minimising thecost of human collaboration, measured by the number of human expert annotationsrequired per image. Additionally, new benchmarks featuring multiple noisylabels for both training and testing are proposed to evaluate HAI-CC methods.Through quantitative comparisons on these benchmarks, LECOMH consistentlyoutperforms competitive HAI-CC approaches, human labellers, multi-raterlearning, and noisy-label learning methods across various datasets, offering apromising solution for addressing real-world image classification challenges.</description><author>Zheng Zhang, Cuong Nguyen, Kevin Wells, Thanh-Toan Do, Gustavo Carneiro</author><pubDate>Wed, 01 May 2024 16:27:51 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.13172v2</guid></item><item><title>EALD-MLLM: Emotion Analysis in Long-sequential and De-identity videos with Multi-modal Large Language Model</title><link>http://arxiv.org/abs/2405.00574v1</link><description>Emotion AI is the ability of computers to understand human emotional states.Existing works have achieved promising progress, but two limitations remain tobe solved: 1) Previous studies have been more focused on short sequential videoemotion analysis while overlooking long sequential video. However, the emotionsin short sequential videos only reflect instantaneous emotions, which may bedeliberately guided or hidden. In contrast, long sequential videos can revealauthentic emotions; 2) Previous studies commonly utilize various signals suchas facial, speech, and even sensitive biological signals (e.g.,electrocardiogram). However, due to the increasing demand for privacy,developing Emotion AI without relying on sensitive signals is becomingimportant. To address the aforementioned limitations, in this paper, weconstruct a dataset for Emotion Analysis in Long-sequential and De-identityvideos called EALD by collecting and processing the sequences of athletes'post-match interviews. In addition to providing annotations of the overallemotional state of each video, we also provide the Non-Facial Body Language(NFBL) annotations for each player. NFBL is an inner-driven emotionalexpression and can serve as an identity-free clue to understanding theemotional state. Moreover, we provide a simple but effective baseline forfurther research. More precisely, we evaluate the Multimodal Large LanguageModels (MLLMs) with de-identification signals (e.g., visual, speech, and NFBLs)to perform emotion analysis. Our experimental results demonstrate that: 1)MLLMs can achieve comparable, even better performance than the supervisedsingle-modal models, even in a zero-shot scenario; 2) NFBL is an important cuein long sequential emotion analysis. EALD will be available on the open-sourceplatform.</description><author>Deng Li, Xin Liu, Bohao Xing, Baiqiang Xia, Yuan Zong, Bihan Wen, Heikki Kälviäinen</author><pubDate>Wed, 01 May 2024 16:25:54 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.00574v1</guid></item><item><title>RTG-SLAM: Real-time 3D Reconstruction at Scale using Gaussian Splatting</title><link>http://arxiv.org/abs/2404.19706v2</link><description>We present Real-time Gaussian SLAM (RTG-SLAM), a real-time 3D reconstructionsystem with an RGBD camera for large-scale environments using Gaussiansplatting. The system features a compact Gaussian representation and a highlyefficient on-the-fly Gaussian optimization scheme. We force each Gaussian to beeither opaque or nearly transparent, with the opaque ones fitting the surfaceand dominant colors, and transparent ones fitting residual colors. By renderingdepth in a different way from color rendering, we let a single opaque Gaussianwell fit a local surface region without the need of multiple overlappingGaussians, hence largely reducing the memory and computation cost. Foron-the-fly Gaussian optimization, we explicitly add Gaussians for three typesof pixels per frame: newly observed, with large color errors, and with largedepth errors. We also categorize all Gaussians into stable and unstable ones,where the stable Gaussians are expected to well fit previously observed RGBDimages and otherwise unstable. We only optimize the unstable Gaussians and onlyrender the pixels occupied by unstable Gaussians. In this way, both the numberof Gaussians to be optimized and pixels to be rendered are largely reduced, andthe optimization can be done in real time. We show real-time reconstructions ofa variety of large scenes. Compared with the state-of-the-art NeRF-based RGBDSLAM, our system achieves comparable high-quality reconstruction but witharound twice the speed and half the memory cost, and shows superior performancein the realism of novel view synthesis and camera tracking accuracy.</description><author>Zhexi Peng, Tianjia Shao, Yong Liu, Jingke Zhou, Yin Yang, Jingdong Wang, Kun Zhou</author><pubDate>Wed, 01 May 2024 16:25:30 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.19706v2</guid></item><item><title>A Survey of Graph Neural Networks for Social Recommender Systems</title><link>http://arxiv.org/abs/2212.04481v3</link><description>Social recommender systems (SocialRS) simultaneously leverage theuser-to-item interactions as well as the user-to-user social relations for thetask of generating item recommendations to users. Additionally exploitingsocial relations is clearly effective in understanding users' tastes due to theeffects of homophily and social influence. For this reason, SocialRS hasincreasingly attracted attention. In particular, with the advance of graphneural networks (GNN), many GNN-based SocialRS methods have been developedrecently. Therefore, we conduct a comprehensive and systematic review of theliterature on GNN-based SocialRS. In this survey, we first identify 84 paperson GNN-based SocialRS after annotating 2151 papers by following the PRISMAframework (preferred reporting items for systematic reviews and meta-analyses).Then, we comprehensively review them in terms of their inputs and architecturesto propose a novel taxonomy: (1) input taxonomy includes 5 groups of input typenotations and 7 groups of input representation notations; (2) architecturetaxonomy includes 8 groups of GNN encoder notations, 2 groups of decodernotations, and 12 groups of loss function notations. We classify the GNN-basedSocialRS methods into several categories as per the taxonomy and describe theirdetails. Furthermore, we summarize benchmark datasets and metrics widely usedto evaluate the GNN-based SocialRS methods. Finally, we conclude this survey bypresenting some future research directions. GitHub repository with the curatedlist of papers are available athttps://github.com/claws-lab/awesome-GNN-social-recsys.</description><author>Kartik Sharma, Yeon-Chang Lee, Sivagami Nambi, Aditya Salian, Shlok Shah, Sang-Wook Kim, Srijan Kumar</author><pubDate>Wed, 01 May 2024 16:24:47 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2212.04481v3</guid></item><item><title>On the Impact of Data Heterogeneity in Federated Learning Environments with Application to Healthcare Networks</title><link>http://arxiv.org/abs/2404.18519v2</link><description>Federated Learning (FL) allows multiple privacy-sensitive applications toleverage their dataset for a global model construction without any disclosureof the information. One of those domains is healthcare, where groups of siloscollaborate in order to generate a global predictor with improved accuracy andgeneralization. However, the inherent challenge lies in the high heterogeneityof medical data, necessitating sophisticated techniques for assessment andcompensation. This paper presents a comprehensive exploration of themathematical formalization and taxonomy of heterogeneity within FLenvironments, focusing on the intricacies of medical data. In particular, weaddress the evaluation and comparison of the most popular FL algorithms withrespect to their ability to cope with quantity-based, feature and labeldistribution-based heterogeneity. The goal is to provide a quantitativeevaluation of the impact of data heterogeneity in FL systems for healthcarenetworks as well as a guideline on FL algorithm selection. Our research extendsbeyond existing studies by benchmarking seven of the most common FL algorithmsagainst the unique challenges posed by medical data use cases. The papertargets the prediction of the risk of stroke recurrence through a set oftabular clinical reports collected by different federated hospital silos: dataheterogeneity frequently encountered in this scenario and its impact on FLperformance are discussed.</description><author>Usevalad Milasheuski. Luca Barbieri, Bernardo Camajori Tedeschini, Monica Nicoli, Stefano Savazzi</author><pubDate>Wed, 01 May 2024 16:20:53 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.18519v2</guid></item><item><title>ODBO: Bayesian Optimization with Search Space Prescreening for Directed Protein Evolution</title><link>http://arxiv.org/abs/2205.09548v6</link><description>Directed evolution is a versatile technique in protein engineering thatmimics the process of natural selection by iteratively alternating betweenmutagenesis and screening in order to search for sequences that optimize agiven property of interest, such as catalytic activity and binding affinity toa specified target. However, the space of possible proteins is too large tosearch exhaustively in the laboratory, and functional proteins are scarce inthe vast sequence space. Machine learning (ML) approaches can acceleratedirected evolution by learning to map protein sequences to functions withoutbuilding a detailed model of the underlying physics, chemistry and biologicalpathways. Despite the great potentials held by these ML methods, they encountersevere challenges in identifying the most suitable sequences for a targetedfunction. These failures can be attributed to the common practice of adopting ahigh-dimensional feature representation for protein sequences and inefficientsearch methods. To address these issues, we propose an efficient, experimentaldesign-oriented closed-loop optimization framework for protein directedevolution, termed ODBO, which employs a combination of novel low-dimensionalprotein encoding strategy and Bayesian optimization enhanced with search spaceprescreening via outlier detection. We further design an initial sampleselection strategy to minimize the number of experimental samples for trainingML models. We conduct and report four protein directed evolution experimentsthat substantiate the capability of the proposed framework for finding of thevariants with properties of interest. We expect the ODBO framework to greatlyreduce the experimental cost and time cost of directed evolution, and can befurther generalized as a powerful tool for adaptive experimental design in abroader context.</description><author>Lixue Cheng, Ziyi Yang, Changyu Hsieh, Benben Liao, Shengyu Zhang</author><pubDate>Wed, 01 May 2024 16:20:12 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2205.09548v6</guid></item><item><title>Spherical Linear Interpolation and Text-Anchoring for Zero-shot Composed Image Retrieval</title><link>http://arxiv.org/abs/2405.00571v1</link><description>Composed Image Retrieval (CIR) is a complex task that retrieves images usinga query, which is configured with an image and a caption that describes desiredmodifications to that image. Supervised CIR approaches have shown strongperformance, but their reliance on expensive manually-annotated datasetsrestricts their scalability and broader applicability. To address these issues,previous studies have proposed pseudo-word token-based Zero-Shot CIR (ZS-CIR)methods, which utilize a projection module to map images to word tokens.However, we conjecture that this approach has a downside: the projection moduledistorts the original image representation and confines the resulting composedembeddings to the text-side. In order to resolve this, we introduce a novelZS-CIR method that uses Spherical Linear Interpolation (Slerp) to directlymerge image and text representations by identifying an intermediate embeddingof both. Furthermore, we introduce Text-Anchored-Tuning (TAT), a method thatfine-tunes the image encoder while keeping the text encoder fixed. TAT closesthe modality gap between images and text, making the Slerp process much moreeffective. Notably, the TAT method is not only efficient in terms of the scaleof the training dataset and training time, but it also serves as an excellentinitial checkpoint for training supervised CIR models, thereby highlighting itswider potential. The integration of the Slerp-based ZS-CIR with a TAT-tunedmodel enables our approach to deliver state-of-the-art retrieval performanceacross CIR benchmarks.</description><author>Young Kyun Jang, Dat Huynh, Ashish Shah, Wen-Kai Chen, Ser-Nam Lim</author><pubDate>Wed, 01 May 2024 16:19:54 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.00571v1</guid></item><item><title>WEST GCN-LSTM: Weighted Stacked Spatio-Temporal Graph Neural Networks for Regional Traffic Forecasting</title><link>http://arxiv.org/abs/2405.00570v1</link><description>Regional traffic forecasting is a critical challenge in urban mobility, withapplications to various fields such as the Internet of Everything. In recentyears, spatio-temporal graph neural networks have achieved state-of-the-artresults in the context of numerous traffic forecasting challenges. This workaims at expanding upon the conventional spatio-temporal graph neural networkarchitectures in a manner that may facilitate the inclusion of informationregarding the examined regions, as well as the populations that traverse them,in order to establish a more efficient prediction model. The end-product ofthis scientific endeavour is a novel spatio-temporal graph neural networkarchitecture that is referred to as WEST (WEighted STacked) GCN-LSTM.Furthermore, the inclusion of the aforementioned information is conducted viathe use of two novel dedicated algorithms that are referred to as the SharedBorders Policy and the Adjustable Hops Policy. Through information fusion anddistillation, the proposed solution manages to significantly outperform itscompetitors in the frame of an experimental evaluation that consists of 19forecasting models, across several datasets. Finally, an additional ablationstudy determined that each of the components of the proposed solutioncontributes towards enhancing its overall performance.</description><author>Theodoros Theodoropoulos, Angelos-Christos Maroudis, Antonios Makris, Konstantinos Tserpes</author><pubDate>Wed, 01 May 2024 16:19:19 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.00570v1</guid></item><item><title>Powering In-Database Dynamic Model Slicing for Structured Data Analytics</title><link>http://arxiv.org/abs/2405.00568v1</link><description>Relational database management systems (RDBMS) are widely used for thestorage and retrieval of structured data. To derive insights beyond statisticalaggregation, we typically have to extract specific subdatasets from thedatabase using conventional database operations, and then apply deep neuralnetworks (DNN) training and inference on these respective subdatasets in aseparate machine learning system. The process can be prohibitively expensive,especially when there are a combinatorial number of subdatasets extracted fordifferent analytical purposes. This calls for efficient in-database support ofadvanced analytical methods In this paper, we introduce LEADS, a novelSQL-aware dynamic model slicing technique to customize models for subdatasetsspecified by SQL queries. LEADS improves the predictive modeling of structureddata via the mixture of experts (MoE) technique and maintains inferenceefficiency by a SQL-aware gating network. At the core of LEADS is theconstruction of a general model with multiple expert sub-models via MoE trainedover the entire database. This SQL-aware MoE technique scales up the modelingcapacity, enhances effectiveness, and preserves efficiency by activating onlynecessary experts via the gating network during inference. Additionally, weintroduce two regularization terms during the training process of LEADS tostrike a balance between effectiveness and efficiency. We also design and buildan in-database inference system, called INDICES, to support end-to-end advancedstructured data analytics by non-intrusively incorporating LEADS ontoPostgreSQL. Our extensive experiments on real-world datasets demonstrate thatLEADS consistently outperforms baseline models, and INDICES delivers effectivein-database analytics with a considerable reduction in inference latencycompared to traditional solutions.</description><author>Lingze Zeng, Naili Xing, Shaofeng Cai, Gang Chen, Beng Chin Ooi, Jian Pei, Yuncheng Wu</author><pubDate>Wed, 01 May 2024 16:18:12 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.00568v1</guid></item><item><title>NumLLM: Numeric-Sensitive Large Language Model for Chinese Finance</title><link>http://arxiv.org/abs/2405.00566v1</link><description>Recently, many works have proposed various financial large language models(FinLLMs) by pre-training from scratch or fine-tuning open-sourced LLMs onfinancial corpora. However, existing FinLLMs exhibit unsatisfactory performancein understanding financial text when numeric variables are involved inquestions. In this paper, we propose a novel LLM, called numeric-sensitivelarge language model (NumLLM), for Chinese finance. We first construct afinancial corpus from financial textbooks which is essential for improvingnumeric capability of LLMs during fine-tuning. After that, we train twoindividual low-rank adaptation (LoRA) modules by fine-tuning on our constructedfinancial corpus. One module is for adapting general-purpose LLMs to financialdomain, and the other module is for enhancing the ability of NumLLM tounderstand financial text with numeric variables. Lastly, we merge the two LoRAmodules into the foundation model to obtain NumLLM for inference. Experimentson financial question-answering benchmark show that NumLLM can boost theperformance of the foundation model and can achieve the best overallperformance compared to all baselines, on both numeric and non-numericquestions.</description><author>Huan-Yi Su, Ke Wu, Yu-Hao Huang, Wu-Jun Li</author><pubDate>Wed, 01 May 2024 16:17:27 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.00566v1</guid></item><item><title>Attention is All They Need: Exploring the Media Archaeology of the Computer Vision Research Paper</title><link>http://arxiv.org/abs/2209.11200v2</link><description>Research papers, in addition to textual documents, are a designed interfacethrough which researchers communicate. Recently, rapid growth has transformedthat interface in many fields of computing. In this work, we examine theeffects of this growth from a media archaeology perspective, through thechanges to figures and tables in research papers. Specifically, we study thesechanges in computer vision over the past decade, as the deep learningrevolution has driven unprecedented growth in the discipline. We ground ourinvestigation through interviews with veteran researchers spanning computervision, graphics and visualization. Our analysis focuses on the researchattention economy: how research paper elements contribute towards advertising,measuring and disseminating an increasingly commodified ``contribution.''Through this work, we seek to motivate future discussion surrounding the designof both the research paper itself as well as the larger sociotechnical researchpublishing system, including tools for finding, reading and writing researchpapers.</description><author>Samuel Goree, Gabriel Appleby, David Crandall, Norman Su</author><pubDate>Wed, 01 May 2024 16:17:18 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2209.11200v2</guid></item><item><title>Mixture of insighTful Experts (MoTE): The Synergy of Thought Chains and Expert Mixtures in Self-Alignment</title><link>http://arxiv.org/abs/2405.00557v1</link><description>As the capabilities of large language models (LLMs) have expandeddramatically, aligning these models with human values presents a significantchallenge, posing potential risks during deployment. Traditional alignmentstrategies rely heavily on human intervention, such as Supervised Fine-Tuning(SFT) and Reinforcement Learning from Human Feedback (RLHF), or on theself-alignment capacities of LLMs, which usually require a strong LLM'semergent ability to improve its original bad answer. To address thesechallenges, we propose a novel self-alignment method that utilizes a Chain ofThought (CoT) approach, termed AlignCoT. This method encompasses stages ofQuestion Analysis, Answer Guidance, and Safe Answer production. It is designedto enable LLMs to generate high-quality, safe responses throughout variousstages of their development. Furthermore, we introduce the Mixture ofinsighTful Experts (MoTE) architecture, which applies the mixture of experts toenhance each component of the AlignCoT process, markedly increasing alignmentefficiency. The MoTE approach not only outperforms existing methods in aligningLLMs with human values but also highlights the benefits of using self-generateddata, revealing the dual benefits of improved alignment and trainingefficiency.</description><author>Zhili Liu, Yunhao Gou, Kai Chen, Lanqing Hong, Jiahui Gao, Fei Mi, Yu Zhang, Zhenguo Li, Xin Jiang, Qun Liu, James T. Kwok</author><pubDate>Wed, 01 May 2024 16:06:05 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.00557v1</guid></item><item><title>Swarm Learning: A Survey of Concepts, Applications, and Trends</title><link>http://arxiv.org/abs/2405.00556v1</link><description>Deep learning models have raised privacy and security concerns due to theirreliance on large datasets on central servers. As the number of Internet ofThings (IoT) devices increases, artificial intelligence (AI) will be crucialfor resource management, data processing, and knowledge acquisition. To addressthose issues, federated learning (FL) has introduced a novel approach tobuilding a versatile, large-scale machine learning framework that operates in adecentralized and hardware-agnostic manner. However, FL faces network bandwidthlimitations and data breaches. To reduce the central dependency in FL andincrease scalability, swarm learning (SL) has been proposed in collaborationwith Hewlett Packard Enterprise (HPE). SL represents a decentralized machinelearning framework that leverages blockchain technology for secure, scalable,and private data management. A blockchain-based network enables the exchangeand aggregation of model parameters among participants, thus mitigating therisk of a single point of failure and eliminating communication bottlenecks. Tothe best of our knowledge, this survey is the first to introduce the principlesof Swarm Learning, its architectural design, and its fields of application. Inaddition, it highlights numerous research avenues that require furtherexploration by academic and industry communities to unlock the full potentialand applications of SL.</description><author>Elham Shammar, Xiaohui Cui, Mohammed A. A. Al-qaness</author><pubDate>Wed, 01 May 2024 15:59:24 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.00556v1</guid></item><item><title>Derivative-based regularization for regression</title><link>http://arxiv.org/abs/2405.00555v1</link><description>In this work, we introduce a novel approach to regularization inmultivariable regression problems. Our regularizer, called DLoss, penalisesdifferences between the model's derivatives and derivatives of the datagenerating function as estimated from the training data. We call theseestimated derivatives data derivatives. The goal of our method is to align themodel to the data, not only in terms of target values but also in terms of thederivatives involved. To estimate data derivatives, we select (from thetraining data) 2-tuples of input-value pairs, using either nearest neighbour orrandom, selection. On synthetic and real datasets, we evaluate theeffectiveness of adding DLoss, with different weights, to the standard meansquared error loss. The experimental results show that with DLoss (usingnearest neighbour selection) we obtain, on average, the best rank with respectto MSE on validation data sets, compared to no regularization, L2regularization, and Dropout.</description><author>Enrico Lopedoto, Maksim Shekhunov, Vitaly Aksenov, Kizito Salako, Tillman Weyde</author><pubDate>Wed, 01 May 2024 15:57:59 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.00555v1</guid></item><item><title>Influence Maximization with Unknown Individual Effect on General Network</title><link>http://arxiv.org/abs/2301.12226v2</link><description>The identification of a seed set to maximize information spread in a networkis crucial, a concept known as Influence Maximization (IM). Elegant IMalgorithms could naturally extend to cases where each node is equipped withspecific weight, referred to as individual effect, to measure the node'simportance. Prevailing literature has typically assumed that the individualeffect remains constant during the cascade process. However, this assumption isnot always feasible, as the individual effect of each node is primarilyevaluated by the difference between the outputs in the activated andnon-activated states, with one of these states always being unobservable afterpropagation. Moreover, the individual effect is sensitive to the environmentalinformation provided by surrounding nodes. To address these challenges, weextend the consideration of IM to a broader scenario involving general networkswith dynamic node individual effects, leveraging causality techniques. In ourpaper, we address this through the development of a Causal InfluenceMaximization (CauIM) algorithm. Theoretically, for CauIM, we present thegeneralized lower bound of influence spread and provide robustness analysis.Empirically, in synthetic and real-world experiments, we demonstrate theeffectiveness and robustness of CauIM, along with a novel accelerationtechnique.</description><author>Xinyan Su, Zhiheng Zhang, Jiyan Qiu, Jun Li</author><pubDate>Wed, 01 May 2024 15:56:39 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2301.12226v2</guid></item><item><title>Image-Based Virtual Try-On: A Survey</title><link>http://arxiv.org/abs/2311.04811v3</link><description>Image-based virtual try-on aims to synthesize a naturally dressed personimage with a clothing image, which revolutionizes online shopping and inspiresrelated topics within image generation, showing both research significance andcommercial potential. However, there is a gap between current research progressand commercial applications and an absence of comprehensive overview of thisfield to accelerate the development. In this survey, we provide a comprehensiveanalysis of the state-of-the-art techniques and methodologies in aspects ofpipeline architecture, person representation and key modules such as try-onindication, clothing warping and try-on stage. We propose a new semanticcriteria with CLIP, and evaluate representative methods with uniformlyimplemented evaluation metrics on the same dataset. In addition to quantitativeand qualitative evaluation of current open-source methods, unresolved issuesare highlighted and future research directions are prospected to identify keytrends and inspire further exploration. The uniformly implemented evaluationmetrics, dataset and collected methods will be made public available athttps://github.com/little-misfit/Survey-Of-Virtual-Try-On.</description><author>Dan Song, Xuanpu Zhang, Juan Zhou, Weizhi Nie, Ruofeng Tong, Mohan Kankanhalli, An-An Liu</author><pubDate>Wed, 01 May 2024 15:56:23 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.04811v3</guid></item><item><title>Shifting Focus with HCEye: Exploring the Dynamics of Visual Highlighting and Cognitive Load on User Attention and Saliency Prediction</title><link>http://arxiv.org/abs/2404.14232v2</link><description>Visual highlighting can guide user attention in complex interfaces. However,its effectiveness under limited attentional capacities is underexplored. Thispaper examines the joint impact of visual highlighting (permanent and dynamic)and dual-task-induced cognitive load on gaze behaviour. Our analysis, usingeye-movement data from 27 participants viewing 150 unique webpages reveals thatwhile participants' ability to attend to UI elements decreases with increasingcognitive load, dynamic adaptations (i.e., highlighting) remainattention-grabbing. The presence of these factors significantly alters whatpeople attend to and thus what is salient. Accordingly, we show thatstate-of-the-art saliency models increase their performance when accounting fordifferent cognitive loads. Our empirical insights, along with our openlyavailable dataset, enhance our understanding of attentional processes in UIsunder varying cognitive (and perceptual) loads and open the door for new modelsthat can predict user attention while multitasking.</description><author>Anwesha Das, Zekun Wu, Iza Škrjanec, Anna Maria Feit</author><pubDate>Wed, 01 May 2024 15:54:30 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.14232v2</guid></item><item><title>Iterative Preference Learning from Human Feedback: Bridging Theory and Practice for RLHF under KL-Constraint</title><link>http://arxiv.org/abs/2312.11456v4</link><description>This paper studies the alignment process of generative models withReinforcement Learning from Human Feedback (RLHF). We first identify theprimary challenges of existing popular methods like offline PPO and offline DPOas lacking in strategical exploration of the environment. Then, to understandthe mathematical principle of RLHF, we consider a standard mathematicalformulation, the reverse-KL regularized contextual bandit for RLHF. Despite itswidespread practical application, a rigorous theoretical analysis of thisformulation remains open. We investigate its behavior in three distinctsettings -- offline, online, and hybrid -- and propose efficient algorithmswith finite-sample theoretical guarantees. Moving towards practical applications, our framework, with a robustapproximation of the information-theoretical policy improvement oracle,naturally gives rise to several novel RLHF algorithms. This includes aniterative version of the Direct Preference Optimization (DPO) algorithm foronline settings, and a multi-step rejection sampling strategy for offlinescenarios. Our empirical evaluations on real-world alignment experiment oflarge language model demonstrate that these proposed methods significantlysurpass existing strong baselines, such as DPO and Rejection SamplingOptimization (RSO), showcasing the connections between solid theoreticalfoundations and their potent practical implementations.</description><author>Wei Xiong, Hanze Dong, Chenlu Ye, Ziqi Wang, Han Zhong, Heng Ji, Nan Jiang, Tong Zhang</author><pubDate>Wed, 01 May 2024 15:50:56 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.11456v4</guid></item><item><title>The Inverse of Exact Renormalization Group Flows as Statistical Inference</title><link>http://arxiv.org/abs/2212.11379v2</link><description>We build on the view of the Exact Renormalization Group (ERG) as aninstantiation of Optimal Transport described by a functionalconvection-diffusion equation. We provide a new information theoreticperspective for understanding the ERG through the intermediary of BayesianStatistical Inference. This connection is facilitated by the Dynamical BayesianInference scheme, which encodes Bayesian inference in the form of a oneparameter family of probability distributions solving an integro-differentialequation derived from Bayes' law. In this note, we demonstrate how theDynamical Bayesian Inference equation is, itself, equivalent to a diffusionequation which we dub Bayesian Diffusion. Identifying the features that defineBayesian Diffusion, and mapping them onto the features that define the ERG, weobtain a dictionary outlining how renormalization can be understood as theinverse of statistical inference.</description><author>David S. Berman, Marc S. Klinger</author><pubDate>Wed, 01 May 2024 15:30:57 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2212.11379v2</guid></item><item><title>New Benchmark Dataset and Fine-Grained Cross-Modal Fusion Framework for Vietnamese Multimodal Aspect-Category Sentiment Analysis</title><link>http://arxiv.org/abs/2405.00543v1</link><description>The emergence of multimodal data on social media platforms presents newopportunities to better understand user sentiments toward a given aspect.However, existing multimodal datasets for Aspect-Category Sentiment Analysis(ACSA) often focus on textual annotations, neglecting fine-grained informationin images. Consequently, these datasets fail to fully exploit the richnessinherent in multimodal. To address this, we introduce a new Vietnamesemultimodal dataset, named ViMACSA, which consists of 4,876 text-image pairswith 14,618 fine-grained annotations for both text and image in the hoteldomain. Additionally, we propose a Fine-Grained Cross-Modal Fusion Framework(FCMF) that effectively learns both intra- and inter-modality interactions andthen fuses these information to produce a unified multimodal representation.Experimental results show that our framework outperforms SOTA models on theViMACSA dataset, achieving the highest F1 score of 79.73%. We also explorecharacteristics and challenges in Vietnamese multimodal sentiment analysis,including misspellings, abbreviations, and the complexities of the Vietnameselanguage. This work contributes both a benchmark dataset and a new frameworkthat leverages fine-grained multimodal information to improve multimodalaspect-category sentiment analysis. Our dataset is available for researchpurposes:https://github.com/hoangquy18/Multimodal-Aspect-Category-Sentiment-Analysis.</description><author>Quy Hoang Nguyen, Minh-Van Truong Nguyen, Kiet Van Nguyen</author><pubDate>Wed, 01 May 2024 15:29:03 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.00543v1</guid></item><item><title>UWAFA-GAN: Ultra-Wide-Angle Fluorescein Angiography Transformation via Multi-scale Generation and Registration Enhancement</title><link>http://arxiv.org/abs/2405.00542v1</link><description>Fundus photography, in combination with the ultra-wide-angle fundus (UWF)techniques, becomes an indispensable diagnostic tool in clinical settings byoffering a more comprehensive view of the retina. Nonetheless, UWF fluoresceinangiography (UWF-FA) necessitates the administration of a fluorescent dye viainjection into the patient's hand or elbow unlike UWF scanning laserophthalmoscopy (UWF-SLO). To mitigate potential adverse effects associated withinjections, researchers have proposed the development of cross-modality medicalimage generation algorithms capable of converting UWF-SLO images into theirUWF-FA counterparts. Current image generation techniques applied to fundusphotography encounter difficulties in producing high-resolution retinal images,particularly in capturing minute vascular lesions. To address these issues, weintroduce a novel conditional generative adversarial network (UWAFA-GAN) tosynthesize UWF-FA from UWF-SLO. This approach employs multi-scale generatorsand an attention transmit module to efficiently extract both global structuresand local lesions. Additionally, to counteract the image blurriness issue thatarises from training with misaligned data, a registration module is integratedwithin this framework. Our method performs non-trivially on inception scoresand details generation. Clinical user studies further indicate that the UWF-FAimages generated by UWAFA-GAN are clinically comparable to authentic images interms of diagnostic reliability. Empirical evaluations on our proprietary UWFimage datasets elucidate that UWAFA-GAN outperforms extant methodologies. Thecode is accessible at https://github.com/Tinysqua/UWAFA-GAN.</description><author>Ruiquan Ge, Zhaojie Fang, Pengxue Wei, Zhanghao Chen, Hongyang Jiang, Ahmed Elazab, Wangting Li, Xiang Wan, Shaochong Zhang, Changmiao Wang</author><pubDate>Wed, 01 May 2024 15:27:43 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.00542v1</guid></item><item><title>DSI2I: Dense Style for Unpaired Image-to-Image Translation</title><link>http://arxiv.org/abs/2212.13253v3</link><description>Unpaired exemplar-based image-to-image (UEI2I) translation aims to translatea source image to a target image domain with the style of a target imageexemplar, without ground-truth input-translation pairs. Existing UEI2I methodsrepresent style using one vector per image or rely on semantic supervision todefine one style vector per object. Here, in contrast, we propose to representstyle as a dense feature map, allowing for a finer-grained transfer to thesource image without requiring any external semantic information. We then relyon perceptual and adversarial losses to disentangle our dense style and contentrepresentations. To stylize the source content with the exemplar style, weextract unsupervised cross-domain semantic correspondences and warp theexemplar style to the source content. We demonstrate the effectiveness of ourmethod on four datasets using standard metrics together with a localized stylemetric we propose, which measures style similarity in a class-wise manner. Ourresults show that the translations produced by our approach are more diverse,preserve the source content better, and are closer to the exemplars whencompared to the state-of-the-art methods. Project page:https://github.com/IVRL/dsi2i</description><author>Baran Ozaydin, Tong Zhang, Sabine Süsstrunk, Mathieu Salzmann</author><pubDate>Wed, 01 May 2024 15:20:47 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2212.13253v3</guid></item><item><title>A Legal Framework for Natural Language Processing Model Training in Portugal</title><link>http://arxiv.org/abs/2405.00536v1</link><description>Recent advances in deep learning have promoted the advent of manycomputational systems capable of performing intelligent actions that, untilthen, were restricted to the human intellect. In the particular case of humanlanguages, these advances allowed the introduction of applications like ChatGPTthat are capable of generating coherent text without being explicitlyprogrammed to do so. Instead, these models use large volumes of textual data tolearn meaningful representations of human languages. Associated with theseadvances, concerns about copyright and data privacy infringements caused bythese applications have emerged. Despite these concerns, the pace at which newnatural language processing applications continued to be developed largelyoutperformed the introduction of new regulations. Today, communication barriersbetween legal experts and computer scientists motivate many unintentional legalinfringements during the development of such applications. In this paper, amultidisciplinary team intends to bridge this communication gap and promotemore compliant Portuguese NLP research by presenting a series of everyday NLPuse cases, while highlighting the Portuguese legislation that may arise duringits development.</description><author>Rúben Almeida, Evelin Amorim</author><pubDate>Wed, 01 May 2024 15:18:50 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.00536v1</guid></item><item><title>Machine Learning for Synthetic Data Generation: A Review</title><link>http://arxiv.org/abs/2302.04062v7</link><description>Machine learning heavily relies on data, but real-world applications oftenencounter various data-related issues. These include data of poor quality,insufficient data points leading to under-fitting of machine learning models,and difficulties in data access due to concerns surrounding privacy, safety,and regulations. In light of these challenges, the concept of synthetic datageneration emerges as a promising alternative that allows for data sharing andutilization in ways that real-world data cannot facilitate. This paper presentsa comprehensive systematic review of existing studies that employ machinelearning models for the purpose of generating synthetic data. The reviewencompasses various perspectives, starting with the applications of syntheticdata generation, spanning computer vision, speech, natural language processing,healthcare, and business domains. Additionally, it explores different machinelearning methods, with particular emphasis on neural network architectures anddeep generative models. The paper also addresses the crucial aspects of privacyand fairness concerns related to synthetic data generation. Furthermore, thisstudy identifies the challenges and opportunities prevalent in this emergingfield, shedding light on the potential avenues for future research. By delvinginto the intricacies of synthetic data generation, this paper aims tocontribute to the advancement of knowledge and inspire further exploration insynthetic data generation.</description><author>Yingzhou Lu, Minjie Shen, Huazheng Wang, Xiao Wang, Capucine van Rechem, Tianfan Fu, Wenqi Wei</author><pubDate>Wed, 01 May 2024 15:14:40 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2302.04062v7</guid></item><item><title>ULLER: A Unified Language for Learning and Reasoning</title><link>http://arxiv.org/abs/2405.00532v1</link><description>The field of neuro-symbolic artificial intelligence (NeSy), which combineslearning and reasoning, has recently experienced significant growth. There noware a wide variety of NeSy frameworks, each with its own specific language forexpressing background knowledge and how to relate it to neural networks. Thisheterogeneity hinders accessibility for newcomers and makes comparing differentNeSy frameworks challenging. We propose a unified language for NeSy, which wecall ULLER, a Unified Language for LEarning and Reasoning. ULLER encompasses awide variety of settings, while ensuring that knowledge described in it can beused in existing NeSy systems. ULLER has a neuro-symbolic first-order syntaxfor which we provide example semantics including classical, fuzzy, andprobabilistic logics. We believe ULLER is a first step towards making NeSyresearch more accessible and comparable, paving the way for libraries thatstreamline training and evaluation across a multitude of semantics, knowledgebases, and NeSy systems.</description><author>Emile van Krieken, Samy Badreddine, Robin Manhaeve, Eleonora Giunchiglia</author><pubDate>Wed, 01 May 2024 15:05:52 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.00532v1</guid></item><item><title>FMLFS: A federated multi-label feature selection based on information theory in IoT environment</title><link>http://arxiv.org/abs/2405.00524v1</link><description>In certain emerging applications such as health monitoring wearable andtraffic monitoring systems, Internet-of-Things (IoT) devices generate orcollect a huge amount of multi-label datasets. Within these datasets, eachinstance is linked to a set of labels. The presence of noisy, redundant, orirrelevant features in these datasets, along with the curse of dimensionality,poses challenges for multi-label classifiers. Feature selection (FS) proves tobe an effective strategy in enhancing classifier performance and addressingthese challenges. Yet, there is currently no existing distributed multi-labelFS method documented in the literature that is suitable for distributedmulti-label datasets within IoT environments. This paper introduces FMLFS, thefirst federated multi-label feature selection method. Here, mutual informationbetween features and labels serves as the relevancy metric, while thecorrelation distance between features, derived from mutual information andjoint entropy, is utilized as the redundancy measure. Following aggregation ofthese metrics on the edge server and employing Pareto-based bi-objective andcrowding distance strategies, the sorted features are subsequently sent back tothe IoT devices. The proposed method is evaluated through two scenarios: 1)transmitting reduced-size datasets to the edge server for centralizedclassifier usage, and 2) employing federated learning with reduced-sizedatasets. Evaluation across three metrics - performance, time complexity, andcommunication cost - demonstrates that FMLFS outperforms five other comparablemethods in the literature and provides a good trade-off on three real-worlddatasets.</description><author>Afsaneh Mahanipour, Hana Khamfroush</author><pubDate>Wed, 01 May 2024 14:58:28 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.00524v1</guid></item><item><title>CookingSense: A Culinary Knowledgebase with Multidisciplinary Assertions</title><link>http://arxiv.org/abs/2405.00523v1</link><description>This paper introduces CookingSense, a descriptive collection of knowledgeassertions in the culinary domain extracted from various sources, including webdata, scientific papers, and recipes, from which knowledge covering a broadrange of aspects is acquired. CookingSense is constructed through a series ofdictionary-based filtering and language model-based semantic filteringtechniques, which results in a rich knowledgebase of multidisciplinaryfood-related assertions. Additionally, we present FoodBench, a novel benchmarkto evaluate culinary decision support systems. From evaluations with FoodBench,we empirically prove that CookingSense improves the performance of retrievalaugmented language models. We also validate the quality and variety ofassertions in CookingSense through qualitative analysis.</description><author>Donghee Choi, Mogan Gim, Donghyeon Park, Mujeen Sung, Hyunjae Kim, Jaewoo Kang, Jihun Choi</author><pubDate>Wed, 01 May 2024 14:58:09 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.00523v1</guid></item><item><title>Navigating WebAI: Training Agents to Complete Web Tasks with Large Language Models and Reinforcement Learning</title><link>http://arxiv.org/abs/2405.00516v1</link><description>Recent advancements in language models have demonstrated remarkableimprovements in various natural language processing (NLP) tasks such as webnavigation. Supervised learning (SL) approaches have achieved impressiveperformance while utilizing significantly less training data compared toprevious methods. However, these SL-based models fall short when compared toreinforcement learning (RL) approaches, which have shown superior results. Inthis paper, we propose a novel approach that combines SL and RL techniques overthe MiniWoB benchmark to leverage the strengths of both methods. We alsoaddress a critical limitation in previous models' understanding of HTMLcontent, revealing a tendency to memorize target elements rather thancomprehend the underlying structure. To rectify this, we propose methods toenhance true understanding and present a new baseline of results. Ourexperiments demonstrate that our approach outperforms previous SL methods oncertain tasks using less data and narrows the performance gap with RL models,achieving 43.58\% average accuracy in SL and 36.69\% when combined with amultimodal RL approach. This study sets a new direction for future webnavigation and offers insights into the limitations and potential of languagemodeling for computer tasks.</description><author>Lucas-Andreï Thil, Mirela Popa, Gerasimos Spanakis</author><pubDate>Wed, 01 May 2024 14:51:45 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.00516v1</guid></item><item><title>GAD-Generative Learning for HD Map-Free Autonomous Driving</title><link>http://arxiv.org/abs/2405.00515v1</link><description>Deep-learning-based techniques have been widely adopted for autonomousdriving software stacks for mass production in recent years, focusing primarilyon perception modules, with some work extending this method to predictionmodules. However, the downstream planning and control modules are stilldesigned with hefty handcrafted rules, dominated by optimization-based methodssuch as quadratic programming or model predictive control. This results in aperformance bottleneck for autonomous driving systems in that corner casessimply cannot be solved by enumerating hand-crafted rules. We present adeep-learning-based approach that brings prediction, decision, and planningmodules together with the attempt to overcome the rule-based methods'deficiency in real-world applications of autonomous driving, especially forurban scenes. The DNN model we proposed is solely trained with 10 hours ofhuman driver data, and it supports all mass-production ADAS features availableon the market to date. This method is deployed onto a Jiyue test car with nomodification to its factory-ready sensor set and compute platform. thefeasibility, usability, and commercial potential are demonstrated in thisarticle.</description><author>Weijian Sun, Yanbo Jia, Qi Zeng, Zihao Liu, Jiang Liao, Yue Li, Xianfeng Li, Bolin Zhao</author><pubDate>Wed, 01 May 2024 14:51:39 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.00515v1</guid></item><item><title>Get Your Embedding Space in Order: Domain-Adaptive Regression for Forest Monitoring</title><link>http://arxiv.org/abs/2405.00514v1</link><description>Image-level regression is an important task in Earth observation, wherevisual domain and label shifts are a core challenge hampering generalization.However, cross-domain regression with remote sensing data remains understudieddue to the absence of suited datasets. We introduce a new dataset with aerialand satellite imagery in five countries with three forest-related regressiontasks. To match real-world applicative interests, we compare methods through arestrictive setup where no prior on the target domain is available duringtraining, and models are adapted with limited information during testing.Building on the assumption that ordered relationships generalize better, wepropose manifold diffusion for regression as a strong baseline for transductionin low-data regimes. Our comparison highlights the comparative advantages ofinductive and transductive methods in cross-domain regression.</description><author>Sizhuo Li, Dimitri Gominski, Martin Brandt, Xiaoye Tong, Philippe Ciais</author><pubDate>Wed, 01 May 2024 14:49:09 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.00514v1</guid></item><item><title>DressCode: Autoregressively Sewing and Generating Garments from Text Guidance</title><link>http://arxiv.org/abs/2401.16465v3</link><description>Apparel's significant role in human appearance underscores the importance ofgarment digitalization for digital human creation. Recent advances in 3Dcontent creation are pivotal for digital human creation. Nonetheless, garmentgeneration from text guidance is still nascent. We introduce a text-driven 3Dgarment generation framework, DressCode, which aims to democratize design fornovices and offer immense potential in fashion design, virtual try-on, anddigital human creation. We first introduce SewingGPT, a GPT-based architectureintegrating cross-attention with text-conditioned embedding to generate sewingpatterns with text guidance. We then tailor a pre-trained Stable Diffusion togenerate tile-based Physically-based Rendering (PBR) textures for the garments.By leveraging a large language model, our framework generates CG-friendlygarments through natural language interaction. It also facilitates patterncompletion and texture editing, streamlining the design process throughuser-friendly interaction. This framework fosters innovation by allowingcreators to freely experiment with designs and incorporate unique elements intotheir work. With comprehensive evaluations and comparisons with otherstate-of-the-art methods, our method showcases superior quality and alignmentwith input prompts. User studies further validate our high-quality renderingresults, highlighting its practical utility and potential in productionsettings. Our project page is https://IHe-KaiI.github.io/DressCode/.</description><author>Kai He, Kaixin Yao, Qixuan Zhang, Lingjie Liu, Jingyi Yu, Lan Xu</author><pubDate>Wed, 01 May 2024 14:48:22 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.16465v3</guid></item><item><title>Why You Should Not Trust Interpretations in Machine Learning: Adversarial Attacks on Partial Dependence Plots</title><link>http://arxiv.org/abs/2404.18702v2</link><description>The adoption of artificial intelligence (AI) across industries has led to thewidespread use of complex black-box models and interpretation tools fordecision making. This paper proposes an adversarial framework to uncover thevulnerability of permutation-based interpretation methods for machine learningtasks, with a particular focus on partial dependence (PD) plots. Thisadversarial framework modifies the original black box model to manipulate itspredictions for instances in the extrapolation domain. As a result, it producesdeceptive PD plots that can conceal discriminatory behaviors while preservingmost of the original model's predictions. This framework can produce multiplefooled PD plots via a single model. By using real-world datasets including anauto insurance claims dataset and COMPAS (Correctional Offender ManagementProfiling for Alternative Sanctions) dataset, our results show that it ispossible to intentionally hide the discriminatory behavior of a predictor andmake the black-box model appear neutral through interpretation tools like PDplots while retaining almost all the predictions of the original black-boxmodel. Managerial insights for regulators and practitioners are provided basedon the findings.</description><author>Xi Xin, Giles Hooker, Fei Huang</author><pubDate>Wed, 01 May 2024 14:44:45 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.18702v2</guid></item><item><title>Benchmarking Deep Learning Architectures for Urban Vegetation Point Cloud Semantic Segmentation from MLS</title><link>http://arxiv.org/abs/2306.10274v3</link><description>Vegetation is crucial for sustainable and resilient cities providing variousecosystem services and well-being of humans. However, vegetation is undercritical stress with rapid urbanization and expanding infrastructurefootprints. Consequently, mapping of this vegetation is essential in the urbanenvironment. Recently, deep learning for point cloud semantic segmentation hasshown significant progress. Advanced models attempt to obtain state-of-the-artperformance on benchmark datasets, comprising multiple classes and representingreal world scenarios. However, class specific segmentation with respect tovegetation points has not been explored. Therefore, selection of a deeplearning model for vegetation points segmentation is ambiguous. To address thisproblem, we provide a comprehensive assessment of point-based deep learningmodels for semantic segmentation of vegetation class. We have selected sevenrepresentative point-based models, namely PointCNN, KPConv (omni-supervised),RandLANet, SCFNet, PointNeXt, SPoTr and PointMetaBase. These models areinvestigated on three different datasets, specifically Chandigarh, Toronto3Dand Kerala, which are characterized by diverse nature of vegetation and varyingscene complexity combined with changing per-point features and class-wisecomposition. PointMetaBase and KPConv (omni-supervised) achieve the highestmIoU on the Chandigarh (95.24%) and Toronto3D datasets (91.26%), respectivelywhile PointCNN provides the highest mIoU on the Kerala dataset (85.68%). Thepaper develops a deeper insight, hitherto not reported, into the working ofthese models for vegetation segmentation and outlines the ingredients thatshould be included in a model specifically for vegetation segmentation. Thispaper is a step towards the development of a novel architecture for vegetationpoints segmentation.</description><author>Aditya Aditya, Bharat Lohani, Jagannath Aryal, Stephan Winter</author><pubDate>Wed, 01 May 2024 14:38:59 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.10274v3</guid></item><item><title>NeRF-Guided Unsupervised Learning of RGB-D Registration</title><link>http://arxiv.org/abs/2405.00507v1</link><description>This paper focuses on training a robust RGB-D registration model withoutground-truth pose supervision. Existing methods usually adopt a pairwisetraining strategy based on differentiable rendering, which enforces thephotometric and the geometric consistency between the two registered frames assupervision. However, this frame-to-frame framework suffers from poormulti-view consistency due to factors such as lighting changes, geometryocclusion and reflective materials. In this paper, we present NeRF-UR, a novelframe-to-model optimization framework for unsupervised RGB-D registration.Instead of frame-to-frame consistency, we leverage the neural radiance field(NeRF) as a global model of the scene and use the consistency between the inputand the NeRF-rerendered frames for pose optimization. This design cansignificantly improve the robustness in scenarios with poor multi-viewconsistency and provides better learning signal for the registration model.Furthermore, to bootstrap the NeRF optimization, we create a synthetic dataset,Sim-RGBD, through a photo-realistic simulator to warm up the registrationmodel. By first training the registration model on Sim-RGBD and laterunsupervisedly fine-tuning on real data, our framework enables distilling thecapability of feature extraction and registration from simulation to reality.Our method outperforms the state-of-the-art counterparts on two popular indoorRGB-D datasets, ScanNet and 3DMatch. Code and models will be released for paperreproduction.</description><author>Zhinan Yu, Zheng Qin, Yijie Tang, Yongjun Wang, Renjiao Yi, Chenyang Zhu, Kai Xu</author><pubDate>Wed, 01 May 2024 14:38:03 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.00507v1</guid></item><item><title>KVP10k : A Comprehensive Dataset for Key-Value Pair Extraction in Business Documents</title><link>http://arxiv.org/abs/2405.00505v1</link><description>In recent years, the challenge of extracting information from businessdocuments has emerged as a critical task, finding applications across numerousdomains. This effort has attracted substantial interest from both industry andacademy, highlighting its significance in the current technological landscape.Most datasets in this area are primarily focused on Key Information Extraction(KIE), where the extraction process revolves around extracting informationusing a specific, predefined set of keys. Unlike most existing datasets andbenchmarks, our focus is on discovering key-value pairs (KVPs) without relyingon predefined keys, navigating through an array of diverse templates andcomplex layouts. This task presents unique challenges, primarily due to theabsence of comprehensive datasets and benchmarks tailored for non-predeterminedKVP extraction. To address this gap, we introduce KVP10k , a new dataset andbenchmark specifically designed for KVP extraction. The dataset contains 10707richly annotated images. In our benchmark, we also introduce a new challengingtask that combines elements of KIE as well as KVP in a single task. KVP10k setsitself apart with its extensive diversity in data and richly detailedannotations, paving the way for advancements in the field of informationextraction from complex business documents.</description><author>Oshri Naparstek, Roi Pony, Inbar Shapira, Foad Abo Dahood, Ophir Azulai, Yevgeny Yaroker, Nadav Rubinstein, Maksym Lysak, Peter Staar, Ahmed Nassar, Nikolaos Livathinos, Christoph Auer, Elad Amrani, Idan Friedman, Orit Prince, Yevgeny Burshtein, Adi Raz Goldfarb, Udi Barzelay</author><pubDate>Wed, 01 May 2024 14:37:27 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.00505v1</guid></item><item><title>A Statistical-Modelling Approach to Feedforward Neural Network Model Selection</title><link>http://arxiv.org/abs/2207.04248v5</link><description>Feedforward neural networks (FNNs) can be viewed as non-linear regressionmodels, where covariates enter the model through a combination of weightedsummations and non-linear functions. Although these models have somesimilarities to the approaches used within statistical modelling, the majorityof neural network research has been conducted outside of the field ofstatistics. This has resulted in a lack of statistically-based methodology,and, in particular, there has been little emphasis on model parsimony.Determining the input layer structure is analogous to variable selection, whilethe structure for the hidden layer relates to model complexity. In practice,neural network model selection is often carried out by comparing models usingout-of-sample performance. However, in contrast, the construction of anassociated likelihood function opens the door to information-criteria-basedvariable and architecture selection. A novel model selection method, whichperforms both input- and hidden-node selection, is proposed using the Bayesianinformation criterion (BIC) for FNNs. The choice of BIC over out-of-sampleperformance as the model selection objective function leads to an increasedprobability of recovering the true model, while parsimoniously achievingfavourable out-of-sample performance. Simulation studies are used to evaluateand justify the proposed method, and applications on real data areinvestigated.</description><author>Andrew McInerney, Kevin Burke</author><pubDate>Wed, 01 May 2024 14:36:27 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2207.04248v5</guid></item><item><title>Semantic-guided modeling of spatial relation and object co-occurrence for indoor scene recognition</title><link>http://arxiv.org/abs/2305.12661v3</link><description>Exploring the semantic context in scene images is essential for indoor scenerecognition. However, due to the diverse intra-class spatial layouts and thecoexisting inter-class objects, modeling contextual relationships to adaptvarious image characteristics is a great challenge. Existing contextualmodeling methods for scene recognition exhibit two limitations: 1) Theytypically model only one kind of spatial relationship among objects withinscenes in an artificially predefined manner, with limited exploration ofdiverse spatial layouts. 2) They often overlook the differences in coexistingobjects across different scenes, suppressing scene recognition performance. Toovercome these limitations, we propose SpaCoNet, which simultaneously modelsSpatial relation and Co-occurrence of objects guided by semantic segmentation.Firstly, the Semantic Spatial Relation Module (SSRM) is constructed to modelscene spatial features. With the help of semantic segmentation, this moduledecouples the spatial information from the scene image and thoroughly exploresall spatial relationships among objects in an end-to-end manner. Secondly, bothspatial features from the SSRM and deep features from the Image FeatureExtraction Module are allocated to each object, so as to distinguish thecoexisting object across different scenes. Finally, utilizing thediscriminative features above, we design a Global-Local Dependency Module toexplore the long-range co-occurrence among objects, and further generate asemantic-guided feature representation for indoor scene recognition.Experimental results on three widely used scene datasets demonstrate theeffectiveness and generality of the proposed method.</description><author>Chuanxin Song, Hanbo Wu, Xin Ma</author><pubDate>Wed, 01 May 2024 14:29:25 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.12661v3</guid></item><item><title>Towards Learning Contrast Kinetics with Multi-Condition Latent Diffusion Models</title><link>http://arxiv.org/abs/2403.13890v2</link><description>Contrast agents in dynamic contrast enhanced magnetic resonance imaging allowto localize tumors and observe their contrast kinetics, which is essential forcancer characterization and respective treatment decision-making. However,contrast agent administration is not only associated with adverse health risks,but also restricted for patients during pregnancy, and for those with kidneymalfunction, or other adverse reactions. With contrast uptake as key biomarkerfor lesion malignancy, cancer recurrence risk, and treatment response, itbecomes pivotal to reduce the dependency on intravenous contrast agentadministration. To this end, we propose a multi-conditional latent diffusionmodel capable of acquisition time-conditioned image synthesis of DCE-MRItemporal sequences. To evaluate medical image synthesis, we additionallypropose and validate the Fr\'echet radiomics distance as an image qualitymeasure based on biomarker variability between synthetic and real imaging data.Our results demonstrate our method's ability to generate realisticmulti-sequence fat-saturated breast DCE-MRI and uncover the emerging potentialof deep learning based contrast kinetics simulation. We publicly share ouraccessible codebase at https://github.com/RichardObi/ccnet and provide auser-friendly library for Fr\'echet radiomics distance calculation athttps://pypi.org/project/frd-score.</description><author>Richard Osuala, Daniel Lang, Preeti Verma, Smriti Joshi, Apostolia Tsirikoglou, Grzegorz Skorupko, Kaisar Kushibar, Lidia Garrucho, Walter H. L. Pinaya, Oliver Diaz, Julia Schnabel, Karim Lekadir</author><pubDate>Wed, 01 May 2024 14:18:17 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.13890v2</guid></item><item><title>SeaTurtleID2022: A long-span dataset for reliable sea turtle re-identification</title><link>http://arxiv.org/abs/2211.10307v4</link><description>This paper introduces the first public large-scale, long-span dataset withsea turtle photographs captured in the wild --\href{https://www.kaggle.com/datasets/wildlifedatasets/seaturtleid2022}{SeaTurtleID2022}.The dataset contains 8729 photographs of 438 unique individuals collectedwithin 13 years, making it the longest-spanned dataset for animalre-identification. All photographs include various annotations, e.g., identity,encounter timestamp, and body parts segmentation masks. Instead of standard"random" splits, the dataset allows for two realistic and ecologicallymotivated splits: (i) a \textit{time-aware closed-set} with training,validation, and test data from different days/years, and (ii) a\textit{time-aware open-set} with new unknown individuals in test andvalidation sets. We show that time-aware splits are essential for benchmarkingre-identification methods, as random splits lead to performance overestimation.Furthermore, a baseline instance segmentation and re-identification performanceover various body parts is provided. Finally, an end-to-end system for seaturtle re-identification is proposed and evaluated. The proposed system basedon Hybrid Task Cascade for head instance segmentation and ArcFace-trainedfeature-extractor achieved an accuracy of 86.8\%.</description><author>Lukáš Adam, Vojtěch Čermák, Kostas Papafitsoros, Lukáš Picek</author><pubDate>Wed, 01 May 2024 14:16:09 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2211.10307v4</guid></item><item><title>Unbiased Learning to Rank Meets Reality: Lessons from Baidu's Large-Scale Search Dataset</title><link>http://arxiv.org/abs/2404.02543v2</link><description>Unbiased learning-to-rank (ULTR) is a well-established framework for learningfrom user clicks, which are often biased by the ranker collecting the data.While theoretically justified and extensively tested in simulation, ULTRtechniques lack empirical validation, especially on modern search engines. TheBaidu-ULTR dataset released for the WSDM Cup 2023, collected from Baidu'ssearch engine, offers a rare opportunity to assess the real-world performanceof prominent ULTR techniques. Despite multiple submissions during the WSDM Cup2023 and the subsequent NTCIR ULTRE-2 task, it remains unclear whether theobserved improvements stem from applying ULTR or other learning techniques. In this work, we revisit and extend the available experiments on theBaidu-ULTR dataset. We find that standard unbiased learning-to-rank techniquesrobustly improve click predictions but struggle to consistently improve rankingperformance, especially considering the stark differences obtained by choice ofranking loss and query-document features. Our experiments reveal that gains inclick prediction do not necessarily translate to enhanced ranking performanceon expert relevance annotations, implying that conclusions strongly depend onhow success is measured in this benchmark.</description><author>Philipp Hager, Romain Deffayet, Jean-Michel Renders, Onno Zoeter, Maarten de Rijke</author><pubDate>Wed, 01 May 2024 14:11:34 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.02543v2</guid></item><item><title>GOLD: Geometry Problem Solver with Natural Language Description</title><link>http://arxiv.org/abs/2405.00494v1</link><description>Addressing the challenge of automated geometry math problem-solving inartificial intelligence (AI) involves understanding multi-modal information andmathematics. Current methods struggle with accurately interpreting geometrydiagrams, which hinders effective problem-solving. To tackle this issue, wepresent the Geometry problem sOlver with natural Language Description (GOLD)model. GOLD enhances the extraction of geometric relations by separatelyprocessing symbols and geometric primitives within the diagram. Subsequently,it converts the extracted relations into natural language descriptions,efficiently utilizing large language models to solve geometry math problems.Experiments show that the GOLD model outperforms the Geoformer model, theprevious best method on the UniGeo dataset, by achieving accuracy improvementsof 12.7% and 42.1% in calculation and proving subsets. Additionally, itsurpasses the former best model on the PGPS9K and Geometry3K datasets, PGPSNet,by obtaining accuracy enhancements of 1.8% and 3.2%, respectively.</description><author>Jiaxin Zhang, Yashar Moshfeghi</author><pubDate>Wed, 01 May 2024 14:00:51 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.00494v1</guid></item><item><title>Unsupervised Representation Learning in Deep Reinforcement Learning: A Review</title><link>http://arxiv.org/abs/2208.14226v3</link><description>This review addresses the problem of learning abstract representations of themeasurement data in the context of Deep Reinforcement Learning (DRL). While thedata are often ambiguous, high-dimensional, and complex to interpret, manydynamical systems can be effectively described by a low-dimensional set ofstate variables. Discovering these state variables from the data is a crucialaspect for (i) improving the data efficiency, robustness, and generalization ofDRL methods, (ii) tackling the curse of dimensionality, and (iii) bringinginterpretability and insights into black-box DRL. This review provides acomprehensive and complete overview of unsupervised representation learning inDRL by describing the main Deep Learning tools used for learningrepresentations of the world, providing a systematic view of the method andprinciples, summarizing applications, benchmarks and evaluation strategies, anddiscussing open challenges and future directions.</description><author>Nicolò Botteghi, Mannes Poel, Christoph Brune</author><pubDate>Wed, 01 May 2024 14:00:39 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2208.14226v3</guid></item><item><title>Is Temperature the Creativity Parameter of Large Language Models?</title><link>http://arxiv.org/abs/2405.00492v1</link><description>Large language models (LLMs) are applied to all sorts of creative tasks, andtheir outputs vary from beautiful, to peculiar, to pastiche, into plainplagiarism. The temperature parameter of an LLM regulates the amount ofrandomness, leading to more diverse outputs; therefore, it is often claimed tobe the creativity parameter. Here, we investigate this claim using a narrativegeneration task with a predetermined fixed context, model and prompt.Specifically, we present an empirical analysis of the LLM output for differenttemperature values using four necessary conditions for creativity in narrativegeneration: novelty, typicality, cohesion, and coherence. We find thattemperature is weakly correlated with novelty, and unsurprisingly, moderatelycorrelated with incoherence, but there is no relationship with either cohesionor typicality. However, the influence of temperature on creativity is far morenuanced and weak than suggested by the "creativity parameter" claim; overallresults suggest that the LLM generates slightly more novel outputs astemperatures get higher. Finally, we discuss ideas to allow more controlled LLMcreativity, rather than relying on chance via changing the temperatureparameter.</description><author>Max Peeperkorn, Tom Kouwenhoven, Dan Brown, Anna Jordanous</author><pubDate>Wed, 01 May 2024 13:59:37 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.00492v1</guid></item><item><title>On the Relevance of Byzantine Robust Optimization Against Data Poisoning</title><link>http://arxiv.org/abs/2405.00491v1</link><description>The success of machine learning (ML) has been intimately linked with theavailability of large amounts of data, typically collected from heterogeneoussources and processed on vast networks of computing devices (also called {\emworkers}). Beyond accuracy, the use of ML in critical domains such ashealthcare and autonomous driving calls for robustness against {\em datapoisoning}and some {\em faulty workers}. The problem of {\em Byzantine ML}formalizes these robustness issues by considering a distributed ML environmentin which workers (storing a portion of the global dataset) can deviatearbitrarily from the prescribed algorithm. Although the problem has attracted alot of attention from a theoretical point of view, its practical importance foraddressing realistic faults (where the behavior of any worker is locallyconstrained) remains unclear. It has been argued that the seemingly weakerthreat model where only workers' local datasets get poisoned is morereasonable. We prove that, while tolerating a wider range of faulty behaviors,Byzantine ML yields solutions that are, in a precise sense, optimal even underthe weaker data poisoning threat model. Then, we study a generic data poisoningmodel wherein some workers have {\em fully-poisonous local data}, i.e., theirdatasets are entirely corruptible, and the remainders have {\empartially-poisonous local data}, i.e., only a fraction of their local datasetsis corruptible. We prove that Byzantine-robust schemes yield optimal solutionsagainst both these forms of data poisoning, and that the former is more harmfulwhen workers have {\em heterogeneous} local data.</description><author>Sadegh Farhadkhani, Rachid Guerraoui, Nirupam Gupta, Rafael Pinot</author><pubDate>Wed, 01 May 2024 13:57:14 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.00491v1</guid></item></channel></rss>