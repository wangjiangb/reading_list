<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/"><channel><title>Arxivfresh papers</title><link></link><description>Arxiv paper</description><language>en-US</language><lastBuildDate>Tue, 27 Aug 2024 13:00:34 GMT</lastBuildDate><generator>rfeed v1.0.0</generator><docs>https://github.com/svpino/rfeed/blob/master/README.md</docs><item><title>Advancing Humanoid Locomotion: Mastering Challenging Terrains with Denoising World Model Learning</title><link>http://arxiv.org/abs/2408.14472v1</link><description>Humanoid robots, with their human-like skeletal structure, are especiallysuited for tasks in human-centric environments. However, this structure isaccompanied by additional challenges in locomotion controller design,especially in complex real-world environments. As a result, existing humanoidrobots are limited to relatively simple terrains, either with model-basedcontrol or model-free reinforcement learning. In this work, we introduceDenoising World Model Learning (DWL), an end-to-end reinforcement learningframework for humanoid locomotion control, which demonstrates the world's firsthumanoid robot to master real-world challenging terrains such as snowy andinclined land in the wild, up and down stairs, and extremely uneven terrains.All scenarios run the same learned neural network with zero-shot sim-to-realtransfer, indicating the superior robustness and generalization capability ofthe proposed method.</description><author>Xinyang Gu, Yen-Jen Wang, Xiang Zhu, Chengming Shi, Yanjiang Guo, Yichen Liu, Jianyu Chen</author><pubDate>Mon, 26 Aug 2024 17:59:03 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.14472v1</guid></item><item><title>A Practitioner's Guide to Continual Multimodal Pretraining</title><link>http://arxiv.org/abs/2408.14471v1</link><description>Multimodal foundation models serve numerous applications at the intersectionof vision and language. Still, despite being pretrained on extensive data, theybecome outdated over time. To keep models updated, research into continualpretraining mainly explores scenarios with either (1) infrequent,indiscriminate updates on large-scale new data, or (2) frequent, sample-levelupdates. However, practical model deployment often operates in the gap betweenthese two limit cases, as real-world applications often demand adaptation tospecific subdomains, tasks or concepts -- spread over the entire, varying lifecycle of a model. In this work, we complement current perspectives on continualpretraining through a research test bed as well as provide comprehensiveguidance for effective continual model updates in such scenarios. We firstintroduce FoMo-in-Flux, a continual multimodal pretraining benchmark withrealistic compute constraints and practical deployment requirements,constructed over 63 datasets with diverse visual and semantic coverage. UsingFoMo-in-Flux, we explore the complex landscape of practical continualpretraining through multiple perspectives: (1) A data-centric investigation ofdata mixtures and stream orderings that emulate real-world deploymentsituations, (2) a method-centric investigation ranging from simple fine-tuningand traditional continual learning strategies to parameter-efficient updatesand model merging, (3) meta learning rate schedules and mechanistic designchoices, and (4) the influence of model and compute scaling. Together, ourinsights provide a practitioner's guide to continual multimodal pretraining forreal-world deployment. Our benchmark and code is here:https://github.com/ExplainableML/fomo_in_flux.</description><author>Karsten Roth, Vishaal Udandarao, Sebastian Dziadzio, Ameya Prabhu, Mehdi Cherti, Oriol Vinyals, Olivier HÃ©naff, Samuel Albanie, Matthias Bethge, Zeynep Akata</author><pubDate>Mon, 26 Aug 2024 17:59:01 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.14471v1</guid></item><item><title>Step-by-Step Unmasking for Parameter-Efficient Fine-tuning of Large Language Models</title><link>http://arxiv.org/abs/2408.14470v1</link><description>Fine-tuning large language models (LLMs) on downstream tasks requiressubstantial computational resources. A class of parameter-efficient fine-tuning(PEFT) aims to mitigate these computational challenges by selectivelyfine-tuning only a small fraction of the model parameters. Althoughcomputationally efficient, these techniques often fail to match the performanceof fully fine-tuned models, primarily due to inherent biases introduced duringparameter selection. Traditional selective PEFT techniques use a fixed set ofparameters based on a predefined budget (a process also known as unmasking),failing to capture parameter importance dynamically and often ending upexceeding the budget. We introduce $\text{ID}^3$, a novel selective PEFT methodthat calculates parameter importance continually and dynamically unmasksparameters by balancing exploration and exploitation in parameter selection.Our empirical study on 15 tasks spanning natural language understanding andgenerative tasks demonstrates the effectiveness of our method compared tofixed-masking-based PEFT techniques. We analytically show that $\text{ID}^3$reduces the number of gradient updates by a factor of two, enhancingcomputational efficiency. $\text{ID}^3$ is robust to random initialization ofneurons and, therefore, can be seamlessly integrated into existing additive andreparametrization-based PEFT modules such as adapters and LoRA for dynamicsparsification.</description><author>Aradhye Agarwal, Suhas K Ramesh, Ayan Sengupta, Tanmoy Chakraborty</author><pubDate>Mon, 26 Aug 2024 17:58:53 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.14470v1</guid></item><item><title>Grounded Multi-Hop VideoQA in Long-Form Egocentric Videos</title><link>http://arxiv.org/abs/2408.14469v1</link><description>This paper considers the problem of Multi-Hop Video Question Answering(MH-VidQA) in long-form egocentric videos. This task not only requires toanswer visual questions, but also to localize multiple relevant time intervalswithin the video as visual evidences. We develop an automated pipeline tocreate multi-hop question-answering pairs with associated temporal evidence,enabling to construct a large-scale dataset for instruction-tuning. To monitorthe progress of this new task, we further curate a high-quality benchmark,MultiHop-EgoQA, with careful manual verification and refinement. Experimentalresults reveal that existing multi-modal systems exhibit inadequate multi-hopgrounding and reasoning abilities, resulting in unsatisfactory performance. Wethen propose a novel architecture, termed as Grounding Scattered Evidence withLarge Language Model (GeLM), that enhances multi-modal large language models(MLLMs) by incorporating a grounding module to retrieve temporal evidence fromvideos using flexible grounding tokens. Trained on our visual instruction data,GeLM demonstrates improved multi-hop grounding and reasoning capabilities,setting a new baseline for this challenging task. Furthermore, when trained onthird-person view videos, the same architecture also achieves state-of-the-artperformance on the single-hop VidQA benchmark, ActivityNet-RTL, demonstratingits effectiveness.</description><author>Qirui Chen, Shangzhe Di, Weidi Xie</author><pubDate>Mon, 26 Aug 2024 17:58:47 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.14469v1</guid></item><item><title>K-Sort Arena: Efficient and Reliable Benchmarking for Generative Models via K-wise Human Preferences</title><link>http://arxiv.org/abs/2408.14468v1</link><description>The rapid advancement of visual generative models necessitates efficient andreliable evaluation methods. Arena platform, which gathers user votes on modelcomparisons, can rank models with human preferences. However, traditional Arenamethods, while established, require an excessive number of comparisons forranking to converge and are vulnerable to preference noise in voting,suggesting the need for better approaches tailored to contemporary evaluationchallenges. In this paper, we introduce K-Sort Arena, an efficient and reliableplatform based on a key insight: images and videos possess higher perceptualintuitiveness than texts, enabling rapid evaluation of multiple samplessimultaneously. Consequently, K-Sort Arena employs K-wise comparisons, allowingK models to engage in free-for-all competitions, which yield much richerinformation than pairwise comparisons. To enhance the robustness of the system,we leverage probabilistic modeling and Bayesian updating techniques. We proposean exploration-exploitation-based matchmaking strategy to facilitate moreinformative comparisons. In our experiments, K-Sort Arena exhibits 16.3x fasterconvergence compared to the widely used ELO algorithm. To further validate thesuperiority and obtain a comprehensive leaderboard, we collect human feedbackvia crowdsourced evaluations of numerous cutting-edge text-to-image andtext-to-video models. Thanks to its high efficiency, K-Sort Arena cancontinuously incorporate emerging models and update the leaderboard withminimal votes. Our project has undergone several months of internal testing andis now available at https://huggingface.co/spaces/ksort/K-Sort-Arena</description><author>Zhikai Li, Xuewen Liu, Dongrong Fu, Jianquan Li, Qingyi Gu, Kurt Keutzer, Zhen Dong</author><pubDate>Mon, 26 Aug 2024 17:58:20 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.14468v1</guid></item><item><title>Explicit Inductive Inference using Large Language Models</title><link>http://arxiv.org/abs/2408.14467v1</link><description>Large Language Models (LLMs) are reported to hold undesirable attestationbias on inference tasks: when asked to predict if a premise P entails ahypothesis H, instead of considering H's conditional truthfulness entailed byP, LLMs tend to use the out-of-context truth label of H as a fragile proxy. Inthis paper, we propose a pipeline that exploits this bias to do explicitinductive inference. Our pipeline uses an LLM to transform a premise into a setof attested alternatives, and then aggregate answers of the derived newentailment inquiries to support the original inference prediction. On adirectional predicate entailment benchmark, we demonstrate that by applyingthis simple pipeline, we can improve the overall performance of LLMs oninference and substantially alleviate the impact of their attestation bias.</description><author>Tianyang Liu, Tianyi Li, Liang Cheng, Mark Steedman</author><pubDate>Mon, 26 Aug 2024 17:58:17 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.14467v1</guid></item><item><title>A domain decomposition-based autoregressive deep learning model for unsteady and nonlinear partial differential equations</title><link>http://arxiv.org/abs/2408.14461v1</link><description>In this paper, we propose a domain-decomposition-based deep learning (DL)framework, named transient-CoMLSim, for accurately modeling unsteady andnonlinear partial differential equations (PDEs). The framework consists of twokey components: (a) a convolutional neural network (CNN)-based autoencoderarchitecture and (b) an autoregressive model composed of fully connectedlayers. Unlike existing state-of-the-art methods that operate on the entirecomputational domain, our CNN-based autoencoder computes a lower-dimensionalbasis for solution and condition fields represented on subdomains. Timesteppingis performed entirely in the latent space, generating embeddings of thesolution variables from the time history of embeddings of solution andcondition variables. This approach not only reduces computational complexitybut also enhances scalability, making it well-suited for large-scalesimulations. Furthermore, to improve the stability of our rollouts, we employ acurriculum learning (CL) approach during the training of the autoregressivemodel. The domain-decomposition strategy enables scaling to out-of-distributiondomain sizes while maintaining the accuracy of predictions -- a feature noteasily integrated into popular DL-based approaches for physics simulations. Webenchmark our model against two widely-used DL architectures, Fourier NeuralOperator (FNO) and U-Net, and demonstrate that our framework outperforms themin terms of accuracy, extrapolation to unseen timesteps, and stability for awide range of use cases.</description><author>Sheel Nidhan, Haoliang Jiang, Lalit Ghule, Clancy Umphrey, Rishikesh Ranade, Jay Pathak</author><pubDate>Mon, 26 Aug 2024 17:50:47 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.14461v1</guid></item><item><title>LLM Pruning and Distillation in Practice: The Minitron Approach</title><link>http://arxiv.org/abs/2408.11796v2</link><description>We present a comprehensive report on compressing the Llama 3.1 8B and MistralNeMo 12B models to 4B and 8B parameters, respectively, using pruning anddistillation. We explore two distinct pruning strategies: (1) depth pruning and(2) joint hidden/attention/MLP (width) pruning, and evaluate the results oncommon benchmarks from the LM Evaluation Harness. The models are then alignedwith NeMo Aligner and tested in instruct-tuned versions. This approach producesa compelling 4B model from Llama 3.1 8B and a state-of-the-artMistral-NeMo-Minitron-8B (MN-Minitron-8B for brevity) model from Mistral NeMo12B. We found that with no access to the original data, it is beneficial toslightly fine-tune teacher models on the distillation dataset. We open-sourceour base model weights on Hugging Face with a permissive license.</description><author>Sharath Turuvekere Sreenivas, Saurav Muralidharan, Raviraj Joshi, Marcin Chochowski, Mostofa Patwary, Mohammad Shoeybi, Bryan Catanzaro, Jan Kautz, Pavlo Molchanov</author><pubDate>Mon, 26 Aug 2024 17:50:46 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.11796v2</guid></item><item><title>Dense Center-Direction Regression for Object Counting and Localization with Point Supervision</title><link>http://arxiv.org/abs/2408.14457v1</link><description>Object counting and localization problems are commonly addressed with pointsupervised learning, which allows the use of less labor-intensive pointannotations. However, learning based on point annotations poses challenges dueto the high imbalance between the sets of annotated and unannotated pixels,which is often treated with Gaussian smoothing of point annotations and focalloss. However, these approaches still focus on the pixels in the immediatevicinity of the point annotations and exploit the rest of the data onlyindirectly. In this work, we propose a novel approach termed CeDiRNet forpoint-supervised learning that uses a dense regression of directions pointingtowards the nearest object centers, i.e. center-directions. This providesgreater support for each center point arising from many surrounding pixelspointing towards the object center. We propose a formulation ofcenter-directions that allows the problem to be split into the domain-specificdense regression of center-directions and the final localization task based ona small, lightweight, and domain-agnostic localization network that can betrained with synthetic data completely independent of the target domain. Wedemonstrate the performance of the proposed method on six different datasetsfor object counting and localization, and show that it outperforms the existingstate-of-the-art methods. The code is accessible on GitHub athttps://github.com/vicoslab/CeDiRNet.git.</description><author>Domen Tabernik, Jon MuhoviÄ, Danijel SkoÄaj</author><pubDate>Mon, 26 Aug 2024 17:49:27 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.14457v1</guid></item><item><title>Center Direction Network for Grasping Point Localization on Cloths</title><link>http://arxiv.org/abs/2408.14456v1</link><description>Object grasping is a fundamental challenge in robotics and computer vision,critical for advancing robotic manipulation capabilities. Deformable objects,like fabrics and cloths, pose additional challenges due to their non-rigidnature. In this work, we introduce CeDiRNet-3DoF, a deep-learning model forgrasp point detection, with a particular focus on cloth objects. CeDiRNet-3DoFemploys center direction regression alongside a localization network, attainingfirst place in the perception task of ICRA 2023's Cloth Manipulation Challenge.Recognizing the lack of standardized benchmarks in the literature that hindereffective method comparison, we present the ViCoS Towel Dataset. This extensivebenchmark dataset comprises 8,000 real and 12,000 synthetic images, serving asa robust resource for training and evaluating contemporary data-drivendeep-learning approaches. Extensive evaluation revealed CeDiRNet-3DoF'srobustness in real-world performance, outperforming state-of-the-art methods,including the latest transformer-based models. Our work bridges a crucial gap,offering a robust solution and benchmark for cloth grasping in computer visionand robotics. Code and dataset are available at:https://github.com/vicoslab/CeDiRNet-3DoF</description><author>Domen Tabernik, Jon MuhoviÄ, Matej Urbas, Danijel SkoÄaj</author><pubDate>Mon, 26 Aug 2024 17:49:05 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.14456v1</guid></item><item><title>Reconstructing physiological signals from fMRI across the adult lifespan</title><link>http://arxiv.org/abs/2408.14453v1</link><description>Interactions between the brain and body are of fundamental importance forhuman behavior and health. Functional magnetic resonance imaging (fMRI)captures whole-brain activity noninvasively, and modeling how fMRI signalsinteract with physiological dynamics of the body can provide new insight intobrain function and offer potential biomarkers of disease. However,physiological recordings are not always possible to acquire since they requireextra equipment and setup, and even when they are, the recorded physiologicalsignals may contain substantial artifacts. To overcome this limitation, machinelearning models have been proposed to directly extract features of respiratoryand cardiac activity from resting-state fMRI signals. To date, such work hasbeen carried out only in healthy young adults and in a pediatric population,leaving open questions about the efficacy of these approaches on older adults.Here, we propose a novel framework that leverages Transformer-basedarchitectures for reconstructing two key physiological signals - low-frequencyrespiratory volume (RV) and heart rate (HR) fluctuations - from fMRI data, andtest these models on a dataset of individuals aged 36-89 years old. Ourframework outperforms previously proposed approaches (attaining mediancorrelations between predicted and measured signals of r ~ .698 for RV and r ~.618 for HR), indicating the potential of leveraging attention mechanisms tomodel fMRI-physiological signal relationships. We also evaluate several modeltraining and fine-tuning strategies, and find that incorporating young-adultdata during training improves the performance when predicting physiologicalsignals in the aging cohort. Overall, our approach successfully infers keyphysiological variables directly from fMRI data from individuals across a widerange of the adult lifespan.</description><author>Shiyu Wang, Ziyuan Xu, Yamin Li, Mara Mather, Roza G. Bayrak, Catie Chang</author><pubDate>Mon, 26 Aug 2024 17:48:42 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.14453v1</guid></item><item><title>Symmetry &amp; Critical Points</title><link>http://arxiv.org/abs/2408.14445v1</link><description>Critical points of an invariant function may or may not be symmetric. Weprove, however, that if a symmetric critical point exists, those adjacent to itare generically symmetry breaking. This mathematical mechanism is shown tocarry important implications for our ability to efficiently minimize invariantnonconvex functions, in particular those associated with neural networks.</description><author>Yossi Arjevani</author><pubDate>Mon, 26 Aug 2024 17:36:51 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.14445v1</guid></item><item><title>Temporal Ensemble Logic</title><link>http://arxiv.org/abs/2408.14443v1</link><description>We introduce Temporal Ensemble Logic (TEL), a monadic, first-order modallogic for linear-time temporal reasoning. TEL includes primitive temporalconstructs such as ``always up to $t$ time later'' ($\Box_t$), ``sometimesbefore $t$ time in the future'' ($\Diamond_t$), and ``$t$-time later''$\varphi_t$. TEL has been motivated from the requirement for rigor andreproducibility for cohort specification and discovery in clinical andpopulation health research, to fill a gap in formalizing temporal reasoning inbiomedicine. In this paper, we first introduce TEL in a general set up, withdiscrete and dense time as special cases. We then focus on the theoreticaldevelopment of discrete TEL on the temporal domain of positive integers$\mathbb{N}^+$, denoted as ${\rm TEL}_{\mathbb{N}^+}$. ${\rmTEL}_{\mathbb{N}^+}$ is strictly more expressive than the standard monadicsecond order logic, characterized by B\"{u}chi automata. We present its formalsemantics, a proof system, and provide a proof for the undecidability of thesatisfiability of ${\rm TEL}_{\mathbb{N}^+}$. We also discuss expressivenessand decidability fragments for ${\rm TEL}_{\mathbb{N}^+}$, followed byillustrative applications.</description><author>Guo-Qiang Zhang</author><pubDate>Mon, 26 Aug 2024 17:36:25 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.14443v1</guid></item><item><title>Model Parallel Training and Transfer Learning for Convolutional Neural Networks by Domain Decomposition</title><link>http://arxiv.org/abs/2408.14442v1</link><description>Deep convolutional neural networks (CNNs) have been shown to be verysuccessful in a wide range of image processing applications. However, due totheir increasing number of model parameters and an increasing availability oflarge amounts of training data, parallelization strategies to efficiently traincomplex CNNs are necessary. In previous work by the authors, a novel modelparallel CNN architecture was proposed which is loosely inspired by domaindecomposition. In particular, the novel network architecture is based on adecomposition of the input data into smaller subimages. For each of thesesubimages, local CNNs with a proportionally smaller number of parameters aretrained in parallel and the resulting local classifications are then aggregatedin a second step by a dense feedforward neural network (DNN). In the presentwork, we compare the resulting CNN-DNN architecture to less costly alternativesto combine the local classifications into a final, global decision.Additionally, we investigate the performance of the CNN-DNN trained as onecoherent model as well as using a transfer learning strategy, where theparameters of the pre-trained local CNNs are used as initial values for asubsequently trained global coherent CNN-DNN model.</description><author>Axel Klawonn, Martin Lanser, Janine Weber</author><pubDate>Mon, 26 Aug 2024 17:35:01 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.14442v1</guid></item><item><title>Beyond Scale: The Diversity Coefficient as a Data Quality Metric for Variability in Natural Language Data</title><link>http://arxiv.org/abs/2306.13840v3</link><description>Current trends in pre-training Large Language Models (LLMs) primarily focuson the scaling of model and dataset size. While the quality of pre-trainingdata is considered an important factor for training powerful LLMs, it remains anebulous concept that has not been rigorously characterized. To this end, wepropose a formalization of one key aspect of data quality -- measuring thevariability of natural language data -- specifically via a measure we call thediversity coefficient. Our empirical analysis shows that the proposed diversitycoefficient aligns with the intuitive properties of diversity and variability,e.g., it increases as the number of latent concepts increases. Then, we measurethe diversity coefficient of publicly available pre-training datasets anddemonstrate that their formal diversity is high compared to theoretical lowerand upper bounds. Finally, we conduct a comprehensive set of controlledinterventional experiments with GPT-2 and LLaMAv2 that demonstrate thediversity coefficient of pre-training data characterizes useful aspects ofdownstream model evaluation performance -- totaling 44 models of various sizes(51M to 7B parameters). We conclude that our formal notion of diversity is animportant aspect of data quality that captures variability and causally leadsto improved evaluation performance.</description><author>Brando Miranda, Alycia Lee, Sudharsan Sundar, Allison Casasola, Sanmi Koyejo</author><pubDate>Mon, 26 Aug 2024 17:34:44 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.13840v3</guid></item><item><title>Attend-Fusion: Efficient Audio-Visual Fusion for Video Classification</title><link>http://arxiv.org/abs/2408.14441v1</link><description>Exploiting both audio and visual modalities for video classification is achallenging task, as the existing methods require large model architectures,leading to high computational complexity and resource requirements. Smallerarchitectures, on the other hand, struggle to achieve optimal performance. Inthis paper, we propose Attend-Fusion, an audio-visual (AV) fusion approach thatintroduces a compact model architecture specifically designed to captureintricate audio-visual relationships in video data. Through extensiveexperiments on the challenging YouTube-8M dataset, we demonstrate thatAttend-Fusion achieves an F1 score of 75.64\% with only 72M parameters, whichis comparable to the performance of larger baseline models such asFully-Connected Late Fusion (75.96\% F1 score, 341M parameters). Attend-Fusionachieves similar performance to the larger baseline model while reducing themodel size by nearly 80\%, highlighting its efficiency in terms of modelcomplexity. Our work demonstrates that the Attend-Fusion model effectivelycombines audio and visual information for video classification, achievingcompetitive performance with significantly reduced model size. This approachopens new possibilities for deploying high-performance video understandingsystems in resource-constrained environments across various applications.</description><author>Mahrukh Awan, Asmar Nadeem, Muhammad Junaid Awan, Armin Mustafa, Syed Sameed Husain</author><pubDate>Mon, 26 Aug 2024 17:33:47 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.14441v1</guid></item><item><title>Improved Uncertainty Estimation of Graph Neural Network Potentials Using Engineered Latent Space Distances</title><link>http://arxiv.org/abs/2407.10844v2</link><description>Graph neural networks (GNNs) have been shown to be astonishingly capablemodels for molecular property prediction, particularly as surrogates forexpensive density functional theory calculations of relaxed energy for novelmaterial discovery. However, one limitation of GNNs in this context is the lackof useful uncertainty prediction methods, as this is critical to the materialdiscovery pipeline. In this work, we show that uncertainty quantification forrelaxed energy calculations is more complex than uncertainty quantification forother kinds of molecular property prediction, due to the effect that structureoptimizations have on the error distribution. We propose that distribution-freetechniques are more useful tools for assessing calibration, recalibrating, anddeveloping uncertainty prediction methods for GNNs performing relaxed energycalculations. We also develop a relaxed energy task for evaluating uncertaintymethods for equivariant GNNs, based on distribution-free recalibration andusing the Open Catalyst Project dataset. We benchmark a set of popularuncertainty prediction methods on this task, and show that latent distancemethods, with our novel improvements, are the most well-calibrated andeconomical approach for relaxed energy calculations. Finally, we demonstratethat our latent space distance method produces results which align with ourexpectations on a clustering example, and on specific equation of state andadsorbate coverage examples from outside the training dataset.</description><author>Joseph Musielewicz, Janice Lan, Matt Uyttendaele, John R. Kitchin</author><pubDate>Mon, 26 Aug 2024 17:31:16 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.10844v2</guid></item><item><title>Tracing Privacy Leakage of Language Models to Training Data via Adjusted Influence Functions</title><link>http://arxiv.org/abs/2408.10468v3</link><description>The responses generated by Large Language Models (LLMs) can include sensitiveinformation from individuals and organizations, leading to potential privacyleakage. This work implements Influence Functions (IFs) to trace privacyleakage back to the training data, thereby mitigating privacy concerns ofLanguage Models (LMs). However, we notice that current IFs struggle toaccurately estimate the influence of tokens with large gradient norms,potentially overestimating their influence. When tracing the most influentialsamples, this leads to frequently tracing back to samples with large gradientnorm tokens, overshadowing the actual most influential samples even if theirinfluences are well estimated. To address this issue, we propose HeuristicallyAdjusted IF (HAIF), which reduces the weight of tokens with large gradientnorms, thereby significantly improving the accuracy of tracing the mostinfluential samples. To establish easily obtained groundtruth for tracingprivacy leakage, we construct two datasets, PII-E and PII-CR, representing twodistinct scenarios: one with identical text in the model outputs andpre-training data, and the other where models leverage their reasoningabilities to generate text divergent from pre-training data. HAIF significantlyimproves tracing accuracy, enhancing it by 20.96% to 73.71% on the PII-Edataset and 3.21% to 45.93% on the PII-CR dataset, compared to the best SOTAIFs against various GPT-2 and QWen-1.5 models. HAIF also outperforms SOTA IFson real-world pretraining data CLUECorpus2020, demonstrating strong robustnessregardless prompt and response lengths.</description><author>Jinxin Liu, Zao Yang</author><pubDate>Mon, 26 Aug 2024 17:28:23 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.10468v3</guid></item><item><title>Evaluating Large Language Models on Spatial Tasks: A Multi-Task Benchmarking Study</title><link>http://arxiv.org/abs/2408.14438v1</link><description>The advent of large language models such as ChatGPT, Gemini, and others hasunderscored the importance of evaluating their diverse capabilities, rangingfrom natural language understanding to code generation. However, theirperformance on spatial tasks has not been comprehensively assessed. This studyaddresses this gap by introducing a novel multi-task spatial evaluationdataset, designed to systematically explore and compare the performance ofseveral advanced models on spatial tasks. The dataset encompasses twelvedistinct task types, including spatial understanding and path planning, eachwith verified, accurate answers. We evaluated multiple models, includingOpenAI's gpt-3.5-turbo, gpt-4o, and ZhipuAI's glm-4, through a two-phasetesting approach. Initially, we conducted zero-shot testing, followed bycategorizing the dataset by difficulty and performing prompt tuning tests.Results indicate that gpt-4o achieved the highest overall accuracy in the firstphase, with an average of 71.3%. Although moonshot-v1-8k slightlyunderperformed overall, it surpassed gpt-4o in place name recognition tasks.The study also highlights the impact of prompt strategies on model performancein specific tasks. For example, the Chain-of-Thought (COT) strategy increasedgpt-4o's accuracy in path planning from 12.4% to 87.5%, while a one-shotstrategy enhanced moonshot-v1-8k's accuracy in mapping tasks from 10.1% to76.3%.</description><author>Liuchang Xu Shuo Zhao, Qingming Lin, Luyao Chen, Qianqian Luo, Sensen Wu, Xinyue Ye, Hailin Feng, Zhenhong Du</author><pubDate>Mon, 26 Aug 2024 17:25:16 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.14438v1</guid></item><item><title>Sparsity-Aware Hardware-Software Co-Design of Spiking Neural Networks: An Overview</title><link>http://arxiv.org/abs/2408.14437v1</link><description>Spiking Neural Networks (SNNs) are inspired by the sparse and event-drivennature of biological neural processing, and offer the potential forultra-low-power artificial intelligence. However, realizing their efficiencybenefits requires specialized hardware and a co-design approach thateffectively leverages sparsity. We explore the hardware-software co-design ofsparse SNNs, examining how sparsity representation, hardware architectures, andtraining techniques influence hardware efficiency. We analyze the impact ofstatic and dynamic sparsity, discuss the implications of different neuronmodels and encoding schemes, and investigate the need for adaptability inhardware designs. Our work aims to illuminate the path towards embeddedneuromorphic systems that fully exploit the computational advantages of sparseSNNs.</description><author>Ilkin Aliyev, Kama Svoboda, Tosiron Adegbija, Jean-Marc Fellous</author><pubDate>Mon, 26 Aug 2024 17:22:11 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.14437v1</guid></item><item><title>Social perception of faces in a vision-language model</title><link>http://arxiv.org/abs/2408.14435v1</link><description>We explore social perception of human faces in CLIP, a widely usedopen-source vision-language model. To this end, we compare the similarity inCLIP embeddings between different textual prompts and a set of face images. Ourtextual prompts are constructed from well-validated social psychology termsdenoting social perception. The face images are synthetic and aresystematically and independently varied along six dimensions: the legallyprotected attributes of age, gender, and race, as well as facial expression,lighting, and pose. Independently and systematically manipulating faceattributes allows us to study the effect of each on social perception andavoids confounds that can occur in wild-collected data due to uncontrolledsystematic correlations between attributes. Thus, our findings are experimentalrather than observational. Our main findings are three. First, while CLIP istrained on the widest variety of images and texts, it is able to makefine-grained human-like social judgments on face images. Second, age, gender,and race do systematically impact CLIP's social perception of faces, suggestingan undesirable bias in CLIP vis-a-vis legally protected attributes. Moststrikingly, we find a strong pattern of bias concerning the faces of Blackwomen, where CLIP produces extreme values of social perception across differentages and facial expressions. Third, facial expression impacts social perceptionmore than age and lighting as much as age. The last finding predicts thatstudies that do not control for unprotected visual attributes may reach thewrong conclusions on bias. Our novel method of investigation, which is foundedon the social psychology literature and on the experiments involving themanipulation of individual attributes, yields sharper and more reliableobservations than previous observational methods and may be applied to studybiases in any vision-language model.</description><author>Carina I. Hausladen, Manuel Knott, Colin F. Camerer, Pietro Perona</author><pubDate>Mon, 26 Aug 2024 17:21:54 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.14435v1</guid></item><item><title>Employing Artificial Intelligence to Steer Exascale Workflows with Colmena</title><link>http://arxiv.org/abs/2408.14434v1</link><description>Computational workflows are a common class of application on supercomputers,yet the loosely coupled and heterogeneous nature of workflows often fails totake full advantage of their capabilities. We created Colmena to leverage themassive parallelism of a supercomputer by using Artificial Intelligence (AI) tolearn from and adapt a workflow as it executes. Colmena allows scientists todefine how their application should respond to events (e.g., task completion)as a series of cooperative agents. In this paper, we describe the design ofColmena, the challenges we overcame while deploying applications on exascalesystems, and the science workflows we have enhanced through interweaving AI.The scaling challenges we discuss include developing steering strategies thatmaximize node utilization, introducing data fabrics that reduce communicationoverhead of data-intensive tasks, and implementing workflow tasks that cachecostly operations between invocations. These innovations coupled with a varietyof application patterns accessible through our agent-based steering model haveenabled science advances in chemistry, biophysics, and materials science usingdifferent types of AI. Our vision is that Colmena will spur creative solutionsthat harness AI across many domains of scientific computing.</description><author>Logan Ward, J. Gregory Pauloski, Valerie Hayot-Sasson, Yadu Babuji, Alexander Brace, Ryan Chard, Kyle Chard, Rajeev Thakur, Ian Foster</author><pubDate>Mon, 26 Aug 2024 17:21:19 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.14434v1</guid></item><item><title>Contextual Bandit with Herding Effects: Algorithms and Recommendation Applications</title><link>http://arxiv.org/abs/2408.14432v1</link><description>Contextual bandits serve as a fundamental algorithmic framework foroptimizing recommendation decisions online. Though extensive attention has beenpaid to tailoring contextual bandits for recommendation applications, the"herding effects" in user feedback have been ignored. These herding effectsbias user feedback toward historical ratings, breaking down the assumption ofunbiased feedback inherent in contextual bandits. This paper develops a novelvariant of the contextual bandit that is tailored to address the feedback biascaused by the herding effects. A user feedback model is formulated to capturethis feedback bias. We design the TS-Conf (Thompson Sampling under Conformity)algorithm, which employs posterior sampling to balance the exploration andexploitation tradeoff. We prove an upper bound for the regret of the algorithm,revealing the impact of herding effects on learning speed. Extensiveexperiments on datasets demonstrate that TS-Conf outperforms four benchmarkalgorithms. Analysis reveals that TS-Conf effectively mitigates the negativeimpact of herding effects, resulting in faster learning and improvedrecommendation accuracy.</description><author>Luyue Xu, Liming Wang, Hong Xie, Mingqiang Zhou</author><pubDate>Mon, 26 Aug 2024 17:20:34 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.14432v1</guid></item><item><title>Few-Shot 3D Volumetric Segmentation with Multi-Surrogate Fusion</title><link>http://arxiv.org/abs/2408.14427v1</link><description>Conventional 3D medical image segmentation methods typically require learningheavy 3D networks (e.g., 3D-UNet), as well as large amounts of in-domain datawith accurate pixel/voxel-level labels to avoid overfitting. These solutionsare thus extremely time- and labor-expensive, but also may easily fail togeneralize to unseen objects during training. To alleviate this issue, wepresent MSFSeg, a novel few-shot 3D segmentation framework with a lightweightmulti-surrogate fusion (MSF). MSFSeg is able to automatically segment unseen 3Dobjects/organs (during training) provided with one or a few annotated 2D slicesor 3D sequence segments, via learning dense query-support organ/lesion anatomycorrelations across patient populations. Our proposed MSF module minescomprehensive and diversified morphology correlations between unlabeled and thefew labeled slices/sequences through multiple designated surrogates, making itable to generate accurate cross-domain 3D segmentation masks given annotatedslices or sequences. We demonstrate the effectiveness of our proposed frameworkby showing superior performance on conventional few-shot segmentationbenchmarks compared to prior art, and remarkable cross-domain cross-volumesegmentation performance on proprietary 3D segmentation datasets forchallenging entities, i.e., tubular structures, with only limited 2D or 3Dlabels.</description><author>Meng Zheng, Benjamin Planche, Zhongpai Gao, Terrence Chen, Richard J. Radke, Ziyan Wu</author><pubDate>Mon, 26 Aug 2024 17:15:37 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.14427v1</guid></item><item><title>Tackling GenAI Copyright Issues: Originality Estimation and Genericization</title><link>http://arxiv.org/abs/2406.03341v4</link><description>The rapid progress of generative AI technology has sparked significantcopyright concerns, leading to numerous lawsuits filed against AI developers.While various techniques for mitigating copyright issues have been studied,significant risks remain. Here, we propose a genericization method thatmodifies the outputs of a generative model to make them more generic and lesslikely to infringe copyright. To achieve this, we introduce a metric forquantifying the level of originality of data in a manner that is consistentwith the legal framework. This metric can be practically estimated by drawingsamples from a generative model, which is then used for the genericizationprocess. As a practical implementation, we introduce PREGen, which combines ourgenericization method with an existing mitigation technique. Experimentsdemonstrate that our genericization method successfully modifies the output ofa text-to-image generative model so that it produces more generic,copyright-compliant images. Compared to the existing method, PREGen reduces thelikelihood of generating copyrighted characters by more than half when thenames of copyrighted characters are used as the prompt, dramatically improvingthe performance. Additionally, while generative models can produce copyrightedcharacters even when their names are not directly mentioned in the prompt,PREGen almost entirely prevents the generation of such characters in thesecases.</description><author>Hiroaki Chiba-Okabe, Weijie J. Su</author><pubDate>Mon, 26 Aug 2024 17:12:07 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.03341v4</guid></item><item><title>Asymptotic Dynamics of Alternating Minimization for Bilinear Regression</title><link>http://arxiv.org/abs/2402.04751v2</link><description>This study investigates the asymptotic dynamics of alternating minimizationapplied to optimize a bilinear non-convex function with normally distributedcovariates. This is achieved by employing the replica method to amulti-temperature glassy system which unfolds the algorithm's time evolution.Our results show that the dynamics can be described effectively by atwo-dimensional discrete stochastic process, where each step depends on allprevious time steps, revealing the structure of the memory dependence in theevolution of alternating minimization. The theoretical framework developed inthis work can be applied to the analysis of various iterative algorithms,extending beyond the scope of alternating minimization.</description><author>Koki Okajima, Takashi Takahashi</author><pubDate>Mon, 26 Aug 2024 17:12:01 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.04751v2</guid></item><item><title>Efficient Model-Stealing Attacks Against Inductive Graph Neural Networks</title><link>http://arxiv.org/abs/2405.12295v3</link><description>Graph Neural Networks (GNNs) are recognized as potent tools for processingreal-world data organized in graph structures. Especially inductive GNNs, whichallow for the processing of graph-structured data without relying on predefinedgraph structures, are becoming increasingly important in a wide range ofapplications. As such these networks become attractive targets formodel-stealing attacks where an adversary seeks to replicate the functionalityof the targeted network. Significant efforts have been devoted to developingmodel-stealing attacks that extract models trained on images and texts.However, little attention has been given to stealing GNNs trained on graphdata. This paper identifies a new method of performing unsupervisedmodel-stealing attacks against inductive GNNs, utilizing graph contrastivelearning and spectral graph augmentations to efficiently extract informationfrom the targeted model. The new type of attack is thoroughly evaluated on sixdatasets and the results show that our approach outperforms the currentstate-of-the-art by Shen et al. (2021). In particular, our attack surpasses thebaseline across all benchmarks, attaining superior fidelity and downstreamaccuracy of the stolen model while necessitating fewer queries directed towardthe target model.</description><author>Marcin Podhajski, Jan DubiÅski, Franziska Boenisch, Adam Dziedzic, Agnieszka Pregowska And Tomasz Michalak</author><pubDate>Mon, 26 Aug 2024 17:10:41 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.12295v3</guid></item><item><title>Evaluating saliency scores in point clouds of natural environments by learning surface anomalies</title><link>http://arxiv.org/abs/2408.14421v1</link><description>In recent years, three-dimensional point clouds are used increasingly todocument natural environments. Each dataset contains a diverse set of objects,at varying shapes and sizes, distributed throughout the data and intricatelyintertwined with the topography. Therefore, regions of interest are difficultto find and consequent analyses become a challenge. Inspired from visualperception principles, we propose to differentiate objects of interest from thecluttered environment by evaluating how much they stand out from theirsurroundings, i.e., their geometric salience. Previous saliency detectionapproaches suggested mostly handcrafted attributes for the task. However, suchmethods fail when the data are too noisy or have high levels of texture. Herewe propose a learning-based mechanism that accommodates noise and texturedsurfaces. We assume that within the natural environment any change from theprevalent surface would suggest a salient object. Thus, we first learn theunderlying surface and then search for anomalies within it. Initially, a deepneural network is trained to reconstruct the surface. Regions where thereconstructed part deviates significantly from the original point cloud yield asubstantial reconstruction error, signifying an anomaly, i.e., saliency. Wedemonstrate the effectiveness of the proposed approach by searching for salientfeatures in various natural scenarios, which were acquired by differentacquisition platforms. We show the strong correlation between thereconstruction error and salient objects.</description><author>Reuma Arav, Dennis Wittich, Franz Rottensteiner</author><pubDate>Mon, 26 Aug 2024 17:04:52 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.14421v1</guid></item><item><title>CHARTOM: A Visual Theory-of-Mind Benchmark for Multimodal Large Language Models</title><link>http://arxiv.org/abs/2408.14419v1</link><description>We introduce CHARTOM, a visual theory-of-mind benchmark for multimodal largelanguage models. CHARTOM consists of specially designed data visualizingcharts. Given a chart, a language model needs to not only correctly comprehendthe chart (the FACT question) but also judge if the chart will be misleading toa human reader (the MIND question). Both questions have significant societalbenefits. We detail the construction of the CHARTOM benchmark including itscalibration on human performance.</description><author>Shubham Bharti, Shiyun Cheng, Jihyun Rho, Martina Rao, Xiaojin Zhu</author><pubDate>Mon, 26 Aug 2024 17:04:23 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.14419v1</guid></item><item><title>MEDSAGE: Enhancing Robustness of Medical Dialogue Summarization to ASR Errors with LLM-generated Synthetic Dialogues</title><link>http://arxiv.org/abs/2408.14418v1</link><description>Automatic Speech Recognition (ASR) systems are pivotal in transcribing speechinto text, yet the errors they introduce can significantly degrade theperformance of downstream tasks like summarization. This issue is particularlypronounced in clinical dialogue summarization, a low-resource domain wheresupervised data for fine-tuning is scarce, necessitating the use of ASR modelsas black-box solutions. Employing conventional data augmentation for enhancingthe noise robustness of summarization models is not feasible either due to theunavailability of sufficient medical dialogue audio recordings andcorresponding ASR transcripts. To address this challenge, we propose MEDSAGE,an approach for generating synthetic samples for data augmentation using LargeLanguage Models (LLMs). Specifically, we leverage the in-context learningcapabilities of LLMs and instruct them to generate ASR-like errors based on afew available medical dialogue examples with audio recordings. Experimentalresults show that LLMs can effectively model ASR noise, and incorporating thisnoisy data into the training process significantly improves the robustness andaccuracy of medical dialogue summarization systems. This approach addresses thechallenges of noisy ASR outputs in critical applications, offering a robustsolution to enhance the reliability of clinical dialogue summarization.</description><author>Kuluhan Binici, Abhinav Ramesh Kashyap, Viktor Schlegel, Andy T. Liu, Vijay Prakash Dwivedi, Thanh-Tung Nguyen, Xiaoxue Gao, Nancy F. Chen, Stefan Winkler</author><pubDate>Mon, 26 Aug 2024 17:04:00 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.14418v1</guid></item><item><title>Hyperdimensional Computing Empowered Federated Foundation Model over Wireless Networks for Metaverse</title><link>http://arxiv.org/abs/2408.14416v1</link><description>The Metaverse, a burgeoning collective virtual space merging augmentedreality and persistent virtual worlds, necessitates advanced artificialintelligence (AI) and communication technologies to support immersive andinteractive experiences. Federated learning (FL) has emerged as a promisingtechnique for collaboratively training AI models while preserving data privacy.However, FL faces challenges such as high communication overhead andsubstantial computational demands, particularly for neural network (NN) models.To address these issues, we propose an integrated federated split learning andhyperdimensional computing (FSL-HDC) framework for emerging foundation models.This novel approach reduces communication costs, computation load, and privacyrisks, making it particularly suitable for resource-constrained edge devices inthe Metaverse, ensuring real-time responsive interactions. Additionally, weintroduce an optimization algorithm that concurrently optimizes transmissionpower and bandwidth to minimize the maximum transmission time among all usersto the server. The simulation results based on the MNIST dataset indicate thatFSL-HDC achieves an accuracy rate of approximately 87.5%, which is slightlylower than that of FL-HDC. However, FSL-HDC exhibits a significantly fasterconvergence speed, approximately 3.733x that of FSL-NN, and demonstratesrobustness to non-IID data distributions. Moreover, our proposed optimizationalgorithm can reduce the maximum transmission time by up to 64% compared withthe baseline.</description><author>Yahao Ding, Wen Shang, Minrui Xu, Zhaohui Yang, Ye Hu, Dusit Niyato, Mohammad Shikh-Bahaei</author><pubDate>Mon, 26 Aug 2024 17:03:14 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.14416v1</guid></item><item><title>LoG-VMamba: Local-Global Vision Mamba for Medical Image Segmentation</title><link>http://arxiv.org/abs/2408.14415v1</link><description>Mamba, a State Space Model (SSM), has recently shown competitive performanceto Convolutional Neural Networks (CNNs) and Transformers in Natural LanguageProcessing and general sequence modeling. Various attempts have been made toadapt Mamba to Computer Vision tasks, including medical image segmentation(MIS). Vision Mamba (VM)-based networks are particularly attractive due totheir ability to achieve global receptive fields, similar to VisionTransformers, while also maintaining linear complexity in the number of tokens.However, the existing VM models still struggle to maintain both spatially localand global dependencies of tokens in high dimensional arrays due to theirsequential nature. Employing multiple and/or complicated scanning strategies iscomputationally costly, which hinders applications of SSMs to high-dimensional2D and 3D images that are common in MIS problems. In this work, we proposeLocal-Global Vision Mamba, LoG-VMamba, that explicitly enforces spatiallyadjacent tokens to remain nearby on the channel axis, and retains the globalcontext in a compressed form. Our method allows the SSMs to access the localand global contexts even before reaching the last token while requiring only asimple scanning strategy. Our segmentation models are computationally efficientand substantially outperform both CNN and Transformers-based baselines on adiverse set of 2D and 3D MIS tasks. The implementation of LoG-VMamba isavailable at \url{https://github.com/Oulu-IMEDS/LoG-VMamba}.</description><author>Trung Dinh Quoc Dang, Huy Hoang Nguyen, Aleksei Tiulpin</author><pubDate>Mon, 26 Aug 2024 17:02:25 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.14415v1</guid></item><item><title>Prediction Instability in Machine Learning Ensembles</title><link>http://arxiv.org/abs/2407.03194v5</link><description>In machine learning ensembles predictions from multiple models areaggregated. Despite widespread use and strong performance of ensembles inapplied problems little is known about the mathematical properties ofaggregating models and associated consequences for safe, explainable use ofsuch models. In this paper we prove a theorem that shows that any ensemble willexhibit at least one of the following forms of prediction instability. It willeither ignore agreement among all underlying models, change its mind when noneof the underlying models have done so, or be manipulable through inclusion orexclusion of options it would never actually predict. As a consequence,ensemble aggregation procedures will always need to balance the benefits ofinformation use against the risk of these prediction instabilities. Thisanalysis also sheds light on what specific forms of prediction instability toexpect from particular ensemble algorithms; for example popular tree ensembleslike random forest, or xgboost will violate basic, intuitive fairnessproperties. Finally, we show that this can be ameliorated by using consistentmodels in asymptotic conditions.</description><author>Jeremy Kedziora</author><pubDate>Mon, 26 Aug 2024 16:57:34 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.03194v5</guid></item><item><title>Implicit Concept Removal of Diffusion Models</title><link>http://arxiv.org/abs/2310.05873v6</link><description>Text-to-image (T2I) diffusion models often inadvertently generate unwantedconcepts such as watermarks and unsafe images. These concepts, termed as the"implicit concepts", could be unintentionally learned during training and thenbe generated uncontrollably during inference. Existing removal methods stillstruggle to eliminate implicit concepts primarily due to their dependency onthe model's ability to recognize concepts it actually can not discern. Toaddress this, we utilize the intrinsic geometric characteristics of implicitconcepts and present the Geom-Erasing, a novel concept removal method based onthe geometric-driven control. Specifically, once an unwanted implicit conceptis identified, we integrate the existence and geometric information of theconcept into the text prompts with the help of an accessible classifier ordetector model. Subsequently, the model is optimized to identify anddisentangle this information, which is then adopted as negative prompts duringgeneration. Moreover, we introduce the Implicit Concept Dataset (ICD), a novelimage-text dataset imbued with three typical implicit concepts (i.e., QR codes,watermarks, and text), reflecting real-life situations where implicit conceptsare easily injected. Geom-Erasing effectively mitigates the generation ofimplicit concepts, achieving the state-of-the-art results on the InappropriateImage Prompts (I2P) and our challenging Implicit Concept Dataset (ICD)benchmarks.</description><author>Zhili Liu, Kai Chen, Yifan Zhang, Jianhua Han, Lanqing Hong, Hang Xu, Zhenguo Li, Dit-Yan Yeung, James Kwok</author><pubDate>Mon, 26 Aug 2024 16:55:02 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.05873v6</guid></item><item><title>Spectrally Informed Learning of Fluid Flows</title><link>http://arxiv.org/abs/2408.14407v1</link><description>Accurate and efficient fluid flow models are essential for applicationsrelating to many physical phenomena including geophysical, aerodynamic, andbiological systems. While these flows may exhibit rich and multiscale dynamics,in many cases underlying low-rank structures exist which describe the bulk ofthe motion. These structures tend to be spatially large and temporally slow,and may contain most of the energy in a given flow. The extraction andparsimonious representation of these low-rank dynamics from high-dimensionaldata is a key challenge. Inspired by the success of physics-informed machinelearning methods, we propose a spectrally-informed approach to extract low-rankmodels of fluid flows by leveraging known spectral properties in the learningprocess. We incorporate this knowledge by imposing regularizations on thelearned dynamics, which bias the training process towards learninglow-frequency structures with corresponding higher power. We demonstrate theeffectiveness of this method to improve prediction and produce learned modelswhich better match the underlying spectral properties of prototypical fluidflows.</description><author>Benjamin D. Shaffer, Jeremy R. Vorenberg, M. Ani Hsieh</author><pubDate>Mon, 26 Aug 2024 16:49:42 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.14407v1</guid></item><item><title>A Dataset and Benchmark for Hospital Course Summarization with Adapted Large Language Models</title><link>http://arxiv.org/abs/2403.05720v2</link><description>Brief hospital course (BHC) summaries are clinical documents that summarize apatient's hospital stay. While large language models (LLMs) depict remarkablecapabilities in automating real-world tasks, their capabilities for healthcareapplications such as synthesizing BHCs from clinical notes have not been shown.We introduce a novel pre-processed dataset, the MIMIC-IV-BHC, encapsulatingclinical note and brief hospital course (BHC) pairs to adapt LLMs for BHCsynthesis. Furthermore, we introduce a benchmark of the summarizationperformance of two general-purpose LLMs and three healthcare-adapted LLMs. Using clinical notes as input, we apply prompting-based (using in-contextlearning) and fine-tuning-based adaptation strategies to three open-source LLMs(Clinical-T5-Large, Llama2-13B, FLAN-UL2) and two proprietary LLMs (GPT-3.5,GPT-4). We evaluate these LLMs across multiple context-length inputs usingnatural language similarity metrics. We further conduct a clinical study withfive clinicians, comparing clinician-written and LLM-generated BHCs across 30samples, focusing on their potential to enhance clinical decision-makingthrough improved summary quality. We observe that the Llama2-13B fine-tuned LLMoutperforms other domain-adapted models given quantitative evaluation metricsof BLEU and BERT-Score. GPT-4 with in-context learning shows more robustness toincreasing context lengths of clinical note inputs than fine-tuned Llama2-13B.Despite comparable quantitative metrics, the reader study depicts a significantpreference for summaries generated by GPT-4 with in-context learning comparedto both Llama2-13B fine-tuned summaries and the original summaries,highlighting the need for qualitative clinical evaluation.</description><author>Asad Aali, Dave Van Veen, Yamin Ishraq Arefeen, Jason Hom, Christian Bluethgen, Eduardo Pontes Reis, Sergios Gatidis, Namuun Clifford, Joseph Daws, Arash S. Tehrani, Jangwon Kim, Akshay S. Chaudhari</author><pubDate>Mon, 26 Aug 2024 16:48:08 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.05720v2</guid></item><item><title>Application of Neural Ordinary Differential Equations for ITER Burning Plasma Dynamics</title><link>http://arxiv.org/abs/2408.14404v1</link><description>The dynamics of burning plasmas in tokamaks are crucial for advancingcontrolled thermonuclear fusion. This study introduces the NeuralPlasmaODE, amulti-region multi-timescale transport model to simulate the complex energytransfer processes in ITER deuterium-tritium (D-T) plasmas. Our model capturesthe interactions between energetic alpha particles, electrons, and ions, whichare vital for understanding phenomena such as thermal runaway instability. Weemploy neural ordinary differential equations (Neural ODEs) for the numericalderivation of diffusivity parameters, enabling precise modeling of energyinteractions between different plasma regions. By leveraging transfer learning,we utilize model parameters derived from DIII-D experimental data, enhancingthe efficiency and accuracy of our simulations without training from scratch.Applying this model to ITER's inductive and non-inductive operationalscenarios, our results demonstrate that radiation and transport processeseffectively remove excess heat from the core plasma, preventing thermal runawayinstability. This study underscores the potential of machine learning inadvancing our understanding and control of burning plasma dynamics in fusionreactors.</description><author>Zefang Liu, Weston M. Stacey</author><pubDate>Mon, 26 Aug 2024 16:47:20 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.14404v1</guid></item><item><title>Global Attractor for a Reaction-Diffusion Model Arising in Biological Dynamic in 3D Soil Structure</title><link>http://arxiv.org/abs/2310.02060v3</link><description>Partial Differential Equations (PDEs) play a crucial role as tools formodeling and comprehending intricate natural processes, notably within thedomain of biology. This research explores the domain of microbial activitywithin the complex matrix of 3D soil structures, providing valuableunderstanding into both the existence and uniqueness of solutions and theasymptotic behavior of the corresponding PDE model. Our investigation resultsin the discovery of a global attractor, a fundamental feature with significantimplications for long-term system behavior. To enhance the clarity of ourfindings, numerical simulations are employed to visually illustrate theattributes of this global attractor.</description><author>Mohamed Elghandouri, Khalil Ezzinbi, Mouad Klai, Olivier Monga</author><pubDate>Mon, 26 Aug 2024 16:42:45 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.02060v3</guid></item><item><title>A quasi-Bayesian sequential approach to deconvolution density estimation</title><link>http://arxiv.org/abs/2408.14402v1</link><description>Density deconvolution addresses the estimation of the unknown (probability)density function $f$ of a random signal from data that are observed with anindependent additive random noise. This is a classical problem in statistics,for which frequentist and Bayesian nonparametric approaches are available todeal with static or batch data. In this paper, we consider the problem ofdensity deconvolution in a streaming or online setting where noisy data arriveprogressively, with no predetermined sample size, and we develop a sequentialnonparametric approach to estimate $f$. By relying on a quasi-Bayesiansequential approach, often referred to as Newton's algorithm, we obtainestimates of $f$ that are of easy evaluation, computationally efficient, andwith a computational cost that remains constant as the amount of dataincreases, which is critical in the streaming setting. Large sample asymptoticproperties of the proposed estimates are studied, yielding provable guaranteeswith respect to the estimation of $f$ at a point (local) and on an interval(uniform). In particular, we establish local and uniform central limittheorems, providing corresponding asymptotic credible intervals and bands. Wevalidate empirically our methods on synthetic and real data, by considering thecommon setting of Laplace and Gaussian noise distributions, and make acomparison with respect to the kernel-based approach and a Bayesiannonparametric approach with a Dirichlet process mixture prior.</description><author>Stefano Favaro, Sandra Fortini</author><pubDate>Mon, 26 Aug 2024 16:40:04 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.14402v1</guid></item><item><title>Satellite Sunroof: High-res Digital Surface Models and Roof Segmentation for Global Solar Mapping</title><link>http://arxiv.org/abs/2408.14400v1</link><description>The transition to renewable energy, particularly solar, is key to mitigatingclimate change. Google's Solar API aids this transition by estimating solarpotential from aerial imagery, but its impact is constrained by geographicalcoverage. This paper proposes expanding the API's reach using satelliteimagery, enabling global solar potential assessment. We tackle challengesinvolved in building a Digital Surface Model (DSM) and roof instancesegmentation from lower resolution and single oblique views using deep learningmodels. Our models, trained on aligned satellite and aerial datasets, produce25cm DSMs and roof segments. With ~1m DSM MAE on buildings, ~5deg roof pitcherror and ~56% IOU on roof segmentation, they significantly enhance the SolarAPI's potential to promote solar adoption.</description><author>Vishal Batchu, Alex Wilson, Betty Peng, Carl Elkin, Umangi Jain, Christopher Van Arsdale, Ross Goroshin, Varun Gulshan</author><pubDate>Mon, 26 Aug 2024 16:34:13 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.14400v1</guid></item><item><title>Language-specific Calibration for Pruning Multilingual Language Models</title><link>http://arxiv.org/abs/2408.14398v1</link><description>Recent advances in large language model (LLM) pruning have shownstate-of-the-art compression results in post-training and retraining-freesettings while maintaining high predictive performance. However, such researchmainly considers calibrating pruning using English text, despite themultilingual nature of modern LLMs and their frequent uses in non-Englishlanguages. In this paper, we set out to explore effective strategies forcalibrating the pruning of multilingual language models. We present the firstcomprehensive empirical study, comparing different calibration languages forpruning multilingual models across diverse tasks, models, and state-of-the-artpruning techniques. Our results present practical suggestions, for example,calibrating in the target language can efficiently yield lower perplexity, butdoes not necessarily benefit downstream tasks. Our further analysis experimentsunveil that calibration in the target language mainly contributes to preservinglanguage-specific features related to fluency and coherence, but might notcontribute to capturing language-agnostic features such as languageunderstanding and reasoning. Last, we provide practical recommendations forfuture practitioners.</description><author>Simon Kurz, Zhixue Zhao, Jian-Jia Chen, Lucie Flek</author><pubDate>Mon, 26 Aug 2024 16:29:13 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.14398v1</guid></item><item><title>Uncovering Knowledge Gaps in Radiology Report Generation Models through Knowledge Graphs</title><link>http://arxiv.org/abs/2408.14397v1</link><description>Recent advancements in artificial intelligence have significantly improvedthe automatic generation of radiology reports. However, existing evaluationmethods fail to reveal the models' understanding of radiological images andtheir capacity to achieve human-level granularity in descriptions. To bridgethis gap, we introduce a system, named ReXKG, which extracts structuredinformation from processed reports to construct a comprehensive radiologyknowledge graph. We then propose three metrics to evaluate the similarity ofnodes (ReXKG-NSC), distribution of edges (ReXKG-AMS), and coverage of subgraphs(ReXKG-SCS) across various knowledge graphs. We conduct an in-depth comparativeanalysis of AI-generated and human-written radiology reports, assessing theperformance of both specialist and generalist models. Our study provides adeeper understanding of the capabilities and limitations of current AI modelsin radiology report generation, offering valuable insights for improving modelperformance and clinical applicability.</description><author>Xiaoman Zhang, JuliÃ¡n N. Acosta, Hong-Yu Zhou, Pranav Rajpurkar</author><pubDate>Mon, 26 Aug 2024 16:28:56 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.14397v1</guid></item><item><title>On the Error Analysis of 3D Gaussian Splatting and an Optimal Projection Strategy</title><link>http://arxiv.org/abs/2402.00752v4</link><description>3D Gaussian Splatting has garnered extensive attention and application inreal-time neural rendering. Concurrently, concerns have been raised about thelimitations of this technology in aspects such as point cloud storage,performance, and robustness in sparse viewpoints, leading to variousimprovements. However, there has been a notable lack of attention to thefundamental problem of projection errors introduced by the local affineapproximation inherent in the splatting itself, and the consequential impact ofthese errors on the quality of photo-realistic rendering. This paper addressesthe projection error function of 3D Gaussian Splatting, commencing with theresidual error from the first-order Taylor expansion of the projectionfunction. The analysis establishes a correlation between the error and theGaussian mean position. Subsequently, leveraging function optimization theory,this paper analyzes the function's minima to provide an optimal projectionstrategy for Gaussian Splatting referred to Optimal Gaussian Splatting, whichcan accommodate a variety of camera models. Experimental validation furtherconfirms that this projection methodology reduces artifacts, resulting in amore convincingly realistic rendering.</description><author>Letian Huang, Jiayang Bai, Jie Guo, Yuanqi Li, Yanwen Guo</author><pubDate>Mon, 26 Aug 2024 16:27:42 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.00752v4</guid></item><item><title>DQ-DETR: DETR with Dynamic Query for Tiny Object Detection</title><link>http://arxiv.org/abs/2404.03507v3</link><description>Despite previous DETR-like methods having performed successfully in genericobject detection, tiny object detection is still a challenging task for themsince the positional information of object queries is not customized fordetecting tiny objects, whose scale is extraordinarily smaller than generalobjects. Also, DETR-like methods using a fixed number of queries make themunsuitable for aerial datasets, which only contain tiny objects, and thenumbers of instances are imbalanced between different images. Thus, we presenta simple yet effective model, named DQ-DETR, which consists of three differentcomponents: categorical counting module, counting-guided feature enhancement,and dynamic query selection to solve the above-mentioned problems. DQ-DETR usesthe prediction and density maps from the categorical counting module todynamically adjust the number of object queries and improve the positionalinformation of queries. Our model DQ-DETR outperforms previous CNN-based andDETR-like methods, achieving state-of-the-art mAP 30.2% on the AI-TOD-V2dataset, which mostly consists of tiny objects.</description><author>Yi-Xin Huang, Hou-I Liu, Hong-Han Shuai, Wen-Huang Cheng</author><pubDate>Mon, 26 Aug 2024 16:22:35 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.03507v3</guid></item><item><title>CURE4Rec: A Benchmark for Recommendation Unlearning with Deeper Influence</title><link>http://arxiv.org/abs/2408.14393v1</link><description>With increasing privacy concerns in artificial intelligence, regulations havemandated the right to be forgotten, granting individuals the right to withdrawtheir data from models. Machine unlearning has emerged as a potential solutionto enable selective forgetting in models, particularly in recommender systemswhere historical data contains sensitive user information. Despite recentadvances in recommendation unlearning, evaluating unlearning methodscomprehensively remains challenging due to the absence of a unified evaluationframework and overlooked aspects of deeper influence, e.g., fairness. Toaddress these gaps, we propose CURE4Rec, the first comprehensive benchmark forrecommendation unlearning evaluation. CURE4Rec covers four aspects, i.e.,unlearning Completeness, recommendation Utility, unleaRning efficiency, andrecommendation fairnEss, under three data selection strategies, i.e., coredata, edge data, and random data. Specifically, we consider the deeperinfluence of unlearning on recommendation fairness and robustness towards datawith varying impact levels. We construct multiple datasets with CURE4Recevaluation and conduct extensive experiments on existing recommendationunlearning methods. Our code is released athttps://github.com/xiye7lai/CURE4Rec.</description><author>Chaochao Chen, Jiaming Zhang, Yizhao Zhang, Li Zhang, Lingjuan Lyu, Yuyuan Li, Biao Gong, Chenggang Yan</author><pubDate>Mon, 26 Aug 2024 16:21:50 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.14393v1</guid></item><item><title>SpikeGS: Reconstruct 3D scene via fast-moving bio-inspired sensors</title><link>http://arxiv.org/abs/2407.03771v2</link><description>3D Gaussian Splatting (3DGS) demonstrates unparalleled superior performancein 3D scene reconstruction. However, 3DGS heavily relies on the sharp images.Fulfilling this requirement can be challenging in real-world scenariosespecially when the camera moves fast, which severely limits the application of3DGS. To address these challenges, we proposed Spike Gausian Splatting(SpikeGS), the first framework that integrates the spike streams into 3DGSpipeline to reconstruct 3D scenes via a fast-moving bio-inspired camera. Withaccumulation rasterization, interval supervision, and a specially designedpipeline, SpikeGS extracts detailed geometry and texture from high temporalresolution but texture lacking spike stream, reconstructs 3D scenes captured in1 second. Extensive experiments on multiple synthetic and real-world datasetsdemonstrate the superiority of SpikeGS compared with existing spike-based anddeblur 3D scene reconstruction methods. Codes and data will be released soon.</description><author>Yijia Guo, Liwen Hu, Lei Ma, Tiejun Huang</author><pubDate>Mon, 26 Aug 2024 16:15:57 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.03771v2</guid></item><item><title>GloSoFarID: Global multispectral dataset for Solar Farm IDentification in satellite imagery</title><link>http://arxiv.org/abs/2404.05180v2</link><description>Solar Photovoltaic (PV) technology is increasingly recognized as a pivotalsolution in the global pursuit of clean and renewable energy. This technologyaddresses the urgent need for sustainable energy alternatives by convertingsolar power into electricity without greenhouse gas emissions. It not onlycurtails global carbon emissions but also reduces reliance on finite,non-renewable energy sources. In this context, monitoring solar panel farmsbecomes essential for understanding and facilitating the worldwide shift towardclean energy. This study contributes to this effort by developing the firstcomprehensive global dataset of multispectral satellite imagery of solar panelfarms. This dataset is intended to form the basis for training robust machinelearning models, which can accurately map and analyze the expansion anddistribution of solar panel farms globally. The insights gained from thisendeavor will be instrumental in guiding informed decision-making for asustainable energy future. https://github.com/yzyly1992/GloSoFarID</description><author>Zhiyuan Yang, Ryan Rad</author><pubDate>Mon, 26 Aug 2024 16:13:30 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.05180v2</guid></item><item><title>Reprogramming Foundational Large Language Models(LLMs) for Enterprise Adoption for Spatio-Temporal Forecasting Applications: Unveiling a New Era in Copilot-Guided Cross-Modal Time Series Representation Learning</title><link>http://arxiv.org/abs/2408.14387v1</link><description>Spatio-temporal forecasting plays a crucial role in various sectors such astransportation systems, logistics, and supply chain management. However,existing methods are limited by their ability to handle large, complexdatasets. To overcome this limitation, we introduce a hybrid approach thatcombines the strengths of open-source large and small-scale language models(LLMs and LMs) with traditional forecasting methods. We augment traditionalmethods with dynamic prompting and a grouped-query, multi-head attentionmechanism to more effectively capture both intra-series and inter-seriesdependencies in evolving nonlinear time series data. In addition, we facilitateon-premises customization by fine-tuning smaller open-source LMs for timeseries trend analysis utilizing descriptions generated by open-source large LMson consumer-grade hardware using Low-Rank Adaptation with Activation MemoryReduction (LoRA-AMR) technique to reduce computational overhead and activationstorage memory demands while preserving inference latency. We combine languagemodel processing for time series trend analysis with traditional time seriesrepresentation learning method for cross-modal integration, achieving robustand accurate forecasts. The framework effectiveness is demonstrated throughextensive experiments on various real-world datasets, outperforming existingmethods by significant margins in terms of forecast accuracy.</description><author>Sakhinana Sagar Srinivas, Chidaksh Ravuru, Geethan Sannidhi, Venkataramana Runkana</author><pubDate>Mon, 26 Aug 2024 16:11:53 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.14387v1</guid></item><item><title>Learning Tree-Structured Composition of Data Augmentation</title><link>http://arxiv.org/abs/2408.14381v1</link><description>Data augmentation is widely used for training a neural network given littlelabeled data. A common practice of augmentation training is applying acomposition of multiple transformations sequentially to the data. Existingaugmentation methods such as RandAugment randomly sample from a list ofpre-selected transformations, while methods such as AutoAugment apply advancedsearch to optimize over an augmentation set of size $k^d$, which is the numberof transformation sequences of length $d$, given a list of $k$ transformations. In this paper, we design efficient algorithms whose running time complexityis much faster than the worst-case complexity of $O(k^d)$, provably. We proposea new algorithm to search for a binary tree-structured composition of $k$transformations, where each tree node corresponds to one transformation. Thebinary tree generalizes sequential augmentations, such as the SimCLRaugmentation scheme for contrastive learning. Using a top-down, recursivesearch procedure, our algorithm achieves a runtime complexity of $O(2^d k)$,which is much faster than $O(k^d)$ as $k$ increases above $2$. We apply ouralgorithm to tackle data distributions with heterogeneous subpopulations bysearching for one tree in each subpopulation and then learning a weightedcombination, resulting in a forest of trees. We validate our proposed algorithms on numerous graph and image datasets,including a multi-label graph classification dataset we collected. The datasetexhibits significant variations in the sizes of graphs and their averagedegrees, making it ideal for studying data augmentation. We show that ourapproach can reduce the computation cost by 43% over existing search methodswhile improving performance by 4.3%. The tree structures can be used tointerpret the relative importance of each transformation, such as identifyingthe important transformations on small vs. large graphs.</description><author>Dongyue Li, Kailai Chen, Predrag Radivojac, Hongyang R. Zhang</author><pubDate>Mon, 26 Aug 2024 16:04:13 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.14381v1</guid></item><item><title>Probing Causality Manipulation of Large Language Models</title><link>http://arxiv.org/abs/2408.14380v1</link><description>Large language models (LLMs) have shown various ability on natural languageprocessing, including problems about causality. It is not intuitive for LLMs tocommand causality, since pretrained models usually work on statisticalassociations, and do not focus on causes and effects in sentences. So thatprobing internal manipulation of causality is necessary for LLMs. This paperproposes a novel approach to probe causality manipulation hierarchically, byproviding different shortcuts to models and observe behaviors. We exploitretrieval augmented generation (RAG) and in-context learning (ICL) for modelson a designed causality classification task. We conduct experiments onmainstream LLMs, including GPT-4 and some smaller and domain-specific models.Our results suggest that LLMs can detect entities related to causality andrecognize direct causal relationships. However, LLMs lack specialized cognitionfor causality, merely treating them as part of the global semantic of thesentence.</description><author>Chenyang Zhang, Haibo Tong, Bin Zhang, Dongyu Zhang</author><pubDate>Mon, 26 Aug 2024 16:00:41 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.14380v1</guid></item><item><title>Revenge of the Fallen? Recurrent Models Match Transformers at Predicting Human Language Comprehension Metrics</title><link>http://arxiv.org/abs/2404.19178v2</link><description>Transformers have generally supplanted recurrent neural networks as thedominant architecture for both natural language processing tasks and formodelling the effect of predictability on online human language comprehension.However, two recently developed recurrent model architectures, RWKV and Mamba,appear to perform natural language tasks comparably to or better thantransformers of equivalent scale. In this paper, we show that contemporaryrecurrent models are now also able to match - and in some cases, exceed - theperformance of comparably sized transformers at modeling online human languagecomprehension. This suggests that transformer language models are not uniquelysuited to this task, and opens up new directions for debates about the extentto which architectural features of language models make them better or worsemodels of human language comprehension.</description><author>James A. Michaelov, Catherine Arnett, Benjamin K. Bergen</author><pubDate>Mon, 26 Aug 2024 15:59:03 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.19178v2</guid></item><item><title>SelEx: Self-Expertise in Fine-Grained Generalized Category Discovery</title><link>http://arxiv.org/abs/2408.14371v1</link><description>In this paper, we address Generalized Category Discovery, aiming tosimultaneously uncover novel categories and accurately classify known ones.Traditional methods, which lean heavily on self-supervision and contrastivelearning, often fall short when distinguishing between fine-grained categories.To address this, we introduce a novel concept called `self-expertise', whichenhances the model's ability to recognize subtle differences and uncoverunknown categories. Our approach combines unsupervised and supervisedself-expertise strategies to refine the model's discernment and generalization.Initially, hierarchical pseudo-labeling is used to provide `soft supervision',improving the effectiveness of self-expertise. Our supervised technique differsfrom traditional methods by utilizing more abstract positive and negativesamples, aiding in the formation of clusters that can generalize to novelcategories. Meanwhile, our unsupervised strategy encourages the model tosharpen its category distinctions by considering within-category examples as`hard' negatives. Supported by theoretical insights, our empirical resultsshowcase that our method outperforms existing state-of-the-art techniques inGeneralized Category Discovery across several fine-grained datasets. Our codeis available at: https://github.com/SarahRastegar/SelEx.</description><author>Sarah Rastegar, Mohammadreza Salehi, Yuki M. Asano, Hazel Doughty, Cees G. M. Snoek</author><pubDate>Mon, 26 Aug 2024 15:53:50 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.14371v1</guid></item><item><title>Graph-SCP: Accelerating Set Cover Problems with Graph Neural Networks</title><link>http://arxiv.org/abs/2310.07979v2</link><description>Machine learning (ML) approaches are increasingly being used to acceleratecombinatorial optimization (CO) problems. We investigate the Set Cover Problem(SCP) and propose Graph-SCP, a graph neural network method that augmentsexisting optimization solvers by learning to identify a much smallersub-problem that contains the solution space. Graph-SCP uses both supervisedlearning from prior solved instances and unsupervised learning aimed atminimizing the SCP objective. We evaluate the performance of Graph-SCP onsynthetically weighted and unweighted SCP instances with diverse problemcharacteristics and complexities, and on instances from the OR Library, acanonical benchmark for SCP. We show that Graph-SCP reduces the problem size by60-80% and achieves runtime speedups of up to 10x on average when compared toGurobi (a state-of-the-art commercial solver), while maintaining solutionquality. This is in contrast to fast greedy solutions that significantlycompromise solution quality to achieve guaranteed polynomial runtime. Weshowcase Graph-SCP's ability to generalize to larger problem sizes, training onSCP instances with up to 3,000 subsets and testing on SCP instances with up to10,000 subsets.</description><author>Zohair Shafi, Benjamin A. Miller, Tina Eliassi-Rad, Rajmonda S. Caceres</author><pubDate>Mon, 26 Aug 2024 15:51:38 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.07979v2</guid></item><item><title>Exploiting Conjugate Label Information for Multi-Instance Partial-Label Learning</title><link>http://arxiv.org/abs/2408.14369v1</link><description>Multi-instance partial-label learning (MIPL) addresses scenarios where eachtraining sample is represented as a multi-instance bag associated with acandidate label set containing one true label and several false positives.Existing MIPL algorithms have primarily focused on mapping multi-instance bagsto candidate label sets for disambiguation, disregarding the intrinsicproperties of the label space and the supervised information provided bynon-candidate label sets. In this paper, we propose an algorithm named ELIMIPL,i.e., Exploiting conjugate Label Information for Multi-Instance Partial-Labellearning, which exploits the conjugate label information to improve thedisambiguation performance. To achieve this, we extract the label informationembedded in both candidate and non-candidate label sets, incorporating theintrinsic properties of the label space. Experimental results obtained frombenchmark and real-world datasets demonstrate the superiority of the proposedELIMIPL over existing MIPL algorithms and other well-established partial-labellearning algorithms.</description><author>Wei Tang, Weijia Zhang, Min-Ling Zhang</author><pubDate>Mon, 26 Aug 2024 15:49:31 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.14369v1</guid></item><item><title>GR-MG: Leveraging Partially Annotated Data via Multi-Modal Goal Conditioned Policy</title><link>http://arxiv.org/abs/2408.14368v1</link><description>The robotics community has consistently aimed to achieve generalizable robotmanipulation with flexible natural language instructions. One of the primarychallenges is that obtaining robot data fully annotated with both actions andtexts is time-consuming and labor-intensive. However, partially annotated data,such as human activity videos without action labels and robot play data withoutlanguage labels, is much easier to collect. Can we leverage these data toenhance the generalization capability of robots? In this paper, we proposeGR-MG, a novel method which supports conditioning on both a languageinstruction and a goal image. During training, GR-MG samples goal images fromtrajectories and conditions on both the text and the goal image or solely onthe image when text is unavailable. During inference, where only the text isprovided, GR-MG generates the goal image via a diffusion-based image-editingmodel and condition on both the text and the generated image. This approachenables GR-MG to leverage large amounts of partially annotated data while stillusing language to flexibly specify tasks. To generate accurate goal images, wepropose a novel progress-guided goal image generation model which injects taskprogress information into the generation process, significantly improving thefidelity and the performance. In simulation experiments, GR-MG improves theaverage number of tasks completed in a row of 5 from 3.35 to 4.04. Inreal-robot experiments, GR-MG is able to perform 47 different tasks andimproves the success rate from 62.5% to 75.0% and 42.4% to 57.6% in simple andgeneralization settings, respectively. Code and checkpoints will be availableat the project page: https://gr-mg.github.io/.</description><author>Peiyan Li, Hongtao Wu, Yan Huang, Chilam Cheang, Liang Wang, Tao Kong</author><pubDate>Mon, 26 Aug 2024 15:46:41 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.14368v1</guid></item><item><title>Controller Synthesis for Timeline-based Games</title><link>http://arxiv.org/abs/2307.12289v4</link><description>In the timeline-based approach to planning, the evolution over time of a setof state variables (the timelines) is governed by a set of temporalconstraints. Traditional timeline-based planning systems excel at theintegration of planning with execution by handling temporal uncertainty. Inorder to handle general nondeterminism as well, the concept of timeline-basedgames has been recently introduced. It has been proved that finding whether awinning strategy exists for such games is 2EXPTIME-complete. However, aconcrete approach to synthesize controllers implementing such strategies ismissing. This paper fills this gap, by providing an effective andcomputationally optimal approach to controller synthesis for timeline-basedgames.</description><author>Renato Acampora, Luca Geatti, Nicola Gigante, Angelo Montanari, Valentino Picotti</author><pubDate>Mon, 26 Aug 2024 15:43:41 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.12289v4</guid></item><item><title>Swin transformers are robust to distribution and concept drift in endoscopy-based longitudinal rectal cancer assessment</title><link>http://arxiv.org/abs/2405.03762v2</link><description>Endoscopic images are used at various stages of rectal cancer treatmentstarting from cancer screening, diagnosis, during treatment to assess responseand toxicity from treatments such as colitis, and at follow up to detect newtumor or local regrowth (LR). However, subjective assessment is highly variableand can underestimate the degree of response in some patients, subjecting themto unnecessary surgery, or overestimate response that places patients at riskof disease spread. Advances in deep learning has shown the ability to produceconsistent and objective response assessment for endoscopic images. However,methods for detecting cancers, regrowth, and monitoring response during theentire course of patient treatment and follow-up are lacking. This is because,automated diagnosis and rectal cancer response assessment requires methods thatare robust to inherent imaging illumination variations and confoundingconditions (blood, scope, blurring) present in endoscopy images as well aschanges to the normal lumen and tumor during treatment. Hence, a hierarchicalshifted window (Swin) transformer was trained to distinguish rectal cancer fromnormal lumen using endoscopy images. Swin as well as two convolutional(ResNet-50, WideResNet-50), and vision transformer (ViT) models were trainedand evaluated on follow-up longitudinal images to detect LR on private datasetas well as on out-of-distribution (OOD) public colonoscopy datasets to detectpre/non-cancerous polyps. Color shifts were applied using optimal transport tosimulate distribution shifts. Swin and ResNet models were similarly accurate inthe in-distribution dataset. Swin was more accurate than other methods(follow-up: 0.84, OOD: 0.83) even when subject to color shifts (follow-up:0.83, OOD: 0.87), indicating capability to provide robust performance forlongitudinal cancer assessment.</description><author>Jorge Tapias Gomez, Aneesh Rangnekar, Hannah Williams, Hannah Thompson, Julio Garcia-Aguilar, Joshua Jesse Smith, Harini Veeraraghavan</author><pubDate>Mon, 26 Aug 2024 15:40:18 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.03762v2</guid></item><item><title>An Embedding is Worth a Thousand Noisy Labels</title><link>http://arxiv.org/abs/2408.14358v1</link><description>The performance of deep neural networks scales with dataset size and labelquality, rendering the efficient mitigation of low-quality data annotationscrucial for building robust and cost-effective systems. Existing strategies toaddress label noise exhibit severe limitations due to computational complexityand application dependency. In this work, we propose WANN, a Weighted AdaptiveNearest Neighbor approach that builds on self-supervised featurerepresentations obtained from foundation models. To guide the weighted votingscheme, we introduce a reliability score, which measures the likelihood of adata label being correct. WANN outperforms reference methods, including alinear layer trained with robust loss functions, on diverse datasets of varyingsize and under various noise types and severities. WANN also exhibits superiorgeneralization on imbalanced data compared to both Adaptive-NNs (ANN) and fixedk-NNs. Furthermore, the proposed weighting scheme enhances superviseddimensionality reduction under noisy labels. This yields a significant boost inclassification performance with 10x and 100x smaller image embeddings,minimizing latency and storage requirements. Our approach, emphasizingefficiency and explainability, emerges as a simple, robust solution to overcomethe inherent limitations of deep neural network training. The code is availableat https://github.com/francescodisalvo05/wann-noisy-labels .</description><author>Francesco Di Salvo, Sebastian Doerrich, Ines Rieger, Christian Ledig</author><pubDate>Mon, 26 Aug 2024 15:32:31 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.14358v1</guid></item><item><title>SWE-bench-java: A GitHub Issue Resolving Benchmark for Java</title><link>http://arxiv.org/abs/2408.14354v1</link><description>GitHub issue resolving is a critical task in software engineering, recentlygaining significant attention in both industry and academia. Within this task,SWE-bench has been released to evaluate issue resolving capabilities of largelanguage models (LLMs), but has so far only focused on Python version. However,supporting more programming languages is also important, as there is a strongdemand in industry. As a first step toward multilingual support, we havedeveloped a Java version of SWE-bench, called SWE-bench-java. We have publiclyreleased the dataset, along with the corresponding Docker-based evaluationenvironment and leaderboard, which will be continuously maintained and updatedin the coming months. To verify the reliability of SWE-bench-java, we implementa classic method SWE-agent and test several powerful LLMs on it. As is wellknown, developing a high-quality multi-lingual benchmark is time-consuming andlabor-intensive, so we welcome contributions through pull requests orcollaboration to accelerate its iteration and refinement, paving the way forfully automated programming.</description><author>Daoguang Zan, Zhirong Huang, Ailun Yu, Shaoxin Lin, Yifan Shi, Wei Liu, Dong Chen, Zongshuai Qi, Hao Yu, Lei Yu, Dezhi Ran, Muhan Zeng, Bo Shen, Pan Bian, Guangtai Liang, Bei Guan, Pengjie Huang, Tao Xie, Yongji Wang, Qianxiang Wang</author><pubDate>Mon, 26 Aug 2024 15:30:05 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.14354v1</guid></item><item><title>Assessing Contamination in Large Language Models: Introducing the LogProber method</title><link>http://arxiv.org/abs/2408.14352v1</link><description>In machine learning, contamination refers to situations where testing dataleak into the training set. The issue is particularly relevant for theevaluation of the performance of Large Language Models (LLMs), which aregenerally trained on gargantuan, and generally opaque, corpora of text scrapedfrom the world wide web. Developing tools to detect contamination is thereforecrucial to be able to fairly and properly track the evolution of theperformance of LLMs. Most recent works in the field are not tailored toquantify contamination on short sequences of text like we find in psychologyquestionnaires. In the present paper we introduce LogProber, a novel,efficient, algorithm that we show able to detect contamination using tokenprobability in given sentences. In the second part we investigate thelimitations of the method and discuss how different training methods cancontaminate models without leaving traces in the token probabilities.</description><author>Nicolas Yax, Pierre-Yves Oudeyer, Stefano Palminteri</author><pubDate>Mon, 26 Aug 2024 15:29:34 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.14352v1</guid></item><item><title>Deep learning-based ecological analysis of camera trap images is impacted by training data quality and size</title><link>http://arxiv.org/abs/2408.14348v1</link><description>Large wildlife image collections from camera traps are crucial forbiodiversity monitoring, offering insights into species richness, occupancy,and activity patterns. However, manual processing of these data istime-consuming, hindering analytical processes. To address this, deep neuralnetworks have been widely adopted to automate image analysis. Despite theirgrowing use, the impact of model training decisions on downstream ecologicalmetrics remains unclear. Here, we analyse camera trap data from an Africansavannah and an Asian sub-tropical dry forest to compare key ecological metricsderived from expert-generated species identifications with those generated fromdeep neural networks. We assess the impact of model architecture, training datanoise, and dataset size on ecological metrics, including species richness,occupancy, and activity patterns. Our results show that while modelarchitecture has minimal impact, large amounts of noise and reduced datasetsize significantly affect these metrics. Nonetheless, estimated ecologicalmetrics are resilient to considerable noise, tolerating up to 10% error inspecies labels and a 50% reduction in training set size without changingsignificantly. We also highlight that conventional metrics like classificationerror may not always be representative of a model's ability to accuratelymeasure ecological metrics. We conclude that ecological metrics derived fromdeep neural network predictions closely match those calculated from expertlabels and remain robust to variations in the factors explored. However,training decisions for deep neural networks can impact downstream ecologicalanalysis. Therefore, practitioners should prioritize creating large, cleantraining sets and evaluate deep neural network solutions based on their abilityto measure the ecological metrics of interest.</description><author>Omiros Pantazis, Peggy Bevan, Holly Pringle, Guilherme Braga Ferreira, Daniel J. Ingram, Emily Madsen, Liam Thomas, Dol Raj Thanet, Thakur Silwal, Santosh Rayamajhi, Gabriel Brostow, Oisin Mac Aodha, Kate E. Jones</author><pubDate>Mon, 26 Aug 2024 15:26:27 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.14348v1</guid></item><item><title>Binocular Model: A deep learning solution for online melt pool temperature analysis using dual-wavelength Imaging Pyrometry</title><link>http://arxiv.org/abs/2408.11126v2</link><description>In metal Additive Manufacturing (AM), monitoring the temperature of the MeltPool (MP) is crucial for ensuring part quality, process stability, defectprevention, and overall process optimization. Traditional methods, are slow toconverge and require extensive manual effort to translate data into actionableinsights, rendering them impractical for real-time monitoring and control. Toaddress this challenge, we propose an Artificial Intelligence (AI)-basedsolution aimed at reducing manual data processing reliance and improving theefficiency of transitioning from data to insight. In our study, we utilize adataset comprising dual-wavelength real-time process monitoring data andcorresponding temperature maps. We introduce a deep learning model called the"Binocular model," which exploits dual input observations to perform a preciseanalysis of MP temperature in Laser Powder Bed Fusion (L-PBF). Through advanceddeep learning techniques, we seamlessly convert raw data into temperature maps,significantly streamlining the process and enabling batch processing at a rateof up to 750 frames per second, approximately 1000 times faster thanconventional methods. Our Binocular model achieves high accuracy in temperatureestimation, evidenced by a 0.95 R-squared score, while simultaneously enhancingprocessing efficiency by a factor of $\sim1000x$ times. This model directlyaddresses the challenge of real-time MP temperature monitoring and offersinsights into the encountered constraints and the benefits of our DeepLearning-based approach. By combining efficiency and precision, our workcontributes to the advancement of temperature monitoring in L-PBF, thus drivingprogress in the field of metal AM.</description><author>Javid Akhavan, Chaitanya Krishna Vallabh, Xiayun Zhao, Souran Manoochehri</author><pubDate>Mon, 26 Aug 2024 15:19:12 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.11126v2</guid></item><item><title>A Brief Analysis of the Iterative Next Boundary Detection Network for Tree Rings Delineation in Images of Pinus taeda</title><link>http://arxiv.org/abs/2408.14343v1</link><description>This work presents the INBD network proposed by Gillert et al. in CVPR-2023and studies its application for delineating tree rings in RGB images of Pinustaeda cross sections captured by a smartphone (UruDendro dataset), which areimages with different characteristics from the ones used to train the method.The INBD network operates in two stages: first, it segments the background,pith, and ring boundaries. In the second stage, the image is transformed intopolar coordinates, and ring boundaries are iteratively segmented from the pithto the bark. Both stages are based on the U-Net architecture. The methodachieves an F-Score of 77.5, a mAR of 0.540, and an ARAND of 0.205 on theevaluation set. The code for the experiments is available athttps://github.com/hmarichal93/mlbrief_inbd.</description><author>Henry Marichal, Gregory Randall</author><pubDate>Mon, 26 Aug 2024 15:16:28 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.14343v1</guid></item><item><title>Graph Reinforcement Learning for Power Grids: A Comprehensive Survey</title><link>http://arxiv.org/abs/2407.04522v3</link><description>The rise of renewable energy and distributed generation requires newapproaches to overcome the limitations of traditional methods. In this context,Graph Neural Networks are promising due to their ability to learn fromgraph-structured data. Combined with Reinforcement Learning, they can serve ascontrol approaches to determine remedial network actions. This review analyseshow Graph Reinforcement Learning (GRL) can improve representation learning anddecision making in power grid use cases. Although GRL has demonstratedadaptability to unpredictable events and noisy data, it is primarily at aproof-of-concept stage. We highlight open challenges and limitations withrespect to real-world applications.</description><author>Mohamed Hassouna, Clara HolzhÃ¼ter, Pawel Lytaev, Josephine Thomas, Bernhard Sick, Christoph Scholz</author><pubDate>Mon, 26 Aug 2024 15:13:22 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.04522v3</guid></item><item><title>Foundation Models for Music: A Survey</title><link>http://arxiv.org/abs/2408.14340v1</link><description>In recent years, foundation models (FMs) such as large language models (LLMs)and latent diffusion models (LDMs) have profoundly impacted diverse sectors,including music. This comprehensive review examines state-of-the-art (SOTA)pre-trained models and foundation models in music, spanning from representationlearning, generative learning and multimodal learning. We first contextualisethe significance of music in various industries and trace the evolution of AIin music. By delineating the modalities targeted by foundation models, wediscover many of the music representations are underexplored in FM development.Then, emphasis is placed on the lack of versatility of previous methods ondiverse music applications, along with the potential of FMs in musicunderstanding, generation and medical application. By comprehensively exploringthe details of the model pre-training paradigm, architectural choices,tokenisation, finetuning methodologies and controllability, we emphasise theimportant topics that should have been well explored, like instruction tuningand in-context learning, scaling law and emergent ability, as well aslong-sequence modelling etc. A dedicated section presents insights into musicagents, accompanied by a thorough analysis of datasets and evaluationsessential for pre-training and downstream tasks. Finally, by underscoring thevital importance of ethical considerations, we advocate that following researchon FM for music should focus more on such issues as interpretability,transparency, human responsibility, and copyright issues. The paper offersinsights into future challenges and trends on FMs for music, aiming to shapethe trajectory of human-AI collaboration in the music realm.</description><author>Yinghao Ma, Anders Ãland, Anton Ragni, Bleiz MacSen Del Sette, Charalampos Saitis, Chris Donahue, Chenghua Lin, Christos Plachouras, Emmanouil Benetos, Elio Quinton, Elona Shatri, Fabio Morreale, Ge Zhang, GyÃ¶rgy Fazekas, Gus Xia, Huan Zhang, Ilaria Manco, Jiawen Huang, Julien Guinot, Liwei Lin, Luca Marinelli, Max W. Y. Lam, Megha Sharma, Qiuqiang Kong, Roger B. Dannenberg, Ruibin Yuan, Shangda Wu, Shih-Lun Wu, Shuqi Dai, Shun Lei, Shiyin Kang, Simon Dixon, Wenhu Chen, Wehhao Huang, Xingjian Du, Xingwei Qu, Xu Tan, Yizhi Li, Zeyue Tian, Zhiyong Wu, Zhizheng Wu, Ziyang Ma, Ziyu Wang</author><pubDate>Mon, 26 Aug 2024 15:13:14 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.14340v1</guid></item><item><title>ConceptMix: A Compositional Image Generation Benchmark with Controllable Difficulty</title><link>http://arxiv.org/abs/2408.14339v1</link><description>Compositionality is a critical capability in Text-to-Image (T2I) models, asit reflects their ability to understand and combine multiple concepts from textdescriptions. Existing evaluations of compositional capability rely heavily onhuman-designed text prompts or fixed templates, limiting their diversity andcomplexity, and yielding low discriminative power. We propose ConceptMix, ascalable, controllable, and customizable benchmark which automaticallyevaluates compositional generation ability of T2I models. This is done in twostages. First, ConceptMix generates the text prompts: concretely, usingcategories of visual concepts (e.g., objects, colors, shapes, spatialrelationships), it randomly samples an object and k-tuples of visual concepts,then uses GPT4-o to generate text prompts for image generation based on thesesampled concepts. Second, ConceptMix evaluates the images generated in responseto these prompts: concretely, it checks how many of the k concepts actuallyappeared in the image by generating one question per visual concept and using astrong VLM to answer them. Through administering ConceptMix to a diverse set ofT2I models (proprietary as well as open ones) using increasing values of k, weshow that our ConceptMix has higher discrimination power than earlierbenchmarks. Specifically, ConceptMix reveals that the performance of severalmodels, especially open models, drops dramatically with increased k.Importantly, it also provides insight into the lack of prompt diversity inwidely-used training datasets. Additionally, we conduct extensive human studiesto validate the design of ConceptMix and compare our automatic grading withhuman judgement. We hope it will guide future T2I model development.</description><author>Xindi Wu, Dingli Yu, Yangsibo Huang, Olga Russakovsky, Sanjeev Arora</author><pubDate>Mon, 26 Aug 2024 15:08:12 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.14339v1</guid></item><item><title>Machine Learning for Quantifier Selection in cvc5</title><link>http://arxiv.org/abs/2408.14338v1</link><description>In this work we considerably improve the state-of-the-art SMT solving onfirst-order quantified problems by efficient machine learning guidance ofquantifier selection. Quantifiers represent a significant challenge for SMT andare technically a source of undecidability. In our approach, we train anefficient machine learning model that informs the solver which quantifiersshould be instantiated and which not. Each quantifier may be instantiatedmultiple times and the set of the active quantifiers changes as the solvingprogresses. Therefore, we invoke the ML predictor many times, during the wholerun of the solver. To make this efficient, we use fast ML models based ongradient boosting decision trees. We integrate our approach into thestate-of-the-art cvc5 SMT solver and show a considerable increase of thesystem's holdout-set performance after training it on a large set offirst-order problems collected from the Mizar Mathematical Library.</description><author>Jan JakubÅ¯v, MikolÃ¡Å¡ Janota, Jelle Piepenbrock, Josef Urban</author><pubDate>Mon, 26 Aug 2024 15:07:35 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.14338v1</guid></item><item><title>Equivariant Reinforcement Learning under Partial Observability</title><link>http://arxiv.org/abs/2408.14336v1</link><description>Incorporating inductive biases is a promising approach for tacklingchallenging robot learning domains with sample-efficient solutions. This paperidentifies partially observable domains where symmetries can be a usefulinductive bias for efficient learning. Specifically, by encoding theequivariance regarding specific group symmetries into the neural networks, ouractor-critic reinforcement learning agents can reuse solutions in the past forrelated scenarios. Consequently, our equivariant agents outperformnon-equivariant approaches significantly in terms of sample efficiency andfinal performance, demonstrated through experiments on a range of robotic tasksin simulation and real hardware.</description><author>Hai Nguyen, Andrea Baisero, David Klee, Dian Wang, Robert Platt, Christopher Amato</author><pubDate>Mon, 26 Aug 2024 15:07:01 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.14336v1</guid></item><item><title>One-layer transformers fail to solve the induction heads task</title><link>http://arxiv.org/abs/2408.14332v1</link><description>A simple communication complexity argument proves that no one-layertransformer can solve the induction heads task unless its size is exponentiallylarger than the size sufficient for a two-layer transformer.</description><author>Clayton Sanford, Daniel Hsu, Matus Telgarsky</author><pubDate>Mon, 26 Aug 2024 15:01:04 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.14332v1</guid></item><item><title>LoQT: Low Rank Adapters for Quantized Training</title><link>http://arxiv.org/abs/2405.16528v2</link><description>Training of large neural networks requires significant computationalresources. Despite advances using low-rank adapters and quantization,pretraining of models such as LLMs on consumer hardware has not been possiblewithout model sharding, offloading during training, or per-layer gradientupdates. To address these limitations, we propose LoQT, a method forefficiently training quantized models. LoQT uses gradient-based tensorfactorization to initialize low-rank trainable weight matrices that areperiodically merged into quantized full-rank weight matrices. Our approach issuitable for both pretraining and fine-tuning of models, which we demonstrateexperimentally for language modeling and downstream task adaptation. We findthat LoQT enables efficient training of models up to 7B parameters on aconsumer-grade 24GB GPU. We also demonstrate the feasibility of training a 13Bparameter model using per-layer gradient updates on the same hardware.</description><author>Sebastian Loeschcke, Mads Toftrup, Michael J. Kastoryano, Serge Belongie, VÃ©steinn SnÃ¦bjarnarson</author><pubDate>Mon, 26 Aug 2024 14:59:53 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.16528v2</guid></item><item><title>Beyond Silence: Bias Analysis through Loss and Asymmetric Approach in Audio Anti-Spoofing</title><link>http://arxiv.org/abs/2406.17246v2</link><description>Current trends in audio anti-spoofing detection research strive to improvemodels' ability to generalize across unseen attacks by learning to identify avariety of spoofing artifacts. This emphasis has primarily focused on the spoofclass. Recently, several studies have noted that the distribution of silencediffers between the two classes, which can serve as a shortcut. In this paper,we extend class-wise interpretations beyond silence. We employ loss analysisand asymmetric methodologies to move away from traditional attack-focused andresult-oriented evaluations towards a deeper examination of model behaviors.Our investigations highlight the significant differences in training dynamicsbetween the two classes, emphasizing the need for future research to focus onrobust modeling of the bonafide class.</description><author>Hye-jin Shim, Md Sahidullah, Jee-weon Jung, Shinji Watanabe, Tomi Kinnunen</author><pubDate>Mon, 26 Aug 2024 14:56:06 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.17246v2</guid></item><item><title>Automated Machine Learning in Insurance</title><link>http://arxiv.org/abs/2408.14331v1</link><description>Machine Learning (ML) has gained popularity in actuarial research andinsurance industrial applications. However, the performance of most ML tasksheavily depends on data preprocessing, model selection, and hyperparameteroptimization, which are considered to be intensive in terms of domainknowledge, experience, and manual labor. Automated Machine Learning (AutoML)aims to automatically complete the full life-cycle of ML tasks and providesstate-of-the-art ML models without human intervention or supervision. Thispaper introduces an AutoML workflow that allows users without domain knowledgeor prior experience to achieve robust and effortless ML deployment by writingonly a few lines of code. This proposed AutoML is specifically tailored for theinsurance application, with features like the balancing step in datapreprocessing, ensemble pipelines, and customized loss functions. Thesefeatures are designed to address the unique challenges of the insurance domain,including the imbalanced nature of common insurance datasets. The full code anddocumentation are available on the GitHub repository.(https://github.com/PanyiDong/InsurAutoML)</description><author>Panyi Dong, Zhiyu Quan</author><pubDate>Mon, 26 Aug 2024 14:55:40 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.14331v1</guid></item><item><title>PHEVA: A Privacy-preserving Human-centric Video Anomaly Detection Dataset</title><link>http://arxiv.org/abs/2408.14329v1</link><description>PHEVA, a Privacy-preserving Human-centric Ethical Video Anomaly detectiondataset. By removing pixel information and providing only de-identified humanannotations, PHEVA safeguards personally identifiable information. The datasetincludes seven indoor/outdoor scenes, featuring one novel, context-specificcamera, and offers over 5x the pose-annotated frames compared to the largestprevious dataset. This study benchmarks state-of-the-art methods on PHEVA usinga comprehensive set of metrics, including the 10% Error Rate (10ER), a metricused for anomaly detection for the first time providing insights relevant toreal-world deployment. As the first of its kind, PHEVA bridges the gap betweenconventional training and real-world deployment by introducing continuallearning benchmarks, with models outperforming traditional methods in 82.14% ofcases. The dataset is publicly available athttps://github.com/TeCSAR-UNCC/PHEVA.git.</description><author>Ghazal Alinezhad Noghre, Shanle Yao, Armin Danesh Pazho, Babak Rahimi Ardabili, Vinit Katariya, Hamed Tabkhi</author><pubDate>Mon, 26 Aug 2024 14:55:23 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.14329v1</guid></item><item><title>Streamline tractography of the fetal brain in utero with machine learning</title><link>http://arxiv.org/abs/2408.14326v1</link><description>Diffusion-weighted magnetic resonance imaging (dMRI) is the only non-invasivetool for studying white matter tracts and structural connectivity of the brain.These assessments rely heavily on tractography techniques, which reconstructvirtual streamlines representing white matter fibers. Much effort has beendevoted to improving tractography methodology for adult brains, whiletractography of the fetal brain has been largely neglected. Fetal tractographyfaces unique difficulties due to low dMRI signal quality, immature and rapidlydeveloping brain structures, and paucity of reference data. This work presentsthe first machine learning model for fetal tractography. The model inputconsists of five sources of information: (1) Fiber orientation, inferred from adiffusion tensor fit to the dMRI signal; (2) Directions of recent propagationsteps; (3) Global spatial information, encoded as distances to keypoints in thebrain cortex; (4) Tissue segmentation information; and (5) Prior informationabout the expected local fiber orientations supplied with an atlas. In order tomitigate the local tensor estimation error, a large spatial context around thecurrent point in the diffusion tensor image is encoded using convolutional andattention neural network modules. Moreover, the diffusion tensor information ata hypothetical next point is included in the model input. Filtering rules basedon anatomically constrained tractography are applied to prune implausiblestreamlines. We trained the model on manually-refined whole-brain fetaltractograms and validated the trained model on an independent set of 11 testscans with gestational ages between 23 and 36 weeks. Results show that ourproposed method achieves superior performance across all evaluated tracts. Thenew method can significantly advance the capabilities of dMRI for studyingnormal and abnormal brain development in utero.</description><author>Weide Liu, Camilo Calixto, Simon K. Warfield, Davood Karimi</author><pubDate>Mon, 26 Aug 2024 14:54:14 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.14326v1</guid></item><item><title>Function-Space MCMC for Bayesian Wide Neural Networks</title><link>http://arxiv.org/abs/2408.14325v1</link><description>Bayesian Neural Networks represent a fascinating confluence of deep learningand probabilistic reasoning, offering a compelling framework for understandinguncertainty in complex predictive models. In this paper, we investigate the useof the preconditioned Crank-Nicolson algorithm and its Langevin version tosample from the reparametrised posterior distribution of the weights as thewidths of Bayesian Neural Networks grow larger. In addition to being robust inthe infinite-dimensional setting, we prove that the acceptance probabilities ofthe proposed methods approach 1 as the width of the network increases,independently of any stepsize tuning. Moreover, we examine and compare how themixing speeds of the underdamped Langevin Monte Carlo, the preconditionedCrank-Nicolson and the preconditioned Crank-Nicolson Langevin samplers areinfluenced by changes in the network width in some real-world cases. Ourfindings suggest that, in wide Bayesian Neural Networks configurations, thepreconditioned Crank-Nicolson method allows for more efficient sampling of thereparametrised posterior distribution, as evidenced by a higher effectivesample size and improved diagnostic results compared with the other analysedalgorithms.</description><author>Lucia Pezzetti, Stefano Favaro, Stefano Pelucchetti</author><pubDate>Mon, 26 Aug 2024 14:54:13 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.14325v1</guid></item><item><title>Rethinking Knowledge Transfer in Learning Using Privileged Information</title><link>http://arxiv.org/abs/2408.14319v1</link><description>In supervised machine learning, privileged information (PI) is informationthat is unavailable at inference, but is accessible during training time.Research on learning using privileged information (LUPI) aims to transfer theknowledge captured in PI onto a model that can perform inference without PI. Itseems that this extra bit of information ought to make the resulting modelbetter. However, finding conclusive theoretical or empirical evidence thatsupports the ability to transfer knowledge using PI has been challenging. Inthis paper, we critically examine the assumptions underlying existingtheoretical analyses and argue that there is little theoretical justificationfor when LUPI should work. We analyze LUPI methods and reveal that apparentimprovements in empirical risk of existing research may not directly resultfrom PI. Instead, these improvements often stem from dataset anomalies ormodifications in model design misguidedly attributed to PI. Our experiments fora wide variety of application domains further demonstrate that state-of-the-artLUPI approaches fail to effectively transfer knowledge from PI. Thus, weadvocate for practitioners to exercise caution when working with PI to avoidunintended inductive biases.</description><author>Danil Provodin, Bram van den Akker, Christina Katsimerou, Maurits Kaptein, Mykola Pechenizkiy</author><pubDate>Mon, 26 Aug 2024 14:51:26 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.14319v1</guid></item><item><title>Bridging the Usability Gap: Theoretical and Methodological Advances for Spectral Learning of Hidden Markov Models</title><link>http://arxiv.org/abs/2302.07437v3</link><description>The Baum-Welch (B-W) algorithm is the most widely accepted method forinferring hidden Markov models (HMM). However, it is prone to getting stuck inlocal optima, and can be too slow for many real-time applications. Spectrallearning of HMMs (SHMM), based on the method of moments (MOM) has been proposedin the literature to overcome these obstacles. Despite its promises, asymptotictheory for SHMM has been elusive, and the long-run performance of SHMM candegrade due to unchecked propagation of error. In this paper, we (1) provide anasymptotic distribution for the approximate error of the likelihood estimatedby SHMM, (2) propose a novel algorithm called projected SHMM (PSHMM) thatmitigates the problem of error propagation, and (3) develop online learningvariants of both SHMM and PSHMM that accommodate potential nonstationarity. Wecompare the performance of SHMM with PSHMM and estimation through the B-Walgorithm on both simulated data and data from real world applications, andfind that PSHMM not only retains the computational advantages of SHMM, but alsoprovides more robust estimation and forecasting.</description><author>Xiaoyuan Ma, Jordan Rodu</author><pubDate>Mon, 26 Aug 2024 14:46:08 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2302.07437v3</guid></item><item><title>Claim Verification in the Age of Large Language Models: A Survey</title><link>http://arxiv.org/abs/2408.14317v1</link><description>The large and ever-increasing amount of data available on the Internetcoupled with the laborious task of manual claim and fact verification hassparked the interest in the development of automated claim verificationsystems. Several deep learning and transformer-based models have been proposedfor this task over the years. With the introduction of Large Language Models(LLMs) and their superior performance in several NLP tasks, we have seen asurge of LLM-based approaches to claim verification along with the use of novelmethods such as Retrieval Augmented Generation (RAG). In this survey, wepresent a comprehensive account of recent claim verification frameworks usingLLMs. We describe the different components of the claim verification pipelineused in these frameworks in detail including common approaches to retrieval,prompting, and fine-tuning. Finally, we describe publicly available Englishdatasets created for this task.</description><author>Alphaeus Dmonte, Roland Oruche, Marcos Zampieri, Prasad Calyam, Isabelle Augenstein</author><pubDate>Mon, 26 Aug 2024 14:45:03 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.14317v1</guid></item><item><title>Logic interpretations of ANN partition cells</title><link>http://arxiv.org/abs/2408.14314v1</link><description>Consider a binary classification problem solved using a feed-forwardartificial neural network (ANN). Let the ANN be composed of a ReLU layer andseveral linear layers (convolution, sum-pooling, or fully connected). We assumethe network was trained with high accuracy. Despite numerous suggestedapproaches, interpreting an artificial neural network remains challenging forhumans. For a new method of interpretation, we construct a bridge between asimple ANN and logic. As a result, we can analyze and manipulate the semanticsof an ANN using the powerful tool set of logic. To achieve this, we decomposethe input space of the ANN into several network partition cells. Each networkpartition cell represents a linear combination that maps input values to aclassifying output value. For interpreting the linear map of a partition cellusing logic expressions, we suggest minterm values as the input of a simpleANN. We derive logic expressions representing interaction patterns forseparating objects classified as 1 from those classified as 0. To facilitate aninterpretation of logic expressions, we present them as binary logic trees.</description><author>Ingo Schmitt</author><pubDate>Mon, 26 Aug 2024 14:43:43 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.14314v1</guid></item><item><title>Cross-view Action Recognition Understanding From Exocentric to Egocentric Perspective</title><link>http://arxiv.org/abs/2305.15699v3</link><description>Understanding action recognition in egocentric videos has emerged as a vitalresearch topic with numerous practical applications. With the limitation in thescale of egocentric data collection, learning robust deep learning-based actionrecognition models remains difficult. Transferring knowledge learned from thelarge-scale exocentric data to the egocentric data is challenging due to thedifference in videos across views. Our work introduces a novel cross-viewlearning approach to action recognition (CVAR) that effectively transfersknowledge from the exocentric to the selfish view. First, we present a novelgeometric-based constraint into the self-attention mechanism in Transformerbased on analyzing the camera positions between two views. Then, we propose anew cross-view self-attention loss learned on unpaired cross-view data toenforce the self-attention mechanism learning to transfer knowledge acrossviews. Finally, to further improve the performance of our cross-view learningapproach, we present the metrics to measure the correlations in videos andattention maps effectively. Experimental results on standard egocentric actionrecognition benchmarks, i.e., Charades-Ego, EPIC-Kitchens-55, andEPIC-Kitchens-100, have shown our approach's effectiveness and state-of-the-artperformance.</description><author>Thanh-Dat Truong, Khoa Luu</author><pubDate>Mon, 26 Aug 2024 14:39:33 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.15699v3</guid></item><item><title>LLM-3D Print: Large Language Models To Monitor and Control 3D Printing</title><link>http://arxiv.org/abs/2408.14307v1</link><description>Industry 4.0 has revolutionized manufacturing by driving digitalization andshifting the paradigm toward additive manufacturing (AM). Fused DepositionModeling (FDM), a key AM technology, enables the creation of highly customized,cost-effective products with minimal material waste through layer-by-layerextrusion, posing a significant challenge to traditional subtractive methods.However, the susceptibility of material extrusion techniques to errors oftenrequires expert intervention to detect and mitigate defects that can severelycompromise product quality. While automated error detection and machinelearning models exist, their generalizability across diverse 3D printer setups,firmware, and sensors is limited, and deep learning methods require extensivelabeled datasets, hindering scalability and adaptability. To address thesechallenges, we present a process monitoring and control framework thatleverages pre-trained Large Language Models (LLMs) alongside 3D printers todetect and address printing defects. The LLM evaluates print quality byanalyzing images captured after each layer or print segment, identifyingfailure modes and querying the printer for relevant parameters. It thengenerates and executes a corrective action plan. We validated the effectivenessof the proposed framework in identifying defects by comparing it against acontrol group of engineers with diverse AM expertise. Our evaluationdemonstrated that LLM-based agents not only accurately identify common 3Dprinting errors, such as inconsistent extrusion, stringing, warping, and layeradhesion, but also effectively determine the parameters causing these failuresand autonomously correct them without any need for human intervention.</description><author>Yayati Jadhav, Peter Pak, Amir Barati Farimani</author><pubDate>Mon, 26 Aug 2024 14:38:19 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.14307v1</guid></item><item><title>BlockPruner: Fine-grained Pruning for Large Language Models</title><link>http://arxiv.org/abs/2406.10594v3</link><description>With the rapid growth in the size and complexity of large language models(LLMs), the costs associated with their training and inference have escalatedsignificantly. Research indicates that certain layers in LLMs harborsubstantial redundancy, and pruning these layers has minimal impact on theoverall performance. While various layer pruning methods have been developedbased on this insight, they generally overlook the finer-grained redundancieswithin the layers themselves. In this paper, we delve deeper into thearchitecture of LLMs and demonstrate that finer-grained pruning can be achievedby targeting redundancies in multi-head attention (MHA) and multi-layerperceptron (MLP) blocks. We propose a novel, training-free structured pruningapproach called BlockPruner. Unlike existing layer pruning methods, BlockPrunersegments each Transformer layer into MHA and MLP blocks. It then assesses theimportance of these blocks using perplexity measures and applies a heuristicsearch for iterative pruning. We applied BlockPruner to LLMs of various sizesand architectures and validated its performance across a wide range ofdownstream tasks. Experimental results show that BlockPruner achieves moregranular and effective pruning compared to state-of-the-art baselines.</description><author>Longguang Zhong, Fanqi Wan, Ruijun Chen, Xiaojun Quan, Liangzhi Li</author><pubDate>Mon, 26 Aug 2024 14:30:38 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.10594v3</guid></item><item><title>May the Forgetting Be with You: Alternate Replay for Learning with Noisy Labels</title><link>http://arxiv.org/abs/2408.14284v1</link><description>Forgetting presents a significant challenge during incremental training,making it particularly demanding for contemporary AI systems to assimilate newknowledge in streaming data environments. To address this issue, mostapproaches in Continual Learning (CL) rely on the replay of a restricted bufferof past data. However, the presence of noise in real-world scenarios, wherehuman annotation is constrained by time limitations or where data isautomatically gathered from the web, frequently renders these strategiesvulnerable. In this study, we address the problem of CL under Noisy Labels(CLN) by introducing Alternate Experience Replay (AER), which takes advantageof forgetting to maintain a clear distinction between clean, complex, and noisysamples in the memory buffer. The idea is that complex or mislabeled examples,which hardly fit the previously learned data distribution, are most likely tobe forgotten. To grasp the benefits of such a separation, we equip AER withAsymmetric Balanced Sampling (ABS): a new sample selection strategy thatprioritizes purity on the current task while retaining relevant samples fromthe past. Through extensive computational comparisons, we demonstrate theeffectiveness of our approach in terms of both accuracy and purity of theobtained buffer, resulting in a remarkable average gain of 4.71% points inaccuracy with respect to existing loss-based purification strategies. Code isavailable at https://github.com/aimagelab/mammoth.</description><author>Monica Millunzi, Lorenzo Bonicelli, Angelo Porrello, Jacopo Credi, Petter N. Kolm, Simone Calderara</author><pubDate>Mon, 26 Aug 2024 14:09:40 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.14284v1</guid></item><item><title>Field theory for optimal signal propagation in ResNets</title><link>http://arxiv.org/abs/2305.07715v2</link><description>Residual networks have significantly better trainability and thus performancethan feed-forward networks at large depth. Introducing skip connectionsfacilitates signal propagation to deeper layers. In addition, previous worksfound that adding a scaling parameter for the residual branch further improvesgeneralization performance. While they empirically identified a particularlybeneficial range of values for this scaling parameter, the associatedperformance improvement and its universality across network hyperparameters yetneed to be understood. For feed-forward networks, finite-size theories have ledto important insights with regard to signal propagation and hyperparametertuning. We here derive a systematic finite-size field theory for residualnetworks to study signal propagation and its dependence on the scaling for theresidual branch. We derive analytical expressions for the response function, ameasure for the network's sensitivity to inputs, and show that for deepnetworks the empirically found values for the scaling parameter lie within therange of maximal sensitivity. Furthermore, we obtain an analytical expressionfor the optimal scaling parameter that depends only weakly on other networkhyperparameters, such as the weight variance, thereby explaining itsuniversality across hyperparameters. Overall, this work provides a theoreticalframework to study ResNets at finite size.</description><author>Kirsten Fischer, David Dahmen, Moritz Helias</author><pubDate>Mon, 26 Aug 2024 14:09:37 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.07715v2</guid></item><item><title>Predictability and Causality in Spanish and English Natural Language Generation</title><link>http://arxiv.org/abs/2408.14283v1</link><description>In recent years, the field of Natural Language Generation (NLG) has beenboosted by the recent advances in deep learning technologies. Nonetheless,these new data-intensive methods introduce language-dependent disparities inNLG as the main training data sets are in English. Also, most neural NLGsystems use decoder-only (causal) transformer language models, which work wellfor English, but were not designed with other languages in mind. In this workwe depart from the hypothesis that they may introduce generation bias in targetlanguages with less rigid word ordering, subject omission, or differentattachment preferences for relative clauses, so that for these target languagesother language generation strategies may be more desirable. This paper firstcompares causal and non-causal language modeling for English and Spanish, twolanguages with different grammatical structures and over 1.5 billion and 0.5billion speakers, respectively. For this purpose, we define a novel metric ofaverage causal and non-causal context-conditioned entropy of the grammaticalcategory distribution for both languages as an information-theoretic a prioriapproach. The evaluation of natural text sources (such as training data) inboth languages reveals lower average non-causal conditional entropy in Spanishand lower causal conditional entropy in English. According to this experiment,Spanish is more predictable than English given a non-causal context. Then, byapplying a conditional relative entropy metric to text generation experiments,we obtain as insights that the best performance is respectively achieved withcausal NLG in English, and with non-causal NLG in Spanish. These insightssupport further research in NLG in Spanish using bidirectional transformerlanguage models.</description><author>Andrea Busto-CastiÃ±eira, Francisco J. GonzÃ¡lez-CastaÃ±o, Silvia GarcÃ­a-MÃ©ndez, Francisco de Arriba-PÃ©rez</author><pubDate>Mon, 26 Aug 2024 14:09:28 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.14283v1</guid></item><item><title>Pediatric TSC-Related Epilepsy Classification from Clinical MR Images Using Quantum Neural Network</title><link>http://arxiv.org/abs/2408.12615v2</link><description>Tuberous sclerosis complex (TSC) manifests as a multisystem disorder withsignificant neurological implications. This study addresses the critical needfor robust classification models tailored to TSC in pediatric patients,introducing QResNet,a novel deep learning model seamlessly integratingconventional convolutional neural networks with quantum neural networks. Themodel incorporates a two-layer quantum layer (QL), comprising ZZFeatureMap andAnsatz layers, strategically designed for processing classical data within aquantum framework. A comprehensive evaluation, demonstrates the superiorperformance of QResNet in TSC MRI image classification compared to conventional3D-ResNet models. These compelling findings underscore the potential of quantumcomputing to revolutionize medical imaging and diagnostics.Remarkably, thismethod surpasses conventional CNNs in accuracy and Area Under the Curve (AUC)metrics with the current dataset. Future research endeavors may focus onexploring the scalability and practical implementation of quantum algorithms inreal-world medical imaging scenarios.</description><author>Ling Lin, Yihang Zhou, Zhanqi Hu, Dian Jiang, Congcong Liu, Shuo Zhou, Yanjie Zhu, Jianxiang Liao, Dong Liang, Hairong Zheng, Haifeng Wang</author><pubDate>Mon, 26 Aug 2024 14:06:59 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.12615v2</guid></item><item><title>Uncertainties of Latent Representations in Computer Vision</title><link>http://arxiv.org/abs/2408.14281v1</link><description>Uncertainty quantification is a key pillar of trustworthy machine learning.It enables safe reactions under unsafe inputs, like predicting only when themachine learning model detects sufficient evidence, discarding anomalous data,or emitting warnings when an error is likely to be inbound. This isparticularly crucial in safety-critical areas like medical image classificationor self-driving cars. Despite the plethora of proposed uncertaintyquantification methods achieving increasingly higher scores on performancebenchmarks, uncertainty estimates are often shied away from in practice. Manymachine learning projects start from pretrained latent representations thatcome without uncertainty estimates. Uncertainties would need to be trained bypractitioners on their own, which is notoriously difficult andresource-intense. This thesis makes uncertainty estimates easily accessible by adding them tothe latent representation vectors of pretrained computer vision models. Besidesproposing approaches rooted in probability and decision theory, such asMonte-Carlo InfoNCE (MCInfoNCE) and loss prediction, we delve into boththeoretical and empirical questions. We show that these unobservableuncertainties about unobservable latent representations are indeed provablycorrect. We also provide an uncertainty-aware representation learning (URL)benchmark to compare these unobservables against observable ground-truths.Finally, we compile our findings to pretrain lightweight representationuncertainties on large-scale computer vision models that transfer to unseendatasets in a zero-shot manner. Our findings do not only advance the current theoretical understanding ofuncertainties over latent variables, but also facilitate the access touncertainty quantification for future researchers inside and outside the field,enabling straightforward but trustworthy machine learning.</description><author>Michael Kirchhof</author><pubDate>Mon, 26 Aug 2024 14:02:30 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.14281v1</guid></item><item><title>Attention-guided Feature Distillation for Semantic Segmentation</title><link>http://arxiv.org/abs/2403.05451v2</link><description>In contrast to existing complex methodologies commonly employed fordistilling knowledge from a teacher to a student, this paper showcases theefficacy of a simple yet powerful method for utilizing refined feature maps totransfer attention. The proposed method has proven to be effective indistilling rich information, outperforming existing methods in semanticsegmentation as a dense prediction task. The proposed Attention-guided FeatureDistillation (AttnFD) method, employs the Convolutional Block Attention Module(CBAM), which refines feature maps by taking into account both channel-specificand spatial information content. Simply using the Mean Squared Error (MSE) lossfunction between the refined feature maps of the teacher and the student,AttnFD demonstrates outstanding performance in semantic segmentation, achievingstate-of-the-art results in terms of improving the mean Intersection over Union(mIoU) of the student network on the PascalVoc 2012, Cityscapes, COCO, andCamVid datasets.</description><author>Amir M. Mansourian, Arya Jalali, Rozhan Ahmadi, Shohreh Kasaei</author><pubDate>Mon, 26 Aug 2024 13:58:16 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.05451v2</guid></item><item><title>When accurate prediction models yield harmful self-fulfilling prophecies</title><link>http://arxiv.org/abs/2312.01210v4</link><description>Prediction models are popular in medical research and practice. By predictingan outcome of interest for specific patients, these models may help informdifficult treatment decisions, and are often hailed as the poster children forpersonalized, data-driven healthcare. We show however, that using predictionmodels for decision making can lead to harmful decisions, even when thepredictions exhibit good discrimination after deployment. These models areharmful self-fulfilling prophecies: their deployment harms a group of patientsbut the worse outcome of these patients does not invalidate the predictivepower of the model. Our main result is a formal characterization of a set ofsuch prediction models. Next we show that models that are well calibratedbefore and after deployment are useless for decision making as they made nochange in the data distribution. These results point to the need to revisestandard practices for validation, deployment and evaluation of predictionmodels that are used in medical decisions.</description><author>Wouter A. C. van Amsterdam, Nan van Geloven, Jesse H. Krijthe, Rajesh Ranganath, Giovanni CinÃ¡</author><pubDate>Mon, 26 Aug 2024 13:57:31 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.01210v4</guid></item><item><title>Docling Technical Report</title><link>http://arxiv.org/abs/2408.09869v2</link><description>This technical report introduces Docling, an easy to use, self-contained,MIT-licensed open-source package for PDF document conversion. It is powered bystate-of-the-art specialized AI models for layout analysis (DocLayNet) andtable structure recognition (TableFormer), and runs efficiently on commodityhardware in a small resource budget. The code interface allows for easyextensibility and addition of new features and models.</description><author>Christoph Auer, Maksym Lysak, Ahmed Nassar, Michele Dolfi, Nikolaos Livathinos, Panos Vagenas, Cesar Berrospi Ramis, Matteo Omenetti, Fabian Lindlbauer, Kasper Dinkla, Valery Weber, Lucas Morin, Ingmar Meijer, Viktor Kuropiatnyk, Peter W. J. Staar</author><pubDate>Mon, 26 Aug 2024 13:55:59 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.09869v2</guid></item><item><title>Learning Local Pattern Modularization for Point Cloud Reconstruction from Unseen Classes</title><link>http://arxiv.org/abs/2408.14279v1</link><description>It is challenging to reconstruct 3D point clouds in unseen classes fromsingle 2D images. Instead of object-centered coordinate system, current methodsgeneralized global priors learned in seen classes to reconstruct 3D shapes fromunseen classes in viewer-centered coordinate system. However, thereconstruction accuracy and interpretability are still eager to get improved.To resolve this issue, we introduce to learn local pattern modularization forreconstructing 3D shapes in unseen classes, which achieves both goodgeneralization ability and high reconstruction accuracy. Our insight is tolearn a local prior which is class-agnostic and easy to generalize inobject-centered coordinate system. Specifically, the local prior is learned viaa process of learning and customizing local pattern modularization in seenclasses. During this process, we first learn a set of patterns in localregions, which is the basis in the object-centered coordinate system torepresent an arbitrary region on shapes across different classes. Then, wemodularize each region on an initially reconstructed shape using the learnedlocal patterns. Based on that, we customize the local pattern modularizationusing the input image by refining the reconstruction with more details. Ourmethod enables to reconstruct high fidelity point clouds from unseen classes inobject-centered coordinate system without requiring a large number of patternsor any additional information, such as segmentation supervision or cameraposes. Our experimental results under widely used benchmarks show that ourmethod achieves the state-of-the-art reconstruction accuracy for shapes fromunseen classes. The code is available at https://github.com/chenchao15/Unseen.</description><author>Chao Chen, Zhizhong Han, Yu-Shen Liu</author><pubDate>Mon, 26 Aug 2024 13:55:42 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.14279v1</guid></item><item><title>Epidemic Information Extraction for Event-Based Surveillance using Large Language Models</title><link>http://arxiv.org/abs/2408.14277v1</link><description>This paper presents a novel approach to epidemic surveillance, leveraging thepower of Artificial Intelligence and Large Language Models (LLMs) for effectiveinterpretation of unstructured big data sources, like the popular ProMED andWHO Disease Outbreak News. We explore several LLMs, evaluating theircapabilities in extracting valuable epidemic information. We further enhancethe capabilities of the LLMs using in-context learning, and test theperformance of an ensemble model incorporating multiple open-source LLMs. Thefindings indicate that LLMs can significantly enhance the accuracy andtimeliness of epidemic modelling and forecasting, offering a promising tool formanaging future pandemic events.</description><author>Sergio Consoli, Peter Markov, Nikolaos I. Stilianakis, Lorenzo Bertolini, Antonio Puertas Gallardo, Mario Ceresa</author><pubDate>Mon, 26 Aug 2024 13:53:04 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.14277v1</guid></item><item><title>Filter &amp; Align: Curating Image-Text Data with Human Knowledge</title><link>http://arxiv.org/abs/2312.06726v3</link><description>The increasing availability of image-text pairs has largely fueled the rapidadvancement in vision-language foundation models. However, the vast scale ofthese datasets inevitably introduces significant variability in data quality,which can adversely affect the model performance. This highlights the criticalrole of data filtering, not only to enhance training efficiency but also toimprove overall data quality. Existing methods typically rely on metrics suchas CLIP Score and BLIP Score, which are derived from pre-trained models.However, these models are often trained on uncurated, noisy datasets, which canperpetuate errors and misalignments in the filtered dataset. We present a novelalgorithm that incorporates human knowledge on image-text alignment to guidefiltering vast corpus of web-crawled image-text datasets into a compact andhigh-quality form. To systemically capture human preferences on image-textalignments, we collect a diverse image-text dataset where each image isassociated with multiple captions from various sources, and establish acomprehensive set of both subjective and objective criteria for criticallyguiding the alignment assessment from labelers. Additionally, we train a rewardmodel on these human-preference annotations to internalize the nuanced humanunderstanding of image-text alignment. The resulting reward model thus can actas a human-like referee to filter image-text pairs. Extensive experimentsdemonstrate that we can maintain, sometimes even improve, model performancewhile compressing the image-text datasets up to ~90%. An impressive example isthat, by aggressively reducing the total training sample from 130M to only15.5M, our BLIP-B/16 models consistently show an average improvement of 2.9% onretrieval tasks and 11.5% on captioning tasks compared to full-size-datasetcounterparts.</description><author>Lei Zhang, Fangxun Shu, Tianyang Liu, Sucheng Ren, Hao Jiang, Cihang Xie</author><pubDate>Mon, 26 Aug 2024 13:52:18 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.06726v3</guid></item><item><title>OLGA: One-cLass Graph Autoencoder</title><link>http://arxiv.org/abs/2406.09131v2</link><description>One-class learning (OCL) comprises a set of techniques applied whenreal-world problems have a single class of interest. The usual procedure forOCL is learning a hypersphere that comprises instances of this class and,ideally, repels unseen instances from any other classes. Besides, several OCLalgorithms for graphs have been proposed since graph representation learninghas succeeded in various fields. These methods may use a two-step strategy,initially representing the graph and, in a second step, classifying its nodes.On the other hand, end-to-end methods learn the node representations whileclassifying the nodes in one learning process. We highlight three main gaps inthe literature on OCL for graphs: (i) non-customized representations for OCL;(ii) the lack of constraints on hypersphere parameters learning; and (iii) themethods' lack of interpretability and visualization. We propose One-cLass GraphAutoencoder (OLGA). OLGA is end-to-end and learns the representations for thegraph nodes while encapsulating the interest instances by combining two lossfunctions. We propose a new hypersphere loss function to encapsulate theinterest instances. OLGA combines this new hypersphere loss with the graphautoencoder reconstruction loss to improve model learning. OLGA achievedstate-of-the-art results and outperformed six other methods with astatistically significant difference from five methods. Moreover, OLGA learnslow-dimensional representations maintaining the classification performance withan interpretable model representation learning and results.</description><author>M. P. S. GÃ´lo, J. G. B. M. Junior, D. F. Silva, R. M. Marcacini</author><pubDate>Mon, 26 Aug 2024 13:48:32 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.09131v2</guid></item><item><title>Reliable Multi-modal Medical Image-to-image Translation Independent of Pixel-wise Aligned Data</title><link>http://arxiv.org/abs/2408.14270v1</link><description>The current mainstream multi-modal medical image-to-image translation methodsface a contradiction. Supervised methods with outstanding performance rely onpixel-wise aligned training data to constrain the model optimization. However,obtaining pixel-wise aligned multi-modal medical image datasets is challenging.Unsupervised methods can be trained without paired data, but their reliabilitycannot be guaranteed. At present, there is no ideal multi-modal medicalimage-to-image translation method that can generate reliable translationresults without the need for pixel-wise aligned data. This work aims to developa novel medical image-to-image translation model that is independent ofpixel-wise aligned data (MITIA), enabling reliable multi-modal medicalimage-to-image translation under the condition of misaligned training data. Theproposed MITIA model utilizes a prior extraction network composed of amulti-modal medical image registration module and a multi-modal misalignmenterror detection module to extract pixel-level prior information from trainingdata with misalignment errors to the largest extent. The extracted priorinformation is then used to construct a regularization term to constrain theoptimization of the unsupervised cycle-consistent GAN model, restricting itssolution space and thereby improving the performance and reliability of thegenerator. We trained the MITIA model using six datasets containing differentmisalignment errors and two well-aligned datasets. Subsequently, we comparedthe proposed method with six other state-of-the-art image-to-image translationmethods. The results of both quantitative analysis and qualitative visualinspection indicate that MITIA achieves superior performance compared to thecompeting state-of-the-art methods, both on misaligned data and aligned data.</description><author>Langrui Zhou, Guang Li</author><pubDate>Mon, 26 Aug 2024 13:45:58 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.14270v1</guid></item><item><title>PDEBENCH: An Extensive Benchmark for Scientific Machine Learning</title><link>http://arxiv.org/abs/2210.07182v7</link><description>Machine learning-based modeling of physical systems has experienced increasedinterest in recent years. Despite some impressive progress, there is still alack of benchmarks for Scientific ML that are easy to use but still challengingand representative of a wide range of problems. We introduce PDEBench, abenchmark suite of time-dependent simulation tasks based on PartialDifferential Equations (PDEs). PDEBench comprises both code and data tobenchmark the performance of novel machine learning models against bothclassical numerical simulations and machine learning baselines. Our proposedset of benchmark problems contribute the following unique features: (1) A muchwider range of PDEs compared to existing benchmarks, ranging from relativelycommon examples to more realistic and difficult problems; (2) much largerready-to-use datasets compared to prior work, comprising multiple simulationruns across a larger number of initial and boundary conditions and PDEparameters; (3) more extensible source codes with user-friendly APIs for datageneration and baseline results with popular machine learning models (FNO,U-Net, PINN, Gradient-Based Inverse Method). PDEBench allows researchers toextend the benchmark freely for their own purposes using a standardized API andto compare the performance of new models to existing baseline methods. We alsopropose new evaluation metrics with the aim to provide a more holisticunderstanding of learning methods in the context of Scientific ML. With thosemetrics we identify tasks which are challenging for recent ML methods andpropose these tasks as future challenges for the community. The code isavailable at https://github.com/pdebench/PDEBench.</description><author>Makoto Takamoto, Timothy Praditia, Raphael Leiteritz, Dan MacKinlay, Francesco Alesiani, Dirk PflÃ¼ger, Mathias Niepert</author><pubDate>Mon, 26 Aug 2024 13:43:46 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2210.07182v7</guid></item><item><title>1-Bit FQT: Pushing the Limit of Fully Quantized Training to 1-bit</title><link>http://arxiv.org/abs/2408.14267v1</link><description>Fully quantized training (FQT) accelerates the training of deep neuralnetworks by quantizing the activations, weights, and gradients into lowerprecision. To explore the ultimate limit of FQT (the lowest achievableprecision), we make a first attempt to 1-bit FQT. We provide a theoreticalanalysis of FQT based on Adam and SGD, revealing that the gradient varianceinfluences the convergence of FQT. Building on these theoretical results, weintroduce an Activation Gradient Pruning (AGP) strategy. The strategy leveragesthe heterogeneity of gradients by pruning less informative gradients andenhancing the numerical precision of remaining gradients to mitigate gradientvariance. Additionally, we propose Sample Channel joint Quantization (SCQ),which utilizes different quantization strategies in the computation of weightgradients and activation gradients to ensure that the method is friendly tolow-bitwidth hardware. Finally, we present a framework to deploy our algorithm.For fine-tuning VGGNet-16 and ResNet-18 on multiple datasets, our algorithmachieves an average accuracy improvement of approximately 6%, compared toper-sample quantization. Moreover, our training speedup can reach a maximum of5.13x compared to full precision training.</description><author>Chang Gao, Jianfei Chen, Kang Zhao, Jiaqi Wang, Liping Jing</author><pubDate>Mon, 26 Aug 2024 13:42:43 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.14267v1</guid></item><item><title>VFMM3D: Releasing the Potential of Image by Vision Foundation Model for Monocular 3D Object Detection</title><link>http://arxiv.org/abs/2404.09431v2</link><description>Due to its cost-effectiveness and widespread availability, monocular 3Dobject detection, which relies solely on a single camera during inference,holds significant importance across various applications, including autonomousdriving and robotics. Nevertheless, directly predicting the coordinates ofobjects in 3D space from monocular images poses challenges. Therefore, aneffective solution involves transforming monocular images into LiDAR-likerepresentations and employing a LiDAR-based 3D object detector to predict the3D coordinates of objects. The key step in this method is accurately convertingthe monocular image into a reliable point cloud form. In this paper, we presentVFMM3D, an innovative framework that leverages the capabilities of VisionFoundation Models (VFMs) to accurately transform single-view images into LiDARpoint cloud representations. VFMM3D utilizes the Segment Anything Model (SAM)and Depth Anything Model (DAM) to generate high-quality pseudo-LiDAR dataenriched with rich foreground information. Specifically, the Depth AnythingModel (DAM) is employed to generate dense depth maps. Subsequently, the SegmentAnything Model (SAM) is utilized to differentiate foreground and backgroundregions by predicting instance masks. These predicted instance masks and depthmaps are then combined and projected into 3D space to generate pseudo-LiDARpoints. Finally, any object detectors based on point clouds can be utilized topredict the 3D coordinates of objects. Comprehensive experiments are conductedon two challenging 3D object detection datasets, KITTI and Waymo. Our VFMM3Destablishes a new state-of-the-art performance on both datasets. Additionally,experimental results demonstrate the generality of VFMM3D, showcasing itsseamless integration into various LiDAR-based 3D object detectors.</description><author>Bonan Ding, Jin Xie, Jing Nie, Jiale Cao, Xuelong Li, Yanwei Pang</author><pubDate>Mon, 26 Aug 2024 13:41:14 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.09431v2</guid></item><item><title>HyperSBINN: A Hypernetwork-Enhanced Systems Biology-Informed Neural Network for Efficient Drug Cardiosafety Assessment</title><link>http://arxiv.org/abs/2408.14266v1</link><description>Mathematical modeling in systems toxicology enables a comprehensiveunderstanding of the effects of pharmaceutical substances on cardiac health.However, the complexity of these models limits their widespread application inearly drug discovery. In this paper, we introduce a novel approach to solvingparameterized models of cardiac action potentials by combining meta-learningtechniques with Systems Biology-Informed Neural Networks (SBINNs). The proposedmethod, HyperSBINN, effectively addresses the challenge of predicting theeffects of various compounds at different concentrations on cardiac actionpotentials, outperforming traditional differential equation solvers in speed.Our model efficiently handles scenarios with limited data and complexparameterized differential equations. The HyperSBINN model demonstrates robustperformance in predicting APD90 values, indicating its potential as a reliabletool for modeling cardiac electrophysiology and aiding in preclinical drugdevelopment. This framework represents an advancement in computationalmodeling, offering a scalable and efficient solution for simulating andunderstanding complex biological systems.</description><author>Inass Soukarieh, Gerhard Hessler, HervÃ© Minoux, Marcel Mohr, Friedemann Schmidt, Jan Wenzel, Pierre Barbillon, Hugo Gangloff, Pierre Gloaguen</author><pubDate>Mon, 26 Aug 2024 13:40:33 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.14266v1</guid></item><item><title>Self-supervised Speech Representations Still Struggle with African American Vernacular English</title><link>http://arxiv.org/abs/2408.14262v1</link><description>Underperformance of ASR systems for speakers of African American VernacularEnglish (AAVE) and other marginalized language varieties is a well-documentedphenomenon, and one that reinforces the stigmatization of these varieties. Weinvestigate whether or not the recent wave of Self-Supervised Learning (SSL)speech models can close the gap in ASR performance between AAVE and MainstreamAmerican English (MAE). We evaluate four SSL models (wav2vec 2.0, HuBERT,WavLM, and XLS-R) on zero-shot Automatic Speech Recognition (ASR) for these twovarieties and find that these models perpetuate the bias in performance againstAAVE. Additionally, the models have higher word error rates on utterances withmore phonological and morphosyntactic features of AAVE. Despite the success ofSSL speech models in improving ASR for low resource varieties, SSL pre-trainingalone may not bridge the gap between AAVE and MAE. Our code is publiclyavailable at https://github.com/cmu-llab/s3m-aave.</description><author>Kalvin Chang, Yi-Hui Chou, Jiatong Shi, Hsuan-Ming Chen, Nicole Holliday, Odette Scharenborg, David R. Mortensen</author><pubDate>Mon, 26 Aug 2024 13:29:25 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.14262v1</guid></item></channel></rss>