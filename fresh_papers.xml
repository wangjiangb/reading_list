<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/"><channel><title>Arxivfresh papers</title><link></link><description>Arxiv paper</description><language>en-US</language><lastBuildDate>Wed, 10 May 2023 14:00:03 GMT</lastBuildDate><generator>rfeed v1.0.0</generator><docs>https://github.com/svpino/rfeed/blob/master/README.md</docs><item><title>Policy Gradient Methods in the Presence of Symmetries and State Abstractions</title><link>http://arxiv.org/abs/2305.05666v1</link><description>Reinforcement learning on high-dimensional and complex problems relies onabstraction for improved efficiency and generalization. In this paper, we studyabstraction in the continuous-control setting, and extend the definition of MDPhomomorphisms to the setting of continuous state and action spaces. We derive apolicy gradient theorem on the abstract MDP for both stochastic anddeterministic policies. Our policy gradient results allow for leveragingapproximate symmetries of the environment for policy optimization. Based onthese theorems, we propose a family of actor-critic algorithms that are able tolearn the policy and the MDP homomorphism map simultaneously, using the laxbisimulation metric. Finally, we introduce a series of environments withcontinuous symmetries to further demonstrate the ability of our algorithm foraction abstraction in the presence of such symmetries. We demonstrate theeffectiveness of our method on our environments, as well as on challengingvisual control tasks from the DeepMind Control Suite. Our method's ability toutilize MDP homomorphisms for representation learning leads to improvedperformance, and the visualizations of the latent space clearly demonstrate thestructure of the learned abstraction.</description><author>Prakash Panangaden, Sahand Rezaei-Shoshtari, Rosie Zhao, David Meger, Doina Precup</author><pubDate>Tue, 09 May 2023 18:59:10 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.05666v1</guid></item><item><title>ImageBind: One Embedding Space To Bind Them All</title><link>http://arxiv.org/abs/2305.05665v1</link><description>We present ImageBind, an approach to learn a joint embedding across sixdifferent modalities - images, text, audio, depth, thermal, and IMU data. Weshow that all combinations of paired data are not necessary to train such ajoint embedding, and only image-paired data is sufficient to bind themodalities together. ImageBind can leverage recent large scale vision-languagemodels, and extends their zero-shot capabilities to new modalities just byusing their natural pairing with images. It enables novel emergent applications'out-of-the-box' including cross-modal retrieval, composing modalities witharithmetic, cross-modal detection and generation. The emergent capabilitiesimprove with the strength of the image encoder and we set a newstate-of-the-art on emergent zero-shot recognition tasks across modalities,outperforming specialist supervised models. Finally, we show strong few-shotrecognition results outperforming prior work, and that ImageBind serves as anew way to evaluate vision models for visual and non-visual tasks.</description><author>Rohit Girdhar, Alaaeldin El-Nouby, Zhuang Liu, Mannat Singh, Kalyan Vasudev Alwala, Armand Joulin, Ishan Misra</author><pubDate>Tue, 09 May 2023 18:59:07 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.05665v1</guid></item><item><title>InternChat: Solving Vision-Centric Tasks by Interacting with Chatbots Beyond Language</title><link>http://arxiv.org/abs/2305.05662v1</link><description>We present an interactive visual framework named InternChat, or iChat forshort. The framework integrates chatbots that have planning and reasoningcapabilities, such as ChatGPT, with non-verbal instructions like pointingmovements that enable users to directly manipulate images or videos on thescreen. Pointing (including gestures, cursors, etc.) movements can provide moreflexibility and precision in performing vision-centric tasks that requirefine-grained control, editing, and generation of visual content. The nameInternChat stands for interaction, nonverbal, and chatbots. Different fromexisting interactive systems that rely on pure language, by incorporatingpointing instructions, the proposed iChat significantly improves the efficiencyof communication between users and chatbots, as well as the accuracy ofchatbots in vision-centric tasks, especially in complicated visual scenarioswhere the number of objects is greater than 2. Additionally, in iChat, anauxiliary control mechanism is used to improve the control capability of LLM,and a large vision-language model termed Husky is fine-tuned for high-qualitymulti-modal dialogue (impressing ChatGPT-3.5-turbo with 93.89% GPT-4 Quality).We hope this work can spark new ideas and directions for future interactivevisual systems. Welcome to watch the code athttps://github.com/OpenGVLab/InternChat.</description><author>Zhaoyang Liu, Yinan He, Wenhai Wang, Weiyun Wang, Yi Wang, Shoufa Chen, Qinglong Zhang, Yang Yang, Qingyun Li, Jiashuo Yu, Kunchang Li, Zhe Chen, Xue Yang, Xizhou Zhu, Yali Wang, Limin Wang, Ping Luo, Jifeng Dai, Yu Qiao</author><pubDate>Tue, 09 May 2023 18:58:34 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.05662v1</guid></item><item><title>ShapeCoder: Discovering Abstractions for Visual Programs from Unstructured Primitives</title><link>http://arxiv.org/abs/2305.05661v1</link><description>Programs are an increasingly popular representation for visual data, exposingcompact, interpretable structure that supports manipulation. Visual programsare usually written in domain-specific languages (DSLs). Finding "good"programs, that only expose meaningful degrees of freedom, requires access to aDSL with a "good" library of functions, both of which are typically authored bydomain experts. We present ShapeCoder, the first system capable of taking adataset of shapes, represented with unstructured primitives, and jointlydiscovering (i) useful abstraction functions and (ii) programs that use theseabstractions to explain the input shapes. The discovered abstractions capturecommon patterns (both structural and parametric) across the dataset, so thatprograms rewritten with these abstractions are more compact, and expose fewerdegrees of freedom. ShapeCoder improves upon previous abstraction discoverymethods, finding better abstractions, for more complex inputs, under lessstringent input assumptions. This is principally made possible by twomethodological advancements: (a) a shape to program recognition network thatlearns to solve sub-problems and (b) the use of e-graphs, augmented with aconditional rewrite scheme, to determine when abstractions with complexparametric expressions can be applied, in a tractable manner. We evaluateShapeCoder on multiple datasets of 3D shapes, where primitive decompositionsare either parsed from manual annotations or produced by an unsupervised cuboidabstraction method. In all domains, ShapeCoder discovers a library ofabstractions that capture high-level relationships, remove extraneous degreesof freedom, and achieve better dataset compression compared with alternativeapproaches. Finally, we investigate how programs rewritten to use discoveredabstractions prove useful for downstream tasks.</description><author>R. Kenny Jones, Paul Guerrero, Niloy J. Mitra, Daniel Ritchie</author><pubDate>Tue, 09 May 2023 18:55:48 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.05661v1</guid></item><item><title>TidyBot: Personalized Robot Assistance with Large Language Models</title><link>http://arxiv.org/abs/2305.05658v1</link><description>For a robot to personalize physical assistance effectively, it must learnuser preferences that can be generally reapplied to future scenarios. In thiswork, we investigate personalization of household cleanup with robots that cantidy up rooms by picking up objects and putting them away. A key challenge isdetermining the proper place to put each object, as people's preferences canvary greatly depending on personal taste or cultural background. For instance,one person may prefer storing shirts in the drawer, while another may preferthem on the shelf. We aim to build systems that can learn such preferences fromjust a handful of examples via prior interactions with a particular person. Weshow that robots can combine language-based planning and perception with thefew-shot summarization capabilities of large language models (LLMs) to infergeneralized user preferences that are broadly applicable to futureinteractions. This approach enables fast adaptation and achieves 91.2% accuracyon unseen objects in our benchmark dataset. We also demonstrate our approach ona real-world mobile manipulator called TidyBot, which successfully puts away85.0% of objects in real-world test scenarios.</description><author>Jimmy Wu, Rika Antonova, Adam Kan, Marion Lepert, Andy Zeng, Shuran Song, Jeannette Bohg, Szymon Rusinkiewicz, Thomas Funkhouser</author><pubDate>Tue, 09 May 2023 18:52:59 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.05658v1</guid></item><item><title>Provably Convergent Plug-and-Play Quasi-Newton Methods</title><link>http://arxiv.org/abs/2303.07271v2</link><description>Plug-and-Play (PnP) methods are a class of efficient iterative methods thataim to combine data fidelity terms and deep denoisers using classicaloptimization algorithms, such as ISTA or ADMM. Existing provable PnP methodsimpose heavy restrictions on the denoiser or fidelity function, such asnonexpansiveness or strict convexity. In this work, we propose a provable PnPmethod that imposes relatively light conditions based on proximal denoisers,and introduce a quasi-Newton step to greatly accelerate convergence. Byspecially parameterizing the deep denoiser as a gradient step, we furthercharacterize the fixed-points of the quasi-Newton PnP algorithm as criticalpoints of a possibly non-convex function.</description><author>Hong Ye Tan, Subhadip Mukherjee, Junqi Tang, Carola-Bibiane Schönlieb</author><pubDate>Tue, 09 May 2023 18:50:21 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2303.07271v2</guid></item><item><title>Could AI be the Great Filter? What Astrobiology can Teach the Intelligence Community about Anthropogenic Risks</title><link>http://arxiv.org/abs/2305.05653v1</link><description>Where is everybody? This phrase distills the foreboding of what has come tobe known as the Fermi Paradox - the disquieting idea that, if extraterrestriallife is probable in the Universe, then why have we not encountered it? Thisconundrum has puzzled scholars for decades, and many hypotheses have beenproposed suggesting both naturalistic and sociological explanations. Oneintriguing hypothesis is known as the Great Filter, which suggests that someevent required for the emergence of intelligent life is extremely unlikely,hence the cosmic silence. A logically equivalent version of this hypothesis --and one that should give us pause -- suggests that some catastrophic event islikely to occur that prevents life's expansion throughout the cosmos. Thiscould be a naturally occurring event, or more disconcertingly, something thatintelligent beings do to themselves that leads to their own extinction. From anintelligence perspective, framing global catastrophic risk (particularly risksof anthropogenic origin) within the context of the Great Filter can provideinsight into the long-term futures of technologies that we don't fullyunderstand, like artificial intelligence. For the intelligence professionalconcerned with global catastrophic risk, this has significant implications forhow these risks ought to be prioritized.</description><author>Mark M. Bailey</author><pubDate>Tue, 09 May 2023 18:50:02 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.05653v1</guid></item><item><title>SwinIA: Self-Supervised Blind-Spot Image Denoising with Zero Convolutions</title><link>http://arxiv.org/abs/2305.05651v1</link><description>The essence of self-supervised image denoising is to restore the signal fromthe noisy image alone. State-of-the-art solutions for this task rely on theidea of masking pixels and training a fully-convolutional neural network toimpute them. This most often requires multiple forward passes, informationabout the noise model, and intricate regularization functions. In this paper,we propose a Swin Transformer-based Image Autoencoder (SwinIA), the firstconvolution-free architecture for self-supervised denoising. It can be trainedend-to-end with a simple mean squared error loss without masking and does notrequire any prior knowledge about clean data or noise distribution. Despite itssimplicity, SwinIA establishes state-of-the-art on several common benchmarks.</description><author>Mikhail Papkov, Pavel Chizhov</author><pubDate>Tue, 09 May 2023 18:49:27 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.05651v1</guid></item><item><title>Predicting Cardiovascular Disease Risk using Photoplethysmography and Deep Learning</title><link>http://arxiv.org/abs/2305.05648v1</link><description>Cardiovascular diseases (CVDs) are responsible for a large proportion ofpremature deaths in low- and middle-income countries. Early CVD detection andintervention is critical in these populations, yet many existing CVD riskscores require a physical examination or lab measurements, which can bechallenging in such health systems due to limited accessibility. Here weinvestigated the potential to use photoplethysmography (PPG), a sensingtechnology available on most smartphones that can potentially enablelarge-scale screening at low cost, for CVD risk prediction. We developed a deeplearning PPG-based CVD risk score (DLS) to predict the probability of havingmajor adverse cardiovascular events (MACE: non-fatal myocardial infarction,stroke, and cardiovascular death) within ten years, given only age, sex,smoking status and PPG as predictors. We compared the DLS with the office-basedrefit-WHO score, which adopts the shared predictors from WHO and Globoriskscores (age, sex, smoking status, height, weight and systolic blood pressure)but refitted on the UK Biobank (UKB) cohort. In UKB cohort, DLS's C-statistic(71.1%, 95% CI 69.9-72.4) was non-inferior to office-based refit-WHO score(70.9%, 95% CI 69.7-72.2; non-inferiority margin of 2.5%, p&lt;0.01). Thecalibration of the DLS was satisfactory, with a 1.8% mean absolute calibrationerror. Adding DLS features to the office-based score increased the C-statisticby 1.0% (95% CI 0.6-1.4). DLS predicts ten-year MACE risk comparable with theoffice-based refit-WHO score. It provides a proof-of-concept and suggests thepotential of a PPG-based approach strategies for community-based primaryprevention in resource-limited regions.</description><author>Wei-Hung Weng, Sebastien Baur, Mayank Daswani, Christina Chen, Lauren Harrell, Sujay Kakarmath, Mariam Jabara, Babak Behsaz, Cory Y. McLean, Yossi Matias, Greg S. Corrado, Shravya Shetty, Shruthi Prabhakara, Yun Liu, Goodarz Danaei, Diego Ardila</author><pubDate>Tue, 09 May 2023 18:46:43 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.05648v1</guid></item><item><title>Towards Building the Federated GPT: Federated Instruction Tuning</title><link>http://arxiv.org/abs/2305.05644v1</link><description>While ``instruction-tuned" generative large language models (LLMs) havedemonstrated an impressive ability to generalize to new tasks, the trainingphases heavily rely on large amounts of diverse and high-quality instructiondata (such as ChatGPT and GPT-4). Unfortunately, acquiring high-quality data,especially when it comes to human-written data, can pose significant challengesboth in terms of cost and accessibility. Moreover, concerns related to privacycan further limit access to such data, making the process of obtaining it acomplex and nuanced undertaking. Consequently, this hinders the generality ofthe tuned models and may restrict their effectiveness in certain contexts. Totackle this issue, our study introduces a new approach called FederatedInstruction Tuning (FedIT), which leverages federated learning (FL) as thelearning framework for the instruction tuning of LLMs. This marks the firstexploration of FL-based instruction tuning for LLMs. This is especiallyimportant since text data is predominantly generated by end users. Therefore,it is imperative to design and adapt FL approaches to effectively leveragethese users' diverse instructions stored on local devices, while preservingprivacy and ensuring data security. In the current paper, by conducting widelyused GPT-4 auto-evaluation, we demonstrate that by exploiting the heterogeneousand diverse sets of instructions on the client's end with the proposedframework FedIT, we improved the performance of LLMs compared to centralizedtraining with only limited local instructions. Further, in this paper, wedeveloped a Github repository named Shepherd. This repository offers afoundational framework for exploring federated fine-tuning of LLMs usingheterogeneous instructions across diverse categories.</description><author>Jianyi Zhang, Saeed Vahidian, Martin Kuo, Chunyuan Li, Ruiyi Zhang, Guoyin Wang, Yiran Chen</author><pubDate>Tue, 09 May 2023 18:42:34 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.05644v1</guid></item><item><title>A duality framework for generalization analysis of random feature models and two-layer neural networks</title><link>http://arxiv.org/abs/2305.05642v1</link><description>We consider the problem of learning functions in the $\mathcal{F}_{p,\pi}$and Barron spaces, which are natural function spaces that arise in thehigh-dimensional analysis of random feature models (RFMs) and two-layer neuralnetworks. Through a duality analysis, we reveal that the approximation andestimation of these spaces can be considered equivalent in a certain sense.This enables us to focus on the easier problem of approximation and estimationwhen studying the generalization of both models. The dual equivalence isestablished by defining an information-based complexity that can effectivelycontrol estimation errors. Additionally, we demonstrate the flexibility of ourduality framework through comprehensive analyses of two concrete applications. The first application is to study learning functions in $\mathcal{F}_{p,\pi}$with RFMs. We prove that the learning does not suffer from the curse ofdimensionality as long as $p&gt;1$, implying RFMs can work beyond the kernelregime. Our analysis extends existing results [CMM21] to the noisy case andremoves the requirement of overparameterization. The second application is to investigate the learnability of reproducingkernel Hilbert space (RKHS) under the $L^\infty$ metric. We derive both lowerand upper bounds of the minimax estimation error by using the spectrum of theassociated kernel. We then apply these bounds to dot-product kernels andanalyze how they scale with the input dimension. Our results suggest thatlearning with ReLU (random) features is generally intractable in terms ofreaching high uniform accuracy.</description><author>Hongrui Chen, Jihao Long, Lei Wu</author><pubDate>Tue, 09 May 2023 18:41:50 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.05642v1</guid></item><item><title>One-shot Federated Learning without Server-side Training</title><link>http://arxiv.org/abs/2204.12493v2</link><description>Federated Learning (FL) has recently made significant progress as a newmachine learning paradigm for privacy protection. Due to the high communicationcost of traditional FL, one-shot federated learning is gaining popularity as away to reduce communication cost between clients and the server. Most of theexisting one-shot FL methods are based on Knowledge Distillation; however,{distillation based approach requires an extra training phase and depends onpublicly available data sets or generated pseudo samples.} In this work, weconsider a novel and challenging cross-silo setting: performing a single roundof parameter aggregation on the local models without server-side training. Inthis setting, we propose an effective algorithm for Model Aggregation viaExploring Common Harmonized Optima (MA-Echo), which iteratively updates theparameters of all local models to bring them close to a common low-loss area onthe loss surface, without harming performance on their own data sets at thesame time. Compared to the existing methods, MA-Echo can work well even inextremely non-identical data distribution settings where the support categoriesof each local model have no overlapped labels with those of the others. Weconduct extensive experiments on two popular image classification data sets tocompare the proposed method with existing methods and demonstrate theeffectiveness of MA-Echo, which clearly outperforms the state-of-the-arts. Thesource code can be accessed in \url{https://github.com/FudanVI/MAEcho}.</description><author>Shangchao Su, Bin Li, Xiangyang Xue</author><pubDate>Tue, 09 May 2023 18:40:04 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2204.12493v2</guid></item><item><title>Representation Learning for Person or Entity-centric Knowledge Graphs: an application in Healthcare</title><link>http://arxiv.org/abs/2305.05640v1</link><description>Knowledge graphs (KGs) are a popular way to organise information based onontologies or schemas and have been used across a variety of scenarios fromsearch to recommendation. Despite advances in KGs, representing knowledgeremains a non-trivial task across industries and it is especially challengingin the biomedical and healthcare domains due to complex interdependentrelations between entities, heterogeneity, lack of standardization, andsparseness of data. KGs are used to discover diagnoses or prioritize genesrelevant to disease, but they often rely on schemas that are not centred arounda node or entity of interest, such as a person. Entity-centric KGs arerelatively unexplored but hold promise in representing important facetsconnected to a central node and unlocking downstream tasks beyond graphtraversal and reasoning, such as generating graph embeddings and training graphneural networks for a wide range of predictive tasks. This paper presents anend-to-end representation learning framework to extract entity-centric KGs fromstructured and unstructured data. We introduce a star-shaped ontology torepresent the multiple facets of a person and use it to guide KG creation.Compact representations of the graphs are created leveraging graph neuralnetworks and experiments are conducted using different levels of heterogeneityor explicitness. A readmission prediction task is used to evaluate the resultsof the proposed framework, showing a stable system, robust to missing data,that outperforms a range of baseline machine learning classifiers. We highlightthat this approach has several potential applications across domains and isopen-sourced. Lastly, we discuss lessons learned, challenges, and next stepsfor the adoption of the framework in practice.</description><author>Christos Theodoropoulos, Natasha Mulligan, Thaddeus Stappenbeck, Joao Bettencourt-Silva</author><pubDate>Tue, 09 May 2023 18:39:45 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.05640v1</guid></item><item><title>An Exploration of Encoder-Decoder Approaches to Multi-Label Classification for Legal and Biomedical Text</title><link>http://arxiv.org/abs/2305.05627v1</link><description>Standard methods for multi-label text classification largely rely onencoder-only pre-trained language models, whereas encoder-decoder models haveproven more effective in other classification tasks. In this study, we comparefour methods for multi-label classification, two based on an encoder only, andtwo based on an encoder-decoder. We carry out experiments on four datasets --two in the legal domain and two in the biomedical domain, each with two levelsof label granularity -- and always depart from the same pre-trained model, T5.Our results show that encoder-decoder methods outperform encoder-only methods,with a growing advantage on more complex datasets and labeling schemes of finergranularity. Using encoder-decoder models in a non-autoregressive fashion, inparticular, yields the best performance overall, so we further study thisapproach through ablations to better understand its strengths.</description><author>Yova Kementchedjhieva, Ilias Chalkidis</author><pubDate>Tue, 09 May 2023 18:13:53 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.05627v1</guid></item><item><title>Creating a Large Language Model of a Philosopher</title><link>http://arxiv.org/abs/2302.01339v2</link><description>Can large language models be trained to produce philosophical texts that aredifficult to distinguish from texts produced by human philosophers? To addressthis question, we fine-tuned OpenAI's GPT-3 with the works of philosopherDaniel C. Dennett as additional training data. To explore the Dennett model, weasked the real Dennett ten philosophical questions and then posed the samequestions to the language model, collecting four responses for each questionwithout cherry-picking. We recruited 425 participants to distinguish Dennett'sanswer from the four machine-generated answers. Experts on Dennett's work (N =25) succeeded 51% of the time, above the chance rate of 20% but short of ourhypothesized rate of 80% correct. For two of the ten questions, the languagemodel produced at least one answer that experts selected more frequently thanDennett's own answer. Philosophy blog readers (N = 302) performed similarly tothe experts, while ordinary research participants (N = 98) were near chancedistinguishing GPT-3's responses from those of an "actual human philosopher".</description><author>Eric Schwitzgebel, David Schwitzgebel, Anna Strasser</author><pubDate>Tue, 09 May 2023 18:06:43 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2302.01339v2</guid></item><item><title>Metric Space Magnitude and Generalisation in Neural Networks</title><link>http://arxiv.org/abs/2305.05611v1</link><description>Deep learning models have seen significant successes in numerousapplications, but their inner workings remain elusive. The purpose of this workis to quantify the learning process of deep neural networks through the lens ofa novel topological invariant called magnitude. Magnitude is an isometryinvariant; its properties are an active area of research as it encodes manyknown invariants of a metric space. We use magnitude to study the internalrepresentations of neural networks and propose a new method for determiningtheir generalisation capabilities. Moreover, we theoretically connect magnitudedimension and the generalisation error, and demonstrate experimentally that theproposed framework can be a good indicator of the latter.</description><author>Rayna Andreeva, Katharina Limbeck, Bastian Rieck, Rik Sarkar</author><pubDate>Tue, 09 May 2023 18:04:50 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.05611v1</guid></item><item><title>Can point cloud networks learn statistical shape models of anatomies?</title><link>http://arxiv.org/abs/2305.05610v1</link><description>Statistical Shape Modeling (SSM) is a valuable tool for investigating andquantifying anatomical variations within populations of anatomies. However,traditional correspondence-based SSM generation methods require atime-consuming re-optimization process each time a new subject is added to thecohort, making the inference process prohibitive for clinical research.Additionally, they require complete geometric proxies (e.g., high-resolutionbinary volumes or surface meshes) as input shapes to construct the SSM.Unordered 3D point cloud representations of shapes are more easily acquiredfrom various medical imaging practices (e.g., thresholded images and surfacescanning). Point cloud deep networks have recently achieved remarkable successin learning permutation-invariant features for different point cloud tasks(e.g., completion, semantic segmentation, classification). However, theirapplication to learning SSM from point clouds is to-date unexplored. In thiswork, we demonstrate that existing point cloud encoder-decoder-based completionnetworks can provide an untapped potential for SSM, capturing population-levelstatistical representations of shapes while reducing the inference burden andrelaxing the input requirement. We discuss the limitations of these techniquesto the SSM application and suggest future improvements. Our work paves the wayfor further exploration of point cloud deep learning for SSM, a promisingavenue for advancing shape analysis literature and broadening SSM to diverseuse cases.</description><author>Jadie Adams, Shireen Elhabian</author><pubDate>Tue, 09 May 2023 18:01:17 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.05610v1</guid></item><item><title>The Case Records of ChatGPT: Language Models and Complex Clinical Questions</title><link>http://arxiv.org/abs/2305.05609v1</link><description>Background: Artificial intelligence language models have shown promise invarious applications, including assisting with clinical decision-making asdemonstrated by strong performance of large language models on medicallicensure exams. However, their ability to solve complex, open-ended cases,which may be representative of clinical practice, remains unexplored. Methods:In this study, the accuracy of large language AI models GPT4 and GPT3.5 indiagnosing complex clinical cases was investigated using published Case Recordsof the Massachusetts General Hospital. A total of 50 cases requiring adiagnosis and diagnostic test published from January 1, 2022 to April 16, 2022were identified. For each case, models were given a prompt requesting the topthree specific diagnoses and associated diagnostic tests, followed by casetext, labs, and figure legends. Model outputs were assessed in comparison tothe final clinical diagnosis and whether the model-predicted test would resultin a correct diagnosis. Results: GPT4 and GPT3.5 accurately provided thecorrect diagnosis in 26% and 22% of cases in one attempt, and 46% and 42%within three attempts, respectively. GPT4 and GPT3.5 provided a correctessential diagnostic test in 28% and 24% of cases in one attempt, and 44% and50% within three attempts, respectively. No significant differences were foundbetween the two models, and multiple trials with identical prompts using theGPT3.5 model provided similar results. Conclusions: In summary, these modelsdemonstrate potential usefulness in generating differential diagnoses butremain limited in their ability to provide a single unifying diagnosis incomplex, open-ended cases. Future research should focus on evaluating modelperformance in larger datasets of open-ended clinical challenges and exploringpotential human-AI collaboration strategies to enhance clinicaldecision-making.</description><author>Timothy Poterucha, Pierre Elias, Christopher M. Haggerty</author><pubDate>Tue, 09 May 2023 17:58:32 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.05609v1</guid></item><item><title>The Role of Relevance in Fair Ranking</title><link>http://arxiv.org/abs/2305.05608v1</link><description>Online platforms mediate access to opportunity: relevance-based rankingscreate and constrain options by allocating exposure to job openings and jobcandidates in hiring platforms, or sellers in a marketplace. In order to do soresponsibly, these socially consequential systems employ various fairnessmeasures and interventions, many of which seek to allocate exposure based onworthiness. Because these constructs are typically not directly observable,platforms must instead resort to using proxy scores such as relevance and inferthem from behavioral signals such as searcher clicks. Yet, it remains an openquestion whether relevance fulfills its role as such a worthiness score inhigh-stakes fair rankings. In this paper, we combine perspectives and tools from the social sciences,information retrieval, and fairness in machine learning to derive a set ofdesired criteria that relevance scores should satisfy in order to meaningfullyguide fairness interventions. We then empirically show that not all of thesecriteria are met in a case study of relevance inferred from biased user clickdata. We assess the impact of these violations on the estimated system fairnessand analyze whether existing fairness interventions may mitigate the identifiedissues. Our analyses and results surface the pressing need for new approachesto relevance collection and generation that are suitable for use in fairranking.</description><author>Aparna Balagopalan, Abigail Z. Jacobs, Asia Biega</author><pubDate>Tue, 09 May 2023 17:58:23 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.05608v1</guid></item><item><title>A Multimodal Transformer: Fusing Clinical Notes with Structured EHR Data for Interpretable In-Hospital Mortality Prediction</title><link>http://arxiv.org/abs/2208.10240v2</link><description>Deep-learning-based clinical decision support using structured electronichealth records (EHR) has been an active research area for predicting risks ofmortality and diseases. Meanwhile, large amounts of narrative clinical notesprovide complementary information, but are often not integrated into predictivemodels. In this paper, we provide a novel multimodal transformer to fuseclinical notes and structured EHR data for better prediction of in-hospitalmortality. To improve interpretability, we propose an integrated gradients (IG)method to select important words in clinical notes and discover the criticalstructured EHR features with Shapley values. These important words and clinicalfeatures are visualized to assist with interpretation of the predictionoutcomes. We also investigate the significance of domain adaptive pretrainingand task adaptive fine-tuning on the Clinical BERT, which is used to learn therepresentations of clinical notes. Experiments demonstrated that our modeloutperforms other methods (AUCPR: 0.538, AUCROC: 0.877, F1:0.490).</description><author>Weimin Lyu, Xinyu Dong, Rachel Wong, Songzhu Zheng, Kayley Abell-Hart, Fusheng Wang, Chao Chen</author><pubDate>Tue, 09 May 2023 17:54:31 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2208.10240v2</guid></item><item><title>Privacy-Preserving Collaborative Chinese Text Recognition with Federated Learning</title><link>http://arxiv.org/abs/2305.05602v1</link><description>In Chinese text recognition, to compensate for the insufficient local dataand improve the performance of local few-shot character recognition, it isoften necessary for one organization to collect a large amount of data fromsimilar organizations. However, due to the natural presence of privateinformation in text data, different organizations are unwilling to shareprivate data, such as addresses and phone numbers. Therefore, it becomesincreasingly important to design a privacy-preserving collaborative trainingframework for the Chinese text recognition task. In this paper, we introducepersonalized federated learning (pFL) into the Chinese text recognition taskand propose the pFedCR algorithm, which significantly improves the modelperformance of each client (organization) without sharing private data.Specifically, based on CRNN, to handle the non-iid problem of client data, weadd several attention layers to the model and design a two-stage trainingapproach for the client. In addition, we fine-tune the output layer of themodel using a virtual dataset on the server, mitigating the problem ofcharacter imbalance in Chinese documents. The proposed approach is validated onpublic benchmarks and two self-built real-world industrial scenario datasets.The experimental results show that the pFedCR algorithm can improve theperformance of local personalized models while also improving theirgeneralization performance on other client data domains. Compared to localtraining within an organization, pFedCR improves model performance by about20%. Compared to other state-of-the-art personalized federated learningmethods, pFedCR improves performance by 6%~8%. Moreover, through federatedlearning, pFedCR can correct erroneous information in the ground truth.</description><author>Shangchao Su, Haiyang Yu, Bin Li, Xiangyang Xue</author><pubDate>Tue, 09 May 2023 17:51:00 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.05602v1</guid></item><item><title>Deep Learning and Geometric Deep Learning: an introduction for mathematicians and physicists</title><link>http://arxiv.org/abs/2305.05601v1</link><description>In this expository paper we want to give a brief introduction, with few keyreferences for further reading, to the inner functioning of the new andsuccessfull algorithms of Deep Learning and Geometric Deep Learning with afocus on Graph Neural Networks. We go over the key ingredients for thesealgorithms: the score and loss function and we explain the main steps for thetraining of a model. We do not aim to give a complete and exhaustive treatment,but we isolate few concepts to give a fast introduction to the subject. Weprovide some appendices to complement our treatment discussing Kullback-Leiblerdivergence, regression, Multi-layer Perceptrons and the Universal ApproximationTheorem.</description><author>R. Fioresi, F. Zanchetta</author><pubDate>Tue, 09 May 2023 17:50:36 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.05601v1</guid></item><item><title>Region-based Contrastive Pretraining for Medical Image Retrieval with Anatomic Query</title><link>http://arxiv.org/abs/2305.05598v1</link><description>We introduce a novel Region-based contrastive pretraining for Medical ImageRetrieval (RegionMIR) that demonstrates the feasibility of medical imageretrieval with similar anatomical regions. RegionMIR addresses two majorchallenges for medical image retrieval i) standardization of clinicallyrelevant searching criteria (e.g., anatomical, pathology-based), and ii)localization of anatomical area of interests that are semantically meaningful.In this work, we propose an ROI image retrieval image network that retrievesimages with similar anatomy by extracting anatomical features (via boundingboxes) and evaluate similarity between pairwise anatomy-categorized featuresbetween the query and the database of images using contrastive learning. ROIqueries are encoded using a contrastive-pretrained encoder that was fine-tunedfor anatomy classification, which generates an anatomical-specific latent spacefor region-correlated image retrieval. During retrieval, we compare theanatomically encoded query to find similar features within a feature databasegenerated from training samples, and retrieve images with similar regions fromtraining samples. We evaluate our approach on both anatomy classification andimage retrieval tasks using the Chest ImaGenome Dataset. Our proposed strategyyields an improvement over state-of-the-art pretraining and co-trainingstrategies, from 92.24 to 94.12 (2.03%) classification accuracy in anatomies.We qualitatively evaluate the image retrieval performance demonstratinggeneralizability across multiple anatomies with different morphology.</description><author>Ho Hin Lee, Alberto Santamaria-Pang, Jameson Merkow, Ozan Oktay, Fernando Pérez-García, Javier Alvarez-Valle, Ivan Tarapov</author><pubDate>Tue, 09 May 2023 17:46:33 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.05598v1</guid></item><item><title>Lifelong Learning on Evolving Graphs Under the Constraints of Imbalanced Classes and New Classes</title><link>http://arxiv.org/abs/2112.10558v2</link><description>Lifelong graph learning deals with the problem of continually adapting graphneural network (GNN) models to changes in evolving graphs. We address twocritical challenges of lifelong graph learning in this work: dealing with newclasses and tackling imbalanced class distributions. The combination of thesetwo challenges is particularly relevant since newly emerging classes typicallyresemble only a tiny fraction of the data, adding to the already skewed classdistribution. We make several contributions: First, we show that the amount ofunlabeled data does not influence the results, which is an essentialprerequisite for lifelong learning on a sequence of tasks. Second, weexperiment with different label rates and show that our methods can performwell with only a tiny fraction of annotated nodes. Third, we propose the gDOCmethod to detect new classes under the constraint of having an imbalanced classdistribution. The critical ingredient is a weighted binary cross-entropy lossfunction to account for the class imbalance. Moreover, we demonstratecombinations of gDOC with various base GNN models such as GraphSAGE, SimplifiedGraph Convolution, and Graph Attention Networks. Lastly, our k-neighborhoodtime difference measure provably normalizes the temporal changes acrossdifferent graph datasets. With extensive experimentation, we find that theproposed gDOC method is consistently better than a naive adaption of DOC tographs. Specifically, in experiments using the smallest history size, theout-of-distribution detection score of gDOC is 0.09 compared to 0.01 for DOC.Furthermore, gDOC achieves an Open-F1 score, a combined measure ofin-distribution classification and out-of-distribution detection, of 0.33compared to 0.25 of DOC (32% increase).</description><author>Lukas Galke, Iacopo Vagliano, Benedikt Franke, Tobias Zielke, Marcel Hoffmann, Ansgar Scherp</author><pubDate>Tue, 09 May 2023 17:43:54 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2112.10558v2</guid></item><item><title>A transfer learning based approach for pronunciation scoring</title><link>http://arxiv.org/abs/2111.00976v2</link><description>Phone-level pronunciation scoring is a challenging task, with performance farfrom that of human annotators. Standard systems generate a score for each phonein a phrase using models trained for automatic speech recognition (ASR) withnative data only. Better performance has been shown when using systems that aretrained specifically for the task using non-native data. Yet, such systems facethe challenge that datasets labelled for this task are scarce and usuallysmall. In this paper, we present a transfer learning-based approach thatleverages a model trained for ASR, adapting it for the task of pronunciationscoring. We analyze the effect of several design choices and compare theperformance with a state-of-the-art goodness of pronunciation (GOP) system. Ourfinal system is 20% better than the GOP system on EpaDB, a database forpronunciation scoring research, for a cost function that prioritizes low ratesof unnecessary corrections.</description><author>Marcelo Sancinetti, Jazmin Vidal, Cyntia Bonomi, Luciana Ferrer</author><pubDate>Tue, 09 May 2023 17:43:19 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2111.00976v2</guid></item><item><title>Few-shot Image Generation via Adaptation-Aware Kernel Modulation</title><link>http://arxiv.org/abs/2210.16559v3</link><description>Few-shot image generation (FSIG) aims to learn to generate new and diversesamples given an extremely limited number of samples from a domain, e.g., 10training samples. Recent work has addressed the problem using transfer learningapproach, leveraging a GAN pretrained on a large-scale source domain datasetand adapting that model to the target domain based on very limited targetdomain samples. Central to recent FSIG methods are knowledge preservingcriteria, which aim to select a subset of source model's knowledge to bepreserved into the adapted model. However, a major limitation of existingmethods is that their knowledge preserving criteria consider only sourcedomain/source task, and they fail to consider target domain/adaptation task inselecting source model's knowledge, casting doubt on their suitability forsetups of different proximity between source and target domain. Our work makestwo contributions. As our first contribution, we re-visit recent FSIG works andtheir experiments. Our important finding is that, under setups which assumptionof close proximity between source and target domains is relaxed, existingstate-of-the-art (SOTA) methods which consider only source domain/source taskin knowledge preserving perform no better than a baseline fine-tuning method.To address the limitation of existing methods, as our second contribution, wepropose Adaptation-Aware kernel Modulation (AdAM) to address general FSIG ofdifferent source-target domain proximity. Extensive experimental results showthat the proposed method consistently achieves SOTA performance acrosssource/target domains of different proximity, including challenging setups whensource and target domains are more apart. Project Page:https://yunqing-me.github.io/AdAM/</description><author>Yunqing Zhao, Keshigeyan Chandrasegaran, Milad Abdollahzadeh, Ngai-Man Cheung</author><pubDate>Tue, 09 May 2023 17:42:00 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2210.16559v3</guid></item><item><title>"Alexa doesn't have that many feelings": Children's understanding of AI through interactions with smart speakers in their homes</title><link>http://arxiv.org/abs/2305.05597v1</link><description>As voice-based Conversational Assistants (CAs), including Alexa, Siri, GoogleHome, have become commonly embedded in households, many children now routinelyinteract with Artificial Intelligence (AI) systems. It is important to researchchildren's experiences with consumer devices which use AI techniques becausethese shape their understanding of AI and its capabilities. We conducted amixed-methods study (questionnaires and interviews) with primary-schoolchildren aged 6-11 in Scotland to establish children's understanding of howvoice-based CAs work, how they perceive their cognitive abilities, agency andother human-like qualities, their awareness and trust of privacy aspects whenusing CAs and what they perceive as appropriate verbal interactions with CAs.Most children overestimated the CAs' intelligence and were uncertain about thesystems' feelings or agency. They also lacked accurate understanding of dataprivacy and security aspects, and believed it was wrong to be rude toconversational assistants. Exploring children's current understanding ofAI-supported technology has educational implications; such findings will enableeducators to develop appropriate materials to address the pressing need for AIliteracy.</description><author>Valentina Andries, Judy Robertson</author><pubDate>Tue, 09 May 2023 17:39:34 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.05597v1</guid></item><item><title>Robust Information Bottleneck for Task-Oriented Communication with Digital Modulation</title><link>http://arxiv.org/abs/2209.10382v2</link><description>Task-oriented communications, mostly using learning-based jointsource-channel coding (JSCC), aim to design a communication-efficient edgeinference system by transmitting task-relevant information to the receiver.However, only transmitting task-relevant information without introducing anyredundancy may cause robustness issues in learning due to the channelvariations, and the JSCC which directly maps the source data into continuouschannel input symbols poses compatibility issues on existing digitalcommunication systems. In this paper, we address these two issues by firstinvestigating the inherent tradeoff between the informativeness of the encodedrepresentations and the robustness to information distortion in the receivedrepresentations, and then propose a task-oriented communication scheme withdigital modulation, named discrete task-oriented JSCC (DT-JSCC), where thetransmitter encodes the features into a discrete representation and transmitsit to the receiver with the digital modulation scheme. In the DT-JSCC scheme,we develop a robust encoding framework, named robust information bottleneck(RIB), to improve the communication robustness to the channel variations, andderive a tractable variational upper bound of the RIB objective function usingthe variational approximation to overcome the computational intractability ofmutual information. The experimental results demonstrate that the proposedDT-JSCC achieves better inference performance than the baseline methods withlow communication latency, and exhibits robustness to channel variations due tothe applied RIB framework.</description><author>Songjie Xie, Shuai Ma, Ming Ding, Yuanming Shi, Mingjian Tang, Youlong Wu</author><pubDate>Tue, 09 May 2023 17:39:32 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2209.10382v2</guid></item><item><title>PET-NeuS: Positional Encoding Tri-Planes for Neural Surfaces</title><link>http://arxiv.org/abs/2305.05594v1</link><description>A signed distance function (SDF) parametrized by an MLP is a commoningredient of neural surface reconstruction. We build on the successful recentmethod NeuS to extend it by three new components. The first component is toborrow the tri-plane representation from EG3D and represent signed distancefields as a mixture of tri-planes and MLPs instead of representing it with MLPsonly. Using tri-planes leads to a more expressive data structure but will alsointroduce noise in the reconstructed surface. The second component is to use anew type of positional encoding with learnable weights to combat noise in thereconstruction process. We divide the features in the tri-plane into multiplefrequency scales and modulate them with sin and cos functions of differentfrequencies. The third component is to use learnable convolution operations onthe tri-plane features using self-attention convolution to produce featureswith different frequency bands. The experiments show that PET-NeuS achieveshigh-fidelity surface reconstruction on standard datasets. Following previouswork and using the Chamfer metric as the most important way to measure surfacereconstruction quality, we are able to improve upon the NeuS baseline by 57% onNerf-synthetic (0.84 compared to 1.97) and by 15.5% on DTU (0.71 compared to0.84). The qualitative evaluation reveals how our method can better control theinterference of high-frequency noise. Code available at\url{https://github.com/yiqun-wang/PET-NeuS}.</description><author>Yiqun Wang, Ivan Skorokhodov, Peter Wonka</author><pubDate>Tue, 09 May 2023 17:35:39 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.05594v1</guid></item><item><title>Interpretations of Domain Adaptations via Layer Variational Analysis</title><link>http://arxiv.org/abs/2302.01798v4</link><description>Transfer learning is known to perform efficiently in many applicationsempirically, yet limited literature reports the mechanism behind the scene.This study establishes both formal derivations and heuristic analysis toformulate the theory of transfer learning in deep learning. Our frameworkutilizing layer variational analysis proves that the success of transferlearning can be guaranteed with corresponding data conditions. Moreover, ourtheoretical calculation yields intuitive interpretations towards the knowledgetransfer process. Subsequently, an alternative method for network-basedtransfer learning is derived. The method shows an increase in efficiency andaccuracy for domain adaptation. It is particularly advantageous when new domaindata is sufficiently sparse during adaptation. Numerical experiments overdiverse tasks validated our theory and verified that our analytic expressionachieved better performance in domain adaptation than the gradient descentmethod.</description><author>Huan-Hsin Tseng, Hsin-Yi Lin, Kuo-Hsuan Hung, Yu Tsao</author><pubDate>Tue, 09 May 2023 17:28:12 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2302.01798v4</guid></item><item><title>AudioSlots: A slot-centric generative model for audio separation</title><link>http://arxiv.org/abs/2305.05591v1</link><description>In a range of recent works, object-centric architectures have been shown tobe suitable for unsupervised scene decomposition in the vision domain. Inspiredby these methods we present AudioSlots, a slot-centric generative model forblind source separation in the audio domain. AudioSlots is built usingpermutation-equivariant encoder and decoder networks. The encoder network basedon the Transformer architecture learns to map a mixed audio spectrogram to anunordered set of independent source embeddings. The spatial broadcast decodernetwork learns to generate the source spectrograms from the source embeddings.We train the model in an end-to-end manner using a permutation invariant lossfunction. Our results on Libri2Mix speech separation constitute a proof ofconcept that this approach shows promise. We discuss the results andlimitations of our approach in detail, and further outline potential ways toovercome the limitations and directions for future work.</description><author>Pradyumna Reddy, Scott Wisdom, Klaus Greff, John R. Hershey, Thomas Kipf</author><pubDate>Tue, 09 May 2023 17:28:07 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.05591v1</guid></item><item><title>StrAE: Autoencoding for Pre-Trained Embeddings using Explicit Structure</title><link>http://arxiv.org/abs/2305.05588v1</link><description>This work explores the utility of explicit structure for representationlearning in NLP by developing StrAE -- an autoencoding framework thatfaithfully leverages sentence structure to learn multi-level node embeddings inan unsupervised fashion. We use StrAE to train models across different types ofsentential structure and objectives, including a novel contrastive loss overstructure, and evaluate the learnt embeddings on a series of both intrinsic andextrinsic tasks. Our experiments indicate that leveraging explicit structurethrough StrAE leads to improved embeddings over prior work, and that our novelcontrastive objective over structure outperforms the standard cross-entropyobjective. Moreover, in contrast to findings from prior work that weaklyleverages structure, we find that being completely faithful to structure doesenable disambiguation between types of structure based on the correspondingmodel's performance. As further evidence of StrAE's utility, we develop asimple proof-of-concept approach to simultaneously induce structure whilelearning embeddings, rather than being given structure, and find thatperformance is comparable to that of the best-performing models where structureis given. Finally, we contextualise these results by comparing StrAE againststandard unstructured baselines learnt in similar settings, and show thatfaithfully leveraging explicit structure can be beneficial in lexical andsentence-level semantics.</description><author>Mattia Opper, Victor Prokhorov, N. Siddharth</author><pubDate>Tue, 09 May 2023 17:20:48 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.05588v1</guid></item><item><title>RLocator: Reinforcement Learning for Bug Localization</title><link>http://arxiv.org/abs/2305.05586v1</link><description>Software developers spend a significant portion of time fixing bugs in theirprojects. To streamline this process, bug localization approaches have beenproposed to identify the source code files that are likely responsible for aparticular bug. Prior work proposed several similarity-based machine-learningtechniques for bug localization. Despite significant advances in thesetechniques, they do not directly optimize the evaluation measures. Instead,they use different metrics in the training and testing phases, which cannegatively impact the model performance in retrieval tasks. In this paper, wepropose RLocator, a Reinforcement Learning-based (RL) bug localizationapproach. We formulate the bug localization problem using a Markov DecisionProcess (MDP) to optimize the evaluation measures directly. We present thetechnique and experimentally evaluate it based on a benchmark dataset of 8,316bug reports from six highly popular Apache projects. Our evaluation shows thatRLocator achieves up to a Mean Reciprocal Rank (MRR) of 0.62 and a Mean AveragePrecision (MAP) of 0.59. Our results demonstrate that directly optimizingevaluation measures considerably contributes to performance improvement of thebug localization problem.</description><author>Partha Chakraborty, Mahmoud Alfadel, Meiyappan Nagappan</author><pubDate>Tue, 09 May 2023 17:19:33 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.05586v1</guid></item><item><title>Group Activity Recognition via Dynamic Composition and Interaction</title><link>http://arxiv.org/abs/2305.05583v1</link><description>Previous group activity recognition approaches were limited to reasoningusing human relations or finding important subgroups and tended to ignoreindispensable group composition and human-object interactions. This absencemakes a partial interpretation of the scene and increases the interference ofirrelevant actions on the results. Therefore, we propose our DynamicFormer withDynamic composition Module (DcM) and Dynamic interaction Module (DiM) to modelrelations and locations of persons and discriminate the contribution ofparticipants, respectively. Our findings on group composition and human-objectinteraction inspire our core idea. Group composition tells us the location ofpeople and their relations inside the group, while interaction reflects therelation between humans and objects outside the group. We utilize spatial andtemporal encoders in DcM to model our dynamic composition and build DiM toexplore interaction with a novel GCN, which has a transformer inside toconsider the temporal neighbors of human/object. Also, a Multi-level DynamicIntegration is employed to integrate features from different levels. We conductextensive experiments on two public datasets and show that our method achievesstate-of-the-art.</description><author>Youliang Zhang, Zhuo Zhou, Wenxuan Liu, Danni Xu, Zheng Wang</author><pubDate>Tue, 09 May 2023 17:18:18 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.05583v1</guid></item><item><title>Fashion CUT: Unsupervised domain adaptation for visual pattern classification in clothes using synthetic data and pseudo-labels</title><link>http://arxiv.org/abs/2305.05580v1</link><description>Accurate product information is critical for e-commerce stores to allowcustomers to browse, filter, and search for products. Product data quality isaffected by missing or incorrect information resulting in poor customerexperience. While machine learning can be used to correct inaccurate or missinginformation, achieving high performance on fashion image classification tasksrequires large amounts of annotated data, but it is expensive to generate dueto labeling costs. One solution can be to generate synthetic data whichrequires no manual labeling. However, training a model with a dataset of solelysynthetic images can lead to poor generalization when performing inference onreal-world data because of the domain shift. We introduce a new unsuperviseddomain adaptation technique that converts images from the synthetic domain intothe real-world domain. Our approach combines a generative neural network and aclassifier that are jointly trained to produce realistic images whilepreserving the synthetic label information. We found that using real-worldpseudo-labels during training helps the classifier to generalize in thereal-world domain, reducing the synthetic bias. We successfully train a visualpattern classification model in the fashion domain without real-worldannotations. Experiments show that our method outperforms other unsuperviseddomain adaptation algorithms.</description><author>Enric Moreu, Alex Martinelli, Martina Naughton, Philip Kelly, Noel E. O'Connor</author><pubDate>Tue, 09 May 2023 17:14:57 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.05580v1</guid></item><item><title>BloombergGPT: A Large Language Model for Finance</title><link>http://arxiv.org/abs/2303.17564v2</link><description>The use of NLP in the realm of financial technology is broad and complex,with applications ranging from sentiment analysis and named entity recognitionto question answering. Large Language Models (LLMs) have been shown to beeffective on a variety of tasks; however, no LLM specialized for the financialdomain has been reported in literature. In this work, we present BloombergGPT,a 50 billion parameter language model that is trained on a wide range offinancial data. We construct a 363 billion token dataset based on Bloomberg'sextensive data sources, perhaps the largest domain-specific dataset yet,augmented with 345 billion tokens from general purpose datasets. We validateBloombergGPT on standard LLM benchmarks, open financial benchmarks, and a suiteof internal benchmarks that most accurately reflect our intended usage. Ourmixed dataset training leads to a model that outperforms existing models onfinancial tasks by significant margins without sacrificing performance ongeneral LLM benchmarks. Additionally, we explain our modeling choices, trainingprocess, and evaluation methodology. We release Training Chronicles (AppendixC) detailing our experience in training BloombergGPT.</description><author>Shijie Wu, Ozan Irsoy, Steven Lu, Vadim Dabravolski, Mark Dredze, Sebastian Gehrmann, Prabhanjan Kambadur, David Rosenberg, Gideon Mann</author><pubDate>Tue, 09 May 2023 17:06:35 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2303.17564v2</guid></item><item><title>Large Language Models Humanize Technology</title><link>http://arxiv.org/abs/2305.05576v1</link><description>Large Language Models (LLMs) have made rapid progress in recent months andweeks, garnering significant public attention. This has sparked concerns aboutaligning these models with human values, their impact on labor markets, and thepotential need for regulation in further research and development. However, thediscourse often lacks a focus on the imperative to widely diffuse the societalbenefits of LLMs. To qualify this societal benefit, we assert that LLMs exhibitemergent abilities to humanize technology more effectively than previoustechnologies, and for people across language, occupation, and accessibilitydivides. We argue that they do so by addressing three mechanizing bottlenecksin today's computing technologies: creating diverse and accessible content,learning complex digital tools, and personalizing machine learning algorithms.We adopt a case-based approach and illustrate each bottleneck with two exampleswhere current technology imposes bottlenecks that LLMs demonstrate the abilityto address. Given this opportunity to humanize technology widely, we advocatefor more widespread understanding of LLMs, tools and methods to simplify use ofLLMs, and cross-cutting institutional capacity.</description><author>Pratyush Kumar</author><pubDate>Tue, 09 May 2023 17:05:36 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.05576v1</guid></item><item><title>An Algorithm For Adversary Aware Decentralized Networked MARL</title><link>http://arxiv.org/abs/2305.05573v1</link><description>Decentralized multi-agent reinforcement learning (MARL) algorithms havebecome popular in the literature since it allows heterogeneous agents to havetheir own reward functions as opposed to canonical multi-agent Markov DecisionProcess (MDP) settings which assume common reward functions over all agents. Inthis work, we follow the existing work on collaborative MARL where agents in aconnected time varying network can exchange information among each other inorder to reach a consensus. We introduce vulnerabilities in the consensusupdates of existing MARL algorithms where agents can deviate from their usualconsensus update, who we term as adversarial agents. We then proceed to providean algorithm that allows non-adversarial agents to reach a consensus in thepresence of adversaries under a constrained setting.</description><author>Soumajyoti Sarkar</author><pubDate>Tue, 09 May 2023 17:02:31 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.05573v1</guid></item><item><title>SMAClite: A Lightweight Environment for Multi-Agent Reinforcement Learning</title><link>http://arxiv.org/abs/2305.05566v1</link><description>There is a lack of standard benchmarks for Multi-Agent Reinforcement Learning(MARL) algorithms. The Starcraft Multi-Agent Challenge (SMAC) has been widelyused in MARL research, but is built on top of a heavy, closed-source computergame, StarCraft II. Thus, SMAC is computationally expensive and requiresknowledge and the use of proprietary tools specific to the game for anymeaningful alteration or contribution to the environment. We introduce SMAClite-- a challenge based on SMAC that is both decoupled from Starcraft II andopen-source, along with a framework which makes it possible to create newcontent for SMAClite without any special knowledge. We conduct experiments toshow that SMAClite is equivalent to SMAC, by training MARL algorithms onSMAClite and reproducing SMAC results. We then show that SMAClite outperformsSMAC in both runtime speed and memory.</description><author>Adam Michalski, Filippos Christianos, Stefano V. Albrecht</author><pubDate>Tue, 09 May 2023 16:55:19 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.05566v1</guid></item><item><title>SkelEx and BoundEx: Natural Visualization of ReLU Neural Networks</title><link>http://arxiv.org/abs/2305.05562v1</link><description>Despite their limited interpretability, weights and biases are still the mostpopular encoding of the functions learned by ReLU Neural Networks (ReLU NNs).That is why we introduce SkelEx, an algorithm to extract a skeleton of themembership functions learned by ReLU NNs, making those functions easier tointerpret and analyze. To the best of our knowledge, this is the first workthat considers linear regions from the perspective of critical points. As anatural follow-up, we also introduce BoundEx, which is the first analyticalmethod known to us to extract the decision boundary from the realization of aReLU NN. Both of those methods introduce very natural visualization tool forReLU NNs trained on low-dimensional data.</description><author>Pawel Pukowski, Haiping Lu</author><pubDate>Tue, 09 May 2023 16:48:34 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.05562v1</guid></item><item><title>Distributional Multi-Objective Decision Making</title><link>http://arxiv.org/abs/2305.05560v1</link><description>For effective decision support in scenarios with conflicting objectives, setsof potentially optimal solutions can be presented to the decision maker. Weexplore both what policies these sets should contain and how such sets can becomputed efficiently. With this in mind, we take a distributional approach andintroduce a novel dominance criterion relating return distributions of policiesdirectly. Based on this criterion, we present the distributional undominatedset and show that it contains optimal policies otherwise ignored by the Paretofront. In addition, we propose the convex distributional undominated set andprove that it comprises all policies that maximise expected utility formultivariate risk-averse decision makers. We propose a novel algorithm to learnthe distributional undominated set and further contribute pruning operators toreduce the set to the convex distributional undominated set. Throughexperiments, we demonstrate the feasibility and effectiveness of these methods,making this a valuable new approach for decision support in real-worldproblems.</description><author>Willem Röpke, Conor F. Hayes, Patrick Mannion, Enda Howley, Ann Nowé, Diederik M. Roijers</author><pubDate>Tue, 09 May 2023 16:47:56 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.05560v1</guid></item><item><title>Social Value Orientation and Integral Emotions in Multi-Agent Systems</title><link>http://arxiv.org/abs/2305.05549v1</link><description>Human social behavior is influenced by individual differences in socialpreferences. Social value orientation (SVO) is a measurable personality traitwhich indicates the relative importance an individual places on their own andon others' welfare when making decisions. SVO and other individual differencevariables are strong predictors of human behavior and social outcomes. However,there are transient changes human behavior associated with emotions that arenot captured by individual differences alone. Integral emotions, the emotionswhich arise in direct response to a decision-making scenario, have been linkedto temporary shifts in decision-making preferences. In this work, we investigated the effects of moderating social preferenceswith integral emotions in multi-agent societies. We developed Svoie, a methodfor designing agents which make decisions based on established SVO policies, aswell as alternative integral emotion policies in response to task outcomes. Weconducted simulation experiments in a resource-sharing task environment, andcompared societies of Svoie agents with societies of agents with fixed SVOpolicies. We find that societies of agents which adapt their behavior throughintegral emotions achieved similar collective welfare to societies of agentswith fixed SVO policies, but with significantly reduced inequality between thewelfare of agents with different SVO traits. We observed that by allowingagents to change their policy in response to task outcomes, agents can moderatetheir behavior to achieve greater social equality. \end{abstract}</description><author>Daniel Collins, Conor Houghton, Nirav Ajmeri</author><pubDate>Tue, 09 May 2023 16:33:50 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.05549v1</guid></item><item><title>ColonMapper: topological mapping and localization for colonoscopy</title><link>http://arxiv.org/abs/2305.05546v1</link><description>Mapping and localization in endoluminal cavities from colonoscopies orgastroscopies has to overcome the challenge of significant shape andillumination changes between reobservations of the same endoluminal location.Instead of geometrical maps that strongly rely on a fixed scene geometry,topological maps are more adequate because they focus on visual placerecognition, i.e. the capability to determine if two video shots are imagingthe same location. We propose a topological mapping and localization systemable to operate on real human colonoscopies. The map is a graph where each nodecodes a colon location by a set of real images of that location. The edgesrepresent traversability between two nodes. For close-in-time images, wherescene changes are minor, place recognition can be successfully managed with therecent transformers-based image-matching algorithms. However, under long-termchanges -- such as different colonoscopies of the same patient -- feature-basedmatching fails. To address this, we propose a GeM global descriptor able toachieve high recall with significant changes in the scene. The addition of aBayesian filter processing the map graph boosts the accuracy of the long-termplace recognition, enabling relocalization in a previously built map. In theexperiments, we construct a map during the withdrawal phase of a firstcolonoscopy. Subsequently, we prove the ability to relocalize within this mapduring a second colonoscopy of the same patient two weeks later. Code andmodels will be available upon acceptance.</description><author>Javier Morlana, Juan D. Tardós, J. M. M. Montiel</author><pubDate>Tue, 09 May 2023 16:32:50 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.05546v1</guid></item><item><title>Calibration Assessment and Boldness-Recalibration for Binary Events</title><link>http://arxiv.org/abs/2305.03780v2</link><description>Probability predictions are essential to inform decision making in medicine,economics, image classification, sports analytics, entertainment, and manyother fields. Ideally, probability predictions are (i) well calibrated, (ii)accurate, and (iii) bold, i.e., far from the base rate of the event.Predictions that satisfy these three criteria are informative for decisionmaking. However, there is a fundamental tension between calibration andboldness, since calibration metrics can be high when predictions are overlycautious, i.e., non-bold. The purpose of this work is to develop a hypothesistest and Bayesian model selection approach to assess calibration, and astrategy for boldness-recalibration that enables practitioners to responsiblyembolden predictions subject to their required level of calibration.Specifically, we allow the user to pre-specify their desired posteriorprobability of calibration, then maximally embolden predictions subject to thisconstraint. We verify the performance of our procedures via simulation, thendemonstrate the breadth of applicability by applying these methods to realworld case studies in each of the fields mentioned above. We find that veryslight relaxation of calibration probability (e.g., from 0.99 to 0.95) canoften substantially embolden predictions (e.g., widening Hockey predictions'range from .25-.75 to .10-.90)</description><author>Adeline P. Guthrie, Christopher T. Franck</author><pubDate>Tue, 09 May 2023 16:31:30 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.03780v2</guid></item><item><title>Integrating Holistic and Local Information to Estimate Emotional Reaction Intensity</title><link>http://arxiv.org/abs/2305.05534v1</link><description>Video-based Emotional Reaction Intensity (ERI) estimation measures theintensity of subjects' reactions to stimuli along several emotional dimensionsfrom videos of the subject as they view the stimuli. We propose a multi-modalarchitecture for video-based ERI combining video and audio information. Videoinput is encoded spatially first, frame-by-frame, combining features encodingholistic aspects of the subjects' facial expressions and features encodingspatially localized aspects of their expressions. Input is then combined acrosstime: from frame-to-frame using gated recurrent units (GRUs), then globally bya transformer. We handle variable video length with a regression token thataccumulates information from all frames into a fixed-dimensional vectorindependent of video length. Audio information is handled similarly: spectralinformation extracted within each frame is integrated across time by a cascadeof GRUs and a transformer with regression token. The video and audio regressiontokens' outputs are merged by concatenation, then input to a final fullyconnected layer producing intensity estimates. Our architecture achievedexcellent performance on the Hume-Reaction dataset in the ERI EsimationChallenge of the Fifth Competition on Affective Behavior Analysis in-the-Wild(ABAW5). The Pearson Correlation Coefficients between estimated and subjectself-reported scores, averaged across all emotions, were 0.455 on thevalidation dataset and 0.4547 on the test dataset, well above the baselines.The transformer's self-attention mechanism enables our architecture to focus onthe most critical video frames regardless of length. Ablation experimentsestablish the advantages of combining holistic/local features and ofmulti-modal integration. Code available at https://github.com/HKUST-NISL/ABAW5.</description><author>Yini Fang, Liang Wu, Frederic Jumelle, Bertram Shi</author><pubDate>Tue, 09 May 2023 16:28:24 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.05534v1</guid></item><item><title>EFE: End-to-end Frame-to-Gaze Estimation</title><link>http://arxiv.org/abs/2305.05526v1</link><description>Despite the recent development of learning-based gaze estimation methods,most methods require one or more eye or face region crops as inputs and producea gaze direction vector as output. Cropping results in a higher resolution inthe eye regions and having fewer confounding factors (such as clothing andhair) is believed to benefit the final model performance. However, thiseye/face patch cropping process is expensive, erroneous, andimplementation-specific for different methods. In this paper, we propose aframe-to-gaze network that directly predicts both 3D gaze origin and 3D gazedirection from the raw frame out of the camera without any face or eyecropping. Our method demonstrates that direct gaze regression from the rawdownscaled frame, from FHD/HD to VGA/HVGA resolution, is possible despite thechallenges of having very few pixels in the eye region. The proposed methodachieves comparable results to state-of-the-art methods in Point-of-Gaze (PoG)estimation on three public gaze datasets: GazeCapture, MPIIFaceGaze, and EVE,and generalizes well to extreme camera view changes.</description><author>Haldun Balim, Seonwook Park, Xi Wang, Xucong Zhang, Otmar Hilliges</author><pubDate>Tue, 09 May 2023 16:25:45 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.05526v1</guid></item><item><title>RMES: Real-Time Micro-Expression Spotting Using Phase From Riesz Pyramid</title><link>http://arxiv.org/abs/2305.05523v1</link><description>Micro-expressions (MEs) are involuntary and subtle facial expressions thatare thought to reveal feelings people are trying to hide. ME spotting detectsthe temporal intervals containing MEs in videos. Detecting such quick andsubtle motions from long videos is difficult. Recent works leverage detailedfacial motion representations, such as the optical flow, and deep learningmodels, leading to high computational complexity. To reduce computationalcomplexity and achieve real-time operation, we propose RMES, a real-time MEspotting framework. We represent motion using phase computed by Riesz Pyramid,and feed this motion representation into a three-stream shallow CNN, whichpredicts the likelihood of each frame belonging to an ME. In comparison tooptical flow, phase provides more localized motion estimates, which areessential for ME spotting, resulting in higher performance. Using phase alsoreduces the required computation of the ME spotting pipeline by 77.8%. Despiteits relative simplicity and low computational complexity, our frameworkachieves state-of-the-art performance on two public datasets: CAS(ME)2 and SAMMLong Videos.</description><author>Yini Fang, Didan Deng, Liang Wu, Frederic Jumelle, Bertram Shi</author><pubDate>Tue, 09 May 2023 16:22:18 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.05523v1</guid></item><item><title>Proximal Causal Learning of Conditional Average Treatment Effects</title><link>http://arxiv.org/abs/2301.10913v2</link><description>Efficiently and flexibly estimating treatment effect heterogeneity is animportant task in a wide variety of settings ranging from medicine tomarketing, and there are a considerable number of promising conditional averagetreatment effect estimators currently available. These, however, typically relyon the assumption that the measured covariates are enough to justifyconditional exchangeability. We propose the P-learner, motivated by the R- andDR-learner, a tailored two-stage loss function for learning heterogeneoustreatment effects in settings where exchangeability given observed covariatesis an implausible assumption, and we wish to rely on proxy variables for causalinference. Our proposed estimator can be implemented by off-the-shelfloss-minimizing machine learning methods, which in the case of kernelregression satisfies an oracle bound on the estimated error as long as thenuisance components are estimated reasonably well.</description><author>Erik Sverdrup, Yifan Cui</author><pubDate>Tue, 09 May 2023 16:22:16 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2301.10913v2</guid></item><item><title>Minimal Learning Machine for Multi-Label Learning</title><link>http://arxiv.org/abs/2305.05518v1</link><description>Distance-based supervised method, the minimal learning machine, constructs apredictive model from data by learning a mapping between input and outputdistance matrices. In this paper, we propose methods and evaluate how thistechnique and its core component, the distance mapping, can be adapted tomulti-label learning. The proposed approach is based on combining the distancemapping with an inverse distance weighting. Although the proposal is one of thesimplest methods in the multi-label learning literature, it achievesstate-of-the-art performance for small to moderate-sized multi-label learningproblems. Besides its simplicity, the proposed method is fully deterministicand its hyper-parameter can be selected via ranking loss-based statistic whichhas a closed form, thus avoiding conventional cross-validation-basedhyper-parameter tuning. In addition, due to its simple linear distancemapping-based construction, we demonstrate that the proposed method can assesspredictions' uncertainty for multi-label classification, which is a valuablecapability for data-centric machine learning pipelines.</description><author>Joonas Hämäläinen, Amauri Souza, César L. C. Mattos, João P. P. Gomes, Tommi Kärkkäinen</author><pubDate>Tue, 09 May 2023 16:16:50 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.05518v1</guid></item><item><title>Proportional Fairness in Federated Learning</title><link>http://arxiv.org/abs/2202.01666v5</link><description>With the increasingly broad deployment of federated learning (FL) systems inthe real world, it is critical but challenging to ensure fairness in FL, i.e.reasonably satisfactory performances for each of the numerous diverse clients.In this work, we introduce and study a new fairness notion in FL, calledproportional fairness (PF), which is based on the relative change of eachclient's performance. From its connection with the bargaining games, we proposePropFair, a novel and easy-to-implement algorithm for finding proportionallyfair solutions in FL and study its convergence properties. Through extensiveexperiments on vision and language datasets, we demonstrate that PropFair canapproximately find PF solutions, and it achieves a good balance between theaverage performances of all clients and of the worst 10% clients. Our code isavailable at\url{https://github.com/huawei-noah/Federated-Learning/tree/main/FairFL}.</description><author>Guojun Zhang, Saber Malekmohammadi, Xi Chen, Yaoliang Yu</author><pubDate>Tue, 09 May 2023 16:16:24 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2202.01666v5</guid></item><item><title>Generative Adversarial Super-Resolution at the Edge with Knowledge Distillation</title><link>http://arxiv.org/abs/2209.03355v2</link><description>Single-Image Super-Resolution can support robotic tasks in environments wherea reliable visual stream is required to monitor the mission, handleteleoperation or study relevant visual details. In this work, we propose anefficient Generative Adversarial Network model for real-time Super-Resolution,called EdgeSRGAN (code available at https://github.com/PIC4SeR/EdgeSRGAN). Weadopt a tailored architecture of the original SRGAN and model quantization toboost the execution on CPU and Edge TPU devices, achieving up to 200 fpsinference. We further optimize our model by distilling its knowledge to asmaller version of the network and obtain remarkable improvements compared tothe standard training approach. Our experiments show that our fast andlightweight model preserves considerably satisfying image quality compared toheavier state-of-the-art models. Finally, we conduct experiments on imagetransmission with bandwidth degradation to highlight the advantages of theproposed system for mobile robotic applications.</description><author>Simone Angarano, Francesco Salvetti, Mauro Martini, Marcello Chiaberge</author><pubDate>Tue, 09 May 2023 16:14:50 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2209.03355v2</guid></item><item><title>Vector Space Semantics for Lambek Calculus with Soft Subexponentials</title><link>http://arxiv.org/abs/2111.11331v2</link><description>We develop a vector space semantics for Lambek Calculus with SoftSubexponentials, apply the calculus to construct compositional vectorinterpretations for parasitic gap noun phrases and discourse units withanaphora and ellipsis, and experiment with the constructions in adistributional sentence similarity task. As opposed to previous work, whichused Lambek Calculus with a Relevant Modality the calculus used in this paperuses a bounded version of the modality and is decidable. The vector spacesemantics of this new modality allows us to meaningfully define contraction asprojection and provide a linear theory behind what we could previously onlyachieve via nonlinear maps.</description><author>Lachlan McPheat, Hadi Wazni, Mehrnoosh Sadrzadeh</author><pubDate>Tue, 09 May 2023 16:06:23 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2111.11331v2</guid></item><item><title>Towards the Practical Utility of Federated Learning in the Medical Domain</title><link>http://arxiv.org/abs/2207.03075v4</link><description>Federated learning (FL) is an active area of research. One of the mostsuitable areas for adopting FL is the medical domain, where patient privacymust be respected. Previous research, however, does not provide a practicalguide to applying FL in the medical domain. We propose empirical benchmarks andexperimental settings for three representative medical datasets with differentmodalities: longitudinal electronic health records, skin cancer images, andelectrocardiogram signals. The likely users of FL such as medical institutionsand IT companies can take these benchmarks as guides for adopting FL andminimize their trial and error. For each dataset, each client data is from adifferent source to preserve real-world heterogeneity. We evaluate six FLalgorithms designed for addressing data heterogeneity among clients, and ahybrid algorithm combining the strengths of two representative FL algorithms.Based on experiment results from three modalities, we discover that simple FLalgorithms tend to outperform more sophisticated ones, while the hybridalgorithm consistently shows good, if not the best performance. We also findthat a frequent global model update leads to better performance under a fixedtraining iteration budget. As the number of participating clients increases,higher cost is incurred due to increased IT administrators and GPUs, but theperformance consistently increases. We expect future users will refer to theseempirical benchmarks to design the FL experiments in the medical domainconsidering their clinical tasks and obtain stronger performance with lowercosts.</description><author>Seongjun Yang, Hyeonji Hwang, Daeyoung Kim, Radhika Dua, Jong-Yeup Kim, Eunho Yang, Edward Choi</author><pubDate>Tue, 09 May 2023 16:06:10 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2207.03075v4</guid></item><item><title>Self-supervised dense representation learning for live-cell microscopy with time arrow prediction</title><link>http://arxiv.org/abs/2305.05511v1</link><description>State-of-the-art object detection and segmentation methods for microscopyimages rely on supervised machine learning, which requires laborious manualannotation of training data. Here we present a self-supervised method based ontime arrow prediction pre-training that learns dense image representations fromraw, unlabeled live-cell microscopy videos. Our method builds upon the task ofpredicting the correct order of time-flipped image regions via a single-imagefeature extractor and a subsequent time arrow prediction head. We show that theresulting dense representations capture inherently time-asymmetric biologicalprocesses such as cell divisions on a pixel-level. We furthermore demonstratethe utility of these representations on several live-cell microscopy datasetsfor detection and segmentation of dividing cells, as well as for cell stateclassification. Our method outperforms supervised methods, particularly whenonly limited ground truth annotations are available as is commonly the case inpractice. We provide code at https://github.com/weigertlab/tarrow.</description><author>Benjamin Gallusser, Max Stieber, Martin Weigert</author><pubDate>Tue, 09 May 2023 15:58:13 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.05511v1</guid></item><item><title>Balancing Privacy and Security in Federated Learning with FedGT: A Group Testing Framework</title><link>http://arxiv.org/abs/2305.05506v1</link><description>We propose FedGT, a novel framework for identifying malicious clients infederated learning with secure aggregation. Inspired by group testing, theframework leverages overlapping groups of clients to detect the presence ofmalicious clients in the groups and to identify them via a decoding operation.The identified clients are then removed from the training of the model, whichis performed over the remaining clients. FedGT strikes a balance betweenprivacy and security, allowing for improved identification capabilities whilestill preserving data privacy. Specifically, the server learns the aggregatedmodel of the clients in each group. The effectiveness of FedGT is demonstratedthrough extensive experiments on the MNIST and CIFAR-10 datasets, showing itsability to identify malicious clients with low misdetection and false alarmprobabilities, resulting in high model utility.</description><author>Marvin Xhemrishi, Johan Östman, Antonia Wachter-Zeh, Alexandre Graell i Amat</author><pubDate>Tue, 09 May 2023 15:54:59 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.05506v1</guid></item><item><title>The logic behind desirable sets of things, and its filter representation</title><link>http://arxiv.org/abs/2302.08176v2</link><description>We identify the logic behind the recent theory of coherent sets of desirable(sets of) things, which generalise desirable (sets of) gambles and coherentchoice functions, and show that this identification allows us to establishvarious representation results for such coherent models in terms of simplerones.</description><author>Gert de Cooman, Arthur Van Camp, Jasper De Bock</author><pubDate>Tue, 09 May 2023 15:54:41 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2302.08176v2</guid></item><item><title>Recursions Are All You Need: Towards Efficient Deep Unfolding Networks</title><link>http://arxiv.org/abs/2305.05505v1</link><description>The use of deep unfolding networks in compressive sensing (CS) has seen widesuccess as they provide both simplicity and interpretability. However, sincemost deep unfolding networks are iterative, this incurs significantredundancies in the network. In this work, we propose a novel recursion-basedframework to enhance the efficiency of deep unfolding models. First, recursionsare used to effectively eliminate the redundancies in deep unfolding networks.Secondly, we randomize the number of recursions during training to decrease theoverall training time. Finally, to effectively utilize the power of recursions,we introduce a learnable unit to modulate the features of the model based onboth the total number of iterations and the current iteration index. Toevaluate the proposed framework, we apply it to both ISTA-Net+ and COAST.Extensive testing shows that our proposed framework allows the network to cutdown as much as 75% of its learnable parameters while mostly maintaining itsperformance, and at the same time, it cuts around 21% and 42% from the trainingtime for ISTA-Net+ and COAST respectively. Moreover, when presented with alimited training dataset, the recursive models match or even outperform theirrespective non-recursive baseline. Codes and pretrained models are available athttps://github.com/Rawwad-Alhejaili/Recursions-Are-All-You-Need .</description><author>Rawwad Alhejaili, Motaz Alfarraj, Hamzah Luqman, Ali Al-Shaikhi</author><pubDate>Tue, 09 May 2023 15:54:41 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.05505v1</guid></item><item><title>Effects of Real-Life Traffic Sign Alteration on YOLOv7- an Object Recognition Model</title><link>http://arxiv.org/abs/2305.05499v1</link><description>The advancement of Image Processing has led to the widespread use of ObjectRecognition (OR) models in various applications, such as airport security andmail sorting. These models have become essential in signifying the capabilitiesof AI and supporting vital services like national postal operations. However,the performance of OR models can be impeded by real-life scenarios, such astraffic sign alteration. Therefore, this research investigates the effects ofaltered traffic signs on the accuracy and performance of object recognitionmodels. To this end, a publicly available dataset was used to create differenttypes of traffic sign alterations, including changes to size, shape, color,visibility, and angles. The impact of these alterations on the YOLOv7 (You OnlyLook Once) model's detection and classification abilities were analyzed. Itreveals that the accuracy of object detection models decreases significantlywhen exposed to modified traffic signs under unlikely conditions. This studyhighlights the significance of enhancing the robustness of object detectionmodels in real-life scenarios and the need for further investigation in thisarea to improve their accuracy and reliability.</description><author>Farhin Farhad Riya, Shahinul Hoque, Md Saif Hassan Onim, Edward Michaud, Edmon Begoli</author><pubDate>Tue, 09 May 2023 15:51:29 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.05499v1</guid></item><item><title>Exploiting Pseudo Image Captions for Multimodal Summarization</title><link>http://arxiv.org/abs/2305.05496v1</link><description>Cross-modal contrastive learning in vision language pretraining (VLP) facesthe challenge of (partial) false negatives. In this paper, we study thisproblem from the perspective of Mutual Information (MI) optimization. It iscommon sense that InfoNCE loss used in contrastive learning will maximize thelower bound of MI between anchors and their positives, while we theoreticallyprove that MI involving negatives also matters when noises commonly exist.Guided by a more general lower bound form for optimization, we propose acontrastive learning strategy regulated by progressively refined cross-modalsimilarity, to more accurately optimize MI between an image/text anchor and itsnegative texts/images instead of improperly minimizing it. Our method performscompetitively on four downstream cross-modal tasks and systematically balancesthe beneficial and harmful effects of (partial) false negative samples undertheoretical guidance.</description><author>Chaoya Jiang, Rui Xie, Wei Ye, Jinan Sun, Shikun Zhang</author><pubDate>Tue, 09 May 2023 15:47:25 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.05496v1</guid></item><item><title>A Simple, Yet Effective Approach to Finding Biases in Code Generation</title><link>http://arxiv.org/abs/2211.00609v2</link><description>Recently, high-performing code generation systems based on large languagemodels have surfaced. They are trained on massive corpora containing much morenatural text than actual executable computer code. This work shows that currentcode generation systems exhibit undesired biases inherited from their largelanguage model backbones, which can reduce the quality of the generated codeunder specific circumstances. To investigate the effect, we propose the "block of influence" concept, whichenables a modular decomposition and analysis of the coding challenges. Weintroduce an automated intervention mechanism reminiscent of adversarialtesting that exposes undesired biases through the failure modes of the modelsunder test. Finally, we demonstrate how our framework can be used as a datatransformation technique during fine-tuning, acting as a mitigation strategyfor these biases.</description><author>Spyridon Mouselinos, Mateusz Malinowski, Henryk Michalewski</author><pubDate>Tue, 09 May 2023 15:47:24 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2211.00609v2</guid></item><item><title>Self-Supervised Anomaly Detection of Rogue Soil Moisture Sensors</title><link>http://arxiv.org/abs/2305.05495v1</link><description>IoT data is a central element in the successful digital transformation ofagriculture. However, IoT data comes with its own set of challenges. E.g., therisk of data contamination due to rogue sensors. A sensor is considered roguewhen it provides incorrect measurements over time. To ensure correct analyticalresults, an essential preprocessing step when working with IoT data is thedetection of such rogue sensors. Existing methods assume that well-behavingsensors are known or that a large majority of the sensors is well-behaving.However, real-world data is often completely unlabeled and voluminous, callingfor self-supervised methods that can detect rogue sensors without priorinformation. We present a self-supervised anomalous sensor detector based on aneural network with a contrastive loss, followed by DBSCAN. A core contributionof our paper is the use of Dynamic Time Warping in the negative sampling forthe triplet loss. This novelty makes the use of triplet networks feasible foranomalous sensor detection. Our method shows promising results on a challengingdataset of soil moisture sensors deployed in multiple pear orchards.</description><author>Boje Deforce, Bart Baesens, Jan Diels, Estefanía Serral Asensio</author><pubDate>Tue, 09 May 2023 15:47:16 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.05495v1</guid></item><item><title>Real-time instance segmentation with polygons using an Intersection-over-Union loss</title><link>http://arxiv.org/abs/2305.05490v1</link><description>Predicting a binary mask for an object is more accurate but also morecomputationally expensive than a bounding box. Polygonal masks as developed inCenterPoly can be a good compromise. In this paper, we improve over CenterPolyby enhancing the classical regression L1 loss with a novel region-based lossand a novel order loss, as well as with a new training process for the verticesprediction head. Moreover, the previous methods that predict polygonal masksuse different coordinate systems, but it is not clear if one is better thananother, if we abstract the architecture requirement. We therefore investigatetheir impact on the prediction. We also use a new evaluation protocol withoracle predictions for the detection head, to further isolate the segmentationprocess and better compare the polygonal masks with binary masks. Our instancesegmentation method is trained and tested with challenging datasets containingurban scenes, with a high density of road users. Experiments show, inparticular, that using a combination of a regression loss and a region-basedloss allows significant improvements on the Cityscapes and IDD test setcompared to CenterPoly. Moreover the inference stage remains fast enough toreach real-time performance with an average of 0.045 s per frame for2048$\times$1024 images on a single RTX 2070 GPU. The code is available$\href{https://github.com/KatiaJDL/CenterPoly-v2}{\text{here}}$.</description><author>Katia Jodogne-Del Litto, Guillaume-Alexandre Bilodeau</author><pubDate>Tue, 09 May 2023 15:43:38 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.05490v1</guid></item><item><title>MAUPQA: Massive Automatically-created Polish Question Answering Dataset</title><link>http://arxiv.org/abs/2305.05486v1</link><description>Recently, open-domain question answering systems have begun to rely heavilyon annotated datasets to train neural passage retrievers. However, manuallyannotating such datasets is both difficult and time-consuming, which limitstheir availability for less popular languages. In this work, we experiment withseveral methods for automatically collecting weakly labeled datasets and showhow they affect the performance of the neural passage retrieval models. As aresult of our work, we publish the MAUPQA dataset, consisting of nearly 400,000question-passage pairs for Polish, as well as the HerBERT-QA neural retriever.</description><author>Piotr Rybak</author><pubDate>Tue, 09 May 2023 15:36:04 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.05486v1</guid></item><item><title>Back-to-Bones: Rediscovering the Role of Backbones in Domain Generalization</title><link>http://arxiv.org/abs/2209.01121v2</link><description>Domain Generalization (DG) studies the capability of a deep learning model togeneralize to out-of-training distributions. In the last decade, literature hasbeen massively filled with training methodologies that claim to obtain moreabstract and robust data representations to tackle domain shifts. Recentresearch has provided a reproducible benchmark for DG, pointing out theeffectiveness of naive empirical risk minimization (ERM) over existingalgorithms. Nevertheless, researchers persist in using the same outdatedfeature extractors, and no attention has been given to the effects of differentbackbones yet. In this paper, we start back to the backbones proposing acomprehensive analysis of their intrinsic generalization capabilities, which sofar have been ignored by the research community. We evaluate a wide variety offeature extractors, from standard residual solutions to transformer-basedarchitectures, finding an evident linear correlation between large-scalesingle-domain classification accuracy and DG capability. Our extensiveexperimentation shows that by adopting competitive backbones in conjunctionwith effective data augmentation, plain ERM outperforms recent DG solutions andachieves state-of-the-art accuracy. Moreover, our additional qualitativestudies reveal that novel backbones give more similar representations tosame-class samples, separating different domains in the feature space. Thisboost in generalization capabilities leaves marginal room for DG algorithms. Itsuggests a new paradigm for investigating the problem, placing backbones in thespotlight and encouraging the development of consistent algorithms on top ofthem. The code is available at https://github.com/PIC4SeR/Back-to-Bones.</description><author>Simone Angarano, Mauro Martini, Francesco Salvetti, Vittorio Mazzia, Marcello Chiaberge</author><pubDate>Tue, 09 May 2023 15:31:36 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2209.01121v2</guid></item><item><title>Investigating the effect of sub-word segmentation on the performance of transformer language models</title><link>http://arxiv.org/abs/2305.05480v1</link><description>We would like to explore how morphemes can affect the performance of alanguage model. We trained GPT-2 and Bert model with StateMorph for bothFinnish and Russian, which is a morpheme segmenting algorithm. As a comparison,we also trained a model with BPE and Morfessor. Our preliminary result showsthat StateMorph can help the model to converge more efficiently and achieve abetter validation score.</description><author>Jue Hou, Anisia Katinskaia, Anh-Duc Vu, Roman Yangarber</author><pubDate>Tue, 09 May 2023 15:30:29 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.05480v1</guid></item><item><title>End to End Lane detection with One-to-Several Transformer</title><link>http://arxiv.org/abs/2305.00675v3</link><description>Although lane detection methods have shown impressive performance inreal-world scenarios, most of methods require post-processing which is notrobust enough. Therefore, end-to-end detectors like DEtection TRansformer(DETR)have been introduced in lane detection. However, one-to-one label assignment inDETR can degrade the training efficiency due to label semantic conflicts.Besides, positional query in DETR is unable to provide explicit positionalprior, making it difficult to be optimized. In this paper, we present theOne-to-Several Transformer(O2SFormer). We first propose the one-to-severallabel assignment, which combines one-to-one and one-to-many label assignmentsto improve the training efficiency while keeping end-to-end detection. Toovercome the difficulty in optimizing one-to-one assignment. We further proposethe layer-wise soft label which adjusts the positive weight of positive laneanchors across different decoder layers. Finally, we design the dynamicanchor-based positional query to explore positional prior by incorporating laneanchors into positional query. Experimental results show that O2SFormersignificantly speeds up the convergence of DETR and outperformsTransformer-based and CNN-based detectors on the CULane dataset. Code will beavailable at https://github.com/zkyseu/O2SFormer.</description><author>Kunyang Zhou, Rui Zhou</author><pubDate>Tue, 09 May 2023 15:30:16 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.00675v3</guid></item><item><title>Mechanism of feature learning in deep fully connected networks and kernel machines that recursively learn features</title><link>http://arxiv.org/abs/2212.13881v3</link><description>In recent years neural networks have achieved impressive results on manytechnological and scientific tasks. Yet, the mechanism through which thesemodels automatically select features, or patterns in data, for predictionremains unclear. Identifying such a mechanism is key to advancing performanceand interpretability of neural networks and promoting reliable adoption ofthese models in scientific applications. In this paper, we identify andcharacterize the mechanism through which deep fully connected neural networkslearn features. We posit the Deep Neural Feature Ansatz, which states thatneural feature learning occurs by implementing the average gradient outerproduct to up-weight features strongly related to model output. Our ansatzsheds light on various deep learning phenomena including emergence of spuriousfeatures and simplicity biases and how pruning networks can increaseperformance, the "lottery ticket hypothesis." Moreover, the mechanismidentified in our work leads to a backpropagation-free method for featurelearning with any machine learning model. To demonstrate the effectiveness ofthis feature learning mechanism, we use it to enable feature learning inclassical, non-feature learning models known as kernel machines and show thatthe resulting models, which we refer to as Recursive Feature Machines, achievestate-of-the-art performance on tabular data.</description><author>Adityanarayanan Radhakrishnan, Daniel Beaglehole, Parthe Pandit, Mikhail Belkin</author><pubDate>Tue, 09 May 2023 15:29:35 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2212.13881v3</guid></item><item><title>Optimizing Privacy, Utility and Efficiency in Constrained Multi-Objective Federated Learning</title><link>http://arxiv.org/abs/2305.00312v4</link><description>Conventionally, federated learning aims to optimize a single objective,typically the utility. However, for a federated learning system to betrustworthy, it needs to simultaneously satisfy multiple/many objectives, suchas maximizing model performance, minimizing privacy leakage and training cost,and being robust to malicious attacks. Multi-Objective Optimization (MOO)aiming to optimize multiple conflicting objectives at the same time is quitesuitable for solving the optimization problem of Trustworthy Federated Learning(TFL). In this paper, we unify MOO and TFL by formulating the problem ofconstrained multi-objective federated learning (CMOFL). Under this formulation,existing MOO algorithms can be adapted to TFL straightforwardly. Different fromexisting CMOFL works focusing on utility, efficiency, fairness, and robustness,we consider optimizing privacy leakage along with utility loss and trainingcost, the three primary objectives of a TFL system. We develop two improvedCMOFL algorithms based on NSGA-II and PSL, respectively, for effectively andefficiently finding Pareto optimal solutions, and we provide theoreticalanalysis on their convergence. We design specific measurements of privacyleakage, utility loss, and training cost for three privacy protectionmechanisms: Randomization, BatchCrypt (An efficient version of homomorphicencryption), and Sparsification. Empirical experiments conducted under each ofthe three protection mechanisms demonstrate the effectiveness of our proposedalgorithms.</description><author>Yan Kang, Hanlin Gu, Xingxing Tang, Yuanqin He, Yuzhu Zhang, Jinnan He, Yuxing Han, Lixin Fan, Kai Chen, Qiang Yang</author><pubDate>Tue, 09 May 2023 15:29:09 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.00312v4</guid></item><item><title>EDeNN: Event Decay Neural Networks for low latency vision</title><link>http://arxiv.org/abs/2209.04362v2</link><description>Despite the success of neural networks in computer vision tasks, digital'neurons' are a very loose approximation of biological neurons. Today'slearning approaches are designed to function on digital devices with digitaldata representations such as image frames. In contrast, biological visionsystems are generally much more capable and efficient than state-of-the-artdigital computer vision algorithms. Event cameras are an emerging sensortechnology which imitates biological vision with asynchronously firing pixels,eschewing the concept of the image frame. To leverage modern learningtechniques, many event-based algorithms are forced to accumulate events back toimage frames, somewhat squandering the advantages of event cameras. We follow the opposite paradigm and develop a new type of neural networkwhich operates closer to the original event data stream. We demonstratestate-of-the-art performance in angular velocity regression and competitiveoptical flow estimation, while avoiding difficulties related to training SNN.Furthermore, the processing latency of our proposed approach is less than 1/10any other implementation, while continuous inference increases this improvementby another order of magnitude.</description><author>Celyn Walters, Simon Hadfield</author><pubDate>Tue, 09 May 2023 15:22:17 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2209.04362v2</guid></item><item><title>Going beyond research datasets: Novel intent discovery in the industry setting</title><link>http://arxiv.org/abs/2305.05474v1</link><description>Novel intent discovery automates the process of grouping similar messages(questions) to identify previously unknown intents. However, current researchfocuses on publicly available datasets which have only the question field andsignificantly differ from real-life datasets. This paper proposes methods toimprove the intent discovery pipeline deployed in a large e-commerce platform.We show the benefit of pre-training language models on in-domain data: bothself-supervised and with weak supervision. We also devise the best method toutilize the conversational structure (i.e., question and answer) of real-lifedatasets during fine-tuning for clustering tasks, which we call Conv. All ourmethods combined to fully utilize real-life datasets give up to 33ppperformance boost over state-of-the-art Constrained Deep Adaptive Clustering(CDAC) model for question only. By comparison CDAC model for the question dataonly gives only up to 13pp performance boost over the naive baseline.</description><author>Aleksandra Chrabrowa, Tsimur Hadeliya, Dariusz Kajtoch, Robert Mroczkowski, Piotr Rybak</author><pubDate>Tue, 09 May 2023 15:21:29 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.05474v1</guid></item><item><title>Beyond Good Intentions: Reporting the Research Landscape of NLP for Social Good</title><link>http://arxiv.org/abs/2305.05471v1</link><description>With the recent advances in natural language processing (NLP), a vast numberof applications have emerged across various use cases. Among the plethora ofNLP applications, many academic researchers are motivated to do work that has apositive social impact, in line with the recent initiatives of NLP for SocialGood (NLP4SG). However, it is not always obvious to researchers how theirresearch efforts are tackling today's big social problems. Thus, in this paper,we introduce NLP4SGPAPERS, a scientific dataset with three associated tasksthat can help identify NLP4SG papers and characterize the NLP4SG landscape by:(1) identifying the papers that address a social problem, (2) mapping them tothe corresponding UN Sustainable Development Goals (SDGs), and (3) identifyingthe task they are solving and the methods they are using. Usingstate-of-the-art NLP models, we address each of these tasks and use them on theentire ACL Anthology, resulting in a visualization workspace that givesresearchers a comprehensive overview of the field of NLP4SG. Our website isavailable at https://nlp4sg.vercel.app . We released our data athttps://huggingface.co/datasets/feradauto/NLP4SGPapers and code athttps://github.com/feradauto/nlp4sg .</description><author>Fernando Gonzalez, Zhijing Jin, Jad Beydoun, Bernhard Schölkopf, Tom Hope, Mrinmaya Sachan, Rada Mihalcea</author><pubDate>Tue, 09 May 2023 15:16:25 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.05471v1</guid></item><item><title>Graph Neural Networks for Airfoil Design</title><link>http://arxiv.org/abs/2305.05469v1</link><description>The study of partial differential equations (PDE) through the framework ofdeep learning emerged a few years ago leading to the impressive approximationsof simple dynamics. Graph neural networks (GNN) turned out to be very useful inthose tasks by allowing the treatment of unstructured data often encountered inthe field of numerical resolutions of PDE. However, the resolutions of harderPDE such as Navier-Stokes equations are still a challenging task and most ofthe work done on the latter concentrate either on simulating the flow aroundsimple geometries or on qualitative results that looks physical for designpurpose. In this study, we try to leverage the work done on deep learning forPDE and GNN by proposing an adaptation of a known architecture in order totackle the task of approximating the solution of the two-dimensionalsteady-state incompressible Navier-Stokes equations over different airfoilgeometries. In addition to that, we test our model not only on its performanceover the volume but also on its performance to approximate surface quantitiessuch as the wall shear stress or the isostatic pressure leading to theinference of global coefficients such as the lift and the drag of our airfoilin order to allow design exploration. This work takes place in a longer projectthat aims to approximate three dimensional steady-state solutions overindustrial geometries.</description><author>Florent Bonnet</author><pubDate>Tue, 09 May 2023 15:15:55 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.05469v1</guid></item><item><title>Provably Safe Reinforcement Learning: A Theoretical and Experimental Comparison</title><link>http://arxiv.org/abs/2205.06750v2</link><description>Ensuring safety of reinforcement learning (RL) algorithms is crucial tounlock their potential for many real-world tasks. However, vanilla RL does notguarantee safety. In recent years, several methods have been proposed toprovide safety guarantees for RL by design. Yet, there is no comprehensivecomparison of these provably safe RL methods. We therefore introduce acategorization of existing provably safe RL methods, present the theoreticalfoundations for both continuous and discrete action spaces, and benchmark themethods' performance empirically. The methods are categorized based on how theaction is adapted by the safety method: action replacement, action projection,and action masking. Our experiments on an inverted pendulum and quadrotorstabilization task show that all provably safe methods are indeed always safe.Furthermore, their trained performance is comparable to unsafe baselines. Thebenchmarking suggests that different provably safe RL approaches should beselected depending on safety specifications, RL algorithms, and type of actionspace.</description><author>Hanna Krasowski, Jakob Thumm, Marlon Müller, Lukas Schäfer, Xiao Wang, Matthias Althoff</author><pubDate>Tue, 09 May 2023 15:14:51 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2205.06750v2</guid></item><item><title>Autoencoded sparse Bayesian in-IRT factorization, calibration, and amortized inference for the Work Disability Functional Assessment Battery</title><link>http://arxiv.org/abs/2210.10952v4</link><description>The Work Disability Functional Assessment Battery (WD-FAB) is amultidimensional item response theory (IRT) instrument designed for assessingwork-related mental and physical function based on responses to an item bank.In prior iterations it was developed using traditional means -- linearfactorization and null hypothesis statistical testing for itempartitioning/selection, and finally, posthoc calibration of disjointunidimensional IRT models. As a result, the WD-FAB, like many other IRTinstruments, is a posthoc model. Its item partitioning, based on exploratoryfactor analysis, is blind to the final nonlinear IRT model and is not performedin a manner consistent with goodness of fit to the final model. In thismanuscript, we develop a Bayesian hierarchical model for self-consistentlyperforming the following simultaneous tasks: scale factorization, itemselection, parameter identification, and response scoring. This method usessparsity-based shrinkage to obviate the linear factorization and nullhypothesis statistical tests that are usually required for developingmultidimensional IRT models, so that item partitioning is consistent with theultimate nonlinear factor model. We also analogize our multidimensional IRTmodel to probabilistic autoencoders, specifying an encoder function thatamortizes the inference of ability parameters from item responses. The encoderfunction is equivalent to the "VBE" step in a stochastic variational Bayesianexpectation maximization (VBEM) procedure that we use for approxiamte Bayesianinference on the entire model. We use the method on a sample of WD-FAB itemresponses and compare the resulting item discriminations to those obtainedusing the traditional posthoc method.</description><author>Joshua C. Chang, Carson C. Chow, Julia Porcino</author><pubDate>Tue, 09 May 2023 15:11:11 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2210.10952v4</guid></item><item><title>Benchmark dataset and instance generator for Real-World Three-Dimensional Bin Packing Problems</title><link>http://arxiv.org/abs/2304.14712v2</link><description>In this article, a benchmark for real-world bin packing problems is proposed.This dataset consists of 12 instances of varying levels of complexity regardingsize (with the number of packages ranging from 38 to 53) and user-definedrequirements. In fact, several real-world-oriented restrictions were taken intoaccount to build these instances: i) item and bin dimensions, ii) weightrestrictions, iii) affinities among package categories iv) preferences forpackage ordering and v) load balancing. Besides the data, we also offer an owndeveloped Python script for the dataset generation, coined Q4RealBPP-DataGen.The benchmark was initially proposed to evaluate the performance of quantumsolvers. Therefore, the characteristics of this set of instances were designedaccording to the current limitations of quantum devices. Additionally, thedataset generator is included to allow the construction of general-purposebenchmarks. The data introduced in this article provides a baseline that willencourage quantum computing researchers to work on real-world bin packingproblems.</description><author>Eneko Osaba, Esther Villar-Rodriguez, Sebastián V. Romero</author><pubDate>Tue, 09 May 2023 15:08:52 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2304.14712v2</guid></item><item><title>Measuring Forgetting of Memorized Training Examples</title><link>http://arxiv.org/abs/2207.00099v2</link><description>Machine learning models exhibit two seemingly contradictory phenomena:training data memorization, and various forms of forgetting. In memorization,models overfit specific training examples and become susceptible to privacyattacks. In forgetting, examples which appeared early in training are forgottenby the end. In this work, we connect these phenomena. We propose a technique tomeasure to what extent models "forget" the specifics of training examples,becoming less susceptible to privacy attacks on examples they have not seenrecently. We show that, while non-convex models can memorize data forever inthe worst-case, standard image, speech, and language models empirically doforget examples over time. We identify nondeterminism as a potentialexplanation, showing that deterministically trained models do not forget. Ourresults suggest that examples seen early when training with extremely largedatasets - for instance those examples used to pre-train a model - may observeprivacy benefits at the expense of examples seen later.</description><author>Matthew Jagielski, Om Thakkar, Florian Tramèr, Daphne Ippolito, Katherine Lee, Nicholas Carlini, Eric Wallace, Shuang Song, Abhradeep Thakurta, Nicolas Papernot, Chiyuan Zhang</author><pubDate>Tue, 09 May 2023 15:08:17 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2207.00099v2</guid></item><item><title>The emergence of clusters in self-attention dynamics</title><link>http://arxiv.org/abs/2305.05465v1</link><description>Viewing Transformers as interacting particle systems, we describe thegeometry of learned representations when the weights are not time dependent. Weshow that particles, representing tokens, tend to cluster toward particularlimiting objects as time tends to infinity. The type of limiting object thatemerges depends on the spectrum of the value matrix. Additionally, in theone-dimensional case we prove that the self-attention matrix converges to alow-rank Boolean matrix. The combination of these results mathematicallyconfirms the empirical observation made by Vaswani et al.\cite{vaswani2017attention} that \emph{leaders} appear in a sequence of tokenswhen processed by Transformers.</description><author>Borjan Geshkovski, Cyril Letrouit, Yury Polyanskiy, Philippe Rigollet</author><pubDate>Tue, 09 May 2023 15:04:42 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.05465v1</guid></item><item><title>Style-A-Video: Agile Diffusion for Arbitrary Text-based Video Style Transfer</title><link>http://arxiv.org/abs/2305.05464v1</link><description>Large-scale text-to-video diffusion models have demonstrated an exceptionalability to synthesize diverse videos. However, due to the lack of extensivetext-to-video datasets and the necessary computational resources for training,directly applying these models for video stylization remains difficult. Also,given that the noise addition process on the input content is random anddestructive, fulfilling the style transfer task's content preservation criteriais challenging. This paper proposes a zero-shot video stylization method namedStyle-A-Video, which utilizes a generative pre-trained transformer with animage latent diffusion model to achieve a concise text-controlled videostylization. We improve the guidance condition in the denoising process,establishing a balance between artistic expression and structure preservation.Furthermore, to decrease inter-frame flicker and avoid the formation ofadditional artifacts, we employ a sampling optimization and a temporalconsistency module. Extensive experiments show that we can attain superiorcontent preservation and stylistic performance while incurring less consumptionthan previous solutions. Code will be available athttps://github.com/haha-lisa/Style-A-Video.</description><author>Nisha Huang, Yuxin Zhang, Weiming Dong</author><pubDate>Tue, 09 May 2023 15:03:27 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.05464v1</guid></item><item><title>Self-Evolving Integrated VHetNets for 6G: A Multi-Tier HFL Approach</title><link>http://arxiv.org/abs/2305.05463v1</link><description>Self-evolving networks (SENs) are emerging technologies that dynamically andautonomously adapt and optimize their performance and behaviour based onchanging conditions and evolving requirements. With the advent offifth-generation (5G) wireless technologies and the resurgence of machinelearning, SENs are expected to become a critical component of future wirelessnetworks. In particular, integrated vertical heterogeneous network (VHetNet)architectures, which enable dynamic, three-dimensional (3D), and agiletopologies, are likely to form a key foundation for SENs. However, thedistributed multi-level computational and communication structure and the fullydynamic nature of self-evolving integrated VHetNets (SEI-VHetNets) necessitatethe deployment of an enhanced distributed learning and computing mechanism toenable full integration and coordination. To address this need, we propose anovel learning technique, multi-tier hierarchical federated learning (MT-HFL),based on hierarchical federated learning (HFL) that enables full integrationand coordination across vertical tiers. Through MT-HFL, SEI-VHetNets can learnand adapt to dynamic network conditions, optimize resource allocation, andenhance user experience in a real-time, scalable, and accurate manner whilepreserving user privacy. This paper presents the key characteristics andchallenges of SEI-VHetNets and discusses how MT-HFL addresses them. We alsodiscuss potential use cases and present a case study demonstrating theadvantages of MT-HFL over conventional terrestrial HFL approaches.</description><author>Amin Farajzadeh, Animesh Yadav, Halim Yanikomeroglu</author><pubDate>Tue, 09 May 2023 15:03:22 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.05463v1</guid></item><item><title>What is the best recipe for character-level encoder-only modelling?</title><link>http://arxiv.org/abs/2305.05461v1</link><description>This paper aims to benchmark recent progress in language understanding modelsthat output contextualised representations at the character level. Many suchmodelling architectures and methods to train those architectures have beenproposed, but it is currently unclear what the relative contributions of thearchitecture vs. the pretraining objective are to final model performance. Weexplore the design space of such models, comparing architectural innovationsand a variety of different pretraining objectives on a suite of evaluationtasks with a fixed training procedure in order to find the currently optimalway to build and train character-level BERT-like models. We find that our bestperforming character-level model exceeds the performance of a token-based modeltrained with the same settings on the same data, suggesting thatcharacter-level models are ready for more widespread adoption. Unfortunately,the best method to train character-level models still relies on a subword-leveltokeniser during pretraining, and final model performance is highly dependenton tokeniser quality. We believe our results demonstrate the readiness ofcharacter-level models for multilingual language representation, and encourageNLP practitioners to try them as drop-in replacements for token-based models.</description><author>Kris Cao</author><pubDate>Tue, 09 May 2023 15:00:15 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.05461v1</guid></item><item><title>Neural Implicit Dense Semantic SLAM</title><link>http://arxiv.org/abs/2304.14560v2</link><description>Visual Simultaneous Localization and Mapping (vSLAM) is a widely usedtechnique in robotics and computer vision that enables a robot to create a mapof an unfamiliar environment using a camera sensor while simultaneouslytracking its position over time. In this paper, we propose a novel RGBD vSLAMalgorithm that can learn a memory-efficient, dense 3D geometry, and semanticsegmentation of an indoor scene in an online manner. Our pipeline combinesclassical 3D vision-based tracking and loop closing with neural fields-basedmapping. The mapping network learns the SDF of the scene as well as RGB, depth,and semantic maps of any novel view using only a set of keyframes.Additionally, we extend our pipeline to large scenes by using multiple localmapping networks. Extensive experiments on well-known benchmark datasetsconfirm that our approach provides robust tracking, mapping, and semanticlabeling even with noisy, sparse, or no input depth. Overall, our proposedalgorithm can greatly enhance scene perception and assist with a range of robotcontrol problems.</description><author>Yasaman Haghighi, Suryansh Kumar, Jean-Philippe Thiran, Luc Van Gool</author><pubDate>Tue, 09 May 2023 14:58:15 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2304.14560v2</guid></item><item><title>Policy Optimization over General State and Action Spaces</title><link>http://arxiv.org/abs/2211.16715v2</link><description>Reinforcement learning (RL) problems over general state and action spaces arenotoriously challenging. In contrast to the tableau setting, one can notenumerate all the states and then iteratively update the policies for eachstate. This prevents the application of many well-studied RL methods especiallythose with provable convergence guarantees. In this paper, we first present asubstantial generalization of the recently developed policy mirror descentmethod to deal with general state and action spaces. We introduce newapproaches to incorporate function approximation into this method, so that wedo not need to use explicit policy parameterization at all. Moreover, wepresent a novel policy dual averaging method for which possibly simplerfunction approximation techniques can be applied. We establish linearconvergence rate to global optimality or sublinear convergence to stationarityfor these methods applied to solve different classes of RL problems under exactpolicy evaluation. We then define proper notions of the approximation errorsfor policy evaluation and investigate their impact on the convergence of thesemethods applied to general-state RL problems with either finite-action orcontinuous-action spaces. To the best of our knowledge, the development ofthese algorithmic frameworks as well as their convergence analysis appear to benew in the literature.</description><author>Guanghui Lan</author><pubDate>Tue, 09 May 2023 14:56:39 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2211.16715v2</guid></item><item><title>AlignSTS: Speech-to-Singing Conversion via Cross-Modal Alignment</title><link>http://arxiv.org/abs/2305.04476v2</link><description>The speech-to-singing (STS) voice conversion task aims to generate singingsamples corresponding to speech recordings while facing a major challenge: thealignment between the target (singing) pitch contour and the source (speech)content is difficult to learn in a text-free situation. This paper proposesAlignSTS, an STS model based on explicit cross-modal alignment, which viewsspeech variance such as pitch and content as different modalities. Inspired bythe mechanism of how humans will sing the lyrics to the melody, AlignSTS: 1)adopts a novel rhythm adaptor to predict the target rhythm representation tobridge the modality gap between content and pitch, where the rhythmrepresentation is computed in a simple yet effective way and is quantized intoa discrete space; and 2) uses the predicted rhythm representation to re-alignthe content based on cross-attention and conducts a cross-modal fusion forre-synthesize. Extensive experiments show that AlignSTS achieves superiorperformance in terms of both objective and subjective metrics. Audio samplesare available at https://alignsts.github.io.</description><author>Ruiqi Li, Rongjie Huang, Lichao Zhang, Jinglin Liu, Zhou Zhao</author><pubDate>Tue, 09 May 2023 14:53:42 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.04476v2</guid></item><item><title>Complexity of Stochastic Dual Dynamic Programming</title><link>http://arxiv.org/abs/1912.07702v9</link><description>Stochastic dual dynamic programming is a cutting plane type algorithm formulti-stage stochastic optimization originated about 30 years ago. In spite ofits popularity in practice, there does not exist any analysis on theconvergence rates of this method. In this paper, we first establish the numberof iterations, i.e., iteration complexity, required by a basic dynamic cuttingplane method for solving relatively simple multi-stage optimization problems,by introducing novel mathematical tools including the saturation of searchpoints. We then refine these basic tools and establish the iteration complexityfor both deterministic and stochastic dual dynamic programming methods forsolving more general multi-stage stochastic optimization problems under thestandard stage-wise independence assumption. Our results indicate that thecomplexity of some deterministic variants of these methods mildly increaseswith the number of stages $T$, in fact linearly dependent on $T$ for discountedproblems. Therefore, they are efficient for strategic decision making whichinvolves a large number of stages, but with a relatively small number ofdecision variables in each stage. Without explicitly discretizing the state andaction spaces, these methods might also be pertinent to the relatedreinforcement learning and stochastic control areas.</description><author>Guanghui Lan</author><pubDate>Tue, 09 May 2023 14:52:40 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/1912.07702v9</guid></item><item><title>Teacher-Student Network for 3D Point Cloud Anomaly Detection with Few Normal Samples</title><link>http://arxiv.org/abs/2210.17258v2</link><description>Anomaly detection, which is a critical and popular topic in computer vision,aims to detect anomalous samples that are different from the normal (i.e.,non-anomalous) ones. The current mainstream methods focus on anomaly detectionfor images, whereas little attention has been paid to 3D point cloud. In thispaper, drawing inspiration from the knowledge transfer ability ofteacher-student architecture and the impressive feature extraction capabilityof recent neural networks, we design a teacher-student structured model for 3Danomaly detection. Specifically, we use feature space alignment, dimensionzoom, and max pooling to extract the features of the point cloud and thenminimize a multi-scale loss between the feature vectors produced by the teacherand the student networks. Moreover, our method only requires very few normalsamples to train the student network due to the teacher-student distillationmechanism. Once trained, the teacher-student network pair can be leveragedjointly to fulfill 3D point cloud anomaly detection based on the calculatedanomaly score. For evaluation, we compare our method against thereconstruction-based method on the ShapeNet-Part dataset. The experimentalresults and ablation studies quantitatively and qualitatively confirm that ourmodel can achieve higher performance compared with the state of the arts in 3Danomaly detection with very few training samples.</description><author>Jianjian Qin, Chunzhi Gu, Jun Yu, Chao Zhang</author><pubDate>Tue, 09 May 2023 14:49:20 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2210.17258v2</guid></item><item><title>Restormer-Plus for Real World Image Deraining: One State-of-the-Art Solution to the GT-RAIN Challenge (CVPR 2023 UG$^2$+ Track 3)</title><link>http://arxiv.org/abs/2305.05454v1</link><description>This technical report presents our Restormer-Plus approach, which wassubmitted to the GT-RAIN Challenge (CVPR 2023 UG$^2$+ Track 3). Detailsregarding the challenge are available athttp://cvpr2023.ug2challenge.org/track3.html. Our Restormer-Plus outperformedall other submitted solutions in terms of peak signal-to-noise ratio (PSNR). Itconsists mainly of four modules: the single image de-raining module, the medianfiltering module, the weighted averaging module, and the post-processingmodule. We named the single-image de-raining module Restormer-X, which is builton Restormer and performed on each rainy image. The median filtering module isemployed as a median operator for the 300 rainy images associated with eachscene. The weighted averaging module combines the median filtering results withthat of Restormer-X to alleviate overfitting if we only use Restormer-X.Finally, the post-processing module is used to improve the brightnessrestoration. Together, these modules render Restormer-Plus to be onestate-of-the-art solution to the GT-RAIN Challenge. Our code is available athttps://github.com/ZJLAB-AMMI/Restormer-Plus.</description><author>Chaochao Zheng, Luping Wang, Bin Liu</author><pubDate>Tue, 09 May 2023 14:48:38 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.05454v1</guid></item><item><title>Multiscale Augmented Normalizing Flows for Image Compression</title><link>http://arxiv.org/abs/2305.05451v1</link><description>Most learning-based image compression methods lack efficiency for high imagequality due to their non-invertible design. The decoding function of thefrequently applied compressive autoencoder architecture is only an approximatedinverse of the encoding transform. This issue can be resolved by usinginvertible latent variable models, which allow a perfect reconstruction if noquantization is performed. Furthermore, many traditional image and video codersapply dynamic block partitioning to vary the compression of certain imageregions depending on their content. Inspired by this approach, hierarchicallatent spaces have been applied to learning-based compression networks. In thispaper, we present a novel concept, which adapts the hierarchical latent spacefor augmented normalizing flows, an invertible latent variable model. Our bestperforming model achieved average rate savings of more than 7% over comparablesingle-scale models.</description><author>Marc Windsheimer, Fabian Brand, André Kaup</author><pubDate>Tue, 09 May 2023 14:42:43 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.05451v1</guid></item><item><title>Neuralizer: General Neuroimage Analysis without Re-Training</title><link>http://arxiv.org/abs/2305.02644v2</link><description>Neuroimage processing tasks like segmentation, reconstruction, andregistration are central to the study of neuroscience. Robust deep learningstrategies and architectures used to solve these tasks are often similar. Yet,when presented with a new task or a dataset with different visualcharacteristics, practitioners most often need to train a new model, orfine-tune an existing one. This is a time-consuming process that poses asubstantial barrier for the thousands of neuroscientists and clinicalresearchers who often lack the resources or machine-learning expertise to traindeep learning models. In practice, this leads to a lack of adoption of deeplearning, and neuroscience tools being dominated by classical frameworks. We introduce Neuralizer, a single model that generalizes to previously unseenneuroimaging tasks and modalities without the need for re-training orfine-tuning. Tasks do not have to be known a priori, and generalization happensin a single forward pass during inference. The model can solve processing tasksacross multiple image modalities, acquisition methods, and datasets, andgeneralize to tasks and modalities it has not been trained on. Our experimentson coronal slices show that when few annotated subjects are available, ourmulti-task network outperforms task-specific baselines without training on thetask.</description><author>Steffen Czolbe, Adrian V. Dalca</author><pubDate>Tue, 09 May 2023 14:39:04 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.02644v2</guid></item><item><title>Robust Implicit Regularization via Weight Normalization</title><link>http://arxiv.org/abs/2305.05448v1</link><description>Overparameterized models may have many interpolating solutions; implicitregularization refers to the hidden preference of a particular optimizationmethod towards a certain interpolating solution among the many. A by nowestablished line of work has shown that (stochastic) gradient descent tends tohave an implicit bias towards low rank and/or sparse solutions when used totrain deep linear networks, explaining to some extent why overparameterizedneural network models trained by gradient descent tend to have goodgeneralization performance in practice. However, existing theory forsquare-loss objectives often requires very small initialization of thetrainable weights, which is at odds with the larger scale at which weights areinitialized in practice for faster convergence and better generalizationperformance. In this paper, we aim to close this gap by incorporating andanalyzing gradient descent with weight normalization, where the weight vectoris reparamterized in terms of polar coordinates, and gradient descent isapplied to the polar coordinates. By analyzing key invariants of the gradientflow and using Lojasiewicz's Theorem, we show that weight normalization alsohas an implicit bias towards sparse solutions in the diagonal linear model, butthat in contrast to plain gradient descent, weight normalization enables arobust bias that persists even if the weights are initialized at practicallylarge scale. Experiments suggest that the gains in both convergence speed androbustness of the implicit bias are improved dramatically by using weightnormalization in overparameterized diagonal linear network models.</description><author>Hung-Hsu Chou, Holger Rauhut, Rachel Ward</author><pubDate>Tue, 09 May 2023 14:38:55 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.05448v1</guid></item><item><title>StyleSync: High-Fidelity Generalized and Personalized Lip Sync in Style-based Generator</title><link>http://arxiv.org/abs/2305.05445v1</link><description>Despite recent advances in syncing lip movements with any audio waves,current methods still struggle to balance generation quality and the model'sgeneralization ability. Previous studies either require long-term data fortraining or produce a similar movement pattern on all subjects with lowquality. In this paper, we propose StyleSync, an effective framework thatenables high-fidelity lip synchronization. We identify that a style-basedgenerator would sufficiently enable such a charming property on both one-shotand few-shot scenarios. Specifically, we design a mask-guided spatialinformation encoding module that preserves the details of the given face. Themouth shapes are accurately modified by audio through modulated convolutions.Moreover, our design also enables personalized lip-sync by introducing stylespace and generator refinement on only limited frames. Thus the identity andtalking style of a target person could be accurately preserved. Extensiveexperiments demonstrate the effectiveness of our method in producinghigh-fidelity results on a variety of scenes. Resources can be found athttps://hangz-nju-cuhk.github.io/projects/StyleSync.</description><author>Jiazhi Guan, Zhanwang Zhang, Hang Zhou, Tianshu Hu, Kaisiyuan Wang, Dongliang He, Haocheng Feng, Jingtuo Liu, Errui Ding, Ziwei Liu, Jingdong Wang</author><pubDate>Tue, 09 May 2023 14:38:13 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.05445v1</guid></item><item><title>Bayesian Over-the-Air FedAvg via Channel Driven Stochastic Gradient Langevin Dynamics</title><link>http://arxiv.org/abs/2305.04152v2</link><description>The recent development of scalable Bayesian inference methods has renewedinterest in the adoption of Bayesian learning as an alternative to conventionalfrequentist learning that offers improved model calibration via uncertaintyquantification. Recently, federated averaging Langevin dynamics (FALD) wasintroduced as a variant of federated averaging that can efficiently implementdistributed Bayesian learning in the presence of noiseless communications. Inthis paper, we propose wireless FALD (WFALD), a novel protocol that realizesFALD in wireless systems by integrating over-the-air computation andchannel-driven sampling for Monte Carlo updates. Unlike prior work on wirelessBayesian learning, WFALD enables (\emph{i}) multiple local updates betweencommunication rounds; and (\emph{ii}) stochastic gradients computed bymini-batch. A convergence analysis is presented in terms of the 2-Wassersteindistance between the samples produced by WFALD and the targeted globalposterior distribution. Analysis and experiments show that, when thesignal-to-noise ratio is sufficiently large, channel noise can be fullyrepurposed for Monte Carlo sampling, thus entailing no loss in performance.</description><author>Boning Zhang, Dongzhu Liu, Osvaldo Simeone, Guangxu Zhu</author><pubDate>Tue, 09 May 2023 14:30:12 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.04152v2</guid></item><item><title>Attention-Based Transformer Networks for Quantum State Tomography</title><link>http://arxiv.org/abs/2305.05433v1</link><description>Neural networks have been actively explored for quantum state tomography(QST) due to their favorable expressibility. To further enhance the efficiencyof reconstructing quantum states, we explore the similarity between languagemodeling and quantum state tomography and propose an attention-based QST methodthat utilizes the Transformer network to capture the correlations betweenmeasured results from different measurements. Our method directly retrieves thedensity matrices of quantum states from measured statistics, with theassistance of an integrated loss function that helps minimize the differencebetween the actual states and the retrieved states. Then, we systematicallytrace different impacts within a bag of common training strategies involvingvarious parameter adjustments on the attention-based QST method. Combiningthese techniques, we establish a robust baseline that can efficientlyreconstruct pure and mixed quantum states. Furthermore, by comparing theperformance of three popular neural network architectures (FCNs, CNNs, andTransformer), we demonstrate the remarkable expressiveness of attention inlearning density matrices from measured statistics.</description><author>Hailan Ma, Zhenhong Sun, Daoyi Dong, Chunlin Chen, Herschel Rabitz</author><pubDate>Tue, 09 May 2023 14:22:13 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.05433v1</guid></item><item><title>$\texttt{BanditQ}:$ Fair Multi-Armed Bandits with Guaranteed Rewards per Arm</title><link>http://arxiv.org/abs/2304.05219v2</link><description>Classic no-regret online prediction algorithms, including variants of theUpper Confidence Bound ($\texttt{UCB}$) algorithm, $\texttt{Hedge}$, and$\texttt{EXP3}$, are inherently unfair by design. The unfairness stems fromtheir very objective of playing the most rewarding arm as many times aspossible while ignoring the less rewarding ones among $N$ arms. In this paper,we consider a fair prediction problem in the stochastic setting with hard lowerbounds on the rate of accrual of rewards for a set of arms. We study theproblem in both full and bandit feedback settings. Using queueing-theoretictechniques in conjunction with adversarial learning, we propose a new onlineprediction policy called $\texttt{BanditQ}$ that achieves the target rewardrates while achieving a regret and target rate violation penalty of$O(T^{\frac{3}{4}}).$ In the full-information setting, the regret bound can befurther improved to $O(\sqrt{T})$ when considering the average regret over theentire horizon of length $T$. The proposed policy is efficient and admits ablack-box reduction from the fair prediction problem to the standard MABproblem with a carefully defined sequence of rewards. The design and analysisof the $\texttt{BanditQ}$ policy involve a novel use of the potential functionmethod in conjunction with scale-free second-order regret bounds and a newself-bounding inequality for the reward gradients, which are of independentinterest.</description><author>Abhishek Sinha</author><pubDate>Tue, 09 May 2023 14:21:16 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2304.05219v2</guid></item><item><title>WikiWeb2M: A Page-Level Multimodal Wikipedia Dataset</title><link>http://arxiv.org/abs/2305.05432v1</link><description>Webpages have been a rich resource for language and vision-language tasks.Yet only pieces of webpages are kept: image-caption pairs, long text articles,or raw HTML, never all in one place. Webpage tasks have resultingly receivedlittle attention and structured image-text data underused. To study multimodalwebpage understanding, we introduce the Wikipedia Webpage 2M (WikiWeb2M) suite;the first to retain the full set of images, text, and structure data availablein a page. WikiWeb2M can be used for tasks like page description generation,section summarization, and contextual image captioning.</description><author>Andrea Burns, Krishna Srinivasan, Joshua Ainslie, Geoff Brown, Bryan A. Plummer, Kate Saenko, Jianmo Ni, Mandy Guo</author><pubDate>Tue, 09 May 2023 14:20:59 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.05432v1</guid></item><item><title>Bone Marrow Cytomorphology Cell Detection using InceptionResNetV2</title><link>http://arxiv.org/abs/2305.05430v1</link><description>Critical clinical decision points in haematology are influenced by therequirement of bone marrow cytology for a haematological diagnosis. Bone marrowcytology, however, is restricted to reference facilities with expertise, andlinked to inter-observer variability which requires a long time to process thatcould result in a delayed or inaccurate diagnosis, leaving an unmet need forcutting-edge supporting technologies. This paper presents a novel transferlearning model for Bone Marrow Cell Detection to provide a solution to all thedifficulties faced for the task along with considerable accuracy. The proposedmodel achieved 96.19\% accuracy which can be used in the future for analysis ofother medical images in this domain.</description><author>Raisa Fairooz Meem, Khandaker Tabin Hasan</author><pubDate>Tue, 09 May 2023 14:18:35 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.05430v1</guid></item><item><title>Echo from noise: synthetic ultrasound image generation using diffusion models for real image segmentation</title><link>http://arxiv.org/abs/2305.05424v1</link><description>We propose a novel pipeline for the generation of synthetic images viaDenoising Diffusion Probabilistic Models (DDPMs) guided by cardiac ultrasoundsemantic label maps. We show that these synthetic images can serve as a viablesubstitute for real data in the training of deep-learning models for medicalimage analysis tasks such as image segmentation. To demonstrate theeffectiveness of this approach, we generated synthetic 2D echocardiographyimages and trained a neural network for segmentation of the left ventricle andleft atrium. The performance of the network trained on exclusively syntheticimages was evaluated on an unseen dataset of real images and yielded mean Dicescores of 88.5 $\pm 6.0$ , 92.3 $\pm 3.9$, 86.3 $\pm 10.7$ \% for leftventricular endocardial, epicardial and left atrial segmentation respectively.This represents an increase of $9.09$, $3.7$ and $15.0$ \% in Dice scorescompared to the previous state-of-the-art. The proposed pipeline has thepotential for application to a wide range of other tasks across various medicalimaging modalities.</description><author>David Stojanovski, Uxio Hermida, Pablo Lamata, Arian Beqiri, Alberto Gomez</author><pubDate>Tue, 09 May 2023 14:15:52 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.05424v1</guid></item><item><title>High-throughput Cotton Phenotyping Big Data Pipeline Lambda Architecture Computer Vision Deep Neural Networks</title><link>http://arxiv.org/abs/2305.05423v1</link><description>In this study, we propose a big data pipeline for cotton bloom detectionusing a Lambda architecture, which enables real-time and batch processing ofdata. Our proposed approach leverages Azure resources such as Data Factory,Event Grids, Rest APIs, and Databricks. This work is the first to develop anddemonstrate the implementation of such a pipeline for plant phenotyping throughAzure's cloud computing service. The proposed pipeline consists of datapreprocessing, object detection using a YOLOv5 neural network model trainedthrough Azure AutoML, and visualization of object detection bounding boxes onoutput images. The trained model achieves a mean Average Precision (mAP) scoreof 0.96, demonstrating its high performance for cotton bloom classification. Weevaluate our Lambda architecture pipeline using 9000 images yielding anoptimized runtime of 34 minutes. The results illustrate the scalability of theproposed pipeline as a solution for deep learning object detection, with thepotential for further expansion through additional Azure processing cores. Thiswork advances the scientific research field by providing a new method forcotton bloom detection on a large dataset and demonstrates the potential ofutilizing cloud computing resources, specifically Azure, for efficient andaccurate big data processing in precision agriculture.</description><author>Amanda Issac, Alireza Ebrahimi, Javad Mohammadpour Velni, Glen Rains</author><pubDate>Tue, 09 May 2023 14:15:19 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.05423v1</guid></item><item><title>Egocentric Hierarchical Visual Semantics</title><link>http://arxiv.org/abs/2305.05422v1</link><description>We are interested in aligning how people think about objects and whatmachines perceive, meaning by this the fact that object recognition, asperformed by a machine, should follow a process which resembles that followedby humans when thinking of an object associated with a certain concept. Theultimate goal is to build systems which can meaningfully interact with theirusers, describing what they perceive in the users' own terms. As from the fieldof Lexical Semantics, humans organize the meaning of words in hierarchies wherethe meaning of, e.g., a noun, is defined in terms of the meaning of a moregeneral noun, its genus, and of one or more differentiating properties, itsdifferentia. The main tenet of this paper is that object recognition shouldimplement a hierarchical process which follows the hierarchical semanticstructure used to define the meaning of words. We achieve this goal byimplementing an algorithm which, for any object, recursively recognizes itsvisual genus and its visual differentia. In other words, the recognition of anobject is decomposed in a sequence of steps where the locally relevant visualfeatures are recognized. This paper presents the algorithm and a firstevaluation.</description><author>Luca Erculiani, Andrea Bontempelli, Andrea Passerini, Fausto Giunchiglia</author><pubDate>Tue, 09 May 2023 14:14:40 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.05422v1</guid></item><item><title>DC3DCD: unsupervised learning for multiclass 3D point cloud change detection</title><link>http://arxiv.org/abs/2305.05421v1</link><description>In a constant evolving world, change detection is of prime importance to keepupdated maps. To better sense areas with complex geometry (urban areas inparticular), considering 3D data appears to be an interesting alternative toclassical 2D images. In this context, 3D point clouds (PCs) obtained by LiDARor photogrammetry are very interesting. While recent studies showed theconsiderable benefit of using deep learning-based methods to detect andcharacterize changes into raw 3D PCs, these studies rely on large annotatedtraining data to obtain accurate results. The collection of these annotationsare tricky and time-consuming. The availability of unsupervised or weaklysupervised approaches is then of prime interest. In this paper, we propose anunsupervised method, called DeepCluster 3D Change Detection (DC3DCD), to detectand categorize multiclass changes at point level. We classify our approach inthe unsupervised family given the fact that we extract in a completelyunsupervised way a number of clusters associated with potential changes. Let usprecise that in the end of the process, the user has only to assign a label toeach of these clusters to derive the final change map. Our method builds uponthe DeepCluster approach, originally designed for image classification, tohandle complex raw 3D PCs and perform change segmentation task. An assessmentof the method on both simulated and real public dataset is provided. Theproposed method allows to outperform fully-supervised traditional machinelearning algorithm and to be competitive with fully-supervised deep learningnetworks applied on rasterization of 3D PCs with a mean of IoU over classes ofchange of 57.06% and 66.69% for the simulated and the real datasets,respectively.</description><author>Iris de Gélis, Sébastien Lefèvre, Thomas Corpetti</author><pubDate>Tue, 09 May 2023 14:13:53 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.05421v1</guid></item><item><title>Weakly Supervised Learning for Analyzing Political Campaigns on Facebook</title><link>http://arxiv.org/abs/2210.10669v2</link><description>Social media platforms are currently the main channel for politicalmessaging, allowing politicians to target specific demographics and adapt basedon their reactions. However, making this communication transparent ischallenging, as the messaging is tightly coupled with its intended audience andoften echoed by multiple stakeholders interested in advancing specificpolicies. Our goal in this paper is to take a first step towards understandingthese highly decentralized settings. We propose a weakly supervised approach toidentify the stance and issue of political ads on Facebook and analyze howpolitical campaigns use some kind of demographic targeting by location, gender,or age. Furthermore, we analyze the temporal dynamics of the political ads onelection polls.</description><author>Tunazzina Islam, Shamik Roy, Dan Goldwasser</author><pubDate>Tue, 09 May 2023 14:13:47 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2210.10669v2</guid></item></channel></rss>