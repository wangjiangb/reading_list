<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/"><channel><title>Arxivfresh papers</title><link></link><description>Arxiv paper</description><language>en-US</language><lastBuildDate>Mon, 24 Jun 2024 14:00:04 GMT</lastBuildDate><generator>rfeed v1.0.0</generator><docs>https://github.com/svpino/rfeed/blob/master/README.md</docs><item><title>A SMART Mnemonic Sounds like "Glue Tonic": Mixing LLMs with Student Feedback to Make Mnemonic Learning Stick</title><link>http://arxiv.org/abs/2406.15352v1</link><description>Keyword mnemonics are memorable explanations that link new terms to simplerkeywords. Prior works generate mnemonics for students, but they do not guidemodels toward mnemonics students prefer and aid learning. We build SMART, amnemonic generator trained on feedback from real students learning new terms.To train SMART, we first fine-tune LLaMA-2 on a curated set of user-writtenmnemonics. We then use LLM alignment to enhance SMART: we deploy mnemonicsgenerated by SMART in a flashcard app to find preferences on mnemonics studentsfavor. We gather 2684 preferences from 45 students across two types: expressed(inferred from ratings) and observed (inferred from student learning), yieldingthree key findings. First, expressed and observed preferences disagree; whatstudents think is helpful does not fully capture what is truly helpful. Second,Bayesian models can synthesize complementary data from multiple preferencetypes into a single effectiveness signal. SMART is tuned via Direct PreferenceOptimization on this signal, which we show resolves ties and missing labels inthe typical method of pairwise comparisons, augmenting data for LLM outputquality gains. Third, mnemonic experts assess SMART as matching GPT-4, at muchlower deployment costs, showing the utility of capturing diverse studentfeedback to align LLMs in education.</description><author>Nishant Balepur, Matthew Shu, Alexander Hoyle, Alison Robey, Shi Feng, Seraphina Goldfarb-Tarrant, Jordan Boyd-Graber</author><pubDate>Fri, 21 Jun 2024 18:59:51 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.15352v1</guid></item><item><title>NAVSIM: Data-Driven Non-Reactive Autonomous Vehicle Simulation and Benchmarking</title><link>http://arxiv.org/abs/2406.15349v1</link><description>Benchmarking vision-based driving policies is challenging. On one hand,open-loop evaluation with real data is easy, but these results do not reflectclosed-loop performance. On the other, closed-loop evaluation is possible insimulation, but is hard to scale due to its significant computational demands.Further, the simulators available today exhibit a large domain gap to realdata. This has resulted in an inability to draw clear conclusions from therapidly growing body of research on end-to-end autonomous driving. In thispaper, we present NAVSIM, a middle ground between these evaluation paradigms,where we use large datasets in combination with a non-reactive simulator toenable large-scale real-world benchmarking. Specifically, we gathersimulation-based metrics, such as progress and time to collision, by unrollingbird's eye view abstractions of the test scenes for a short simulation horizon.Our simulation is non-reactive, i.e., the evaluated policy and environment donot influence each other. As we demonstrate empirically, this decoupling allowsopen-loop metric computation while being better aligned with closed-loopevaluations than traditional displacement errors. NAVSIM enabled a newcompetition held at CVPR 2024, where 143 teams submitted 463 entries, resultingin several new insights. On a large set of challenging scenarios, we observethat simple methods with moderate compute requirements such as TransFuser canmatch recent large-scale end-to-end driving architectures such as UniAD. Ourmodular framework can potentially be extended with new datasets, data curationstrategies, and metrics, and will be continually maintained to host futurechallenges. Our code is available athttps://github.com/autonomousvision/navsim.</description><author>Daniel Dauner, Marcel Hallgarten, Tianyu Li, Xinshuo Weng, Zhiyu Huang, Zetong Yang, Hongyang Li, Igor Gilitschenski, Boris Ivanovic, Marco Pavone, Andreas Geiger, Kashyap Chitta</author><pubDate>Fri, 21 Jun 2024 18:59:02 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.15349v1</guid></item><item><title>Provable Guarantees for Model Performance via Mechanistic Interpretability</title><link>http://arxiv.org/abs/2406.11779v4</link><description>In this work, we propose using mechanistic interpretability -- techniques forreverse engineering model weights into human-interpretable algorithms -- toderive and compactly prove formal guarantees on model performance. We prototypethis approach by formally proving lower bounds on the accuracy of 151 smalltransformers trained on a Max-of-$K$ task. We create 102 differentcomputer-assisted proof strategies and assess their length and tightness ofbound on each of our models. Using quantitative metrics, we find that shorterproofs seem to require and provide more mechanistic understanding. Moreover, wefind that more faithful mechanistic understanding leads to tighter performancebounds. We confirm these connections by qualitatively examining a subset of ourproofs. Finally, we identify compounding structureless noise as a key challengefor using mechanistic interpretability to generate compact proofs on modelperformance.</description><author>Jason Gross, Rajashree Agrawal, Thomas Kwa, Euan Ong, Chun Hei Yip, Alex Gibson, Soufiane Noubir, Lawrence Chan</author><pubDate>Fri, 21 Jun 2024 18:58:28 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.11779v4</guid></item><item><title>Privacy Preserved Blood Glucose Level Cross-Prediction: An Asynchronous Decentralized Federated Learning Approach</title><link>http://arxiv.org/abs/2406.15346v1</link><description>Newly diagnosed Type 1 Diabetes (T1D) patients often struggle to obtaineffective Blood Glucose (BG) prediction models due to the lack of sufficient BGdata from Continuous Glucose Monitoring (CGM), presenting a significant "coldstart" problem in patient care. Utilizing population models to address thischallenge is a potential solution, but collecting patient data for trainingpopulation models in a privacy-conscious manner is challenging, especiallygiven that such data is often stored on personal devices. Considering theprivacy protection and addressing the "cold start" problem in diabetes care, wepropose "GluADFL", blood Glucose prediction by Asynchronous DecentralizedFederated Learning. We compared GluADFL with eight baseline methods using fourdistinct T1D datasets, comprising 298 participants, which demonstrated itssuperior performance in accurately predicting BG levels for cross-patientanalysis. Furthermore, patients' data might be stored and shared across variouscommunication networks in GluADFL, ranging from highly interconnected (e.g.,random, performs the best among others) to more structured topologies (e.g.,cluster and ring), suitable for various social networks. The asynchronoustraining framework supports flexible participation. By adjusting the ratios ofinactive participants, we found it remains stable if less than 70% areinactive. Our results confirm that GluADFL offers a practical,privacy-preserving solution for BG prediction in T1D, significantly enhancingthe quality of diabetes management.</description><author>Chengzhe Piao, Taiyu Zhu, Yu Wang, Stephanie E Baldeweg, Paul Taylor, Pantelis Georgiou, Jiahao Sun, Jun Wang, Kezhi Li</author><pubDate>Fri, 21 Jun 2024 18:57:39 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.15346v1</guid></item><item><title>GenoTEX: A Benchmark for Evaluating LLM-Based Exploration of Gene Expression Data in Alignment with Bioinformaticians</title><link>http://arxiv.org/abs/2406.15341v1</link><description>Recent advancements in machine learning have significantly improved theidentification of disease-associated genes from gene expression datasets.However, these processes often require extensive expertise and manual effort,limiting their scalability. Large Language Model (LLM)-based agents have shownpromise in automating these tasks due to their increasing problem-solvingabilities. To support the evaluation and development of such methods, weintroduce GenoTEX, a benchmark dataset for the automatic exploration of geneexpression data, involving the tasks of dataset selection, preprocessing, andstatistical analysis. GenoTEX provides annotated code and results for solving awide range of gene identification problems, in a full analysis pipeline thatfollows the standard of computational genomics. These annotations are curatedby human bioinformaticians who carefully analyze the datasets to ensureaccuracy and reliability. To provide baselines for these tasks, we presentGenoAgents, a team of LLM-based agents designed with context-aware planning,iterative correction, and domain expert consultation to collaboratively exploregene datasets. Our experiments with GenoAgents demonstrate the potential ofLLM-based approaches in genomics data analysis, while error analysis highlightsthe challenges and areas for future improvement. We propose GenoTEX as apromising resource for benchmarking and enhancing AI-driven methods forgenomics data analysis. We make our benchmark publicly available at\url{https://github.com/Liu-Hy/GenoTex}.</description><author>Haoyang Liu, Haohan Wang</author><pubDate>Fri, 21 Jun 2024 18:55:24 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.15341v1</guid></item><item><title>Full-Scale Indexing and Semantic Annotation of CT Imaging: Boosting FAIRness</title><link>http://arxiv.org/abs/2406.15340v1</link><description>Background: The integration of artificial intelligence into medicine has ledto significant advances, particularly in diagnostics and treatment planning.However, the reliability of AI models is highly dependent on the quality of thetraining data, especially in medical imaging, where varying patient data andevolving medical knowledge pose a challenge to the accuracy andgeneralizability of given datasets. Results: The proposed approach focuses onthe integration and enhancement of clinical computed tomography (CT) imageseries for better findability, accessibility, interoperability, andreusability. Through an automated indexing process, CT image series aresemantically enhanced using the TotalSegmentator framework for segmentation andresulting SNOMED CT annotations. The metadata is standardized with HL7 FHIRresources to enable efficient data recognition and data exchange betweenresearch projects. Conclusions: The study successfully integrates a robustprocess within the UKSH MeDIC, leading to the semantic enrichment of over230,000 CT image series and over 8 million SNOMED CT annotations. Thestandardized representation using HL7 FHIR resources improves discoverabilityand facilitates interoperability, providing a foundation for the FAIRness ofmedical imaging data. However, developing automated annotation methods that cankeep pace with growing clinical datasets remains a challenge to ensurecontinued progress in large-scale integration and indexing of medical imagingfor advanced healthcare AI applications.</description><author>Hannes Ulrich, Robin Hendel, Santiago Pazmino, Björn Bergh, Björn Schreiweis</author><pubDate>Fri, 21 Jun 2024 18:55:22 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.15340v1</guid></item><item><title>Image Conductor: Precision Control for Interactive Video Synthesis</title><link>http://arxiv.org/abs/2406.15339v1</link><description>Filmmaking and animation production often require sophisticated techniquesfor coordinating camera transitions and object movements, typically involvinglabor-intensive real-world capturing. Despite advancements in generative AI forvideo creation, achieving precise control over motion for interactive videoasset generation remains challenging. To this end, we propose Image Conductor,a method for precise control of camera transitions and object movements togenerate video assets from a single image. An well-cultivated training strategyis proposed to separate distinct camera and object motion by camera LoRAweights and object LoRA weights. To further address cinematographic variationsfrom ill-posed trajectories, we introduce a camera-free guidance techniqueduring inference, enhancing object movements while eliminating cameratransitions. Additionally, we develop a trajectory-oriented video motion datacuration pipeline for training. Quantitative and qualitative experimentsdemonstrate our method's precision and fine-grained control in generatingmotion-controllable videos from images, advancing the practical application ofinteractive video synthesis. Project webpage available athttps://liyaowei-stu.github.io/project/ImageConductor/</description><author>Yaowei Li, Xintao Wang, Zhaoyang Zhang, Zhouxia Wang, Ziyang Yuan, Liangbin Xie, Yuexian Zou, Ying Shan</author><pubDate>Fri, 21 Jun 2024 18:55:05 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.15339v1</guid></item><item><title>Keystroke Dynamics Against Academic Dishonesty in the Age of LLMs</title><link>http://arxiv.org/abs/2406.15335v1</link><description>The transition to online examinations and assignments raises significantconcerns about academic integrity. Traditional plagiarism detection systemsoften struggle to identify instances of intelligent cheating, particularly whenstudents utilize advanced generative AI tools to craft their responses. Thisstudy proposes a keystroke dynamics-based method to differentiate between bonafide and assisted writing within academic contexts. To facilitate this, adataset was developed to capture the keystroke patterns of individuals engagedin writing tasks, both with and without the assistance of generative AI. Thedetector, trained using a modified TypeNet architecture, achieved accuraciesranging from 74.98% to 85.72% in condition-specific scenarios and from 52.24%to 80.54% in condition-agnostic scenarios. The findings highlight significantdifferences in keystroke dynamics between genuine and assisted writing. Theoutcomes of this study enhance our understanding of how users interact withgenerative AI and have implications for improving the reliability of digitaleducational platforms.</description><author>Debnath Kundu, Atharva Mehta, Rajesh Kumar, Naman Lal, Avinash Anand, Apoorv Singh, Rajiv Ratn Shah</author><pubDate>Fri, 21 Jun 2024 18:51:26 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.15335v1</guid></item><item><title>Multimodal Task Vectors Enable Many-Shot Multimodal In-Context Learning</title><link>http://arxiv.org/abs/2406.15334v1</link><description>The recent success of interleaved Large Multimodal Models (LMMs) in few-shotlearning suggests that in-context learning (ICL) with many examples can bepromising for learning new tasks. However, this many-shot multimodal ICLsetting has one crucial problem: it is fundamentally limited by the model'scontext length set at pretraining. The problem is especially prominent in themultimodal domain, which processes both text and images, requiring additionaltokens. This motivates the need for a multimodal method to compress many shotsinto fewer tokens without finetuning. In this work, we enable LMMs to performmultimodal, many-shot in-context learning by leveraging Multimodal Task Vectors(MTV)--compact implicit representations of in-context examples compressed inthe model's attention heads. Specifically, we first demonstrate the existenceof such MTV in LMMs and then leverage these extracted MTV to enable many-shotin-context learning for various vision-and-language tasks. Our experimentssuggest that MTV can scale in performance with the number of compressed shotsand generalize to similar out-of-domain tasks without additional context lengthfor inference.</description><author>Brandon Huang, Chancharik Mitra, Assaf Arbelle, Leonid Karlinsky, Trevor Darrell, Roei Herzig</author><pubDate>Fri, 21 Jun 2024 18:50:02 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.15334v1</guid></item><item><title>GeoLRM: Geometry-Aware Large Reconstruction Model for High-Quality 3D Gaussian Generation</title><link>http://arxiv.org/abs/2406.15333v1</link><description>In this work, we introduce the Geometry-Aware Large Reconstruction Model(GeoLRM), an approach which can predict high-quality assets with 512k Gaussiansand 21 input images in only 11 GB GPU memory. Previous works neglect theinherent sparsity of 3D structure and do not utilize explicit geometricrelationships between 3D and 2D images. This limits these methods to alow-resolution representation and makes it difficult to scale up to the denseviews for better quality. GeoLRM tackles these issues by incorporating a novel3D-aware transformer structure that directly processes 3D points and usesdeformable cross-attention mechanisms to effectively integrate image featuresinto 3D representations. We implement this solution through a two-stagepipeline: initially, a lightweight proposal network generates a sparse set of3D anchor points from the posed image inputs; subsequently, a specializedreconstruction transformer refines the geometry and retrieves textural details.Extensive experimental results demonstrate that GeoLRM significantlyoutperforms existing models, especially for dense view inputs. We alsodemonstrate the practical applicability of our model with 3D generation tasks,showcasing its versatility and potential for broader adoption in real-worldapplications.</description><author>Chubin Zhang, Hongliang Song, Yi Wei, Yu Chen, Jiwen Lu, Yansong Tang</author><pubDate>Fri, 21 Jun 2024 18:49:31 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.15333v1</guid></item><item><title>Masked Extended Attention for Zero-Shot Virtual Try-On In The Wild</title><link>http://arxiv.org/abs/2406.15331v1</link><description>Virtual Try-On (VTON) is a highly active line of research, with increasingdemand. It aims to replace a piece of garment in an image with one fromanother, while preserving person and garment characteristics as well as imagefidelity. Current literature takes a supervised approach for the task,impairing generalization and imposing heavy computation. In this paper, wepresent a novel zero-shot training-free method for inpainting a clothinggarment by reference. Our approach employs the prior of a diffusion model withno additional training, fully leveraging its native generalizationcapabilities. The method employs extended attention to transfer imageinformation from reference to target images, overcoming two significantchallenges. We first initially warp the reference garment over the target humanusing deep features, alleviating "texture sticking". We then leverage theextended attention mechanism with careful masking, eliminating leakage ofreference background and unwanted influence. Through a user study, qualitative,and quantitative comparison to state-of-the-art approaches, we demonstratesuperior image quality and garment preservation compared unseen clothing piecesor human figures.</description><author>Nadav Orzech, Yotam Nitzan, Ulysse Mizrahi, Dov Danon, Amit H. Bermano</author><pubDate>Fri, 21 Jun 2024 18:45:37 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.15331v1</guid></item><item><title>Gradient-Mask Tuning Elevates the Upper Limits of LLM Performance</title><link>http://arxiv.org/abs/2406.15330v1</link><description>Large language models (LLMs) have revolutionized lots of fields of research.Although it is well-known that fine-tuning is essential for enhancing thecapabilities of LLMs, existing research suggests that there is potentialredundancy in the fine-tuning process and therefore proposes to update only asubset of parameters. However, these methods fail to leverage the task-specificinformation to identify important parameters during training. Based on theinsight that gradients inherently contain information on task-specific data, wepropose Gradient-Mask Tuning (GMT), a method that selectively updatesparameters during training based on their gradient information. Specifically,we compute the absolute values of the gradients and apply masking to those withrelatively smaller magnitudes. Our empirical results across various tasksdemonstrate that GMT not only outperforms traditional fine-tuning methods butalso elevates the upper limits of LLM performance. Further analysis indicatesthat GMT exhibits insensitivity to mask ratio and possesses computationalefficiency comparable to vanilla SFT.</description><author>Haoling Li, Xin Zhang, Xiao Liu, Yeyun Gong, Yifan Wang, Yujiu Yang, Qi Chen, Peng Cheng</author><pubDate>Fri, 21 Jun 2024 18:42:52 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.15330v1</guid></item><item><title>An End-to-End, Segmentation-Free, Arabic Handwritten Recognition Model on KHATT</title><link>http://arxiv.org/abs/2406.15329v1</link><description>An end-to-end, segmentation-free, deep learning model trained from scratch isproposed, leveraging DCNN for feature extraction, alongside BidirectionalLong-Short Term Memory (BLSTM) for sequence recognition and ConnectionistTemporal Classification (CTC) loss function on the KHATT database. The trainingphase yields remarkable results 84% recognition rate on the test dataset at thecharacter level and 71% on the word level, establishing an image-based sequencerecognition framework that operates without segmentation only at the linelevel. The analysis and preprocessing of the KFUPM Handwritten Arabic TexT(KHATT) database are also presented. Finally, advanced image processingtechniques, including filtering, transformation, and line segmentation areimplemented. The importance of this work is highlighted by its wide-rangingapplications. Including digitizing, documentation, archiving, and texttranslation in fields such as banking. Moreover, AHR serves as a pivotal toolfor making images searchable, enhancing information retrieval capabilities, andenabling effortless editing. This functionality significantly reduces the timeand effort required for tasks such as Arabic data organization andmanipulation.</description><author>Sondos Aabed, Ahmad Khairaldin</author><pubDate>Fri, 21 Jun 2024 18:42:07 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.15329v1</guid></item><item><title>Fine-grained Attention in Hierarchical Transformers for Tabular Time-series</title><link>http://arxiv.org/abs/2406.15327v1</link><description>Tabular data is ubiquitous in many real-life systems. In particular,time-dependent tabular data, where rows are chronologically related, istypically used for recording historical events, e.g., financial transactions,healthcare records, or stock history. Recently, hierarchical variants of theattention mechanism of transformer architectures have been used to modeltabular time-series data. At first, rows (or columns) are encoded separately bycomputing attention between their fields. Subsequently, encoded rows (orcolumns) are attended to one another to model the entire tabular time-series.While efficient, this approach constrains the attention granularity and limitsits ability to learn patterns at the field-level across separate rows, orcolumns. We take a first step to address this gap by proposing Fieldy, afine-grained hierarchical model that contextualizes fields at both the row andcolumn levels. We compare our proposal against state of the art models onregression and classification tasks using public tabular time-series datasets.Our results show that combining row-wise and column-wise attention improvesperformance without increasing model size. Code and data are available athttps://github.com/raphaaal/fieldy.</description><author>Raphael Azorin, Zied Ben Houidi, Massimo Gallo, Alessandro Finamore, Pietro Michiardi</author><pubDate>Fri, 21 Jun 2024 18:40:46 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.15327v1</guid></item><item><title>Bug In the Code Stack: Can LLMs Find Bugs in Large Python Code Stacks</title><link>http://arxiv.org/abs/2406.15325v1</link><description>Recent research in Needle-in-a-Haystack (NIAH) benchmarks has explored thecapabilities of Large Language Models (LLMs) in retrieving contextualinformation from large text documents. However, as LLMs become increasinglyintegrated into software development processes, it is crucial to evaluate theirperformance in code-based environments. As LLMs are further developed forprogram synthesis, we need to ensure that LLMs can understand syntax and writesyntactically correct code. As a step in ensuring LLMs understand syntax, LLMscan be evaluated in their ability to find and detect syntax bugs. Ourbenchmark, Bug In The Code Stack (BICS), is designed to assess the ability ofLLMs to identify simple syntax bugs within large source code. Our findingsreveal three key insights: (1) code-based environments pose significantly morechallenge compared to text-based environments for retrieval tasks, (2) there isa substantial performance disparity among different models, and (3) there is anotable correlation between longer context lengths and performance degradation,though the extent of this degradation varies between models.</description><author>Hokyung Lee, Sumanyu Sharma, Bing Hu</author><pubDate>Fri, 21 Jun 2024 18:37:10 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.15325v1</guid></item><item><title>Large Reasoning Models for 3D Floorplanning in EDA: Learning from Imperfections</title><link>http://arxiv.org/abs/2406.10538v2</link><description>In this paper, we introduce Dreamweaver, which belongs to a new class ofauto-regressive decision-making models known as large reasoning models (LRMs).Dreamweaver is designed to improve 3D floorplanning in electronic designautomation (EDA) via an architecture that melds advancements insequence-to-sequence reinforcement learning algorithms. A significant advantageof our approach is its ability to effectively reason over large discrete actionspaces, which is essential for handling the numerous potential positions forvarious functional blocks in floorplanning. Additionally, Dreamweaverdemonstrates strong performance even when trained on entirely randomtrajectories, showcasing its capacity to leverage sub-optimal or non-experttrajectories to enhance its results. This innovative approach contributes tostreamlining the integrated circuit (IC) design flow and reducing the highcomputational costs typically associated with floorplanning. We evaluate itsperformance against a current state-of-the-art method, highlighting notableimprovements.</description><author>Fin Amin, Nirjhor Rouf, Tse-Han Pan, Md Kamal Ibn Shafi, Paul D. Franzon</author><pubDate>Fri, 21 Jun 2024 18:36:12 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.10538v2</guid></item><item><title>Large language models surpass human experts in predicting neuroscience results</title><link>http://arxiv.org/abs/2403.03230v3</link><description>Scientific discoveries often hinge on synthesizing decades of research, atask that potentially outstrips human information processing capacities. Largelanguage models (LLMs) offer a solution. LLMs trained on the vast scientificliterature could potentially integrate noisy yet interrelated findings toforecast novel results better than human experts. To evaluate this possibility,we created BrainBench, a forward-looking benchmark for predicting neuroscienceresults. We find that LLMs surpass experts in predicting experimental outcomes.BrainGPT, an LLM we tuned on the neuroscience literature, performed better yet.Like human experts, when LLMs were confident in their predictions, they weremore likely to be correct, which presages a future where humans and LLMs teamtogether to make discoveries. Our approach is not neuroscience-specific and istransferable to other knowledge-intensive endeavors.</description><author>Xiaoliang Luo, Akilles Rechardt, Guangzhi Sun, Kevin K. Nejad, Felipe Yáñez, Bati Yilmaz, Kangjoo Lee, Alexandra O. Cohen, Valentina Borghesani, Anton Pashkov, Daniele Marinazzo, Jonathan Nicholas, Alessandro Salatiello, Ilia Sucholutsky, Pasquale Minervini, Sepehr Razavi, Roberta Rocca, Elkhan Yusifov, Tereza Okalova, Nianlong Gu, Martin Ferianc, Mikail Khona, Kaustubh R. Patil, Pui-Shee Lee, Rui Mata, Nicholas E. Myers, Jennifer K Bizley, Sebastian Musslick, Isil Poyraz Bilgin, Guiomar Niso, Justin M. Ales, Michael Gaebler, N Apurva Ratan Murty, Leyla Loued-Khenissi, Anna Behler, Chloe M. Hall, Jessica Dafflon, Sherry Dongqi Bao, Bradley C. Love</author><pubDate>Fri, 21 Jun 2024 18:35:46 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.03230v3</guid></item><item><title>MTUncertainty: Assessing the Need for Post-editing of Machine Translation Outputs by Fine-tuning OpenAI LLMs</title><link>http://arxiv.org/abs/2308.00158v6</link><description>Translation Quality Evaluation (TQE) is an essential step of the moderntranslation production process. TQE is critical in assessing both machinetranslation (MT) and human translation (HT) quality without referencetranslations. The ability to evaluate or even simply estimate the quality oftranslation automatically may open significant efficiency gains through processoptimisation. This work examines whether the state-of-the-art large languagemodels (LLMs) can be used for this purpose. We take OpenAI models as the beststate-of-the-art technology and approach TQE as a binary classification task.On eight language pairs including English to Italian, German, French, Japanese,Dutch, Portuguese, Turkish, and Chinese, our experimental results show thatfine-tuned gpt3.5 can demonstrate good performance on translation qualityprediction tasks, i.e. whether the translation needs to be edited. Anotherfinding is that simply increasing the sizes of LLMs does not lead to apparentbetter performances on this task by comparing the performance of threedifferent versions of OpenAI models: curie, davinci, and gpt3.5 with 13B, 175B,and 175B parameters, respectively.</description><author>Serge Gladkoff, Lifeng Han, Gleb Erofeev, Irina Sorokina, Goran Nenadic</author><pubDate>Fri, 21 Jun 2024 18:34:47 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2308.00158v6</guid></item><item><title>AGLA: Mitigating Object Hallucinations in Large Vision-Language Models with Assembly of Global and Local Attention</title><link>http://arxiv.org/abs/2406.12718v2</link><description>Despite their great success across various multimodal tasks, LargeVision-Language Models (LVLMs) are facing a prevalent problem with objecthallucinations, where the generated textual responses are inconsistent withground-truth objects in the given image. This paper investigates various LVLMsand pinpoints attention deficiency toward discriminative local image featuresas one root cause of object hallucinations. Specifically, LVLMs predominantlyattend to prompt-independent global image features, while failing to captureprompt-relevant local features, consequently undermining the visual groundingcapacity of LVLMs and leading to hallucinations. To this end, we proposeAssembly of Global and Local Attention (AGLA), a training-free andplug-and-play approach that mitigates object hallucinations by exploring anensemble of global features for response generation and local features forvisual discrimination simultaneously. Our approach exhibits an image-promptmatching scheme that captures prompt-relevant local features from images,leading to an augmented view of the input image where prompt-relevant contentis reserved while irrelevant distractions are masked. With the augmented view,a calibrated decoding distribution can be derived by integrating generativeglobal features from the original image and discriminative local features fromthe augmented image. Extensive experiments show that AGLA consistentlymitigates object hallucinations and enhances general perception capability forLVLMs across various discriminative and generative benchmarks. Our code will bereleased at https://github.com/Lackel/AGLA.</description><author>Wenbin An, Feng Tian, Sicong Leng, Jiahao Nie, Haonan Lin, QianYing Wang, Guang Dai, Ping Chen, Shijian Lu</author><pubDate>Fri, 21 Jun 2024 18:33:21 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.12718v2</guid></item><item><title>Rethinking Remote Sensing Change Detection With A Mask View</title><link>http://arxiv.org/abs/2406.15320v1</link><description>Remote sensing change detection aims to compare two or more images recordedfor the same area but taken at different time stamps to quantitatively andqualitatively assess changes in geographical entities and environmentalfactors. Mainstream models usually built on pixel-by-pixel change detectionparadigms, which cannot tolerate the diversity of changes due to complex scenesand variation in imaging conditions. To address this shortcoming, this paperrethinks the change detection with the mask view, and further proposes thecorresponding: 1) meta-architecture CDMask and 2) instance networkCDMaskFormer. Components of CDMask include Siamese backbone, change extractor,pixel decoder, transformer decoder and normalized detector, which ensures theproper functioning of the mask detection paradigm. Since the change query canbe adaptively updated based on the bi-temporal feature content, the proposedCDMask can adapt to different latent data distributions, thus accuratelyidentifying regions of interest changes in complex scenarios. Consequently, wefurther propose the instance network CDMaskFormer customized for the changedetection task, which includes: (i) a Spatial-temporal convolutionalattention-based instantiated change extractor to capture spatio-temporalcontext simultaneously with lightweight operations; and (ii) a scene-guidedaxial attention-instantiated transformer decoder to extract more spatialdetails. State-of-the-art performance of CDMaskFormer is achieved on fivebenchmark datasets with a satisfactory efficiency-accuracy trade-off. Code isavailable at https://github.com/xwmaxwma/rschange.</description><author>Xiaowen Ma, Zhenkai Wu, Rongrong Lian, Wei Zhang, Siyang Song</author><pubDate>Fri, 21 Jun 2024 18:27:58 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.15320v1</guid></item><item><title>Testing Calibration in Nearly-Linear Time</title><link>http://arxiv.org/abs/2402.13187v2</link><description>In the recent literature on machine learning and decision making, calibrationhas emerged as a desirable and widely-studied statistical property of theoutputs of binary prediction models. However, the algorithmic aspects ofmeasuring model calibration have remained relatively less well-explored.Motivated by [BGHN23], which proposed a rigorous framework for measuringdistances to calibration, we initiate the algorithmic study of calibrationthrough the lens of property testing. We define the problem of calibrationtesting from samples where given $n$ draws from a distribution $\mathcal{D}$ on$(predictions, binary outcomes)$, our goal is to distinguish between the casewhere $\mathcal{D}$ is perfectly calibrated, and the case where $\mathcal{D}$is $\varepsilon$-far from calibration. We make the simple observation that the empirical smooth calibration linearprogram can be reformulated as an instance of minimum-cost flow on ahighly-structured graph, and design an exact dynamic programming-based solverfor it which runs in time $O(n\log^2(n))$, and solves the calibration testingproblem information-theoretically optimally in the same time. This improvesupon state-of-the-art black-box linear program solvers requiring$\Omega(n^\omega)$ time, where $\omega &gt; 2$ is the exponent of matrixmultiplication. We also develop algorithms for tolerant variants of our testingproblem improving upon black-box linear program solvers, and give samplecomplexity lower bounds for alternative calibration measures to the oneconsidered in this work. Finally, we present experiments showing the testingproblem we define faithfully captures standard notions of calibration, and thatour algorithms scale efficiently to accommodate large sample sizes.</description><author>Lunjia Hu, Arun Jambulapati, Kevin Tian, Chutong Yang</author><pubDate>Fri, 21 Jun 2024 18:27:22 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.13187v2</guid></item><item><title>LongRAG: Enhancing Retrieval-Augmented Generation with Long-context LLMs</title><link>http://arxiv.org/abs/2406.15319v1</link><description>In traditional RAG framework, the basic retrieval units are normally short.The common retrievers like DPR normally work with 100-word Wikipediaparagraphs. Such a design forces the retriever to search over a large corpus tofind the `needle' unit. In contrast, the readers only need to extract answersfrom the short retrieved units. Such an imbalanced `heavy' retriever and`light' reader design can lead to sub-optimal performance. In order toalleviate the imbalance, we propose a new framework LongRAG, consisting of a`long retriever' and a `long reader'. LongRAG processes the entire Wikipediainto 4K-token units, which is 30x longer than before. By increasing the unitsize, we significantly reduce the total units from 22M to 700K. Thissignificantly lowers the burden of retriever, which leads to a remarkableretrieval score: answer recall@1=71% on NQ (previously 52%) and answerrecall@2=72% (previously 47%) on HotpotQA (full-wiki). Then we feed the top-kretrieved units ($\approx$ 30K tokens) to an existing long-context LLM toperform zero-shot answer extraction. Without requiring any training, LongRAGachieves an EM of 62.7% on NQ, which is the best known result. LongRAG alsoachieves 64.3% on HotpotQA (full-wiki), which is on par of the SoTA model. Ourstudy offers insights into the future roadmap for combining RAG withlong-context LLMs.</description><author>Ziyan Jiang, Xueguang Ma, Wenhu Chen</author><pubDate>Fri, 21 Jun 2024 18:23:21 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.15319v1</guid></item><item><title>Unfolding ADMM for Enhanced Subspace Clustering of Hyperspectral Images</title><link>http://arxiv.org/abs/2404.07112v3</link><description>Deep subspace clustering methods are now prominent in clustering, typicallyusing fully connected networks and a self-representation loss function.However, these methods often struggle with overfitting and lackinterpretability. In this paper, we explore an alternative clustering approachbased on deep unfolding. By unfolding iterative optimization methods intoneural networks, this approach offers enhanced interpretability and reliabilitycompared to data-driven deep learning methods, and greater adaptability andgeneralization than model-based approaches. Hence, unfolding has become widelyused in inverse imaging problems, such as image restoration, reconstruction,and super-resolution, but has not been sufficiently explored yet in the contextof clustering. In this work, we introduce an innovative clustering architecturefor hyperspectral images (HSI) by unfolding an iterative solver based on theAlternating Direction Method of Multipliers (ADMM) for sparse subspaceclustering. To our knowledge, this is the first attempt to apply unfolding ADMMfor computing the self-representation matrix in subspace clustering. Moreover,our approach captures well the structural characteristics of HSI data byemploying the K nearest neighbors algorithm as part of a structure preservationmodule. Experimental evaluation of three established HSI datasets shows clearlythe potential of the unfolding approach in HSI clustering and even demonstratessuperior performance compared to state-of-the-art techniques.</description><author>Xianlu Li, Nicolas Nadisic, Shaoguang Huang, Aleksandra Pižurica</author><pubDate>Fri, 21 Jun 2024 18:14:19 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.07112v3</guid></item><item><title>Getting Serious about Humor: Crafting Humor Datasets with Unfunny Large Language Models</title><link>http://arxiv.org/abs/2403.00794v2</link><description>Humor is a fundamental facet of human cognition and interaction. Yet, despiterecent advances in natural language processing, humor detection remains achallenging task that is complicated by the scarcity of datasets that pairhumorous texts with similar non-humorous counterparts. In our work, weinvestigate whether large language models (LLMs), can generate synthetic datafor humor detection via editing texts. We benchmark LLMs on an existing humandataset and show that current LLMs display an impressive ability to 'unfun'jokes, as judged by humans and as measured on the downstream task of humordetection. We extend our approach to a code-mixed English-Hindi humor dataset,where we find that GPT-4's synthetic data is highly rated by bilingualannotators and provides challenging adversarial examples for humor classifiers.</description><author>Zachary Horvitz, Jingru Chen, Rahul Aditya, Harshvardhan Srivastava, Robert West, Zhou Yu, Kathleen McKeown</author><pubDate>Fri, 21 Jun 2024 18:12:35 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.00794v2</guid></item><item><title>Impact of Decentralized Learning on Player Utilities in Stackelberg Games</title><link>http://arxiv.org/abs/2403.00188v2</link><description>When deployed in the world, a learning agent such as a recommender system ora chatbot often repeatedly interacts with another learning agent (such as auser) over time. In many such two-agent systems, each agent learns separatelyand the rewards of the two agents are not perfectly aligned. To betterunderstand such cases, we examine the learning dynamics of the two-agent systemand the implications for each agent's objective. We model these systems asStackelberg games with decentralized learning and show that standard regretbenchmarks (such as Stackelberg equilibrium payoffs) result in worst-caselinear regret for at least one player. To better capture these systems, weconstruct a relaxed regret benchmark that is tolerant to small learning errorsby agents. We show that standard learning algorithms fail to provide sublinearregret, and we develop algorithms to achieve near-optimal $O(T^{2/3})$ regretfor both players with respect to these benchmarks. We further design relaxedenvironments under which faster learning ($O(\sqrt{T})$) is possible.Altogether, our results take a step towards assessing how two-agentinteractions in sequential and decentralized learning environments affect theutility of both agents.</description><author>Kate Donahue, Nicole Immorlica, Meena Jagadeesan, Brendan Lucier, Aleksandrs Slivkins</author><pubDate>Fri, 21 Jun 2024 18:11:10 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.00188v2</guid></item><item><title>STARD: A Chinese Statute Retrieval Dataset with Real Queries Issued by Non-professionals</title><link>http://arxiv.org/abs/2406.15313v1</link><description>Statute retrieval aims to find relevant statutory articles for specificqueries. This process is the basis of a wide range of legal applications suchas legal advice, automated judicial decisions, legal document drafting, etc.Existing statute retrieval benchmarks focus on formal and professional queriesfrom sources like bar exams and legal case documents, thereby neglectingnon-professional queries from the general public, which often lack preciselegal terminology and references. To address this gap, we introduce the STAtuteRetrieval Dataset (STARD), a Chinese dataset comprising 1,543 query casescollected from real-world legal consultations and 55,348 candidate statutoryarticles. Unlike existing statute retrieval datasets, which primarily focus onprofessional legal queries, STARD captures the complexity and diversity of realqueries from the general public. Through a comprehensive evaluation of variousretrieval baselines, we reveal that existing retrieval approaches all fallshort of these real queries issued by non-professional users. The best methodonly achieves a Recall@100 of 0.907, suggesting the necessity for furtherexploration and additional research in this area. All the codes and datasets are available at:https://github.com/oneal2000/STARD/tree/main</description><author>Weihang Su, Yiran Hu, Anzhe Xie, Qingyao Ai, Zibing Que, Ning Zheng, Yun Liu, Weixing Shen, Yiqun Liu</author><pubDate>Fri, 21 Jun 2024 18:10:09 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.15313v1</guid></item><item><title>DASB -- Discrete Audio and Speech Benchmark</title><link>http://arxiv.org/abs/2406.14294v2</link><description>Discrete audio tokens have recently gained considerable attention for theirpotential to connect audio and language processing, enabling the creation ofmodern multimodal large language models. Ideal audio tokens must effectivelypreserve phonetic and semantic content along with paralinguistic information,speaker identity, and other details. While several types of audio tokens havebeen recently proposed, identifying the optimal tokenizer for various tasks ischallenging due to the inconsistent evaluation settings in existing studies. Toaddress this gap, we release the Discrete Audio and Speech Benchmark (DASB), acomprehensive leaderboard for benchmarking discrete audio tokens across a widerange of discriminative tasks, including speech recognition, speakeridentification and verification, emotion recognition, keyword spotting, andintent classification, as well as generative tasks such as speech enhancement,separation, and text-to-speech. Our results show that, on average, semantictokens outperform compression tokens across most discriminative and generativetasks. However, the performance gap between semantic tokens and standardcontinuous representations remains substantial, highlighting the need forfurther research in this field.</description><author>Pooneh Mousavi, Luca Della Libera, Jarod Duret, Artem Ploujnikov, Cem Subakan, Mirco Ravanelli</author><pubDate>Fri, 21 Jun 2024 18:07:17 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.14294v2</guid></item><item><title>Offline Diversity Maximization Under Imitation Constraints</title><link>http://arxiv.org/abs/2307.11373v3</link><description>There has been significant recent progress in the area of unsupervised skilldiscovery, utilizing various information-theoretic objectives as measures ofdiversity. Despite these advances, challenges remain: current methods requiresignificant online interaction, fail to leverage vast amounts of availabletask-agnostic data and typically lack a quantitative measure of skill utility.We address these challenges by proposing a principled offline algorithm forunsupervised skill discovery that, in addition to maximizing diversity, ensuresthat each learned skill imitates state-only expert demonstrations to a certaindegree. Our main analytical contribution is to connect Fenchel duality,reinforcement learning, and unsupervised skill discovery to maximize a mutualinformation objective subject to KL-divergence state occupancy constraints.Furthermore, we demonstrate the effectiveness of our method on the standardoffline benchmark D4RL and on a custom offline dataset collected from a 12-DoFquadruped robot for which the policies trained in simulation transfer well tothe real robotic system.</description><author>Marin Vlastelica, Jin Cheng, Georg Martius, Pavel Kolev</author><pubDate>Fri, 21 Jun 2024 17:59:57 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.11373v3</guid></item><item><title>The Normal Distributions Indistinguishability Spectrum and its Application to Privacy-Preserving Machine Learning</title><link>http://arxiv.org/abs/2309.01243v3</link><description>Differential Privacy (DP) (and its variants) is the most common method formachine learning (ML) on privacy-sensitive data. In big data analytics, oneoften uses randomized sketching/aggregation algorithms to make processinghigh-dimensional data tractable. Intuitively, such ML algorithms should providesome inherent privacy, yet most existing DP mechanisms do not leverage orunder-utilize this inherent randomness, resulting in potentially redundantnoising. The motivating question of our work is: (How) can we improve theutility of DP mechanisms for randomized ML queries, by leveraging therandomness of the query itself? Towards a (positive) answer, our key contribution is (proving) what we callthe NDIS theorem, a theoretical result with several practical implications. Ina nutshell, NDIS is a closed-form analytic computation for the(varepsilon,delta)-indistinguishability-spectrum (IS) of two arbitrary normaldistributions N1 and N2, i.e., the optimal delta (for any given varepsilon)such that N1 and N2 are (varepsilon,delta)-close according to the DP distance.The importance of the NDIS theorem lies in that (1) it yields efficientestimators for IS, and (2) it allows us to analyze DP-mechanism withnormally-distributed outputs, as well as more general mechanisms by leveragingtheir behavior on large inputs. We apply the NDIS theorem to derive DPmechanisms for queries with normally-distributed outputs--i.e., Gaussian RandomProjections (RP)--and for more general queries--i.e., Ordinary Least Squares(OLS). Compared to existing techniques, our new DP mechanisms achieve superiorprivacy/utility trade-offs by leveraging the randomness of the underlyingalgorithms. We then apply the NDIS theorem to a data-driven DP notion--inparticular relative DP introduced by Lu et al. [S&amp;P 2024]. Our methodidentifies the range of (varepsilon,delta) for which no additional noising isneeded.</description><author>Yun Lu, Malik Magdon-Ismail, Yu Wei, Vassilis Zikas</author><pubDate>Fri, 21 Jun 2024 17:54:57 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2309.01243v3</guid></item><item><title>CREATOR: Tool Creation for Disentangling Abstract and Concrete Reasoning of Large Language Models</title><link>http://arxiv.org/abs/2305.14318v3</link><description>Large Language Models (LLMs) have made significant progress in utilizingtools, but their ability is limited by API availability and the instability ofimplicit reasoning, particularly when both planning and execution are involved.To overcome these limitations, we propose CREATOR, a novel framework thatenables LLMs to create their own tools using documentation and coderealization. CREATOR disentangles abstract tool creation and concrete decisionexecution, resulting in improved performance. We evaluate CREATOR on MATH andTabMWP benchmarks, respectively consisting of challenging math competitionproblems and diverse tabular contents. Remarkably, CREATOR outperforms existingchain-of-thought, program-of-thought, and tool-using baselines. Additionally,we introduce the Creation Challenge dataset, featuring 2K diverse questions, toemphasize the necessity and benefits of LLMs' tool creation ability. Furtherresearch demonstrates that leveraging LLMs as tool creators facilitatesknowledge transfer, and LLMs exhibit varying levels of tool creation abilities,enabling them to adapt to diverse situations. The tool creation abilityrevolutionizes the LLM's problem-solving paradigm, driving us closer to thenext frontier of artificial intelligence. All the codes and data are released.</description><author>Cheng Qian, Chi Han, Yi R. Fung, Yujia Qin, Zhiyuan Liu, Heng Ji</author><pubDate>Fri, 21 Jun 2024 17:51:22 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.14318v3</guid></item><item><title>DUAL-REFLECT: Enhancing Large Language Models for Reflective Translation through Dual Learning Feedback Mechanisms</title><link>http://arxiv.org/abs/2406.07232v2</link><description>Recently, large language models (LLMs) enhanced by self-reflection haveachieved promising performance on machine translation. The key idea is guidingLLMs to generate translation with human-like feedback. However, existingself-reflection methods lack effective feedback information, limiting thetranslation performance. To address this, we introduce a DUAL-REFLECTframework, leveraging the dual learning of translation tasks to provideeffective feedback, thereby enhancing the models' self-reflective abilities andimproving translation performance. The application of this method acrossvarious translation tasks has proven its effectiveness in improving translationaccuracy and eliminating ambiguities, especially in translation tasks withlow-resource language pairs.</description><author>Andong Chen, Lianzhang Lou, Kehai Chen, Xuefeng Bai, Yang Xiang, Muyun Yang, Tiejun Zhao, Min Zhang</author><pubDate>Fri, 21 Jun 2024 17:49:33 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.07232v2</guid></item><item><title>Deep hybrid models: infer and plan in the real world</title><link>http://arxiv.org/abs/2402.10088v2</link><description>Determining an optimal plan to accomplish a goal is a hard problem inrealistic scenarios, which often comprise dynamic and causal relationshipsbetween several entities. Although traditionally such problems have beentackled with optimal control and reinforcement learning, a recentbiologically-motivated proposal casts planning and control as an inferenceprocess. Among these new approaches, one is particularly promising: activeinference. This new paradigm assumes that action and perception are twocomplementary aspects of life whereby the role of the former is to fulfill thepredictions inferred by the latter. In this study, we present an effectivesolution, based on active inference, to complex control tasks. The proposedarchitecture exploits hybrid (discrete and continuous) processing to constructa hierarchical and dynamic representation of the self and the environment,which is then used to produce a flexible plan consisting of subgoals atdifferent temporal scales. We evaluate this deep hybrid model on a non-trivialtask: reaching a moving object after having picked a moving tool. This studyextends past work on planning as inference and advances an alternativedirection to optimal control and reinforcement learning.</description><author>Matteo Priorelli, Ivilin Peev Stoianov</author><pubDate>Fri, 21 Jun 2024 17:46:55 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.10088v2</guid></item><item><title>Directly Fine-Tuning Diffusion Models on Differentiable Rewards</title><link>http://arxiv.org/abs/2309.17400v2</link><description>We present Direct Reward Fine-Tuning (DRaFT), a simple and effective methodfor fine-tuning diffusion models to maximize differentiable reward functions,such as scores from human preference models. We first show that it is possibleto backpropagate the reward function gradient through the full samplingprocedure, and that doing so achieves strong performance on a variety ofrewards, outperforming reinforcement learning-based approaches. We then proposemore efficient variants of DRaFT: DRaFT-K, which truncates backpropagation toonly the last K steps of sampling, and DRaFT-LV, which obtains lower-variancegradient estimates for the case when K=1. We show that our methods work wellfor a variety of reward functions and can be used to substantially improve theaesthetic quality of images generated by Stable Diffusion 1.4. Finally, we drawconnections between our approach and prior work, providing a unifyingperspective on the design space of gradient-based fine-tuning algorithms.</description><author>Kevin Clark, Paul Vicol, Kevin Swersky, David J Fleet</author><pubDate>Fri, 21 Jun 2024 17:45:11 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2309.17400v2</guid></item><item><title>Learning Spatio-Temporal Patterns of Polar Ice Layers With Physics-Informed Graph Neural Network</title><link>http://arxiv.org/abs/2406.15299v1</link><description>Learning spatio-temporal patterns of polar ice layers is crucial formonitoring the change in ice sheet balance and evaluating ice dynamicprocesses. While a few researchers focus on learning ice layer patterns fromechogram images captured by airborne snow radar sensors via differentconvolutional neural networks, the noise in the echogram images proves to be amajor obstacle. Instead, we focus on geometric deep learning based on graphneural networks to learn the spatio-temporal patterns from thicknessinformation of shallow ice layers and make predictions for deep layers. In thispaper, we propose a physics-informed hybrid graph neural network that combinesthe GraphSAGE framework for graph feature learning with the long short-termmemory (LSTM) structure for learning temporal changes, and introducemeasurements of physical ice properties from Model Atmospheric Regional (MAR)weather model as physical node features. We found that our proposed network canconsistently outperform the current non-inductive or non-physical model inpredicting deep ice layer thickness.</description><author>Zesheng Liu, Maryam Rahnemoonfar</author><pubDate>Fri, 21 Jun 2024 17:41:02 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.15299v1</guid></item><item><title>NLP-KG: A System for Exploratory Search of Scientific Literature in Natural Language Processing</title><link>http://arxiv.org/abs/2406.15294v1</link><description>Scientific literature searches are often exploratory, whereby users are notyet familiar with a particular field or concept but are interested in learningmore about it. However, existing systems for scientific literature search aretypically tailored to keyword-based lookup searches, limiting the possibilitiesfor exploration. We propose NLP-KG, a feature-rich system designed to supportthe exploration of research literature in unfamiliar natural languageprocessing (NLP) fields. In addition to a semantic search, NLP-KG allows usersto easily find survey papers that provide a quick introduction to a field ofinterest. Further, a Fields of Study hierarchy graph enables users tofamiliarize themselves with a field and its related areas. Finally, a chatinterface allows users to ask questions about unfamiliar concepts or specificarticles in NLP and obtain answers grounded in knowledge retrieved fromscientific publications. Our system provides users with comprehensiveexploration possibilities, supporting them in investigating the relationshipsbetween different fields, understanding unfamiliar concepts in NLP, and findingrelevant research literature. Demo, video, and code are available at:https://github.com/NLP-Knowledge-Graph/NLP-KG-WebApp.</description><author>Tim Schopf, Florian Matthes</author><pubDate>Fri, 21 Jun 2024 17:38:22 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.15294v1</guid></item><item><title>Grants4Companies: Applying Declarative Methods for Recommending and Reasoning About Business Grants in the Austrian Public Administration (System Description)</title><link>http://arxiv.org/abs/2406.15293v1</link><description>We describe the methods and technologies underlying the applicationGrants4Companies. The application uses a logic-based expert system to display alist of business grants suitable for the logged-in business. To evaluatesuitability of the grants, formal representations of their conditions areevaluated against properties of the business, taken from the registers of theAustrian public administration. The logical language for the representations ofthe grant conditions is based on S-expressions. We further describe a Proof ofConcept implementation of reasoning over the formalised grant conditions. Theproof of concept is implemented in Common Lisp and interfaces with a reasoningengine implemented in Scryer Prolog. The application has recently gone live andis provided as part of the Business Service Portal by the Austrian FederalMinistry of Finance.</description><author>Björn Lellmann, Philipp Marek, Markus Triska</author><pubDate>Fri, 21 Jun 2024 17:38:02 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.15293v1</guid></item><item><title>Pessimistic asynchronous sampling in high-cost Bayesian optimization</title><link>http://arxiv.org/abs/2406.15291v1</link><description>Asynchronous Bayesian optimization is a recently implemented technique thatallows for parallel operation of experimental systems and disjointed workflows.Contrasting with serial Bayesian optimization which individually selectsexperiments one at a time after conducting a measurement for each experiment,asynchronous policies sequentially assign multiple experiments beforemeasurements can be taken and evaluate new measurements continuously as theyare made available. This technique allows for faster data generation andtherefore faster optimization of an experimental space. This work extends thecapabilities of asynchronous optimization methods beyond prior studies byevaluating four additional policies that incorporate pessimistic predictions inthe training data set. Combined with a conventional greedy policy, the fivetotal policies were evaluated in a simulated environment and benchmarked withserial sampling. Under some conditions and parameter space dimensionalities,the pessimistic asynchronous policy reached optimum experimental conditions insignificantly fewer experiments than equivalent serial policies and proved tobe less susceptible to convergence onto local optima at higher dimensions.Without accounting for the faster sampling rate, the pessimistic asynchronousalgorithm presented in this work could result in more efficient algorithmdriven optimization of high-cost experimental spaces. Accounting for samplingrate, the presented asynchronous algorithm could allow for faster optimizationin experimental spaces where multiple experiments can be run before results arecollected.</description><author>Amanda A. Volk, Kristofer G. Reyes, Jeffrey G. Ethier, Luke A. Baldwin</author><pubDate>Fri, 21 Jun 2024 17:35:27 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.15291v1</guid></item><item><title>The Greek podcast corpus: Competitive speech models for low-resourced languages with weakly supervised data</title><link>http://arxiv.org/abs/2406.15284v1</link><description>The development of speech technologies for languages with limited digitalrepresentation poses significant challenges, primarily due to the scarcity ofavailable data. This issue is exacerbated in the era of large, data-intensivemodels. Recent research has underscored the potential of leveraging weaksupervision to augment the pool of available data. In this study, we compile an800-hour corpus of Modern Greek from podcasts and employ Whisper large-v3 togenerate silver transcriptions. This corpus is utilized to fine-tune ourmodels, aiming to assess the efficacy of this approach in enhancing ASRperformance. Our analysis spans 16 distinct podcast domains, alongsideevaluations on established datasets for Modern Greek. The findings indicateconsistent WER improvements, correlating with increases in both data volume andmodel size. Our study confirms that assembling large, weakly supervised corporaserves as a cost-effective strategy for advancing speech technologies inunder-resourced languages.</description><author>Georgios Paraskevopoulos, Chara Tsoukala, Athanasios Katsamanis, Vassilis Katsouros</author><pubDate>Fri, 21 Jun 2024 17:28:47 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.15284v1</guid></item><item><title>FT-AED: Benchmark Dataset for Early Freeway Traffic Anomalous Event Detection</title><link>http://arxiv.org/abs/2406.15283v1</link><description>Early and accurate detection of anomalous events on the freeway, such asaccidents, can improve emergency response and clearance. However, existingdelays and errors in event identification and reporting make it a difficultproblem to solve. Current large-scale freeway traffic datasets are not designedfor anomaly detection and ignore these challenges. In this paper, we introducethe first large-scale lane-level freeway traffic dataset for anomaly detection.Our dataset consists of a month of weekday radar detection sensor datacollected in 4 lanes along an 18-mile stretch of Interstate 24 heading towardNashville, TN, comprising over 3.7 million sensor measurements. We also collectofficial crash reports from the Nashville Traffic Management Center andmanually label all other potential anomalies in the dataset. To show thepotential for our dataset to be used in future machine learning and trafficresearch, we benchmark numerous deep learning anomaly detection models on ourdataset. We find that unsupervised graph neural network autoencoders are apromising solution for this problem and that ignoring spatial relationshipsleads to decreased performance. We demonstrate that our methods can reducereporting delays by over 10 minutes on average while detecting 75% of crashes.Our dataset and all preprocessing code needed to get started are publiclyreleased at https://vu.edu/ft-aed/ to facilitate future research.</description><author>Austin Coursey, Junyi Ji, Marcos Quinones-Grueiro, William Barbour, Yuhang Zhang, Tyler Derr, Gautam Biswas</author><pubDate>Fri, 21 Jun 2024 17:27:17 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.15283v1</guid></item><item><title>Cross-Modality Safety Alignment</title><link>http://arxiv.org/abs/2406.15279v1</link><description>As Artificial General Intelligence (AGI) becomes increasingly integrated intovarious facets of human life, ensuring the safety and ethical alignment of suchsystems is paramount. Previous studies primarily focus on single-modalitythreats, which may not suffice given the integrated and complex nature ofcross-modality interactions. We introduce a novel safety alignment challengecalled Safe Inputs but Unsafe Output (SIUO) to evaluate cross-modality safetyalignment. Specifically, it considers cases where single modalities are safeindependently but could potentially lead to unsafe or unethical outputs whencombined. To empirically investigate this problem, we developed the SIUO, across-modality benchmark encompassing 9 critical safety domains, such asself-harm, illegal activities, and privacy violations. Our findings revealsubstantial safety vulnerabilities in both closed- and open-source LVLMs, suchas GPT-4V and LLaVA, underscoring the inadequacy of current models to reliablyinterpret and respond to complex, real-world scenarios.</description><author>Siyin Wang, Xingsong Ye, Qinyuan Cheng, Junwen Duan, Shimin Li, Jinlan Fu, Xipeng Qiu, Xuanjing Huang</author><pubDate>Fri, 21 Jun 2024 17:14:15 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.15279v1</guid></item><item><title>Cognitive Map for Language Models: Optimal Planning via Verbally Representing the World Model</title><link>http://arxiv.org/abs/2406.15275v1</link><description>Language models have demonstrated impressive capabilities across variousnatural language processing tasks, yet they struggle with planning tasksrequiring multi-step simulations. Inspired by human cognitive processes, thispaper investigates the optimal planning power of language models that canconstruct a cognitive map of a given environment. Our experiments demonstratethat cognitive map significantly enhances the performance of both optimal andreachable planning generation ability in the Gridworld path planning task. Weobserve that our method showcases two key characteristics similar to humancognition: \textbf{generalization of its planning ability to extrapolatedenvironments and rapid adaptation with limited training data.} We hope ourfindings in the Gridworld task provide insights into modeling human cognitiveprocesses in language models, potentially leading to the development of moreadvanced and robust systems that better resemble human cognition.</description><author>Doyoung Kim, Jongwon Lee, Jinho Park, Minjoon Seo</author><pubDate>Fri, 21 Jun 2024 17:10:05 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.15275v1</guid></item><item><title>Exponential Quantum Communication Advantage in Distributed Inference and Learning</title><link>http://arxiv.org/abs/2310.07136v2</link><description>Training and inference with large machine learning models that far exceed thememory capacity of individual devices necessitates the design of distributedarchitectures, forcing one to contend with communication constraints. Wepresent a framework for distributed computation over a quantum network in whichdata is encoded into specialized quantum states. We prove that for modelswithin this framework, inference and training using gradient descent can beperformed with exponentially less communication compared to their classicalanalogs, and with relatively modest overhead relative to standardgradient-based methods. We show that certain graph neural networks areparticularly amenable to implementation within this framework, and moreoverpresent empirical evidence that they perform well on standard benchmarks. Toour knowledge, this is the first example of exponential quantum advantage for ageneric class of machine learning problems that hold regardless of the dataencoding cost. Moreover, we show that models in this class can encode highlynonlinear features of their inputs, and their expressivity increasesexponentially with model depth. We also delineate the space of models for whichexponential communication advantages hold by showing that they cannot hold forlinear classification. Our results can be combined with natural privacyadvantages in the communicated quantum states that limit the amount ofinformation that can be extracted from them about the data and modelparameters. Taken as a whole, these findings form a promising foundation fordistributed machine learning over quantum networks.</description><author>Hagay Michaeli, Dar Gilboa, Daniel Soudry, Jarrod R. McClean</author><pubDate>Fri, 21 Jun 2024 17:10:03 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.07136v2</guid></item><item><title>You Only Acquire Sparse-channel (YOAS): A Unified Framework for Dense-channel EEG Generation</title><link>http://arxiv.org/abs/2406.15269v1</link><description>High-precision acquisition of dense-channel electroencephalogram (EEG)signals is often impeded by the costliness and lack of portability ofequipment. In contrast, generating dense-channel EEG signals effectively fromsparse channels shows promise and economic viability. However, sparse-channelEEG poses challenges such as reduced spatial resolution, information loss,signal mixing, and heightened susceptibility to noise and interference. Toaddress these challenges, we first theoretically formulate the dense-channelEEG generation problem as by optimizing a set of cross-channel EEG signalgeneration problems. Then, we propose the YOAS framework for generatingdense-channel data from sparse-channel EEG signals. The YOAS totally consistsof four sequential stages: Data Preparation, Data Preprocessing, Biased-EEGGeneration, and Synthetic EEG Generation. Data Preparation and Preprocessingcarefully consider the distribution of EEG electrodes and low signal-to-noiseratio problem of EEG signals. Biased-EEG Generation includes sub-modules ofBiasEEGGanFormer and BiasEEGDiffFormer, which facilitate long-term featureextraction with attention and generate signals by combining electrode positionalignment with diffusion model, respectively. Synthetic EEG Generationsynthesizes the final signals, employing a deduction paradigm for multi-channelEEG generation. Extensive experiments confirmed YOAS's feasibility, efficiency,and theoretical validity, even remarkably enhancing data discernibility. Thisbreakthrough in dense-channel EEG signal generation from sparse-channel dataopens new avenues for exploration in EEG signal processing and application.</description><author>Hongyu Chen, Weiming Zeng, Luhui Cai, Yueyang Li, Lei Wang, Jia Lu, Hongjie Yan, Wai Ting Siok, Nizhuan Wang</author><pubDate>Fri, 21 Jun 2024 17:04:14 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.15269v1</guid></item><item><title>Towards Robust Training Datasets for Machine Learning with Ontologies: A Case Study for Emergency Road Vehicle Detection</title><link>http://arxiv.org/abs/2406.15268v1</link><description>Countless domains rely on Machine Learning (ML) models, includingsafety-critical domains, such as autonomous driving, which this paper focuseson. While the black box nature of ML is simply a nuisance in some domains, insafety-critical domains, this makes ML models difficult to trust. To fullyutilize ML models in safety-critical domains, it would be beneficial to have amethod to improve trust in model robustness and accuracy without human expertschecking each decision. This research proposes a method to increase trust in MLmodels used in safety-critical domains by ensuring the robustness andcompleteness of the model's training dataset. Because ML models embody whatthey are trained with, ensuring the completeness of training datasets can helpto increase the trust in the training of ML models. To this end, this paperproposes the use of a domain ontology and an image quality characteristicontology to validate the domain completeness and image quality robustness of atraining dataset. This research also presents an experiment as a proof ofconcept for this method, where ontologies are built for the emergency roadvehicle domain.</description><author>Lynn Vonderhaar, Timothy Elvira, Tyler Procko, Omar Ochoa</author><pubDate>Fri, 21 Jun 2024 17:03:38 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.15268v1</guid></item><item><title>Evaluating Diversity in Automatic Poetry Generation</title><link>http://arxiv.org/abs/2406.15267v1</link><description>Natural Language Generation (NLG), and more generally generative AI, areamong the currently most impactful research fields. Creative NLG, such asautomatic poetry generation, is a fascinating niche in this area. While mostprevious research has focused on forms of the Turing test when evaluatingautomatic poetry generation - can humans distinguish between automatic andhuman generated poetry - we evaluate the diversity of automatically generatedpoetry, by comparing distributions of generated poetry to distributions ofhuman poetry along structural, lexical, semantic and stylistic dimensions,assessing different model types (word vs. character-level, general purpose LLMsvs. poetry-specific models), including the very recent LLaMA3, and types offine-tuning (conditioned vs. unconditioned). We find that current automaticpoetry systems are considerably underdiverse along multiple dimensions - theyoften do not rhyme sufficiently, are semantically too uniform and even do notmatch the length distribution of human poetry. Our experiments reveal, however,that style-conditioning and character-level modeling clearly increasesdiversity across virtually all dimensions we explore. Our identifiedlimitations may serve as the basis for more genuinely diverse future poetrygeneration models.</description><author>Yanran Chen, Hannes Gröner, Sina Zarrieß, Steffen Eger</author><pubDate>Fri, 21 Jun 2024 17:03:21 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.15267v1</guid></item><item><title>Perception of Phonological Assimilation by Neural Speech Recognition Models</title><link>http://arxiv.org/abs/2406.15265v1</link><description>Human listeners effortlessly compensate for phonological changes duringspeech perception, often unconsciously inferring the intended sounds. Forexample, listeners infer the underlying /n/ when hearing an utterance such as"clea[m] pan", where [m] arises from place assimilation to the following labial[p]. This article explores how the neural speech recognition model Wav2Vec2perceives assimilated sounds, and identifies the linguistic knowledge that isimplemented by the model to compensate for assimilation during Automatic SpeechRecognition (ASR). Using psycholinguistic stimuli, we systematically analyzehow various linguistic context cues influence compensation patterns in themodel's output. Complementing these behavioral experiments, our probingexperiments indicate that the model shifts its interpretation of assimilatedsounds from their acoustic form to their underlying form in its final layers.Finally, our causal intervention experiments suggest that the model relies onminimal phonological context cues to accomplish this shift. These findingsrepresent a step towards better understanding the similarities and differencesin phonological processing between neural ASR models and humans.</description><author>Charlotte Pouw, Marianne de Heer Kloots, Afra Alishahi, Willem Zuidema</author><pubDate>Fri, 21 Jun 2024 16:58:22 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.15265v1</guid></item><item><title>Towards Fine-Grained Citation Evaluation in Generated Text: A Comparative Analysis of Faithfulness Metrics</title><link>http://arxiv.org/abs/2406.15264v1</link><description>Large language models (LLMs) often produce unsupported or unverifiableinformation, known as "hallucinations." To mitigate this, retrieval-augmentedLLMs incorporate citations, grounding the content in verifiable sources.Despite such developments, manually assessing how well a citation supports theassociated statement remains a major challenge. Previous studies usefaithfulness metrics to estimate citation support automatically but are limitedto binary classification, overlooking fine-grained citation support inpractical scenarios. To investigate the effectiveness of faithfulness metricsin fine-grained scenarios, we propose a comparative evaluation framework thatassesses the metric effectiveness in distinguishinging citations betweenthree-category support levels: full, partial, and no support. Our frameworkemploys correlation analysis, classification evaluation, and retrievalevaluation to measure the alignment between metric scores and human judgmentscomprehensively. Our results show no single metric consistently excels acrossall evaluations, revealing the complexity of assessing fine-grained support.Based on the findings, we provide practical recommendations for developing moreeffective metrics.</description><author>Weijia Zhang, Mohammad Aliannejadi, Yifei Yuan, Jiahuan Pei, Jia-Hong Huang, Evangelos Kanoulas</author><pubDate>Fri, 21 Jun 2024 16:57:24 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.15264v1</guid></item><item><title>A Tiny Transformer for Low-Power Arrhythmia Classification on Microcontrollers</title><link>http://arxiv.org/abs/2402.10748v2</link><description>Wearable systems for the continuous and real-time monitoring ofcardiovascular diseases are becoming widespread and valuable assets indiagnosis and therapy. A promising approach for real-time analysis of theelectrocardiographic (ECG) signal and the detection of heart conditions, suchas arrhythmia, is represented by the transformer machine learning model.Transformers are powerful models for the classification of time series,although efficient implementation in the wearable domain raises significantdesign challenges, to combine adequate accuracy and a suitable complexity. Inthis work, we present a tiny transformer model for the analysis of the ECGsignal, requiring only 6k parameters and reaching 98.97% accuracy in therecognition of the 5 most common arrhythmia classes from the MIT-BIH Arrhythmiadatabase, assessed considering 8-bit integer inference as required forefficient execution on low-power microcontroller-based devices. We explored anaugmentation-based training approach for improving the robustness againstelectrode motion artifacts noise, resulting in a worst-case post-deploymentperformance assessment of 98.36% accuracy. Suitability for wearable monitoringsolutions is finally demonstrated through efficient deployment on the parallelultra-low-power GAP9 processor, where inference execution requires 4.28ms and0.09mJ.</description><author>Paola Busia, Matteo Antonio Scrugli, Victor Jean-Baptiste Jung, Luca Benini, Paolo Meloni</author><pubDate>Fri, 21 Jun 2024 16:55:13 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.10748v2</guid></item><item><title>Fast sampling from constrained spaces using the Metropolis-adjusted Mirror Langevin algorithm</title><link>http://arxiv.org/abs/2312.08823v3</link><description>We propose a new method called the Metropolis-adjusted Mirror Langevinalgorithm for approximate sampling from distributions whose support is acompact and convex set. This algorithm adds an accept-reject filter to theMarkov chain induced by a single step of the Mirror Langevin algorithm (Zhanget al., 2020), which is a basic discretisation of the Mirror Langevin dynamics.Due to the inclusion of this filter, our method is unbiased relative to thetarget, while known discretisations of the Mirror Langevin dynamics includingthe Mirror Langevin algorithm have an asymptotic bias. For this algorithm, wealso give upper bounds for the number of iterations taken to mix to aconstrained distribution whose potential is relatively smooth, convex, andLipschitz continuous with respect to a self-concordant mirror function. As aconsequence of the reversibility of the Markov chain induced by the inclusionof the Metropolis-Hastings filter, we obtain an exponentially better dependenceon the error tolerance for approximate constrained sampling. We also presentnumerical experiments that corroborate our theoretical findings.</description><author>Vishwak Srinivasan, Andre Wibisono, Ashia Wilson</author><pubDate>Fri, 21 Jun 2024 16:52:52 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.08823v3</guid></item><item><title>V-RECS, a Low-Cost LLM4VIS Recommender with Explanations, Captioning and Suggestions</title><link>http://arxiv.org/abs/2406.15259v1</link><description>NL2VIS (natural language to visualization) is a promising and recent researcharea that involves interpreting natural language queries and translating theminto visualizations that accurately represent the underlying data. As wenavigate the era of big data, NL2VIS holds considerable application potentialsince it greatly facilitates data exploration by non-expert users. Followingthe increasingly widespread usage of generative AI in NL2VIS applications, inthis paper we present V-RECS, the first LLM-based Visual Recommender augmentedwith explanations(E), captioning(C), and suggestions(S) for further dataexploration. V-RECS' visualization narratives facilitate both responseverification and data exploration by non-expert users. Furthermore, ourproposed solution mitigates computational, controllability, and cost issuesassociated with using powerful LLMs by leveraging a methodology to effectivelyfine-tune small models. To generate insightful visualization narratives, we useChain-of-Thoughts (CoT), a prompt engineering technique to help LLM identifyand generate the logical steps to produce a correct answer. Since CoT isreported to perform poorly with small LLMs, we adopted a strategy in which alarge LLM (GPT-4), acting as a Teacher, generates CoT-based instructions tofine-tune a small model, Llama-2-7B, which plays the role of a Student.Extensive experiments-based on a framework for the quantitative evaluation ofAI-based visualizations and on manual assessment by a group ofparticipants-show that V-RECS achieves performance scores comparable to GPT-4,at a much lower cost. The efficacy of the V-RECS teacher-student paradigm isalso demonstrated by the fact that the un-tuned Llama fails to perform the taskin the vast majority of test cases. We release V-RECS for the visualizationcommunity to assist visualization designers throughout the entire visualizationgeneration process.</description><author>Luca Podo, Marco Angelini, Paola Velardi</author><pubDate>Fri, 21 Jun 2024 16:50:10 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.15259v1</guid></item><item><title>Fingerprint Membership and Identity Inference Against Generative Adversarial Networks</title><link>http://arxiv.org/abs/2406.15253v1</link><description>Generative models are gaining significant attention as potential catalystsfor a novel industrial revolution. Since automated sample generation can beuseful to solve privacy and data scarcity issues that usually affect learnedbiometric models, such technologies became widely spread in this field. In thispaper, we assess the vulnerabilities of generative machine learning modelsconcerning identity protection by designing and testing an identity inferenceattack on fingerprint datasets created by means of a generative adversarialnetwork. Experimental results show that the proposed solution proves to beeffective under different configurations and easily extendable to otherbiometric measurements.</description><author>Saverio Cavasin, Daniele Mari, Simone Milani, Mauro Conti</author><pubDate>Fri, 21 Jun 2024 16:43:47 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.15253v1</guid></item><item><title>MantisScore: Building Automatic Metrics to Simulate Fine-grained Human Feedback for Video Generation</title><link>http://arxiv.org/abs/2406.15252v1</link><description>The recent years have witnessed great advances in video generation. However,the development of automatic video metrics is lagging significantly behind.None of the existing metric is able to provide reliable scores over generatedvideos. The main barrier is the lack of large-scale human-annotated dataset. Inthis paper, we release VideoFeedback, the first large-scale dataset containinghuman-provided multi-aspect score over 37.6K synthesized videos from 11existing video generative models. We train MantisScore (initialized fromMantis) based on VideoFeedback to enable automatic video quality assessment.Experiments show that the Spearman correlation between MantisScore and humanscan reach 77.1 on VideoFeedback-test, beating the prior best metrics by about50 points. Further result on other held-out EvalCrafter, GenAI-Bench, andVBench show that MantisScore has consistently much higher correlation withhuman judges than other metrics. Due to these results, we believe MantisScorecan serve as a great proxy for human raters to (1) rate different video modelsto track progress (2) simulate fine-grained human feedback in ReinforcementLearning with Human Feedback (RLHF) to improve current video generation models.</description><author>Xuan He, Dongfu Jiang, Ge Zhang, Max Ku, Achint Soni, Sherman Siu, Haonan Chen, Abhranil Chandra, Ziyan Jiang, Aaran Arulraj, Kai Wang, Quy Duc Do, Yuansheng Ni, Bohan Lyu, Yaswanth Narsupalli, Rongqi Fan, Zhiheng Lyu, Yuchen Lin, Wenhu Chen</author><pubDate>Fri, 21 Jun 2024 16:43:46 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.15252v1</guid></item><item><title>Equivariance via Minimal Frame Averaging for More Symmetries and Efficiency</title><link>http://arxiv.org/abs/2406.07598v4</link><description>We consider achieving equivariance in machine learning systems via frameaveraging. Current frame averaging methods involve a costly sum over largeframes or rely on sampling-based approaches that only yield approximateequivariance. Here, we propose Minimal Frame Averaging (MFA), a mathematicalframework for constructing provably minimal frames that are exactlyequivariant. The general foundations of MFA also allow us to extend frameaveraging to more groups than previously considered, including the Lorentzgroup for describing symmetries in space-time, and the unitary group forcomplex-valued domains. Results demonstrate the efficiency and effectiveness ofencoding symmetries via MFA across a diverse range of tasks, including $n$-bodysimulation, top tagging in collider physics, and relaxed energy prediction. Ourcode is available at https://github.com/divelab/MFA.</description><author>Yuchao Lin, Jacob Helwig, Shurui Gui, Shuiwang Ji</author><pubDate>Fri, 21 Jun 2024 16:43:36 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.07598v4</guid></item><item><title>Open Problem: Order Optimal Regret Bounds for Kernel-Based Reinforcement Learning</title><link>http://arxiv.org/abs/2406.15250v1</link><description>Reinforcement Learning (RL) has shown great empirical success in variousapplication domains. The theoretical aspects of the problem have beenextensively studied over past decades, particularly under tabular and linearMarkov Decision Process structures. Recently, non-linear function approximationusing kernel-based prediction has gained traction. This approach isparticularly interesting as it naturally extends the linear structure, andhelps explain the behavior of neural-network-based models at their infinitewidth limit. The analytical results however do not adequately address theperformance guarantees for this case. We will highlight this open problem,overview existing partial results, and discuss related challenges.</description><author>Sattar Vakili</author><pubDate>Fri, 21 Jun 2024 16:43:02 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.15250v1</guid></item><item><title>Unsupervised Morphological Tree Tokenizer</title><link>http://arxiv.org/abs/2406.15245v1</link><description>As a cornerstone in language modeling, tokenization involves segmenting textinputs into pre-defined atomic units. Conventional statistical tokenizers oftendisrupt constituent boundaries within words, thereby corrupting semanticinformation. To address this drawback, we introduce morphological structureguidance to tokenization and propose a deep model to induce character-levelstructures of words. Specifically, the deep model jointly encodes internalstructures and representations of words with a mechanism named$\textit{MorphOverriding}$ to ensure the indecomposability of morphemes. Bytraining the model with self-supervised objectives, our method is capable ofinducing character-level structures that align with morphological rules withoutannotated training data. Based on the induced structures, our algorithmtokenizes words through vocabulary matching in a top-down manner. Empiricalresults indicate that the proposed method effectively retains completemorphemes and outperforms widely adopted methods such as BPE and WordPiece onboth morphological segmentation tasks and language modeling tasks. The codewill be released later.</description><author>Qingyang Zhu, Xiang Hu, Pengyu Ji, Wei Wu, Kewei Tu</author><pubDate>Fri, 21 Jun 2024 16:35:49 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.15245v1</guid></item><item><title>Large Legal Fictions: Profiling Legal Hallucinations in Large Language Models</title><link>http://arxiv.org/abs/2401.01301v2</link><description>Do large language models (LLMs) know the law? These models are increasinglybeing used to augment legal practice, education, and research, yet theirrevolutionary potential is threatened by the presence of hallucinations --textual output that is not consistent with legal facts. We present the firstsystematic evidence of these hallucinations, documenting LLMs' varyingperformance across jurisdictions, courts, time periods, and cases. Our workmakes four key contributions. First, we develop a typology of legalhallucinations, providing a conceptual framework for future research in thisarea. Second, we find that legal hallucinations are alarmingly prevalent,occurring between 58% of the time with ChatGPT 4 and 88% with Llama 2, whenthese models are asked specific, verifiable questions about random federalcourt cases. Third, we illustrate that LLMs often fail to correct a user'sincorrect legal assumptions in a contra-factual question setup. Fourth, weprovide evidence that LLMs cannot always predict, or do not always know, whenthey are producing legal hallucinations. Taken together, our findings cautionagainst the rapid and unsupervised integration of popular LLMs into legaltasks. Even experienced lawyers must remain wary of legal hallucinations, andthe risks are highest for those who stand to benefit from LLMs the most -- prose litigants or those without access to traditional legal resources.</description><author>Matthew Dahl, Varun Magesh, Mirac Suzgun, Daniel E. Ho</author><pubDate>Fri, 21 Jun 2024 16:32:27 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.01301v2</guid></item><item><title>Reinforcement Learning with Latent State Inference for Autonomous On-ramp Merging under Observation Delay</title><link>http://arxiv.org/abs/2403.11852v3</link><description>This paper presents a novel approach to address the challenging problem ofautonomous on-ramp merging, where a self-driving vehicle needs to seamlesslyintegrate into a flow of vehicles on a multi-lane highway. We introduce theLane-keeping, Lane-changing with Latent-state Inference and Safety Controller(L3IS) agent, designed to perform the on-ramp merging task safely withoutcomprehensive knowledge about surrounding vehicles' intents or driving styles.We also present an augmentation of this agent called AL3IS that accounts forobservation delays, allowing the agent to make more robust decisions inreal-world environments with vehicle-to-vehicle (V2V) communication delays. Bymodeling the unobservable aspects of the environment through latent states,such as other drivers' intents, our approach enhances the agent's ability toadapt to dynamic traffic conditions, optimize merging maneuvers, and ensuresafe interactions with other vehicles. We demonstrate the effectiveness of ourmethod through extensive simulations generated from real traffic data andcompare its performance with existing approaches. L3IS shows a 99.90% successrate in a challenging on-ramp merging case generated from the real US Highway101 data. We further perform a sensitivity analysis on AL3IS to evaluate itsrobustness against varying observation delays, which demonstrates an acceptableperformance of 93.84% success rate in 1-second V2V communication delay.</description><author>Amin Tabrizian, Zhitong Huang, Peng Wei</author><pubDate>Fri, 21 Jun 2024 16:31:50 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.11852v3</guid></item><item><title>Large Batch Analysis for Adagrad Under Anisotropic Smoothness</title><link>http://arxiv.org/abs/2406.15244v1</link><description>Adaptive gradient algorithms have been widely adopted in training large-scaledeep neural networks, especially large foundation models. Despite their hugesuccess in practice, their theoretical advantages over stochastic gradientdescent (SGD) have not been fully understood, especially in the largebatch-size setting commonly used in practice. This is because the onlytheoretical result that can demonstrate the benefit of Adagrad over SGD wasobtained in the original paper of Adagrad for nonsmooth objective functions.However, for nonsmooth objective functions, there can be a linear slowdown ofconvergence when batch size increases, and thus a convergence analysis based onnonsmooth assumption cannot be used for large batch algorithms. In this work,we resolve this gap between theory and practice by providing a new analysis ofAdagrad on both convex and nonconvex smooth objectives suitable for the largebatch setting. It is shown that under the anisotropic smoothness and noiseconditions, increased batch size does not slow down convergence for Adagrad,and thus it can still achieve a faster convergence guarantee over SGD even inthe large batch setting. We present detailed comparisons between SGD andAdagrad to provide a better understanding of the benefits of adaptive gradientmethods. Experiments in logistic regression and instruction followingfine-tuning tasks provide strong evidence to support our theoretical analysis.</description><author>Yuxing Liu, Rui Pan, Tong Zhang</author><pubDate>Fri, 21 Jun 2024 16:29:31 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.15244v1</guid></item><item><title>XNLP: An Interactive Demonstration System for Universal Structured NLP</title><link>http://arxiv.org/abs/2308.01846v2</link><description>Structured Natural Language Processing (XNLP) is an important subset of NLPthat entails understanding the underlying semantic or syntactic structure oftexts, which serves as a foundational component for many downstreamapplications. Despite certain recent efforts to explore universal solutions forspecific categories of XNLP tasks, a comprehensive and effective approach forunifying all XNLP tasks long remains underdeveloped. In the meanwhile, whileXNLP demonstration systems are vital for researchers exploring various XNLPtasks, existing platforms can be limited to, e.g., supporting few XNLP tasks,lacking interactivity and universalness. To this end, we propose an advancedXNLP demonstration platform, where we propose leveraging LLM to achieveuniversal XNLP, with one model for all with high generalizability. Overall, oursystem advances in multiple aspects, including universal XNLP modeling, highperformance, interpretability, scalability, and interactivity, providing aunified platform for exploring diverse XNLP tasks in the community. XNLP isonline: https://xnlp.haofei.vip</description><author>Hao Fei, Meishan Zhang, Min Zhang, Tat-Seng Chua</author><pubDate>Fri, 21 Jun 2024 16:26:05 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2308.01846v2</guid></item><item><title>Detecting Synthetic Lyrics with Few-Shot Inference</title><link>http://arxiv.org/abs/2406.15231v1</link><description>In recent years, generated content in music has gained significantpopularity, with large language models being effectively utilized to producehuman-like lyrics in various styles, themes, and linguistic structures. Thistechnological advancement supports artists in their creative processes but alsoraises issues of authorship infringement, consumer satisfaction and contentspamming. To address these challenges, methods for detecting generated lyricsare necessary. However, existing works have not yet focused on this specificmodality or on creative text in general regarding machine-generated contentdetection methods and datasets. In response, we have curated the first datasetof high-quality synthetic lyrics and conducted a comprehensive quantitativeevaluation of various few-shot content detection approaches, testing theirgeneralization capabilities and complementing this with a human evaluation. Ourbest few-shot detector, based on LLM2Vec, surpasses stylistic and statisticalmethods, which are shown competitive in other domains at distinguishinghuman-written from machine-generated content. It also shows good generalizationcapabilities to new artists and models, and effectively detects post-generationparaphrasing. This study emphasizes the need for further research on creativecontent detection, particularly in terms of generalization and scalability withlarger song catalogs. All datasets, pre-processing scripts, and code areavailable publicly on GitHub and Hugging Face under the Apache 2.0 license.</description><author>Yanis Labrak, Gabriel Meseguer-Brocal, Elena V. Epure</author><pubDate>Fri, 21 Jun 2024 16:19:21 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.15231v1</guid></item><item><title>ExDAG: Exact learning of DAGs</title><link>http://arxiv.org/abs/2406.15229v1</link><description>There has been a growing interest in causal learning in recent years.Commonly used representations of causal structures, including Bayesian networksand structural equation models (SEM), take the form of directed acyclic graphs(DAGs). We provide a novel mixed-integer quadratic programming formulation andassociated algorithm that identifies DAGs on up to 50 vertices, where these areidentifiable. We call this method ExDAG, which stands for Exact learning ofDAGs. Although there is a superexponential number of constraints that preventthe formation of cycles, the algorithm adds constraints violated by solutionsfound, rather than imposing all constraints in each continuous-valuedrelaxation. Our empirical results show that ExDAG outperforms localstate-of-the-art solvers in terms of precision and outperforms state-of-the-artglobal solvers with respect to scaling, when considering Gaussian noise. Wealso provide validation with respect to other noise distributions.</description><author>Pavel Rytíř, Aleš Wodecki, Jakub Mareček</author><pubDate>Fri, 21 Jun 2024 16:15:38 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.15229v1</guid></item><item><title>A LLM-Based Ranking Method for the Evaluation of Automatic Counter-Narrative Generation</title><link>http://arxiv.org/abs/2406.15227v1</link><description>The proliferation of misinformation and harmful narratives in onlinediscourse has underscored the critical need for effective Counter Narrative(CN) generation techniques. However, existing automatic evaluation methodsoften lack interpretability and fail to capture the nuanced relationshipbetween generated CNs and human perception. Aiming to achieve a highercorrelation with human judgments, this paper proposes a novel approach to assesgenerated CNs that consists on the use of a Large Language Model (LLM) as aevaluator. By comparing generated CNs pairwise in a tournament-style format, weestablish a model ranking pipeline that achieves a correlation of $0.88$ withhuman preference. As an additional contribution, we leverage LLMs as zero-shot(ZS) CN generators and conduct a comparative analysis of chat, instruct, andbase models, exploring their respective strengths and limitations. Throughmeticulous evaluation, including fine-tuning experiments, we elucidate thedifferences in performance and responsiveness to domain-specific data. Weconclude that chat-aligned models in ZS are the best option for carrying outthe task, provided they do not refuse to generate an answer due to securityconcerns.</description><author>Irune Zubiaga, Aitor Soroa, Rodrigo Agerri</author><pubDate>Fri, 21 Jun 2024 16:11:33 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.15227v1</guid></item><item><title>Fine-grained analysis of non-parametric estimation for pairwise learning</title><link>http://arxiv.org/abs/2305.19640v2</link><description>In this paper, we are concerned with the generalization performance ofnon-parametric estimation for pairwise learning. Most of the existing workrequires the hypothesis space to be convex or a VC-class, and the loss to beconvex. However, these restrictive assumptions limit the applicability of theresults in studying many popular methods, especially kernel methods and neuralnetworks. We significantly relax these restrictive assumptions and establish asharp oracle inequality of the empirical minimizer with a general hypothesisspace for the Lipschitz continuous pairwise losses. Our results can be used tohandle a wide range of pairwise learning problems including ranking, AUCmaximization, pairwise regression, and metric and similarity learning. As anapplication, we apply our general results to study pairwise least squaresregression and derive an excess generalization bound that matches the minimaxlower bound for pointwise least squares regression up to a logrithmic term. Thekey novelty here is to construct a structured deep ReLU neural network as anapproximation of the true predictor and design the targeted hypothesis spaceconsisting of the structured networks with controllable complexity. Thissuccessful application demonstrates that the obtained general results indeedhelp us to explore the generalization performance on a variety of problems thatcannot be handled by existing approaches.</description><author>Junyu Zhou, Shuo Huang, Han Feng, Puyu Wang, Ding-Xuan Zhou</author><pubDate>Fri, 21 Jun 2024 16:10:29 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.19640v2</guid></item><item><title>Deep UAV Path Planning with Assured Connectivity in Dense Urban Setting</title><link>http://arxiv.org/abs/2406.15225v1</link><description>Unmanned Ariel Vehicle (UAV) services with 5G connectivity is an emergingfield with numerous applications. Operator-controlled UAV flights and manualstatic flight configurations are major limitations for the wide adoption ofscalability of UAV services. Several services depend on excellent UAVconnectivity with a cellular network and maintaining it is challenging inpredetermined flight paths. This paper addresses these limitations by proposinga Deep Reinforcement Learning (DRL) framework for UAV path planning withassured connectivity (DUPAC). During UAV flight, DUPAC determines the bestroute from a defined source to the destination in terms of distance and signalquality. The viability and performance of DUPAC are evaluated under simulatedreal-world urban scenarios using the Unity framework. The results confirm thatDUPAC achieves an autonomous UAV flight path similar to base method with only2% increment while maintaining an average 9% better connection qualitythroughout the flight.</description><author>Jiyong Oh, Syed M. Raza, Lusungu J. Mwasinga, Moonseong Kim, Hyunseung Choo</author><pubDate>Fri, 21 Jun 2024 16:10:25 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.15225v1</guid></item><item><title>A Dataset and Benchmark for Copyright Infringement Unlearning from Text-to-Image Diffusion Models</title><link>http://arxiv.org/abs/2403.12052v3</link><description>Copyright law confers upon creators the exclusive rights to reproduce,distribute, and monetize their creative works. However, recent progress intext-to-image generation has introduced formidable challenges to copyrightenforcement. These technologies enable the unauthorized learning andreplication of copyrighted content, artistic creations, and likenesses, leadingto the proliferation of unregulated content. Notably, models like stablediffusion, which excel in text-to-image synthesis, heighten the risk ofcopyright infringement and unauthorized distribution.Machine unlearning, whichseeks to eradicate the influence of specific data or concepts from machinelearning models, emerges as a promising solution by eliminating the\enquote{copyright memories} ingrained in diffusion models. Yet, the absence ofcomprehensive large-scale datasets and standardized benchmarks for evaluatingthe efficacy of unlearning techniques in the copyright protection scenariosimpedes the development of more effective unlearning methods. To address thisgap, we introduce a novel pipeline that harmonizes CLIP, ChatGPT, and diffusionmodels to curate a dataset. This dataset encompasses anchor images, associatedprompts, and images synthesized by text-to-image models. Additionally, we havedeveloped a mixed metric based on semantic and style information, validatedthrough both human and artist assessments, to gauge the effectiveness ofunlearning approaches. Our dataset, benchmark library, and evaluation metricswill be made publicly available to foster future research and practicalapplications (https://rmpku.github.io/CPDM-page/, website /http://149.104.22.83/unlearning.tar.gz, dataset).</description><author>Rui Ma, Qiang Zhou, Yizhu Jin, Daquan Zhou, Bangjun Xiao, Xiuyu Li, Yi Qu, Aishani Singh, Kurt Keutzer, Jingtong Hu, Xiaodong Xie, Zhen Dong, Shanghang Zhang, Shiji Zhou</author><pubDate>Fri, 21 Jun 2024 15:58:30 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.12052v3</guid></item><item><title>Unsupervised Extraction of Dialogue Policies from Conversations</title><link>http://arxiv.org/abs/2406.15214v1</link><description>Dialogue policies play a crucial role in developing task-oriented dialoguesystems, yet their development and maintenance are challenging and typicallyrequire substantial effort from experts in dialogue modeling. While in manysituations, large amounts of conversational data are available for the task athand, people lack an effective solution able to extract dialogue policies fromthis data. In this paper, we address this gap by first illustrating how LargeLanguage Models (LLMs) can be instrumental in extracting dialogue policies fromdatasets, through the conversion of conversations into a unified intermediaterepresentation consisting of canonical forms. We then propose a novel methodfor generating dialogue policies utilizing a controllable and interpretablegraph-based methodology. By combining canonical forms across conversations intoa flow network, we find that running graph traversal algorithms helps inextracting dialogue flows. These flows are a better representation of theunderlying interactions than flows extracted by prompting LLMs. Our techniquefocuses on giving conversation designers greater control, offering aproductivity tool to improve the process of developing dialogue policies.</description><author>Makesh Narsimhan Sreedhar, Traian Rebedea, Christopher Parisien</author><pubDate>Fri, 21 Jun 2024 15:57:25 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.15214v1</guid></item><item><title>Large Language Model-Enabled Multi-Agent Manufacturing Systems</title><link>http://arxiv.org/abs/2406.01893v2</link><description>Traditional manufacturing faces challenges adapting to dynamic environmentsand quickly responding to manufacturing changes. The use of multi-agent systemshas improved adaptability and coordination but requires further advancements inrapid human instruction comprehension, operational adaptability, andcoordination through natural language integration. Large language models likeGPT-3.5 and GPT-4 enhance multi-agent manufacturing systems by enabling agentsto communicate in natural language and interpret human instructions fordecision-making. This research introduces a novel framework where largelanguage models enhance the capabilities of agents in manufacturing, makingthem more adaptable, and capable of processing context-specific instructions. Acase study demonstrates the practical application of this framework, showinghow agents can effectively communicate, understand tasks, and executemanufacturing processes, including precise G-code allocation among agents. Thefindings highlight the importance of continuous large language modelintegration into multi-agent manufacturing systems and the development ofsophisticated agent communication protocols for a more flexible manufacturingsystem.</description><author>Jonghan Lim, Birgit Vogel-Heuser, Ilya Kovalenko</author><pubDate>Fri, 21 Jun 2024 15:54:46 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.01893v2</guid></item><item><title>Injecting Bias in Text-To-Image Models via Composite-Trigger Backdoors</title><link>http://arxiv.org/abs/2406.15213v1</link><description>Recent advances in large text-conditional image generative models such asStable Diffusion, Midjourney, and DALL-E 3 have revolutionized the field ofimage generation, allowing users to produce high-quality, realistic images fromtextual prompts. While these developments have enhanced artistic creation andvisual communication, they also present an underexplored attack opportunity:the possibility of inducing biases by an adversary into the generated imagesfor malicious intentions, e.g., to influence society and spread propaganda. Inthis paper, we demonstrate the possibility of such a bias injection threat byan adversary who backdoors such models with a small number of malicious datasamples; the implemented backdoor is activated when special triggers exist inthe input prompt of the backdoored models. On the other hand, the model'sutility is preserved in the absence of the triggers, making the attack highlyundetectable. We present a novel framework that enables efficient generation ofpoisoning samples with composite (multi-word) triggers for such an attack. Ourextensive experiments using over 1 million generated images and againsthundreds of fine-tuned models demonstrate the feasibility of the presentedbackdoor attack. We illustrate how these biases can bypass conventionaldetection mechanisms, highlighting the challenges in proving the existence ofbiases within operational constraints. Our cost analysis confirms the lowfinancial barrier to executing such attacks, underscoring the need for robustdefensive strategies against such vulnerabilities in text-to-image generationmodels.</description><author>Ali Naseh, Jaechul Roh, Eugene Bagdasaryan, Amir Houmansadr</author><pubDate>Fri, 21 Jun 2024 15:53:19 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.15213v1</guid></item><item><title>How Effective is GPT-4 Turbo in Generating School-Level Questions from Textbooks Based on Bloom's Revised Taxonomy?</title><link>http://arxiv.org/abs/2406.15211v1</link><description>We evaluate the effectiveness of GPT-4 Turbo in generating educationalquestions from NCERT textbooks in zero-shot mode. Our study highlights GPT-4Turbo's ability to generate questions that require higher-order thinkingskills, especially at the "understanding" level according to Bloom's RevisedTaxonomy. While we find a notable consistency between questions generated byGPT-4 Turbo and those assessed by humans in terms of complexity, there areoccasional differences. Our evaluation also uncovers variations in how humansand machines evaluate question quality, with a trend inversely related toBloom's Revised Taxonomy levels. These findings suggest that while GPT-4 Turbois a promising tool for educational question generation, its efficacy variesacross different cognitive levels, indicating a need for further refinement tofully meet educational standards.</description><author>Subhankar Maity, Aniket Deroy, Sudeshna Sarkar</author><pubDate>Fri, 21 Jun 2024 15:52:37 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.15211v1</guid></item><item><title>A Low-Overhead Incorporation-Extrapolation based Few-Shot CSI Feedback Framework for Massive MIMO Systems</title><link>http://arxiv.org/abs/2312.04062v2</link><description>Accurate channel state information (CSI) is essential for downlink precodingin frequency division duplexing (FDD) massive multiple-input multiple-output(MIMO) systems with orthogonal frequency-division multiplexing (OFDM). However,obtaining CSI through feedback from the user equipment (UE) becomes challengingwith the increasing scale of antennas and subcarriers and leads to extremelyhigh CSI feedback overhead. Deep learning-based methods have emerged forcompressing CSI but these methods generally require substantial collectedsamples and thus pose practical challenges. Moreover, existing deep learningmethods also suffer from dramatically growing feedback overhead owing to theirfocus on full-dimensional CSI feedback. To address these issues, we propose alow-overhead Incorporation-Extrapolation based Few-Shot CSI feedback Framework(IEFSF) for massive MIMO systems. An incorporation-extrapolation scheme foreigenvector-based CSI feedback is proposed to reduce the feedback overhead.Then, to alleviate the necessity of extensive collected samples and enablefew-shot CSI feedback, we further propose a knowledge-driven data augmentation(KDDA) method and an artificial intelligence-generated content (AIGC) -baseddata augmentation method by exploiting the domain knowledge of wirelesschannels and by exploiting a novel generative model, respectively. Experimentalresults based on the DeepMIMO dataset demonstrate that the proposed IEFSFsignificantly reduces CSI feedback overhead by 64 times compared with existingmethods while maintaining higher feedback accuracy using only several hundredcollected samples.</description><author>Binggui Zhou, Xi Yang, Jintao Wang, Shaodan Ma, Feifei Gao, Guanghua Yang</author><pubDate>Fri, 21 Jun 2024 15:51:24 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.04062v2</guid></item><item><title>Explainable Online Unsupervised Anomaly Detection for Cyber-Physical Systems via Causal Discovery from Time Series</title><link>http://arxiv.org/abs/2404.09871v2</link><description>Online unsupervised detection of anomalies is crucial to guarantee thecorrect operation of cyber-physical systems and the safety of humansinteracting with them. State-of-the-art approaches based on deep learning vianeural networks achieve outstanding performance at anomaly recognition,evaluating the discrepancy between a normal model of the system (with noanomalies) and the real-time stream of sensor time series. However, largetraining data and time are typically required, and explainability is still achallenge to identify the root of the anomaly and implement predictivemaintainance. In this paper, we use causal discovery to learn a normal causalgraph of the system, and we evaluate the persistency of causal links duringreal-time acquisition of sensor data to promptly detect anomalies. On twobenchmark anomaly detection datasets, we show that our method has highertraining efficiency, outperforms the accuracy of state-of-the-art neuralarchitectures and correctly identifies the sources of $&gt;10$ differentanomalies. The code for experimental replication is athttp://tinyurl.com/case24causal.</description><author>Daniele Meli</author><pubDate>Fri, 21 Jun 2024 15:48:45 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.09871v2</guid></item><item><title>Landscape More Secure Than Portrait? Zooming Into the Directionality of Digital Images With Security Implications</title><link>http://arxiv.org/abs/2406.15206v1</link><description>The orientation in which a source image is captured can affect the resultingsecurity in downstream applications. One reason for this is that manystate-of-the-art methods in media security assume that image statistics aresimilar in the horizontal and vertical directions, allowing them to reduce thenumber of features (or trainable weights) by merging coefficients. We show thatthis artificial symmetrization tends to suppress important properties ofnatural images and common processing operations, causing a loss of performance.We also observe the opposite problem, where unaddressed directionality causeslearning-based methods to overfit to a single orientation. These are vulnerableto manipulation if an adversary chooses inputs with the less commonorientation. This paper takes a comprehensive approach, identifies andsystematizes causes of directionality at several stages of a typicalacquisition pipeline, measures their effect, and demonstrates for threeselected security applications (steganalysis, forensic source identification,and the detection of synthetic images) how the performance of state-of-the-artmethods can be improved by properly accounting for directionality.</description><author>Benedikt Lorch, Rainer Böhme</author><pubDate>Fri, 21 Jun 2024 15:48:25 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.15206v1</guid></item><item><title>A Survey on Intelligent Internet of Things: Applications, Security, Privacy, and Future Directions</title><link>http://arxiv.org/abs/2406.03820v2</link><description>The rapid advances in the Internet of Things (IoT) have promoted a revolutionin communication technology and offered various customer services. Artificialintelligence (AI) techniques have been exploited to facilitate IoT operationsand maximize their potential in modern application scenarios. In particular,the convergence of IoT and AI has led to a new networking paradigm calledIntelligent IoT (IIoT), which has the potential to significantly transformbusinesses and industrial domains. This paper presents a comprehensive surveyof IIoT by investigating its significant applications in mobile networks, aswell as its associated security and privacy issues. Specifically, we exploreand discuss the roles of IIoT in a wide range of key application domains, fromsmart healthcare and smart cities to smart transportation and smart industries.Through such extensive discussions, we investigate important security issues inIIoT networks, where network attacks, confidentiality, integrity, and intrusionare analyzed, along with a discussion of potential countermeasures. Privacyissues in IIoT networks were also surveyed and discussed, including data,location, and model privacy leakage. Finally, we outline several key challengesand highlight potential research directions in this important area.</description><author>Ons Aouedi, Thai-Hoc Vu, Alessio Sacco, Dinh C. Nguyen, Kandaraj Piamrat, Guido Marchetto, Quoc-Viet Pham</author><pubDate>Fri, 21 Jun 2024 15:43:41 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.03820v2</guid></item><item><title>Incentivizing High-Quality Content in Online Recommender Systems</title><link>http://arxiv.org/abs/2306.07479v3</link><description>In content recommender systems such as TikTok and YouTube, the platform'srecommendation algorithm shapes content producer incentives. Many platformsemploy online learning, which generates intertemporal incentives, since contentproduced today affects recommendations of future content. We study the gamebetween producers and analyze the content created at equilibrium. We show thatstandard online learning algorithms, such as Hedge and EXP3, unfortunatelyincentivize producers to create low-quality content, where producers' effortapproaches zero in the long run for typical learning rate schedules. Motivatedby this negative result, we design learning algorithms that incentivizeproducers to invest high effort and achieve high user welfare. At a conceptuallevel, our work illustrates the unintended impact that a platform's learningalgorithm can have on content quality and introduces algorithmic approaches tomitigating these effects.</description><author>Xinyan Hu, Meena Jagadeesan, Michael I. Jordan, Jacob Steinhardt</author><pubDate>Fri, 21 Jun 2024 15:39:07 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.07479v3</guid></item><item><title>Exploring the Efficacy of Robotic Assistants with ChatGPT and Claude in Enhancing ADHD Therapy: Innovating Treatment Paradigms</title><link>http://arxiv.org/abs/2406.15198v1</link><description>Attention Deficit Hyperactivity Disorder (ADHD) is a neurodevelopmentalcondition characterized by inattention, hyperactivity, and impulsivity, whichcan significantly impact an individual's daily functioning and quality of life.Occupational therapy plays a crucial role in managing ADHD by fostering thedevelopment of skills needed for daily living and enhancing an individual'sability to participate fully in school, home, and social situations. Recentstudies highlight the potential of integrating Large Language Models (LLMs)like ChatGPT and Socially Assistive Robots (SAR) to improve psychologicaltreatments. This integration aims to overcome existing limitations in mentalhealth therapy by providing tailored support and adapting to the unique needsof this sensitive group. However, there remains a significant gap in researchexploring the combined use of these advanced technologies in ADHD therapy,suggesting an opportunity for novel therapeutic approaches. Thus, we integrated two advanced language models, ChatGPT-4 Turbo andClaude-3 Opus, into a robotic assistant to explore how well each model performsin robot-assisted interactions. Additionally, we have compared theirperformance in a simulated therapy scenario to gauge their effectivenessagainst a clinically validated customized model. The results of this study showthat ChatGPT-4 Turbo excelled in performance and responsiveness, making itsuitable for time-sensitive applications. Claude-3 Opus, on the other hand,showed strengths in understanding, coherence, and ethical considerations,prioritizing safe and engaging interactions. Both models demonstratedinnovation and adaptability, but ChatGPT-4 Turbo offered greater ease ofintegration and broader language support. The selection between them hinges onthe specific demands of ADHD therapy.</description><author>Santiago Berrezueta-Guzman, Mohanad Kandil, María-Luisa Martín-Ruiz, Iván Pau-de-la-Cruz, Stephan Krusche</author><pubDate>Fri, 21 Jun 2024 15:38:25 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.15198v1</guid></item><item><title>Reward Steering with Evolutionary Heuristics for Decoding-time Alignment</title><link>http://arxiv.org/abs/2406.15193v1</link><description>The widespread applicability and increasing omnipresence of LLMs haveinstigated a need to align LLM responses to user and stakeholder preferences.Many preference optimization approaches have been proposed that fine-tune LLMparameters to achieve good alignment. However, such parameter tuning is knownto interfere with model performance on many tasks. Moreover, keeping up withshifting user preferences is tricky in such a situation. Decoding-timealignment with reward model guidance solves these issues at the cost ofincreased inference time. However, most of such methods fail to strike theright balance between exploration and exploitation of reward -- often due tothe conflated formulation of these two aspects - to give well-alignedresponses. To remedy this we decouple these two aspects and implement them inan evolutionary fashion: exploration is enforced by decoding from mutatedinstructions and exploitation is represented as the periodic replacement ofpoorly-rewarded generations with well-rewarded ones. Empirical evidencesindicate that this strategy outperforms many preference optimization anddecode-time alignment approaches on two widely accepted alignment benchmarksAlpacaEval 2 and MT-Bench. Our implementation will be available at:https://darwin-alignment.github.io.</description><author>Chia-Yu Hung, Navonil Majumder, Ambuj Mehrish, Soujanya Poria</author><pubDate>Fri, 21 Jun 2024 15:35:16 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.15193v1</guid></item><item><title>Reinforcement-Learning based routing for packet-optical networks with hybrid telemetry</title><link>http://arxiv.org/abs/2406.12602v2</link><description>This article provides a methodology and open-source implementation ofReinforcement Learning algorithms for finding optimal routes in apacket-optical network scenario. The algorithm uses measurements provided bythe physical layer (pre-FEC bit error rate and propagation delay) and the linklayer (link load) to configure a set of latency-based rewards and penaltiesbased on such measurements. Then, the algorithm executes Q-learning based onthis set of rewards for finding the optimal routing strategies. It is furthershown that the algorithm dynamically adapts to changing network conditions byre-calculating optimal policies upon either link load changes or linkdegradation as measured by pre-FEC BER.</description><author>A. L. García Navarro, Nataliia Koneva, Alfonso Sánchez-Macián, José Alberto Hernández, Óscar González de Dios, J. M. Rivas-Moscoso</author><pubDate>Fri, 21 Jun 2024 15:35:08 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.12602v2</guid></item><item><title>Causal Learning in Biomedical Applications</title><link>http://arxiv.org/abs/2406.15189v1</link><description>We present a benchmark for methods in causal learning. Specifically, weconsider training a rich class of causal models from time-series data, and wesuggest the use of the Krebs cycle and models of metabolism more broadly.</description><author>Petr Ryšavý, Xiaoyu He, Jakub Mareček</author><pubDate>Fri, 21 Jun 2024 15:31:45 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.15189v1</guid></item><item><title>UDA: A Benchmark Suite for Retrieval Augmented Generation in Real-world Document Analysis</title><link>http://arxiv.org/abs/2406.15187v1</link><description>The use of Retrieval-Augmented Generation (RAG) has improved Large LanguageModels (LLMs) in collaborating with external data, yet significant challengesexist in real-world scenarios. In areas such as academic literature and financequestion answering, data are often found in raw text and tables in HTML or PDFformats, which can be lengthy and highly unstructured. In this paper, weintroduce a benchmark suite, namely Unstructured Document Analysis (UDA), thatinvolves 2,965 real-world documents and 29,590 expert-annotated Q&amp;A pairs. Werevisit popular LLM- and RAG-based solutions for document analysis and evaluatethe design choices and answer qualities across multiple document domains anddiverse query types. Our evaluation yields interesting findings and highlightsthe importance of data parsing and retrieval. We hope our benchmark can shedlight and better serve real-world document analysis applications. The benchmarksuite and code can be found at https://github.com/qinchuanhui/UDA-Benchmark.</description><author>Yulong Hui, Yao Lu, Huanchen Zhang</author><pubDate>Fri, 21 Jun 2024 15:29:39 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.15187v1</guid></item><item><title>DiffExplainer: Unveiling Black Box Models Via Counterfactual Generation</title><link>http://arxiv.org/abs/2406.15182v1</link><description>In the field of medical imaging, particularly in tasks related to earlydisease detection and prognosis, understanding the reasoning behind AI modelpredictions is imperative for assessing their reliability. Conventionalexplanation methods encounter challenges in identifying decisive features inmedical image classifications, especially when discriminative features aresubtle or not immediately evident. To address this limitation, we propose anagent model capable of generating counterfactual images that prompt differentdecisions when plugged into a black box model. By employing this agent model,we can uncover influential image patterns that impact the black model's finalpredictions. Through our methodology, we efficiently identify features thatinfluence decisions of the deep black box. We validated our approach in therigorous domain of medical prognosis tasks, showcasing its efficacy andpotential to enhance the reliability of deep learning models in medical imageclassification compared to existing interpretation methods. The code will bepublicly available at https://github.com/ayanglab/DiffExplainer.</description><author>Yingying Fang, Shuang Wu, Zihao Jin, Caiwen Xu, Shiyi Wang, Simon Walsh, Guang Yang</author><pubDate>Fri, 21 Jun 2024 15:27:02 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.15182v1</guid></item><item><title>Hybrid Alignment Training for Large Language Models</title><link>http://arxiv.org/abs/2406.15178v1</link><description>Alignment training is crucial for enabling large language models (LLMs) tocater to human intentions and preferences. It is typically performed based ontwo stages with different objectives: instruction-following alignment andhuman-preference alignment. However, aligning LLMs with these objectives insequence suffers from an inherent problem: the objectives may conflict, and theLLMs cannot guarantee to simultaneously align with the instructions and humanpreferences well. To response to these, in this work, we propose a HybridAlignment Training (Hbat) approach, based on alternating alignment and modifiedelastic weight consolidation methods. The basic idea is to alternate betweendifferent objectives during alignment training, so that better collaborationcan be achieved between the two alignment tasks.We experiment with Hbat onsummarization and dialogue tasks. Experimental results show that the proposed\textsc{Hbat} can significantly outperform all baselines. Notably, Hbat yieldsconsistent performance gains over the traditional two-stage alignment trainingwhen using both proximal policy optimization and direct preferenceoptimization.</description><author>Chenglong Wang, Hang Zhou, Kaiyan Chang, Bei Li, Yongyu Mu, Tong Xiao, Tongran Liu, Jingbo Zhu</author><pubDate>Fri, 21 Jun 2024 15:23:57 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.15178v1</guid></item><item><title>Enhancing Idiomatic Representation in Multiple Languages via an Adaptive Contrastive Triplet Loss</title><link>http://arxiv.org/abs/2406.15175v1</link><description>Accurately modeling idiomatic or non-compositional language has been alongstanding challenge in Natural Language Processing (NLP). This is partlybecause these expressions do not derive their meanings solely from theirconstituent words, but also due to the scarcity of relevant data resources, andtheir impact on the performance of downstream tasks such as machine translationand simplification. In this paper we propose an approach to model idiomaticityeffectively using a triplet loss that incorporates the asymmetric contributionof components words to an idiomatic meaning for training language models byusing adaptive contrastive learning and resampling miners to build anidiomatic-aware learning objective. Our proposed method is evaluated on aSemEval challenge and outperforms previous alternatives significantly in manymetrics.</description><author>Wei He, Marco Idiart, Carolina Scarton, Aline Villavicencio</author><pubDate>Fri, 21 Jun 2024 15:21:41 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.15175v1</guid></item><item><title>Évaluation des capacités de réponse de larges modèles de langage (LLM) pour des questions d'historiens</title><link>http://arxiv.org/abs/2406.15173v1</link><description>Large Language Models (LLMs) like ChatGPT or Bard have revolutionizedinformation retrieval and captivated the audience with their ability togenerate custom responses in record time, regardless of the topic. In thisarticle, we assess the capabilities of various LLMs in producing reliable,comprehensive, and sufficiently relevant responses about historical facts inFrench. To achieve this, we constructed a testbed comprising numeroushistory-related questions of varying types, themes, and levels of difficulty.Our evaluation of responses from ten selected LLMs reveals numerousshortcomings in both substance and form. Beyond an overall insufficientaccuracy rate, we highlight uneven treatment of the French language, as well asissues related to verbosity and inconsistency in the responses provided byLLMs.</description><author>Mathieu Chartier, Nabil Dakkoune, Guillaume Bourgeois, Stéphane Jean</author><pubDate>Fri, 21 Jun 2024 15:19:57 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.15173v1</guid></item><item><title>Multimodal Deformable Image Registration for Long-COVID Analysis Based on Progressive Alignment and Multi-perspective Loss</title><link>http://arxiv.org/abs/2406.15172v1</link><description>Long COVID is characterized by persistent symptoms, particularly pulmonaryimpairment, which necessitates advanced imaging for accurate diagnosis.Hyperpolarised Xenon-129 MRI (XeMRI) offers a promising avenue by visualisinglung ventilation, perfusion, as well as gas transfer. Integrating functionaldata from XeMRI with structural data from Computed Tomography (CT) is crucialfor comprehensive analysis and effective treatment strategies in long COVID,requiring precise data alignment from those complementary imaging modalities.To this end, CT-MRI registration is an essential intermediate step, given thesignificant challenges posed by the direct alignment of CT and Xe-MRI.Therefore, we proposed an end-to-end multimodal deformable image registrationmethod that achieves superior performance for aligning long-COVID lung CT andproton density MRI (pMRI) data. Moreover, our method incorporates a novelMulti-perspective Loss (MPL) function, enhancing state-of-the-art deep learningmethods for monomodal registration by making them adaptable for multimodaltasks. The registration results achieve a Dice coefficient score of 0.913,indicating a substantial improvement over the state-of-the-art multimodal imageregistration techniques. Since the XeMRI and pMRI images are acquired in thesame sessions and can be roughly aligned, our results facilitate subsequentregistration between XeMRI and CT, thereby potentially enhancing clinicaldecision-making for long COVID management.</description><author>Jiahua Li, James T. Grist, Fergus V. Gleeson, Bartłomiej W. Papież</author><pubDate>Fri, 21 Jun 2024 15:19:18 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.15172v1</guid></item><item><title>Multi-view Disentanglement for Reinforcement Learning with Multiple Cameras</title><link>http://arxiv.org/abs/2404.14064v2</link><description>The performance of image-based Reinforcement Learning (RL) agents can varydepending on the position of the camera used to capture the images. Training onmultiple cameras simultaneously, including a first-person egocentric camera,can leverage information from different camera perspectives to improve theperformance of RL. However, hardware constraints may limit the availability ofmultiple cameras in real-world deployment. Additionally, cameras may becomedamaged in the real-world preventing access to all cameras that were usedduring training. To overcome these hardware constraints, we propose Multi-ViewDisentanglement (MVD), which uses multiple cameras to learn a policy that isrobust to a reduction in the number of cameras to generalise to any singlecamera from the training set. Our approach is a self-supervised auxiliary taskfor RL that learns a disentangled representation from multiple cameras, with ashared representation that is aligned across all cameras to allowgeneralisation to a single camera, and a private representation that iscamera-specific. We show experimentally that an RL agent trained on a singlethird-person camera is unable to learn an optimal policy in many control tasks;but, our approach, benefiting from multiple cameras during training, is able tosolve the task using only the same single third-person camera.</description><author>Mhairi Dunion, Stefano V. Albrecht</author><pubDate>Fri, 21 Jun 2024 15:12:54 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.14064v2</guid></item><item><title>This actually looks like that: Proto-BagNets for local and global interpretability-by-design</title><link>http://arxiv.org/abs/2406.15168v1</link><description>Interpretability is a key requirement for the use of machine learning modelsin high-stakes applications, including medical diagnosis. Explaining black-boxmodels mostly relies on post-hoc methods that do not faithfully reflect themodel's behavior. As a remedy, prototype-based networks have been proposed, buttheir interpretability is limited as they have been shown to provide coarse,unreliable, and imprecise explanations.In this work, we introduceProto-BagNets, an interpretable-by-design prototype-based model that combinesthe advantages of bag-of-local feature models and prototype learning to providemeaningful, coherent, and relevant prototypical parts needed for accurate andinterpretable image classification tasks. We evaluated the Proto-BagNet fordrusen detection on publicly available retinal OCT data. The Proto-BagNetperformed comparably to the state-of-the-art interpretable andnon-interpretable models while providing faithful, accurate, and clinicallymeaningful local and global explanations. The code is available athttps://github.com/kdjoumessi/Proto-BagNets.</description><author>Kerol Djoumessi, Bubacarr Bah, Laura Kühlewein, Philipp Berens, Lisa Koch</author><pubDate>Fri, 21 Jun 2024 15:12:15 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.15168v1</guid></item><item><title>A Syntax-Injected Approach for Faster and More Accurate Sentiment Analysis</title><link>http://arxiv.org/abs/2406.15163v1</link><description>Sentiment Analysis (SA) is a crucial aspect of Natural Language Processing(NLP), addressing subjective assessments in textual content. Syntactic parsingis useful in SA because explicit syntactic information can improve accuracywhile providing explainability, but it tends to be a computational bottleneckin practice due to the slowness of parsing algorithms. This paper addressessaid bottleneck by using a SEquence Labeling Syntactic Parser (SELSP) to injectsyntax into SA. By treating dependency parsing as a sequence labeling problem,we greatly enhance the speed of syntax-based SA. SELSP is trained and evaluatedon a ternary polarity classification task, demonstrating its faster performanceand better accuracy in polarity prediction tasks compared to conventionalparsers like Stanza and to heuristic approaches that use shallow syntacticrules for SA like VADER. This increased speed and improved accuracy make SELSPparticularly appealing to SA practitioners in both research and industry. Inaddition, we test several sentiment dictionaries on our SELSP to see which oneimproves the performance in polarity prediction tasks. Moreover, we compare theSELSP with Transformer-based models trained on a 5-label classification task.The results show that dictionaries that capture polarity judgment variationprovide better results than dictionaries that ignore polarity judgmentvariation. Moreover, we show that SELSP is considerably faster thanTransformer-based models in polarity prediction tasks.</description><author>Muhammad Imran, Olga Kellert, Carlos Gómez-Rodríguez</author><pubDate>Fri, 21 Jun 2024 15:08:25 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.15163v1</guid></item><item><title>Stochastic Optimisation Framework using the Core Imaging Library and Synergistic Image Reconstruction Framework for PET Reconstruction</title><link>http://arxiv.org/abs/2406.15159v1</link><description>We introduce a stochastic framework into the open--source Core ImagingLibrary (CIL) which enables easy development of stochastic algorithms. Fivesuch algorithms from the literature are developed, Stochastic Gradient Descent,Stochastic Average Gradient (-Am\'elior\'e), (Loopless) Stochastic VarianceReduced Gradient. We showcase the functionality of the framework with acomparative study against a deterministic algorithm on a simulated 2D PETdataset, with the use of the open-source Synergistic Image ReconstructionFramework. We observe that stochastic optimisation methods can converge infewer passes of the data than a standard deterministic algorithm.</description><author>Evangelos Papoutsellis, Casper da Costa-Luis, Daniel Deidda, Claire Delplancke, Margaret Duff, Gemma Fardell, Ashley Gillman, Jakob S. Jørgensen, Zeljko Kereta, Evgueni Ovtchinnikov, Edoardo Pasca, Georg Schramm, Kris Thielemans</author><pubDate>Fri, 21 Jun 2024 15:05:02 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.15159v1</guid></item><item><title>ApiQ: Finetuning of 2-Bit Quantized Large Language Model</title><link>http://arxiv.org/abs/2402.05147v3</link><description>Memory-efficient finetuning of large language models (LLMs) has recentlyattracted huge attention with the increasing size of LLMs, primarily due to theconstraints posed by GPU memory limitations and the effectiveness of thesemethods compared to full finetuning. Despite the advancements, currentstrategies for memory-efficient finetuning, such as QLoRA, exhibit inconsistentperformance across diverse bit-width quantizations and multifaceted tasks. Thisinconsistency largely stems from the detrimental impact of the quantizationprocess on preserved knowledge, leading to catastrophic forgetting andundermining the utilization of pretrained models for finetuning purposes. Inthis work, we introduce a novel quantization framework, ApiQ, designed torestore the lost information from quantization by concurrently initializing theLoRA components and quantizing the weights of LLMs. This approach ensures themaintenance of the original LLM's activation precision while mitigating theerror propagation from shallower into deeper layers. Through comprehensiveevaluations conducted on a spectrum of language tasks with various LLMs, ApiQdemonstrably minimizes activation error during quantization. Consequently, itconsistently achieves superior finetuning results across various bit-widths.</description><author>Baohao Liao, Christian Herold, Shahram Khadivi, Christof Monz</author><pubDate>Fri, 21 Jun 2024 15:03:48 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.05147v3</guid></item><item><title>Perks and Pitfalls of Faithfulness in Regular, Self-Explainable and Domain Invariant GNNs</title><link>http://arxiv.org/abs/2406.15156v1</link><description>As Graph Neural Networks (GNNs) become more pervasive, it becomes paramountto build robust tools for computing explanations of their predictions. A keydesideratum is that these explanations are faithful, i.e., that they portray anaccurate picture of the GNN's reasoning process. A number of differentfaithfulness metrics exist, begging the question of what faithfulness isexactly, and what its properties are. We begin by showing that existing metricsare not interchangeable -- i.e., explanations attaining high faithfulnessaccording to one metric may be unfaithful according to others -- and can besystematically insensitive to important properties of the explanation, andsuggest how to address these issues. We proceed to show that, surprisingly,optimizing for faithfulness is not always a sensible design goal. Specifically,we show that for injective regular GNN architectures, perfectly faithfulexplanations are completely uninformative. The situation is different formodular GNNs, such as self-explainable and domain-invariant architectures,where optimizing faithfulness does not compromise informativeness, and is alsounexpectedly tied to out-of-distribution generalization.</description><author>Steve Azzolin, Antonio Longa, Stefano Teso, Andrea Passerini</author><pubDate>Fri, 21 Jun 2024 15:01:23 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.15156v1</guid></item><item><title>Are LLMs Naturally Good at Synthetic Tabular Data Generation?</title><link>http://arxiv.org/abs/2406.14541v2</link><description>Large language models (LLMs) have demonstrated their prowess in generatingsynthetic text and images; however, their potential for generating tabular data-- arguably the most common data type in business and scientific applications-- is largely underexplored. This paper demonstrates that LLMs, used as-is, orafter traditional fine-tuning, are severely inadequate as synthetic tablegenerators. Due to the autoregressive nature of LLMs, fine-tuning with randomorder permutation runs counter to the importance of modeling functionaldependencies, and renders LLMs unable to model conditional mixtures ofdistributions (key to capturing real world constraints). We showcase how LLMscan be made to overcome some of these deficiencies by making thempermutation-aware.</description><author>Shengzhe Xu, Cho-Ting Lee, Mandar Sharma, Raquib Bin Yousuf, Nikhil Muralidhar, Naren Ramakrishnan</author><pubDate>Fri, 21 Jun 2024 15:00:02 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.14541v2</guid></item><item><title>CantTalkAboutThis: Aligning Language Models to Stay on Topic in Dialogues</title><link>http://arxiv.org/abs/2404.03820v2</link><description>Recent advancements in instruction-tuning datasets have predominantly focusedon specific tasks like mathematical or logical reasoning. There has been anotable gap in data designed for aligning language models to maintain topicrelevance in conversations - a critical aspect for deploying chatbots toproduction. We introduce the CantTalkAboutThis dataset to help language modelsremain focused on the subject at hand during task-oriented interactions. Itconsists of synthetic dialogues on a wide range of conversation topics fromdifferent domains. These dialogues are interspersed with distractor turns thatintentionally divert the chatbot from the predefined topic. Fine-tuninglanguage models on this dataset helps make them resilient to deviating from therole assigned and improves their ability to maintain topical coherence comparedto general-purpose instruction-tuned LLMs like GPT-4-turbo andMixtral-Instruct. Additionally, preliminary observations suggest that trainingmodels on this dataset also enhance their performance on fine-grainedinstruction following tasks, including safety alignment.</description><author>Makesh Narsimhan Sreedhar, Traian Rebedea, Shaona Ghosh, Jiaqi Zeng, Christopher Parisien</author><pubDate>Fri, 21 Jun 2024 14:57:11 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.03820v2</guid></item><item><title>Generative Topological Networks</title><link>http://arxiv.org/abs/2406.15152v1</link><description>Generative models have seen significant advancements in recent years, yetoften remain challenging and costly to train and use. We introduce GenerativeTopological Networks (GTNs) -- a new class of generative models that addressesthese shortcomings. GTNs are trained deterministically using a simplesupervised learning approach grounded in topology theory. GTNs are fast totrain, and require only a single forward pass in a standard feedforward neuralnetwork to generate samples. We demonstrate the strengths of GTNs in severaldatasets, including MNIST, celebA and the Hands and Palm Images dataset.Finally, the theory behind GTNs offers insights into how to train generativemodels for improved performance.</description><author>Alona Levy-Jurgenson, Zohar Yakhini</author><pubDate>Fri, 21 Jun 2024 14:55:34 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.15152v1</guid></item><item><title>Speech foundation models in healthcare: Effect of layer selection on pathological speech feature prediction</title><link>http://arxiv.org/abs/2402.01796v2</link><description>Accurately extracting clinical information from speech is critical to thediagnosis and treatment of many neurological conditions. As such, there isinterest in leveraging AI for automatic, objective assessments of clinicalspeech to facilitate diagnosis and treatment of speech disorders. We exploretransfer learning using foundation models, focusing on the impact of layerselection for the downstream task of predicting pathological speech features.We find that selecting an optimal layer can greatly improve performance (~15.8%increase in balanced accuracy per feature as compared to worst layer, ~13.6%increase as compared to final layer), though the best layer varies by predictedfeature and does not always generalize well to unseen data. A learned weightedsum offers comparable performance to the average best layer in-distribution(only ~1.2% lower) and had strong generalization for out-of-distribution data(only 1.5% lower than the average best layer).</description><author>Daniela A. Wiepert, Rene L. Utianski, Joseph R. Duffy, John L. Stricker, Leland R. Barnard, David T. Jones, Hugo Botha</author><pubDate>Fri, 21 Jun 2024 14:49:56 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.01796v2</guid></item><item><title>Gaussian Splatting to Real World Flight Navigation Transfer with Liquid Networks</title><link>http://arxiv.org/abs/2406.15149v1</link><description>Simulators are powerful tools for autonomous robot learning as they offerscalable data generation, flexible design, and optimization of trajectories.However, transferring behavior learned from simulation data into the real worldproves to be difficult, usually mitigated with compute-heavy domainrandomization methods or further model fine-tuning. We present a method toimprove generalization and robustness to distribution shifts in sim-to-realvisual quadrotor navigation tasks. To this end, we first build a simulator byintegrating Gaussian Splatting with quadrotor flight dynamics, and then, trainrobust navigation policies using Liquid neural networks. In this way, we obtaina full-stack imitation learning protocol that combines advances in 3D Gaussiansplatting radiance field rendering, crafty programming of expert demonstrationtraining data, and the task understanding capabilities of Liquid networks.Through a series of quantitative flight tests, we demonstrate the robusttransfer of navigation skills learned in a single simulation scene directly tothe real world. We further show the ability to maintain performance beyond thetraining environment under drastic distribution and physical environmentchanges. Our learned Liquid policies, trained on single target manoeuvrescurated from a photorealistic simulated indoor flight only, generalize tomulti-step hikes onboard a real hardware platform outdoors.</description><author>Alex Quach, Makram Chahine, Alexander Amini, Ramin Hasani, Daniela Rus</author><pubDate>Fri, 21 Jun 2024 14:48:37 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.15149v1</guid></item><item><title>Branches: A Fast Dynamic Programming and Branch &amp; Bound Algorithm for Optimal Decision Trees</title><link>http://arxiv.org/abs/2406.02175v2</link><description>Decision Tree Learning is a fundamental problem for Interpretable MachineLearning, yet it poses a formidable optimization challenge. Despite numerousefforts dating back to the early 1990's, practical algorithms have onlyrecently emerged, primarily leveraging Dynamic Programming (DP) and Branch &amp;Bound (B&amp;B) techniques. These breakthroughs led to the development of twodistinct approaches. Algorithms like DL8.5 and MurTree operate on the space ofnodes (or branches), they are very fast, but do not penalise complex DecisionTrees, i.e. they do not solve for sparsity. On the other hand, algorithms likeOSDT and GOSDT operate on the space of Decision Trees, they solve for sparsitybut at the detriment of speed. In this work, we introduce Branches, a novelalgorithm that integrates the strengths of both paradigms. Leveraging DP andB&amp;B, Branches achieves exceptional speed while also solving for sparsity.Central to its efficiency is a novel analytical bound enabling substantialpruning of the search space. Furthermore, Branches does not necessitate binaryfeatures. Theoretical analysis demonstrates that Branches has a lowercomplexity bound compared to state-of-the-art methods, a claim validatedthrough extensive empirical evaluation. Our results illustrate that Branchesoutperforms the state of the art in terms of speed and number of iterationswhile consistently yielding optimal Decision Trees.</description><author>Ayman Chaouki, Jesse Read, Albert Bifet</author><pubDate>Fri, 21 Jun 2024 14:45:51 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.02175v2</guid></item><item><title>Uncertainty-Aware Probabilistic Graph Neural Networks for Road-Level Traffic Accident Prediction</title><link>http://arxiv.org/abs/2309.05072v2</link><description>Traffic accidents present substantial challenges to human safety andsocioeconomic development in urban areas. Developing a reliable and responsibletraffic accident prediction model is crucial to addressing growing publicsafety concerns and enhancing the safety of urban mobility systems. Traditionalmethods face limitations at fine spatiotemporal scales due to the sporadicnature of highrisk accidents and the predominance of nonaccidentcharacteristics. Furthermore, while most current models show promisingoccurrence prediction, they overlook the uncertainties arising from theinherent nature of accidents, and then fail to adequately map the hierarchicalranking of accident risk values for more precise insights. To address theseissues, we introduce the Spatiotemporal ZeroInflated Tweedie Graph NeuralNetwork ,STZITDGNN, the first uncertainty-aware probabilistic graph deeplearning model in roadlevel traffic accident prediction for multi-steps. Thismodel integrates the interpretability of the statistical Tweedie family modeland the expressive power of graph neural networks. Its decoder innovativelyemploys a compound Tweedie model, a Poisson distribution to model the frequencyof accident occurrences and a Gamma distribution to assess injury severity,supplemented by a zeroinflated component to effectively identify exessivenon-incident instances. Empirical tests using realworld traffic data fromLondon, UK, demonstrate that the STZITDGNN surpasses other baseline modelsacross multiple benchmarks and metrics, including accident risk valueprediction, uncertainty minimisation, nonaccident road identification andaccident occurrence accuracy. Our study demonstrates that STZTIDGNN caneffectively inform targeted road monitoring, thereby improving urban roadsafety strategies.</description><author>Xiaowei Gao, Xinke Jiang, Dingyi Zhuang, Huanfa Chen, Shenhao Wang, Stephen Law, James Haworth</author><pubDate>Fri, 21 Jun 2024 14:45:44 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2309.05072v2</guid></item><item><title>Chain-of-Thought Unfaithfulness as Disguised Accuracy</title><link>http://arxiv.org/abs/2402.14897v3</link><description>Understanding the extent to which Chain-of-Thought (CoT) generations alignwith a large language model's (LLM) internal computations is critical fordeciding whether to trust an LLM's output. As a proxy for CoT faithfulness,Lanham et al. (2023) propose a metric that measures a model's dependence on itsCoT for producing an answer. Within a single family of proprietary models, theyfind that LLMs exhibit a scaling-then-inverse-scaling relationship betweenmodel size and their measure of faithfulness, and that a 13 billion parametermodel exhibits increased faithfulness compared to models ranging from 810million to 175 billion parameters in size. We evaluate whether these resultsgeneralize as a property of all LLMs. We replicate the experimental setup intheir section focused on scaling experiments with three different families ofmodels and, under specific conditions, successfully reproduce the scalingtrends for CoT faithfulness they report. However, after normalizing the metricto account for a model's bias toward certain answer choices, unfaithfulnessdrops significantly for smaller less-capable models. This normalizedfaithfulness metric is also strongly correlated ($R^2$=0.74) with accuracy,raising doubts about its validity for evaluating faithfulness.</description><author>Oliver Bentham, Nathan Stringham, Ana Marasović</author><pubDate>Fri, 21 Jun 2024 14:39:14 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.14897v3</guid></item><item><title>KalMamba: Towards Efficient Probabilistic State Space Models for RL under Uncertainty</title><link>http://arxiv.org/abs/2406.15131v1</link><description>Probabilistic State Space Models (SSMs) are essential for ReinforcementLearning (RL) from high-dimensional, partial information as they provideconcise representations for control. Yet, they lack the computationalefficiency of their recent deterministic counterparts such as S4 or Mamba. Wepropose KalMamba, an efficient architecture to learn representations for RLthat combines the strengths of probabilistic SSMs with the scalability ofdeterministic SSMs. KalMamba leverages Mamba to learn the dynamics parametersof a linear Gaussian SSM in a latent space. Inference in this latent spaceamounts to standard Kalman filtering and smoothing. We realize these operationsusing parallel associative scanning, similar to Mamba, to obtain a principled,highly efficient, and scalable probabilistic SSM. Our experiments show thatKalMamba competes with state-of-the-art SSM approaches in RL whilesignificantly improving computational efficiency, especially on longerinteraction sequences.</description><author>Philipp Becker, Niklas Freymuth, Gerhard Neumann</author><pubDate>Fri, 21 Jun 2024 14:27:36 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.15131v1</guid></item><item><title>Assessing Good, Bad and Ugly Arguments Generated by ChatGPT: a New Dataset, its Methodology and Associated Tasks</title><link>http://arxiv.org/abs/2406.15130v1</link><description>The recent success of Large Language Models (LLMs) has sparked concerns abouttheir potential to spread misinformation. As a result, there is a pressing needfor tools to identify ``fake arguments'' generated by such models. To createthese tools, examples of texts generated by LLMs are needed. This paperintroduces a methodology to obtain good, bad and ugly arguments fromargumentative essays produced by ChatGPT, OpenAI's LLM. We then describe anovel dataset containing a set of diverse arguments, ArGPT. We assess theeffectiveness of our dataset and establish baselines for severalargumentation-related tasks. Finally, we show that the artificially generateddata relates well to human argumentation and thus is useful as a tool to trainand test systems for the defined tasks.</description><author>Victor Hugo Nascimento Rocha, Igor Cataneo Silveira, Paulo Pirozelli, Denis Deratani Mauá, Fabio Gagliardi Cozman</author><pubDate>Fri, 21 Jun 2024 14:27:10 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.15130v1</guid></item></channel></rss>