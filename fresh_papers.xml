<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/"><channel><title>Arxivfresh papers</title><link></link><description>Arxiv paper</description><language>en-US</language><lastBuildDate>Tue, 27 Aug 2024 01:00:12 GMT</lastBuildDate><generator>rfeed v1.0.0</generator><docs>https://github.com/svpino/rfeed/blob/master/README.md</docs><item><title>On the good reliability of an interval-based metric to validate prediction uncertainty for machine learning regression tasks</title><link>http://arxiv.org/abs/2408.13089v2</link><description>This short study presents an opportunistic approach to a (more) reliablevalidation method for prediction uncertainty average calibration. Consideringthat variance-based calibration metrics (ZMS, NLL, RCE...) are quite sensitiveto the presence of heavy tails in the uncertainty and error distributions, ashift is proposed to an interval-based metric, the Prediction Interval CoverageProbability (PICP). It is shown on a large ensemble of molecular propertiesdatasets that (1) sets of z-scores are well represented by Student's-$t(\nu)$distributions, $\nu$ being the number of degrees of freedom; (2) accurateestimation of 95 $\%$ prediction intervals can be obtained by the simple$2\sigma$ rule for $\nu&gt;3$; and (3) the resulting PICPs are more quickly andreliably tested than variance-based calibration metrics. Overall, this methodenables to test 20 $\%$ more datasets than ZMS testing. Conditional calibrationis also assessed using the PICP approach.</description><author>Pascal Pernot</author><pubDate>Mon, 26 Aug 2024 06:40:07 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.13089v2</guid></item><item><title>Zeoformer: Coarse-Grained Periodic Graph Transformer for OSDA-Zeolite Affinity Prediction</title><link>http://arxiv.org/abs/2408.12984v2</link><description>To date, the International Zeolite Association Structure Commission (IZA-SC)has cataloged merely 255 distinct zeolite structures, with millions oftheoretically possible structures yet to be discovered. The synthesis of aspecific zeolite typically necessitates the use of an organicstructure-directing agent (OSDA), since the selectivity for a particularzeolite is largely determined by the affinity between the OSDA and the zeolite.Therefore, finding the best affinity OSDA-zeolite pair is the key to thesynthesis of targeted zeolite. However, OSDA-zeolite pairs frequently exhibitcomplex geometric structures, i.e., a complex crystal structure formed by alarge number of atoms. Although some existing machine learning methods canrepresent the periodicity of crystals, they cannot accurately represent crystalstructures with local variability. To address this issue, we propose a novelapproach called Zeoformer, which can effectively represent coarse-grainedcrystal periodicity and fine-grained local variability. Zeoformer reconstructsthe unit cell centered around each atom and encodes the pairwise distancesbetween this central atom and other atoms within the reconstructed unit cell.The introduction of pairwise distances within the reconstructed unit cell moreeffectively represents the overall structure of the unit cell and thedifferences between different unit cells, enabling the model to more accuratelyand efficiently predict the properties of OSDA-zeolite pairs and generalcrystal structures. Through comprehensive evaluation, our Zeoformer modeldemonstrates the best performance on OSDA-zeolite pair datasets and two typesof crystal material datasets.</description><author>Xiangxiang Shen, Zheng Wan, Lingfeng Wen, Licheng Sun, Ou Yang Ming Jie, Xuan Tang, Xian Zeng, Mingsong Chen, Xiao He, Xian Wei</author><pubDate>Mon, 26 Aug 2024 02:42:23 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.12984v2</guid></item><item><title>MME-RealWorld: Could Your Multimodal LLM Challenge High-Resolution Real-World Scenarios that are Difficult for Humans?</title><link>http://arxiv.org/abs/2408.13257v1</link><description>Comprehensive evaluation of Multimodal Large Language Models (MLLMs) hasrecently garnered widespread attention in the research community. However, weobserve that existing benchmarks present several common barriers that make itdifficult to measure the significant challenges that models face in the realworld, including: 1) small data scale leads to a large performance variance; 2)reliance on model-based annotations results in restricted data quality; 3)insufficient task difficulty, especially caused by the limited imageresolution. To tackle these issues, we introduce MME-RealWorld. Specifically,we collect more than $300$K images from public datasets and the Internet,filtering $13,366$ high-quality images for annotation. This involves theefforts of professional $25$ annotators and $7$ experts in MLLMs, contributingto $29,429$ question-answer pairs that cover $43$ subtasks across $5$real-world scenarios, extremely challenging even for humans. As far as we know,MME-RealWorld is the largest manually annotated benchmark to date, featuringthe highest resolution and a targeted focus on real-world applications. Wefurther conduct a thorough evaluation involving $28$ prominent MLLMs, such asGPT-4o, Gemini 1.5 Pro, and Claude 3.5 Sonnet. Our results show that even themost advanced models struggle with our benchmarks, where none of them reach$60\%$ accuracy. The challenges of perceiving high-resolution images andunderstanding complex real-world scenarios remain urgent issues to beaddressed. The data and evaluation code are released athttps://mme-realworld.github.io/ .</description><author>Yi-Fan Zhang, Huanyu Zhang, Haochen Tian, Chaoyou Fu, Shuangqing Zhang, Junfei Wu, Feng Li, Kun Wang, Qingsong Wen, Zhang Zhang, Liang Wang, Rong Jin, Tieniu Tan</author><pubDate>Fri, 23 Aug 2024 17:59:51 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.13257v1</guid></item><item><title>How Diffusion Models Learn to Factorize and Compose</title><link>http://arxiv.org/abs/2408.13256v1</link><description>Diffusion models are capable of generating photo-realistic images thatcombine elements which likely do not appear together in the training set,demonstrating the ability to compositionally generalize. Nonetheless, theprecise mechanism of compositionality and how it is acquired through trainingremains elusive. Inspired by cognitive neuroscientific approaches, we considera highly reduced setting to examine whether and when diffusion models learnsemantically meaningful and factorized representations of composable features.We performed extensive controlled experiments on conditional DenoisingDiffusion Probabilistic Models (DDPMs) trained to generate various forms of 2DGaussian data. We found that the models learn factorized but not fullycontinuous manifold representations for encoding continuous features ofvariation underlying the data. With such representations, models demonstratesuperior feature compositionality but limited ability to interpolate overunseen values of a given feature. Our experimental results further demonstratethat diffusion models can attain compositionality with few compositionalexamples, suggesting a more efficient way to train DDPMs. Finally, we connectmanifold formation in diffusion models to percolation theory in physics,offering insight into the sudden onset of factorized representation learning.Our thorough toy experiments thus contribute a deeper understanding of howdiffusion models capture compositional structure in data.</description><author>Qiyao Liang, Ziming Liu, Mitchell Ostrow, Ila Fiete</author><pubDate>Fri, 23 Aug 2024 17:59:03 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.13256v1</guid></item><item><title>Ensemble Modeling of Multiple Physical Indicators to Dynamically Phenotype Autism Spectrum Disorder</title><link>http://arxiv.org/abs/2408.13255v1</link><description>Early detection of autism, a neurodevelopmental disorder marked by socialcommunication challenges, is crucial for timely intervention. Recentadvancements have utilized naturalistic home videos captured via the mobileapplication GuessWhat. Through interactive games played between children andtheir guardians, GuessWhat has amassed over 3,000 structured videos from 382children, both diagnosed with and without Autism Spectrum Disorder (ASD). Thiscollection provides a robust dataset for training computer vision models todetect ASD-related phenotypic markers, including variations in emotionalexpression, eye contact, and head movements. We have developed a protocol tocurate high-quality videos from this dataset, forming a comprehensive trainingset. Utilizing this set, we trained individual LSTM-based models using eyegaze, head positions, and facial landmarks as input features, achieving testAUCs of 86%, 67%, and 78%, respectively. To boost diagnostic accuracy, weapplied late fusion techniques to create ensemble models, improving the overallAUC to 90%. This approach also yielded more equitable results across differentgenders and age groups. Our methodology offers a significant step forward inthe early detection of ASD by potentially reducing the reliance on subjectiveassessments and making early identification more accessibly and equitable.</description><author>Marie Huynh, Aaron Kline, Saimourya Surabhi, Kaitlyn Dunlap, Onur Cezmi Mutlu, Mohammadmahdi Honarmand, Parnian Azizian, Peter Washington, Dennis P. Wall</author><pubDate>Fri, 23 Aug 2024 17:55:58 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.13255v1</guid></item><item><title>Search-Adaptor: Embedding Customization for Information Retrieval</title><link>http://arxiv.org/abs/2310.08750v3</link><description>Embeddings extracted by pre-trained Large Language Models (LLMs) havesignificant potential to improve information retrieval and search. Beyond thezero-shot setup in which they are being conventionally used, being able to takeadvantage of the information from the relevant query-corpus paired data canfurther boost the LLM capabilities. In this paper, we propose a novel method,Search-Adaptor, for customizing LLMs for information retrieval in an efficientand robust way. Search-Adaptor modifies the embeddings generated by pre-trainedLLMs, and can be integrated with any LLM, including those only available viaprediction APIs. On multiple English, multilingual, and multimodal retrievaldatasets, we show consistent and significant performance benefits forSearch-Adaptor -- e.g., more than 5% improvements for Google Embedding APIs innDCG@10 averaged over 14 BEIR datasets.</description><author>Jinsung Yoon, Sercan O Arik, Yanfei Chen, Tomas Pfister</author><pubDate>Fri, 23 Aug 2024 17:55:12 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.08750v3</guid></item><item><title>MagicDec: Breaking the Latency-Throughput Tradeoff for Long Context Generation with Speculative Decoding</title><link>http://arxiv.org/abs/2408.11049v3</link><description>Large Language Models (LLMs) have become more prevalent in long-contextapplications such as interactive chatbots, document analysis, and agentworkflows, but it is challenging to serve long-context requests with lowlatency and high throughput. Speculative decoding (SD) is a widely usedtechnique to reduce latency without sacrificing performance but theconventional wisdom suggests that its efficacy is limited to small batch sizes.In MagicDec, we show that surprisingly SD can achieve speedup even for a highthroughput inference regime for moderate to long sequences. More interestingly,an intelligent drafting strategy can achieve better speedup with increasingbatch size based on our rigorous analysis. MagicDec first identifies thebottleneck shifts with increasing batch size and sequence length, and usesthese insights to deploy speculative decoding more effectively for highthroughput inference. Then, it leverages draft models with sparse KV cache toaddress the KV bottleneck that scales with both sequence length and batch size.This finding underscores the broad applicability of speculative decoding inlong-context serving, as it can enhance throughput and reduce latency withoutcompromising accuracy. For moderate to long sequences, we demonstrate up to 2xspeedup for LLaMA-2-7B-32K and 1.84x speedup for LLaMA-3.1-8B when servingbatch sizes ranging from 32 to 256 on 8 NVIDIA A100 GPUs. The code is availableat https://github.com/Infini-AI-Lab/MagicDec/.</description><author>Jian Chen, Vashisth Tiwari, Ranajoy Sadhukhan, Zhuoming Chen, Jinyuan Shi, Ian En-Hsu Yen, Beidi Chen</author><pubDate>Fri, 23 Aug 2024 17:54:34 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.11049v3</guid></item><item><title>Domain-specific long text classification from sparse relevant information</title><link>http://arxiv.org/abs/2408.13253v1</link><description>Large Language Models have undoubtedly revolutionized the Natural LanguageProcessing field, the current trend being to promote one-model-for-all tasks(sentiment analysis, translation, etc.). However, the statistical mechanisms atwork in the larger language models struggle to exploit the relevant informationwhen it is very sparse, when it is a weak signal. This is the case, forexample, for the classification of long domain-specific documents, when therelevance relies on a single relevant word or on very few relevant words fromtechnical jargon. In the medical domain, it is essential to determine whether agiven report contains critical information about a patient's condition. Thiscritical information is often based on one or few specific isolated terms. Inthis paper, we propose a hierarchical model which exploits a short list ofpotential target terms to retrieve candidate sentences and represent them intothe contextualized embedding of the target term(s) they contain. A pooling ofthe term(s) embedding(s) entails the document representation to be classified.We evaluate our model on one public medical document benchmark in English andon one private French medical dataset. We show that our narrower hierarchicalmodel is better than larger language models for retrieving relevant longdocuments in a domain-specific context.</description><author>Célia D'Cruz, Jean-Marc Bereder, Frédéric Precioso, Michel Riveill</author><pubDate>Fri, 23 Aug 2024 17:54:19 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.13253v1</guid></item><item><title>LayerPano3D: Layered 3D Panorama for Hyper-Immersive Scene Generation</title><link>http://arxiv.org/abs/2408.13252v1</link><description>3D immersive scene generation is a challenging yet critical task in computervision and graphics. A desired virtual 3D scene should 1) exhibitomnidirectional view consistency, and 2) allow for free exploration in complexscene hierarchies. Existing methods either rely on successive scene expansionvia inpainting or employ panorama representation to represent large FOV sceneenvironments. However, the generated scene suffers from semantic drift duringexpansion and is unable to handle occlusion among scene hierarchies. To tacklethese challenges, we introduce LayerPano3D, a novel framework for full-view,explorable panoramic 3D scene generation from a single text prompt. Our keyinsight is to decompose a reference 2D panorama into multiple layers atdifferent depth levels, where each layer reveals the unseen space from thereference views via diffusion prior. LayerPano3D comprises multiple dedicateddesigns: 1) we introduce a novel text-guided anchor view synthesis pipeline forhigh-quality, consistent panorama generation. 2) We pioneer the Layered 3DPanorama as underlying representation to manage complex scene hierarchies andlift it into 3D Gaussians to splat detailed 360-degree omnidirectional sceneswith unconstrained viewing paths. Extensive experiments demonstrate that ourframework generates state-of-the-art 3D panoramic scene in both full viewconsistency and immersive exploratory experience. We believe that LayerPano3Dholds promise for advancing 3D panoramic scene creation with numerousapplications.</description><author>Shuai Yang, Jing Tan, Mengchen Zhang, Tong Wu, Yixuan Li, Gordon Wetzstein, Ziwei Liu, Dahua Lin</author><pubDate>Fri, 23 Aug 2024 17:50:23 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.13252v1</guid></item><item><title>Re-evaluation of Face Anti-spoofing Algorithm in Post COVID-19 Era Using Mask Based Occlusion Attack</title><link>http://arxiv.org/abs/2408.13251v1</link><description>Face anti-spoofing algorithms play a pivotal role in the robust deployment offace recognition systems against presentation attacks. Conventionally, fullfacial images are required by such systems to correctly authenticateindividuals, but the widespread requirement of masks due to the currentCOVID-19 pandemic has introduced new challenges for these biometricauthentication systems. Hence, in this work, we investigate the performance ofpresentation attack detection (PAD) algorithms under synthetic facialocclusions using masks and glasses. We have used five variants of masks tocover the lower part of the face with varying coverage areas (low-coverage,medium-coverage, high-coverage, round coverage), and 3D cues. We have also useddifferent variants of glasses that cover the upper part of the face. Wesystematically tested the performance of four PAD algorithms under theseocclusion attacks using a benchmark dataset. We have specifically looked atfour different baseline PAD algorithms that focus on, texture, image quality,frame difference/motion, and abstract features through a convolutional neuralnetwork (CNN). Additionally we have introduced a new hybrid model that uses CNNand local binary pattern textures. Our experiment shows that adding theocclusions significantly degrades the performance of all of the PAD algorithms.Our results show the vulnerability of face anti-spoofing algorithms withocclusions, which could be in the usage of such algorithms in the post-pandemicera.</description><author>Vaibhav Sundharam, Abhijit Sarkar, A. Lynn Abbott</author><pubDate>Fri, 23 Aug 2024 17:48:22 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.13251v1</guid></item><item><title>Foundational Model for Electron Micrograph Analysis: Instruction-Tuning Small-Scale Language-and-Vision Assistant for Enterprise Adoption</title><link>http://arxiv.org/abs/2408.13248v1</link><description>Semiconductor imaging and analysis are critical yet understudied in deeplearning, limiting our ability for precise control and optimization insemiconductor manufacturing. We introduce a small-scale multimodal frameworkfor analyzing semiconductor electron microscopy images (MAEMI) throughvision-language instruction tuning. We generate a customizedinstruction-following dataset using large multimodal models on microscopicimage analysis. We perform knowledge transfer from larger to smaller modelsthrough knowledge distillation, resulting in improved accuracy of smallermodels on visual question answering (VQA) tasks. This approach eliminates theneed for expensive, human expert-annotated datasets for microscopic imageanalysis tasks. Enterprises can further finetune MAEMI on their intellectualdata, enhancing privacy and performance on low-cost consumer hardware. Ourexperiments show that MAEMI outperforms traditional methods, adapts to datadistribution shifts, and supports high-throughput screening.</description><author>Sakhinana Sagar Srinivas, Chidaksh Ravuru, Geethan Sannidhi, Venkataramana Runkana</author><pubDate>Fri, 23 Aug 2024 17:42:11 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.13248v1</guid></item><item><title>Data Exposure from LLM Apps: An In-depth Investigation of OpenAI's GPTs</title><link>http://arxiv.org/abs/2408.13247v1</link><description>LLM app ecosystems are quickly maturing and supporting a wide range of usecases, which requires them to collect excessive user data. Given that the LLMapps are developed by third-parties and that anecdotal evidence suggests LLMplatforms currently do not strictly enforce their policies, user data sharedwith arbitrary third-parties poses a significant privacy risk. In this paper weaim to bring transparency in data practices of LLM apps. As a case study, westudy OpenAI's GPT app ecosystem. We develop an LLM-based framework to conductthe static analysis of natural language-based source code of GPTs and theirActions (external services) to characterize their data collection practices.Our findings indicate that Actions collect expansive data about users,including sensitive information prohibited by OpenAI, such as passwords. Wefind that some Actions, including related to advertising and analytics, areembedded in multiple GPTs, which allow them to track user activities acrossGPTs. Additionally, co-occurrence of Actions exposes as much as 9.5x more datato them, than it is exposed to individual Actions. Lastly, we develop anLLM-based privacy policy analysis framework to automatically check theconsistency of data collection by Actions with disclosures in their privacypolicies. Our measurements indicate that the disclosures for most of thecollected data types are omitted in privacy policies, with only 5.8% of Actionsclearly disclosing their data collection practices.</description><author>Evin Jaff, Yuhao Wu, Ning Zhang, Umar Iqbal</author><pubDate>Fri, 23 Aug 2024 17:42:06 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.13247v1</guid></item><item><title>Impacts of floating-point non-associativity on reproducibility for HPC and deep learning applications</title><link>http://arxiv.org/abs/2408.05148v2</link><description>Run-by-run variability in parallel programs caused by floating-pointnon-associativity (FPNA) has been known to significantly affect reproducibilityin iterative algorithms, due to accumulating errors. Non-reproducibilitynegatively affects efficiency and effectiveness of correctness testing forstochastic programs. Recently, the sensitivity of deep learning (DL) trainingand inference pipelines to FPNA have been found to be extreme, and can preventcertification for commercial applications, accurate assessment of robustnessand sensitivity, and bug detection. New approaches in scientific computingapplications have coupled DL models with high-performance computing (HPC)simulations, leading to an aggravation of debugging and testing challenges.Here we perform an investigation of the statistical properties of FPNA withinmodern parallel programming models, analyze performance and productivityimpacts of replacing atomic operations with deterministic alternatives on GPUs,and examine the recently-added deterministic options within the PyTorchframework within the context of GPU deployment, uncovering and quantifying theimpacts of input parameters triggering run-by-run variability and reporting onthe reliability and completeness of the documentation. Finally, we evaluate thestrategy of exploiting automatic determinism provided by deterministichardware, using the Groq LPU$^{TM}$ accelerator for inference portions of theDL pipeline. We demonstrate the benefits that this strategy can provide withinreproducibility and correctness efforts.</description><author>Sanjif Shanmugavelu, Mathieu Taillefumier, Christopher Culver, Oscar Hernandez, Mark Coletti, Ada Sedova</author><pubDate>Fri, 23 Aug 2024 17:40:15 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.05148v2</guid></item><item><title>MCTR: Multi Camera Tracking Transformer</title><link>http://arxiv.org/abs/2408.13243v1</link><description>Multi-camera tracking plays a pivotal role in various real-worldapplications. While end-to-end methods have gained significant interest insingle-camera tracking, multi-camera tracking remains predominantly reliant onheuristic techniques. In response to this gap, this paper introducesMulti-Camera Tracking tRansformer (MCTR), a novel end-to-end approach tailoredfor multi-object detection and tracking across multiple cameras withoverlapping fields of view. MCTR leverages end-to-end detectors like DEtectorTRansformer (DETR) to produce detections and detection embeddings independentlyfor each camera view. The framework maintains set of track embeddings thatencaplusate global information about the tracked objects, and updates them atevery frame by integrating the local information from the view-specificdetection embeddings. The track embeddings are probabilistically associatedwith detections in every camera view and frame to generate consistent objecttracks. The soft probabilistic association facilitates the design ofdifferentiable losses that enable end-to-end training of the entire system. Tovalidate our approach, we conduct experiments on MMPTrack and AI CityChallenge, two recently introduced large-scale multi-camera multi-objecttracking datasets.</description><author>Alexandru Niculescu-Mizil, Deep Patel, Iain Melvin</author><pubDate>Fri, 23 Aug 2024 17:37:03 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.13243v1</guid></item><item><title>Improving Equivariant Model Training via Constraint Relaxation</title><link>http://arxiv.org/abs/2408.13242v1</link><description>Equivariant neural networks have been widely used in a variety ofapplications due to their ability to generalize well in tasks where theunderlying data symmetries are known. Despite their successes, such networkscan be difficult to optimize and require careful hyperparameter tuning to trainsuccessfully. In this work, we propose a novel framework for improving theoptimization of such models by relaxing the hard equivariance constraint duringtraining: We relax the equivariance constraint of the network's intermediatelayers by introducing an additional non-equivariance term that we progressivelyconstrain until we arrive at an equivariant solution. By controlling themagnitude of the activation of the additional relaxation term, we allow themodel to optimize over a larger hypothesis space containing approximateequivariant networks and converge back to an equivariant solution at the end oftraining. We provide experimental results on different state-of-the-art networkarchitectures, demonstrating how this training framework can result inequivariant models with improved generalization performance.</description><author>Stefanos Pertigkiozoglou, Evangelos Chatzipantazis, Shubhendu Trivedi, Kostas Daniilidis</author><pubDate>Fri, 23 Aug 2024 17:35:08 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.13242v1</guid></item><item><title>Which Prosodic Features Matter Most for Pragmatics?</title><link>http://arxiv.org/abs/2408.13240v1</link><description>We investigate which prosodic features matter most in conveying prosodicfunctions. We use the problem of predicting human perceptions of pragmaticsimilarity among utterance pairs to evaluate the utility of prosodic featuresof different types. We find, for example, that duration-related features aremore important than pitch-related features, and that utterance-initial featuresare more important than utterance-final features. Further, failure analysisindicates that modeling using pitch features only often fails to handleimportant pragmatic functions, and suggests that several generally-neglectedacoustic and prosodic features are pragmatically significant, includingnasality and vibrato. These findings can guide future basic research inprosody, and suggest how to improve speech synthesis evaluation, among otherapplications.</description><author>Nigel G. Ward, Divette Marco, Olac Fuentes</author><pubDate>Fri, 23 Aug 2024 17:29:05 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.13240v1</guid></item><item><title>CustomCrafter: Customized Video Generation with Preserving Motion and Concept Composition Abilities</title><link>http://arxiv.org/abs/2408.13239v1</link><description>Customized video generation aims to generate high-quality videos guided bytext prompts and subject's reference images. However, since it is only trainedon static images, the fine-tuning process of subject learning disruptsabilities of video diffusion models (VDMs) to combine concepts and generatemotions. To restore these abilities, some methods use additional video similarto the prompt to fine-tune or guide the model. This requires frequent changesof guiding videos and even re-tuning of the model when generating differentmotions, which is very inconvenient for users. In this paper, we proposeCustomCrafter, a novel framework that preserves the model's motion generationand conceptual combination abilities without additional video and fine-tuningto recovery. For preserving conceptual combination ability, we design aplug-and-play module to update few parameters in VDMs, enhancing the model'sability to capture the appearance details and the ability of conceptcombinations for new subjects. For motion generation, we observed that VDMstend to restore the motion of video in the early stage of denoising, whilefocusing on the recovery of subject details in the later stage. Therefore, wepropose Dynamic Weighted Video Sampling Strategy. Using the pluggability of oursubject learning modules, we reduce the impact of this module on motiongeneration in the early stage of denoising, preserving the ability to generatemotion of VDMs. In the later stage of denoising, we restore this module torepair the appearance details of the specified subject, thereby ensuring thefidelity of the subject's appearance. Experimental results show that our methodhas a significant improvement compared to previous methods.</description><author>Tao Wu, Yong Zhang, Xintao Wang, Xianpan Zhou, Guangcong Zheng, Zhongang Qi, Ying Shan, Xi Li</author><pubDate>Fri, 23 Aug 2024 17:26:06 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.13239v1</guid></item><item><title>JacNet: Learning Functions with Structured Jacobians</title><link>http://arxiv.org/abs/2408.13237v1</link><description>Neural networks are trained to learn an approximate mapping from an inputdomain to a target domain. Incorporating prior knowledge about true mappings iscritical to learning a useful approximation. With current architectures, it ischallenging to enforce structure on the derivatives of the input-outputmapping. We propose to use a neural network to directly learn the Jacobian ofthe input-output function, which allows easy control of the derivative. Wefocus on structuring the derivative to allow invertibility and also demonstratethat other useful priors, such as $k$-Lipschitz, can be enforced. Using thisapproach, we can learn approximations to simple functions that are guaranteedto be invertible and easily compute the inverse. We also show similar resultsfor 1-Lipschitz functions.</description><author>Jonathan Lorraine, Safwan Hossain</author><pubDate>Fri, 23 Aug 2024 17:21:44 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.13237v1</guid></item><item><title>Classifier-Free Guidance is a Predictor-Corrector</title><link>http://arxiv.org/abs/2408.09000v2</link><description>We investigate the theoretical foundations of classifier-free guidance (CFG).CFG is the dominant method of conditional sampling for text-to-image diffusionmodels, yet unlike other aspects of diffusion, it remains on shaky theoreticalfooting. In this paper, we disprove common misconceptions, by showing that CFGinteracts differently with DDPM (Ho et al., 2020) and DDIM (Song et al., 2021),and neither sampler with CFG generates the gamma-powered distribution$p(x|c)^\gamma p(x)^{1-\gamma}$. Then, we clarify the behavior of CFG byshowing that it is a kind of predictor-corrector method (Song et al., 2020)that alternates between denoising and sharpening, which we callpredictor-corrector guidance (PCG). We prove that in the SDE limit, CFG isactually equivalent to combining a DDIM predictor for the conditionaldistribution together with a Langevin dynamics corrector for a gamma-powereddistribution (with a carefully chosen gamma). Our work thus provides a lens totheoretically understand CFG by embedding it in a broader design space ofprincipled sampling methods.</description><author>Arwen Bradley, Preetum Nakkiran</author><pubDate>Fri, 23 Aug 2024 17:21:35 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.09000v2</guid></item><item><title>DesignQA: A Multimodal Benchmark for Evaluating Large Language Models' Understanding of Engineering Documentation</title><link>http://arxiv.org/abs/2404.07917v2</link><description>This research introduces DesignQA, a novel benchmark aimed at evaluating theproficiency of multimodal large language models (MLLMs) in comprehending andapplying engineering requirements in technical documentation. Developed with afocus on real-world engineering challenges, DesignQA uniquely combinesmultimodal data-including textual design requirements, CAD images, andengineering drawings-derived from the Formula SAE student competition.Different from many existing MLLM benchmarks, DesignQA containsdocument-grounded visual questions where the input image and input documentcome from different sources. The benchmark features automatic evaluationmetrics and is divided into segments-Rule Comprehension, Rule Compliance, andRule Extraction-based on tasks that engineers perform when designing accordingto requirements. We evaluate state-of-the-art models (at the time of writing)like GPT-4o, GPT-4, Claude-Opus, Gemini-1.0, and LLaVA-1.5 against thebenchmark, and our study uncovers the existing gaps in MLLMs' abilities tointerpret complex engineering documentation. The MLLMs tested, while promising,struggle to reliably retrieve relevant rules from the Formula SAEdocumentation, face challenges in recognizing technical components in CADimages, and encounter difficulty in analyzing engineering drawings. Thesefindings underscore the need for multimodal models that can better handle themultifaceted questions characteristic of design according to technicaldocumentation. This benchmark sets a foundation for future advancements inAI-supported engineering design processes. DesignQA is publicly available at:https://github.com/anniedoris/design_qa/.</description><author>Anna C. Doris, Daniele Grandi, Ryan Tomich, Md Ferdous Alam, Mohammadmehdi Ataei, Hyunmin Cheong, Faez Ahmed</author><pubDate>Fri, 23 Aug 2024 17:19:18 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.07917v2</guid></item><item><title>Double Descent: Understanding Linear Model Estimation of Nonidentifiable Parameters and a Model for Overfitting</title><link>http://arxiv.org/abs/2408.13235v1</link><description>We consider ordinary least squares estimation and variations on least squaresestimation such as penalized (regularized) least squares and spectral shrinkageestimates for problems with p &gt; n and associated problems with prediction ofnew observations. After the introduction of Section 1, Section 2 examines anumber of commonly used estimators for p &gt; n. Section 3 introduces predictionwith p &gt; n. Section 4 introduces notational changes to facilitate discussion ofoverfitting and Section 5 illustrates the phenomenon of double descent. Weconclude with some final comments.</description><author>Ronald Christensen</author><pubDate>Fri, 23 Aug 2024 17:19:17 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.13235v1</guid></item><item><title>Multi-Layer Transformers Gradient Can be Approximated in Almost Linear Time</title><link>http://arxiv.org/abs/2408.13233v1</link><description>The quadratic computational complexity in the self-attention mechanism ofpopular transformer architectures poses significant challenges for training andinference, particularly in terms of efficiency and memory requirements. Towardsaddressing these challenges, this paper introduces a novel fast computationmethod for gradient calculation in multi-layer transformer models. Our approachenables the computation of gradients for the entire multi-layer transformermodel in almost linear time $n^{1+o(1)}$, where $n$ is the input sequencelength. This breakthrough significantly reduces the computational bottleneckassociated with the traditional quadratic time complexity. Our theory holds forany loss function and maintains a bounded approximation error across the entiremodel. Furthermore, our analysis can hold when the multi-layer transformermodel contains many practical sub-modules, such as residual connection, casualmask, and multi-head attention. By improving the efficiency of gradientcomputation in large language models, we hope that our work will facilitate themore effective training and deployment of long-context language models based onour theoretical results.</description><author>Yingyu Liang, Zhizhou Sha, Zhenmei Shi, Zhao Song, Yufa Zhou</author><pubDate>Fri, 23 Aug 2024 17:16:43 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.13233v1</guid></item><item><title>Ancient Wisdom, Modern Tools: Exploring Retrieval-Augmented LLMs for Ancient Indian Philosophy</title><link>http://arxiv.org/abs/2408.11903v2</link><description>LLMs have revolutionized the landscape of information retrieval and knowledgedissemination. However, their application in specialized areas is oftenhindered by factual inaccuracies and hallucinations, especially in long-tailknowledge distributions. We explore the potential of retrieval-augmentedgeneration (RAG) models for long-form question answering (LFQA) in aspecialized knowledge domain. We present VedantaNY-10M, a dataset curated fromextensive public discourses on the ancient Indian philosophy of AdvaitaVedanta. We develop and benchmark a RAG model against a standard, non-RAG LLM,focusing on transcription, retrieval, and generation performance. Humanevaluations by computational linguists and domain experts show that the RAGmodel significantly outperforms the standard model in producing factual andcomprehensive responses having fewer hallucinations. In addition, akeyword-based hybrid retriever that emphasizes unique low-frequency termsfurther improves results. Our study provides insights into effectivelyintegrating modern large language models with ancient knowledge systems.Project page with dataset and code: https://sites.google.com/view/vedantany-10m</description><author>Priyanka Mandikal</author><pubDate>Fri, 23 Aug 2024 17:15:39 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.11903v2</guid></item><item><title>Optical ISAC: Fundamental Performance Limits and Transceiver Design</title><link>http://arxiv.org/abs/2408.11792v3</link><description>This paper characterizes the optimal capacity-distortion (C-D) tradeoff in anoptical point-to-point (P2P) system with single-input single-output forcommunication and single-input multiple-output for sensing (SISO-COM andSIMO-SEN) within an integrated sensing and communication (ISAC) framework. Weconsider the optimal rate-distortion (R-D) region and explore several inner(IB) and outer (OB) bounds. We introduce practical, asymptotically optimalmaximum a posteriori (MAP) and maximum likelihood estimators (MLE) for targetdistance, addressing nonlinear measurement-to-state relationships andnon-conjugate priors. As the number of sensing antennas increases, theseestimators converge to the Bayesian Cram\'er-Rao bound (BCRB). We alsoestablish that the achievable rate-CRB (AR-CRB) serves as an OB for the optimalC-D region, valid for both unbiased estimators and asymptotically large numbersof receive antennas. To clarify that the input distribution determines thetradeoff across the Pareto boundary of the C-D region, we propose twoalgorithms: \textit{i}) an iterative Blahut-Arimoto algorithm (BAA)-typemethod, and \textit{ii}) a memory-efficient closed-form (CF) approach. The CFapproach includes a CF optimal distribution for high optical signal-to-noiseratio (O-SNR) conditions. Additionally, we adapt and refine theDeterministic-Random Tradeoff (DRT) to this optical ISAC context.</description><author>Alireza Ghazavi Khorasgani, Mahtab Mirmohseni, Ahmed Elzanaty</author><pubDate>Fri, 23 Aug 2024 17:14:36 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.11792v3</guid></item><item><title>On the design of scalable, high-precision spherical-radial Fourier features</title><link>http://arxiv.org/abs/2408.13231v1</link><description>Approximation using Fourier features is a popular technique for scalingkernel methods to large-scale problems, with myriad applications in machinelearning and statistics. This method replaces the integral representation of ashift-invariant kernel with a sum using a quadrature rule. The design of thelatter is meant to reduce the number of features required for high-precisionapproximation. Specifically, for the squared exponential kernel, one mustdesign a quadrature rule that approximates the Gaussian measure on$\mathbb{R}^d$. Previous efforts in this line of research have faceddifficulties in higher dimensions. We introduce a new family of quadraturerules that accurately approximate the Gaussian measure in higher dimensions byexploiting its isotropy. These rules are constructed as a tensor product of aradial quadrature rule and a spherical quadrature rule. Compared to previouswork, our approach leverages a thorough analysis of the approximation error,which suggests natural choices for both the radial and spherical components. Wedemonstrate that this family of Fourier features yields improved approximationbounds.</description><author>Ayoub Belhadji, Qianyu Julie Zhu, Youssef Marzouk</author><pubDate>Fri, 23 Aug 2024 17:11:25 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.13231v1</guid></item><item><title>Amortized Bayesian Multilevel Models</title><link>http://arxiv.org/abs/2408.13230v1</link><description>Multilevel models (MLMs) are a central building block of the Bayesianworkflow. They enable joint, interpretable modeling of data across hierarchicallevels and provide a fully probabilistic quantification of uncertainty. Despitetheir well-recognized advantages, MLMs pose significant computationalchallenges, often rendering their estimation and evaluation intractable withinreasonable time constraints. Recent advances in simulation-based inferenceoffer promising solutions for addressing complex probabilistic models usingdeep generative networks. However, the utility and reliability of deep learningmethods for estimating Bayesian MLMs remains largely unexplored, especiallywhen compared with gold-standard samplers. To this end, we explore a family ofneural network architectures that leverage the probabilistic factorization ofmultilevel models to facilitate efficient neural network training andsubsequent near-instant posterior inference on unseen data sets. We test ourmethod on several real-world case studies and provide comprehensive comparisonsto Stan as a gold-standard method where possible. Finally, we provide anopen-source implementation of our methods to stimulate further research in thenascent field of amortized Bayesian inference.</description><author>Daniel Habermann, Marvin Schmitt, Lars Kühmichel, Andreas Bulling, Stefan T. Radev, Paul-Christian Bürkner</author><pubDate>Fri, 23 Aug 2024 17:11:04 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.13230v1</guid></item><item><title>Towards Fine-Grained Citation Evaluation in Generated Text: A Comparative Analysis of Faithfulness Metrics</title><link>http://arxiv.org/abs/2406.15264v2</link><description>Large language models (LLMs) often produce unsupported or unverifiablecontent, known as "hallucinations." To mitigate this, retrieval-augmented LLMsincorporate citations, grounding the content in verifiable sources. Despitesuch developments, manually assessing how well a citation supports theassociated statement remains a major challenge. Previous studies usefaithfulness metrics to estimate citation support automatically but are limitedto binary classification, overlooking fine-grained citation support inpractical scenarios. To investigate the effectiveness of faithfulness metricsin fine-grained scenarios, we propose a comparative evaluation framework thatassesses the metric effectiveness in distinguishing citations betweenthree-category support levels: full, partial, and no support. Our frameworkemploys correlation analysis, classification evaluation, and retrievalevaluation to measure the alignment between metric scores and human judgmentscomprehensively. Our results show no single metric consistently excels acrossall evaluations, revealing the complexity of assessing fine-grained support.Based on the findings, we provide practical recommendations for developing moreeffective metrics.</description><author>Weijia Zhang, Mohammad Aliannejadi, Yifei Yuan, Jiahuan Pei, Jia-Hong Huang, Evangelos Kanoulas</author><pubDate>Fri, 23 Aug 2024 17:04:38 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.15264v2</guid></item><item><title>Enhancing Few-Shot Transfer Learning with Optimized Multi-Task Prompt Tuning through Modular Prompt Composition</title><link>http://arxiv.org/abs/2408.13227v1</link><description>In recent years, multi-task prompt tuning has garnered considerable attentionfor its inherent modularity and potential to enhance parameter-efficienttransfer learning across diverse tasks. This paper aims to analyze and improvethe performance of multiple tasks by facilitating the transfer of knowledgebetween their corresponding prompts in a multi-task setting. Our proposedapproach decomposes the prompt for each target task into a combination ofshared prompts (source prompts) and a task-specific prompt (private prompt).During training, the source prompts undergo fine-tuning and are integrated withthe private prompt to drive the target prompt for each task. We present andcompare multiple methods for combining source prompts to construct the targetprompt, analyzing the roles of both source and private prompts within eachmethod. We investigate their contributions to task performance and offerflexible, adjustable configurations based on these insights to optimizeperformance. Our empirical findings clearly showcase improvements in accuracyand robustness compared to the conventional practice of prompt tuning andrelated works. Notably, our results substantially outperform other methods inthe field in few-shot settings, demonstrating superior performance in varioustasks across GLUE benchmark, among other tasks. This achievement is attainedwith a significantly reduced amount of training data, making our method apromising one for few-shot settings.</description><author>Ahmad Pouramini, Hesham Faili</author><pubDate>Fri, 23 Aug 2024 17:01:51 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.13227v1</guid></item><item><title>D&amp;M: Enriching E-commerce Videos with Sound Effects by Key Moment Detection and SFX Matching</title><link>http://arxiv.org/abs/2408.13226v1</link><description>Videos showcasing specific products are increasingly important forE-commerce. Key moments naturally exist as the first appearance of a specificproduct, presentation of its distinctive features, the presence of a buyinglink, etc. Adding proper sound effects (SFX) to these key moments, or videodecoration with SFX (VDSFX), is crucial for enhancing the user engagingexperience. Previous studies about adding SFX to videos perform video to SFXmatching at a holistic level, lacking the ability of adding SFX to a specificmoment. Meanwhile, previous studies on video highlight detection or videomoment retrieval consider only moment localization, leaving moment to SFXmatching untouched. By contrast, we propose in this paper D&amp;M, a unified methodthat accomplishes key moment detection and moment to SFX matchingsimultaneously. Moreover, for the new VDSFX task we build a large-scale datasetSFX-Moment from an E-commerce platform. For a fair comparison, we buildcompetitive baselines by extending a number of current video moment detectionmethods to the new task. Extensive experiments on SFX-Moment show the superiorperformance of the proposed method over the baselines. Code and data will bereleased.</description><author>Jingyu Liu, Minquan Wang, Ye Ma, Bo Wang, Aozhu Chen, Quan Chen, Peng Jiang, Xirong Li</author><pubDate>Fri, 23 Aug 2024 17:01:35 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.13226v1</guid></item><item><title>An Overview on Machine Learning Methods for Partial Differential Equations: from Physics Informed Neural Networks to Deep Operator Learning</title><link>http://arxiv.org/abs/2408.13222v1</link><description>The approximation of solutions of partial differential equations (PDEs) withnumerical algorithms is a central topic in applied mathematics. For manydecades, various types of methods for this purpose have been developed andextensively studied. One class of methods which has received a lot of attentionin recent years are machine learning-based methods, which typically involve thetraining of artificial neural networks (ANNs) by means of stochastic gradientdescent type optimization methods. While approximation methods for PDEs usingANNs have first been proposed in the 1990s they have only gained widepopularity in the last decade with the rise of deep learning. This article aimsto provide an introduction to some of these methods and the mathematical theoryon which they are based. We discuss methods such as physics-informed neuralnetworks (PINNs) and deep BSDE methods and consider several operator learningapproaches.</description><author>Lukas Gonon, Arnulf Jentzen, Benno Kuckuck, Siyu Liang, Adrian Riekert, Philippe von Wurstemberger</author><pubDate>Fri, 23 Aug 2024 16:57:34 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.13222v1</guid></item><item><title>Protecting against simultaneous data poisoning attacks</title><link>http://arxiv.org/abs/2408.13221v1</link><description>Current backdoor defense methods are evaluated against a single attack at atime. This is unrealistic, as powerful machine learning systems are trained onlarge datasets scraped from the internet, which may be attacked multiple timesby one or more attackers. We demonstrate that simultaneously executed datapoisoning attacks can effectively install multiple backdoors in a single modelwithout substantially degrading clean accuracy. Furthermore, we show thatexisting backdoor defense methods do not effectively prevent attacks in thissetting. Finally, we leverage insights into the nature of backdoor attacks todevelop a new defense, BaDLoss, that is effective in the multi-attack setting.With minimal clean accuracy degradation, BaDLoss attains an average attacksuccess rate in the multi-attack setting of 7.98% in CIFAR-10 and 10.29% inGTSRB, compared to the average of other defenses at 64.48% and 84.28%respectively.</description><author>Neel Alex, Shoaib Ahmed Siddiqui, Amartya Sanyal, David Krueger</author><pubDate>Fri, 23 Aug 2024 16:57:27 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.13221v1</guid></item><item><title>HBIC: A Biclustering Algorithm for Heterogeneous Datasets</title><link>http://arxiv.org/abs/2408.13217v1</link><description>Biclustering is an unsupervised machine-learning approach aiming to clusterrows and columns simultaneously in a data matrix. Several biclusteringalgorithms have been proposed for handling numeric datasets. However,real-world data mining problems often involve heterogeneous datasets with mixedattributes. To address this challenge, we introduce a biclustering approachcalled HBIC, capable of discovering meaningful biclusters in complexheterogeneous data, including numeric, binary, and categorical data. Theapproach comprises two stages: bicluster generation and bicluster modelselection. In the initial stage, several candidate biclusters are generatediteratively by adding and removing rows and columns based on the frequency ofvalues in the original matrix. In the second stage, we introduce two approachesfor selecting the most suitable biclusters by considering their size andhomogeneity. Through a series of experiments, we investigated the suitabilityof our approach on a synthetic benchmark and in a biomedical applicationinvolving clinical data of systemic sclerosis patients. The evaluationcomparing our method to existing approaches demonstrates its ability todiscover high-quality biclusters from heterogeneous data. Our biclusteringapproach is a starting point for heterogeneous bicluster discovery, leading toa better understanding of complex underlying data structures.</description><author>Adán José-García, Julie Jacques, Clément Chauvet, Vincent Sobanski, Clarisse Dhaenens</author><pubDate>Fri, 23 Aug 2024 16:48:10 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.13217v1</guid></item><item><title>EUR-USD Exchange Rate Forecasting Based on Information Fusion with Large Language Models and Deep Learning Methods</title><link>http://arxiv.org/abs/2408.13214v1</link><description>Accurate forecasting of the EUR/USD exchange rate is crucial for investors,businesses, and policymakers. This paper proposes a novel framework, IUS, thatintegrates unstructured textual data from news and analysis with structureddata on exchange rates and financial indicators to enhance exchange rateprediction. The IUS framework employs large language models for sentimentpolarity scoring and exchange rate movement classification of texts. Thesetextual features are combined with quantitative features and input into aCausality-Driven Feature Generator. An Optuna-optimized Bi-LSTM model is thenused to forecast the EUR/USD exchange rate. Experiments demonstrate that theproposed method outperforms benchmark models, reducing MAE by 10.69% and RMSEby 9.56% compared to the best performing baseline. Results also show thebenefits of data fusion, with the combination of unstructured and structureddata yielding higher accuracy than structured data alone. Furthermore, featureselection using the top 12 important quantitative features combined with thetextual features proves most effective. The proposed IUS framework andOptuna-Bi-LSTM model provide a powerful new approach for exchange rateforecasting through multi-source data integration.</description><author>Hongcheng Ding, Xuanze Zhao, Zixiao Jiang, Shamsul Nahar Abdullah, Deshinta Arrova Dewi</author><pubDate>Fri, 23 Aug 2024 16:46:36 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.13214v1</guid></item><item><title>End-To-End Causal Effect Estimation from Unstructured Natural Language Data</title><link>http://arxiv.org/abs/2407.07018v2</link><description>Knowing the effect of an intervention is critical for human decision-making,but current approaches for causal effect estimation rely on manual datacollection and structuring, regardless of the causal assumptions. Thisincreases both the cost and time-to-completion for studies. We show how large,diverse observational text data can be mined with large language models (LLMs)to produce inexpensive causal effect estimates under appropriate causalassumptions. We introduce NATURAL, a novel family of causal effect estimatorsbuilt with LLMs that operate over datasets of unstructured text. Our estimatorsuse LLM conditional distributions (over variables of interest, given the textdata) to assist in the computation of classical estimators of causal effect. Weovercome a number of technical challenges to realize this idea, such asautomating data curation and using LLMs to impute missing information. Weprepare six (two synthetic and four real) observational datasets, paired withcorresponding ground truth in the form of randomized trials, which we used tosystematically evaluate each step of our pipeline. NATURAL estimatorsdemonstrate remarkable performance, yielding causal effect estimates that fallwithin 3 percentage points of their ground truth counterparts, including onreal-world Phase 3/4 clinical trials. Our results suggest that unstructuredtext data is a rich source of causal effect information, and NATURAL is a firststep towards an automated pipeline to tap this resource.</description><author>Nikita Dhawan, Leonardo Cotta, Karen Ullrich, Rahul G. Krishnan, Chris J. Maddison</author><pubDate>Fri, 23 Aug 2024 16:41:47 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.07018v2</guid></item><item><title>Optimal Quantum Circuit Design via Unitary Neural Networks</title><link>http://arxiv.org/abs/2408.13211v1</link><description>The process of translating a quantum algorithm into a form suitable forimplementation on a quantum computing platform is crucial but yet challenging.This entails specifying quantum operations with precision, a typicallyintricate task. In this paper, we present an alternative approach: an automatedmethod for synthesizing the functionality of a quantum algorithm into a quantumcircuit model representation. Our methodology involves training a neuralnetwork model using diverse input-output mappings of the quantum algorithm. Wedemonstrate that this trained model can effectively generate a quantum circuitmodel equivalent to the original algorithm. Remarkably, our observationsindicate that the trained model achieves near-perfect mapping of unseen inputsto their respective outputs.</description><author>M. Zomorodi, H. Amini, M. Abbaszadeh, J. Sohrabi, V. Salari, P. Plawiak</author><pubDate>Fri, 23 Aug 2024 16:41:15 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.13211v1</guid></item><item><title>Temporal Fairness in Decision Making Problems</title><link>http://arxiv.org/abs/2408.13208v1</link><description>In this work we consider a new interpretation of fairness in decision makingproblems. Building upon existing fairness formulations, we focus on how toreason over fairness from a temporal perspective, taking into account thefairness of a history of past decisions. After introducing the concept oftemporal fairness, we propose three approaches that incorporate temporalfairness in decision making problems formulated as optimization problems. Wepresent a qualitative evaluation of our approach in four different domains andcompare the solutions against a baseline approach that does not consider thetemporal aspect of fairness.</description><author>Manuel R. Torres, Parisa Zehtabi, Michael Cashmore, Daniele Magazzeni, Manuela Veloso</author><pubDate>Fri, 23 Aug 2024 16:36:58 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.13208v1</guid></item><item><title>DOMAINEVAL: An Auto-Constructed Benchmark for Multi-Domain Code Generation</title><link>http://arxiv.org/abs/2408.13204v1</link><description>Code benchmarks such as HumanEval are widely adopted to evaluate thecapabilities of Large Language Models (LLMs), providing insights into theirstrengths and weaknesses. However, current benchmarks primarily exercise LLMs'capability on common coding tasks (e.g., bubble sort, greatest common divisor),leaving domain-specific coding tasks (e.g., computation, system, cryptography)unexplored. To fill this gap, we propose a multi-domain code benchmark,DOMAINEVAL, designed to evaluate LLMs' coding capabilities thoroughly. Ourpipeline works in a fully automated manner, enabling a push-bottom constructionfrom code repositories into formatted subjects under study. Interestingfindings are observed by evaluating 12 representative LLMs against DOMAINEVAL.We notice that LLMs are generally good at computation tasks while falling shorton cryptography and system coding tasks. The performance gap can be as much as68.94% (80.94% - 12.0%) in some LLMs. We also observe that generating moresamples can increase the overall performance of LLMs, while the domain bias mayeven increase. The contributions of this study include a code generationbenchmark dataset DOMAINEVAL, encompassing six popular domains, a fullyautomated pipeline for constructing code benchmarks, and an identification ofthe limitations of LLMs in code generation tasks based on their performance onDOMAINEVAL, providing directions for future research improvements. Theleaderboard is available at https://domaineval.github.io/.</description><author>Qiming Zhu, Jialun Cao, Yaojie Lu, Hongyu Lin, Xianpei Han, Le Sun, Shing-Chi Cheung</author><pubDate>Fri, 23 Aug 2024 16:33:58 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.13204v1</guid></item><item><title>Instruct-DeBERTa: A Hybrid Approach for Aspect-based Sentiment Analysis on Textual Reviews</title><link>http://arxiv.org/abs/2408.13202v1</link><description>Aspect-based Sentiment Analysis (ABSA) is a critical task in Natural LanguageProcessing (NLP) that focuses on extracting sentiments related to specificaspects within a text, offering deep insights into customer opinions.Traditional sentiment analysis methods, while useful for determining overallsentiment, often miss the implicit opinions about particular product or servicefeatures. This paper presents a comprehensive review of the evolution of ABSAmethodologies, from lexicon-based approaches to machine learning and deeplearning techniques. We emphasize the recent advancements in Transformer-basedmodels, particularly Bidirectional Encoder Representations from Transformers(BERT) and its variants, which have set new benchmarks in ABSA tasks. Wefocused on finetuning Llama and Mistral models, building hybrid models usingthe SetFit framework, and developing our own model by exploiting the strengthsof state-of-the-art (SOTA) Transformer-based models for aspect term extraction(ATE) and aspect sentiment classification (ASC). Our hybrid model Instruct -DeBERTa uses SOTA InstructABSA for aspect extraction and DeBERTa-V3-baseabsa-V1for aspect sentiment classification. We utilize datasets from different domainsto evaluate our model's performance. Our experiments indicate that the proposedhybrid model significantly improves the accuracy and reliability of sentimentanalysis across all experimented domains. As per our findings, our hybrid modelInstruct - DeBERTa is the best-performing model for the joint task of ATE andASC for both SemEval restaurant 2014 and SemEval laptop 2014 datasetsseparately. By addressing the limitations of existing methodologies, ourapproach provides a robust solution for understanding detailed consumerfeedback, thus offering valuable insights for businesses aiming to enhancecustomer satisfaction and product development.</description><author>Dineth Jayakody, A V A Malkith, Koshila Isuranda, Vishal Thenuwara, Nisansa de Silva, Sachintha Rajith Ponnamperuma, G G N Sandamali, K L K Sudheera</author><pubDate>Fri, 23 Aug 2024 16:31:07 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.13202v1</guid></item><item><title>EAViT: External Attention Vision Transformer for Audio Classification</title><link>http://arxiv.org/abs/2408.13201v1</link><description>This paper presents the External Attention Vision Transformer (EAViT) model,a novel approach designed to enhance audio classification accuracy. As digitalaudio resources proliferate, the demand for precise and efficient audioclassification systems has intensified, driven by the need for improvedrecommendation systems and user personalization in various applications,including music streaming platforms and environmental sound recognition.Accurate audio classification is crucial for organizing vast audio librariesinto coherent categories, enabling users to find and interact with theirpreferred audio content more effectively. In this study, we utilize the GTZANdataset, which comprises 1,000 music excerpts spanning ten diverse genres. Each30-second audio clip is segmented into 3-second excerpts to enhance datasetrobustness and mitigate overfitting risks, allowing for more granular featureanalysis. The EAViT model integrates multi-head external attention (MEA)mechanisms into the Vision Transformer (ViT) framework, effectively capturinglong-range dependencies and potential correlations between samples. Thisexternal attention (EA) mechanism employs learnable memory units that enhancethe network's capacity to process complex audio features efficiently. The studydemonstrates that EAViT achieves a remarkable overall accuracy of 93.99%,surpassing state-of-the-art models.</description><author>Aquib Iqbal, Abid Hasan Zim, Md Asaduzzaman Tonmoy, Limengnan Zhou, Asad Malik, Minoru Kuribayashi</author><pubDate>Fri, 23 Aug 2024 16:31:06 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.13201v1</guid></item><item><title>Constrained or Unconstrained? Neural-Network-Based Equation Discovery from Data</title><link>http://arxiv.org/abs/2406.02581v2</link><description>Throughout many fields, practitioners often rely on differential equations tomodel systems. Yet, for many applications, the theoretical derivation of suchequations and/or accurate resolution of their solutions may be intractable.Instead, recently developed methods, including those based on parameterestimation, operator subset selection, and neural networks, allow for thedata-driven discovery of both ordinary and partial differential equations(PDEs), on a spectrum of interpretability. The success of these strategies isoften contingent upon the correct identification of representative equationsfrom noisy observations of state variables and, as importantly and intertwinedwith that, the mathematical strategies utilized to enforce those equations.Specifically, the latter has been commonly addressed via unconstrainedoptimization strategies. Representing the PDE as a neural network, we proposeto discover the PDE by solving a constrained optimization problem and using anintermediate state representation similar to a Physics-Informed Neural Network(PINN). The objective function of this constrained optimization problempromotes matching the data, while the constraints require that the PDE issatisfied at several spatial collocation points. We present a penalty methodand a widely used trust-region barrier method to solve this constrainedoptimization problem, and we compare these methods on numerical examples. Ourresults on the Burgers' and the Korteweg-De Vreis equations demonstrate thatthe latter constrained method outperforms the penalty method, particularly forhigher noise levels or fewer collocation points. For both methods, we solvethese discovered neural network PDEs with classical methods, such as finitedifference methods, as opposed to PINNs-type methods relying on automaticdifferentiation. We briefly highlight other small, yet crucial, implementationdetails.</description><author>Grant Norman, Jacqueline Wentz, Hemanth Kolla, Kurt Maute, Alireza Doostan</author><pubDate>Fri, 23 Aug 2024 16:26:55 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.02581v2</guid></item><item><title>Model Merging by Uncertainty-Based Gradient Matching</title><link>http://arxiv.org/abs/2310.12808v2</link><description>Models trained on different datasets can be merged by a weighted-averaging oftheir parameters, but why does it work and when can it fail? Here, we connectthe inaccuracy of weighted-averaging to mismatches in the gradients and proposea new uncertainty-based scheme to improve the performance by reducing themismatch. The connection also reveals implicit assumptions in other schemessuch as averaging, task arithmetic, and Fisher-weighted averaging. Our newmethod gives consistent improvements for large language models and visiontransformers, both in terms of performance and robustness to hyperparameters.Code available here.</description><author>Nico Daheim, Thomas Möllenhoff, Edoardo Maria Ponti, Iryna Gurevych, Mohammad Emtiyaz Khan</author><pubDate>Fri, 23 Aug 2024 16:25:44 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.12808v2</guid></item><item><title>NAS-Cap: Deep-Learning Driven 3-D Capacitance Extraction with Neural Architecture Search and Data Augmentation</title><link>http://arxiv.org/abs/2408.13195v1</link><description>More accurate capacitance extraction is demanded for designing integratedcircuits under advanced process technology. The pattern matching approach andthe field solver for capacitance extraction have the drawbacks of inaccuracyand large computational cost, respectively. Recent work \cite{yang2023cnn}proposes a grid-based data representation and a convolutional neural network(CNN) based capacitance models (called CNN-Cap), which opens the third way for3-D capacitance extraction to get accurate results with much less time costthan field solver. In this work, the techniques of neural architecture search(NAS) and data augmentation are proposed to train better CNN models for 3-Dcapacitance extraction. Experimental results on datasets from different designsshow that the obtained NAS-Cap models achieve remarkably higher accuracy thanCNN-Cap, while consuming less runtime for inference and space for modelstorage. Meanwhile, the transferability of the NAS is validated, as the oncesearched architecture brought similar error reduction on coupling/totalcapacitance for the test cases from different design and/or process technology.</description><author>Haoyuan Li, Dingcheng Yang, Chunyan Pei, Wenjian Yu</author><pubDate>Fri, 23 Aug 2024 16:25:33 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.13195v1</guid></item><item><title>IFH: a Diffusion Framework for Flexible Design of Graph Generative Models</title><link>http://arxiv.org/abs/2408.13194v1</link><description>Graph generative models can be classified into two prominent families:one-shot models, which generate a graph in one go, and sequential models, whichgenerate a graph by successive additions of nodes and edges. Ideally, betweenthese two extreme models lies a continuous range of models that adopt differentlevels of sequentiality. This paper proposes a graph generative model, calledInsert-Fill-Halt (IFH), that supports the specification of a sequentialitydegree. IFH is based upon the theory of Denoising Diffusion ProbabilisticModels (DDPM), designing a node removal process that gradually destroys agraph. An insertion process learns to reverse this removal process by insertingarcs and nodes according to the specified sequentiality degree. We evaluate theperformance of IFH in terms of quality, run time, and memory, depending ondifferent sequentiality degrees. We also show that using DiGress, adiffusion-based one-shot model, as a generative step in IFH leads toimprovement to the model itself, and is competitive with the currentstate-of-the-art.</description><author>Samuel Cognolato, Alessandro Sperduti, Luciano Serafini</author><pubDate>Fri, 23 Aug 2024 16:24:40 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.13194v1</guid></item><item><title>Reconstructing networks from simple and complex contagions</title><link>http://arxiv.org/abs/2405.00129v2</link><description>Network scientists often use complex dynamic processes to describe networkcontagions, but tools for fitting contagion models typically assume simpledynamics. Here, we address this gap by developing a nonparametric method toreconstruct a network and dynamics from a series of node states, using a modelthat breaks the dichotomy between simple pairwise and complexneighborhood-based contagions. We then show that a network is more easilyreconstructed when observed through the lens of complex contagions if it isdense or the dynamic saturates, and that simple contagions are betterotherwise.</description><author>Nicholas W. Landry, William Thompson, Laurent Hébert-Dufresne, Jean-Gabriel Young</author><pubDate>Fri, 23 Aug 2024 16:22:19 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.00129v2</guid></item><item><title>Accelerating the k-means++ Algorithm by Using Geometric Information</title><link>http://arxiv.org/abs/2408.13189v1</link><description>In this paper, we propose an acceleration of the exact k-means++ algorithmusing geometric information, specifically the Triangle Inequality andadditional norm filters, along with a two-step sampling procedure. Ourexperiments demonstrate that the accelerated version outperforms the standardk-means++ version in terms of the number of visited points and distancecalculations, achieving greater speedup as the number of clusters increases.The version utilizing the Triangle Inequality is particularly effective forlow-dimensional data, while the additional norm-based filter enhancesperformance in high-dimensional instances with greater norm variance amongpoints. Additional experiments show the behavior of our algorithms whenexecuted concurrently across multiple jobs and examine how memory performanceimpacts practical speedup.</description><author>Guillem Rodríguez Corominas, Maria J. Blesa, Christian Blum</author><pubDate>Fri, 23 Aug 2024 16:15:47 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.13189v1</guid></item><item><title>Advancing Voice Cloning for Nepali: Leveraging Transfer Learning in a Low-Resource Language</title><link>http://arxiv.org/abs/2408.10128v2</link><description>Voice cloning is a prominent feature in personalized speech interfaces. Aneural vocal cloning system can mimic someone's voice using just a few audiosamples. Both speaker encoding and speaker adaptation are topics of research inthe field of voice cloning. Speaker adaptation relies on fine-tuning amulti-speaker generative model, which involves training a separate model toinfer a new speaker embedding used for speaker encoding. Both methods canachieve excellent performance, even with a small number of cloning audios, interms of the speech's naturalness and similarity to the original speaker.Speaker encoding approaches are more appropriate for low-resource deploymentsince they require significantly less memory and have a faster cloning timethan speaker adaption, which can offer slightly greater naturalness andsimilarity. The main goal is to create a vocal cloning system that producesaudio output with a Nepali accent or that sounds like Nepali. For the furtheradvancement of TTS, the idea of transfer learning was effectively used toaddress several issues that were encountered in the development of this system,including the poor audio quality and the lack of available data.</description><author>Manjil Karki, Pratik Shakya, Sandesh Acharya, Ravi Pandit, Dinesh Gothe</author><pubDate>Fri, 23 Aug 2024 16:15:30 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.10128v2</guid></item><item><title>Low-light phase retrieval with implicit generative priors</title><link>http://arxiv.org/abs/2402.17745v2</link><description>Phase retrieval (PR) is fundamentally important in scientific imaging and iscrucial for nanoscale techniques like coherent diffractive imaging (CDI). Lowradiation dose imaging is essential for applications involvingradiation-sensitive samples. However, most PR methods struggle in low-dosescenarios due to high shot noise. Recent advancements in optical dataacquisition setups, such as in-situ CDI, have shown promise for low-doseimaging, but they rely on a time series of measurements, making them unsuitablefor single-image applications. Similarly, data-driven phase retrievaltechniques are not easily adaptable to data-scarce situations. Zero-shot deeplearning methods based on pre-trained and implicit generative priors have beeneffective in various imaging tasks but have shown limited success in PR. Inthis work, we propose low-dose deep image prior (LoDIP), which combines in-situCDI with the power of implicit generative priors to address single-imagelow-dose phase retrieval. Quantitative evaluations demonstrate LoDIP's superiorperformance in this task and its applicability to real experimental scenarios.</description><author>Raunak Manekar, Elisa Negrini, Minh Pham, Daniel Jacobs, Jaideep Srivastava, Stanley J. Osher, Jianwei Miao</author><pubDate>Fri, 23 Aug 2024 16:11:31 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.17745v2</guid></item><item><title>Solving Robotics Problems in Zero-Shot with Vision-Language Models</title><link>http://arxiv.org/abs/2407.19094v2</link><description>We introduce Wonderful Team, a multi-agent visual LLM (VLLM) framework forsolving robotics problems in the zero-shot regime. By zero-shot we mean that,for a novel environment, we feed a VLLM an image of the robot's environment anda description of the task, and have the VLLM output the sequence of actionsnecessary for the robot to complete the task. Prior work on VLLMs in roboticshas largely focused on settings where some part of the pipeline is fine-tuned,such as tuning an LLM on robot data or training a separate vision encoder forperception and action generation. Surprisingly, due to recent advances in thecapabilities of VLLMs, this type of fine-tuning may no longer be necessary formany tasks. In this work, we show that with careful engineering, we can prompta single off-the-shelf VLLM to handle all aspects of a robotics task, fromhigh-level planning to low-level location-extraction and action-execution.Wonderful Team builds on recent advances in multi-agent LLMs to partition tasksacross an agent hierarchy, making it self-corrective and able to effectivelypartition and solve even long-horizon tasks. Extensive experiments on VIMABenchand real-world robotic environments demonstrate the system's capability tohandle a variety of robotic tasks, including manipulation, visualgoal-reaching, and visual reasoning, all in a zero-shot manner. These resultsunderscore a key point: vision-language models have progressed rapidly in thepast year, and should strongly be considered as a backbone for roboticsproblems going forward.</description><author>Zidan Wang, Rui Shen, Bradly Stadie</author><pubDate>Fri, 23 Aug 2024 16:06:27 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.19094v2</guid></item><item><title>AI Reliance and Decision Quality: Fundamentals, Interdependence, and the Effects of Interventions</title><link>http://arxiv.org/abs/2304.08804v2</link><description>In AI-assisted decision-making, a central promise of having ahuman-in-the-loop is that they should be able to complement the AI system byoverriding its wrong recommendations. In practice, however, we often see thathumans cannot assess the correctness of AI recommendations and, as a result,adhere to wrong or override correct advice. Different ways of relying on AIrecommendations have immediate, yet distinct, implications for decisionquality. Unfortunately, reliance and decision quality are often inappropriatelyconflated in the current literature on AI-assisted decision-making. In thiswork, we disentangle and formalize the relationship between reliance anddecision quality, and we characterize the conditions under which human-AIcomplementarity is achievable. To illustrate how reliance and decision qualityrelate to one another, we propose a visual framework and demonstrate itsusefulness for interpreting empirical findings, including the effects ofinterventions like explanations. Overall, our research highlights theimportance of distinguishing between reliance behavior and decision quality inAI-assisted decision-making.</description><author>Jakob Schoeffer, Johannes Jakubik, Michael Voessing, Niklas Kuehl, Gerhard Satzger</author><pubDate>Fri, 23 Aug 2024 16:06:01 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2304.08804v2</guid></item><item><title>Can LLM be a Good Path Planner based on Prompt Engineering? Mitigating the Hallucination for Path Planning</title><link>http://arxiv.org/abs/2408.13184v1</link><description>Spatial reasoning in Large Language Models (LLMs) is the foundation forembodied intelligence. However, even in simple maze environments, LLMs stillencounter challenges in long-term path-planning, primarily influenced by theirspatial hallucination and context inconsistency hallucination by long-termreasoning. To address this challenge, this study proposes an innovative model,Spatial-to-Relational Transformation and Curriculum Q-Learning (S2RCQL). Toaddress the spatial hallucination of LLMs, we propose the Spatial-to-Relationalapproach, which transforms spatial prompts into entity relations and pathsrepresenting entity relation chains. This approach fully taps the potential ofLLMs in terms of sequential thinking. As a result, we design a path-planningalgorithm based on Q-learning to mitigate the context inconsistencyhallucination, which enhances the reasoning ability of LLMs. Using the Q-valueof state-action as auxiliary information for prompts, we correct thehallucinations of LLMs, thereby guiding LLMs to learn the optimal path.Finally, we propose a reverse curriculum learning technique based on LLMs tofurther mitigate the context inconsistency hallucination. LLMs can rapidlyaccumulate successful experiences by reducing task difficulty and leveragingthem to tackle more complex tasks. We performed comprehensive experiments basedon Baidu's self-developed LLM: ERNIE-Bot 4.0. The results showed that ourS2RCQL achieved a 23%--40% improvement in both success and optimality ratescompared with advanced prompt engineering.</description><author>Hourui Deng, Hongjie Zhang, Jie Ou, Chaosheng Feng</author><pubDate>Fri, 23 Aug 2024 16:02:54 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.13184v1</guid></item><item><title>Deep Learning for Lung Disease Classification Using Transfer Learning and a Customized CNN Architecture with Attention</title><link>http://arxiv.org/abs/2408.13180v1</link><description>Many people die from lung-related diseases every year. X-ray is an effectiveway to test if one is diagnosed with a lung-related disease or not. This studyconcentrates on categorizing three distinct types of lung X-rays: thosedepicting healthy lungs, those showing lung opacities, and those indicative ofviral pneumonia. Accurately diagnosing the disease at an early phase iscritical. In this paper, five different pre-trained models will be tested onthe Lung X-ray Image Dataset. SqueezeNet, VGG11, ResNet18, DenseNet, andMobileNetV2 achieved accuracies of 0.64, 0.85, 0.87, 0.88, and 0.885,respectively. MobileNetV2, as the best-performing pre-trained model, will thenbe further analyzed as the base model. Eventually, our own model,MobileNet-Lung based on MobileNetV2, with fine-tuning and an additional layerof attention within feature layers, was invented to tackle the lung diseaseclassification task and achieved an accuracy of 0.933. This result issignificantly improved compared with all five pre-trained models.</description><author>Xiaoyi Liu, Zhou Yu, Lianghao Tan</author><pubDate>Fri, 23 Aug 2024 16:00:10 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.13180v1</guid></item><item><title>Augmented Functional Random Forests: Classifier Construction and Unbiased Functional Principal Components Importance through Ad-Hoc Conditional Permutations</title><link>http://arxiv.org/abs/2408.13179v1</link><description>This paper introduces a novel supervised classification strategy thatintegrates functional data analysis (FDA) with tree-based methods, addressingthe challenges of high-dimensional data and enhancing the classificationperformance of existing functional classifiers. Specifically, we proposeaugmented versions of functional classification trees and functional randomforests, incorporating a new tool for assessing the importance of functionalprincipal components. This tool provides an ad-hoc method for determiningunbiased permutation feature importance in functional data, particularly whendealing with correlated features derived from successive derivatives. Our studydemonstrates that these additional features can significantly enhance thepredictive power of functional classifiers. Experimental evaluations on bothreal-world and simulated datasets showcase the effectiveness of the proposedmethodology, yielding promising results compared to existing methods.</description><author>Fabrizio Maturo, Annamaria Porreca</author><pubDate>Fri, 23 Aug 2024 15:58:41 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.13179v1</guid></item><item><title>Identifying Crucial Objects in Blind and Low-Vision Individuals' Navigation</title><link>http://arxiv.org/abs/2408.13175v1</link><description>This paper presents a curated list of 90 objects essential for the navigationof blind and low-vision (BLV) individuals, encompassing road, sidewalk, andindoor environments. We develop the initial list by analyzing 21 publiclyavailable videos featuring BLV individuals navigating various settings. Then,we refine the list through feedback from a focus group study involving blind,low-vision, and sighted companions of BLV individuals. A subsequent analysisreveals that most contemporary datasets used to train recent computer visionmodels contain only a small subset of the objects in our proposed list.Furthermore, we provide detailed object labeling for these 90 objects across 31video segments derived from the original 21 videos. Finally, we make the objectlist, the 21 videos, and object labeling in the 31 video segments publiclyavailable. This paper aims to fill the existing gap and foster the developmentof more inclusive and effective navigation aids for the BLV community.</description><author>Md Touhidul Islam, Imran Kabir, Elena Ariel Pearce, Md Alimoor Reza, Syed Masum Billah</author><pubDate>Fri, 23 Aug 2024 15:50:50 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.13175v1</guid></item><item><title>Lessons in co-creation: the inconvenient truths of inclusive sign language technology development</title><link>http://arxiv.org/abs/2408.13171v1</link><description>In the era of AI-driven language technologies, there is a growing demand forthe participation and leadership of deaf communities in sign languagetechnology development, often framed as co-creation. This paper, developedthrough collaborative and iterative dialogue between the authors with data frominformal participant observations, examines the involvement of the EuropeanUnion of the Deaf in two EU Horizon 2020 projects, EASIER and SignON. Theseprojects aimed to develop mobile translation applications between signed andspoken languages, bringing together predominantly hearing, non-signingtechnology experts with predominantly hearing sign language academics andorganizations representing deaf end users in large multi-partner consortia.While co-creation is sometimes presented as the best or required way to doresearch or even as emancipatory, it frequently masks systemic issues of powerimbalances and tokenism. Drawing from EUD's experiences of these projects, wehighlight several inconvenient truths of co-creation, and propose seven lessonsfor future initiatives: recognizing deaf partners' invisible labour as work,managing expectations about technologies, cripping co-creation processes,exploring alternative methods to mitigate co-creation fatigue, seekingintersectional feedback, ensuring co-creation is not just virtue signalling,and fostering deaf leadership in AI sign language research. We argue forco-creation as a transformative activity that fundamentally alters the statusquo and levels the playing field. This necessitates increasing the number ofdeaf researchers and enhancing AI literacy among deaf communities. Withoutthese critical transformative actions, co-creation risks merely paying lipservice to deaf communities.</description><author>Maartje De Meulder, Davy Van Landuyt, Rehana Omardeen</author><pubDate>Fri, 23 Aug 2024 15:43:34 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.13171v1</guid></item><item><title>A density ratio framework for evaluating the utility of synthetic data</title><link>http://arxiv.org/abs/2408.13167v1</link><description>Synthetic data generation is a promising technique to facilitate the use ofsensitive data while mitigating the risk of privacy breaches. However, forsynthetic data to be useful in downstream analysis tasks, it needs to be ofsufficient quality. Various methods have been proposed to measure the utilityof synthetic data, but their results are often incomplete or even misleading.In this paper, we propose using density ratio estimation to improve qualityevaluation for synthetic data, and thereby the quality of synthesized datasets.We show how this framework relates to and builds on existing measures, yieldingglobal and local utility measures that are informative and easy to interpret.We develop an estimator which requires little to no manual tuning due toautomatic selection of a nonparametric density ratio model. Throughsimulations, we find that density ratio estimation yields more accurateestimates of global utility than established procedures. A real-world dataapplication demonstrates how the density ratio can guide refinements ofsynthesis models and can be used to improve downstream analyses. We concludethat density ratio estimation is a valuable tool in synthetic data generationworkflows and provide these methods in the accessible open source R-packagedensityratio.</description><author>Thom Benjamin Volker, Peter-Paul de Wolf, Erik-Jan van Kesteren</author><pubDate>Fri, 23 Aug 2024 15:39:30 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.13167v1</guid></item><item><title>Say No to Freeloader: Protecting Intellectual Property of Your Deep Model</title><link>http://arxiv.org/abs/2408.13161v1</link><description>Model intellectual property (IP) protection has attracted growing attentionas science and technology advancements stem from human intellectual labor andcomputational expenses. Ensuring IP safety for trainers and owners is of utmostimportance, particularly in domains where ownership verification andapplicability authorization are required. A notable approach to safeguardingmodel IP involves proactively preventing the use of well-trained models ofauthorized domains from unauthorized domains. In this paper, we introduce anovel Compact Un-transferable Pyramid Isolation Domain (CUPI-Domain) whichserves as a barrier against illegal transfers from authorized to unauthorizeddomains. Drawing inspiration from human transitive inference and learningabilities, the CUPI-Domain is designed to obstruct cross-domain transfers byemphasizing the distinctive style features of the authorized domain. Thisemphasis leads to failure in recognizing irrelevant private style features onunauthorized domains. To this end, we propose novel CUPI-Domain generators,which select features from both authorized and CUPI-Domain as anchors. Then, wefuse the style features and semantic features of these anchors to generatelabeled and style-rich CUPI-Domain. Additionally, we design externalDomain-Information Memory Banks (DIMB) for storing and updating labeled pyramidfeatures to obtain stable domain class features and domain class-wise stylefeatures. Based on the proposed whole method, the novel style anddiscriminative loss functions are designed to effectively enhance thedistinction in style and discriminative features between authorized andunauthorized domains, respectively. Moreover, we provide two solutions forutilizing CUPI-Domain based on whether the unauthorized domain is known:target-specified CUPI-Domain and target-free CUPI-Domain.</description><author>Lianyu Wang, Meng Wang, Huazhu Fu, Daoqiang Zhang</author><pubDate>Fri, 23 Aug 2024 15:34:33 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.13161v1</guid></item><item><title>KonvLiNA: Integrating Kolmogorov-Arnold Network with Linear Nyström Attention for feature fusion in Crop Field Detection</title><link>http://arxiv.org/abs/2408.13160v1</link><description>Crop field detection is a critical component of precision agriculture,essential for optimizing resource allocation and enhancing agriculturalproductivity. This study introduces KonvLiNA, a novel framework that integratesConvolutional Kolmogorov-Arnold Networks (cKAN) with Nystr\"om attentionmechanisms for effective crop field detection. Leveraging KAN adaptiveactivation functions and the efficiency of Nystr\"om attention in handlinglargescale data, KonvLiNA significantly enhances feature extraction, enablingthe model to capture intricate patterns in complex agricultural environments.Experimental results on rice crop dataset demonstrate KonvLiNA superiority overstate-of-the-art methods, achieving a 0.415 AP and 0.459 AR with the Swin-Lbackbone, outperforming traditional YOLOv8 by significant margins.Additionally, evaluation on the COCO dataset showcases competitive performanceacross small, medium, and large objects, highlighting KonvLiNA efficacy indiverse agricultural settings. This work highlights the potential of hybrid KANand attention mechanisms for advancing precision agriculture through improvedcrop field detection and management.</description><author>Haruna Yunusa, Qin Shiyin, Adamu Lawan, Abdulrahman Hamman Adama Chukkol</author><pubDate>Fri, 23 Aug 2024 15:33:07 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.13160v1</guid></item><item><title>Doubly-Dynamic ISAC Precoding for Vehicular Networks: A Constrained Deep Reinforcement Learning (CDRL) Approach</title><link>http://arxiv.org/abs/2405.14347v3</link><description>Integrated sensing and communication (ISAC) technology is essential forsupporting vehicular networks. However, the communication channel in thisscenario exhibits time variations, and the potential targets may move rapidly,resulting in double dynamics. This nature poses a challenge for real-timeprecoder design. While optimization-based solutions are widely researched, theyare complex and heavily rely on perfect channel-related information, which isimpractical in double dynamics. To address this challenge, we propose usingconstrained deep reinforcement learning to facilitate dynamic updates to theISAC precoder. Additionally, the primal dual-deep deterministic policy gradientand Wolpertinger architecture are tailored to efficiently train the algorithmunder complex constraints and varying numbers of users. The proposed scheme notonly adapts to the dynamics based on observations but also leveragesenvironmental information to enhance performance and reduce complexity. Itssuperiority over existing candidates has been validated through experiments.</description><author>Zonghui Yang, Shijian Gao, Xiang Cheng</author><pubDate>Fri, 23 Aug 2024 15:31:28 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.14347v3</guid></item><item><title>AI and Jobs: Has the Inflection Point Arrived? Evidence from an Online Labor Platform</title><link>http://arxiv.org/abs/2312.04180v2</link><description>The emergence of Large Language Models (LLMs) has renewed the debate on theimportant issue of "technology displacement". While prior research hasinvestigated the effect of information technology in general on human laborfrom a macro perspective, this paper complements the literature by examiningthe impact of LLMs on freelancers from a micro perspective. Specifically, weleverage the release of ChatGPT to investigate how AI influences freelancersacross different online labor markets (OLMs). Employing theDifference-in-Differences method, we discovered two distinct scenariosfollowing ChatGPT's release: 1) the displacement effect of LLMs, featuringreduced work volume and earnings, as is exemplified by the translation &amp;localization OLM; 2) the productivity effect of LLMs, featuring increased workvolume and earnings, as is exemplified by the web development OLM. To shedlight on the underlying mechanisms, we developed a Cournot-type competitionmodel to highlight the existence of an inflection point for each occupationwhich separates the timeline of AI progress into a honeymoon phase and asubstitution phase. Before AI performance crosses the inflection point, humanlabor benefits each time AI improves, resulting in the honeymoon phase.However, after AI performance crosses the inflection point, additional AIenhancement hurts human labor. Further analyzing the progression from ChatGPT3.5 to 4.0, we found three effect scenarios (i.e., productivity toproductivity, displacement to displacement, and productivity to displacement),consistent with the inflection point conjecture. Heterogeneous analyses revealthat U.S. web developers tend to benefit more from the release of ChatGPTcompared to their counterparts in other regions, and somewhat surprisingly,experienced translators seem more likely to exit the market than lessexperienced translators after the release of ChatGPT.</description><author>Dandan Qiao, Huaxia Rui, Qian Xiong</author><pubDate>Fri, 23 Aug 2024 15:29:05 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.04180v2</guid></item><item><title>Causal machine learning for sustainable agroecosystems</title><link>http://arxiv.org/abs/2408.13155v1</link><description>In a changing climate, sustainable agriculture is essential for food securityand environmental health. However, it is challenging to understand the complexinteractions among its biophysical, social, and economic components. Predictivemachine learning (ML), with its capacity to learn from data, is leveraged insustainable agriculture for applications like yield prediction and weatherforecasting. Nevertheless, it cannot explain causal mechanisms and remainsdescriptive rather than prescriptive. To address this gap, we propose causalML, which merges ML's data processing with causality's ability to reason aboutchange. This facilitates quantifying intervention impacts for evidence-baseddecision-making and enhances predictive model robustness. We showcase causal MLthrough eight diverse applications that benefit stakeholders across theagri-food chain, including farmers, policymakers, and researchers.</description><author>Vasileios Sitokonstantinou, Emiliano Díaz Salas Porras, Jordi Cerdà Bautista, Maria Piles, Ioannis Athanasiadis, Hannah Kerner, Giulia Martini, Lily-belle Sweet, Ilias Tsoumas, Jakob Zscheischler, Gustau Camps-Valls</author><pubDate>Fri, 23 Aug 2024 15:25:50 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.13155v1</guid></item><item><title>Interpretable breast cancer classification using CNNs on mammographic images</title><link>http://arxiv.org/abs/2408.13154v1</link><description>Deep learning models have achieved promising results in breast cancerclassification, yet their 'black-box' nature raises interpretability concerns.This research addresses the crucial need to gain insights into thedecision-making process of convolutional neural networks (CNNs) for mammogramclassification, specifically focusing on the underlying reasons for the CNN'spredictions of breast cancer. For CNNs trained on the Mammographic ImageAnalysis Society (MIAS) dataset, we compared the post-hoc interpretabilitytechniques LIME, Grad-CAM, and Kernel SHAP in terms of explanatory depth andcomputational efficiency. The results of this analysis indicate that Grad-CAM,in particular, provides comprehensive insights into the behavior of the CNN,revealing distinctive patterns in normal, benign, and malignant breast tissue.We discuss the implications of the current findings for the use of machinelearning models and interpretation techniques in clinical practice.</description><author>Ann-Kristin Balve, Peter Hendrix</author><pubDate>Fri, 23 Aug 2024 15:25:42 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.13154v1</guid></item><item><title>Generative Topological Networks</title><link>http://arxiv.org/abs/2406.15152v2</link><description>Generative models have seen significant advancements in recent years, yetoften remain challenging and costly to train and use. We introduce GenerativeTopological Networks (GTNs) -- a new class of generative models that addressesthese shortcomings. GTNs are trained deterministically using a simplesupervised learning approach grounded in topology theory. GTNs are fast totrain, and require only a single forward pass in a standard feedforward neuralnetwork to generate samples. We demonstrate the strengths of GTNs on severaldatasets, including MNIST, CelebA and the Hands and Palm Images dataset.Finally, the theory behind GTNs offers insights into how to train generativemodels for improved performance. Code and weights are available at:https://github.com/alonalj/GTN</description><author>Alona Levy-Jurgenson, Zohar Yakhini</author><pubDate>Fri, 23 Aug 2024 15:23:19 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.15152v2</guid></item><item><title>Long-Term Pre-training for Temporal Action Detection with Transformers</title><link>http://arxiv.org/abs/2408.13152v1</link><description>Temporal action detection (TAD) is challenging, yet fundamental forreal-world video applications. Recently, DETR-based models for TAD have beenprevailing thanks to their unique benefits. However, transformers demand a hugedataset, and unfortunately data scarcity in TAD causes a severe degeneration.In this paper, we identify two crucial problems from data scarcity: attentioncollapse and imbalanced performance. To this end, we propose a new pre-trainingstrategy, Long-Term Pre-training (LTP), tailored for transformers. LTP has twomain components: 1) class-wise synthesis, 2) long-term pretext tasks. Firstly,we synthesize long-form video features by merging video snippets of a targetclass and non-target classes. They are analogous to untrimmed data used in TAD,despite being created from trimmed data. In addition, we devise two types oflong-term pretext tasks to learn long-term dependency. They impose long-termconditions such as finding second-to-fourth or short-duration actions. Ourextensive experiments show state-of-the-art performances in DETR-based methodson ActivityNet-v1.3 and THUMOS14 by a large margin. Moreover, we demonstratethat LTP significantly relieves the data scarcity issues in TAD.</description><author>Jihwan Kim, Miso Lee, Jae-Pil Heo</author><pubDate>Fri, 23 Aug 2024 15:20:53 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.13152v1</guid></item><item><title>Adaptive Backtracking For Faster Optimization</title><link>http://arxiv.org/abs/2408.13150v1</link><description>Backtracking line search is foundational in numerical optimization. The basicidea is to adjust the step size of an algorithm by a constant factor until somechosen criterion (e.g. Armijo, Goldstein, Descent Lemma) is satisfied. Wepropose a new way for adjusting step sizes, replacing the constant factor usedin regular backtracking with one that takes into account the degree to whichthe chosen criterion is violated, without additional computational burden. Forconvex problems, we prove adaptive backtracking requires fewer adjustments toproduce a feasible step size than regular backtracking does for two popularline search criteria: the Armijo condition and the descent lemma. For nonconvexsmooth problems, we additionally prove adaptive backtracking enjoys the sameguarantees of regular backtracking. Finally, we perform a variety ofexperiments on over fifteen real world datasets, all of which confirm thatadaptive backtracking often leads to significantly faster optimization.</description><author>Joao V. Cavalcanti, Laurent Lessard, Ashia C. Wilson</author><pubDate>Fri, 23 Aug 2024 15:16:57 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.13150v1</guid></item><item><title>Spiking NeRF: Representing the Real-World Geometry by a Discontinuous Representation</title><link>http://arxiv.org/abs/2311.09077v3</link><description>A crucial reason for the success of existing NeRF-based methods is to build aneural density field for the geometry representation via multiple perceptronlayers (MLPs). MLPs are continuous functions, however, real geometry or densityfield is frequently discontinuous at the interface between the air and thesurface. Such a contrary brings the problem of unfaithful geometryrepresentation. To this end, this paper proposes spiking NeRF, which leveragesspiking neurons and a hybrid Artificial Neural Network (ANN)-Spiking NeuralNetwork (SNN) framework to build a discontinuous density field for faithfulgeometry representation. Specifically, we first demonstrate the reason whycontinuous density fields will bring inaccuracy. Then, we propose to use thespiking neurons to build a discontinuous density field. We conduct acomprehensive analysis for the problem of existing spiking neuron models andthen provide the numerical relationship between the parameter of the spikingneuron and the theoretical accuracy of geometry. Based on this, we propose abounded spiking neuron to build the discontinuous density field. Our methodachieves SOTA performance. The source code and the supplementary material areavailable at https://github.com/liaozhanfeng/Spiking-NeRF.</description><author>Zhanfeng Liao, Qian Zheng, Yan Liu, Gang Pan</author><pubDate>Fri, 23 Aug 2024 15:16:29 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.09077v3</guid></item><item><title>Focus on Neighbors and Know the Whole: Towards Consistent Dense Multiview Text-to-Image Generator for 3D Creation</title><link>http://arxiv.org/abs/2408.13149v1</link><description>Generating dense multiview images from text prompts is crucial for creatinghigh-fidelity 3D assets. Nevertheless, existing methods struggle withspace-view correspondences, resulting in sparse and low-quality outputs. Inthis paper, we introduce CoSER, a novel consistent dense MultiviewText-to-Image Generator for Text-to-3D, achieving both efficiency and qualityby meticulously learning neighbor-view coherence and further alleviatingambiguity through the swift traversal of all views. For achieving neighbor-viewconsistency, each viewpoint densely interacts with adjacent viewpoints toperceive the global spatial structure, and aggregates information along motionpaths explicitly defined by physical principles to refine details. To furtherenhance cross-view consistency and alleviate content drift, CoSER rapidly scanall views in spiral bidirectional manner to aware holistic information and thenscores each point based on semantic material. Subsequently, we conduct weighteddown-sampling along the spatial dimension based on scores, thereby facilitatingprominent information fusion across all views with lightweight computation.Technically, the core module is built by integrating the attention mechanismwith a selective state space model, exploiting the robust learning capabilitiesof the former and the low overhead of the latter. Extensive evaluation showsthat CoSER is capable of producing dense, high-fidelity, content-consistentmultiview images that can be flexibly integrated into various 3D generationmodels.</description><author>Bonan Li, Zicheng Zhang, Xingyi Yang, Xinchao Wang</author><pubDate>Fri, 23 Aug 2024 15:16:01 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.13149v1</guid></item><item><title>ShapeICP: Iterative Category-level Object Pose and Shape Estimation from Depth</title><link>http://arxiv.org/abs/2408.13147v1</link><description>Category-level object pose and shape estimation from a single depth image hasrecently drawn research attention due to its wide applications in robotics andself-driving. The task is particularly challenging because the three unknowns,object pose, object shape, and model-to-measurement correspondences, arecompounded together but only a single view of depth measurements is provided.The vast majority of the prior work heavily relies on data-driven approaches toobtain solutions to at least one of the unknowns and typically two, runningwith the risk of failing to generalize to unseen domains. The shaperepresentations used in the prior work also mainly focus on point cloud andsigned distance field (SDF). In stark contrast to the prior work, we approachthe problem using an iterative estimation method that does not require learningfrom any pose-annotated data. In addition, we adopt a novel mesh-based objectactive shape model that has not been explored by the previous literature. Ouralgorithm, named ShapeICP, has its foundation in the iterative closest point(ICP) algorithm but is equipped with additional features for the category-levelpose and shape estimation task. The results show that even without using anypose-annotated data, ShapeICP surpasses many data-driven approaches that relyon the pose data for training, opening up new solution space for researchers toconsider.</description><author>Yihao Zhang, John J. Leonard</author><pubDate>Fri, 23 Aug 2024 15:12:55 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.13147v1</guid></item><item><title>Reproduction of scan B-statistic for kernel change-point detection algorithm</title><link>http://arxiv.org/abs/2408.13146v1</link><description>Change-point detection has garnered significant attention due to its broadrange of applications, including epidemic disease outbreaks, social networkevolution, image analysis, and wireless communications. In an online setting,where new data samples arrive sequentially, it is crucial to continuously testwhether these samples originate from a different distribution. Ideally, thedetection algorithm should be distribution-free to ensure robustness inreal-world applications. In this paper, we reproduce a recently proposed onlinechange-point detection algorithm based on an efficient kernel-based scanB-statistic, and compare its performance with two commonly used parametricstatistics. Our numerical experiments demonstrate that the scan B-statisticconsistently delivers superior performance. In more challenging scenarios,parametric methods may fail to detect changes, whereas the scan B-statisticsuccessfully identifies them in a timely manner. Additionally, the use ofsubsampling techniques offers a modest improvement to the original algorithm.</description><author>Zihan Wang</author><pubDate>Fri, 23 Aug 2024 15:12:31 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.13146v1</guid></item><item><title>iMTSP: Solving Min-Max Multiple Traveling Salesman Problem with Imperative Learning</title><link>http://arxiv.org/abs/2405.00285v4</link><description>This paper considers a Min-Max Multiple Traveling Salesman Problem (MTSP),where the goal is to find a set of tours, one for each agent, to collectivelyvisit all the cities while minimizing the length of the longest tour. ThoughMTSP has been widely studied, obtaining near-optimal solutions for large-scaleproblems is still challenging due to its NP-hardness. Recent efforts indata-driven methods face challenges of the need for hard-to-obtain supervisionand issues with high variance in gradient estimations, leading to slowconvergence and highly suboptimal solutions. We address these issues byreformulating MTSP as a bilevel optimization problem, using the concept ofimperative learning (IL). This involves introducing an allocation network thatdecomposes the MTSP into multiple single-agent traveling salesman problems(TSPs). The longest tour from these TSP solutions is then used toself-supervise the allocation network, resulting in a new self-supervised,bilevel, end-to-end learning framework, which we refer to as imperative MTSP(iMTSP). Additionally, to tackle the high-variance gradient issues during theoptimization, we introduce a control variate-based gradient estimationalgorithm. Our experiments showed that these innovative designs enable ourgradient estimator to converge 20% faster than the advanced reinforcementlearning baseline and find up to 80% shorter tour length compared with GoogleOR-Tools MTSP solver, especially in large-scale problems (e.g. 1000 cities and15 agents).</description><author>Yifan Guo, Zhongqiang Ren, Chen Wang</author><pubDate>Fri, 23 Aug 2024 15:02:34 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.00285v4</guid></item><item><title>Verification of Geometric Robustness of Neural Networks via Piecewise Linear Approximation and Lipschitz Optimisation</title><link>http://arxiv.org/abs/2408.13140v1</link><description>We address the problem of verifying neural networks against geometrictransformations of the input image, including rotation, scaling, shearing, andtranslation. The proposed method computes provably sound piecewise linearconstraints for the pixel values by using sampling and linear approximations incombination with branch-and-bound Lipschitz optimisation. A feature of themethod is that it obtains tighter over-approximations of the perturbationregion than the present state-of-the-art. We report results from experiments ona comprehensive set of benchmarks. We show that our proposed implementationresolves more verification cases than present approaches while being morecomputationally efficient.</description><author>Ben Batten, Yang Zheng, Alessandro De Palma, Panagiotis Kouvaros, Alessio Lomuscio</author><pubDate>Fri, 23 Aug 2024 15:02:09 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.13140v1</guid></item><item><title>Optimally Solving Simultaneous-Move Dec-POMDPs: The Sequential Central Planning Approach</title><link>http://arxiv.org/abs/2408.13139v1</link><description>Centralized training for decentralized execution paradigm emerged as thestate-of-the-art approach to epsilon-optimally solving decentralized partiallyobservable Markov decision processes. However, scalability remains asignificant issue. This paper presents a novel and more scalable alternative,namely sequential-move centralized training for decentralized execution. Thisparadigm further pushes the applicability of Bellman's principle of optimality,raising three new properties. First, it allows a central planner to reason uponsufficient sequential-move statistics instead of prior simultaneous-move ones.Next, it proves that epsilon-optimal value functions are piecewise linear andconvex in sufficient sequential-move statistics. Finally, it drops thecomplexity of the backup operators from double exponential to polynomial at theexpense of longer planning horizons. Besides, it makes it easy to usesingle-agent methods, e.g., SARSA algorithm enhanced with these findingsapplies while still preserving convergence guarantees. Experiments on two- aswell as many-agent domains from the literature against epsilon-optimalsimultaneous-move solvers confirm the superiority of the novel approach. Thisparadigm opens the door for efficient planning and reinforcement learningmethods for multi-agent systems.</description><author>Johan Peralez, Aurélien Delage, Jacopo Castellini, Rafael F. Cunha, Jilles S. Dibangoye</author><pubDate>Fri, 23 Aug 2024 15:01:37 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.13139v1</guid></item><item><title>Deep Learning at the Intersection: Certified Robustness as a Tool for 3D Vision</title><link>http://arxiv.org/abs/2408.13135v1</link><description>This paper presents preliminary work on a novel connection between certifiedrobustness in machine learning and the modeling of 3D objects. We highlight anintriguing link between the Maximal Certified Radius (MCR) of a classifierrepresenting a space's occupancy and the space's Signed Distance Function(SDF). Leveraging this relationship, we propose to use the certification methodof randomized smoothing (RS) to compute SDFs. Since RS' high computational costprevents its practical usage as a way to compute SDFs, we propose an algorithmto efficiently run RS in low-dimensional applications, such as 3D space, byexpressing RS' fundamental operations as Gaussian smoothing on pre-computedvoxel grids. Our approach offers an innovative and practical tool to computeSDFs, validated through proof-of-concept experiments in novel view synthesis.This paper bridges two previously disparate areas of machine learning, openingnew avenues for further exploration and potential cross-domain advancements.</description><author>Gabriel Pérez S, Juan C. Pérez, Motasem Alfarra, Jesús Zarzar, Sara Rojas, Bernard Ghanem, Pablo Arbeláez</author><pubDate>Fri, 23 Aug 2024 15:00:32 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.13135v1</guid></item><item><title>DeTPP: Leveraging Object Detection for Robust Long-Horizon Event Prediction</title><link>http://arxiv.org/abs/2408.13131v1</link><description>Forecasting future events over extended periods, known as long-horizonprediction, is a fundamental task in various domains, including retail,finance, healthcare, and social networks. Traditional methods, such as MarkedTemporal Point Processes (MTPP), typically use autoregressive models to predictmultiple future events. However, these models frequently encounter issues suchas converging to constant or repetitive outputs, which significantly limitstheir effectiveness and applicability. To overcome these limitations, wepropose DeTPP (Detection-based Temporal Point Processes), a novel approachinspired by object detection methods from computer vision. DeTPP utilizes anovel matching-based loss function that selectively focuses on reliablypredictable events, enhancing both training robustness and inference diversity.Our method sets a new state-of-the-art in long-horizon event prediction,significantly outperforming existing MTPP and next-K approaches. Theimplementation of DeTPP is publicly available on GitHub.</description><author>Ivan Karpukhin, Andrey Savchenko</author><pubDate>Fri, 23 Aug 2024 14:57:46 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.13131v1</guid></item><item><title>CathAction: A Benchmark for Endovascular Intervention Understanding</title><link>http://arxiv.org/abs/2408.13126v1</link><description>Real-time visual feedback from catheterization analysis is crucial forenhancing surgical safety and efficiency during endovascular interventions.However, existing datasets are often limited to specific tasks, small scale,and lack the comprehensive annotations necessary for broader endovascularintervention understanding. To tackle these limitations, we introduceCathAction, a large-scale dataset for catheterization understanding. OurCathAction dataset encompasses approximately 500,000 annotated frames forcatheterization action understanding and collision detection, and 25,000 groundtruth masks for catheter and guidewire segmentation. For each task, webenchmark recent related works in the field. We further discuss the challengesof endovascular intentions compared to traditional computer vision tasks andpoint out open research questions. We hope that CathAction will facilitate thedevelopment of endovascular intervention understanding methods that can beapplied to real-world applications. The dataset is available athttps://airvlab.github.io/cathdata/.</description><author>Baoru Huang, Tuan Vo, Chayun Kongtongvattana, Giulio Dagnino, Dennis Kundrat, Wenqiang Chi, Mohamed Abdelaziz, Trevor Kwok, Tudor Jianu, Tuong Do, Hieu Le, Minh Nguyen, Hoan Nguyen, Erman Tjiputra, Quang Tran, Jianyang Xie, Yanda Meng, Binod Bhattarai, Zhaorui Tan, Hongbin Liu, Hong Seng Gan, Wei Wang, Xi Yang, Qiufeng Wang, Jionglong Su, Kaizhu Huang, Angelos Stefanidis, Min Guo, Bo Du, Rong Tao, Minh Vu, Guoyan Zheng, Yalin Zheng, Francisco Vasconcelos, Danail Stoyanov, Daniel Elson, Ferdinando Rodriguez y Baena, Anh Nguyen</author><pubDate>Fri, 23 Aug 2024 14:54:49 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.13126v1</guid></item><item><title>Evidential Deep Partial Multi-View Classification With Discount Fusion</title><link>http://arxiv.org/abs/2408.13123v1</link><description>Incomplete multi-view data classification poses significant challenges due tothe common issue of missing views in real-world scenarios. Despiteadvancements, existing methods often fail to provide reliable predictions,largely due to the uncertainty of missing views and the inconsistent quality ofimputed data. To tackle these problems, we propose a novel framework calledEvidential Deep Partial Multi-View Classification (EDP-MVC). Initially, we useK-means imputation to address missing views, creating a complete set ofmulti-view data. However, the potential conflicts and uncertainties within thisimputed data can affect the reliability of downstream inferences. To managethis, we introduce a Conflict-Aware Evidential Fusion Network (CAEFN), whichdynamically adjusts based on the reliability of the evidence, ensuringtrustworthy discount fusion and producing reliable inference outcomes.Comprehensive experiments on various benchmark datasets reveal EDP-MVC not onlymatches but often surpasses the performance of state-of-the-art methods.</description><author>Haojian Huang, Zhe Liu, Sukumar Letchmunan, Mingwei Lin, Muhammet Deveci, Witold Pedrycz, Patrick Siarry</author><pubDate>Fri, 23 Aug 2024 14:50:49 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.13123v1</guid></item><item><title>Global Attractor for a Reaction-Diffusion Model Arising in Biological Dynamic in 3D Soil Structure</title><link>http://arxiv.org/abs/2310.02060v2</link><description>Partial Differential Equations (PDEs) play a crucial role as tools formodeling and comprehending intricate natural processes, notably within thedomain of biology. This research explores the domain of microbial activitywithin the complex matrix of 3D soil structures, providing valuableunderstanding into both the existence and uniqueness of solutions and theasymptotic behavior of the corresponding PDE model. Our investigation resultsin the discovery of a global attractor, a fundamental feature with significantimplications for long-term system behavior. To enhance the clarity of ourfindings, numerical simulations are employed to visually illustrate theattributes of this global attractor.</description><author>Mohamed Elghandouri, Khalil Ezzinbi, Mouad Klai, Olivier Monga</author><pubDate>Fri, 23 Aug 2024 14:42:14 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.02060v2</guid></item><item><title>End-to-end Surface Optimization for Light Control</title><link>http://arxiv.org/abs/2408.13117v1</link><description>Designing a freeform surface to reflect or refract light to achieve a targetdistribution is a challenging inverse problem. In this paper, we propose anend-to-end optimization strategy for an optical surface mesh. Our formulationleverages a novel differentiable rendering model, and is directly driven by thedifference between the resulting light distribution and the targetdistribution. We also enforce geometric constraints related to fabricationrequirements, to facilitate CNC milling and polishing of the designed surface.To address the issue of local minima, we formulate a face-based optimaltransport problem between the current mesh and the target distribution, whichmakes effective large changes to the surface shape. The combination of ouroptimal transport update and rendering-guided optimization produces an opticalsurface design with a resulting image closely resembling the target, while thefabrication constraints in our optimization help to ensure consistency betweenthe rendering model and the final physical results. The effectiveness of ouralgorithm is demonstrated on a variety of target images using both simulatedrendering and physical prototypes.</description><author>Yuou Sun, Bailin Deng, Juyong Zhang</author><pubDate>Fri, 23 Aug 2024 14:40:40 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.13117v1</guid></item><item><title>Controlled Learning of Pointwise Nonlinearities in Neural-Network-Like Architectures</title><link>http://arxiv.org/abs/2408.13114v1</link><description>We present a general variational framework for the training of freeformnonlinearities in layered computational architectures subject to some slopeconstraints. The regularization that we add to the traditional training losspenalizes the second-order total variation of each trainable activation. Theslope constraints allow us to impose properties such as 1-Lipschitz stability,firm non-expansiveness, and monotonicity/invertibility. These properties arecrucial to ensure the proper functioning of certain classes ofsignal-processing algorithms (e.g., plug-and-play schemes, unrolled proximalgradient, invertible flows). We prove that the global optimum of the statedconstrained-optimization problem is achieved with nonlinearities that areadaptive nonuniform linear splines. We then show how to solve the resultingfunction-optimization problem numerically by representing the nonlinearities ina suitable (nonuniform) B-spline basis. Finally, we illustrate the use of ourframework with the data-driven design of (weakly) convex regularizers for thedenoising of images and the resolution of inverse problems.</description><author>Michael Unser, Alexis Goujon, Stanislas Ducotterd</author><pubDate>Fri, 23 Aug 2024 14:39:27 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.13114v1</guid></item><item><title>Leveraging Task Structures for Improved Identifiability in Neural Network Representations</title><link>http://arxiv.org/abs/2306.14861v3</link><description>This work extends the theory of identifiability in supervised learning byconsidering the consequences of having access to a distribution of tasks. Insuch cases, we show that linear identifiability is achievable in the generalmulti-task regression setting. Furthermore, we show that the existence of atask distribution which defines a conditional prior over latent factors reducesthe equivalence class for identifiability to permutations and scaling of thetrue latent factors, a stronger and more useful result than linearidentifiability. Crucially, when we further assume a causal structure overthese tasks, our approach enables simple maximum marginal likelihoodoptimization, and suggests potential downstream applications to causalrepresentation learning. Empirically, we find that this straightforwardoptimization procedure enables our model to outperform more generalunsupervised models in recovering canonical representations for both syntheticdata and real-world molecular data.</description><author>Wenlin Chen, Julien Horwood, Juyeon Heo, José Miguel Hernández-Lobato</author><pubDate>Fri, 23 Aug 2024 14:26:46 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.14861v3</guid></item><item><title>Dynamic Label Adversarial Training for Deep Learning Robustness Against Adversarial Attacks</title><link>http://arxiv.org/abs/2408.13102v1</link><description>Adversarial training is one of the most effective methods for enhancing modelrobustness. Recent approaches incorporate adversarial distillation inadversarial training architectures. However, we notice two scenarios of defensemethods that limit their performance: (1) Previous methods primarily use staticground truth for adversarial training, but this often causes robustoverfitting; (2) The loss functions are either Mean Squared Error orKL-divergence leading to a sub-optimal performance on clean accuracy. To solvethose problems, we propose a dynamic label adversarial training (DYNAT)algorithm that enables the target model to gradually and dynamically gainrobustness from the guide model's decisions. Additionally, we found that abudgeted dimension of inner optimization for the target model may contribute tothe trade-off between clean accuracy and robust accuracy. Therefore, we proposea novel inner optimization method to be incorporated into the adversarialtraining. This will enable the target model to adaptively search foradversarial examples based on dynamic labels from the guiding model,contributing to the robustness of the target model. Extensive experimentsvalidate the superior performance of our approach.</description><author>Zhenyu Liu, Haoran Duan, Huizhi Liang, Yang Long, Vaclav Snasel, Guiseppe Nicosia, Rajiv Ranjan, Varun Ojha</author><pubDate>Fri, 23 Aug 2024 14:25:12 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.13102v1</guid></item><item><title>Functional Tensor Decompositions for Physics-Informed Neural Networks</title><link>http://arxiv.org/abs/2408.13101v1</link><description>Physics-Informed Neural Networks (PINNs) have shown continuous and increasingpromise in approximating partial differential equations (PDEs), although theyremain constrained by the curse of dimensionality. In this paper, we propose ageneralized PINN version of the classical variable separable method. To dothis, we first show that, using the universal approximation theorem, amultivariate function can be approximated by the outer product of neuralnetworks, whose inputs are separated variables. We leverage tensordecomposition forms to separate the variables in a PINN setting. By employingCanonic Polyadic (CP), Tensor-Train (TT), and Tucker decomposition forms withinthe PINN framework, we create robust architectures for learning multivariatefunctions from separate neural networks connected by outer products. Ourmethodology significantly enhances the performance of PINNs, as evidenced byimproved results on complex high-dimensional PDEs, including the 3d Helmholtzand 5d Poisson equations, among others. This research underscores the potentialof tensor decomposition-based variably separated PINNs to surpass thestate-of-the-art, offering a compelling solution to the dimensionalitychallenge in PDE approximation.</description><author>Sai Karthikeya Vemuri, Tim Büchner, Julia Niebling, Joachim Denzler</author><pubDate>Fri, 23 Aug 2024 14:24:43 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.13101v1</guid></item><item><title>Large-scale Pre-trained Models are Surprisingly Strong in Incremental Novel Class Discovery</title><link>http://arxiv.org/abs/2303.15975v5</link><description>Discovering novel concepts in unlabelled datasets and in a continuous manneris an important desideratum of lifelong learners. In the literature suchproblems have been partially addressed under very restricted settings, wherenovel classes are learned by jointly accessing a related labelled set (e.g.,NCD) or by leveraging only a supervisedly pre-trained model (e.g., class-iNCD).In this work we challenge the status quo in class-iNCD and propose a learningparadigm where class discovery occurs continuously and truly unsupervisedly,without needing any related labelled set. In detail, we propose to exploit thericher priors from strong self-supervised pre-trained models (PTM). To thisend, we propose simple baselines, composed of a frozen PTM backbone and alearnable linear classifier, that are not only simple to implement but alsoresilient under longer learning scenarios. We conduct extensive empiricalevaluation on a multitude of benchmarks and show the effectiveness of ourproposed baselines when compared with sophisticated state-of-the-art methods.The code is open source.</description><author>Mingxuan Liu, Subhankar Roy, Zhun Zhong, Nicu Sebe, Elisa Ricci</author><pubDate>Fri, 23 Aug 2024 14:19:06 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2303.15975v5</guid></item><item><title>A Heterogeneous Dynamic Convolutional Neural Network for Image Super-resolution</title><link>http://arxiv.org/abs/2402.15704v2</link><description>Convolutional neural networks can automatically learn features via deepnetwork architectures and given input samples. However, robustness of obtainedmodels may have challenges in varying scenes. Bigger differences of a networkarchitecture are beneficial to extract more complementary structuralinformation to enhance robustness of an obtained super-resolution model. Inthis paper, we present a heterogeneous dynamic convolutional network in imagesuper-resolution (HDSRNet). To capture more information, HDSRNet is implementedby a heterogeneous parallel network. The upper network can facilitate morecontexture information via stacked heterogeneous blocks to improve effects ofimage super-resolution. Each heterogeneous block is composed of a combinationof a dilated, dynamic, common convolutional layers, ReLU and residual learningoperation. It can not only adaptively adjust parameters, according to differentinputs, but also prevent long-term dependency problem. The lower networkutilizes a symmetric architecture to enhance relations of different layers tomine more structural information, which is complementary with a upper networkfor image super-resolution. The relevant experimental results show that theproposed HDSRNet is effective to deal with image resolving. The code of HDSRNetcan be obtained at https://github.com/hellloxiaotian/HDSRNet.</description><author>Chunwei Tian, Xuanyu Zhang, Tao Wang, Wangmeng Zuo, Yanning Zhang, Chia-Wen Lin</author><pubDate>Fri, 23 Aug 2024 14:18:17 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.15704v2</guid></item><item><title>Diffusion-based Episodes Augmentation for Offline Multi-Agent Reinforcement Learning</title><link>http://arxiv.org/abs/2408.13092v1</link><description>Offline multi-agent reinforcement learning (MARL) is increasingly recognizedas crucial for effectively deploying RL algorithms in environments wherereal-time interaction is impractical, risky, or costly. In the offline setting,learning from a static dataset of past interactions allows for the developmentof robust and safe policies without the need for live data collection, whichcan be fraught with challenges. Building on this foundational importance, wepresent EAQ, Episodes Augmentation guided by Q-total loss, a novel approach foroffline MARL framework utilizing diffusion models. EAQ integrates the Q-totalfunction directly into the diffusion model as a guidance to maximize the globalreturns in an episode, eliminating the need for separate training. Our focusprimarily lies on cooperative scenarios, where agents are required to actcollectively towards achieving a shared goal-essentially, maximizing globalreturns. Consequently, we demonstrate that our episodes augmentation in acollaborative manner significantly boosts offline MARL algorithm compared tothe original dataset, improving the normalized return by +17.3% and +12.9% formedium and poor behavioral policies in SMAC simulator, respectively.</description><author>Jihwan Oh, Sungnyun Kim, Gahee Kim, Sunghwan Kim, Se-Young Yun</author><pubDate>Fri, 23 Aug 2024 14:17:17 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.13092v1</guid></item><item><title>Analysis of child development facts and myths using text mining techniques and classification models</title><link>http://arxiv.org/abs/2408.13091v1</link><description>The rapid dissemination of misinformation on the internet complicates thedecision-making process for individuals seeking reliable information,particularly parents researching child development topics. This misinformationcan lead to adverse consequences, such as inappropriate treatment of childrenbased on myths. While previous research has utilized text-mining techniques topredict child abuse cases, there has been a gap in the analysis of childdevelopment myths and facts. This study addresses this gap by applying textmining techniques and classification models to distinguish between myths andfacts about child development, leveraging newly gathered data from publiclyavailable websites. The research methodology involved several stages. First,text mining techniques were employed to pre-process the data, ensuring enhancedaccuracy. Subsequently, the structured data was analysed using six robustMachine Learning (ML) classifiers and one Deep Learning (DL) model, with twofeature extraction techniques applied to assess their performance across threedifferent training-testing splits. To ensure the reliability of the results,cross-validation was performed using both k-fold and leave-one-out methods.Among the classification models tested, Logistic Regression (LR) demonstratedthe highest accuracy, achieving a 90% accuracy with the Bag-of-Words (BoW)feature extraction technique. LR stands out for its exceptional speed andefficiency, maintaining low testing time per statement (0.97 microseconds).These findings suggest that LR, when combined with BoW, is effective inaccurately classifying child development information, thus providing a valuabletool for combating misinformation and assisting parents in making informeddecisions.</description><author>Mehedi Tajrian, Azizur Rahman, Muhammad Ashad Kabir, Md Rafiqul Islam</author><pubDate>Fri, 23 Aug 2024 14:16:54 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.13091v1</guid></item><item><title>On the good reliability of an interval-based metric to validate prediction uncertainty for machine learning regression tasks</title><link>http://arxiv.org/abs/2408.13089v1</link><description>This short study presents an opportunistic approach to a (more) reliablevalidation method for prediction uncertainty average calibration. Consideringthat variance-based calibration metrics (ZMS, NLL, RCE...) are quite sensitiveto the presence of heavy tails in the uncertainty and error distributions, ashift is proposed to an interval-based metric, the Prediction Interval CoverageProbability (PICP). It is shown on a large ensemble of molecular propertiesdatasets that (1) sets of z-scores are well represented by Student's-$t(\nu)$distributions, $\nu$ being the number of degrees of freedom; (2) accurateestimation of 95 $\%$ prediction intervals can be obtained by the simple$2\sigma$ rule for $\nu&gt;3$; and (3) the resulting PICPs are more quickly andreliably tested than variance-based calibration metrics. Overall, this methodenables to test 20 $\%$ more datasets than ZMS testing. Conditional calibrationis also assessed using the PICP approach.</description><author>Pascal Pernot</author><pubDate>Fri, 23 Aug 2024 14:16:10 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.13089v1</guid></item><item><title>Recent Advances in Generative AI and Large Language Models: Current Status, Challenges, and Perspectives</title><link>http://arxiv.org/abs/2407.14962v5</link><description>The emergence of Generative Artificial Intelligence (AI) and Large LanguageModels (LLMs) has marked a new era of Natural Language Processing (NLP),introducing unprecedented capabilities that are revolutionizing variousdomains. This paper explores the current state of these cutting-edgetechnologies, demonstrating their remarkable advancements and wide-rangingapplications. Our paper contributes to providing a holistic perspective on thetechnical foundations, practical applications, and emerging challenges withinthe evolving landscape of Generative AI and LLMs. We believe that understandingthe generative capabilities of AI systems and the specific context of LLMs iscrucial for researchers, practitioners, and policymakers to collaborativelyshape the responsible and ethical integration of these technologies intovarious domains. Furthermore, we identify and address main research gaps,providing valuable insights to guide future research endeavors within the AIresearch community.</description><author>Desta Haileselassie Hagos, Rick Battle, Danda B. Rawat</author><pubDate>Fri, 23 Aug 2024 14:14:21 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.14962v5</guid></item><item><title>Physics-Inspired Generative Models in Medical Imaging: A Review</title><link>http://arxiv.org/abs/2407.10856v2</link><description>Physics-inspired Generative Models (GMs), in particular Diffusion Models(DMs) and Poisson Flow Models (PFMs), enhance Bayesian methods and promisegreat utility in medical imaging. This review examines the transformative roleof such generative methods. First, a variety of physics-inspired GMs, includingDenoising Diffusion Probabilistic Models (DDPMs), Score-based Diffusion Models(SDMs), and Poisson Flow Generative Models (PFGMs and PFGM++), are revisited,with an emphasis on their accuracy, robustness as well as acceleration. Then,major applications of physics-inspired GMs in medical imaging are presented,comprising image reconstruction, image generation, and image analysis. Finally,future research directions are brainstormed, including unification ofphysics-inspired GMs, integration with Vision-Language Models (VLMs), andpotential novel applications of GMs. Since the development of generativemethods has been rapid, this review will hopefully give peers and learners atimely snapshot of this new family of physics-driven generative models and helpcapitalize their enormous potential for medical imaging.</description><author>Dennis Hein, Afshin Bozorgpour, Dorit Merhof, Ge Wang</author><pubDate>Fri, 23 Aug 2024 14:13:19 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.10856v2</guid></item><item><title>Map-Free Visual Relocalization Enhanced by Instance Knowledge and Depth Knowledge</title><link>http://arxiv.org/abs/2408.13085v1</link><description>Map-free relocalization technology is crucial for applications in autonomousnavigation and augmented reality, but relying on pre-built maps is oftenimpractical. It faces significant challenges due to limitations in matchingmethods and the inherent lack of scale in monocular images. These issues leadto substantial rotational and metric errors and even localization failures inreal-world scenarios. Large matching errors significantly impact the overallrelocalization process, affecting both rotational and translational accuracy.Due to the inherent limitations of the camera itself, recovering the metricscale from a single image is crucial, as this significantly impacts thetranslation error. To address these challenges, we propose a map-freerelocalization method enhanced by instance knowledge and depth knowledge. Byleveraging instance-based matching information to improve global matchingresults, our method significantly reduces the possibility of mismatching acrossdifferent objects. The robustness of instance knowledge across the scene helpsthe feature point matching model focus on relevant regions and enhance matchingaccuracy. Additionally, we use estimated metric depth from a single image toreduce metric errors and improve scale recovery accuracy. By integratingmethods dedicated to mitigating large translational and rotational errors, ourapproach demonstrates superior performance in map-free relocalizationtechniques.</description><author>Mingyu Xiao, Runze Chen, Haiyong Luo, Fang Zhao, Juan Wang, Xuepeng Ma</author><pubDate>Fri, 23 Aug 2024 14:12:03 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.13085v1</guid></item><item><title>Avatar Visual Similarity for Social HCI: Increasing Self-Awareness</title><link>http://arxiv.org/abs/2408.13084v1</link><description>Self-awareness is a critical factor in social human-human interaction and,hence, in social HCI interaction. Increasing self-awareness through mirrors orvideo recordings is common in face-to-face trainings, since it influencesantecedents of self-awareness like explicit identification and implicitaffective identification (affinity). However, increasing self-awareness hasbeen scarcely examined in virtual trainings with virtual avatars, which allowfor adjusting the similarity, e.g. to avoid negative effects ofself-consciousness. Automatic visual similarity in avatars is an open issuerelated to high costs. It is important to understand which features need to bemanipulated and which degree of similarity is necessary for self-awareness toleverage the added value of using avatars for self-awareness. This articleexamines the relationship between avatar visual similarity and increasingself-awareness in virtual training environments. We define visual similaritybased on perceptually important facial features for human-human identificationand develop a theory-based methodology to systematically manipulate visualsimilarity of virtual avatars and support self-awareness. Three personalizedversions of virtual avatars with varying degrees of visual similarity toparticipants were created (weak, medium and strong facial featuresmanipulation). In a within-subject study (N=33), we tested effects of degree ofsimilarity on perceived similarity, explicit identification and implicitaffective identification (affinity). Results show significant differencesbetween the weak similarity manipulation, and both the strong manipulation andthe random avatar for all three antecedents of self-awareness. An increasingdegree of avatar visual similarity influences antecedents of self-awareness invirtual environments.</description><author>Bernhard Hilpert, Claudio Alves da Silva, Leon Christidis, Chirag Bhuvaneshwara, Patrick Gebhard, Fabrizio Nunnari, Dimitra Tsovaltzi</author><pubDate>Fri, 23 Aug 2024 14:11:35 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.13084v1</guid></item><item><title>Enhancing Training Efficiency Using Packing with Flash Attention</title><link>http://arxiv.org/abs/2407.09105v5</link><description>Padding is often used in tuning LLM models by adding special tokens toshorter training examples to match the length of the longest sequence in eachbatch. While this ensures uniformity for batch processing, it introducesinefficiencies by including irrelevant padding tokens in the computation andwastes GPU resources. Hugging Face SFT trainer has always offered the option touse packing to combine multiple training examples, allowing for maximalutilization of GPU resources. However, up till now, it did not offer propermasking of each packed training example. This capability has now been added toHugging Face Transformers 4.44. We analyse this new feature and show thebenefits across different variations of packing.</description><author>Achintya Kundu, Rhui Dih Lee, Laura Wynter, Raghu Kiran Ganti, Mayank Mishra</author><pubDate>Fri, 23 Aug 2024 14:11:05 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.09105v5</guid></item><item><title>MathScape: Evaluating MLLMs in multimodal Math Scenarios through a Hierarchical Benchmark</title><link>http://arxiv.org/abs/2408.07543v3</link><description>With the development of Multimodal Large Language Models (MLLMs), theevaluation of multimodal models in the context of mathematical problems hasbecome a valuable research field. Multimodal visual-textual mathematicalreasoning serves as a critical indicator for evaluating the comprehension andcomplex multi-step quantitative reasoning abilities of MLLMs. However, previousmultimodal math benchmarks have not sufficiently integrated visual and textualinformation. To address this gap, we proposed MathScape, a new benchmark thatemphasizes the understanding and application of combined visual and textualinformation. MathScape is designed to evaluate photo-based math problemscenarios, assessing the theoretical understanding and application ability ofMLLMs through a categorical hierarchical approach. We conduct amulti-dimensional evaluation on 11 advanced MLLMs, revealing that our benchmarkis challenging even for the most sophisticated models. By analyzing theevaluation results, we identify the limitations of MLLMs, offering valuableinsights for enhancing model performance.</description><author>Minxuan Zhou, Hao Liang, Tianpeng Li, Zhiyu Wu, Mingan Lin, Linzhuang Sun, Yaqi Zhou, Yan Zhang, Xiaoqin Huang, Yicong Chen, Yujing Qiao, Weipeng Chen, Bin Cui, Wentao Zhang, Zenan Zhou</author><pubDate>Fri, 23 Aug 2024 14:09:34 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.07543v3</guid></item><item><title>Multivariate Time-Series Anomaly Detection based on Enhancing Graph Attention Networks with Topological Analysis</title><link>http://arxiv.org/abs/2408.13082v1</link><description>Unsupervised anomaly detection in time series is essential in industrialapplications, as it significantly reduces the need for manual intervention.Multivariate time series pose a complex challenge due to their feature andtemporal dimensions. Traditional methods use Graph Neural Networks (GNNs) orTransformers to analyze spatial while RNNs to model temporal dependencies.These methods focus narrowly on one dimension or engage in coarse-grainedfeature extraction, which can be inadequate for large datasets characterized byintricate relationships and dynamic changes. This paper introduces a noveltemporal model built on an enhanced Graph Attention Network (GAT) formultivariate time series anomaly detection called TopoGDN. Our model analyzesboth time and feature dimensions from a fine-grained perspective. First, weintroduce a multi-scale temporal convolution module to extract detailedtemporal features. Additionally, we present an augmented GAT to manage complexinter-feature dependencies, which incorporates graph topology into nodefeatures across multiple scales, a versatile, plug-and-play enhancement thatsignificantly boosts the performance of GAT. Our experimental results confirmthat our approach surpasses the baseline models on four datasets, demonstratingits potential for widespread application in fields requiring robust anomalydetection. The code is available at https://github.com/ljj-cyber/TopoGDN.</description><author>Zhe Liu, Xiang Huang, Jingyun Zhang, Zhifeng Hao, Li Sun, Hao Peng</author><pubDate>Fri, 23 Aug 2024 14:06:30 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.13082v1</guid></item><item><title>Abductive Reasoning in a Paraconsistent Framework</title><link>http://arxiv.org/abs/2408.07287v2</link><description>We explore the problem of explaining observations starting from a classicallyinconsistent theory by adopting a paraconsistent framework. We consider twoexpansions of the well-known Belnap--Dunn paraconsistent four-valued logic$\mathsf{BD}$: $\mathsf{BD}_\circ$ introduces formulas of the form $\circ\phi$(the information on $\phi$ is reliable), while $\mathsf{BD}_\triangle$ augmentsthe language with $\triangle\phi$'s (there is information that $\phi$ is true).We define and motivate the notions of abduction problems and explanations in$\mathsf{BD}_\circ$ and $\mathsf{BD}_\triangle$ and show that they are notreducible to one another. We analyse the complexity of standard abductivereasoning tasks (solution recognition, solution existence, and relevance /necessity of hypotheses) in both logics. Finally, we show how to reduceabduction in $\mathsf{BD}_\circ$ and $\mathsf{BD}_\triangle$ to abduction inclassical propositional logic, thereby enabling the reuse of existing abductivereasoning procedures.</description><author>Meghyn Bienvenu, Katsumi Inoue, Daniil Kozhemiachenko</author><pubDate>Fri, 23 Aug 2024 14:05:17 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.07287v2</guid></item><item><title>AEMLO: AutoEncoder-Guided Multi-Label Oversampling</title><link>http://arxiv.org/abs/2408.13078v1</link><description>Class imbalance significantly impacts the performance of multi-labelclassifiers. Oversampling is one of the most popular approaches, as it augmentsinstances associated with less frequent labels to balance the classdistribution. Existing oversampling methods generate feature vectors ofsynthetic samples through replication or linear interpolation and assign labelsthrough neighborhood information. Linear interpolation typically generates newsamples between existing data points, which may result in insufficientdiversity of synthesized samples and further lead to the overfitting issue.Deep learning-based methods, such as AutoEncoders, have been proposed togenerate more diverse and complex synthetic samples, achieving excellentperformance on imbalanced binary or multi-class datasets. In this study, weintroduce AEMLO, an AutoEncoder-guided Oversampling technique specificallydesigned for tackling imbalanced multi-label data. AEMLO is built upon twofundamental components. The first is an encoder-decoder architecture thatenables the model to encode input data into a low-dimensional feature space,learn its latent representations, and then reconstruct it back to its originaldimension, thus applying to the generation of new data. The second is anobjective function tailored to optimize the sampling task for multi-labelscenarios. We show that AEMLO outperforms the existing state-of-the-art methodswith extensive empirical studies.</description><author>Ao Zhou, Bin Liu, Jin Wang, Kaiwei Sun, Kelin Liu</author><pubDate>Fri, 23 Aug 2024 14:01:33 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.13078v1</guid></item><item><title>Hierarchical Spatio-Temporal State-Space Modeling for fMRI Analysis</title><link>http://arxiv.org/abs/2408.13074v1</link><description>Recent advances in deep learning structured state space models, especiallythe Mamba architecture, have demonstrated remarkable performance improvementswhile maintaining linear complexity. In this study, we introduce functionalspatiotemporal Mamba (FST-Mamba), a Mamba-based model designed for discoveringneurological biomarkers using functional magnetic resonance imaging (fMRI). Wefocus on dynamic functional network connectivity (dFNC) derived from fMRI andpropose a hierarchical spatiotemporal Mamba-based network that processesspatial and temporal information separately using Mamba-based encoders.Leveraging the topological uniqueness of the FNC matrix, we introduce acomponent-wise varied-scale aggregation (CVA) mechanism to aggregateconnectivity across individual components within brain networks, enabling themodel to capture both inter-component and inter-network information. To betterhandle the FNC data, we develop a new component-specific scanning order.Additionally, we propose symmetric rotary position encoding (SymRope) to encodethe relative positions of each functional connection while considering thesymmetric nature of the FNC matrix. Experimental results demonstratesignificant improvements in the proposed FST-Mamba model on various brain-basedclassification and regression tasks. Our work reveals the substantial potentialof attention-free sequence modeling in brain discovery.</description><author>Yuxiang Wei, Anees Abrol, Reihaneh Hassanzadeh, Vince Calhoun</author><pubDate>Fri, 23 Aug 2024 13:58:14 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.13074v1</guid></item><item><title>Resilience through Scene Context in Visual Referring Expression Generation</title><link>http://arxiv.org/abs/2404.12289v2</link><description>Scene context is well known to facilitate humans' perception of visibleobjects. In this paper, we investigate the role of context in ReferringExpression Generation (REG) for objects in images, where existing research hasoften focused on distractor contexts that exert pressure on the generator. Wetake a new perspective on scene context in REG and hypothesize that contextualinformation can be conceived of as a resource that makes REG models moreresilient and facilitates the generation of object descriptions, and objecttypes in particular. We train and test Transformer-based REG models with targetrepresentations that have been artificially obscured with noise to varyingdegrees. We evaluate how properties of the models' visual context affect theirprocessing and performance. Our results show that even simple scene contextsmake models surprisingly resilient to perturbations, to the extent that theycan identify referent types even when visual information about the target iscompletely missing.</description><author>Simeon Junker, Sina Zarrieß</author><pubDate>Fri, 23 Aug 2024 13:58:12 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.12289v2</guid></item><item><title>IntelliCare: Improving Healthcare Analysis with Variance-Controlled Patient-Level Knowledge from Large Language Models</title><link>http://arxiv.org/abs/2408.13073v1</link><description>While pioneering deep learning methods have made great strides in analyzingelectronic health record (EHR) data, they often struggle to fully capture thesemantics of diverse medical codes from limited data. The integration ofexternal knowledge from Large Language Models (LLMs) presents a promisingavenue for improving healthcare predictions. However, LLM analyses may exhibitsignificant variance due to ambiguity problems and inconsistency issues,hindering their effective utilization. To address these challenges, we proposeIntelliCare, a novel framework that leverages LLMs to provide high-qualitypatient-level external knowledge and enhance existing EHR models. Concretely,IntelliCare identifies patient cohorts and employs task-relevant statisticalinformation to augment LLM understanding and generation, effectively mitigatingthe ambiguity problem. Additionally, it refines LLM-derived knowledge through ahybrid approach, generating multiple analyses and calibrating them using boththe EHR model and perplexity measures. Experimental evaluations on threeclinical prediction tasks across two large-scale EHR datasets demonstrate thatIntelliCare delivers significant performance improvements to existing methods,highlighting its potential in advancing personalized healthcare predictions anddecision support systems.</description><author>Zhihao Yu, Yujie Jin, Yongxin Xu, Xu Chu, Yasha Wang, Junfeng Zhao</author><pubDate>Fri, 23 Aug 2024 13:56:00 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.13073v1</guid></item><item><title>mHuBERT-147: A Compact Multilingual HuBERT Model</title><link>http://arxiv.org/abs/2406.06371v4</link><description>We present mHuBERT-147, the first general-purpose massively multilingualHuBERT speech representation model trained on 90K hours of clean, open-licensedata. To scale up the multi-iteration HuBERT approach, we use faiss-basedclustering, achieving 5.2x faster label assignment than the original method. Wealso apply a new multilingual batching up-sampling strategy, leveraging bothlanguage and dataset diversity. After 3 training iterations, our compact 95Mparameter mHuBERT-147 outperforms larger models trained on substantially moredata. We rank second and first on the ML-SUPERB 10min and 1h leaderboards, withSOTA scores for 3 tasks. Across ASR/LID tasks, our model consistently surpassesXLS-R (300M params; 436K hours) and demonstrates strong competitiveness againstthe much larger MMS (1B params; 491K hours). Our findings indicate thatmHuBERT-147 is a promising model for multilingual speech tasks, offering anunprecedented balance between high performance and parameter efficiency.</description><author>Marcely Zanon Boito, Vivek Iyer, Nikolaos Lagos, Laurent Besacier, Ioan Calapodescu</author><pubDate>Fri, 23 Aug 2024 13:55:50 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.06371v4</guid></item><item><title>On Class Separability Pitfalls In Audio-Text Contrastive Zero-Shot Learning</title><link>http://arxiv.org/abs/2408.13068v1</link><description>Recent advances in audio-text cross-modal contrastive learning have shown itspotential towards zero-shot learning. One possibility for this is by projectingitem embeddings from pre-trained backbone neural networks into a cross-modalspace in which item similarity can be calculated in either domain. This processrelies on a strong unimodal pre-training of the backbone networks, and on adata-intensive training task for the projectors. These two processes can bebiased by unintentional data leakage, which can arise from using supervisedlearning in pre-training or from inadvertently training the cross-modalprojection using labels from the zero-shot learning evaluation. In this study,we show that a significant part of the measured zero-shot learning accuracy isdue to strengths inherited from the audio and text backbones, that is, they arenot learned in the cross-modal domain and are not transferred from one modalityto another.</description><author>Tiago Tavares, Fabio Ayres, Zhepei Wang, Paris Smaragdis</author><pubDate>Fri, 23 Aug 2024 13:52:56 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.13068v1</guid></item></channel></rss>