<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/"><channel><title>Arxivfresh papers</title><link></link><description>Arxiv paper</description><language>en-US</language><lastBuildDate>Mon, 08 Jan 2024 14:00:24 GMT</lastBuildDate><generator>rfeed v1.0.0</generator><docs>https://github.com/svpino/rfeed/blob/master/README.md</docs><item><title>Denoising Vision Transformers</title><link>http://arxiv.org/abs/2401.02957v1</link><description>We delve into a nuanced but significant challenge inherent to VisionTransformers (ViTs): feature maps of these models exhibit grid-like artifacts,which detrimentally hurt the performance of ViTs in downstream tasks. Ourinvestigations trace this fundamental issue down to the positional embeddingsat the input stage. To address this, we propose a novel noise model, which isuniversally applicable to all ViTs. Specifically, the noise model dissects ViToutputs into three components: a semantics term free from noise artifacts andtwo artifact-related terms that are conditioned on pixel locations. Such adecomposition is achieved by enforcing cross-view feature consistency withneural fields in a per-image basis. This per-image optimization processextracts artifact-free features from raw ViT outputs, providing clean featuresfor offline applications. Expanding the scope of our solution to support onlinefunctionality, we introduce a learnable denoiser to predict artifact-freefeatures directly from unprocessed ViT outputs, which shows remarkablegeneralization capabilities to novel data without the need for per-imageoptimization. Our two-stage approach, termed Denoising Vision Transformers(DVT), does not require re-training existing pre-trained ViTs and isimmediately applicable to any Transformer-based architecture. We evaluate ourmethod on a variety of representative ViTs (DINO, MAE, DeiT-III, EVA02, CLIP,DINOv2, DINOv2-reg). Extensive evaluations demonstrate that our DVTconsistently and significantly improves existing state-of-the-artgeneral-purpose models in semantic and geometric tasks across multiple datasets(e.g., +3.84 mIoU). We hope our study will encourage a re-evaluation of ViTdesign, especially regarding the naive use of positional embeddings.</description><author>Jiawei Yang, Katie Z Luo, Jiefeng Li, Kilian Q Weinberger, Yonglong Tian, Yue Wang</author><pubDate>Fri, 05 Jan 2024 18:59:52 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.02957v1</guid></item><item><title>MC-ViViT: Multi-branch Classifier-ViViT to detect Mild Cognitive Impairment in older adults using facial videos</title><link>http://arxiv.org/abs/2304.05292v4</link><description>Deep machine learning models including Convolutional Neural Networks (CNN)have been successful in the detection of Mild Cognitive Impairment (MCI) usingmedical images, questionnaires, and videos. This paper proposes a novelMulti-branch Classifier-Video Vision Transformer (MC-ViViT) model todistinguish MCI from those with normal cognition by analyzing facial features.The data comes from the I-CONECT, a behavioral intervention trial aimed atimproving cognitive function by providing frequent video chats. MC-ViViTextracts spatiotemporal features of videos in one branch and augmentsrepresentations by the MC module. The I-CONECT dataset is challenging as thedataset is imbalanced containing Hard-Easy and Positive-Negative samples, whichimpedes the performance of MC-ViViT. We propose a loss function for Hard-Easyand Positive-Negative Samples (HP Loss) by combining Focal loss and AD-CORREloss to address the imbalanced problem. Our experimental results on theI-CONECT dataset show the great potential of MC-ViViT in predicting MCI with ahigh accuracy of 90.63% accuracy on some of the interview videos.</description><author>Jian Sun, Hiroko H. Dodge, Mohammad H. Mahoor</author><pubDate>Fri, 05 Jan 2024 18:59:41 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2304.05292v4</guid></item><item><title>Open-Vocabulary SAM: Segment and Recognize Twenty-thousand Classes Interactively</title><link>http://arxiv.org/abs/2401.02955v1</link><description>The CLIP and Segment Anything Model (SAM) are remarkable vision foundationmodels (VFMs). SAM excels in segmentation tasks across diverse domains, whileCLIP is renowned for its zero-shot recognition capabilities. This paperpresents an in-depth exploration of integrating these two models into a unifiedframework. Specifically, we introduce the Open-Vocabulary SAM, a SAM-inspiredmodel designed for simultaneous interactive segmentation and recognition,leveraging two unique knowledge transfer modules: SAM2CLIP and CLIP2SAM. Theformer adapts SAM's knowledge into the CLIP via distillation and learnabletransformer adapters, while the latter transfers CLIP knowledge into SAM,enhancing its recognition capabilities. Extensive experiments on variousdatasets and detectors show the effectiveness of Open-Vocabulary SAM in bothsegmentation and recognition tasks, significantly outperforming the naivebaselines of simply combining SAM and CLIP. Furthermore, aided with imageclassification data training, our method can segment and recognizeapproximately 22,000 classes.</description><author>Haobo Yuan, Xiangtai Li, Chong Zhou, Yining Li, Kai Chen, Chen Change Loy</author><pubDate>Fri, 05 Jan 2024 18:59:22 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.02955v1</guid></item><item><title>DeepSeek LLM: Scaling Open-Source Language Models with Longtermism</title><link>http://arxiv.org/abs/2401.02954v1</link><description>The rapid development of open-source large language models (LLMs) has beentruly remarkable. However, the scaling law described in previous literaturepresents varying conclusions, which casts a dark cloud over scaling LLMs. Wedelve into the study of scaling laws and present our distinctive findings thatfacilitate scaling of large scale models in two commonly used open-sourceconfigurations, 7B and 67B. Guided by the scaling laws, we introduce DeepSeekLLM, a project dedicated to advancing open-source language models with along-term perspective. To support the pre-training phase, we have developed adataset that currently consists of 2 trillion tokens and is continuouslyexpanding. We further conduct supervised fine-tuning (SFT) and DirectPreference Optimization (DPO) on DeepSeek LLM Base models, resulting in thecreation of DeepSeek Chat models. Our evaluation results demonstrate thatDeepSeek LLM 67B surpasses LLaMA-2 70B on various benchmarks, particularly inthe domains of code, mathematics, and reasoning. Furthermore, open-endedevaluations reveal that DeepSeek LLM 67B Chat exhibits superior performancecompared to GPT-3.5.</description><author>DeepSeek-AI, :, Xiao Bi, Deli Chen, Guanting Chen, Shanhuang Chen, Damai Dai, Chengqi Deng, Honghui Ding, Kai Dong, Qiushi Du, Zhe Fu, Huazuo Gao, Kaige Gao, Wenjun Gao, Ruiqi Ge, Kang Guan, Daya Guo, Jianzhong Guo, Guangbo Hao, Zhewen Hao, Ying He, Wenjie Hu, Panpan Huang, Erhang Li, Guowei Li, Jiashi Li, Yao Li, Y. K. Li, Wenfeng Liang, Fangyun Lin, A. X. Liu, Bo Liu, Wen Liu, Xiaodong Liu, Xin Liu, Yiyuan Liu, Haoyu Lu, Shanghao Lu, Fuli Luo, Shirong Ma, Xiaotao Nie, Tian Pei, Yishi Piao, Junjie Qiu, Hui Qu, Tongzheng Ren, Zehui Ren, Chong Ruan, Zhangli Sha, Zhihong Shao, Junxiao Song, Xuecheng Su, Jingxiang Sun, Yaofeng Sun, Minghui Tang, Bingxuan Wang, Peiyi Wang, Shiyu Wang, Yaohui Wang, Yongji Wang, Tong Wu, Y. Wu, Xin Xie, Zhenda Xie, Ziwei Xie, Yiliang Xiong, Hanwei Xu, R. X. Xu, </author><pubDate>Fri, 05 Jan 2024 18:59:13 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.02954v1</guid></item><item><title>TreeLearn: A Comprehensive Deep Learning Method for Segmenting Individual Trees from Ground-Based LiDAR Forest Point Clouds</title><link>http://arxiv.org/abs/2309.08471v2</link><description>Laser-scanned point clouds of forests make it possible to extract valuableinformation for forest management. To consider single trees, a forest pointcloud needs to be segmented into individual tree point clouds. Existingsegmentation methods are usually based on hand-crafted algorithms, such asidentifying trunks and growing trees from them, and face difficulties in denseforests with overlapping tree crowns. In this study, we propose TreeLearn, adeep learning-based approach for tree instance segmentation of forest pointclouds. Unlike previous methods, TreeLearn is trained on already segmentedpoint clouds in a data-driven manner, making it less reliant on predefinedfeatures and algorithms. Furthermore, TreeLearn is implemented as a fullyautomatic pipeline and does not rely on extensive hyperparameter tuning, whichmakes it easy to use. Additionally, we introduce a new manually segmentedbenchmark forest dataset containing 156 full trees, and 79 partial trees, thathave been cleanly segmented by hand. The data is generated by mobile laserscanning and contributes to create a larger and more diverse data basis formodel development and fine-grained instance segmentation evaluation. We trainedTreeLearn on forest point clouds of 6665 trees, labeled using the Lidar360software. An evaluation on the benchmark dataset shows that TreeLearn performsequally well or better than the algorithm used to generate its training data.Furthermore, the method's performance can be vastly improved by fine-tuning onthe cleanly labeled benchmark dataset. The TreeLearn code is available fromhttps://github.com/ecker-lab/TreeLearn. The data as well as trained models canbe found at https://doi.org/10.25625/VPMPID.</description><author>Jonathan Henrich, Jan van Delden, Dominik Seidel, Thomas Kneib, Alexander Ecker</author><pubDate>Fri, 05 Jan 2024 18:57:34 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2309.08471v2</guid></item><item><title>The Tactician's Web of Large-Scale Formal Knowledge</title><link>http://arxiv.org/abs/2401.02950v1</link><description>The Tactician's Web is a platform offering a large web of stronglyinterconnected, machine-checked, formal mathematical knowledge convenientlypackaged for machine learning, analytics, and proof engineering. Built on topof the Coq proof assistant, the platform exports a dataset containing a widevariety of formal theories, presented as a web of definitions, theorems, proofterms, tactics, and proof states. Theories are encoded both as a semantic graph(rendered below) and as human-readable text, each with a unique set ofadvantages and disadvantages. Proving agents may interact with Coq through thesame rich data representation and can be automatically benchmarked on a set oftheorems. Tight integration with Coq provides the unique possibility to makeagents available to proof engineers as practical tools.</description><author>Lasse Blaauwbroek</author><pubDate>Fri, 05 Jan 2024 18:52:35 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.02950v1</guid></item><item><title>Graph2Tac: Learning Hierarchical Representations of Math Concepts in Theorem proving</title><link>http://arxiv.org/abs/2401.02949v1</link><description>Concepts abound in mathematics and its applications. They vary greatlybetween subject areas, and new ones are introduced in each mathematical paperor application. A formal theory builds a hierarchy of definitions, theorems andproofs that reference each other. When an AI agent is proving a new theorem,most of the mathematical concepts and lemmas relevant to that theorem may havenever been seen during training. This is especially true in the Coq proofassistant, which has a diverse library of Coq projects, each with its owndefinitions, lemmas, and even custom tactic procedures used to prove thoselemmas. It is essential for agents to incorporate such new information intotheir knowledge base on the fly. We work towards this goal by utilizing a new,large-scale, graph-based dataset for machine learning in Coq. We leverage afaithful graph-representation of Coq terms that induces a directed graph ofdependencies between definitions to create a novel graph neural network,Graph2Tac (G2T), that takes into account not only the current goal, but alsothe entire hierarchy of definitions that led to the current goal. G2T is anonline model that is deeply integrated into the users' workflow and can adaptin real time to new Coq projects and their definitions. It complements wellwith other online models that learn in real time from new proof scripts. Ournovel definition embedding task, which is trained to compute representations ofmathematical concepts not seen during training, boosts the performance of theneural network to rival state-of-the-art k-nearest neighbor predictors.</description><author>Jason Rute, Miroslav Olšák, Lasse Blaauwbroek, Fidel Ivan Schaposnik Massolo, Jelle Piepenbrock, Vasily Pestun</author><pubDate>Fri, 05 Jan 2024 18:52:09 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.02949v1</guid></item><item><title>A Novel Skip Orthogonal List for Dynamic Optimal Transport Problem</title><link>http://arxiv.org/abs/2310.18446v4</link><description>Optimal transport is a fundamental topic that has attracted a great amount ofattention from the optimization community in the past decades. In this paper,we consider an interesting discrete dynamic optimal transport problem: can weefficiently update the optimal transport plan when the weights or the locationsof the data points change? This problem is naturally motivated by severalapplications in machine learning. For example, we often need to compute theoptimal transport cost between two different data sets; if some changes happento a few data points, should we re-compute the high complexity cost function orupdate the cost by some efficient dynamic data structure? We are aware thatseveral dynamic maximum flow algorithms have been proposed before, however, theresearch on dynamic minimum cost flow problem is still quite limited, to thebest of our knowledge. We propose a novel 2D Skip Orthogonal List together withsome dynamic tree techniques. Although our algorithm is based on theconventional simplex method, it can efficiently find the variable to pivotwithin expected $O(1)$ time, and complete each pivoting operation withinexpected $O(|V|)$ time where $V$ is the set of all supply and demand nodes.Since dynamic modifications typically do not introduce significant changes, ouralgorithm requires only a few simplex iterations in practice. So our algorithmis more efficient than re-computing the optimal transport cost that needs atleast one traversal over all $|E| = O(|V|^2)$ variables, where $|E|$ denotesthe number of edges in the network. Our experiments demonstrate that ouralgorithm significantly outperforms existing algorithms in the dynamicscenarios.</description><author>Xiaoyang Xu, Hu Ding</author><pubDate>Fri, 05 Jan 2024 18:47:22 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.18446v4</guid></item><item><title>Digital-analog quantum learning on Rydberg atom arrays</title><link>http://arxiv.org/abs/2401.02940v1</link><description>We propose hybrid digital-analog learning algorithms on Rydberg atom arrays,combining the potentially practical utility and near-term realizability ofquantum learning with the rapidly scaling architectures of neutral atoms. Ourconstruction requires only single-qubit operations in the digital setting andglobal driving according to the Rydberg Hamiltonian in the analog setting. Weperform a comprehensive numerical study of our algorithm on both classical andquantum data, given respectively by handwritten digit classification andunsupervised quantum phase boundary learning. We show in the two representativeproblems that digital-analog learning is not only feasible in the near term,but also requires shorter circuit depths and is more robust to realistic errormodels as compared to digital learning schemes. Our results suggest thatdigital-analog learning opens a promising path towards improved variationalquantum learning experiments in the near term.</description><author>Jonathan Z. Lu, Lucy Jiao, Kristina Wolinski, Milan Kornjača, Hong-Ye Hu, Sergio Cantu, Fangli Liu, Susanne F. Yelin, Sheng-Tao Wang</author><pubDate>Fri, 05 Jan 2024 18:31:00 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.02940v1</guid></item><item><title>Locally Adaptive Neural 3D Morphable Models</title><link>http://arxiv.org/abs/2401.02937v1</link><description>We present the Locally Adaptive Morphable Model (LAMM), a highly flexibleAuto-Encoder (AE) framework for learning to generate and manipulate 3D meshes.We train our architecture following a simple self-supervised training scheme inwhich input displacements over a set of sparse control vertices are used tooverwrite the encoded geometry in order to transform one training sample intoanother. During inference, our model produces a dense output that adhereslocally to the specified sparse geometry while maintaining the overallappearance of the encoded object. This approach results in state-of-the-artperformance in both disentangling manipulated geometry and 3D meshreconstruction. To the best of our knowledge LAMM is the first end-to-endframework that enables direct local control of 3D vertex geometry in a singleforward pass. A very efficient computational graph allows our network to trainwith only a fraction of the memory required by previous methods and run fasterduring inference, generating 12k vertex meshes at $&gt;$60fps on a single CPUthread. We further leverage local geometry control as a primitive for higherlevel editing operations and present a set of derivative capabilities such asswapping and sampling object parts. Code and pretrained models can be found athttps://github.com/michaeltrs/LAMM.</description><author>Michail Tarasiou, Rolandos Alexandros Potamias, Eimear O'Sullivan, Stylianos Ploumpis, Stefanos Zafeiriou</author><pubDate>Fri, 05 Jan 2024 18:28:51 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.02937v1</guid></item><item><title>Enhancing Network Initialization for Medical AI Models Using Large-Scale, Unlabeled Natural Images</title><link>http://arxiv.org/abs/2308.07688v4</link><description>Pre-training datasets, like ImageNet, have become the gold standard inmedical image analysis. However, the emergence of self-supervised learning(SSL), which leverages unlabeled data to learn robust features, presents anopportunity to bypass the intensive labeling process. In this study, weexplored if SSL for pre-training on non-medical images can be applied to chestradiographs and how it compares to supervised pre-training on non-medicalimages and on medical images. We utilized a vision transformer and initializedits weights based on (i) SSL pre-training on natural images (DINOv2), (ii) SLpre-training on natural images (ImageNet dataset), and (iii) SL pre-training onchest radiographs from the MIMIC-CXR database. We tested our approach on over800,000 chest radiographs from six large global datasets, diagnosing more than20 different imaging findings. Our SSL pre-training on curated images not onlyoutperformed ImageNet-based pre-training (P&lt;0.001 for all datasets) but, incertain cases, also exceeded SL on the MIMIC-CXR dataset. Our findings suggestthat selecting the right pre-training strategy, especially with SSL, can bepivotal for improving artificial intelligence (AI)'s diagnostic accuracy inmedical imaging. By demonstrating the promise of SSL in chest radiographanalysis, we underline a transformative shift towards more efficient andaccurate AI models in medical imaging.</description><author>Soroosh Tayebi Arasteh, Leo Misera, Jakob Nikolas Kather, Daniel Truhn, Sven Nebelung</author><pubDate>Fri, 05 Jan 2024 18:25:42 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2308.07688v4</guid></item><item><title>SPFormer: Enhancing Vision Transformer with Superpixel Representation</title><link>http://arxiv.org/abs/2401.02931v1</link><description>In this work, we introduce SPFormer, a novel Vision Transformer enhanced bysuperpixel representation. Addressing the limitations of traditional VisionTransformers' fixed-size, non-adaptive patch partitioning, SPFormer employssuperpixels that adapt to the image's content. This approach divides the imageinto irregular, semantically coherent regions, effectively capturing intricatedetails and applicable at both initial and intermediate feature levels. SPFormer, trainable end-to-end, exhibits superior performance across variousbenchmarks. Notably, it exhibits significant improvements on the challengingImageNet benchmark, achieving a 1.4% increase over DeiT-T and 1.1% over DeiT-Srespectively. A standout feature of SPFormer is its inherent explainability.The superpixel structure offers a window into the model's internal processes,providing valuable insights that enhance the model's interpretability. Thislevel of clarity significantly improves SPFormer's robustness, particularly inchallenging scenarios such as image rotations and occlusions, demonstrating itsadaptability and resilience.</description><author>Jieru Mei, Liang-Chieh Chen, Alan Yuille, Cihang Xie</author><pubDate>Fri, 05 Jan 2024 18:15:26 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.02931v1</guid></item><item><title>Dagma-DCE: Interpretable, Non-Parametric Differentiable Causal Discovery</title><link>http://arxiv.org/abs/2401.02930v1</link><description>We introduce Dagma-DCE, an interpretable and model-agnostic scheme fordifferentiable causal discovery. Current non- or over-parametric methods indifferentiable causal discovery use opaque proxies of ``independence'' tojustify the inclusion or exclusion of a causal relationship. We showtheoretically and empirically that these proxies may be arbitrarily differentthan the actual causal strength. Juxtaposed to existing differentiable causaldiscovery algorithms, \textsc{Dagma-DCE} uses an interpretable measure ofcausal strength to define weighted adjacency matrices. In a number of simulateddatasets, we show our method achieves state-of-the-art level performance. Weadditionally show that \textsc{Dagma-DCE} allows for principled thresholdingand sparsity penalties by domain-experts. The code for our method is availableopen-source at https://github.com/DanWaxman/DAGMA-DCE, and can easily beadapted to arbitrary differentiable models.</description><author>Daniel Waxman, Kurt Butler, Petar M. Djuric</author><pubDate>Fri, 05 Jan 2024 18:15:19 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.02930v1</guid></item><item><title>Towards ASR Robust Spoken Language Understanding Through In-Context Learning With Word Confusion Networks</title><link>http://arxiv.org/abs/2401.02921v1</link><description>In the realm of spoken language understanding (SLU), numerous naturallanguage understanding (NLU) methodologies have been adapted by supplying largelanguage models (LLMs) with transcribed speech instead of conventional writtentext. In real-world scenarios, prior to input into an LLM, an automated speechrecognition (ASR) system generates an output transcript hypothesis, whereinherent errors can degrade subsequent SLU tasks. Here we introduce a methodthat utilizes the ASR system's lattice output instead of relying solely on thetop hypothesis, aiming to encapsulate speech ambiguities and enhance SLUoutcomes. Our in-context learning experiments, covering spoken questionanswering and intent classification, underline the LLM's resilience to noisyspeech transcripts with the help of word confusion networks from lattices,bridging the SLU performance gap between using the top ASR hypothesis and anoracle upper bound. Additionally, we delve into the LLM's robustness to varyingASR performance conditions and scrutinize the aspects of in-context learningwhich prove the most influential.</description><author>Kevin Everson, Yile Gu, Huck Yang, Prashanth Gurunath Shivakumar, Guan-Ting Lin, Jari Kolehmainen, Ivan Bulyko, Ankur Gandhe, Shalini Ghosh, Wael Hamza, Hung-yi Lee, Ariya Rastrow, Andreas Stolcke</author><pubDate>Fri, 05 Jan 2024 17:58:10 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.02921v1</guid></item><item><title>Language-free Compositional Action Generation via Decoupling Refinement</title><link>http://arxiv.org/abs/2307.03538v2</link><description>Composing simple elements into complex concepts is crucial yet challenging,especially for 3D action generation. Existing methods largely rely on extensiveneural language annotations to discern composable latent semantics, a processthat is often costly and labor-intensive. In this study, we introduce a novelframework to generate compositional actions without reliance on languageauxiliaries. Our approach consists of three main components: Action Coupling,Conditional Action Generation, and Decoupling Refinement. Action Couplingutilizes an energy model to extract the attention masks of each sub-action,subsequently integrating two actions using these attentions to generatepseudo-training examples. Then, we employ a conditional generative model, CVAE,to learn a latent space, facilitating the diverse generation. Finally, wepropose Decoupling Refinement, which leverages a self-supervised pre-trainedmodel MAE to ensure semantic consistency between the sub-actions andcompositional actions. This refinement process involves rendering generated 3Dactions into 2D space, decoupling these images into two sub-segments, using theMAE model to restore the complete image from sub-segments, and constraining therecovered images to match images rendered from raw sub-actions. Due to the lackof existing datasets containing both sub-actions and compositional actions, wecreated two new datasets, named HumanAct-C and UESTC-C, and present acorresponding evaluation metric. Both qualitative and quantitative assessmentsare conducted to show our efficacy.</description><author>Xiao Liu, Guangyi Chen, Yansong Tang, Guangrun Wang, Ser-Nam Lim</author><pubDate>Fri, 05 Jan 2024 17:56:56 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.03538v2</guid></item><item><title>Analytically-Driven Resource Management for Cloud-Native Microservices</title><link>http://arxiv.org/abs/2401.02920v1</link><description>Resource management for cloud-native microservices has attracted a lot ofrecent attention. Previous work has shown that machine learning (ML)-drivenapproaches outperform traditional techniques, such as autoscaling, in terms ofboth SLA maintenance and resource efficiency. However, ML-driven approachesalso face challenges including lengthy data collection processes and limitedscalability. We present Ursa, a lightweight resource management system forcloud-native microservices that addresses these challenges. Ursa uses ananalytical model that decomposes the end-to-end SLA into per-service SLA, andmaps per-service SLA to individual resource allocations per microservice tier.To speed up the exploration process and avoid prolonged SLA violations, Ursaexplores each microservice individually, and swiftly stops exploration iflatency exceeds its SLA. We evaluate Ursa on a set of representative and end-to-end microservicetopologies, including a social network, media service and video processingpipeline, each consisting of multiple classes and priorities of requests withdifferent SLAs, and compare it against two representative ML-driven systems,Sinan and Firm. Compared to these ML-driven approaches, Ursa providessignificant advantages: It shortens the data collection process by more than128x, and its control plane is 43x faster than ML-driven approaches. At thesame time, Ursa does not sacrifice resource efficiency or SLAs. During onlinedeployment, Ursa reduces the SLA violation rate by 9.0% up to 49.9%, andreduces CPU allocation by up to 86.2% compared to ML-driven approaches.</description><author>Yanqi Zhang, Zhuangzhuang Zhou, Sameh Elnikety, Christina Delimitrou</author><pubDate>Fri, 05 Jan 2024 17:55:32 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.02920v1</guid></item><item><title>Uncovering the human motion pattern: Pattern Memory-based Diffusion Model for Trajectory Prediction</title><link>http://arxiv.org/abs/2401.02916v1</link><description>Human trajectory forecasting is a critical challenge in fields such asrobotics and autonomous driving. Due to the inherent uncertainty of humanactions and intentions in real-world scenarios, various unexpected occurrencesmay arise. To uncover latent motion patterns in human behavior, we introduce anovel memory-based method, named Motion Pattern Priors Memory Network. Ourmethod involves constructing a memory bank derived from clustered priorknowledge of motion patterns observed in the training set trajectories. Weintroduce an addressing mechanism to retrieve the matched pattern and thepotential target distributions for each prediction from the memory bank, whichenables the identification and retrieval of natural motion patterns exhibitedby agents, subsequently using the target priors memory token to guide thediffusion model to generate predictions. Extensive experiments validate theeffectiveness of our approach, achieving state-of-the-art trajectory predictionaccuracy. The code will be made publicly available.</description><author>Yuxin Yang, Pengfei Zhu, Mengshi Qi, Huadong Ma</author><pubDate>Fri, 05 Jan 2024 17:39:52 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.02916v1</guid></item><item><title>A unified uncertainty-aware exploration: Combining epistemic and aleatory uncertainty</title><link>http://arxiv.org/abs/2401.02914v1</link><description>Exploration is a significant challenge in practical reinforcement learning(RL), and uncertainty-aware exploration that incorporates the quantification ofepistemic and aleatory uncertainty has been recognized as an effectiveexploration strategy. However, capturing the combined effect of aleatory andepistemic uncertainty for decision-making is difficult. Existing works estimatealeatory and epistemic uncertainty separately and consider the compositeuncertainty as an additive combination of the two. Nevertheless, the additiveformulation leads to excessive risk-taking behavior, causing instability. Inthis paper, we propose an algorithm that clarifies the theoretical connectionbetween aleatory and epistemic uncertainty, unifies aleatory and epistemicuncertainty estimation, and quantifies the combined effect of bothuncertainties for a risk-sensitive exploration. Our method builds on a novelextension of distributional RL that estimates a parameterized returndistribution whose parameters are random variables encoding epistemicuncertainty. Experimental results on tasks with exploration and risk challengesshow that our method outperforms alternative approaches.</description><author>Parvin Malekzadeh, Ming Hou, Konstantinos N. Plataniotis</author><pubDate>Fri, 05 Jan 2024 17:39:00 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.02914v1</guid></item><item><title>Astrocyte Regulated Neuromorphic Central Pattern Generator Control of Legged Robotic Locomotion</title><link>http://arxiv.org/abs/2312.15805v2</link><description>Neuromorphic computing systems, where information is transmitted throughaction potentials in a bio-plausible fashion, is gaining increasing interestdue to its promise of low-power event-driven computing. Application ofneuromorphic computing in robotic locomotion research have largely focused onCentral Pattern Generators (CPGs) for bionics robotic control algorithms -inspired from neural circuits governing the collaboration of the limb musclesin animal movement. Implementation of artificial CPGs on neuromorphic hardwareplatforms can potentially enable adaptive and energy-efficient edge roboticsapplications in resource constrained environments. However, underlying rewiringmechanisms in CPG for gait emergence process is not well understood. This workaddresses the missing gap in literature pertaining to CPG plasticity andunderscores the critical homeostatic functionality of astrocytes - a cellularcomponent in the brain that is believed to play a major role in multiple brainfunctions. This paper introduces an astrocyte regulated Spiking Neural Network(SNN)-based CPG for learning locomotion gait through Reward-Modulated STDP forquadruped robots, where the astrocytes help build inhibitory connections amongthe artificial motor neurons in different limbs. The SNN-based CPG is simulatedon a multi-object physics simulation platform resulting in the emergence of atrotting gait while running the robot on flat ground. $23.3\times$computational power savings is observed in comparison to a state-of-the-artreinforcement learning based robot control algorithm. Such aneuroscience-algorithm co-design approach can potentially enable a quantum leapin the functionality of neuromorphic systems incorporating glial cellfunctionality.</description><author>Zhuangyu Han, Abhronil Sengupta</author><pubDate>Fri, 05 Jan 2024 17:38:18 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.15805v2</guid></item><item><title>Variational Quantum and Quantum-Inspired Clustering</title><link>http://arxiv.org/abs/2206.09893v2</link><description>Here we present a quantum algorithm for clustering data based on avariational quantum circuit. The algorithm allows to classify data into manyclusters, and can easily be implemented in few-qubit Noisy Intermediate-ScaleQuantum (NISQ) devices. The idea of the algorithm relies on reducing theclustering problem to an optimization, and then solving it via a VariationalQuantum Eigensolver (VQE) combined with non-orthogonal qubit states. Inpractice, the method uses maximally-orthogonal states of the target Hilbertspace instead of the usual computational basis, allowing for a large number ofclusters to be considered even with few qubits. We benchmark the algorithm withnumerical simulations using real datasets, showing excellent performance evenwith one single qubit. Moreover, a tensor network simulation of the algorithmimplements, by construction, a quantum-inspired clustering algorithm that canrun on current classical hardware.</description><author>Pablo Bermejo, Roman Orus</author><pubDate>Fri, 05 Jan 2024 17:25:03 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2206.09893v2</guid></item><item><title>Surgical Aggregation: Federated Class-Heterogeneous Learning</title><link>http://arxiv.org/abs/2301.06683v5</link><description>The release of numerous chest x-ray datasets has spearheaded the developmentof deep learning models with expert-level performance. However, they havelimited interoperability due to class-heterogeneity -- a result of inconsistentlabeling schemes and partial annotations. Therefore, it is challenging toleverage these datasets in aggregate to train models with a completerepresentation of abnormalities that may occur within the thorax. In this work,we propose surgical aggregation, a federated learning framework for aggregatingknowledge from class-heterogeneous datasets and learn a model that cansimultaneously predict the presence of all disease labels present across thedatasets. We evaluate our method using simulated and real-worldclass-heterogeneous datasets across both independent and identicallydistributed (iid) and non-iid settings. Our results show that surgicalaggregation outperforms current methods, has better generalizability, and is acrucial first step towards tackling class-heterogeneity in federated learningto facilitate the development of clinically-useful models using previouslynon-interoperable chest x-ray datasets.</description><author>Pranav Kulkarni, Adway Kanhere, Paul H. Yi, Vishwa S. Parekh</author><pubDate>Fri, 05 Jan 2024 17:18:56 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2301.06683v5</guid></item><item><title>Introducing Bode: A Fine-Tuned Large Language Model for Portuguese Prompt-Based Task</title><link>http://arxiv.org/abs/2401.02909v1</link><description>Large Language Models (LLMs) are increasingly bringing advances to NaturalLanguage Processing. However, low-resource languages, those lacking extensiveprominence in datasets for various NLP tasks, or where existing datasets arenot as substantial, such as Portuguese, already obtain several benefits fromLLMs, but not to the same extent. LLMs trained on multilingual datasetsnormally struggle to respond to prompts in Portuguese satisfactorily,presenting, for example, code switching in their responses. This work proposesa fine-tuned LLaMA 2-based model for Portuguese prompts named Bode in twoversions: 7B and 13B. We evaluate the performance of this model inclassification tasks using the zero-shot approach with in-context learning, andcompare it with other LLMs. Our main contribution is to bring an LLM withsatisfactory results in the Portuguese language, as well as to provide a modelthat is free for research or commercial purposes.</description><author>Gabriel Lino Garcia, Pedro Henrique Paiola, Luis Henrique Morelli, Giovani Candido, Arnaldo Cândido Júnior, Danilo Samuel Jodas, Luis C. S. Afonso, Ivan Rizzo Guilherme, Bruno Elias Penteado, João Paulo Papa</author><pubDate>Fri, 05 Jan 2024 17:15:01 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.02909v1</guid></item><item><title>MLLM-Protector: Ensuring MLLM's Safety without Hurting Performance</title><link>http://arxiv.org/abs/2401.02906v1</link><description>The deployment of multimodal large language models (MLLMs) has brought fortha unique vulnerability: susceptibility to malicious attacks through visualinputs. We delve into the novel challenge of defending MLLMs against suchattacks. We discovered that images act as a "foreign language" that is notconsidered during alignment, which can make MLLMs prone to producing harmfulresponses. Unfortunately, unlike the discrete tokens considered in text-basedLLMs, the continuous nature of image signals presents significant alignmentchallenges, which poses difficulty to thoroughly cover the possible scenarios.This vulnerability is exacerbated by the fact that open-source MLLMs arepredominantly fine-tuned on limited image-text pairs that is much less than theextensive text-based pretraining corpus, which makes the MLLMs more prone tocatastrophic forgetting of their original abilities during explicit alignmenttuning. To tackle these challenges, we introduce MLLM-Protector, aplug-and-play strategy combining a lightweight harm detector and a responsedetoxifier. The harm detector's role is to identify potentially harmful outputsfrom the MLLM, while the detoxifier corrects these outputs to ensure theresponse stipulates to the safety standards. This approach effectivelymitigates the risks posed by malicious visual inputs without compromising themodel's overall performance. Our results demonstrate that MLLM-Protector offersa robust solution to a previously unaddressed aspect of MLLM security.</description><author>Renjie Pi, Tianyang Han, Yueqi Xie, Rui Pan, Qing Lian, Hanze Dong, Jipeng Zhang, Tong Zhang</author><pubDate>Fri, 05 Jan 2024 17:05:42 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.02906v1</guid></item><item><title>H2G2-Net: A Hierarchical Heterogeneous Graph Generative Network Framework for Discovery of Multi-Modal Physiological Responses</title><link>http://arxiv.org/abs/2401.02905v1</link><description>Discovering human cognitive and emotional states using multi-modalphysiological signals draws attention across various research applications.Physiological responses of the human body are influenced by human cognition andcommonly used to analyze cognitive states. From a network science perspective,the interactions of these heterogeneous physiological modalities in a graphstructure may provide insightful information to support prediction of cognitivestates. However, there is no clue to derive exact connectivity betweenheterogeneous modalities and there exists a hierarchical structure ofsub-modalities. Existing graph neural networks are designed to learn onnon-hierarchical homogeneous graphs with pre-defined graph structures; theyfailed to learn from hierarchical, multi-modal physiological data without apre-defined graph structure. To this end, we propose a hierarchicalheterogeneous graph generative network (H2G2-Net) that automatically learns agraph structure without domain knowledge, as well as a powerful representationon the hierarchical heterogeneous graph in an end-to-end fashion. We validatethe proposed method on the CogPilot dataset that consists of multi-modalphysiological signals. Extensive experiments demonstrate that our proposedmethod outperforms the state-of-the-art GNNs by 5%-20% in prediction accuracy.</description><author>Haidong Gu, Nathan Gaw, Yinan Wang, Chancellor Johnstone, Christine Beauchene, Sophia Yuditskaya, Hrishikesh Rao, Chun-An Chou</author><pubDate>Fri, 05 Jan 2024 17:05:33 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.02905v1</guid></item><item><title>Class-wise Generalization Error: an Information-Theoretic Analysis</title><link>http://arxiv.org/abs/2401.02904v1</link><description>Existing generalization theories of supervised learning typically take aholistic approach and provide bounds for the expected generalization over thewhole data distribution, which implicitly assumes that the model generalizessimilarly for all the classes. In practice, however, there are significantvariations in generalization performance among different classes, which cannotbe captured by the existing generalization bounds. In this work, we tackle thisproblem by theoretically studying the class-generalization error, whichquantifies the generalization performance of each individual class. We derive anovel information-theoretic bound for class-generalization error using the KLdivergence, and we further obtain several tighter bounds using the conditionalmutual information (CMI), which are significantly easier to estimate inpractice. We empirically validate our proposed bounds in different neuralnetworks and show that they accurately capture the complex class-generalizationerror behavior. Moreover, we show that the theoretical tools developed in thispaper can be applied in several applications beyond this context.</description><author>Firas Laakom, Yuheng Bu, Moncef Gabbouj</author><pubDate>Fri, 05 Jan 2024 17:05:14 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.02904v1</guid></item><item><title>Deep Reinforcement Learning for Local Path Following of an Autonomous Formula SAE Vehicle</title><link>http://arxiv.org/abs/2401.02903v1</link><description>With the continued introduction of driverless events to Formula:Society ofAutomotive Engineers (F:SAE) competitions around the world, teams areinvestigating all aspects of the autonomous vehicle stack. This paper presentsthe use of Deep Reinforcement Learning (DRL) and Inverse Reinforcement Learning(IRL) to map locally-observed cone positions to a desired steering angle forrace track following. Two state-of-the-art algorithms not previously tested inthis context: soft actor critic (SAC) and adversarial inverse reinforcementlearning (AIRL), are used to train models in a representative simulation. Threenovel reward functions for use by RL algorithms in an autonomous racing contextare also discussed. Tests performed in simulation and the real world suggestthat both algorithms can successfully train models for local path following.Suggestions for future work are presented to allow these models to scale to afull F:SAE vehicle.</description><author>Harvey Merton, Thomas Delamore, Karl Stol, Henry Williams</author><pubDate>Fri, 05 Jan 2024 17:04:43 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.02903v1</guid></item><item><title>State Derivative Normalization for Continuous-Time Deep Neural Networks</title><link>http://arxiv.org/abs/2401.02902v1</link><description>The importance of proper data normalization for deep neural networks is wellknown. However, in continuous-time state-space model estimation, it has beenobserved that improper normalization of either the hidden state or hidden statederivative of the model estimate, or even of the time interval can lead tonumerical and optimization challenges with deep learning based methods. Thisresults in a reduced model quality. In this contribution, we show that thesethree normalization tasks are inherently coupled. Due to the existence of thiscoupling, we propose a solution to all three normalization challenges byintroducing a normalization constant at the state derivative level. We showthat the appropriate choice of the normalization constant is related to thedynamics of the to-be-identified system and we derive multiple methods ofobtaining an effective normalization constant. We compare and discuss all thenormalization strategies on a benchmark problem based on experimental data froma cascaded tanks system and compare our results with other methods of theidentification literature.</description><author>Jonas Weigand, Gerben I. Beintema, Jonas Ulmen, Daniel Görges, Roland Tóth, Maarten Schoukens, Martin Ruskowski</author><pubDate>Fri, 05 Jan 2024 17:04:33 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.02902v1</guid></item><item><title>Nonlinear functional regression by functional deep neural network with kernel embedding</title><link>http://arxiv.org/abs/2401.02890v1</link><description>With the rapid development of deep learning in various fields of science andtechnology, such as speech recognition, image classification, and naturallanguage processing, recently it is also widely applied in the functional dataanalysis (FDA) with some empirical success. However, due to the infinitedimensional input, we need a powerful dimension reduction method for functionallearning tasks, especially for the nonlinear functional regression. In thispaper, based on the idea of smooth kernel integral transformation, we propose afunctional deep neural network with an efficient and fully data-dependentdimension reduction method. The architecture of our functional net consists ofa kernel embedding step: an integral transformation with a data-dependentsmooth kernel; a projection step: a dimension reduction by projection witheigenfunction basis based on the embedding kernel; and finally an expressivedeep ReLU neural network for the prediction. The utilization of smooth kernelembedding enables our functional net to be discretization invariant, efficient,and robust to noisy observations, capable of utilizing information in bothinput functions and responses data, and have a low requirement on the number ofdiscrete points for an unimpaired generalization performance. We conducttheoretical analysis including approximation error and generalization erroranalysis, and numerical simulations to verify these advantages of ourfunctional net.</description><author>Zhongjie Shi, Jun Fan, Linhao Song, Ding-Xuan Zhou, Johan A. K. Suykens</author><pubDate>Fri, 05 Jan 2024 16:43:39 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.02890v1</guid></item><item><title>A Distributed Block Chebyshev-Davidson Algorithm for Parallel Spectral Clustering</title><link>http://arxiv.org/abs/2212.04443v2</link><description>We develop a distributed Block Chebyshev-Davidson algorithm to solvelarge-scale leading eigenvalue problems for spectral analysis in spectralclustering. First, the efficiency of the Chebyshev-Davidson algorithm relies onthe prior knowledge of the eigenvalue spectrum, which could be expensive toestimate. This issue can be lessened by the analytic spectrum estimation of theLaplacian or normalized Laplacian matrices in spectral clustering, making theproposed algorithm very efficient for spectral clustering. Second, to make theproposed algorithm capable of analyzing big data, a distributed and parallelversion has been developed with attractive scalability. The speedup by parallelcomputing is approximately equivalent to $\sqrt{p}$, where $p$ denotes thenumber of processes. {Numerical results will be provided to demonstrate itsefficiency in spectral clustering and scalability advantage over existingeigensolvers used for spectral clustering in parallel computing environments.}</description><author>Qiyuan Pang, Haizhao Yang</author><pubDate>Fri, 05 Jan 2024 16:40:44 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2212.04443v2</guid></item><item><title>Energy-Preserving Reduced Operator Inference for Efficient Design and Control</title><link>http://arxiv.org/abs/2401.02889v1</link><description>Many-query computations, in which a computational model for an engineeringsystem must be evaluated many times, are crucial in design and control. Forsystems governed by partial differential equations (PDEs), typicalhigh-fidelity numerical models are high-dimensional and too computationallyexpensive for the many-query setting. Thus, efficient surrogate models arerequired to enable low-cost computations in design and control. This workpresents a physics-preserving reduced model learning approach that targets PDEswhose quadratic operators preserve energy, such as those arising in governingequations in many fluids problems. The approach is based on the OperatorInference method, which fits reduced model operators to state snapshot and timederivative data in a least-squares sense. However, Operator Inference does notgenerally learn a reduced quadratic operator with the energy-preservingproperty of the original PDE. Thus, we propose a new energy-preserving OperatorInference (EP-OpInf) approach, which imposes this structure on the learnedreduced model via constrained optimization. Numerical results using the viscousBurgers' and Kuramoto-Sivashinksy equation (KSE) demonstrate that EP-OpInflearns efficient and accurate reduced models that retain this energy-preservingstructure.</description><author>Tomoki Koike, Elizabeth Qian</author><pubDate>Fri, 05 Jan 2024 16:39:48 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.02889v1</guid></item><item><title>Application of federated learning techniques for arrhythmia classification using 12-lead ECG signals</title><link>http://arxiv.org/abs/2208.10993v3</link><description>Artificial Intelligence-based (AI) analysis of large, curated medicaldatasets is promising for providing early detection, faster diagnosis, and moreeffective treatment using low-power Electrocardiography (ECG) monitoringdevices information. However, accessing sensitive medical data from diversesources is highly restricted since improper use, unsafe storage, or dataleakage could violate a person's privacy. This work uses a Federated Learning(FL) privacy-preserving methodology to train AI models over heterogeneous setsof high-definition ECG from 12-lead sensor arrays collected from sixheterogeneous sources. We evaluated the capacity of the resulting models toachieve equivalent performance compared to state-of-the-art models trained in aCentralized Learning (CL) fashion. Moreover, we assessed the performance of oursolution over Independent and Identical distributed (IID) and non-IID federateddata. Our methodology involves machine learning techniques based on Deep NeuralNetworks and Long-Short-Term Memory models. It has a robust data preprocessingpipeline with feature engineering, selection, and data balancing techniques.Our AI models demonstrated comparable performance to models trained using CL,IID, and non-IID approaches. They showcased advantages in reduced complexityand faster training time, making them well-suited for cloud-edge architectures.</description><author>Daniel Mauricio Jimenez Gutierrez, Hafiz Muuhammad Hassan, Lorella Landi, Andrea Vitaletti, Ioannis Chatzigiannakis</author><pubDate>Fri, 05 Jan 2024 16:32:10 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2208.10993v3</guid></item><item><title>MsDC-DEQ-Net: Deep Equilibrium Model (DEQ) with Multi-scale Dilated Convolution for Image Compressive Sensing (CS)</title><link>http://arxiv.org/abs/2401.02884v1</link><description>Compressive sensing (CS) is a technique that enables the recovery of sparsesignals using fewer measurements than traditional sampling methods. To addressthe computational challenges of CS reconstruction, our objective is to developan interpretable and concise neural network model for reconstructing naturalimages using CS. We achieve this by mapping one step of the iterative shrinkagethresholding algorithm (ISTA) to a deep network block, representing oneiteration of ISTA. To enhance learning ability and incorporate structuraldiversity, we integrate aggregated residual transformations (ResNeXt) andsqueeze-and-excitation (SE) mechanisms into the ISTA block. This block servesas a deep equilibrium layer, connected to a semi-tensor product network(STP-Net) for convenient sampling and providing an initial reconstruction. Theresulting model, called MsDC-DEQ-Net, exhibits competitive performance comparedto state-of-the-art network-based methods. It significantly reduces storagerequirements compared to deep unrolling methods, using only one iteration blockinstead of multiple iterations. Unlike deep unrolling models, MsDC-DEQ-Net canbe iteratively used, gradually improving reconstruction accuracy whileconsidering computation trade-offs. Additionally, the model benefits frommulti-scale dilated convolutions, further enhancing performance.</description><author>Youhao Yu, Richard M. Dansereau</author><pubDate>Fri, 05 Jan 2024 16:25:58 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.02884v1</guid></item><item><title>AutoGL: A Library for Automated Graph Learning</title><link>http://arxiv.org/abs/2104.04987v3</link><description>Recent years have witnessed an upsurge in research interests and applicationsof machine learning on graphs. However, manually designing the optimal machinelearning algorithms for different graph datasets and tasks is inflexible,labor-intensive, and requires expert knowledge, limiting its adaptivity andapplicability. Automated machine learning (AutoML) on graphs, aiming toautomatically design the optimal machine learning algorithm for a given graphdataset and task, has received considerable attention. However, none of theexisting libraries can fully support AutoML on graphs. To fill this gap, wepresent Automated Graph Learning (AutoGL), the first dedicated library forautomated machine learning on graphs. AutoGL is open-source, easy to use, andflexible to be extended. Specifically, we propose a three-layer architecture,consisting of backends to interface with devices, a complete automated graphlearning pipeline, and supported graph applications. The automated machinelearning pipeline further contains five functional modules: auto featureengineering, neural architecture search, hyper-parameter optimization, modeltraining, and auto ensemble, covering the majority of existing AutoML methodson graphs. For each module, we provide numerous state-of-the-art methods andflexible base classes and APIs, which allow easy usage and customization. Wefurther provide experimental results to showcase the usage of our AutoGLlibrary. We also present AutoGL-light, a lightweight version of AutoGL tofacilitate customizing pipelines and enriching applications, as well asbenchmarks for graph neural architecture search. The codes of AutoGL arepublicly available at https://github.com/THUMNLab/AutoGL.</description><author>Ziwei Zhang, Yijian Qin, Zeyang Zhang, Chaoyu Guan, Jie Cai, Heng Chang, Jiyan Jiang, Haoyang Li, Zixin Sun, Beini Xie, Yang Yao, Yipeng Zhang, Xin Wang, Wenwu Zhu</author><pubDate>Fri, 05 Jan 2024 16:15:40 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2104.04987v3</guid></item><item><title>Advancing Ischemic Stroke Diagnosis: A Novel Two-Stage Approach for Blood Clot Origin Identification</title><link>http://arxiv.org/abs/2304.13775v2</link><description>An innovative two-stage methodology for categorizing blood clot origins ispresented in this paper, which is important for the diagnosis and treatment ofischemic stroke. First, a background classifier based on MobileNetV3 segmentsbig whole-slide digital pathology images into numerous tiles to detect thepresence of cellular material. After that, different pre-trained imageclassification algorithms are fine-tuned to determine the origin of bloodclots. Due to complex blood flow dynamics and limitations in conventionalimaging methods such as computed tomography (CT), magnetic resonance imaging(MRI), and ultrasound, identifying the sources of blood clots is a challengingtask. Although these techniques are useful for identifying blood clots, theyare not very good at determining how they originated. To address thesechallenges, our method makes use of robust computer vision models that havebeen refined using information from whole-slide digital pathology images. Outof all the models tested, the PoolFormer \cite{yu2022metaformer} performsbetter than the others, with 93.4\% accuracy, 93.4\% precision, 93.4\% recall,and 93.4\% F1-score. Moreover, it achieves the good weighted multi-classlogarithmic loss (WMCLL) of 0.4361, which emphasizes how effective it is inthis particular application. These encouraging findings suggest that ourapproach can successfully identify the origin of blood clots in a variety ofvascular locations, potentially advancing ischemic stroke diagnosis andtreatment approaches.</description><author>Koushik Sivarama Krishnan, P. J. Joe Nikesh, Swathi Gnanasekar, Karthik Sivarama Krishnan</author><pubDate>Fri, 05 Jan 2024 16:13:31 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2304.13775v2</guid></item><item><title>Efficient Parameter Optimisation for Quantum Kernel Alignment: A Sub-sampling Approach in Variational Training</title><link>http://arxiv.org/abs/2401.02879v1</link><description>Quantum machine learning with quantum kernels for classification problems isa growing area of research. Recently, quantum kernel alignment techniques thatparameterise the kernel have been developed, allowing the kernel to be trainedand therefore aligned with a specific dataset. While quantum kernel alignmentis a promising technique, it has been hampered by considerable training costsbecause the full kernel matrix must be constructed at every training iteration.Addressing this challenge, we introduce a novel method that seeks to balanceefficiency and performance. We present a sub-sampling training approach thatuses a subset of the kernel matrix at each training step, thereby reducing theoverall computational cost of the training. In this work, we apply thesub-sampling method to synthetic datasets and a real-world breast cancerdataset and demonstrate considerable reductions in the number of circuitsrequired to train the quantum kernel while maintaining classification accuracy.</description><author>M. Emre Sahin, Benjamin C. B. Symons, Pushpak Pati, Fayyaz Minhas, Declan Millar, Maria Gabrani, Jan Lukas Robertus, Stefano Mensa</author><pubDate>Fri, 05 Jan 2024 16:11:34 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.02879v1</guid></item><item><title>Analyzing Wrap-Up Effects through an Information-Theoretic Lens</title><link>http://arxiv.org/abs/2203.17213v2</link><description>Numerous analyses of reading time (RT) data have been implemented -- all inan effort to better understand the cognitive processes driving readingcomprehension. However, data measured on words at the end of a sentence -- oreven at the end of a clause -- is often omitted due to the confounding factorsintroduced by so-called "wrap-up effects," which manifests as a skeweddistribution of RTs for these words. Consequently, the understanding of thecognitive processes that might be involved in these wrap-up effects is limited.In this work, we attempt to learn more about these processes by examining therelationship between wrap-up effects and information-theoretic quantities, suchas word and context surprisals. We find that the distribution of information inprior contexts is often predictive of sentence- and clause-final RTs (while notof sentence-medial RTs). This lends support to several prior hypotheses aboutthe processes involved in wrap-up effects.</description><author>Clara Meister, Tiago Pimentel, Thomas Hikaru Clark, Ryan Cotterell, Roger Levy</author><pubDate>Fri, 05 Jan 2024 16:10:15 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2203.17213v2</guid></item><item><title>Optimal Chaining of Vehicle Plans with Time Windows</title><link>http://arxiv.org/abs/2401.02873v1</link><description>For solving problems from the domain of vehicle routing with time windows, weoften need to connect vehicle plans into sequences spanning a longer timehorizon or, in other words, we need to perform a plan chaining. Recently, anetwork-based solution has been proposed to solve the fleet-sizing problem. Themethod, however, does not consider the time flexibility of the plans, anessential property of all vehicle routing problems with time windows. Instead,plans have fixed times and cannot be delayed. This work presents a new problemformulation that considers delays in line with the given time windows and amethod that can be used to solve it. Moreover, we prove that the method isoptimal, and we analyze its complexity. Finally, we list some practicalapplications and perform a demonstration for one of them: the method forsolving the static Dial-a-ride problem. The demonstration results show that fora significant number of instances, the proposed method provides a bettersolution than the other two heuristic baseline methods we have evaluated, whilenot having the largest computational time requirements.</description><author>David Fiedler, Fabio V. Difonzo, Jan Mrkos</author><pubDate>Fri, 05 Jan 2024 16:04:55 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.02873v1</guid></item><item><title>On the Efficacy of Sampling Adapters</title><link>http://arxiv.org/abs/2307.03749v2</link><description>Sampling is a common strategy for generating text from probabilistic models,yet standard ancestral sampling often results in text that is incoherent orungrammatical. To alleviate this issue, various modifications to a model'ssampling distribution, such as nucleus or top-k sampling, have been introducedand are now ubiquitously used in language generation systems. We propose aunified framework for understanding these techniques, which we term samplingadapters. Sampling adapters often lead to qualitatively better text, whichraises the question: From a formal perspective, how are they changing the(sub)word-level distributions of language generation models? And why do theselocal changes lead to higher-quality text? We argue that the shift they enforcecan be viewed as a trade-off between precision and recall: while the modelloses its ability to produce certain strings, its precision rate on desirabletext increases. While this trade-off is not reflected in standard metrics ofdistribution quality (such as perplexity), we find that severalprecision-emphasizing measures indeed indicate that sampling adapters can leadto probability distributions more aligned with the true distribution. Further,these measures correlate with higher sequence-level quality scores,specifically, Mauve.</description><author>Clara Meister, Tiago Pimentel, Luca Malagutti, Ethan G. Wilcox, Ryan Cotterell</author><pubDate>Fri, 05 Jan 2024 15:55:23 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.03749v2</guid></item><item><title>AFSPP: Agent Framework for Shaping Preference and Personality with Large Language Models</title><link>http://arxiv.org/abs/2401.02870v1</link><description>The evolution of Large Language Models (LLMs) has introduced a new paradigmfor investigating human behavior emulation. Recent research has employedLLM-based Agents to create a sociological research environment, in which agentsexhibit behavior based on the unfiltered characteristics of large languagemodels. However, these studies overlook the iterative development within ahuman-like setting - Human preferences and personalities are complex, shaped byvarious factors and subject to ongoing change as a result of environmental andsubjective influences. In light of this observation, we propose Agent Frameworkfor Shaping Preference and Personality (AFSPP), exploring the multifacetedimpact of social networks and subjective consciousness on LLM-based Agents'preference and personality formation. With AFSPP, we have, for the first time,successfully replicated several key findings from human personalityexperiments. And other AFSPP-based experimental results indicate that planmaking, sensory perceptions and social networking with subjective information,wield the most pronounced influence on preference shaping. AFSPP cansignificantly enhance the efficiency and scope of psychological experiments,while yielding valuable insights for Trustworthy Artificial Intelligenceresearch for strategies to prevent undesirable preference and personalitydevelopment.</description><author>Zihong He, Changwang Zhang</author><pubDate>Fri, 05 Jan 2024 15:52:59 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.02870v1</guid></item><item><title>LITE: A Stable Framework for Lattice-Integrated Embedding of Topological Descriptors</title><link>http://arxiv.org/abs/2312.17093v2</link><description>In this paper, we introduce a new family of descriptors for persistencediagrams. Our approach transforms these diagrams into elements of afinite-dimensional vector space using functionals based on the discretemeasures they induce. While our focus is primarily on identity andfrequency-based transformations, we do not restrict our approach exclusively tothis types of techniques. We term this family of transformations as LITE(Lattice Integrated Topological Embedding) and prove stability for some membersof this family against the 1-$Kantorovitch$-$Rubinstein$ metric, ensuring itsresponsiveness to subtle data variations. Extensive comparative analysisreveals that our descriptor performs competitively with the currentstate-of-art from the topological data analysis literature, and oftensurpasses, the existing methods. This research not only introduces aninnovative perspective for data scientists but also critiques the currenttrajectory of literature on methodologies for vectorizing diagrams. Itestablishes a foundation for future progress in applying persistence diagramsto data analysis and machine learning under a more simple and effective lens.</description><author>Michael Etienne Van Huffel, Matteo Palo</author><pubDate>Fri, 05 Jan 2024 15:48:43 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.17093v2</guid></item><item><title>"It's not like Jarvis, but it's pretty close!" -- Examining ChatGPT's Usage among Undergraduate Students in Computer Science</title><link>http://arxiv.org/abs/2311.09651v2</link><description>Large language models (LLMs) such as ChatGPT and Google Bard have garneredsignificant attention in the academic community. Previous research hasevaluated these LLMs for various applications such as generating programmingexercises and solutions. However, these evaluations have predominantly beenconducted by instructors and researchers, not considering the actual usage ofLLMs by students. This study adopts a student-first approach to comprehensivelyunderstand how undergraduate computer science students utilize ChatGPT, apopular LLM, released by OpenAI. We employ a combination of student surveys andinterviews to obtain valuable insights into the benefits, challenges, andsuggested improvements related to ChatGPT. Our findings suggest that a majorityof students (over 57%) have a convincingly positive outlook towards adoptingChatGPT as an aid in coursework-related tasks. However, our research alsohighlights various challenges that must be resolved for long-term acceptance ofChatGPT amongst students. The findings from this investigation have broaderimplications and may be applicable to other LLMs and their role in computingeducation.</description><author>Ishika Joshi, Ritvik Budhiraja, Harshal D Akolekar, Jagat Sesh Challa, Dhruv Kumar</author><pubDate>Fri, 05 Jan 2024 15:47:03 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.09651v2</guid></item><item><title>Hierarchical Randomized Smoothing</title><link>http://arxiv.org/abs/2310.16221v3</link><description>Real-world data is complex and often consists of objects that can bedecomposed into multiple entities (e.g. images into pixels, graphs intointerconnected nodes). Randomized smoothing is a powerful framework for makingmodels provably robust against small changes to their inputs - by guaranteeingrobustness of the majority vote when randomly adding noise beforeclassification. Yet, certifying robustness on such complex data via randomizedsmoothing is challenging when adversaries do not arbitrarily perturb entireobjects (e.g. images) but only a subset of their entities (e.g. pixels). As asolution, we introduce hierarchical randomized smoothing: We partially smoothobjects by adding random noise only on a randomly selected subset of theirentities. By adding noise in a more targeted manner than existing methods weobtain stronger robustness guarantees while maintaining high accuracy. Weinitialize hierarchical smoothing using different noising distributions,yielding novel robustness certificates for discrete and continuous domains. Weexperimentally demonstrate the importance of hierarchical smoothing in imageand node classification, where it yields superior robustness-accuracytrade-offs. Overall, hierarchical smoothing is an important contributiontowards models that are both - certifiably robust to perturbations andaccurate.</description><author>Yan Scholten, Jan Schuchardt, Aleksandar Bojchevski, Stephan Günnemann</author><pubDate>Fri, 05 Jan 2024 15:43:12 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.16221v3</guid></item><item><title>Patterns of Persistence and Diffusibility across the World's Languages</title><link>http://arxiv.org/abs/2401.01698v2</link><description>Language similarities can be caused by genetic relatedness, areal contact,universality, or chance. Colexification, i.e. a type of similarity where asingle lexical form is used to convey multiple meanings, is underexplored. Inour work, we shed light on the linguistic causes of cross-lingual similarity incolexification and phonology, by exploring genealogical stability (persistence)and contact-induced change (diffusibility). We construct large-scale graphsincorporating semantic, genealogical, phonological and geographical data for1,966 languages. We then show the potential of this resource, by investigatingseveral established hypotheses from previous work in linguistics, whileproposing new ones. Our results strongly support a previously establishedhypothesis in the linguistic literature, while offering contradicting evidenceto another. Our large scale resource opens for further research acrossdisciplines, e.g.~in multilingual NLP and comparative linguistics.</description><author>Yiyi Chen, Johannes Bjerva</author><pubDate>Fri, 05 Jan 2024 15:33:40 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.01698v2</guid></item><item><title>Reversing the Irreversible: A Survey on Inverse Biometrics</title><link>http://arxiv.org/abs/2401.02861v1</link><description>With the widespread use of biometric recognition, several issues related tothe privacy and security provided by this technology have been recently raisedand analysed. As a result, the early common belief among the biometricscommunity of templates irreversibility has been proven wrong. It is now anaccepted fact that it is possible to reconstruct from an unprotected template asynthetic sample that matches the bona fide one. This reverse engineeringprocess, commonly referred to as \textit{inverse biometrics}, constitutes asevere threat for biometric systems from two different angles: on the one hand,sensitive personal data (i.e., biometric data) can be derived from compromisedunprotected templates; on the other hand, other powerful attacks can belaunched building upon these reconstructed samples. Given its importantimplications, biometric stakeholders have produced over the last fifteen yearsnumerous works analysing the different aspects related to inverse biometrics:development of reconstruction algorithms for different characteristics;proposal of methodologies to assess the vulnerabilities of biometric systems tothe aforementioned algorithms; development of countermeasures to reduce thepossible effects of attacks. The present article is an effort to condense allthis information in one comprehensive review of: the problem itself, theevaluation of the problem, and the mitigation of the problem. The presentarticle is an effort to condense all this information in one comprehensivereview of: the problem itself, the evaluation of the problem, and themitigation of the problem.</description><author>Marta Gomez-Barrero, Javier Galbally</author><pubDate>Fri, 05 Jan 2024 15:32:40 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.02861v1</guid></item><item><title>Framework for Variable-lag Motif Following Relation Inference In Time Series using Matrix Profile analysis</title><link>http://arxiv.org/abs/2401.02860v1</link><description>Knowing who follows whom and what patterns they are following are crucialsteps to understand collective behaviors (e.g. a group of human, a school offish, or a stock market). Time series is one of resources that can be used toget insight regarding following relations. However, the concept of followingpatterns or motifs and the solution to find them in time series are notobvious. In this work, we formalize a concept of following motifs between twotime series and present a framework to infer following patterns between twotime series. The framework utilizes one of efficient and scalable methods toretrieve motifs from time series called the Matrix Profile Method. We compareour proposed framework with several baselines. The framework performs betterthan baselines in the simulation datasets. In the dataset of sound recording,the framework is able to retrieve the following motifs within a pair of timeseries that two singers sing following each other. In the cryptocurrencydataset, the framework is capable of capturing the following motifs within apair of time series from two digital currencies, which implies that the valuesof one currency follow the values of another currency patterns. Our frameworkcan be utilized in any field of time series to get insight regarding followingpatterns between time series.</description><author>Naaek Chinpattanakarn, Chainarong Amornbunchornvej</author><pubDate>Fri, 05 Jan 2024 15:32:24 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.02860v1</guid></item><item><title>Generative Large Language Models are autonomous practitioners of evidence-based medicine</title><link>http://arxiv.org/abs/2401.02851v1</link><description>Background: Evidence-based medicine (EBM) is fundamental to modern clinicalpractice, requiring clinicians to continually update their knowledge and applythe best clinical evidence in patient care. The practice of EBM faceschallenges due to rapid advancements in medical research, leading toinformation overload for clinicians. The integration of artificial intelligence(AI), specifically Generative Large Language Models (LLMs), offers a promisingsolution towards managing this complexity. Methods: This study involved the curation of real-world clinical cases acrossvarious specialties, converting them into .json files for analysis. LLMs,including proprietary models like ChatGPT 3.5 and 4, Gemini Pro, andopen-source models like LLaMA v2 and Mixtral-8x7B, were employed. These modelswere equipped with tools to retrieve information from case files and makeclinical decisions similar to how clinicians must operate in the real world.Model performance was evaluated based on correctness of final answer, judicioususe of tools, conformity to guidelines, and resistance to hallucinations. Results: GPT-4 was most capable of autonomous operation in a clinicalsetting, being generally more effective in ordering relevant investigations andconforming to clinical guidelines. Limitations were observed in terms of modelability to handle complex guidelines and diagnostic nuances. RetrievalAugmented Generation made recommendations more tailored to patients andhealthcare systems. Conclusions: LLMs can be made to function as autonomous practitioners ofevidence-based medicine. Their ability to utilize tooling can be harnessed tointeract with the infrastructure of a real-world healthcare system and performthe tasks of patient management in a guideline directed manner. Promptengineering may help to further enhance this potential and transform healthcarefor the clinician and the patient.</description><author>Akhil Vaid, Joshua Lampert, Juhee Lee, Ashwin Sawant, Donald Apakama, Ankit Sakhuja, Ali Soroush, Denise Lee, Isotta Landi, Nicole Bussola, Ismail Nabeel, Robbie Freeman, Patricia Kovatch, Brendan Carr, Benjamin Glicksberg, Edgar Argulian, Stamatios Lerakis, Monica Kraft, Alexander Charney, Girish Nadkarni</author><pubDate>Fri, 05 Jan 2024 15:09:57 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.02851v1</guid></item><item><title>Generating Non-Stationary Textures using Self-Rectification</title><link>http://arxiv.org/abs/2401.02847v1</link><description>This paper addresses the challenge of example-based non-stationary texturesynthesis. We introduce a novel twostep approach wherein users first modify areference texture using standard image editing tools, yielding an initial roughtarget for the synthesis. Subsequently, our proposed method, termed"self-rectification", automatically refines this target into a coherent,seamless texture, while faithfully preserving the distinct visualcharacteristics of the reference exemplar. Our method leverages a pre-traineddiffusion network, and uses self-attention mechanisms, to gradually align thesynthesized texture with the reference, ensuring the retention of thestructures in the provided target. Through experimental validation, ourapproach exhibits exceptional proficiency in handling non-stationary textures,demonstrating significant advancements in texture synthesis when compared toexisting state-of-the-art techniques. Code is available athttps://github.com/xiaorongjun000/Self-Rectification</description><author>Yang Zhou, Rongjun Xiao, Dani Lischinski, Daniel Cohen-Or, Hui Huang</author><pubDate>Fri, 05 Jan 2024 15:07:05 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.02847v1</guid></item><item><title>Thousands of AI Authors on the Future of AI</title><link>http://arxiv.org/abs/2401.02843v1</link><description>In the largest survey of its kind, 2,778 researchers who had published intop-tier artificial intelligence (AI) venues gave predictions on the pace of AIprogress and the nature and impacts of advanced AI systems The aggregateforecasts give at least a 50% chance of AI systems achieving several milestonesby 2028, including autonomously constructing a payment processing site fromscratch, creating a song indistinguishable from a new song by a popularmusician, and autonomously downloading and fine-tuning a large language model.If science continues undisrupted, the chance of unaided machines outperforminghumans in every possible task was estimated at 10% by 2027, and 50% by 2047.The latter estimate is 13 years earlier than that reached in a similar surveywe conducted only one year earlier [Grace et al., 2022]. However, the chance ofall human occupations becoming fully automatable was forecast to reach 10% by2037, and 50% as late as 2116 (compared to 2164 in the 2022 survey). Most respondents expressed substantial uncertainty about the long-term valueof AI progress: While 68.3% thought good outcomes from superhuman AI are morelikely than bad, of these net optimists 48% gave at least a 5% chance ofextremely bad outcomes such as human extinction, and 59% of net pessimists gave5% or more to extremely good outcomes. Between 38% and 51% of respondents gaveat least a 10% chance to advanced AI leading to outcomes as bad as humanextinction. More than half suggested that "substantial" or "extreme" concern iswarranted about six different AI-related scenarios, including misinformation,authoritarian control, and inequality. There was disagreement about whetherfaster or slower AI progress would be better for the future of humanity.However, there was broad agreement that research aimed at minimizing potentialrisks from AI systems ought to be prioritized more.</description><author>Katja Grace, Harlan Stewart, Julia Fabienne Sandkühler, Stephen Thomas, Ben Weinstein-Raun, Jan Brauner</author><pubDate>Fri, 05 Jan 2024 14:53:09 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.02843v1</guid></item><item><title>Multi-Stage Contrastive Regression for Action Quality Assessment</title><link>http://arxiv.org/abs/2401.02841v1</link><description>In recent years, there has been growing interest in the video-based actionquality assessment (AQA). Most existing methods typically solve AQA problem byconsidering the entire video yet overlooking the inherent stage-levelcharacteristics of actions. To address this issue, we design a novelMulti-stage Contrastive Regression (MCoRe) framework for the AQA task. Thisapproach allows us to efficiently extract spatial-temporal information, whilesimultaneously reducing computational costs by segmenting the input video intomultiple stages or procedures. Inspired by the graph contrastive learning, wepropose a new stage-wise contrastive learning loss function to enhanceperformance. As a result, MCoRe demonstrates the state-of-the-art result so faron the widely-adopted fine-grained AQA dataset.</description><author>Qi An, Mengshi Qi, Huadong Ma</author><pubDate>Fri, 05 Jan 2024 14:48:19 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.02841v1</guid></item><item><title>Pheme: Efficient and Conversational Speech Generation</title><link>http://arxiv.org/abs/2401.02839v1</link><description>In recent years, speech generation has seen remarkable progress, nowachieving one-shot generation capability that is often virtuallyindistinguishable from real human voice. Integrating such advancements inspeech generation with large language models might revolutionize a wide rangeof applications. However, certain applications, such as assistiveconversational systems, require natural and conversational speech generationtools that also operate efficiently in real time. Current state-of-the-artmodels like VALL-E and SoundStorm, powered by hierarchical neural audio codecs,require large neural components and extensive training data to work well. Incontrast, MQTTS aims to build more compact conversational TTS models whilecapitalizing on smaller-scale real-life conversational speech data. However,its autoregressive nature yields high inference latency and thus limits itsreal-time usage. In order to mitigate the current limitations of thestate-of-the-art TTS models while capitalizing on their strengths, in this workwe introduce the Pheme model series that 1) offers compact yet high-performingmodels, 2) allows for parallel speech generation of 3) natural conversationalspeech, and 4) it can be trained efficiently on smaller-scale conversationaldata, cutting data demands by more than 10x but still matching the quality ofthe autoregressive TTS models. We also show that through simple teacher-studentdistillation we can meet significant improvements in voice quality forsingle-speaker setups on top of pretrained Pheme checkpoints, relying solely onsynthetic speech generated by much larger teacher models. Audio samples andpretrained models are available online.</description><author>Paweł Budzianowski, Taras Sereda, Tomasz Cichy, Ivan Vulić</author><pubDate>Fri, 05 Jan 2024 14:47:20 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.02839v1</guid></item><item><title>CrisisViT: A Robust Vision Transformer for Crisis Image Classification</title><link>http://arxiv.org/abs/2401.02838v1</link><description>In times of emergency, crisis response agencies need to quickly andaccurately assess the situation on the ground in order to deploy relevantservices and resources. However, authorities often have to make decisions basedon limited information, as data on affected regions can be scarce until localresponse services can provide first-hand reports. Fortunately, the widespreadavailability of smartphones with high-quality cameras has made citizenjournalism through social media a valuable source of information for crisisresponders. However, analyzing the large volume of images posted by citizensrequires more time and effort than is typically available. To address thisissue, this paper proposes the use of state-of-the-art deep neural models forautomatic image classification/tagging, specifically by adaptingtransformer-based architectures for crisis image classification (CrisisViT). Weleverage the new Incidents1M crisis image dataset to develop a range of newtransformer-based image classification models. Through experimentation over thestandard Crisis image benchmark dataset, we demonstrate that the CrisisViTmodels significantly outperform previous approaches in emergency type, imagerelevance, humanitarian category, and damage severity classification.Additionally, we show that the new Incidents1M dataset can further augment theCrisisViT models resulting in an additional 1.25% absolute accuracy gain.</description><author>Zijun Long, Richard McCreadie, Muhammad Imran</author><pubDate>Fri, 05 Jan 2024 14:45:45 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.02838v1</guid></item><item><title>PromptBench: A Unified Library for Evaluation of Large Language Models</title><link>http://arxiv.org/abs/2312.07910v2</link><description>The evaluation of large language models (LLMs) is crucial to assess theirperformance and mitigate potential security risks. In this paper, we introducePromptBench, a unified library to evaluate LLMs. It consists of several keycomponents that are easily used and extended by researchers: promptconstruction, prompt engineering, dataset and model loading, adversarial promptattack, dynamic evaluation protocols, and analysis tools. PromptBench isdesigned to be an open, general, and flexible codebase for research purposesthat can facilitate original study in creating new benchmarks, deployingdownstream applications, and designing new evaluation protocols. The code isavailable at: https://github.com/microsoft/promptbench and will be continuouslysupported.</description><author>Kaijie Zhu, Qinlin Zhao, Hao Chen, Jindong Wang, Xing Xie</author><pubDate>Fri, 05 Jan 2024 14:45:00 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.07910v2</guid></item><item><title>Two-stage Progressive Residual Dense Attention Network for Image Denoising</title><link>http://arxiv.org/abs/2401.02831v1</link><description>Deep convolutional neural networks (CNNs) for image denoising can effectivelyexploit rich hierarchical features and have achieved great success. However,many deep CNN-based denoising models equally utilize the hierarchical featuresof noisy images without paying attention to the more important and usefulfeatures, leading to relatively low performance. To address the issue, wedesign a new Two-stage Progressive Residual Dense Attention Network(TSP-RDANet) for image denoising, which divides the whole process of denoisinginto two sub-tasks to remove noise progressively. Two different attentionmechanism-based denoising networks are designed for the two sequentialsub-tasks: the residual dense attention module (RDAM) is designed for the firststage, and the hybrid dilated residual dense attention module (HDRDAM) isproposed for the second stage. The proposed attention modules are able to learnappropriate local features through dense connection between differentconvolutional layers, and the irrelevant features can also be suppressed. Thetwo sub-networks are then connected by a long skip connection to retain theshallow feature to enhance the denoising performance. The experiments on sevenbenchmark datasets have verified that compared with many state-of-the-artmethods, the proposed TSP-RDANet can obtain favorable results both on syntheticand real noisy image denoising. The code of our TSP-RDANet is available athttps://github.com/WenCongWu/TSP-RDANet.</description><author>Wencong Wu, An Ge, Guannan Lv, Yuelong Xia, Yungang Zhang, Wen Xiong</author><pubDate>Fri, 05 Jan 2024 14:31:20 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.02831v1</guid></item><item><title>PAC-Bayes-Chernoff bounds for unbounded losses</title><link>http://arxiv.org/abs/2401.01148v2</link><description>We present a new high-probability PAC-Bayes oracle bound for unboundedlosses. This result can be understood as a PAC-Bayes version of the Chernoffbound. The proof technique relies on uniformly bounding the tail of certainrandom variable based on the Cram\'er transform of the loss. We highlight twoapplications of our main result. First, we show that our bound solves the openproblem of optimizing the free parameter on many PAC-Bayes bounds. Finally, weshow that our approach allows working with flexible assumptions on the lossfunction, resulting in novel bounds that generalize previous ones and can beminimized to obtain Gibbs-like posteriors.</description><author>Ioar Casado, Luis A. Ortega, Andrés R. Masegosa, Aritz Pérez</author><pubDate>Fri, 05 Jan 2024 14:28:19 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.01148v2</guid></item><item><title>Let's Get It Started: Fostering the Discoverability of New Releases on Deezer</title><link>http://arxiv.org/abs/2401.02827v1</link><description>This paper presents our recent initiatives to foster the discoverability ofnew releases on the music streaming service Deezer. After introducing oursearch and recommendation features dedicated to new releases, we outline ourshift from editorial to personalized release suggestions using cold startembeddings and contextual bandits. Backed by online experiments, we discuss theadvantages of this shift in terms of recommendation quality and exposure of newreleases on the service.</description><author>Léa Briand, Théo Bontempelli, Walid Bendada, Mathieu Morlon, François Rigaud, Benjamin Chapus, Thomas Bouabça, Guillaume Salha-Galvan</author><pubDate>Fri, 05 Jan 2024 14:21:10 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.02827v1</guid></item><item><title>CRSOT: Cross-Resolution Object Tracking using Unaligned Frame and Event Cameras</title><link>http://arxiv.org/abs/2401.02826v1</link><description>Existing datasets for RGB-DVS tracking are collected with DVS346 camera andtheir resolution ($346 \times 260$) is low for practical applications.Actually, only visible cameras are deployed in many practical systems, and thenewly designed neuromorphic cameras may have different resolutions. The latestneuromorphic sensors can output high-definition event streams, but it is verydifficult to achieve strict alignment between events and frames on both spatialand temporal views. Therefore, how to achieve accurate tracking with unalignedneuromorphic and visible sensors is a valuable but unresearched problem. Inthis work, we formally propose the task of object tracking using unalignedneuromorphic and visible cameras. We build the first unaligned frame-eventdataset CRSOT collected with a specially built data acquisition system, whichcontains 1,030 high-definition RGB-Event video pairs, 304,974 video frames. Inaddition, we propose a novel unaligned object tracking framework that canrealize robust tracking even using the loosely aligned RGB-Event data.Specifically, we extract the template and search regions of RGB and Event dataand feed them into a unified ViT backbone for feature embedding. Then, wepropose uncertainty perception modules to encode the RGB and Event features,respectively, then, we propose a modality uncertainty fusion module toaggregate the two modalities. These three branches are jointly optimized in thetraining phase. Extensive experiments demonstrate that our tracker cancollaborate the dual modalities for high-performance tracking even withoutstrictly temporal and spatial alignment. The source code, dataset, andpre-trained models will be released athttps://github.com/Event-AHU/Cross_Resolution_SOT.</description><author>Yabin Zhu, Xiao Wang, Chenglong Li, Bo Jiang, Lin Zhu, Zhixiang Huang, Yonghong Tian, Jin Tang</author><pubDate>Fri, 05 Jan 2024 14:20:22 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.02826v1</guid></item><item><title>Annotation Sensitivity: Training Data Collection Methods Affect Model Performance</title><link>http://arxiv.org/abs/2311.14212v2</link><description>When training data are collected from human annotators, the design of theannotation instrument, the instructions given to annotators, thecharacteristics of the annotators, and their interactions can impact trainingdata. This study demonstrates that design choices made when creating anannotation instrument also impact the models trained on the resultingannotations. We introduce the term annotation sensitivity to refer to theimpact of annotation data collection methods on the annotations themselves andon downstream model performance and predictions. We collect annotations of hatespeech and offensive language in five experimental conditions of an annotationinstrument, randomly assigning annotators to conditions. We then fine-tune BERTmodels on each of the five resulting datasets and evaluate model performance ona holdout portion of each condition. We find considerable differences betweenthe conditions for 1) the share of hate speech/offensive language annotations,2) model performance, 3) model predictions, and 4) model learning curves. Ourresults emphasize the crucial role played by the annotation instrument whichhas received little attention in the machine learning literature. We call foradditional research into how and why the instrument impacts the annotations toinform the development of best practices in instrument design.</description><author>Christoph Kern, Stephanie Eckman, Jacob Beck, Rob Chew, Bolei Ma, Frauke Kreuter</author><pubDate>Fri, 05 Jan 2024 14:18:35 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.14212v2</guid></item><item><title>DocGraphLM: Documental Graph Language Model for Information Extraction</title><link>http://arxiv.org/abs/2401.02823v1</link><description>Advances in Visually Rich Document Understanding (VrDU) have enabledinformation extraction and question answering over documents with complexlayouts. Two tropes of architectures have emerged -- transformer-based modelsinspired by LLMs, and Graph Neural Networks. In this paper, we introduceDocGraphLM, a novel framework that combines pre-trained language models withgraph semantics. To achieve this, we propose 1) a joint encoder architecture torepresent documents, and 2) a novel link prediction approach to reconstructdocument graphs. DocGraphLM predicts both directions and distances betweennodes using a convergent joint loss function that prioritizes neighborhoodrestoration and downweighs distant node detection. Our experiments on threeSotA datasets show consistent improvement on IE and QA tasks with the adoptionof graph features. Moreover, we report that adopting the graph featuresaccelerates convergence in the learning process during training, despite beingsolely constructed through link prediction.</description><author>Dongsheng Wang, Zhiqiang Ma, Armineh Nourbakhsh, Kang Gu, Sameena Shah</author><pubDate>Fri, 05 Jan 2024 14:15:36 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.02823v1</guid></item><item><title>Retrieval-Augmented Text-to-Audio Generation</title><link>http://arxiv.org/abs/2309.08051v2</link><description>Despite recent progress in text-to-audio (TTA) generation, we show that thestate-of-the-art models, such as AudioLDM, trained on datasets with animbalanced class distribution, such as AudioCaps, are biased in theirgeneration performance. Specifically, they excel in generating common audioclasses while underperforming in the rare ones, thus degrading the overallgeneration performance. We refer to this problem as long-tailed text-to-audiogeneration. To address this issue, we propose a simple retrieval-augmentedapproach for TTA models. Specifically, given an input text prompt, we firstleverage a Contrastive Language Audio Pretraining (CLAP) model to retrieverelevant text-audio pairs. The features of the retrieved audio-text data arethen used as additional conditions to guide the learning of TTA models. Weenhance AudioLDM with our proposed approach and denote the resulting augmentedsystem as Re-AudioLDM. On the AudioCaps dataset, Re-AudioLDM achieves astate-of-the-art Frechet Audio Distance (FAD) of 1.37, outperforming theexisting approaches by a large margin. Furthermore, we show that Re-AudioLDMcan generate realistic audio for complex scenes, rare audio classes, and evenunseen audio types, indicating its potential in TTA tasks.</description><author>Yi Yuan, Haohe Liu, Xubo Liu, Qiushi Huang, Mark D. Plumbley, Wenwu Wang</author><pubDate>Fri, 05 Jan 2024 14:10:51 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2309.08051v2</guid></item><item><title>Object-Centric Instruction Augmentation for Robotic Manipulation</title><link>http://arxiv.org/abs/2401.02814v1</link><description>Humans interpret scenes by recognizing both the identities and positions ofobjects in their observations. For a robot to perform tasks such as\enquote{pick and place}, understanding both what the objects are and wherethey are located is crucial. While the former has been extensively discussed inthe literature that uses the large language model to enrich the textdescriptions, the latter remains underexplored. In this work, we introduce the\textit{Object-Centric Instruction Augmentation (OCI)} framework to augmenthighly semantic and information-dense language instruction with position cues.We utilize a Multi-modal Large Language Model (MLLM) to weave knowledge ofobject locations into natural language instruction, thus aiding the policynetwork in mastering actions for versatile manipulation. Additionally, wepresent a feature reuse mechanism to integrate the vision-language featuresfrom off-the-shelf pre-trained MLLM into policy networks. Through a series ofsimulated and real-world robotic tasks, we demonstrate that robotic manipulatorimitation policies trained with our enhanced instructions outperform thoserelying solely on traditional language instructions.</description><author>Junjie Wen, Yichen Zhu, Minjie Zhu, Jinming Li, Zhiyuan Xu, Zhengping Che, Chaomin Shen, Yaxin Peng, Dong Liu, Feifei Feng, Jian Tang</author><pubDate>Fri, 05 Jan 2024 13:54:45 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.02814v1</guid></item><item><title>Physics-Informed Neural Networks for High-Frequency and Multi-Scale Problems using Transfer Learning</title><link>http://arxiv.org/abs/2401.02810v1</link><description>Physics-informed neural network (PINN) is a data-driven solver for partialand ordinary differential equations(ODEs/PDEs). It provides a unified frameworkto address both forward and inverse problems. However, the complexity of theobjective function often leads to training failures. This issue is particularlyprominent when solving high-frequency and multi-scale problems. We proposedusing transfer learning to boost the robustness and convergence of trainingPINN, starting training from low-frequency problems and gradually approachinghigh-frequency problems. Through two case studies, we discovered that transferlearning can effectively train PINN to approximate solutions from low-frequencyproblems to high-frequency problems without increasing network parameters.Furthermore, it requires fewer data points and less training time. Weelaborately described our training strategy, including optimizer selection, andsuggested guidelines for using transfer learning to train neural networks forsolving more complex problems.</description><author>Abdul Hannan Mustajab, Hao Lyu, Zarghaam Rizvi, Frank Wuttke</author><pubDate>Fri, 05 Jan 2024 13:45:08 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.02810v1</guid></item><item><title>Diffbody: Diffusion-based Pose and Shape Editing of Human Images</title><link>http://arxiv.org/abs/2401.02804v1</link><description>Pose and body shape editing in a human image has received increasingattention. However, current methods often struggle with dataset biases anddeteriorate realism and the person's identity when users make large edits. Wepropose a one-shot approach that enables large edits with identitypreservation. To enable large edits, we fit a 3D body model, project the inputimage onto the 3D model, and change the body's pose and shape. Because thisinitial textured body model has artifacts due to occlusion and the inaccuratebody shape, the rendered image undergoes a diffusion-based refinement, in whichstrong noise destroys body structure and identity whereas insufficient noisedoes not help. We thus propose an iterative refinement with weak noise, appliedfirst for the whole body and then for the face. We further enhance the realismby fine-tuning text embeddings via self-supervised learning. Our quantitativeand qualitative evaluations demonstrate that our method outperforms otherexisting methods across various datasets.</description><author>Yuta Okuyama, Yuki Endo, Yoshihiro Kanamori</author><pubDate>Fri, 05 Jan 2024 13:36:19 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.02804v1</guid></item><item><title>Credence: Augmenting Datacenter Switch Buffer Sharing with ML Predictions</title><link>http://arxiv.org/abs/2401.02801v1</link><description>Packet buffers in datacenter switches are shared across all the switch portsin order to improve the overall throughput. The trend of shrinking buffer sizesin datacenter switches makes buffer sharing extremely challenging and acritical performance issue. Literature suggests that push-out buffer sharingalgorithms have significantly better performance guarantees compared todrop-tail algorithms. Unfortunately, switches are unable to benefit from thesealgorithms due to lack of support for push-out operations in hardware. Our keyobservation is that drop-tail buffers can emulate push-out buffers if thefuture packet arrivals are known ahead of time. This suggests that augmentingdrop-tail algorithms with predictions about the future arrivals has thepotential to significantly improve performance. This paper is the first research attempt in this direction. We proposeCredence, a drop-tail buffer sharing algorithm augmented with machine-learnedpredictions. Credence can unlock the performance only attainable by push-outalgorithms so far. Its performance hinges on the accuracy of predictions.Specifically, Credence achieves near-optimal performance of the best knownpush-out algorithm LQD (Longest Queue Drop) with perfect predictions, butgracefully degrades to the performance of the simplest drop-tail algorithmComplete Sharing when the prediction error gets arbitrarily worse. Ourevaluations show that Credence improves throughput by $1.5$x compared totraditional approaches. In terms of flow completion times, we show thatCredence improves upon the state-of-the-art approaches by up to $95\%$ usingoff-the-shelf machine learning techniques that are also practical in today'shardware. We believe this work opens several interesting future workopportunities both in systems and theory that we discuss at the end of thispaper.</description><author>Vamsi Addanki, Maciej Pacut, Stefan Schmid</author><pubDate>Fri, 05 Jan 2024 13:29:59 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.02801v1</guid></item><item><title>PeFoMed: Parameter Efficient Fine-tuning on Multimodal Large Language Models for Medical Visual Question Answering</title><link>http://arxiv.org/abs/2401.02797v1</link><description>Multimodal large language models (MLLMs) represent an evolutionary expansionin the capabilities of traditional large language models, enabling them totackle challenges that surpass the scope of purely text-based applications. Itleverages the knowledge previously encoded within these language models,thereby enhancing their applicability and functionality in the reign ofmultimodal contexts. Recent works investigate the adaptation of MLLMs topredict free-form answers as a generative task to solve medical visual questionanswering (Med-VQA) tasks. In this paper, we propose a parameter efficientframework for fine-tuning MLLM specifically tailored to Med-VQA applications,and empirically validate it on a public benchmark dataset. To accuratelymeasure the performance, we employ human evaluation and the results reveal thatour model achieves an overall accuracy of 81.9%, and outperforms the GPT-4vmodel by a significant margin of 26% absolute accuracy on closed-endedquestions. The code will be available here: https://github.com/jinlHe/PeFoMed.</description><author>Jinlong He, Pengfei Li, Gang Liu, Zixu Zhao, Shenjun Zhong</author><pubDate>Fri, 05 Jan 2024 13:22:12 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.02797v1</guid></item><item><title>ConvNet vs Transformer, Supervised vs CLIP: Beyond ImageNet Accuracy</title><link>http://arxiv.org/abs/2311.09215v2</link><description>Modern computer vision offers a great variety of models to practitioners, andselecting a model from multiple options for specific applications can bechallenging. Conventionally, competing model architectures and trainingprotocols are compared by their classification accuracy on ImageNet. However,this single metric does not fully capture performance nuances critical forspecialized tasks. In this work, we conduct an in-depth comparative analysis ofmodel behaviors beyond ImageNet accuracy, for both ConvNet and VisionTransformer architectures, each across supervised and CLIP training paradigms.Although our selected models have similar ImageNet accuracies and computerequirements, we find that they differ in many other aspects: types ofmistakes, output calibration, transferability, and feature invariance, amongothers. This diversity in model characteristics, not captured by traditionalmetrics, highlights the need for more nuanced analysis when choosing amongdifferent models. Our code is available athttps://github.com/kirill-vish/Beyond-INet.</description><author>Kirill Vishniakov, Zhiqiang Shen, Zhuang Liu</author><pubDate>Fri, 05 Jan 2024 13:16:25 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.09215v2</guid></item><item><title>Subjective and Objective Analysis of Indian Social Media Video Quality</title><link>http://arxiv.org/abs/2401.02794v1</link><description>We conducted a large-scale subjective study of the perceptual quality ofUser-Generated Mobile Video Content on a set of mobile-originated videosobtained from the Indian social media platform ShareChat. The content viewed byvolunteer human subjects under controlled laboratory conditions has the benefitof culturally diversifying the existing corpus of User-Generated Content (UGC)video quality datasets. There is a great need for large and diverse UGC-VQAdatasets, given the explosive global growth of the visual internet and socialmedia platforms. This is particularly true in regard to videos obtained bysmartphones, especially in rapidly emerging economies like India. ShareChatprovides a safe and cultural community oriented space for users to generate andshare content in their preferred Indian languages and dialects. Our subjectivequality study, which is based on this data, offers a boost of cultural, visual,and language diversification to the video quality research community. We expectthat this new data resource will also allow for the development of systems thatcan predict the perceived visual quality of Indian social media videos, tocontrol scaling and compression protocols for streaming, provide better userrecommendations, and guide content analysis and processing. We demonstrate thevalue of the new data resource by conducting a study of leading blind videoquality models on it, including a new model, called MoEVA, which deploys amixture of experts to predict video quality. Both the new LIVE-ShareChatdataset and sample source code for MoEVA are being made freely available to theresearch community at https://github.com/sandeep-sm/LIVE-SC</description><author>Sandeep Mishra, Mukul Jha, Alan C. Bovik</author><pubDate>Fri, 05 Jan 2024 13:13:09 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.02794v1</guid></item><item><title>Reinforcement Learning and Data-Generation for Syntax-Guided Synthesis</title><link>http://arxiv.org/abs/2307.09564v2</link><description>Program synthesis is the task of automatically generating code based on aspecification. In Syntax-Guided Synthesis (SyGuS) this specification is acombination of a syntactic template and a logical formula, and the result isguaranteed to satisfy both. We present a reinforcement-learning guided algorithm for SyGuS which usesMonte-Carlo Tree Search (MCTS) to search the space of candidate solutions. Ouralgorithm learns policy and value functions which, combined with the upperconfidence bound for trees, allow it to balance exploration and exploitation. Acommon challenge in applying machine learning approaches to syntax-guidedsynthesis is the scarcity of training data. To address this, we present amethod for automatically generating training data for SyGuS based onanti-unification of existing first-order satisfiability problems, which we useto train our MCTS policy. We implement and evaluate this setup and demonstratethat learned policy and value improve the synthesis performance over a baselineby over 26 percentage points in the training and testing sets. Our tooloutperforms state-of-the-art tool cvc5 on the training set and performscomparably in terms of the total number of problems solved on the testing set(solving 23% of the benchmarks on which cvc5 fails). We make our data setpublicly available, to enable further application of machine learning methodsto the SyGuS problem.</description><author>Julian Parsert, Elizabeth Polgreen</author><pubDate>Fri, 05 Jan 2024 13:07:10 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.09564v2</guid></item><item><title>Cadmium Zinc Telluride (CZT) photon counting detector Characterisation for soft tissue imaging</title><link>http://arxiv.org/abs/2401.02106v2</link><description>The use of photon counting detection technology has resulted in significantX-ray imaging research interest in recent years. Computed Tomography (CT)scanners can benefit from photon-counting detectors, which are new technologywith the potential to overcome key limitations of conventional CT detectors.Researchers are still studying the effectiveness and sensitivity ofsemiconductor detector materials in photon counting detectors for detectingsoft tissue contrasts. This study aimed to characterize the performance of theCadmium Zinc Telluride photon counting detector in identifying various tissues.An optimal frame rate per second (FPS) of CZT detector was evaluated by settingthe X-ray tube voltage and current at 25 keV, 35 keV and 0.5 mA, 1.0 mArespectively by keeping the optimum FPS fixed, the detector energy thresholdswere set in small steps from 15 keV to 35 keV and the Currents were set forX-ray tubes in ranges of 0.1 mA to 1.0 mA to find the relationship betweenvoltage and current of the X-ray source and counts per second (CPS). Thesamples i.e., fat, liver, muscles, paraffin wax, and contrast media werestacked at six different thickness levels in a stair-step chamber made fromPlexi-glass. X-ray transmission at six different thicknesses of tissue sampleswas also examined for five different energy (regions) thresholds (21 keV, 25keV, 29 keV, 31 keV, and 45 keV) to determine the effect on count per second(CPS). In this study, 12 frames per second is found to be the optimum framerate per second (FPS) based on the spectral response of an X-ray source and CPShas a linear relationship with X-ray tube current as well. It was also notedthat A sample's thickness also affects its X-ray transmission at differentenergy thresholds. A high sensitivity and linearity of the detectors make themsuitable for use in both preclinical and medical applications.</description><author>K. Hameed, Rafidah Zainon, Mahbubunnabi Tamal</author><pubDate>Fri, 05 Jan 2024 13:05:16 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.02106v2</guid></item><item><title>Weakly Semi-supervised Tool Detection in Minimally Invasive Surgery Videos</title><link>http://arxiv.org/abs/2401.02791v1</link><description>Surgical tool detection is essential for analyzing and evaluating minimallyinvasive surgery videos. Current approaches are mostly based on supervisedmethods that require large, fully instance-level labels (i.e., bounding boxes).However, large image datasets with instance-level labels are often limitedbecause of the burden of annotation. Thus, surgical tool detection is importantwhen providing image-level labels instead of instance-level labels sinceimage-level annotations are considerably more time-efficient thaninstance-level annotations. In this work, we propose to strike a balancebetween the extremely costly annotation burden and detection performance. Wefurther propose a co-occurrence loss, which considers a characteristic thatsome tool pairs often co-occur together in an image to leverage image-levellabels. Encapsulating the knowledge of co-occurrence using the co-occurrenceloss helps to overcome the difficulty in classification that originates fromthe fact that some tools have similar shapes and textures. Extensiveexperiments conducted on the Endovis2018 dataset in various data settings showthe effectiveness of our method.</description><author>Ryo Fujii, Ryo Hachiuma, Hideo Saito</author><pubDate>Fri, 05 Jan 2024 13:05:02 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.02791v1</guid></item><item><title>Large Language Models in Plant Biology</title><link>http://arxiv.org/abs/2401.02789v1</link><description>Large Language Models (LLMs), such as ChatGPT, have taken the world by stormand have passed certain forms of the Turing test. However, LLMs are not limitedto human language and analyze sequential data, such as DNA, protein, and geneexpression. The resulting foundation models can be repurposed to identify thecomplex patterns within the data, resulting in powerful, multi-purposeprediction tools able to explain cellular systems. This review outlines thedifferent types of LLMs and showcases their recent uses in biology. Since LLMshave not yet been embraced by the plant community, we also cover how thesemodels can be deployed for the plant kingdom.</description><author>Hilbert Yuen In Lam, Xing Er Ong, Marek Mutwil</author><pubDate>Fri, 05 Jan 2024 12:59:20 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.02789v1</guid></item><item><title>Brain tumor segmentation using synthetic MR images -- A comparison of GANs and diffusion models</title><link>http://arxiv.org/abs/2306.02986v2</link><description>Large annotated datasets are required for training deep learning models, butin medical imaging data sharing is often complicated due to ethics,anonymization and data protection legislation. Generative AI models, such asgenerative adversarial networks (GANs) and diffusion models, can today producevery realistic synthetic images, and can potentially facilitate data sharing.However, in order to share synthetic medical images it must first bedemonstrated that they can be used for training different networks withacceptable performance. Here, we therefore comprehensively evaluate four GANs(progressive GAN, StyleGAN 1-3) and a diffusion model for the task of braintumor segmentation (using two segmentation networks, U-Net and a Swintransformer). Our results show that segmentation networks trained on syntheticimages reach Dice scores that are 80% - 90% of Dice scores when training withreal images, but that memorization of the training images can be a problem fordiffusion models if the original dataset is too small. Our conclusion is thatsharing synthetic medical images is a viable option to sharing real images, butthat further work is required. The trained generative models and the generatedsynthetic images are shared on AIDA data hub</description><author>Muhammad Usman Akbar, Måns Larsson, Anders Eklund</author><pubDate>Fri, 05 Jan 2024 12:48:31 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.02986v2</guid></item><item><title>AI Control: Improving Safety Despite Intentional Subversion</title><link>http://arxiv.org/abs/2312.06942v3</link><description>As large language models (LLMs) become more powerful and are deployed moreautonomously, it will be increasingly important to prevent them from causingharmful outcomes. Researchers have investigated a variety of safety techniquesfor this purpose, e.g. using models to review the outputs of other models, orred-teaming techniques to surface subtle failure modes. However, researchershave not evaluated whether such techniques still ensure safety if the model isitself intentionally trying to subvert them. In this paper, we develop andevaluate pipelines of safety techniques ("protocols") that are robust tointentional subversion. We investigate a scenario in which we want to solve a sequence of programmingproblems, using access to a powerful but untrusted model (in our case, GPT-4),access to a less powerful trusted model (in our case, GPT-3.5), and limitedaccess to high-quality trusted labor. We investigate protocols that aim tonever submit solutions containing backdoors, which we operationalize here aslogical errors that are not caught by test cases. We investigate a range of protocols and test each against strategies that theuntrusted model could use to subvert them. One protocol is what we call trustedediting. This protocol first asks GPT-4 to write code, and then asks GPT-3.5 torate the suspiciousness of that code. If the code is below some suspiciousnessthreshold, it is submitted. Otherwise, GPT-3.5 edits the solution to removeparts that seem suspicious and then submits the edited code. Another protocolis untrusted monitoring. This protocol asks GPT-4 to write code, and then asksanother instance of GPT-4 whether the code is backdoored, using varioustechniques to prevent the GPT-4 instances from colluding. These protocolsimprove substantially on simple baselines.</description><author>Ryan Greenblatt, Buck Shlegeris, Kshitij Sachan, Fabien Roger</author><pubDate>Fri, 05 Jan 2024 12:41:27 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.06942v3</guid></item><item><title>FlashDecoding++: Faster Large Language Model Inference on GPUs</title><link>http://arxiv.org/abs/2311.01282v4</link><description>As the Large Language Model (LLM) becomes increasingly important in variousdomains. However, the following challenges still remain unsolved inaccelerating LLM inference: (1) Synchronized partial softmax update. Thesoftmax operation requires a synchronized update operation among each partialsoftmax result, leading to ~20% overheads for the attention computation inLLMs. (2) Under-utilized computation of flat GEMM. The shape of matricesperforming GEMM in LLM inference is flat, leading to under-utilized computationand &gt;50% performance loss after padding zeros in previous designs. (3)Performance loss due to static dataflow. Kernel performance in LLM depends onvaried input data features, hardware configurations, etc. A single and staticdataflow may lead to a 50.25% performance loss for GEMMs of different shapes inLLM inference. We present FlashDecoding++, a fast LLM inference engine supporting mainstreamLLMs and hardware back-ends. To tackle the above challenges, FlashDecoding++creatively proposes: (1) Asynchronized softmax with unified max value.FlashDecoding++ introduces a unified max value technique for different partialsoftmax computations to avoid synchronization. (2) Flat GEMM optimization withdouble buffering. FlashDecoding++ points out that flat GEMMs with differentshapes face varied bottlenecks. Then, techniques like double buffering areintroduced. (3) Heuristic dataflow with hardware resource adaptation.FlashDecoding++ heuristically optimizes dataflow using different hardwareresource considering input dynamics. Due to the versatility of optimizations inFlashDecoding++, FlashDecoding++ can achieve up to 4.86x and 2.18x speedup onboth NVIDIA and AMD GPUs compared to Hugging Face implementations.FlashDecoding++ also achieves an average speedup of 1.37x compared tostate-of-the-art LLM inference engines on mainstream LLMs.</description><author>Ke Hong, Guohao Dai, Jiaming Xu, Qiuli Mao, Xiuhong Li, Jun Liu, Kangdi Chen, Yuhan Dong, Yu Wang</author><pubDate>Fri, 05 Jan 2024 12:41:13 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.01282v4</guid></item><item><title>From LLM to Conversational Agent: A Memory Enhanced Architecture with Fine-Tuning of Large Language Models</title><link>http://arxiv.org/abs/2401.02777v1</link><description>This paper introduces RAISE (Reasoning and Acting through Scratchpad andExamples), an advanced architecture enhancing the integration of Large LanguageModels (LLMs) like GPT-4 into conversational agents. RAISE, an enhancement ofthe ReAct framework, incorporates a dual-component memory system, mirroringhuman short-term and long-term memory, to maintain context and continuity inconversations. It entails a comprehensive agent construction scenario,including phases like Conversation Selection, Scene Extraction, CoT Completion,and Scene Augmentation, leading to the LLMs Training phase. This approachappears to enhance agent controllability and adaptability in complex,multi-turn dialogues. Our preliminary evaluations in a real estate salescontext suggest that RAISE has some advantages over traditional agents,indicating its potential for broader applications. This work contributes to theAI field by providing a robust framework for developing more context-aware andversatile conversational agents.</description><author>Na Liu, Liangyu Chen, Xiaoyu Tian, Wei Zou, Kaijiang Chen, Ming Cui</author><pubDate>Fri, 05 Jan 2024 12:26:46 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.02777v1</guid></item><item><title>mFACE: Multilingual Summarization with Factual Consistency Evaluation</title><link>http://arxiv.org/abs/2212.10622v2</link><description>Abstractive summarization has enjoyed renewed interest in recent years,thanks to pre-trained language models and the availability of large-scaledatasets. Despite promising results, current models still suffer fromgenerating factually inconsistent summaries, reducing their utility forreal-world application. Several recent efforts attempt to address this bydevising models that automatically detect factual inconsistencies in machinegenerated summaries. However, they focus exclusively on English, a languagewith abundant resources. In this work, we leverage factual consistencyevaluation models to improve multilingual summarization. We explore twointuitive approaches to mitigate hallucinations based on the signal provided bya multilingual NLI model, namely data filtering and controlled generation.Experimental results in the 45 languages from the XLSum dataset show gains overstrong baselines in both automatic and human evaluation.</description><author>Roee Aharoni, Shashi Narayan, Joshua Maynez, Jonathan Herzig, Elizabeth Clark, Mirella Lapata</author><pubDate>Fri, 05 Jan 2024 12:13:55 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2212.10622v2</guid></item><item><title>Tackling Electrode Shift In Gesture Recognition with HD-EMG Electrode Subsets</title><link>http://arxiv.org/abs/2401.02773v1</link><description>sEMG pattern recognition algorithms have been explored extensively indecoding movement intent, yet are known to be vulnerable to changing recordingconditions, exhibiting significant drops in performance across subjects, andeven across sessions. Multi-channel surface EMG, also referred to ashigh-density sEMG (HD-sEMG) systems, have been used to improve performance withthe information collected through the use of additional electrodes. However, alack of robustness is ever present due to limited datasets and the difficultiesin addressing sources of variability, such as electrode placement. In thisstudy, we propose training on a collection of input channel subsets andaugmenting our training distribution with data from different electrodelocations, simultaneously targeting electrode shift and reducing inputdimensionality. Our method increases robustness against electrode shift andresults in significantly higher intersession performance across subjects andclassification algorithms.</description><author>Joao Pereira, Dimitrios Chalatsis, Balint Hodossy, Dario Farina</author><pubDate>Fri, 05 Jan 2024 12:13:00 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.02773v1</guid></item><item><title>Deep learning in computed tomography pulmonary angiography imaging: a dual-pronged approach for pulmonary embolism detection</title><link>http://arxiv.org/abs/2311.05197v4</link><description>The increasing reliance on Computed Tomography Pulmonary Angiography (CTPA)for Pulmonary Embolism (PE) diagnosis presents challenges and a pressing needfor improved diagnostic solutions. The primary objective of this study is toleverage deep learning techniques to enhance the Computer Assisted Diagnosis(CAD) of PE. With this aim, we propose a classifier-guided detection approachthat effectively leverages the classifier's probabilistic inference to directthe detection predictions, marking a novel contribution in the domain ofautomated PE diagnosis. Our classification system includes an Attention-GuidedConvolutional Neural Network (AG-CNN) that uses local context by employing anattention mechanism. This approach emulates a human expert's attention bylooking at both global appearances and local lesion regions before making adecision. The classifier demonstrates robust performance on the FUMPE dataset,achieving an AUROC of 0.927, sensitivity of 0.862, specificity of 0.879, and anF1-score of 0.805 with the Inception-v3 backbone architecture. Moreover, AG-CNNoutperforms the baseline DenseNet-121 model, achieving an 8.1% AUROC gain.While previous research has mostly focused on finding PE in the main arteries,our use of cutting-edge object detection models and ensembling techniquesgreatly improves the accuracy of detecting small embolisms in the peripheralarteries. Finally, our proposed classifier-guided detection approach furtherrefines the detection metrics, contributing new state-of-the-art to thecommunity: mAP$_{50}$, sensitivity, and F1-score of 0.846, 0.901, and 0.779,respectively, outperforming the former benchmark with a significant 3.7%improvement in mAP$_{50}$. Our research aims to elevate PE patient care byintegrating AI solutions into clinical workflows, highlighting the potential ofhuman-AI collaboration in medical diagnostics.</description><author>Fabiha Bushra, Muhammad E. H. Chowdhury, Rusab Sarmun, Saidul Kabir, Menatalla Said, Sohaib Bassam Zoghoul, Adam Mushtak, Israa Al-Hashimi, Abdulrahman Alqahtani, Anwarul Hasan</author><pubDate>Fri, 05 Jan 2024 12:09:38 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.05197v4</guid></item><item><title>Unsupervised Visible-Infrared Person ReID by Collaborative Learning with Neighbor-Guided Label Refinement</title><link>http://arxiv.org/abs/2305.12711v3</link><description>Unsupervised learning visible-infrared person re-identification (USL-VI-ReID)aims at learning modality-invariant features from unlabeled cross-modalitydataset, which is crucial for practical applications in video surveillancesystems. The key to essentially address the USL-VI-ReID task is to solve thecross-modality data association problem for further heterogeneous jointlearning. To address this issue, we propose a Dual Optimal Transport LabelAssignment (DOTLA) framework to simultaneously assign the generated labels fromone modality to its counterpart modality. The proposed DOTLA mechanismformulates a mutual reinforcement and efficient solution to cross-modality dataassociation, which could effectively reduce the side-effects of someinsufficient and noisy label associations. Besides, we further propose across-modality neighbor consistency guided label refinement and regularizationmodule, to eliminate the negative effects brought by the inaccurate supervisedsignals, under the assumption that the prediction or label distribution of eachexample should be similar to its nearest neighbors. Extensive experimentalresults on the public SYSU-MM01 and RegDB datasets demonstrate theeffectiveness of the proposed method, surpassing existing state-of-the-artapproach by a large margin of 7.76% mAP on average, which even surpasses somesupervised VI-ReID methods.</description><author>De Cheng, Xiaojian Huang, Nannan Wang, Lingfeng He, Zhihui Li, Xinbo Gao</author><pubDate>Fri, 05 Jan 2024 12:03:37 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.12711v3</guid></item><item><title>DRKF: Distilled Rotated Kernel Fusion for Efficient Rotation Invariant Descriptors in Local Feature Matching</title><link>http://arxiv.org/abs/2209.10907v3</link><description>The performance of local feature descriptors degrades in the presence oflarge rotation variations. To address this issue, we present an efficientapproach to learning rotation invariant descriptors. Specifically, we proposeRotated Kernel Fusion (RKF) which imposes rotations on the convolution kernelto improve the inherent nature of CNN. Since RKF can be processed by thesubsequent re-parameterization, no extra computational costs will be introducedin the inference stage. Moreover, we present Multi-oriented Feature Aggregation(MOFA) which aggregates features extracted from multiple rotated versions ofthe input image and can provide auxiliary knowledge for the training of RKF byleveraging the distillation strategy. We refer to the distilled RKF model asDRKF. Besides the evaluation on a rotation-augmented version of the publicdataset HPatches, we also contribute a new dataset named DiverseBEV which iscollected during the drone's flight and consists of bird's eye view images withlarge viewpoint changes and camera rotations. Extensive experiments show thatour method can outperform other state-of-the-art techniques when exposed tolarge rotation variations.</description><author>Ranran Huang, Jiancheng Cai, Chao Li, Zhuoyuan Wu, Xinmin Liu, Zhenhua Chai</author><pubDate>Fri, 05 Jan 2024 12:03:22 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2209.10907v3</guid></item><item><title>Complex systems approach to natural language</title><link>http://arxiv.org/abs/2401.02772v1</link><description>The review summarizes the main methodological concepts used in studyingnatural language from the perspective of complexity science and documents theirapplicability in identifying both universal and system-specific features oflanguage in its written representation. Three main complexity-related researchtrends in quantitative linguistics are covered. The first part addresses theissue of word frequencies in texts and demonstrates that taking punctuationinto consideration restores scaling whose violation in the Zipf's law is oftenobserved for the most frequent words. The second part introduces methodsinspired by time series analysis, used in studying various kinds ofcorrelations in written texts. The related time series are generated on thebasis of text partition into sentences or into phrases between consecutivepunctuation marks. It turns out that these series develop features often foundin signals generated by complex systems, like long-range correlations or(multi)fractal structures. Moreover, it appears that the distances betweenpunctuation marks comply with the discrete variant of the Weibull distribution.In the third part, the application of the network formalism to natural languageis reviewed, particularly in the context of the so-called word-adjacencynetworks. Parameters characterizing topology of such networks can be used forclassification of texts, for example, from a stylometric perspective. Networkapproach can also be applied to represent the organization of wordassociations. Structure of word-association networks turns out to besignificantly different from that observed in random networks, revealinggenuine properties of language. Finally, punctuation seems to have asignificant impact not only on the language's information-carrying ability butalso on its key statistical properties, hence it is recommended to considerpunctuation marks on a par with words.</description><author>Tomasz Stanisz, Stanisław Drożdż, Jarosław Kwapień</author><pubDate>Fri, 05 Jan 2024 12:01:26 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.02772v1</guid></item><item><title>Powerformer: A Section-adaptive Transformer for Power Flow Adjustment</title><link>http://arxiv.org/abs/2401.02771v1</link><description>In this paper, we present a novel transformer architecture tailored forlearning robust power system state representations, which strives to optimizepower dispatch for the power flow adjustment across different transmissionsections. Specifically, our proposed approach, named Powerformer, develops adedicated section-adaptive attention mechanism, separating itself from theself-attention used in conventional transformers. This mechanism effectivelyintegrates power system states with transmission section information, whichfacilitates the development of robust state representations. Furthermore, byconsidering the graph topology of power system and the electrical attributes ofbus nodes, we introduce two customized strategies to further enhance theexpressiveness: graph neural network propagation and multi-factor attentionmechanism. Extensive evaluations are conducted on three power system scenarios,including the IEEE 118-bus system, a realistic 300-bus system in China, and alarge-scale European system with 9241 buses, where Powerformer demonstrates itssuperior performance over several baseline methods.</description><author>Kaixuan Chen, Wei Luo, Shunyu Liu, Yaoquan Wei, Yihe Zhou, Yunpeng Qing, Quan Zhang, Jie Song, Mingli Song</author><pubDate>Fri, 05 Jan 2024 12:01:19 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.02771v1</guid></item><item><title>Quantum artificial vision for defect detection in manufacturing</title><link>http://arxiv.org/abs/2208.04988v2</link><description>In this paper we consider several algorithms for quantum computer visionusing Noisy Intermediate-Scale Quantum (NISQ) devices, and benchmark them for areal problem against their classical counterparts. Specifically, we considertwo approaches: a quantum Support Vector Machine (QSVM) on a universalgate-based quantum computer, and QBoost on a quantum annealer. The quantumvision systems are benchmarked for an unbalanced dataset of images where theaim is to detect defects in manufactured car pieces. We see that the quantumalgorithms outperform their classical counterparts in several ways, with QBoostallowing for larger problems to be analyzed with present-day quantum annealers.Data preprocessing, including dimensionality reduction and contrastenhancement, is also discussed, as well as hyperparameter tuning in QBoost. Tothe best of our knowledge, this is the first implementation of quantum computervision systems for a problem of industrial relevance in a manufacturingproduction line.</description><author>Daniel Guijo, Victor Onofre, Gianni Del Bimbo, Samuel Mugel, Daniel Estepa, Xabier De Carlos, Ana Adell, Aizea Lojo, Josu Bilbao, Roman Orus</author><pubDate>Fri, 05 Jan 2024 12:01:04 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2208.04988v2</guid></item><item><title>Managing the unknown: a survey on Open Set Recognition and tangential areas</title><link>http://arxiv.org/abs/2312.08785v2</link><description>In real-world scenarios classification models are often required to performrobustly when predicting samples belonging to classes that have not appearedduring its training stage. Open Set Recognition addresses this issue bydevising models capable of detecting unknown classes from samples arrivingduring the testing phase, while maintaining a good level of performance in theclassification of samples belonging to known classes. This reviewcomprehensively overviews the recent literature related to Open SetRecognition, identifying common practices, limitations, and connections of thisfield with other machine learning research areas, such as continual learning,out-of-distribution detection, novelty detection, and uncertainty estimation.Our work also uncovers open problems and suggests several research directionsthat may motivate and articulate future efforts towards more safe ArtificialIntelligence methods.</description><author>Marcos Barcina-Blanco, Jesus L. Lobo, Pablo Garcia-Bringas, Javier Del Ser</author><pubDate>Fri, 05 Jan 2024 11:42:22 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.08785v2</guid></item><item><title>Tensor Networks for Explainable Machine Learning in Cybersecurity</title><link>http://arxiv.org/abs/2401.00867v2</link><description>In this paper we show how tensor networks help in developing explainabilityof machine learning algorithms. Specifically, we develop an unsupervisedclustering algorithm based on Matrix Product States (MPS) and apply it in thecontext of a real use-case of adversary-generated threat intelligence. Ourinvestigation proves that MPS rival traditional deep learning models such asautoencoders and GANs in terms of performance, while providing much richermodel interpretability. Our approach naturally facilitates the extraction offeature-wise probabilities, Von Neumann Entropy, and mutual information,offering a compelling narrative for classification of anomalies and fosteringan unprecedented level of transparency and interpretability, somethingfundamental to understand the rationale behind artificial intelligencedecisions.</description><author>Borja Aizpurua, Roman Orus</author><pubDate>Fri, 05 Jan 2024 11:40:56 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.00867v2</guid></item><item><title>Lower Difficulty and Better Robustness: A Bregman Divergence Perspective for Adversarial Training</title><link>http://arxiv.org/abs/2208.12511v3</link><description>In this paper, we investigate on improving the adversarial robustnessobtained in adversarial training (AT) via reducing the difficulty ofoptimization. To better study this problem, we build a novel Bregman divergenceperspective for AT, in which AT can be viewed as the sliding process of thetraining data points on the negative entropy curve. Based on this perspective,we analyze the learning objectives of two typical AT methods, i.e., PGD-AT andTRADES, and we find that the optimization process of TRADES is easier thanPGD-AT for that TRADES separates PGD-AT. In addition, we discuss the functionof entropy in TRADES, and we find that models with high entropy can be betterrobustness learners. Inspired by the above findings, we propose two methods,i.e., FAIT and MER, which can both not only reduce the difficulty ofoptimization under the 10-step PGD adversaries, but also provide betterrobustness. Our work suggests that reducing the difficulty of optimizationunder the 10-step PGD adversaries is a promising approach for enhancing theadversarial robustness in AT.</description><author>Zihui Wu, Haichang Gao, Bingqian Zhou, Xiaoyan Guo, Shudong Zhang</author><pubDate>Fri, 05 Jan 2024 11:38:20 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2208.12511v3</guid></item><item><title>Fus-MAE: A cross-attention-based data fusion approach for Masked Autoencoders in remote sensing</title><link>http://arxiv.org/abs/2401.02764v1</link><description>Self-supervised frameworks for representation learning have recently stirredup interest among the remote sensing community, given their potential tomitigate the high labeling costs associated with curating large satellite imagedatasets. In the realm of multimodal data fusion, while the often usedcontrastive learning methods can help bridging the domain gap between differentsensor types, they rely on data augmentations techniques that require expertiseand careful design, especially for multispectral remote sensing data. Apossible but rather scarcely studied way to circumvent these limitations is touse a masked image modelling based pretraining strategy. In this paper, weintroduce Fus-MAE, a self-supervised learning framework based on maskedautoencoders that uses cross-attention to perform early and feature-level datafusion between synthetic aperture radar and multispectral optical data - twomodalities with a significant domain gap. Our empirical findings demonstratethat Fus-MAE can effectively compete with contrastive learning strategiestailored for SAR-optical data fusion and outperforms other masked-autoencodersframeworks trained on a larger corpus.</description><author>Hugo Chan-To-Hing, Bharadwaj Veeravalli</author><pubDate>Fri, 05 Jan 2024 11:36:21 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.02764v1</guid></item><item><title>Detection and Classification of Diabetic Retinopathy using Deep Learning Algorithms for Segmentation to Facilitate Referral Recommendation for Test and Treatment Prediction</title><link>http://arxiv.org/abs/2401.02759v1</link><description>This research paper addresses the critical challenge of diabetic retinopathy(DR), a severe complication of diabetes leading to potential blindness. Theproposed methodology leverages transfer learning with convolutional neuralnetworks (CNNs) for automatic DR detection using a single fundus photograph,demonstrating high effectiveness with a quadratic weighted kappa score of0.92546 in the APTOS 2019 Blindness Detection Competition. The paper reviewsexisting literature on DR detection, spanning classical computer vision methodsto deep learning approaches, particularly focusing on CNNs. It identifies gapsin the research, emphasizing the lack of exploration in integrating pretrainedlarge language models with segmented image inputs for generatingrecommendations and understanding dynamic interactions within a web applicationcontext.Objectives include developing a comprehensive DR detection methodology,exploring model integration, evaluating performance through competitionranking, contributing significantly to DR detection methodologies, andidentifying research gaps.The methodology involves data preprocessing, dataaugmentation, and the use of a U-Net neural network architecture forsegmentation. The U-Net model efficiently segments retinal structures,including blood vessels, hard and soft exudates, haemorrhages, microaneurysms,and the optical disc. High evaluation scores in Jaccard, F1, recall, precision,and accuracy underscore the model's potential for enhancing diagnosticcapabilities in retinal pathology assessment.The outcomes of this research holdpromise for improving patient outcomes through timely diagnosis andintervention in the fight against diabetic retinopathy, marking a significantcontribution to the field of medical image analysis.</description><author>Manoj S H, Arya A Bosale</author><pubDate>Fri, 05 Jan 2024 11:19:24 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.02759v1</guid></item><item><title>Cross-Covariate Gait Recognition: A Benchmark</title><link>http://arxiv.org/abs/2312.14404v2</link><description>Gait datasets are essential for gait research. However, this paper observesthat present benchmarks, whether conventional constrained or emergingreal-world datasets, fall short regarding covariate diversity. To bridge thisgap, we undertake an arduous 20-month effort to collect a cross-covariate gaitrecognition (CCGR) dataset. The CCGR dataset has 970 subjects and about 1.6million sequences; almost every subject has 33 views and 53 differentcovariates. Compared to existing datasets, CCGR has both population andindividual-level diversity. In addition, the views and covariates are welllabeled, enabling the analysis of the effects of different factors. CCGRprovides multiple types of gait data, including RGB, parsing, silhouette, andpose, offering researchers a comprehensive resource for exploration. In orderto delve deeper into addressing cross-covariate gait recognition, we proposeparsing-based gait recognition (ParsingGait) by utilizing the newly proposedparsing data. We have conducted extensive experiments. Our main results show:1) Cross-covariate emerges as a pivotal challenge for practical applications ofgait recognition. 2) ParsingGait demonstrates remarkable potential for furtheradvancement. 3) Alarmingly, existing SOTA methods achieve less than 43%accuracy on the CCGR, highlighting the urgency of exploring cross-covariategait recognition. Link: https://github.com/ShinanZou/CCGR.</description><author>Shinan Zou, Chao Fan, Jianbo Xiong, Chuanfu Shen, Shiqi Yu, Jin Tang</author><pubDate>Fri, 05 Jan 2024 11:14:58 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.14404v2</guid></item><item><title>Systematic review of image segmentation using complex networks</title><link>http://arxiv.org/abs/2401.02758v1</link><description>This review presents various image segmentation methods using complexnetworks. Image segmentation is one of the important steps in image analysis as ithelps analyze and understand complex images. At first, it has been tried toclassify complex networks based on how it being used in image segmentation. In computer vision and image processing applications, image segmentation isessential for analyzing complex images with irregular shapes, textures, oroverlapping boundaries. Advanced algorithms make use of machine learning,clustering, edge detection, and region-growing techniques. Graph theoryprinciples combined with community detection-based methods allow for moreprecise analysis and interpretation of complex images. Hybrid approachescombine multiple techniques for comprehensive, robust segmentation, improvingresults in computer vision and image processing tasks.</description><author>Amin Rezaei, Fatemeh Asadi</author><pubDate>Fri, 05 Jan 2024 11:14:07 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.02758v1</guid></item><item><title>Context-Aware Iteration Policy Network for Efficient Optical Flow Estimation</title><link>http://arxiv.org/abs/2312.07180v4</link><description>Existing recurrent optical flow estimation networks are computationallyexpensive since they use a fixed large number of iterations to update the flowfield for each sample. An efficient network should skip iterations when theflow improvement is limited. In this paper, we develop a Context-AwareIteration Policy Network for efficient optical flow estimation, whichdetermines the optimal number of iterations per sample. The policy networkachieves this by learning contextual information to realize whether flowimprovement is bottlenecked or minimal. On the one hand, we use iterationembedding and historical hidden cell, which include previous iterationsinformation, to convey how flow has changed from previous iterations. On theother hand, we use the incremental loss to make the policy network implicitlyperceive the magnitude of optical flow improvement in the subsequent iteration.Furthermore, the computational complexity in our dynamic network iscontrollable, allowing us to satisfy various resource preferences with a singletrained model. Our policy network can be easily integrated intostate-of-the-art optical flow networks. Extensive experiments show that ourmethod maintains performance while reducing FLOPs by about 40%/20% for theSintel/KITTI datasets.</description><author>Ri Cheng, Ruian He, Xuhao Jiang, Shili Zhou, Weimin Tan, Bo Yan</author><pubDate>Fri, 05 Jan 2024 11:10:24 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.07180v4</guid></item><item><title>Hyperparameter-Free Approach for Faster Minimum Bayes Risk Decoding</title><link>http://arxiv.org/abs/2401.02749v1</link><description>Minimum Bayes-Risk (MBR) decoding is shown to be a powerful alternative tobeam search decoding for a wide range of text generation tasks. However, MBRrequires a huge amount of time for inference to compute the MBR objective,which makes the method infeasible in many situations where response time iscritical. Confidence-based pruning (CBP) (Cheng and Vlachos, 2023) has recentlybeen proposed to reduce the inference time in machine translation tasks.Although it is shown to significantly reduce the amount of computation, itrequires hyperparameter tuning using a development set to be effective. To thisend, we propose Approximate Minimum Bayes-Risk (AMBR) decoding, ahyperparameter-free method to run MBR decoding approximately. AMBR is derivedfrom the observation that the problem of computing the sample-based MBRobjective is the medoid identification problem. AMBR uses the CorrelatedSequential Halving (CSH) algorithm (Baharav and Tse, 2019), the bestapproximation algorithm to date for the medoid identification problem, tocompute the sample-based MBR objective. We evaluate AMBR on machinetranslation, text summarization, and image captioning tasks. The results showthat AMBR achieves on par with CBP, with CBP selecting hyperparameters throughan Oracle for each given computation budget.</description><author>Yuu Jinnai, Kaito Ariu</author><pubDate>Fri, 05 Jan 2024 11:02:08 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.02749v1</guid></item><item><title>Reading Between the Frames: Multi-Modal Depression Detection in Videos from Non-Verbal Cues</title><link>http://arxiv.org/abs/2401.02746v1</link><description>Depression, a prominent contributor to global disability, affects asubstantial portion of the population. Efforts to detect depression from socialmedia texts have been prevalent, yet only a few works explored depressiondetection from user-generated video content. In this work, we address thisresearch gap by proposing a simple and flexible multi-modal temporal modelcapable of discerning non-verbal depression cues from diverse modalities innoisy, real-world videos. We show that, for in-the-wild videos, usingadditional high-level non-verbal cues is crucial to achieving good performance,and we extracted and processed audio speech embeddings, face emotionembeddings, face, body and hand landmarks, and gaze and blinking information.Through extensive experiments, we show that our model achieves state-of-the-artresults on three key benchmark datasets for depression detection from video bya substantial margin. Our code is publicly available on GitHub.</description><author>David Gimeno-Gómez, Ana-Maria Bucur, Adrian Cosma, Carlos-David Martínez-Hinarejos, Paolo Rosso</author><pubDate>Fri, 05 Jan 2024 10:47:42 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.02746v1</guid></item><item><title>MAMI: Multi-Attentional Mutual-Information for Long Sequence Neuron Captioning</title><link>http://arxiv.org/abs/2401.02744v1</link><description>Neuron labeling is an approach to visualize the behaviour and respond of acertain neuron to a certain pattern that activates the neuron. Neuron labelingextract information about the features captured by certain neurons in a deepneural network, one of which uses the encoder-decoder image captioningapproach. The encoder used can be a pretrained CNN-based model and the decoderis an RNN-based model for text generation. Previous work, namely MILAN (MutualInformation-guided Linguistic Annotation of Neuron), has tried to visualize theneuron behaviour using modified Show, Attend, and Tell (SAT) model in theencoder, and LSTM added with Bahdanau attention in the decoder. MILAN can showgreat result on short sequence neuron captioning, but it does not show greatresult on long sequence neuron captioning, so in this work, we would like toimprove the performance of MILAN even more by utilizing different kind ofattention mechanism and additionally adding several attention result into one,in order to combine all the advantages from several attention mechanism. Usingour compound dataset, we obtained higher BLEU and F1-Score on our proposedmodel, achieving 17.742 and 0.4811 respectively. At some point where the modelconverges at the peak, our model obtained BLEU of 21.2262 and BERTScoreF1-Score of 0.4870.</description><author>Alfirsa Damasyifa Fauzulhaq, Wahyu Parwitayasa, Joseph Ananda Sugihdharma, M. Fadli Ridhani, Novanto Yudistira</author><pubDate>Fri, 05 Jan 2024 10:41:55 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.02744v1</guid></item><item><title>MoTCoder: Elevating Large Language Models with Modular of Thought for Challenging Programming Tasks</title><link>http://arxiv.org/abs/2312.15960v2</link><description>Large Language Models (LLMs) have showcased impressive capabilities inhandling straightforward programming tasks. However, their performance tends tofalter when confronted with more challenging programming problems. We observethat conventional models often generate solutions as monolithic code blocks,restricting their effectiveness in tackling intricate questions. To overcomethis limitation, we present Modular-of-Thought Coder (MoTCoder). We introduce apioneering framework for MoT instruction tuning, designed to promote thedecomposition of tasks into logical sub-tasks and sub-modules. Ourinvestigations reveal that, through the cultivation and utilization ofsub-modules, MoTCoder significantly improves both the modularity andcorrectness of the generated solutions, leading to substantial relative pass@1improvements of 12.9% on APPS and 9.43% on CodeContests. Our codes areavailable at https://github.com/dvlab-research/MoTCoder.</description><author>Jingyao Li, Pengguang Chen, Jiaya Jia</author><pubDate>Fri, 05 Jan 2024 10:33:32 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.15960v2</guid></item><item><title>DeepMerge: Deep-Learning-Based Region-Merging for Image Segmentation</title><link>http://arxiv.org/abs/2305.19787v2</link><description>Image segmentation aims to partition an image according to the objects in thescene and is a fundamental step in analysing very high spatial-resolution (VHR)remote sensing imagery. Current methods struggle to effectively consider landobjects with diverse shapes and sizes. Additionally, the determination ofsegmentation scale parameters frequently adheres to a static and empiricaldoctrine, posing limitations on the segmentation of large-scale remote sensingimages and yielding algorithms with limited interpretability. To address theabove challenges, we propose a deep-learning-based region merging method dubbedDeepMerge to handle the segmentation of complete objects in large VHR images byintegrating deep learning and region adjacency graph (RAG). This is the firstmethod to use deep learning to learn the similarity and merge similar adjacentsuper-pixels in RAG. We propose a modified binary tree sampling method togenerate shift-scale data, serving as inputs for transformer-based deeplearning networks, a shift-scale attention with 3-Dimension relative positionembedding to learn features across scales, and an embedding to fuse learnedfeatures with hand-crafted features. DeepMerge can achieve high segmentationaccuracy in a supervised manner from large-scale remotely sensed images andprovides an interpretable optimal scale parameter, which is validated using aremote sensing image of 0.55 m resolution covering an area of 5,660 km^2. Theexperimental results show that DeepMerge achieves the highest F value (0.9550)and the lowest total error TE (0.0895), correctly segmenting objects ofdifferent sizes and outperforming all competing segmentation methods.</description><author>Xianwei Lv, Claudio Persello, Wangbin Li, Xiao Huang, Dongping Ming, Alfred Stein</author><pubDate>Fri, 05 Jan 2024 10:29:59 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.19787v2</guid></item><item><title>Fairness-Aware Job Scheduling for Multi-Job Federated Learning</title><link>http://arxiv.org/abs/2401.02740v1</link><description>Federated learning (FL) enables multiple data owners (a.k.a. FL clients) tocollaboratively train machine learning models without disclosing sensitiveprivate data. Existing FL research mostly focuses on the monopoly scenario inwhich a single FL server selects a subset of FL clients to update their localmodels in each round of training. In practice, there can be multiple FL serverssimultaneously trying to select clients from the same pool. In this paper, wepropose a first-of-its-kind Fairness-aware Federated Job Scheduling (FairFedJS)approach to bridge this gap. Based on Lyapunov optimization, it ensures fairallocation of high-demand FL client datasets to FL jobs in need of them, byjointly considering the current demand and the job payment bids, in order toprevent prolonged waiting. Extensive experiments comparing FairFedJS againstfour state-of-the-art approaches on two datasets demonstrate its significantadvantages. It outperforms the best baseline by 31.9% and 1.0% on average interms of scheduling fairness and convergence time, respectively, whileachieving comparable test accuracy.</description><author>Yuxin Shi, Han Yu</author><pubDate>Fri, 05 Jan 2024 10:29:08 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.02740v1</guid></item><item><title>Diffusion Variational Inference: Diffusion Models as Expressive Variational Posteriors</title><link>http://arxiv.org/abs/2401.02739v1</link><description>We propose denoising diffusion variational inference (DDVI), an approximateinference algorithm for latent variable models which relies on diffusion modelsas expressive variational posteriors. Our method augments variationalposteriors with auxiliary latents, which yields an expressive class of modelsthat perform diffusion in latent space by reversing a user-specified noisingprocess. We fit these models by optimizing a novel lower bound on the marginallikelihood inspired by the wake-sleep algorithm. Our method is easy toimplement (it fits a regularized extension of the ELBO), is compatible withblack-box variational inference, and outperforms alternative classes ofapproximate posteriors based on normalizing flows or adversarial networks. Whenapplied to deep latent variable models, our method yields the denoisingdiffusion VAE (DD-VAE) algorithm. We use this algorithm on a motivating task inbiology -- inferring latent ancestry from human genomes -- outperforming strongbaselines on the Thousand Genomes dataset.</description><author>Top Piriyakulkij, Yingheng Wang, Volodymyr Kuleshov</author><pubDate>Fri, 05 Jan 2024 10:27:44 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.02739v1</guid></item><item><title>On the numerical reliability of nonsmooth autodiff: a MaxPool case study</title><link>http://arxiv.org/abs/2401.02736v1</link><description>This paper considers the reliability of automatic differentiation (AD) forneural networks involving the nonsmooth MaxPool operation. We investigate thebehavior of AD across different precision levels (16, 32, 64 bits) andconvolutional architectures (LeNet, VGG, and ResNet) on various datasets(MNIST, CIFAR10, SVHN, and ImageNet). Although AD can be incorrect, recentresearch has shown that it coincides with the derivative almost everywhere,even in the presence of nonsmooth operations (such as MaxPool and ReLU). On theother hand, in practice, AD operates with floating-point numbers (not realnumbers), and there is, therefore, a need to explore subsets on which AD can benumerically incorrect. These subsets include a bifurcation zone (where AD isincorrect over reals) and a compensation zone (where AD is incorrect overfloating-point numbers but correct over reals). Using SGD for the trainingprocess, we study the impact of different choices of the nonsmooth Jacobian forthe MaxPool function on the precision of 16 and 32 bits. These findings suggestthat nonsmooth MaxPool Jacobians with lower norms help maintain stable andefficient test accuracy, whereas those with higher norms can result ininstability and decreased performance. We also observe that the influence ofMaxPool's nonsmooth Jacobians on learning can be reduced by using batchnormalization, Adam-like optimizers, or increasing the precision level.</description><author>Ryan Boustany</author><pubDate>Fri, 05 Jan 2024 10:14:39 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.02736v1</guid></item><item><title>Shared active subspace for multivariate vector-valued functions</title><link>http://arxiv.org/abs/2401.02735v1</link><description>This paper proposes several approaches as baselines to compute a sharedactive subspace for multivariate vector-valued functions. The goal is tominimize the deviation between the function evaluations on the original spaceand those on the reconstructed one. This is done either by manipulating thegradients or the symmetric positive (semi-)definite (SPD) matrices computedfrom the gradients of each component function so as to get a single structurecommon to all component functions. These approaches can be applied to any datairrespective of the underlying distribution unlike the existing vector-valuedapproach that is constrained to a normal distribution. We test theeffectiveness of these methods on five optimization problems. The experimentsshow that, in general, the SPD-level methods are superior to the gradient-levelones, and are close to the vector-valued approach in the case of a normaldistribution. Interestingly, in most cases it suffices to take the sum of theSPD matrices to identify the best shared active subspace.</description><author>Khadija Musayeva, Mickael Binois</author><pubDate>Fri, 05 Jan 2024 10:08:38 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.02735v1</guid></item><item><title>FedNS: A Fast Sketching Newton-Type Algorithm for Federated Learning</title><link>http://arxiv.org/abs/2401.02734v1</link><description>Recent Newton-type federated learning algorithms have demonstrated linearconvergence with respect to the communication rounds. However, communicatingHessian matrices is often unfeasible due to their quadratic communicationcomplexity. In this paper, we introduce a novel approach to tackle this issuewhile still achieving fast convergence rates. Our proposed method, named asFederated Newton Sketch methods (FedNS), approximates the centralized Newton'smethod by communicating the sketched square-root Hessian instead of the exactHessian. To enhance communication efficiency, we reduce the sketch size tomatch the effective dimension of the Hessian matrix. We provide convergenceanalysis based on statistical learning for the federated Newton sketchapproaches. Specifically, our approaches reach super-linear convergence ratesw.r.t. the communication rounds for the first time. We validate theeffectiveness of our algorithms through various experiments, which coincidewith our theoretical findings.</description><author>Jian Li, Yong Liu, Wei Wang, Haoran Wu, Weiping Wang</author><pubDate>Fri, 05 Jan 2024 10:06:41 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.02734v1</guid></item></channel></rss>