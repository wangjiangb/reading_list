<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/"><channel><title>Arxivfresh papers</title><link></link><description>Arxiv paper</description><language>en-US</language><lastBuildDate>Mon, 12 Jun 2023 06:00:36 GMT</lastBuildDate><generator>rfeed v1.0.0</generator><docs>https://github.com/svpino/rfeed/blob/master/README.md</docs><item><title>Prodigy: An Expeditiously Adaptive Parameter-Free Learner</title><link>http://arxiv.org/abs/2306.06101v1</link><description>We consider the problem of estimating the learning rate in adaptive methods,such as Adagrad and Adam. We describe two techniques, Prodigy and Resetting, toprovably estimate the distance to the solution $D$, which is needed to set thelearning rate optimally. Our techniques are modifications of the D-Adaptationmethod for learning-rate-free learning. Our methods improve upon theconvergence rate of D-Adaptation by a factor of $O(\sqrt{\log(D/d_0)})$, where$d_0$ is the initial estimate of $D$. We test our methods on 12 commonlogistic-regression benchmark datasets, VGG11 and ResNet-50 training onCIFAR10, ViT training on Imagenet, LSTM training on IWSLT14, DLRM training onCriteo dataset, VarNet on Knee MRI dataset, as well as RoBERTa and GPTtransformer training on BookWiki. Our experimental results show that ourapproaches consistently outperform D-Adaptation and reach test accuracy valuesclose to that of hand-tuned Adam.</description><author>Konstantin Mishchenko, Aaron Defazio</author><pubDate>Fri, 09 Jun 2023 18:59:35 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.06101v1</guid></item><item><title>NuCLR: Nuclear Co-Learned Representations</title><link>http://arxiv.org/abs/2306.06099v1</link><description>We introduce Nuclear Co-Learned Representations (NuCLR), a deep learningmodel that predicts various nuclear observables, including binding and decayenergies, and nuclear charge radii. The model is trained using a multi-taskapproach with shared representations and obtains state-of-the-art performance,achieving levels of precision that are crucial for understanding fundamentalphenomena in nuclear (astro)physics. We also report an intriguing finding thatthe learned representation of NuCLR exhibits the prominent emergence of crucialaspects of the nuclear shell model, namely the shell structure, including thewell-known magic numbers, and the Pauli Exclusion Principle. This suggests thatthe model is capable of capturing the underlying physical principles and thatour approach has the potential to offer valuable insights into nuclear theory.</description><author>Ouail Kitouni, Niklas Nolte, Sokratis Trifinopoulos, Subhash Kantamneni, Mike Williams</author><pubDate>Fri, 09 Jun 2023 18:59:16 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.06099v1</guid></item><item><title>Error Feedback Can Accurately Compress Preconditioners</title><link>http://arxiv.org/abs/2306.06098v1</link><description>Leveraging second-order information at the scale of deep networks is one ofthe main lines of approach for improving the performance of current optimizersfor deep learning. Yet, existing approaches for accurate full-matrixpreconditioning, such as Full-Matrix Adagrad (GGT) or Matrix-Free ApproximateCurvature (M-FAC) suffer from massive storage costs when applied even tomedium-scale models, as they must store a sliding window of gradients, whosememory requirements are multiplicative in the model dimension. In this paper,we address this issue via an efficient and simple-to-implement error-feedbacktechnique that can be applied to compress preconditioners by up to two ordersof magnitude in practice, without loss of convergence. Specifically, ourapproach compresses the gradient information via sparsification or low-rankcompression \emph{before} it is fed into the preconditioner, feeding thecompression error back into future iterations. Extensive experiments on deepneural networks for vision show that this approach can compress full-matrixpreconditioners by up to two orders of magnitude without impact on accuracy,effectively removing the memory overhead of full-matrix preconditioning forimplementations of full-matrix Adagrad (GGT) and natural gradient (M-FAC). Ourcode is available at https://github.com/IST-DASLab/EFCP.</description><author>Ionut-Vlad Modoranu, Aleksei Kalinov, Eldar Kurtic, Dan Alistarh</author><pubDate>Fri, 09 Jun 2023 18:58:47 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.06098v1</guid></item><item><title>On the Reliability of Watermarks for Large Language Models</title><link>http://arxiv.org/abs/2306.04634v2</link><description>As LLMs become commonplace, machine-generated text has the potential to floodthe internet with spam, social media bots, and valueless content. Watermarkingis a simple and effective strategy for mitigating such harms by enabling thedetection and documentation of LLM-generated text. Yet a crucial questionremains: How reliable is watermarking in realistic settings in the wild? There,watermarked text may be modified to suit a user's needs, or entirely rewrittento avoid detection. We study the robustness of watermarked text after it is re-written by humans,paraphrased by a non-watermarked LLM, or mixed into a longer hand-writtendocument. We find that watermarks remain detectable even after human andmachine paraphrasing. While these attacks dilute the strength of the watermark,paraphrases are statistically likely to leak n-grams or even longer fragmentsof the original text, resulting in high-confidence detections when enoughtokens are observed. For example, after strong human paraphrasing the watermarkis detectable after observing 800 tokens on average, when setting a 1e-5 falsepositive rate. We also consider a range of new detection schemes that aresensitive to short spans of watermarked text embedded inside a large document,and we compare the robustness of watermarking to other kinds of detectors.</description><author>John Kirchenbauer, Jonas Geiping, Yuxin Wen, Manli Shu, Khalid Saifullah, Kezhi Kong, Kasun Fernando, Aniruddha Saha, Micah Goldblum, Tom Goldstein</author><pubDate>Fri, 09 Jun 2023 18:58:04 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.04634v2</guid></item><item><title>Leveraging Large Language Models for Scalable Vector Graphics-Driven Image Understanding</title><link>http://arxiv.org/abs/2306.06094v1</link><description>Recently, large language models (LLMs) have made significant advancements innatural language understanding and generation. However, their potential incomputer vision remains largely unexplored. In this paper, we introduce a new,exploratory approach that enables LLMs to process images using the ScalableVector Graphics (SVG) format. By leveraging the XML-based textual descriptionsof SVG representations instead of raster images, we aim to bridge the gapbetween the visual and textual modalities, allowing LLMs to directly understandand manipulate images without the need for parameterized visual components. Ourmethod facilitates simple image classification, generation, and in-contextlearning using only LLM capabilities. We demonstrate the promise of ourapproach across discriminative and generative tasks, highlighting its (i)robustness against distribution shift, (ii) substantial improvements achievedby tapping into the in-context learning abilities of LLMs, and (iii) imageunderstanding and generation capabilities with human guidance. Our code, data,and models can be found here https://github.com/mu-cai/svg-llm.</description><author>Mu Cai, Zeyi Huang, Yuheng Li, Haohan Wang, Yong Jae Lee</author><pubDate>Fri, 09 Jun 2023 18:57:01 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.06094v1</guid></item><item><title>HyP-NeRF: Learning Improved NeRF Priors using a HyperNetwork</title><link>http://arxiv.org/abs/2306.06093v1</link><description>Neural Radiance Fields (NeRF) have become an increasingly popularrepresentation to capture high-quality appearance and shape of scenes andobjects. However, learning generalizable NeRF priors over categories of scenesor objects has been challenging due to the high dimensionality of networkweight space. To address the limitations of existing work on generalization,multi-view consistency and to improve quality, we propose HyP-NeRF, a latentconditioning method for learning generalizable category-level NeRF priors usinghypernetworks. Rather than using hypernetworks to estimate only the weights ofa NeRF, we estimate both the weights and the multi-resolution hash encodingsresulting in significant quality gains. To improve quality even further, weincorporate a denoise and finetune strategy that denoises images rendered fromNeRFs estimated by the hypernetwork and finetunes it while retaining multiviewconsistency. These improvements enable us to use HyP-NeRF as a generalizableprior for multiple downstream tasks including NeRF reconstruction fromsingle-view or cluttered scenes and text-to-NeRF. We provide qualitativecomparisons and evaluate HyP-NeRF on three tasks: generalization, compression,and retrieval, demonstrating our state-of-the-art results.</description><author>Bipasha Sen, Gaurav Singh, Aditya Agarwal, Rohith Agaram, K Madhava Krishna, Srinath Sridhar</author><pubDate>Fri, 09 Jun 2023 18:56:07 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.06093v1</guid></item><item><title>Realistic Saliency Guided Image Enhancement</title><link>http://arxiv.org/abs/2306.06092v1</link><description>Common editing operations performed by professional photographers include thecleanup operations: de-emphasizing distracting elements and enhancing subjects.These edits are challenging, requiring a delicate balance between manipulatingthe viewer's attention while maintaining photo realism. While recent approachescan boast successful examples of attention attenuation or amplification, mostof them also suffer from frequent unrealistic edits. We propose a realism lossfor saliency-guided image enhancement to maintain high realism across varyingimage types, while attenuating distractors and amplifying objects of interest.Evaluations with professional photographers confirm that we achieve the dualobjective of realism and effectiveness, and outperform the recent approaches ontheir own datasets, while requiring a smaller memory footprint and runtime. Wethus offer a viable solution for automating image enhancement and photo cleanupoperations.</description><author>S. Mahdi H. Miangoleh, Zoya Bylinskii, Eric Kee, Eli Shechtman, Yağız Aksoy</author><pubDate>Fri, 09 Jun 2023 18:52:34 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.06092v1</guid></item><item><title>Computational Flash Photography through Intrinsics</title><link>http://arxiv.org/abs/2306.06089v1</link><description>Flash is an essential tool as it often serves as the sole controllable lightsource in everyday photography. However, the use of flash is a binary decisionat the time a photograph is captured with limited control over itscharacteristics such as strength or color. In this work, we study thecomputational control of the flash light in photographs taken with or withoutflash. We present a physically motivated intrinsic formulation for flashphotograph formation and develop flash decomposition and generation methods forflash and no-flash photographs, respectively. We demonstrate that our intrinsicformulation outperforms alternatives in the literature and allows us tocomputationally control flash in in-the-wild images.</description><author>Sepideh Sarajian Maralan, Chris Careaga, Yağız Aksoy</author><pubDate>Fri, 09 Jun 2023 18:51:20 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.06089v1</guid></item><item><title>SENS: Sketch-based Implicit Neural Shape Modeling</title><link>http://arxiv.org/abs/2306.06088v1</link><description>We present SENS, a novel method for generating and editing 3D models fromhand-drawn sketches, including those of an abstract nature. Our method allowsusers to quickly and easily sketch a shape, and then maps the sketch into thelatent space of a part-aware neural implicit shape architecture. SENS analyzesthe sketch and encodes its parts into ViT patch encoding, then feeds them intoa transformer decoder that converts them to shape embeddings, suitable forediting 3D neural implicit shapes. SENS not only provides intuitivesketch-based generation and editing, but also excels in capturing the intent ofthe user's sketch to generate a variety of novel and expressive 3D shapes, evenfrom abstract sketches. We demonstrate the effectiveness of our model comparedto the state-of-the-art using objective metric evaluation criteria and adecisive user study, both indicating strong performance on sketches with amedium level of abstraction. Furthermore, we showcase its intuitivesketch-based shape editing capabilities.</description><author>Alexandre Binninger, Amir Hertz, Olga Sorkine-Hornung, Daniel Cohen-Or, Raja Giryes</author><pubDate>Fri, 09 Jun 2023 18:50:53 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.06088v1</guid></item><item><title>Learning Not to Spoof</title><link>http://arxiv.org/abs/2306.06087v1</link><description>As intelligent trading agents based on reinforcement learning (RL) gainprevalence, it becomes more important to ensure that RL agents obey laws,regulations, and human behavioral expectations. There is substantial literatureconcerning the aversion of obvious catastrophes like crashing a helicopter orbankrupting a trading account, but little around the avoidance of subtlenon-normative behavior for which there are examples, but no programmabledefinition. Such behavior may violate legal or regulatory, rather than physicalor monetary, constraints. In this article, I consider a series of experiments in which an intelligentstock trading agent maximizes profit but may also inadvertently learn to spoofthe market in which it participates. I first inject a hand-coded spoofing agentto a multi-agent market simulation and learn to recognize spoofing activitysequences. Then I replace the hand-coded spoofing trader with a simpleprofit-maximizing RL agent and observe that it independently discovers spoofingas the optimal strategy. Finally, I introduce a method to incorporate therecognizer as normative guide, shaping the agent's perceived rewards andaltering its selected actions. The agent remains profitable while avoidingspoofing behaviors that would result in even higher profit. After presentingthe empirical results, I conclude with some recommendations. The method shouldgeneralize to the reduction of any unwanted behavior for which a recognizer canbe learned.</description><author>David Byrd</author><pubDate>Fri, 09 Jun 2023 18:49:56 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.06087v1</guid></item><item><title>Developing Speech Processing Pipelines for Police Accountability</title><link>http://arxiv.org/abs/2306.06086v1</link><description>Police body-worn cameras have the potential to improve accountability andtransparency in policing. Yet in practice, they result in millions of hours offootage that is never reviewed. We investigate the potential of largepre-trained speech models for facilitating reviews, focusing on ASR and officerspeech detection in footage from traffic stops. Our proposed pipeline includestraining data alignment and filtering, fine-tuning with resource constraints,and combining officer speech detection with ASR for a fully automated approach.We find that (1) fine-tuning strongly improves ASR performance on officerspeech (WER=12-13%), (2) ASR on officer speech is much more accurate than oncommunity member speech (WER=43.55-49.07%), (3) domain-specific tasks likeofficer speech detection and diarization remain challenging. Our work offerspractical applications for reviewing body camera footage and general guidancefor adapting pre-trained speech models to noisy multi-speaker domains.</description><author>Anjalie Field, Prateek Verma, Nay San, Jennifer L. Eberhardt, Dan Jurafsky</author><pubDate>Fri, 09 Jun 2023 18:48:58 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.06086v1</guid></item><item><title>Trapping LLM Hallucinations Using Tagged Context Prompts</title><link>http://arxiv.org/abs/2306.06085v1</link><description>Recent advances in large language models (LLMs), such as ChatGPT, have led tohighly sophisticated conversation agents. However, these models suffer from"hallucinations," where the model generates false or fabricated information.Addressing this challenge is crucial, particularly with AI-driven platformsbeing adopted across various sectors. In this paper, we propose a novel methodto recognize and flag instances when LLMs perform outside their domainknowledge, and ensuring users receive accurate information. We find that the use of context combined with embedded tags can successfullycombat hallucinations within generative language models. To do this, webaseline hallucination frequency in no-context prompt-response pairs usinggenerated URLs as easily-tested indicators of fabricated data. We observed asignificant reduction in overall hallucination when context was supplied alongwith question prompts for tested generative engines. Lastly, we evaluated howplacing tags within contexts impacted model responses and were able toeliminate hallucinations in responses with 98.88% effectiveness.</description><author>Philip Feldman, James R. Foulds, Shimei Pan</author><pubDate>Fri, 09 Jun 2023 18:48:54 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.06085v1</guid></item><item><title>Mind2Web: Towards a Generalist Agent for the Web</title><link>http://arxiv.org/abs/2306.06070v1</link><description>We introduce Mind2Web, the first dataset for developing and evaluatinggeneralist agents for the web that can follow language instructions to completecomplex tasks on any website. Existing datasets for web agents either usesimulated websites or only cover a limited set of websites and tasks, thus notsuitable for generalist web agents. With over 2,000 open-ended tasks collectedfrom 137 websites spanning 31 domains and crowdsourced action sequences for thetasks, Mind2Web provides three necessary ingredients for building generalistweb agents: 1) diverse domains, websites, and tasks, 2) use of real-worldwebsites instead of simulated and simplified ones, and 3) a broad spectrum ofuser interaction patterns. Based on Mind2Web, we conduct an initial explorationof using large language models (LLMs) for building generalist web agents. Whilethe raw HTML of real-world websites are often too large to be fed to LLMs, weshow that first filtering it with a small LM significantly improves theeffectiveness and efficiency of LLMs. Our solution demonstrates a decent levelof performance, even on websites or entire domains the model has never seenbefore, but there is still a substantial room to improve towards trulygeneralizable agents. We open-source our dataset, model implementation, andtrained models (https://osu-nlp-group.github.io/Mind2Web) to facilitate furtherresearch on building a generalist agent for the web.</description><author>Xiang Deng, Yu Gu, Boyuan Zheng, Shijie Chen, Samuel Stevens, Boshi Wang, Huan Sun, Yu Su</author><pubDate>Fri, 09 Jun 2023 18:44:31 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.06070v1</guid></item><item><title>Combining a Meta-Policy and Monte-Carlo Planning for Scalable Type-Based Reasoning in Partially Observable Environments</title><link>http://arxiv.org/abs/2306.06067v1</link><description>The design of autonomous agents that can interact effectively with otheragents without prior coordination is a core problem in multi-agent systems.Type-based reasoning methods achieve this by maintaining a belief over a set ofpotential behaviours for the other agents. However, current methods are limitedin that they assume full observability of the state and actions of the otheragent or do not scale efficiently to larger problems with longer planninghorizons. Addressing these limitations, we propose Partially ObservableType-based Meta Monte-Carlo Planning (POTMMCP) - an online Monte-Carlo TreeSearch based planning method for type-based reasoning in large partiallyobservable environments. POTMMCP incorporates a novel meta-policy for guidingsearch and evaluating beliefs, allowing it to search more effectively to longerhorizons using less planning time. We show that our method converges to theoptimal solution in the limit and empirically demonstrate that it effectivelyadapts online to diverse sets of other agents across a range of environments.Comparisons with the state-of-the art method on problems with up to $10^{14}$states and $10^8$ observations indicate that POTMMCP is able to compute bettersolutions significantly faster.</description><author>Jonathon Schwartz, Hanna Kurniawati, Marcus Hutter</author><pubDate>Fri, 09 Jun 2023 18:43:49 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.06067v1</guid></item><item><title>Virtual Node Tuning for Few-shot Node Classification</title><link>http://arxiv.org/abs/2306.06063v1</link><description>Few-shot Node Classification (FSNC) is a challenge in graph representationlearning where only a few labeled nodes per class are available for training.To tackle this issue, meta-learning has been proposed to transfer structuralknowledge from base classes with abundant labels to target novel classes.However, existing solutions become ineffective or inapplicable when baseclasses have no or limited labeled nodes. To address this challenge, we proposean innovative method dubbed Virtual Node Tuning (VNT). Our approach utilizes apretrained graph transformer as the encoder and injects virtual nodes as softprompts in the embedding space, which can be optimized with few-shot labels innovel classes to modulate node embeddings for each specific FSNC task. A uniquefeature of VNT is that, by incorporating a Graph-based Pseudo Prompt Evolution(GPPE) module, VNT-GPPE can handle scenarios with sparse labels in baseclasses. Experimental results on four datasets demonstrate the superiority ofthe proposed approach in addressing FSNC with unlabeled or sparsely labeledbase classes, outperforming existing state-of-the-art methods and even fullysupervised baselines.</description><author>Zhen Tan, Ruocheng Guo, Kaize Ding, Huan Liu</author><pubDate>Fri, 09 Jun 2023 18:38:22 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.06063v1</guid></item><item><title>Assisting Language Learners: Automated Trans-Lingual Definition Generation via Contrastive Prompt Learning</title><link>http://arxiv.org/abs/2306.06058v1</link><description>The standard definition generation task requires to automatically producemono-lingual definitions (e.g., English definitions for English words), butignores that the generated definitions may also consist of unfamiliar words forlanguage learners. In this work, we propose a novel task of Trans-LingualDefinition Generation (TLDG), which aims to generate definitions in anotherlanguage, i.e., the native speaker's language. Initially, we explore theunsupervised manner of this task and build up a simple implementation offine-tuning the multi-lingual machine translation model. Then, we develop twonovel methods, Prompt Combination and Contrastive Prompt Learning, for furtherenhancing the quality of the generation. Our methods are evaluated against thebaseline Pipeline method in both rich- and low-resource settings, and weempirically establish its superiority in generating higher-qualitytrans-lingual definitions.</description><author>Hengyuan Zhang, Dawei Li, Yanran Li, Chenming Shang, Chufan Shi, Yong Jiang</author><pubDate>Fri, 09 Jun 2023 18:32:45 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.06058v1</guid></item><item><title>Exploring the Impact of Image Resolution on Chest X-ray Classification Performance</title><link>http://arxiv.org/abs/2306.06051v1</link><description>Deep learning models for image classification have often used a resolution of$224\times224$ pixels for computational reasons. This study investigates the effect of image resolution on chest X-rayclassification performance, using the ChestX-ray14 dataset. The results show that a higher image resolution, specifically$1024\times1024$ pixels, has the best overall classification performance, witha slight decline in performance between $256\times256$ to $512\times512$ pixelsfor most of the pathological classes. Comparison of saliency map-generated bounding boxes revealed that commonlyused resolutions are insufficient for finding most pathologies.</description><author>Alessandro Wollek, Sardi Hyska, Bastian Sabel, Michael Ingrisch, Tobias Lasser</author><pubDate>Fri, 09 Jun 2023 18:21:52 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.06051v1</guid></item><item><title>AUTODIAL: Efficient Asynchronous Task-Oriented Dialogue Model</title><link>http://arxiv.org/abs/2303.06245v3</link><description>As large dialogue models become commonplace in practice, the problemssurrounding high compute requirements for training, inference and larger memoryfootprint still persists. In this work, we present AUTODIAL, a multi-taskdialogue model that addresses the challenges of deploying dialogue model.AUTODIAL utilizes parallel decoders to perform tasks such as dialogue actprediction, domain prediction, intent prediction, and dialogue state tracking.Using classification decoders over generative decoders allows AUTODIAL tosignificantly reduce memory footprint and achieve faster inference timescompared to existing generative approach namely SimpleTOD. We demonstrate thatAUTODIAL provides 3-6x speedups during inference while having 11x fewerparameters on three dialogue tasks compared to SimpleTOD. Our results show thatextending current dialogue models to have parallel decoders can be a viablealternative for deploying them in resource-constrained environments.</description><author>Prajjwal Bhargava, Pooyan Amini, Shahin Shayandeh, Chinnadhurai Sankar</author><pubDate>Fri, 09 Jun 2023 18:18:03 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2303.06245v3</guid></item><item><title>How Does Fine-Tuning Impact Out-of-Distribution Detection for Vision-Language Models?</title><link>http://arxiv.org/abs/2306.06048v1</link><description>Recent large vision-language models such as CLIP have shown remarkableout-of-distribution (OOD) detection and generalization performance. However,their zero-shot in-distribution (ID) accuracy is often limited for downstreamdatasets. Recent CLIP-based fine-tuning methods such as prompt learning havedemonstrated significant improvements in ID classification and OODgeneralization where OOD labels are available. Nonetheless, it remains unclearwhether the model is reliable to semantic shifts without OOD labels. In thispaper, we aim to bridge the gap and present a comprehensive study to understandhow fine-tuning impact OOD detection for few-shot downstream tasks. By framingOOD detection as multi-modal concept matching, we establish a connectionbetween fine-tuning methods and various OOD scores. Our results suggest that aproper choice of OOD scores is essential for CLIP-based fine-tuning. Inparticular, the maximum concept matching (MCM) score provides a promisingsolution consistently. We also show that prompt learning demonstrates thestate-of-the-art OOD detection performance over the zero-shot counterpart.</description><author>Yifei Ming, Yixuan Li</author><pubDate>Fri, 09 Jun 2023 18:16:50 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.06048v1</guid></item><item><title>DiViNeT: 3D Reconstruction from Disparate Views via Neural Template Regularization</title><link>http://arxiv.org/abs/2306.04699v2</link><description>We present a volume rendering-based neural surface reconstruction method thattakes as few as three disparate RGB images as input. Our key idea is toregularize the reconstruction, which is severely ill-posed and leavingsignificant gaps between the sparse views, by learning a set of neuraltemplates that act as surface priors. Our method coined DiViNet, operates intwo stages. The first stage learns the templates, in the form of 3D Gaussianfunctions, across different scenes, without 3D supervision. In thereconstruction stage, our predicted templates serve as anchors to help "stitch"the surfaces over sparse regions. We demonstrate that our approach is not onlyable to complete the surface geometry but also reconstructs surface details toa reasonable extent from few disparate input views. On the DTU and BlendedMVSdatasets, our approach achieves the best reconstruction quality among existingmethods in the presence of such sparse views, and performs on par, if notbetter, with competing methods when dense views are employed as inputs.</description><author>Aditya Vora, Akshay Gadi Patil, Hao Zhang</author><pubDate>Fri, 09 Jun 2023 18:14:02 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.04699v2</guid></item><item><title>GANeRF: Leveraging Discriminators to Optimize Neural Radiance Fields</title><link>http://arxiv.org/abs/2306.06044v1</link><description>Neural Radiance Fields (NeRF) have shown impressive novel view synthesisresults; nonetheless, even thorough recordings yield imperfections inreconstructions, for instance due to poorly observed areas or minor lightingchanges. Our goal is to mitigate these imperfections from various sources witha joint solution: we take advantage of the ability of generative adversarialnetworks (GANs) to produce realistic images and use them to enhance realism in3D scene reconstruction with NeRFs. To this end, we learn the patchdistribution of a scene using an adversarial discriminator, which providesfeedback to the radiance field reconstruction, thus improving realism in a3D-consistent fashion. Thereby, rendering artifacts are repaired directly inthe underlying 3D representation by imposing multi-view path renderingconstraints. In addition, we condition a generator with multi-resolution NeRFrenderings which is adversarially trained to further improve rendering quality.We demonstrate that our approach significantly improves rendering quality,e.g., nearly halving LPIPS scores compared to Nerfacto while at the same timeimproving PSNR by 1.4dB on the advanced indoor scenes of Tanks and Temples.</description><author>Barbara Roessle, Norman Müller, Lorenzo Porzi, Samuel Rota Bulò, Peter Kontschieder, Matthias Nießner</author><pubDate>Fri, 09 Jun 2023 18:12:35 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.06044v1</guid></item><item><title>Efficient Learning for Selecting Top-m Context-Dependent Designs</title><link>http://arxiv.org/abs/2305.04086v2</link><description>We consider a simulation optimization problem for a context-dependentdecision-making, which aims to determine the top-m designs for all contexts.Under a Bayesian framework, we formulate the optimal dynamic sampling decisionas a stochastic dynamic programming problem, and develop a sequential samplingpolicy to efficiently learn the performance of each design under each context.The asymptotically optimal sampling ratios are derived to attain the optimallarge deviations rate of the worst-case of probability of false selection. Theproposed sampling policy is proved to be consistent and its asymptotic samplingratios are asymptotically optimal. Numerical experiments demonstrate that theproposed method improves the efficiency for selection of top-mcontext-dependent designs.</description><author>Gongbo Zhang, Sihua Chen, Kuihua Huang, Yijie Peng</author><pubDate>Fri, 09 Jun 2023 18:11:50 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.04086v2</guid></item><item><title>L-GreCo: Layerwise-Adaptive Gradient Compression for Efficient and Accurate Deep Learning</title><link>http://arxiv.org/abs/2210.17357v2</link><description>Data-parallel distributed training of deep neural networks (DNN) has gainedvery widespread adoption, but can still experience communication bottlenecks.To address this issue, entire families of compression mechanisms have beendeveloped, including quantization, sparsification, and low-rank approximation,some of which are seeing significant practical adoption. Despite this progress,almost all known compression schemes apply compression uniformly across DNNlayers, although layers are heterogeneous in terms of parameter count and theirimpact on model accuracy. In this work, we provide a general framework foradapting the degree of compression across the model's layers dynamically duringtraining, improving the overall compression, while leading to substantialspeedups, without sacrificing accuracy. Our framework, called L-GreCo, is basedon an adaptive algorithm, which automatically picks the optimal compressionparameters for model layers guaranteeing the best compression ratio whilesatisfying an error constraint. Extensive experiments over image classificationand language modeling tasks shows that L-GreCo is effective across all existingfamilies of compression methods, and achieves up to 2.5$\times$ trainingspeedup and up to 5$\times$ compression improvement over efficientimplementations of existing approaches, while recovering full accuracy.Moreover, L-GreCo is complementary to existing adaptive algorithms, improvingtheir compression ratio by 50% and practical throughput by 66%.</description><author>Mohammadreza Alimohammadi, Ilia Markov, Elias Frantar, Dan Alistarh</author><pubDate>Fri, 09 Jun 2023 18:11:26 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2210.17357v2</guid></item><item><title>A Dynamical Graph Prior for Relational Inference</title><link>http://arxiv.org/abs/2306.06041v1</link><description>Relational inference aims to identify interactions between parts of adynamical system from the observed dynamics. Current state-of-the-art methodsfit a graph neural network (GNN) on a learnable graph to the dynamics. They useone-step message-passing GNNs -- intuitively the right choice sincenon-locality of multi-step or spectral GNNs may confuse direct and indirectinteractions. But the \textit{effective} interaction graph depends on thesampling rate and it is rarely localized to direct neighbors, leading to localminima for the one-step model. In this work, we propose a \textit{dynamicalgraph prior} (DYGR) for relational inference. The reason we call it a prior isthat, contrary to established practice, it constructively uses erroramplification in high-degree non-local polynomial filters to generate goodgradients for graph learning. To deal with non-uniqueness, DYGR simultaneouslyfits a ``shallow'' one-step model with shared graph topology. Experiments showthat DYGR reconstructs graphs far more accurately than earlier methods, withremarkable robustness to under-sampling. Since appropriate sampling rates forunknown dynamical systems are not known a priori, this robustness makes DYGRsuitable for real applications in scientific machine learning.</description><author>Liming Pan, Cheng Shi, Ivan Dokmanić</author><pubDate>Fri, 09 Jun 2023 18:07:04 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.06041v1</guid></item><item><title>Reconstructing Human Expressiveness in Piano Performances with a Transformer Network</title><link>http://arxiv.org/abs/2306.06040v1</link><description>Capturing intricate and subtle variations in human expressiveness in musicperformance using computational approaches is challenging. In this paper, wepropose a novel approach for reconstructing human expressiveness in pianoperformance with a multi-layer bi-directional Transformer encoder. To addressthe needs for large amounts of accurately captured and score-alignedperformance data in training neural networks, we use transcribed scoresobtained from an existing transcription model to train our model. We integratepianist identities to control the sampling process and explore the ability ofour system to model variations in expressiveness for different pianists. Thesystem is evaluated through statistical analysis of generated expressiveperformances and a listening test. Overall, the results suggest that our methodachieves state-of-the-art in generating human-like piano performances fromtranscribed scores, while fully and consistently reconstructing humanexpressiveness poses further challenges.</description><author>Jingjing Tang, Geraint Wiggins, George Fazekas</author><pubDate>Fri, 09 Jun 2023 18:05:53 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.06040v1</guid></item><item><title>Unsupervised hierarchical clustering using the learning dynamics of RBMs</title><link>http://arxiv.org/abs/2302.01851v3</link><description>Datasets in the real world are often complex and to some degree hierarchical,with groups and sub-groups of data sharing common characteristics at differentlevels of abstraction. Understanding and uncovering the hidden structure ofthese datasets is an important task that has many practical applications. Toaddress this challenge, we present a new and general method for buildingrelational data trees by exploiting the learning dynamics of the RestrictedBoltzmann Machine (RBM). Our method is based on the mean-field approach,derived from the Plefka expansion, and developed in the context of disorderedsystems. It is designed to be easily interpretable. We tested our method in anartificially created hierarchical dataset and on three different real-worlddatasets (images of digits, mutations in the human genome, and a homologousfamily of proteins). The method is able to automatically identify thehierarchical structure of the data. This could be useful in the study ofhomologous protein sequences, where the relationships between proteins arecritical for understanding their function and evolution.</description><author>Aurélien Decelle, Lorenzo Rosset, Beatriz Seoane</author><pubDate>Fri, 09 Jun 2023 18:05:09 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2302.01851v3</guid></item><item><title>Causal Deep Reinforcement Learning Using Observational Data</title><link>http://arxiv.org/abs/2211.15355v2</link><description>Deep reinforcement learning (DRL) requires the collection of interventionaldata, which is sometimes expensive and even unethical in the real world, suchas in the autonomous driving and the medical field. Offline reinforcementlearning promises to alleviate this issue by exploiting the vast amount ofobservational data available in the real world. However, observational data maymislead the learning agent to undesirable outcomes if the behavior policy thatgenerates the data depends on unobserved random variables (i.e., confounders).In this paper, we propose two deconfounding methods in DRL to address thisproblem. The methods first calculate the importance degree of different samplesbased on the causal inference technique, and then adjust the impact ofdifferent samples on the loss function by reweighting or resampling the offlinedataset to ensure its unbiasedness. These deconfounding methods can be flexiblycombined with existing model-free DRL algorithms such as soft actor-critic anddeep Q-learning, provided that a weak condition can be satisfied by the lossfunctions of these algorithms. We prove the effectiveness of our deconfoundingmethods and validate them experimentally.</description><author>Wenxuan Zhu, Chao Yu, Qiang Zhang</author><pubDate>Fri, 09 Jun 2023 18:03:15 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2211.15355v2</guid></item><item><title>WindowNet: Learnable Windows for Chest X-ray Classification</title><link>http://arxiv.org/abs/2306.06038v1</link><description>Chest X-ray (CXR) images are commonly compressed to a lower resolution andbit depth to reduce their size, potentially altering subtle diagnosticfeatures. Radiologists use windowing operations to enhance image contrast, but theimpact of such operations on CXR classification performance is unclear. In this study, we show that windowing can improve CXR classificationperformance, and propose WindowNet, a model that learns optimal windowsettings. We first investigate the impact of bit-depth on classification performanceand find that a higher bit-depth (12-bit) leads to improved performance. We then evaluate different windowing settings and show that training with adistinct window generally improves pathology-wise classification performance. Finally, we propose and evaluate WindowNet, a model that learns optimalwindow settings, and show that it significantly improves performance comparedto the baseline model without windowing.</description><author>Alessandro Wollek, Sardi Hyska, Bastian Sabel, Michael Ingrisch, Tobias Lasser</author><pubDate>Fri, 09 Jun 2023 18:02:26 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.06038v1</guid></item><item><title>SNeL: A Structured Neuro-Symbolic Language for Entity-Based Multimodal Scene Understanding</title><link>http://arxiv.org/abs/2306.06036v1</link><description>In the evolving landscape of artificial intelligence, multimodal andNeuro-Symbolic paradigms stand at the forefront, with a particular emphasis onthe identification and interaction with entities and their relations acrossdiverse modalities. Addressing the need for complex querying and interaction inthis context, we introduce SNeL (Structured Neuro-symbolic Language), aversatile query language designed to facilitate nuanced interactions withneural networks processing multimodal data. SNeL's expressive interface enablesthe construction of intricate queries, supporting logical and arithmeticoperators, comparators, nesting, and more. This allows users to target specificentities, specify their properties, and limit results, thereby efficientlyextracting information from a scene. By aligning high-level symbolic reasoningwith low-level neural processing, SNeL effectively bridges the Neuro-Symbolicdivide. The language's versatility extends to a variety of data types,including images, audio, and text, making it a powerful tool for multimodalscene understanding. Our evaluations demonstrate SNeL's potential to reshapethe way we interact with complex neural networks, underscoring its efficacy indriving targeted information extraction and facilitating a deeper understandingof the rich semantics encapsulated in multimodal AI models.</description><author>Silvan Ferreira, Allan Martins, Ivanovitch Silva</author><pubDate>Fri, 09 Jun 2023 18:01:51 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.06036v1</guid></item><item><title>RANS-PINN based Simulation Surrogates for Predicting Turbulent Flows</title><link>http://arxiv.org/abs/2306.06034v1</link><description>Physics-informed neural networks (PINNs) provide a framework to buildsurrogate models for dynamical systems governed by differential equations.During the learning process, PINNs incorporate a physics-based regularizationterm within the loss function to enhance generalization performance. Sincesimulating dynamics controlled by partial differential equations (PDEs) can becomputationally expensive, PINNs have gained popularity in learning parametricsurrogates for fluid flow problems governed by Navier-Stokes equations. In thiswork, we introduce RANS-PINN, a modified PINN framework, to predict flow fields(i.e., velocity and pressure) in high Reynolds number turbulent flow regime. Toaccount for the additional complexity introduced by turbulence, RANS-PINNemploys a 2-equation eddy viscosity model based on a Reynolds-averagedNavier-Stokes (RANS) formulation. Furthermore, we adopt a novel trainingapproach that ensures effective initialization and balance among the variouscomponents of the loss function. The effectiveness of RANS-PINN framework isthen demonstrated using a parametric PINN.</description><author>Shinjan Ghosh, Amit Chakraborty, Georgia Olympia Brikis, Biswadip Dey</author><pubDate>Fri, 09 Jun 2023 17:55:49 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.06034v1</guid></item><item><title>FinGPT: Open-Source Financial Large Language Models</title><link>http://arxiv.org/abs/2306.06031v1</link><description>Large language models (LLMs) have shown the potential of revolutionizingnatural language processing tasks in diverse domains, sparking great interestin finance. Accessing high-quality financial data is the first challenge forfinancial LLMs (FinLLMs). While proprietary models like BloombergGPT have takenadvantage of their unique data accumulation, such privileged access calls foran open-source alternative to democratize Internet-scale financial data. In this paper, we present an open-source large language model, FinGPT, forthe finance sector. Unlike proprietary models, FinGPT takes a data-centricapproach, providing researchers and practitioners with accessible andtransparent resources to develop their FinLLMs. We highlight the importance ofan automatic data curation pipeline and the lightweight low-rank adaptationtechnique in building FinGPT. Furthermore, we showcase several potentialapplications as stepping stones for users, such as robo-advising, algorithmictrading, and low-code development. Through collaborative efforts within theopen-source AI4Finance community, FinGPT aims to stimulate innovation,democratize FinLLMs, and unlock new opportunities in open finance. Twoassociated code repos are \url{https://github.com/AI4Finance-Foundation/FinGPT}and \url{https://github.com/AI4Finance-Foundation/FinNLP}</description><author>Hongyang Yang, Xiao-Yang Liu, Christina Dan Wang</author><pubDate>Fri, 09 Jun 2023 17:52:00 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.06031v1</guid></item><item><title>HiTZ@Antidote: Argumentation-driven Explainable Artificial Intelligence for Digital Medicine</title><link>http://arxiv.org/abs/2306.06029v1</link><description>Providing high quality explanations for AI predictions based on machinelearning is a challenging and complex task. To work well it requires, amongother factors: selecting a proper level of generality/specificity of theexplanation; considering assumptions about the familiarity of the explanationbeneficiary with the AI task under consideration; referring to specificelements that have contributed to the decision; making use of additionalknowledge (e.g. expert evidence) which might not be part of the predictionprocess; and providing evidence supporting negative hypothesis. Finally, thesystem needs to formulate the explanation in a clearly interpretable, andpossibly convincing, way. Given these considerations, ANTIDOTE fosters anintegrated vision of explainable AI, where low-level characteristics of thedeep learning process are combined with higher level schemes proper of thehuman argumentation capacity. ANTIDOTE will exploit cross-disciplinarycompetences in deep learning and argumentation to support a broader andinnovative view of explainable AI, where the need for high-quality explanationsfor clinical cases deliberation is critical. As a first result of the project,we publish the Antidote CasiMedicos dataset to facilitate research onexplainable AI in general, and argumentation in the medical domain inparticular.</description><author>Rodrigo Agerri, Iñigo Alonso, Aitziber Atutxa, Ander Berrondo, Ainara Estarrona, Iker Garcia-Ferrero, Iakes Goenaga, Koldo Gojenola, Maite Oronoz, Igor Perez-Tejedor, German Rigau, Anar Yeginbergenova</author><pubDate>Fri, 09 Jun 2023 17:50:02 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.06029v1</guid></item><item><title>Exploring Local Explanations of Nonlinear Models Using Animated Linear Projections</title><link>http://arxiv.org/abs/2205.05359v2</link><description>The increased predictive power of machine learning models comes at the costof increased complexity and loss of interpretability, particularly incomparison to parametric statistical models. This trade-off has led to theemergence of eXplainable AI (XAI) which provides methods, such as localexplanations (LEs) and local variable attributions (LVAs), to shed light on howa model use predictors to arrive at a prediction. These provide a pointestimate of the linear variable importance in the vicinity of a singleobservation. However, LVAs tend not to effectively handle association betweenpredictors. To understand how the interaction between predictors affects thevariable importance estimate, we can convert LVAs into linear projections anduse the radial tour. This is also useful for learning how a model has made amistake, or the effect of outliers, or the clustering of observations. Theapproach is illustrated with examples from categorical (penguin species,chocolate types) and quantitative (soccer/football salaries, house prices)response models. The methods are implemented in the R package cheem, availableon CRAN.</description><author>Nicholas Spyrison, Dianne Cook, Przemyslaw Biecek</author><pubDate>Fri, 09 Jun 2023 17:44:52 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2205.05359v2</guid></item><item><title>Self-Interpretable Time Series Prediction with Counterfactual Explanations</title><link>http://arxiv.org/abs/2306.06024v1</link><description>Interpretable time series prediction is crucial for safety-critical areassuch as healthcare and autonomous driving. Most existing methods focus oninterpreting predictions by assigning important scores to segments of timeseries. In this paper, we take a different and more challenging route and aimat developing a self-interpretable model, dubbed Counterfactual Time Series(CounTS), which generates counterfactual and actionable explanations for timeseries predictions. Specifically, we formalize the problem of time seriescounterfactual explanations, establish associated evaluation protocols, andpropose a variational Bayesian deep learning model equipped with counterfactualinference capability of time series abduction, action, and prediction. Comparedwith state-of-the-art baselines, our self-interpretable model can generatebetter counterfactual explanations while maintaining comparable predictionaccuracy.</description><author>Jingquan Yan, Hao Wang</author><pubDate>Fri, 09 Jun 2023 17:42:52 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.06024v1</guid></item><item><title>DetZero: Rethinking Offboard 3D Object Detection with Long-term Sequential Point Clouds</title><link>http://arxiv.org/abs/2306.06023v1</link><description>Existing offboard 3D detectors always follow a modular pipeline design totake advantage of unlimited sequential point clouds. We have found that thefull potential of offboard 3D detectors is not explored mainly due to tworeasons: (1) the onboard multi-object tracker cannot generate sufficientcomplete object trajectories, and (2) the motion state of objects poses aninevitable challenge for the object-centric refining stage in leveraging thelong-term temporal context representation. To tackle these problems, we proposea novel paradigm of offboard 3D object detection, named DetZero. Concretely, anoffline tracker coupled with a multi-frame detector is proposed to focus on thecompleteness of generated object tracks. An attention-mechanism refining moduleis proposed to strengthen contextual information interaction across long-termsequential point clouds for object refining with decomposed regression methods.Extensive experiments on Waymo Open Dataset show our DetZero outperforms allstate-of-the-art onboard and offboard 3D detection methods. Notably, DetZeroranks 1st place on Waymo 3D object detection leaderboard with 85.15 mAPH (L2)detection performance. Further experiments validate the application of takingthe place of human labels with such high-quality results. Our empirical studyleads to rethinking conventions and interesting findings that can guide futureresearch on offboard 3D object detection.</description><author>Tao Ma, Xuemeng Yang, Hongbin Zhou, Xin Li, Botian Shi, Junjie Liu, Yuchen Yang, Zhizheng Liu, Liang He, Yu Qiao, Yikang Li, Hongsheng Li</author><pubDate>Fri, 09 Jun 2023 17:42:00 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.06023v1</guid></item><item><title>A Dynamic Partial Computation Offloading for the Metaverse in In-Network Computing</title><link>http://arxiv.org/abs/2306.06022v1</link><description>The In-Network Computing (COIN) paradigm is a promising solution thatleverages unused network resources to perform some tasks to meet up withcomputation-demanding applications, such as metaverse. In this vein, weconsider the metaverse partial computation offloading problem for multiplesubtasks in a COIN environment to minimise energy consumption and delay whiledynamically adjusting the offloading policy based on the changing computationresources status. We prove that the problem is NP and thus transformed it intotwo subproblems: task splitting problem (TSP) on the user side and taskoffloading problem (TOP) on the COIN side. We modelled the TSP as an ordinalpotential game (OPG) and proposed a decentralised algorithm to obtain its NashEquilibrium (NE). Then, we model the TOP as Markov Decision Process (MDP)proposed double deep Q-network (DDQN) to solve for the optimal offloadingpolicy. Unlike the conventional DDQN algorithm, where intelligent agents sampleoffloading decisions randomly within a certain probability, our COIN agentexplores the NE of the TSP and the deep neural network. Finally, simulationresults show that our proposed model approach allows the COIN agent to updateits policies and make more informed decisions, leading to improved performanceover time compared to the traditional baseline.</description><author>Ibrahim Aliyu, Namseok Ko, Tai-Won Um, Jinsul Kim</author><pubDate>Fri, 09 Jun 2023 17:41:34 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.06022v1</guid></item><item><title>Deep Laplacian-based Options for Temporally-Extended Exploration</title><link>http://arxiv.org/abs/2301.11181v2</link><description>Selecting exploratory actions that generate a rich stream of experience forbetter learning is a fundamental challenge in reinforcement learning (RL). Anapproach to tackle this problem consists in selecting actions according tospecific policies for an extended period of time, also known as options. Arecent line of work to derive such exploratory options builds upon theeigenfunctions of the graph Laplacian. Importantly, until now these methodshave been mostly limited to tabular domains where (1) the graph Laplacianmatrix was either given or could be fully estimated, (2) performingeigendecomposition on this matrix was computationally tractable, and (3) valuefunctions could be learned exactly. Additionally, these methods required aseparate option discovery phase. These assumptions are fundamentally notscalable. In this paper we address these limitations and show how recentresults for directly approximating the eigenfunctions of the Laplacian can beleveraged to truly scale up options-based exploration. To do so, we introduce afully online deep RL algorithm for discovering Laplacian-based options andevaluate our approach on a variety of pixel-based tasks. We compare to severalstate-of-the-art exploration methods and show that our approach is effective,general, and especially promising in non-stationary settings.</description><author>Martin Klissarov, Marlos C. Machado</author><pubDate>Fri, 09 Jun 2023 17:33:08 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2301.11181v2</guid></item><item><title>Benchmarking self-supervised video representation learning</title><link>http://arxiv.org/abs/2306.06010v1</link><description>Self-supervised learning is an effective way for label-free modelpre-training, especially in the video domain where labeling is expensive.Existing self-supervised works in the video domain use varying experimentalsetups to demonstrate their effectiveness and comparison across approachesbecomes challenging with no standard benchmark. In this work, we first providea benchmark that enables a comparison of existing approaches on the sameground. Next, we study five different aspects of self-supervised learningimportant for videos; 1) dataset size, 2) complexity, 3) data distribution, 4)data noise, and, 5)feature analysis. To facilitate this study, we focus onseven different methods along with seven different network architectures andperform an extensive set of experiments on 5 different datasets with anevaluation of two different downstream tasks. We present several interestinginsights from this study which span across different properties of pretrainingand target datasets, pretext-tasks, and model architectures among others. Wefurther put some of these insights to the real test and propose an approachthat requires a limited amount of training data and outperforms existingstate-of-the-art approaches which use 10x pretraining data. We believe thiswork will pave the way for researchers to a better understanding ofself-supervised pretext tasks in video representation learning.</description><author>Akash Kumar, Ashlesha Kumar, Vibhav Vineet, Yogesh Singh Rawat</author><pubDate>Fri, 09 Jun 2023 17:27:14 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.06010v1</guid></item><item><title>L0Learn: A Scalable Package for Sparse Learning using L0 Regularization</title><link>http://arxiv.org/abs/2202.04820v2</link><description>We present L0Learn: an open-source package for sparse linear regression andclassification using $\ell_0$ regularization. L0Learn implements scalable,approximate algorithms, based on coordinate descent and local combinatorialoptimization. The package is built using C++ and has user-friendly R and Pythoninterfaces. L0Learn can address problems with millions of features, achievingcompetitive run times and statistical performance with state-of-the-art sparselearning packages. L0Learn is available on both CRAN and GitHub(https://cran.r-project.org/package=L0Learn andhttps://github.com/hazimehh/L0Learn).</description><author>Hussein Hazimeh, Rahul Mazumder, Tim Nonet</author><pubDate>Fri, 09 Jun 2023 17:20:37 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2202.04820v2</guid></item><item><title>Interactive Explanations by Conflict Resolution via Argumentative Exchanges</title><link>http://arxiv.org/abs/2303.15022v2</link><description>As the field of explainable AI (XAI) is maturing, calls for interactiveexplanations for (the outputs of) AI models are growing, but thestate-of-the-art predominantly focuses on static explanations. In this paper,we focus instead on interactive explanations framed as conflict resolutionbetween agents (i.e. AI models and/or humans) by leveraging on computationalargumentation. Specifically, we define Argumentative eXchanges (AXs) fordynamically sharing, in multi-agent systems, information harboured inindividual agents' quantitative bipolar argumentation frameworks towardsresolving conflicts amongst the agents. We then deploy AXs in the XAI settingin which a machine and a human interact about the machine's predictions. Weidentify and assess several theoretical properties characterising AXs that aresuitable for XAI. Finally, we instantiate AXs for XAI by defining various agentbehaviours, e.g. capturing counterfactual patterns of reasoning in machines andhighlighting the effects of cognitive biases in humans. We show experimentally(in a simulated environment) the comparative advantages of these behaviours interms of conflict resolution, and show that the strongest argument may notalways be the most effective.</description><author>Antonio Rago, Hengzhi Li, Francesca Toni</author><pubDate>Fri, 09 Jun 2023 17:20:36 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2303.15022v2</guid></item><item><title>Causal Effect Estimation from Observational and Interventional Data Through Matrix Weighted Linear Estimators</title><link>http://arxiv.org/abs/2306.06002v1</link><description>We study causal effect estimation from a mixture of observational andinterventional data in a confounded linear regression model with multivariatetreatments. We show that the statistical efficiency in terms of expectedsquared error can be improved by combining estimators arising from both theobservational and interventional setting. To this end, we derive methods basedon matrix weighted linear estimators and prove that our methods areasymptotically unbiased in the infinite sample limit. This is an importantimprovement compared to the pooled estimator using the union of interventionaland observational data, for which the bias only vanishes if the ratio ofobservational to interventional data tends to zero. Studies on synthetic dataconfirm our theoretical findings. In settings where confounding is substantialand the ratio of observational to interventional data is large, our estimatorsoutperform a Stein-type estimator and various other baselines.</description><author>Klaus-Rudolf Kladny, Julius von Kügelgen, Bernhard Schölkopf, Michael Muehlebach</author><pubDate>Fri, 09 Jun 2023 17:16:53 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.06002v1</guid></item><item><title>S$^{3}$: Increasing GPU Utilization during Generative Inference for Higher Throughput</title><link>http://arxiv.org/abs/2306.06000v1</link><description>Generating texts with a large language model (LLM) consumes massive amountsof memory. Apart from the already-large model parameters, the key/value (KV)cache that holds information about previous tokens in a sequence can grow to beeven larger than the model itself. This problem is exacerbated in one of thecurrent LLM serving frameworks which reserves the maximum sequence length ofmemory for the KV cache to guarantee generating a complete sequence as they donot know the output sequence length. This restricts us to use a smaller batchsize leading to lower GPU utilization and above all, lower throughput. We arguethat designing a system with a priori knowledge of the output sequence canmitigate this problem. To this end, we propose S$^{3}$, which predicts theoutput sequence length, schedules generation queries based on the prediction toincrease device resource utilization and throughput, and handle mispredictions.Our proposed method achieves 6.49$\times$ throughput over those systems thatassume the worst case for the output sequence length.</description><author>Yunho Jin, Chun-Feng Wu, David Brooks, Gu-Yeon Wei</author><pubDate>Fri, 09 Jun 2023 17:13:43 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.06000v1</guid></item><item><title>COMCAT: Towards Efficient Compression and Customization of Attention-Based Vision Models</title><link>http://arxiv.org/abs/2305.17235v2</link><description>Attention-based vision models, such as Vision Transformer (ViT) and itsvariants, have shown promising performance in various computer vision tasks.However, these emerging architectures suffer from large model sizes and highcomputational costs, calling for efficient model compression solutions. Todate, pruning ViTs has been well studied, while other compression strategiesthat have been widely applied in CNN compression, e.g., model factorization, islittle explored in the context of ViT compression. This paper explores anefficient method for compressing vision transformers to enrich the toolset forobtaining compact attention-based vision models. Based on the new insight onthe multi-head attention layer, we develop a highly efficient ViT compressionsolution, which outperforms the state-of-the-art pruning methods. Forcompressing DeiT-small and DeiT-base models on ImageNet, our proposed approachcan achieve 0.45% and 0.76% higher top-1 accuracy even with fewer parameters.Our finding can also be applied to improve the customization efficiency oftext-to-image diffusion models, with much faster training (up to $2.6\times$speedup) and lower extra storage cost (up to $1927.5\times$ reduction) than theexisting works.</description><author>Jinqi Xiao, Miao Yin, Yu Gong, Xiao Zang, Jian Ren, Bo Yuan</author><pubDate>Fri, 09 Jun 2023 17:11:21 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.17235v2</guid></item><item><title>Distributed Consensus Algorithm for Decision-Making in Multi-agent Multi-armed Bandit</title><link>http://arxiv.org/abs/2306.05998v1</link><description>We study a structured multi-agent multi-armed bandit (MAMAB) problem in adynamic environment. A graph reflects the information-sharing structure amongagents, and the arms' reward distributions are piecewise-stationary withseveral unknown change points. The agents face the identicalpiecewise-stationary MAB problem. The goal is to develop a decision-makingpolicy for the agents that minimizes the regret, which is the expected totalloss of not playing the optimal arm at each time step. Our proposed solution,Restarted Bayesian Online Change Point Detection in Cooperative UpperConfidence Bound Algorithm (RBO-Coop-UCB), involves an efficient multi-agentUCB algorithm as its core enhanced with a Bayesian change point detector. Wealso develop a simple restart decision cooperation that improvesdecision-making. Theoretically, we establish that the expected group regret ofRBO-Coop-UCB is upper bounded by $\mathcal{O}(KNM\log T + K\sqrt{MT\log T})$,where K is the number of agents, M is the number of arms, and T is the numberof time steps. Numerical experiments on synthetic and real-world datasetsdemonstrate that our proposed method outperforms the state-of-the-artalgorithms.</description><author>Xiaotong Cheng, Setareh Maghsudi</author><pubDate>Fri, 09 Jun 2023 17:10:26 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.05998v1</guid></item><item><title>Automated Labeling of German Chest X-Ray Radiology Reports using Deep Learning</title><link>http://arxiv.org/abs/2306.05997v1</link><description>Radiologists are in short supply globally, and deep learning models offer apromising solution to address this shortage as part of clinicaldecision-support systems. However, training such models often requiresexpensive and time-consuming manual labeling of large datasets. Automatic labelextraction from radiology reports can reduce the time required to obtainlabeled datasets, but this task is challenging due to semantically similarwords and missing annotated data. In this work, we explore the potential ofweak supervision of a deep learning-based label prediction model, using arule-based labeler. We propose a deep learning-based CheXpert label predictionmodel, pre-trained on reports labeled by a rule-based German CheXpert model andfine-tuned on a small dataset of manually labeled reports. Our resultsdemonstrate the effectiveness of our approach, which significantly outperformedthe rule-based model on all three tasks. Our findings highlight the benefits ofemploying deep learning-based models even in scenarios with sparse data and theuse of the rule-based labeler as a tool for weak supervision.</description><author>Alessandro Wollek, Philip Haitzer, Thomas Sedlmeyr, Sardi Hyska, Johannes Rueckel, Bastian Sabel, Michael Ingrisch, Tobias Lasser</author><pubDate>Fri, 09 Jun 2023 17:08:35 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.05997v1</guid></item><item><title>adSformers: Personalization from Short-Term Sequences and Diversity of Representations in Etsy Ads</title><link>http://arxiv.org/abs/2302.01255v2</link><description>In this article, we present a general approach to personalizing ads throughencoding and learning from variable-length sequences of recent user actions anddiverse representations. To this end we introduce a three-component modulecalled the adSformer diversifiable personalization module (ADPM) that learns adynamic user representation. We illustrate the module's effectiveness andflexibility by personalizing the Click-Through Rate (CTR) and Post-ClickConversion Rate (PCCVR) models used in sponsored search. The first component ofthe ADPM, the adSformer encoder, includes a novel adSformer block which learnsthe most salient sequence signals. ADPM's second component enriches the learnedsignal through visual, multimodal, and other pretrained representations.Lastly, the third ADPM "learned on the fly" component further diversifies thesignal encoded in the dynamic user representation. The ADPM-personalized CTRand PCCVR models, henceforth referred to as adSformer CTR and adSformer PCCVR,outperform the CTR and PCCVR production baselines by $+2.66\%$ and $+2.42\%$,respectively, in offline Area Under the Receiver Operating Characteristic Curve(ROC-AUC). Following the robust online gains in A/B tests, Etsy Ads deployedthe ADPM-personalized sponsored search system to $100\%$ of traffic as ofFebruary 2023.</description><author>Alaa Awad, Denisa Roberts, Eden Dolev, Andrea Heyman, Zahra Ebrahimzadeh, Zoe Weil, Marcin Mejran, Vaibhav Malpani, Mahir Yavuz</author><pubDate>Fri, 09 Jun 2023 17:05:12 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2302.01255v2</guid></item><item><title>Approximate information state based convergence analysis of recurrent Q-learning</title><link>http://arxiv.org/abs/2306.05991v1</link><description>In spite of the large literature on reinforcement learning (RL) algorithmsfor partially observable Markov decision processes (POMDPs), a completetheoretical understanding is still lacking. In a partially observable setting,the history of data available to the agent increases over time so mostpractical algorithms either truncate the history to a finite window or compressit using a recurrent neural network leading to an agent state that isnon-Markovian. In this paper, it is shown that in spite of the lack of theMarkov property, recurrent Q-learning (RQL) converges in the tabular setting.Moreover, it is shown that the quality of the converged limit depends on thequality of the representation which is quantified in terms of what is known asan approximate information state (AIS). Based on this characterization of theapproximation error, a variant of RQL with AIS losses is presented. Thisvariant performs better than a strong baseline for RQL that does not use AISlosses. It is demonstrated that there is a strong correlation between theperformance of RQL over time and the loss associated with the AISrepresentation.</description><author>Erfan Seyedsalehi, Nima Akbarzadeh, Amit Sinha, Aditya Mahajan</author><pubDate>Fri, 09 Jun 2023 16:59:39 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.05991v1</guid></item><item><title>Quartile-Based Seasonality Decomposition for Time Series Forecasting and Anomaly Detection</title><link>http://arxiv.org/abs/2306.05989v1</link><description>The timely detection of anomalies is essential in the telecom domain as itfacilitates the identification and characterization of irregular patterns,abnormal behaviors, and network anomalies, contributing to enhanced servicequality and operational efficiency. Precisely forecasting and eliminatingpredictable time series patterns constitutes a vital component of time seriesanomaly detection. While the state-of-the-art methods aim to maximizeforecasting accuracy, the computational performance takes a hit. In a systemcomposed of a large number of time series variables, e.g., cell Key PerformanceIndicators (KPIs), the time and space complexity of the forecasting employed isof crucial importance. Quartile-Based Seasonality Decomposition (QBSD) is alive forecasting method proposed in this paper to make an optimal trade-offbetween computational complexity and forecasting accuracy. This paper comparesthe performance of QBSD to the state-of-the-art forecasting methods and theirapplicability to practical anomaly detection. To demonstrate the efficacy ofthe proposed solution, experimental evaluation was conducted using publiclyavailable datasets as well as a telecom KPI dataset.</description><author>Ebenezer RHP Isaac, Bulbul Singh</author><pubDate>Fri, 09 Jun 2023 16:59:27 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.05989v1</guid></item><item><title>How to Unleash the Power of Large Language Models for Few-shot Relation Extraction?</title><link>http://arxiv.org/abs/2305.01555v4</link><description>Scaling language models have revolutionized widespread NLP tasks, yet littlecomprehensively explored few-shot relation extraction with large languagemodels. In this paper, we investigate principal methodologies, in-contextlearning and data generation, for few-shot relation extraction via GPT-3.5through exhaustive experiments. To enhance few-shot performance, we furtherpropose task-related instructions and schema-constrained data generation. Weobserve that in-context learning can achieve performance on par with previousprompt learning approaches, and data generation with the large language modelcan boost previous solutions to obtain new state-of-the-art few-shot results onfour widely-studied relation extraction datasets. We hope our work can inspirefuture research for the capabilities of large language models in few-shotrelation extraction. Code is available inhttps://github.com/zjunlp/DeepKE/tree/main/example/llm.</description><author>Xin Xu, Yuqi Zhu, Xiaohan Wang, Ningyu Zhang</author><pubDate>Fri, 09 Jun 2023 16:59:18 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.01555v4</guid></item><item><title>Agent market orders representation through a contrastive learning approach</title><link>http://arxiv.org/abs/2306.05987v1</link><description>Due to the access to the labeled orders on the CAC40 data from Euronext, weare able to analyse agents' behaviours in the market based on their placedorders. In this study, we construct a self-supervised learning model usingtriplet loss to effectively learn the representation of agent market orders. Byacquiring this learned representation, various downstream tasks becomefeasible. In this work, we utilise the K-means clustering algorithm on thelearned representation vectors of agent orders to identify distinct behaviourtypes within each cluster.</description><author>Ruihua Ruan, Emmanuel Bacry, Jean-François Muzy</author><pubDate>Fri, 09 Jun 2023 16:56:06 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.05987v1</guid></item><item><title>Automatic Change-Point Detection in Time Series via Deep Learning</title><link>http://arxiv.org/abs/2211.03860v2</link><description>Detecting change-points in data is challenging because of the range ofpossible types of change and types of behaviour of data when there is nochange. Statistically efficient methods for detecting a change will depend onboth of these features, and it can be difficult for a practitioner to developan appropriate detection method for their application of interest. We show howto automatically generate new offline detection methods based on training aneural network. Our approach is motivated by many existing tests for thepresence of a change-point being representable by a simple neural network, andthus a neural network trained with sufficient data should have performance atleast as good as these methods. We present theory that quantifies the errorrate for such an approach, and how it depends on the amount of training data.Empirical results show that, even with limited training data, its performanceis competitive with the standard CUSUM-based classifier for detecting a changein mean when the noise is independent and Gaussian, and can substantiallyoutperform it in the presence of auto-correlated or heavy-tailed noise. Ourmethod also shows strong results in detecting and localising changes inactivity based on accelerometer data.</description><author>Jie Li, Paul Fearnhead, Piotr Fryzlewicz, Tengyao Wang</author><pubDate>Fri, 09 Jun 2023 16:55:11 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2211.03860v2</guid></item><item><title>10 Security and Privacy Problems in Large Foundation Models</title><link>http://arxiv.org/abs/2110.15444v3</link><description>Foundation models--such as GPT, CLIP, and DINO--have achieved revolutionaryprogress in the past several years and are commonly believed to be a promisingapproach for general-purpose AI. In particular, self-supervised learning isadopted to pre-train a foundation model using a large amount of unlabeled data.A pre-trained foundation model is like an ``operating system'' of the AIecosystem. Specifically, a foundation model can be used as a feature extractorfor many downstream tasks with little or no labeled training data. Existingstudies on foundation models mainly focused on pre-training a better foundationmodel to improve its performance on downstream tasks in non-adversarialsettings, leaving its security and privacy in adversarial settings largelyunexplored. A security or privacy issue of a pre-trained foundation model leadsto a single point of failure for the AI ecosystem. In this book chapter, wediscuss 10 basic security and privacy problems for the pre-trained foundationmodels, including six confidentiality problems, three integrity problems, andone availability problem. For each problem, we discuss potential opportunitiesand challenges. We hope our book chapter will inspire future research on thesecurity and privacy of foundation models.</description><author>Jinyuan Jia, Hongbin Liu, Neil Zhenqiang Gong</author><pubDate>Fri, 09 Jun 2023 16:53:54 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2110.15444v3</guid></item><item><title>Beyond Detection: Visual Realism Assessment of Deepfakes</title><link>http://arxiv.org/abs/2306.05985v1</link><description>In the era of rapid digitalization and artificial intelligence advancements,the development of DeepFake technology has posed significant security andprivacy concerns. This paper presents an effective measure to assess the visualrealism of DeepFake videos. We utilize an ensemble of two Convolutional NeuralNetwork (CNN) models: Eva and ConvNext. These models have been trained on theDeepFake Game Competition (DFGC) 2022 dataset and aim to predict Mean OpinionScores (MOS) from DeepFake videos based on features extracted from sequences offrames. Our method secured the third place in the recent DFGC on Visual RealismAssessment held in conjunction with the 2023 International Joint Conference onBiometrics (IJCB 2023). We provide an over\-view of the models, datapreprocessing, and training procedures. We also report the performance of ourmodels against the competition's baseline model and discuss the implications ofour findings.</description><author>Luka Dragar, Peter Peer, Vitomir Štruc, Borut Batagelj</author><pubDate>Fri, 09 Jun 2023 16:53:01 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.05985v1</guid></item><item><title>Federated Learning for Medical Image Analysis: A Survey</title><link>http://arxiv.org/abs/2306.05980v1</link><description>Machine learning in medical imaging often faces a fundamental dilemma, namelythe small sample size problem. Many recent studies suggest using multi-domaindata pooled from different acquisition sites/datasets to improve statisticalpower. However, medical images from different sites cannot be easily shared tobuild large datasets for model training due to privacy protection reasons. As apromising solution, federated learning, which enables collaborative training ofmachine learning models based on data from different sites without cross-sitedata sharing, has attracted considerable attention recently. In this paper, weconduct a comprehensive survey of the recent development of federated learningmethods in medical image analysis. We first introduce the background andmotivation of federated learning for dealing with privacy protection andcollaborative learning issues in medical imaging. We then present acomprehensive review of recent advances in federated learning methods formedical image analysis. Specifically, existing methods are categorized based onthree critical aspects of a federated learning system, including client end,server end, and communication techniques. In each category, we summarize theexisting federated learning methods according to specific research problems inmedical image analysis and also provide insights into the motivations ofdifferent approaches. In addition, we provide a review of existing benchmarkmedical imaging datasets and software platforms for current federated learningresearch. We also conduct an experimental study to empirically evaluate typicalfederated learning methods for medical image analysis. This survey can help tobetter understand the current research status, challenges and potentialresearch opportunities in this promising research field.</description><author>Hao Guan, Mingxia Liu</author><pubDate>Fri, 09 Jun 2023 16:46:42 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.05980v1</guid></item><item><title>3D objects and scenes classification, recognition, segmentation, and reconstruction using 3D point cloud data: A review</title><link>http://arxiv.org/abs/2306.05978v1</link><description>Three-dimensional (3D) point cloud analysis has become one of the attractivesubjects in realistic imaging and machine visions due to its simplicity,flexibility and powerful capacity of visualization. Actually, therepresentation of scenes and buildings using 3D shapes and formats leveragedmany applications among which automatic driving, scenes and objectsreconstruction, etc. Nevertheless, working with this emerging type of data hasbeen a challenging task for objects representation, scenes recognition,segmentation, and reconstruction. In this regard, a significant effort hasrecently been devoted to developing novel strategies, using differenttechniques such as deep learning models. To that end, we present in this papera comprehensive review of existing tasks on 3D point cloud: a well-definedtaxonomy of existing techniques is performed based on the nature of the adoptedalgorithms, application scenarios, and main objectives. Various tasks performedon 3D point could data are investigated, including objects and scenesdetection, recognition, segmentation and reconstruction. In addition, weintroduce a list of used datasets, we discuss respective evaluation metrics andwe compare the performance of existing solutions to better inform thestate-of-the-art and identify their limitations and strengths. Lastly, weelaborate on current challenges facing the subject of technology and futuretrends attracting considerable interest, which could be a starting point forupcoming research studies</description><author>Omar Elharrouss, Kawther Hassine, Ayman Zayyan, Zakariyae Chatri, Noor almaadeed, Somaya Al-Maadeed, Khalid Abualsaud</author><pubDate>Fri, 09 Jun 2023 16:45:23 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.05978v1</guid></item><item><title>A memory-efficient neural ODE framework based on high-level adjoint differentiation</title><link>http://arxiv.org/abs/2206.01298v3</link><description>Neural ordinary differential equations (neural ODEs) have emerged as a novelnetwork architecture that bridges dynamical systems and deep learning. However,the gradient obtained with the continuous adjoint method in the vanilla neuralODE is not reverse-accurate. Other approaches suffer either from an excessivememory requirement due to deep computational graphs or from limited choices forthe time integration scheme, hampering their application to large-scale complexdynamical systems. To achieve accurate gradients without compromising memoryefficiency and flexibility, we present a new neural ODE framework, PNODE, basedon high-level discrete adjoint algorithmic differentiation. By leveragingdiscrete adjoint time integrators and advanced checkpointing strategiestailored for these integrators, PNODE can provide a balance between memory andcomputational costs, while computing the gradients consistently and accurately.We provide an open-source implementation based on PyTorch and PETSc, one of themost commonly used portable, scalable scientific computing libraries. Wedemonstrate the performance through extensive numerical experiments on imageclassification and continuous normalizing flow problems. We show that PNODEachieves the highest memory efficiency when compared with otherreverse-accurate methods. On the image classification problems, PNODE is up totwo times faster than the vanilla neural ODE and up to 2.3 times faster thanthe best existing reverse-accurate method. We also show that PNODE enables theuse of the implicit time integration methods that are needed for stiffdynamical systems.</description><author>Hong Zhang, Wenjun Zhao</author><pubDate>Fri, 09 Jun 2023 16:43:27 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2206.01298v3</guid></item><item><title>Unsupervised Discontinuous Constituency Parsing with Mildly Context-Sensitive Grammars</title><link>http://arxiv.org/abs/2212.09140v2</link><description>We study grammar induction with mildly context-sensitive grammars forunsupervised discontinuous parsing. Using the probabilistic linear context-freerewriting system (LCFRS) formalism, our approach fixes the rule structure inadvance and focuses on parameter learning with maximum likelihood. To reducethe computational complexity of both parsing and parameter estimation, werestrict the grammar formalism to LCFRS-2 (i.e., binary LCFRS with fan-out two)and further discard rules that require O(n^6) time to parse, reducing inferenceto O(n^5). We find that using a large number of nonterminals is beneficial andthus make use of tensor decomposition-based rank-space dynamic programming withan embedding-based parameterization of rule probabilities to scale up thenumber of nonterminals. Experiments on German and Dutch show that our approachis able to induce linguistically meaningful trees with continuous anddiscontinuous structures</description><author>Songlin Yang, Roger P. Levy, Yoon Kim</author><pubDate>Fri, 09 Jun 2023 16:42:50 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2212.09140v2</guid></item><item><title>Query Rewriting with Disjunctive Existential Rules and Mappings</title><link>http://arxiv.org/abs/2306.05973v1</link><description>We consider the issue of answering unions of conjunctive queries (UCQs) withdisjunctive existential rules and mappings. While this issue has already beenwell studied from a chase perspective, query rewriting within UCQs has hardlybeen addressed yet. We first propose a sound and complete query rewritingoperator, which has the advantage of establishing a tight relationship betweena chase step and a rewriting step. The associated breadth-first query rewritingalgorithm outputs a minimal UCQ-rewriting when one exists. Second, we show thatfor any ``truly disjunctive'' nonrecursive rule, there exists a conjunctivequery that has no UCQ-rewriting. It follows that the notion of finiteunification sets (fus), which denotes sets of existential rules such that anyUCQ admits a UCQ-rewriting, seems to have little relevance in this setting.Finally, turning our attention to mappings, we show that the problem ofdetermining whether a UCQ admits a UCQ-rewriting through a disjunctive mappingis undecidable. We conclude with a number of open problems.</description><author>Michel Leclère, Marie-Laure Mugnier, Guillaume Pérution-Kihli</author><pubDate>Fri, 09 Jun 2023 16:37:24 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.05973v1</guid></item><item><title>Language Models Can Learn Exceptions to Syntactic Rules</title><link>http://arxiv.org/abs/2306.05969v1</link><description>Artificial neural networks can generalize productively to novel contexts. Canthey also learn exceptions to those productive rules? We explore this questionusing the case of restrictions on English passivization (e.g., the fact that"The vacation lasted five days" is grammatical, but "*Five days was lasted bythe vacation" is not). We collect human acceptability judgments for passivesentences with a range of verbs, and show that the probability distributiondefined by GPT-2, a language model, matches the human judgments with highcorrelation. We also show that the relative acceptability of a verb in theactive vs. passive voice is positively correlated with the relative frequencyof its occurrence in those voices. These results provide preliminary supportfor the entrenchment hypothesis, according to which learners track and uses thedistributional properties of their input to learn negative exceptions to rules.At the same time, this hypothesis fails to explain the magnitude ofunpassivizability demonstrated by certain individual verbs, suggesting thatother cues to exceptionality are available in the linguistic input.</description><author>Cara Su-Yi Leong, Tal Linzen</author><pubDate>Fri, 09 Jun 2023 16:35:11 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.05969v1</guid></item><item><title>Automating Model Comparison in Factor Graphs</title><link>http://arxiv.org/abs/2306.05965v1</link><description>Bayesian state and parameter estimation have been automated effectively inthe literature, however, this has not yet been the case for model comparison,which therefore still requires error-prone and time-consuming manualderivations. As a result, model comparison is often overlooked and ignored,despite its importance. This paper efficiently automates Bayesian modelaveraging, selection, and combination by message passing on a Forney-stylefactor graph with a custom mixture node. Parameter and state inference, andmodel comparison can then be executed simultaneously using message passing withscale factors. This approach shortens the model design cycle and allows for thestraightforward extension to hierarchical and temporal model priors toaccommodate for modeling complicated time-varying processes.</description><author>Bart van Erp, Wouter W. L. Nuijten, Thijs van de Laar, Bert de Vries</author><pubDate>Fri, 09 Jun 2023 16:33:30 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.05965v1</guid></item><item><title>Adaptive Contextual Perception: How to Generalize to New Backgrounds and Ambiguous Objects</title><link>http://arxiv.org/abs/2306.05963v1</link><description>Biological vision systems make adaptive use of context to recognize objectsin new settings with novel contexts as well as occluded or blurry objects infamiliar settings. In this paper, we investigate how vision models adaptivelyuse context for out-of-distribution (OOD) generalization and leverage ouranalysis results to improve model OOD generalization. First, we formulate twodistinct OOD settings where the contexts are either irrelevant(Background-Invariance) or beneficial (Object-Disambiguation), reflecting thediverse contextual challenges faced in biological vision. We then analyze modelperformance in these two different OOD settings and demonstrate that modelsthat excel in one setting tend to struggle in the other. Notably, prior workson learning causal features improve on one setting but hurt in the other. Thisunderscores the importance of generalizing across both OOD settings, as thisability is crucial for both human cognition and robust AI systems. Next, tobetter understand the model properties contributing to OOD generalization, weuse representational geometry analysis and our own probing methods to examine apopulation of models, and we discover that those with more factorizedrepresentations and appropriate feature weighting are more successful inhandling Background-Invariance and Object-Disambiguation tests. We furthervalidate these findings through causal intervention on representationfactorization and feature weighting to demonstrate their causal effect onperformance. Lastly, we propose new augmentation methods to enhance modelgeneralization. These methods outperform strong baselines, yieldingimprovements in both in-distribution and OOD tests. In conclusion, to replicatethe generalization abilities of biological vision, computer vision models musthave factorized object vs. background representations and appropriately weightboth kinds of features.</description><author>Zhuofan Ying, Peter Hase, Mohit Bansal</author><pubDate>Fri, 09 Jun 2023 16:29:54 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.05963v1</guid></item><item><title>Recognize Anything: A Strong Image Tagging Model</title><link>http://arxiv.org/abs/2306.03514v3</link><description>We present the Recognize Anything Model (RAM): a strong foundation model forimage tagging. RAM makes a substantial step for large models in computervision, demonstrating the zero-shot ability to recognize any common categorywith high accuracy. RAM introduces a new paradigm for image tagging, leveraginglarge-scale image-text pairs for training instead of manual annotations. The development of RAM comprises four key steps. Firstly, annotation-freeimage tags are obtained at scale through automatic text semantic parsing.Subsequently, a preliminary model is trained for automatic annotation byunifying the caption and tagging tasks, supervised by the original texts andparsed tags, respectively. Thirdly, a data engine is employed to generateadditional annotations and clean incorrect ones. Lastly, the model is retrainedwith the processed data and fine-tuned using a smaller but higher-qualitydataset. We evaluate the tagging capabilities of RAM on numerous benchmarks andobserve impressive zero-shot performance, significantly outperforming CLIP andBLIP. Remarkably, RAM even surpasses the fully supervised manners and exhibitscompetitive performance with the Google tagging API. We are releasing the RAMat \url{https://recognize-anything.github.io/} to foster the advancements oflarge models in computer vision.</description><author>Youcai Zhang, Xinyu Huang, Jinyu Ma, Zhaoyang Li, Zhaochuan Luo, Yanchun Xie, Yuzhuo Qin, Tong Luo, Yaqian Li, Shilong Liu, Yandong Guo, Lei Zhang</author><pubDate>Fri, 09 Jun 2023 16:21:06 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.03514v3</guid></item><item><title>DDLP: Unsupervised Object-Centric Video Prediction with Deep Dynamic Latent Particles</title><link>http://arxiv.org/abs/2306.05957v1</link><description>We propose a new object-centric video prediction algorithm based on the deeplatent particle (DLP) representation. In comparison to existing slot- orpatch-based representations, DLPs model the scene using a set of keypoints withlearned parameters for properties such as position and size, and are bothefficient and interpretable. Our method, deep dynamic latent particles (DDLP),yields state-of-the-art object-centric video prediction results on severalchallenging datasets. The interpretable nature of DDLP allows us to perform``what-if'' generation -- predict the consequence of changing properties ofobjects in the initial frames, and DLP's compact structure enables efficientdiffusion-based unconditional video generation. Videos, code and pre-trainedmodels are available: https://taldatech.github.io/ddlp-web</description><author>Tal Daniel, Aviv Tamar</author><pubDate>Fri, 09 Jun 2023 16:17:13 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.05957v1</guid></item><item><title>Distributed Task Management in Fog Computing: A Socially Concave Bandit Game</title><link>http://arxiv.org/abs/2203.14572v2</link><description>Fog computing leverages the task offloading capabilities at the network'sedge to improve efficiency and enable swift responses to application demands.However, the design of task allocation strategies in a fog computing network isstill challenging because of the heterogeneity of fog nodes and uncertaintiesin system dynamics. We formulate the distributed task allocation problem as asocial-concave game with bandit feedback and show that the game has a uniqueNash equilibrium, which is implementable using no-regret learning strategies(regret with sublinear growth). We then develop two no-regret onlinedecision-making strategies. One strategy, namely bandit gradient ascent withmomentum, is an online convex optimization algorithm with bandit feedback. Theother strategy, Lipschitz bandit with initialization, is an EXP3 multi-armedbandit algorithm. We establish regret bounds for both strategies and analyzetheir convergence characteristics. Moreover, we compare the proposed strategieswith an allocation strategy named learning with linear rewards. Theoretical-and numerical analysis shows the superior performance of the proposedstrategies for efficient task allocation compared to the state-of-the-artmethods.</description><author>Xiaotong Cheng, Setareh Maghsudi</author><pubDate>Fri, 09 Jun 2023 16:15:14 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2203.14572v2</guid></item><item><title>Path Neural Networks: Expressive and Accurate Graph Neural Networks</title><link>http://arxiv.org/abs/2306.05955v1</link><description>Graph neural networks (GNNs) have recently become the standard approach forlearning with graph-structured data. Prior work has shed light into theirpotential, but also their limitations. Unfortunately, it was shown thatstandard GNNs are limited in their expressive power. These models are no morepowerful than the 1-dimensional Weisfeiler-Leman (1-WL) algorithm in terms ofdistinguishing non-isomorphic graphs. In this paper, we propose Path NeuralNetworks (PathNNs), a model that updates node representations by aggregatingpaths emanating from nodes. We derive three different variants of the PathNNmodel that aggregate single shortest paths, all shortest paths and all simplepaths of length up to K. We prove that two of these variants are strictly morepowerful than the 1-WL algorithm, and we experimentally validate ourtheoretical results. We find that PathNNs can distinguish pairs ofnon-isomorphic graphs that are indistinguishable by 1-WL, while our mostexpressive PathNN variant can even distinguish between 3-WL indistinguishablegraphs. The different PathNN variants are also evaluated on graphclassification and graph regression datasets, where in most cases, theyoutperform the baseline methods.</description><author>Gaspard Michel, Giannis Nikolentzos, Johannes Lutzeyer, Michalis Vazirgiannis</author><pubDate>Fri, 09 Jun 2023 16:11:49 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.05955v1</guid></item><item><title>Overcoming Adversarial Attacks for Human-in-the-Loop Applications</title><link>http://arxiv.org/abs/2306.05952v1</link><description>Including human analysis has the potential to positively affect therobustness of Deep Neural Networks and is relatively unexplored in theAdversarial Machine Learning literature. Neural network visual explanation mapshave been shown to be prone to adversarial attacks. Further research is neededin order to select robust visualizations of explanations for the image analystto evaluate a given model. These factors greatly impact Human-In-The-Loop(HITL) evaluation tools due to their reliance on adversarial images, includingexplanation maps and measurements of robustness. We believe models of humanvisual attention may improve interpretability and robustness of human-machineimagery analysis systems. Our challenge remains, how can HITL evaluation berobust in this adversarial landscape?</description><author>Ryan McCoppin, Marla Kennedy, Platon Lukyanenko, Sean Kennedy</author><pubDate>Fri, 09 Jun 2023 16:09:16 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.05952v1</guid></item><item><title>Unsupervised Video Domain Adaptation for Action Recognition: A Disentanglement Perspective</title><link>http://arxiv.org/abs/2208.07365v2</link><description>Unsupervised video domain adaptation is a practical yet challenging task. Inthis work, for the first time, we tackle it from a disentanglement view. Ourkey idea is to handle the spatial and temporal domain divergence separatelythrough disentanglement. Specifically, we consider the generation ofcross-domain videos from two sets of latent factors, one encoding the staticinformation and another encoding the dynamic information. A Transfer SequentialVAE (TranSVAE) framework is then developed to model such generation. To betterserve for adaptation, we propose several objectives to constrain the latentfactors. With these constraints, the spatial divergence can be readily removedby disentangling the static domain-specific information out, and the temporaldivergence is further reduced from both frame- and video-levels throughadversarial learning. Extensive experiments on the UCF-HMDB, Jester, andEpic-Kitchens datasets verify the effectiveness and superiority of TranSVAEcompared with several state-of-the-art methods. The code with reproducibleresults is publicly accessible.</description><author>Pengfei Wei, Lingdong Kong, Xinghua Qu, Yi Ren, Zhiqiang Xu, Jing Jiang, Xiang Yin</author><pubDate>Fri, 09 Jun 2023 16:06:02 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2208.07365v2</guid></item><item><title>Prediction of Transportation Index for Urban Patterns in Small and Medium-sized Indian Cities using Hybrid RidgeGAN Model</title><link>http://arxiv.org/abs/2306.05951v1</link><description>The rapid urbanization trend in most developing countries including India iscreating a plethora of civic concerns such as loss of green space, degradationof environmental health, clean water availability, air pollution, trafficcongestion leading to delays in vehicular transportation, etc. Transportationand network modeling through transportation indices have been widely used tounderstand transportation problems in the recent past. This necessitatespredicting transportation indices to facilitate sustainable urban planning andtraffic management. Recent advancements in deep learning research, inparticular, Generative Adversarial Networks (GANs), and their modifications inspatial data analysis such as CityGAN, Conditional GAN, and MetroGAN haveenabled urban planners to simulate hyper-realistic urban patterns. Thesesynthetic urban universes mimic global urban patterns and evaluating theirlandscape structures through spatial pattern analysis can aid in comprehendinglandscape dynamics, thereby enhancing sustainable urban planning. This researchaddresses several challenges in predicting the urban transportation index forsmall and medium-sized Indian cities. A hybrid framework based on Kernel RidgeRegression (KRR) and CityGAN is introduced to predict transportation indexusing spatial indicators of human settlement patterns. This paper establishes arelationship between the transportation index and human settlement indicatorsand models it using KRR for the selected 503 Indian cities. The proposed hybridpipeline, we call it RidgeGAN model, can evaluate the sustainability of urbansprawl associated with infrastructure development and transportation systems insprawling cities. Experimental results show that the two-step pipeline approachoutperforms existing benchmarks based on spatial and statistical measures.</description><author>Rahisha Thottolil, Uttam Kumar, Tanujit Chakraborty</author><pubDate>Fri, 09 Jun 2023 16:05:40 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.05951v1</guid></item><item><title>Evaluating the Social Impact of Generative AI Systems in Systems and Society</title><link>http://arxiv.org/abs/2306.05949v1</link><description>Generative AI systems across modalities, ranging from text, image, audio, andvideo, have broad social impacts, but there exists no official standard formeans of evaluating those impacts and which impacts should be evaluated. Wemove toward a standard approach in evaluating a generative AI system for anymodality, in two overarching categories: what is able to be evaluated in a basesystem that has no predetermined application and what is able to be evaluatedin society. We describe specific social impact categories and how to approachand conduct evaluations in the base technical system, then in people andsociety. Our framework for a base system defines seven categories of socialimpact: bias, stereotypes, and representational harms; cultural values andsensitive content; disparate performance; privacy and data protection;financial costs; environmental costs; and data and content moderation laborcosts. Suggested methods for evaluation apply to all modalities and analyses ofthe limitations of existing evaluations serve as a starting point for necessaryinvestment in future evaluations. We offer five overarching categories for whatis able to be evaluated in society, each with their own subcategories:trustworthiness and autonomy; inequality, marginalization, and violence;concentration of authority; labor and creativity; and ecosystem andenvironment. Each subcategory includes recommendations for mitigating harm. Weare concurrently crafting an evaluation repository for the AI researchcommunity to contribute existing evaluations along the given categories. Thisversion will be updated following a CRAFT session at ACM FAccT 2023.</description><author>Irene Solaiman, Zeerak Talat, William Agnew, Lama Ahmad, Dylan Baker, Su Lin Blodgett, Hal Daumé III, Jesse Dodge, Ellie Evans, Sara Hooker, Yacine Jernite, Alexandra Sasha Luccioni, Alberto Lusoli, Margaret Mitchell, Jessica Newman, Marie-Therese Png, Andrew Strait, Apostol Vassilev</author><pubDate>Fri, 09 Jun 2023 16:05:13 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.05949v1</guid></item><item><title>Reading Between the Lines: Modeling User Behavior and Costs in AI-Assisted Programming</title><link>http://arxiv.org/abs/2210.14306v4</link><description>Code-recommendation systems, such as Copilot and CodeWhisperer, have thepotential to improve programmer productivity by suggesting and auto-completingcode. However, to fully realize their potential, we must understand howprogrammers interact with these systems and identify ways to improve thatinteraction. To make progress, we studied GitHub Copilot, a code-recommendationsystem used by millions of programmers daily. We developed CUPS, a taxonomy ofcommon programmer activities when interacting with Copilot. Our study of 21programmers, who completed coding tasks and retrospectively labeled theirsessions with CUPS, showed that CUPS can help us understand how programmersinteract with code-recommendation systems, revealing inefficiencies and timecosts. Our insights reveal how programmers interact with Copilot and motivatenew interface designs and metrics.</description><author>Hussein Mozannar, Gagan Bansal, Adam Fourney, Eric Horvitz</author><pubDate>Fri, 09 Jun 2023 16:03:06 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2210.14306v4</guid></item><item><title>Improving Estimation of the Koopman Operator with Kolmogorov-Smirnov Indicator Functions</title><link>http://arxiv.org/abs/2306.05945v1</link><description>It has become common to perform kinetic analysis using approximate Koopmanoperators that transforms high-dimensional time series of observables intoranked dynamical modes. Key to a practical success of the approach is theidentification of a set of observables which form a good basis in which toexpand the slow relaxation modes. Good observables are, however, difficult toidentify {\em a priori} and sub-optimal choices can lead to significantunderestimations of characteristic timescales. Leveraging the representation ofslow dynamics in terms of Hidden Markov Model (HMM), we propose a simple andcomputationally efficient clustering procedure to infer surrogate observablesthat form a good basis for slow modes. We apply the approach to an analyticallysolvable model system, as well as on three protein systems of differentcomplexities. We consistently demonstrate that the inferred indicator functionscan significantly improve the estimation of the leading eigenvalues of theKoopman operators and correctly identify key states and transition timescalesof stochastic systems, even when good observables are not known {\em a priori}.</description><author>Van A. Ngo, Yen Ting Lin, Danny Perez</author><pubDate>Fri, 09 Jun 2023 16:01:43 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.05945v1</guid></item><item><title>Robust Data-driven Prescriptiveness Optimization</title><link>http://arxiv.org/abs/2306.05937v1</link><description>The abundance of data has led to the emergence of a variety of optimizationtechniques that attempt to leverage available side information to provide moreanticipative decisions. The wide range of methods and contexts of applicationhave motivated the design of a universal unitless measure of performance knownas the coefficient of prescriptiveness. This coefficient was designed toquantify both the quality of contextual decisions compared to a reference oneand the prescriptive power of side information. To identify policies thatmaximize the former in a data-driven context, this paper introduces adistributionally robust contextual optimization model where the coefficient ofprescriptiveness substitutes for the classical empirical risk minimizationobjective. We present a bisection algorithm to solve this model, which relieson solving a series of linear programs when the distributional ambiguity sethas an appropriate nested form and polyhedral structure. Studying a contextualshortest path problem, we evaluate the robustness of the resulting policiesagainst alternative methods when the out-of-sample dataset is subject tovarying amounts of distribution shift.</description><author>Mehran Poursoltani, Erick Delage, Angelos Georghiou</author><pubDate>Fri, 09 Jun 2023 15:56:06 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.05937v1</guid></item><item><title>Revisiting Weighted Aggregation in Federated Learning with Neural Networks</title><link>http://arxiv.org/abs/2302.10911v3</link><description>In federated learning (FL), weighted aggregation of local models is conductedto generate a global model, and the aggregation weights are normalized (the sumof weights is 1) and proportional to the local data sizes. In this paper, werevisit the weighted aggregation process and gain new insights into thetraining dynamics of FL. First, we find that the sum of weights can be smallerthan 1, causing global weight shrinking effect (analogous to weight decay) andimproving generalization. We explore how the optimal shrinking factor isaffected by clients' data heterogeneity and local epochs. Second, we dive intothe relative aggregation weights among clients to depict the clients'importance. We develop client coherence to study the learning dynamics and finda critical point that exists. Before entering the critical point, more coherentclients play more essential roles in generalization. Based on the aboveinsights, we propose an effective method for Federated Learning with LearnableAggregation Weights, named as FedLAW. Extensive experiments verify that ourmethod can improve the generalization of the global model by a large margin ondifferent datasets and models.</description><author>Zexi Li, Tao Lin, Xinyi Shang, Chao Wu</author><pubDate>Fri, 09 Jun 2023 15:49:41 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2302.10911v3</guid></item><item><title>EmotionNAS: Two-stream Neural Architecture Search for Speech Emotion Recognition</title><link>http://arxiv.org/abs/2203.13617v2</link><description>Speech emotion recognition (SER) is an important research topic inhuman-computer interaction. Existing works mainly rely on human expertise todesign models. Despite their success, different datasets often require distinctstructures and hyperparameters. Searching for an optimal model for each datasetis time-consuming and labor-intensive. To address this problem, we propose atwo-stream neural architecture search (NAS) based framework, called\enquote{EmotionNAS}. Specifically, we take two-stream features (i.e.,handcrafted and deep features) as the inputs, followed by NAS to search for theoptimal structure for each stream. Furthermore, we incorporate complementaryinformation in different streams through an efficient information supplementmodule. Experimental results demonstrate that our method outperforms existingmanually-designed and NAS-based models, setting the new state-of-the-artrecord.</description><author>Haiyang Sun, Zheng Lian, Bin Liu, Ying Li, Licai Sun, Cong Cai, Jianhua Tao, Meng Wang, Yuan Cheng</author><pubDate>Fri, 09 Jun 2023 15:45:18 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2203.13617v2</guid></item><item><title>FLSTRA: Federated Learning in Stratosphere</title><link>http://arxiv.org/abs/2302.00163v3</link><description>We propose a federated learning (FL) in stratosphere (FLSTRA) system, where ahigh altitude platform station (HAPS) facilitates a large number of terrestrialclients to collaboratively learn a global model without sharing the trainingdata. FLSTRA overcomes the challenges faced by FL in terrestrial networks, suchas slow convergence and high communication delay due to limited clientparticipation and multi-hop communications. HAPS leverages its altitude andsize to allow the participation of more clients with line-of-sight (LOS) linksand the placement of a powerful server. However, handling many clients at onceintroduces computing and transmission delays. Thus, we aim to obtain adelay-accuracy trade-off for FLSTRA. Specifically, we first develop a jointclient selection and resource allocation algorithm for uplink and downlink tominimize the FL delay subject to the energy and quality-of-service (QoS)constraints. Second, we propose a communication and computation resource-aware(CCRA-FL) algorithm to achieve the target FL accuracy while deriving an upperbound for its convergence rate. The formulated problem is non-convex; thus, wepropose an iterative algorithm to solve it. Simulation results demonstrate theeffectiveness of the proposed FLSTRA system, compared to terrestrialbenchmarks, in terms of FL delay and accuracy.</description><author>Amin Farajzadeh, Animesh Yadav, Omid Abbasi, Wael Jaafar, Halim Yanikomeroglu</author><pubDate>Fri, 09 Jun 2023 15:26:29 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2302.00163v3</guid></item><item><title>GTNet: Graph Transformer Network for 3D Point Cloud Classification and Semantic Segmentation</title><link>http://arxiv.org/abs/2305.15213v2</link><description>Recently, graph-based and Transformer-based deep learning networks havedemonstrated excellent performances on various point cloud tasks. Most of theexisting graph methods are based on static graph, which take a fixed input toestablish graph relations. Moreover, many graph methods apply maximization andaveraging to aggregate neighboring features, so that only a single neighboringpoint affects the feature of centroid or different neighboring points have thesame influence on the centroid's feature, which ignoring the correlation anddifference between points. Most Transformer-based methods extract point cloudfeatures based on global attention and lack the feature learning on localneighbors. To solve the problems of these two types of models, we propose a newfeature extraction block named Graph Transformer and construct a 3D point pointcloud learning network called GTNet to learn features of point clouds on localand global patterns. Graph Transformer integrates the advantages of graph-basedand Transformer-based methods, and consists of Local Transformer and GlobalTransformer modules. Local Transformer uses a dynamic graph to calculate allneighboring point weights by intra-domain cross-attention with dynamicallyupdated graph relations, so that every neighboring point could affect thefeatures of centroid with different weights; Global Transformer enlarges thereceptive field of Local Transformer by a global self-attention. In addition,to avoid the disappearance of the gradient caused by the increasing depth ofnetwork, we conduct residual connection for centroid features in GTNet; we alsoadopt the features of centroid and neighbors to generate the local geometricdescriptors in Local Transformer to strengthen the local information learningcapability of the model. Finally, we use GTNet for shape classification, partsegmentation and semantic segmentation tasks in this paper.</description><author>Wei Zhou, Qian Wang, Weiwei Jin, Xinzhe Shi, Ying He</author><pubDate>Fri, 09 Jun 2023 15:23:12 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.15213v2</guid></item><item><title>Guillotine Regularization: Why removing layers is needed to improve generalization in Self-Supervised Learning</title><link>http://arxiv.org/abs/2206.13378v2</link><description>One unexpected technique that emerged in recent years consists in training aDeep Network (DN) with a Self-Supervised Learning (SSL) method, and using thisnetwork on downstream tasks but with its last few projector layers entirelyremoved. This trick of throwing away the projector is actually critical for SSLmethods to display competitive performances on ImageNet for which more than 30percentage points can be gained that way. This is a little vexing, as one wouldhope that the network layer at which invariance is explicitly enforced by theSSL criterion during training (the last projector layer) should be the one touse for best generalization performance downstream. But it seems not to be, andthis study sheds some light on why. This trick, which we name GuillotineRegularization (GR), is in fact a generically applicable method that has beenused to improve generalization performance in transfer learning scenarios. Inthis work, we identify the underlying reasons behind its success and show thatthe optimal layer to use might change significantly depending on the trainingsetup, the data or the downstream task. Lastly, we give some insights on how toreduce the need for a projector in SSL by aligning the pretext SSL task and thedownstream task.</description><author>Florian Bordes, Randall Balestriero, Quentin Garrido, Adrien Bardes, Pascal Vincent</author><pubDate>Fri, 09 Jun 2023 15:22:16 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2206.13378v2</guid></item><item><title>Speaker Embeddings as Individuality Proxy for Voice Stress Detection</title><link>http://arxiv.org/abs/2306.05915v1</link><description>Since the mental states of the speaker modulate speech, stress introduced bycognitive or physical loads could be detected in the voice. The existing voicestress detection benchmark has shown that the audio embeddings extracted fromthe Hybrid BYOL-S self-supervised model perform well. However, the benchmarkonly evaluates performance separately on each dataset, but does not evaluateperformance across the different types of stress and different languages.Moreover, previous studies found strong individual differences in stresssusceptibility. This paper presents the design and development of voice stressdetection, trained on more than 100 speakers from 9 language groups and fivedifferent types of stress. We address individual variabilities in voice stressanalysis by adding speaker embeddings to the hybrid BYOL-S features. Theproposed method significantly improves voice stress detection performance withan input audio length of only 3-5 seconds.</description><author>Zihan Wu, Neil Scheidwasser-Clow, Karl El Hajal, Milos Cernak</author><pubDate>Fri, 09 Jun 2023 15:11:07 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.05915v1</guid></item><item><title>Single-Image-Based Deep Learning for Segmentation of Early Esophageal Cancer Lesions</title><link>http://arxiv.org/abs/2306.05912v1</link><description>Accurate segmentation of lesions is crucial for diagnosis and treatment ofearly esophageal cancer (EEC). However, neither traditional nor deeplearning-based methods up to today can meet the clinical requirements, with themean Dice score - the most important metric in medical image analysis - hardlyexceeding 0.75. In this paper, we present a novel deep learning approach forsegmenting EEC lesions. Our approach stands out for its uniqueness, as itrelies solely on a single image coming from one patient, forming the so-called"You-Only-Have-One" (YOHO) framework. On one hand, this "one-image-one-network"learning ensures complete patient privacy as it does not use any images fromother patients as the training data. On the other hand, it avoids nearly allgeneralization-related problems since each trained network is applied only tothe input image itself. In particular, we can push the training to"over-fitting" as much as possible to increase the segmentation accuracy. Ourtechnical details include an interaction with clinical physicians to utilizetheir expertise, a geometry-based rendering of a single lesion image togenerate the training set (the \emph{biggest} novelty), and an edge-enhancedUNet. We have evaluated YOHO over an EEC data-set created by ourselves andachieved a mean Dice score of 0.888, which represents a significant advancetoward clinical applications.</description><author>Haipeng Li, Dingrui Liu, Yu Zeng, Shuaicheng Liu, Tao Gan, Nini Rao, Jinlin Yang, Bing Zeng</author><pubDate>Fri, 09 Jun 2023 15:06:26 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.05912v1</guid></item><item><title>Sketch2Stress: Sketching with Structural Stress Awareness</title><link>http://arxiv.org/abs/2306.05911v1</link><description>In the process of product design and digital fabrication, the structuralanalysis of a designed prototype is a fundamental and essential step. However,such a step is usually invisible or inaccessible to designers at the earlysketching phase. This limits the user's ability to consider a shape's physicalproperties and structural soundness. To bridge this gap, we introduce a novelapproach Sketch2Stress that allows users to perform structural analysis ofdesired objects at the sketching stage. This method takes as input a 2Dfreehand sketch and one or multiple locations of user-assigned external forces.With the specially-designed two-branch generative-adversarial framework, itautomatically predicts a normal map and a corresponding structural stress mapdistributed over the user-sketched underlying object. In this way, our methodempowers designers to easily examine the stress sustained everywhere andidentify potential problematic regions of their sketched object. Furthermore,combined with the predicted normal map, users are able to conduct a region-wisestructural analysis efficiently by aggregating the stress effects of multipleforces in the same direction. Finally, we demonstrate the effectiveness andpracticality of our system with extensive experiments and user studies.</description><author>Deng Yu, Chufeng Xiao, Manfred Lau, Hongbo Fu</author><pubDate>Fri, 09 Jun 2023 15:05:41 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.05911v1</guid></item><item><title>2DeteCT -- A large 2D expandable, trainable, experimental Computed Tomography dataset for machine learning</title><link>http://arxiv.org/abs/2306.05907v1</link><description>Recent research in computational imaging largely focuses on developingmachine learning (ML) techniques for image reconstruction, which requireslarge-scale training datasets consisting of measurement data and ground-truthimages. However, suitable experimental datasets for X-ray Computed Tomography(CT) are scarce, and methods are often developed and evaluated only onsimulated data. We fill this gap by providing the community with a versatile,open 2D fan-beam CT dataset suitable for developing ML techniques for a rangeof image reconstruction tasks. To acquire it, we designed a sophisticated,semi-automatic scan procedure that utilizes a highly-flexible laboratory X-rayCT setup. A diverse mix of samples with high natural variability in shape anddensity was scanned slice-by-slice (5000 slices in total) with high angular andspatial resolution and three different beam characteristics: A high-fidelity, alow-dose and a beam-hardening-inflicted mode. In addition, 750out-of-distribution slices were scanned with sample and beam variations toaccommodate robustness and segmentation tasks. We provide raw projection data,reference reconstructions and segmentations based on an open-source dataprocessing pipeline.</description><author>Maximilian B. Kiss, Sophia B. Coban, K. Joost Batenburg, Tristan van Leeuwen, Felix Lucka</author><pubDate>Fri, 09 Jun 2023 15:02:53 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.05907v1</guid></item><item><title>LaDI-VTON: Latent Diffusion Textual-Inversion Enhanced Virtual Try-On</title><link>http://arxiv.org/abs/2305.13501v2</link><description>The rapidly evolving fields of e-commerce and metaverse continue to seekinnovative approaches to enhance the consumer experience. At the same time,recent advancements in the development of diffusion models have enabledgenerative networks to create remarkably realistic images. In this context,image-based virtual try-on, which consists in generating a novel image of atarget model wearing a given in-shop garment, has yet to capitalize on thepotential of these powerful generative solutions. This work introducesLaDI-VTON, the first Latent Diffusion textual Inversion-enhanced model for theVirtual Try-ON task. The proposed architecture relies on a latent diffusionmodel extended with a novel additional autoencoder module that exploitslearnable skip connections to enhance the generation process preserving themodel's characteristics. To effectively maintain the texture and details of thein-shop garment, we propose a textual inversion component that can map thevisual features of the garment to the CLIP token embedding space and thusgenerate a set of pseudo-word token embeddings capable of conditioning thegeneration process. Experimental results on Dress Code and VITON-HD datasetsdemonstrate that our approach outperforms the competitors by a consistentmargin, achieving a significant milestone for the task. Source code and trainedmodels will be publicly released at: https://github.com/miccunifi/ladi-vton.</description><author>Davide Morelli, Alberto Baldrati, Giuseppe Cartella, Marcella Cornia, Marco Bertini, Rita Cucchiara</author><pubDate>Fri, 09 Jun 2023 15:02:00 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.13501v2</guid></item><item><title>TreeDQN: Learning to minimize Branch-and-Bound tree</title><link>http://arxiv.org/abs/2306.05905v1</link><description>Combinatorial optimization problems require an exhaustive search to find theoptimal solution. A convenient approach to solving combinatorial optimizationtasks in the form of Mixed Integer Linear Programs is Branch-and-Bound.Branch-and-Bound solver splits a task into two parts dividing the domain of aninteger variable, then it solves them recursively, producing a tree of nestedsub-tasks. The efficiency of the solver depends on the branchning heuristicused to select a variable for splitting. In the present work, we propose areinforcement learning method that can efficiently learn the branchingheuristic. We view the variable selection task as a tree Markov DecisionProcess, prove that the Bellman operator adapted for the tree Markov DecisionProcess is contracting in mean, and propose a modified learning objective forthe reinforcement learning agent. Our agent requires less training data andproduces smaller trees compared to previous reinforcement learning methods.</description><author>Dmitry Sorokin, Alexander Kostin</author><pubDate>Fri, 09 Jun 2023 15:01:26 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.05905v1</guid></item><item><title>Active Learning with Weak Supervision for Gaussian Processes</title><link>http://arxiv.org/abs/2204.08335v2</link><description>Annotating data for supervised learning can be costly. When the annotationbudget is limited, active learning can be used to select and annotate thoseobservations that are likely to give the most gain in model performance. Wepropose an active learning algorithm that, in addition to selecting whichobservation to annotate, selects the precision of the annotation that isacquired. Assuming that annotations with low precision are cheaper to obtain,this allows the model to explore a larger part of the input space, with thesame annotation budget. We build our acquisition function on the previouslyproposed BALD objective for Gaussian Processes, and empirically demonstrate thegains of being able to adjust the annotation precision in the active learningloop.</description><author>Amanda Olmin, Jakob Lindqvist, Lennart Svensson, Fredrik Lindsten</author><pubDate>Fri, 09 Jun 2023 14:51:13 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2204.08335v2</guid></item><item><title>A Novel Correlation-optimized Deep Learning Method for Wind Speed Forecast</title><link>http://arxiv.org/abs/2306.01986v2</link><description>The increasing installation rate of wind power poses great challenges to theglobal power system. In order to ensure the reliable operation of the powersystem, it is necessary to accurately forecast the wind speed and power of thewind turbines. At present, deep learning is progressively applied to the windspeed prediction. Nevertheless, the recent deep learning methods still reflectthe embarrassment for practical applications due to model interpretability andhardware limitation. To this end, a novel deep knowledge-based learning methodis proposed in this paper. The proposed method hybridizes pre-training methodand auto-encoder structure to improve data representation and modeling of thedeep knowledge-based learning framework. In order to form knowledge andcorresponding absorbers, the original data is preprocessed by an optimizationmodel based on correlation to construct multi-layer networks (knowledge) whichare absorbed by sequence to sequence (Seq2Seq) models. Specifically, newcognition and memory units (CMU) are designed to reinforce traditional deeplearning framework. Finally, the effectiveness of the proposed method isverified by three wind prediction cases from a wind farm in Liaoning, China.Experimental results show that the proposed method increases the stability andtraining efficiency compared to the traditional LSTM method and LSTM/GRU-basedSeq2Seq method for applications of wind speed forecasting.</description><author>Yang Yang, Jin Lang, Jian Wu, Yanyan Zhang, Xiang Zhao</author><pubDate>Fri, 09 Jun 2023 14:46:50 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.01986v2</guid></item><item><title>Asymptotically efficient one-step stochastic gradient descent</title><link>http://arxiv.org/abs/2306.05896v1</link><description>A generic, fast and asymptotically efficient method for parametric estimationis described. It is based on the stochastic gradient descent on theloglikelihood function corrected by a single step of the Fisher scoringalgorithm. We show theoretically and by simulations in the i.i.d. setting thatit is an interesting alternative to the usual stochastic gradient descent withaveraging or the adaptative stochastic gradient descent.</description><author>Alain Bensoussan, Alexandre Brouste, Youssef Esstafa</author><pubDate>Fri, 09 Jun 2023 14:43:07 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.05896v1</guid></item><item><title>C(NN)FD -- a deep learning framework for turbomachinery CFD analysis</title><link>http://arxiv.org/abs/2306.05889v1</link><description>Deep Learning methods have seen a wide range of successful applicationsacross different industries. Up until now, applications to physical simulationssuch as CFD (Computational Fluid Dynamics), have been limited to simpletest-cases of minor industrial relevance. This paper demonstrates thedevelopment of a novel deep learning framework for real-time predictions of theimpact of manufacturing and build variations on the overall performance ofaxial compressors in gas turbines, with a focus on tip clearance variations.The associated scatter in efficiency can significantly increase the $CO_2$emissions, thus being of great industrial and environmental relevance. Theproposed \textit{C(NN)FD} architecture achieves in real-time accuracycomparable to the CFD benchmark. Predicting the flow field and using it tocalculate the corresponding overall performance renders the methodologygeneralisable, while filtering only relevant parts of the CFD solution makesthe methodology scalable to industrial applications.</description><author>Giuseppe Bruni, Sepehr Maleki, Senthil K. Krishnababu</author><pubDate>Fri, 09 Jun 2023 14:35:04 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.05889v1</guid></item><item><title>CI-GNN: A Granger Causality-Inspired Graph Neural Network for Interpretable Brain Network-Based Psychiatric Diagnosis</title><link>http://arxiv.org/abs/2301.01642v2</link><description>There is a recent trend to leverage the power of graph neural networks (GNNs)for brain-network based psychiatric diagnosis, which,in turn, also motivates anurgent need for psychiatrists to fully understand the decision behavior of theused GNNs. However, most of the existing GNN explainers are either post-hoc inwhich another interpretive model needs to be created to explain a well-trainedGNN, or do not consider the causal relationship between the extractedexplanation and the decision, such that the explanation itself containsspurious correlations and suffers from weak faithfulness. In this work, wepropose a granger causality-inspired graph neural network (CI-GNN), a built-ininterpretable model that is able to identify the most influential subgraph(i.e., functional connectivity within brain regions) that is causally relatedto the decision (e.g., major depressive disorder patients or healthy controls),without the training of an auxillary interpretive network. CI-GNN learnsdisentangled subgraph-level representations {\alpha} and \b{eta} that encode,respectively, the causal and noncausal aspects of original graph under a graphvariational autoencoder framework, regularized by a conditional mutualinformation (CMI) constraint. We theoretically justify the validity of the CMIregulation in capturing the causal relationship. We also empirically evaluatethe performance of CI-GNN against three baseline GNNs and four state-of-the-artGNN explainers on synthetic data and three large-scale brain disease datasets.We observe that CI-GNN achieves the best performance in a wide range of metricsand provides more reliable and concise explanations which have clinicalevidence.</description><author>Kaizhong Zheng, Shujian Yu, Badong Chen</author><pubDate>Fri, 09 Jun 2023 14:32:29 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2301.01642v2</guid></item><item><title>TrajectoryFormer: 3D Object Tracking Transformer with Predictive Trajectory Hypotheses</title><link>http://arxiv.org/abs/2306.05888v1</link><description>3D multi-object tracking (MOT) is vital for many applications includingautonomous driving vehicles and service robots. With the commonly usedtracking-by-detection paradigm, 3D MOT has made important progress in recentyears. However, these methods only use the detection boxes of the current frameto obtain trajectory-box association results, which makes it impossible for thetracker to recover objects missed by the detector. In this paper, we presentTrajectoryFormer, a novel point-cloud-based 3D MOT framework. To recover themissed object by detector, we generates multiple trajectory hypotheses withhybrid candidate boxes, including temporally predicted boxes and current-framedetection boxes, for trajectory-box association. The predicted boxes canpropagate object's history trajectory information to the current frame and thusthe network can tolerate short-term miss detection of the tracked objects. Wecombine long-term object motion feature and short-term object appearancefeature to create per-hypothesis feature embedding, which reduces thecomputational overhead for spatial-temporal encoding. Additionally, weintroduce a Global-Local Interaction Module to conduct information interactionamong all hypotheses and models their spatial relations, leading to accurateestimation of hypotheses. Our TrajectoryFormer achieves state-of-the-artperformance on the Waymo 3D MOT benchmarks.</description><author>Xuesong Chen, Shaoshuai Shi, Chao Zhang, Benjin Zhu, Qiang Wang, Ka Chun Cheung, Simon See, Hongsheng Li</author><pubDate>Fri, 09 Jun 2023 14:31:50 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.05888v1</guid></item><item><title>Conformal Credal Self-Supervised Learning</title><link>http://arxiv.org/abs/2205.15239v2</link><description>In semi-supervised learning, the paradigm of self-training refers to the ideaof learning from pseudo-labels suggested by the learner itself. Across variousdomains, corresponding methods have proven effective and achievestate-of-the-art performance. However, pseudo-labels typically stem from ad-hocheuristics, relying on the quality of the predictions though withoutguaranteeing their validity. One such method, so-called credal self-supervisedlearning, maintains pseudo-supervision in the form of sets of (instead ofsingle) probability distributions over labels, thereby allowing for a flexibleyet uncertainty-aware labeling. Again, however, there is no justificationbeyond empirical effectiveness. To address this deficiency, we make use ofconformal prediction, an approach that comes with guarantees on the validity ofset-valued predictions. As a result, the construction of credal sets of labelsis supported by a rigorous theoretical foundation, leading to better calibratedand less error-prone supervision for unlabeled data. Along with this, wepresent effective algorithms for learning from credal self-supervision. Anempirical study demonstrates excellent calibration properties of thepseudo-supervision, as well as the competitiveness of our method on severalbenchmark datasets.</description><author>Julian Lienen, Caglar Demir, Eyke Hüllermeier</author><pubDate>Fri, 09 Jun 2023 14:30:44 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2205.15239v2</guid></item><item><title>An Efficient Speech Separation Network Based on Recurrent Fusion Dilated Convolution and Channel Attention</title><link>http://arxiv.org/abs/2306.05887v1</link><description>We present an efficient speech separation neural network, ARFDCN, whichcombines dilated convolutions, multi-scale fusion (MSF), and channel attentionto overcome the limited receptive field of convolution-based networks and thehigh computational cost of transformer-based networks. The suggested networkarchitecture is encoder-decoder based. By using dilated convolutions withgradually increasing dilation value to learn local and global features andfusing them at adjacent stages, the model can learn rich feature content.Meanwhile, by adding channel attention modules to the network, the model canextract channel weights, learn more important features, and thus improve itsexpressive power and robustness. Experimental results indicate that the modelachieves a decent balance between performance and computational efficiency,making it a promising alternative to current mainstream models for practicalapplications.</description><author>Junyu Wang</author><pubDate>Fri, 09 Jun 2023 14:30:27 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.05887v1</guid></item><item><title>Causal Strategic Classification: A Tale of Two Shifts</title><link>http://arxiv.org/abs/2302.06280v3</link><description>When users can benefit from certain predictive outcomes, they may be prone toact to achieve those outcome, e.g., by strategically modifying their features.The goal in strategic classification is therefore to train predictive modelsthat are robust to such behavior. However, the conventional framework assumesthat changing features does not change actual outcomes, which depicts users as"gaming" the system. Here we remove this assumption, and study learning in acausal strategic setting where true outcomes do change. Focusing on accuracy asour primary objective, we show how strategic behavior and causal effectsunderlie two complementing forms of distribution shift. We characterize theseshifts, and propose a learning algorithm that balances between these two forcesand over time, and permits end-to-end training. Experiments on synthetic andsemi-synthetic data demonstrate the utility of our approach.</description><author>Guy Horowitz, Nir Rosenfeld</author><pubDate>Fri, 09 Jun 2023 14:27:31 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2302.06280v3</guid></item><item><title>Good, but not always Fair: An Evaluation of Gender Bias for three commercial Machine Translation Systems</title><link>http://arxiv.org/abs/2306.05882v1</link><description>Machine Translation (MT) continues to make significant strides in quality andis increasingly adopted on a larger scale. Consequently, analyses have beenredirected to more nuanced aspects, intricate phenomena, as well as potentialrisks that may arise from the widespread use of MT tools. Along this line, thispaper offers a meticulous assessment of three commercial MT systems - GoogleTranslate, DeepL, and Modern MT - with a specific focus on gender translationand bias. For three language pairs (English/Spanish, English/Italian, andEnglish/French), we scrutinize the behavior of such systems at several levelsof granularity and on a variety of naturally occurring gender phenomena intranslation. Our study takes stock of the current state of online MT tools, byrevealing significant discrepancies in the gender translation of the threesystems, with each system displaying varying degrees of bias despite theiroverall translation quality.</description><author>Silvia Alma Piazzolla, Beatrice Savoldi, Luisa Bentivogli</author><pubDate>Fri, 09 Jun 2023 14:24:27 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.05882v1</guid></item><item><title>Time Series Continuous Modeling for Imputation and Forecasting with Implicit Neural Representations</title><link>http://arxiv.org/abs/2306.05880v1</link><description>Although widely explored, time series modeling continues to encountersignificant challenges when confronted with real-world data. We propose a novelmodeling approach leveraging Implicit Neural Representations (INR). Thisapproach enables us to effectively capture the continuous aspect of time seriesand provides a natural solution to recurring modeling issues such as handlingmissing data, dealing with irregular sampling, or unaligned observations frommultiple sensors. By introducing conditional modulation of INR parameters andleveraging meta-learning techniques, we address the issue of generalization toboth unseen samples and time window shifts. Through extensive experimentation,our model demonstrates state-of-the-art performance in forecasting andimputation tasks, while exhibiting flexibility in handling a wide range ofchallenging scenarios that competing models cannot.</description><author>Etienne Le Naour, Louis Serrano, Léon Migus, Yuan Yin, patrick gallinari, Ghislain Agoua, Nicolas Baskiotis, Vincent Guigue</author><pubDate>Fri, 09 Jun 2023 14:20:04 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.05880v1</guid></item><item><title>Is Normalization Indispensable for Multi-domain Federated Learning?</title><link>http://arxiv.org/abs/2306.05879v1</link><description>Federated learning (FL) enhances data privacy with collaborative in-situtraining on decentralized clients. Nevertheless, FL encounters challenges dueto non-independent and identically distributed (non-i.i.d) data, leading topotential performance degradation and hindered convergence. While prior studiespredominantly addressed the issue of skewed label distribution, our researchaddresses a crucial yet frequently overlooked problem known as multi-domain FL.In this scenario, clients' data originate from diverse domains with distinctfeature distributions, as opposed to label distributions. To address themulti-domain problem in FL, we propose a novel method called Federated learningWithout normalizations (FedWon). FedWon draws inspiration from the observationthat batch normalization (BN) faces challenges in effectively modeling thestatistics of multiple domains, while alternative normalization techniquespossess their own limitations. In order to address these issues, FedWoneliminates all normalizations in FL and reparameterizes convolution layers withscaled weight standardization. Through comprehensive experimentation on fourdatasets and four models, our results demonstrate that FedWon surpasses bothFedAvg and the current state-of-the-art method (FedBN) across all experimentalsetups, achieving notable improvements of over 10% in certain domains.Furthermore, FedWon is versatile for both cross-silo and cross-device FL,exhibiting strong performance even with a batch size as small as 1, therebycatering to resource-constrained devices. Additionally, FedWon effectivelytackles the challenge of skewed label distribution.</description><author>Weiming Zhuang, Lingjuan Lyu</author><pubDate>Fri, 09 Jun 2023 14:18:50 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.05879v1</guid></item><item><title>Detecting Adversarial Directions in Deep Reinforcement Learning to Make Robust Decisions</title><link>http://arxiv.org/abs/2306.05873v1</link><description>Learning in MDPs with highly complex state representations is currentlypossible due to multiple advancements in reinforcement learning algorithmdesign. However, this incline in complexity, and furthermore the increase inthe dimensions of the observation came at the cost of volatility that can betaken advantage of via adversarial attacks (i.e. moving along worst-casedirections in the observation space). To solve this policy instability problemwe propose a novel method to detect the presence of these non-robust directionsvia local quadratic approximation of the deep neural policy loss. Our methodprovides a theoretical basis for the fundamental cut-off between safeobservations and adversarial observations. Furthermore, our technique iscomputationally efficient, and does not depend on the methods used to producethe worst-case directions. We conduct extensive experiments in the ArcadeLearning Environment with several different adversarial attack techniques. Mostsignificantly, we demonstrate the effectiveness of our approach even in thesetting where non-robust directions are explicitly optimized to circumvent ourproposed method.</description><author>Ezgi Korkmaz, Jonah Brown-Cohen</author><pubDate>Fri, 09 Jun 2023 14:11:05 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.05873v1</guid></item><item><title>PFNs4BO: In-Context Learning for Bayesian Optimization</title><link>http://arxiv.org/abs/2305.17535v3</link><description>In this paper, we use Prior-data Fitted Networks (PFNs) as a flexiblesurrogate for Bayesian Optimization (BO). PFNs are neural processes that aretrained to approximate the posterior predictive distribution (PPD) throughin-context learning on any prior distribution that can be efficiently sampledfrom. We describe how this flexibility can be exploited for surrogate modelingin BO. We use PFNs to mimic a naive Gaussian process (GP), an advanced GP, anda Bayesian Neural Network (BNN). In addition, we show how to incorporatefurther information into the prior, such as allowing hints about the positionof optima (user priors), ignoring irrelevant dimensions, and performingnon-myopic BO by learning the acquisition function. The flexibility underlyingthese extensions opens up vast possibilities for using PFNs for BO. Wedemonstrate the usefulness of PFNs for BO in a large-scale evaluation onartificial GP samples and three different hyperparameter optimization testbeds:HPO-B, Bayesmark, and PD1. We publish code alongside trained models athttps://github.com/automl/PFNs4BO.</description><author>Samuel Müller, Matthias Feurer, Noah Hollmann, Frank Hutter</author><pubDate>Fri, 09 Jun 2023 14:09:16 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.17535v3</guid></item><item><title>Neural Haircut: Prior-Guided Strand-Based Hair Reconstruction</title><link>http://arxiv.org/abs/2306.05872v1</link><description>Generating realistic human 3D reconstructions using image or video data isessential for various communication and entertainment applications. Whileexisting methods achieved impressive results for body and facial regions,realistic hair modeling still remains challenging due to its high mechanicalcomplexity. This work proposes an approach capable of accurate hair geometryreconstruction at a strand level from a monocular video or multi-view imagescaptured in uncontrolled lighting conditions. Our method has two stages, withthe first stage performing joint reconstruction of coarse hair and bust shapesand hair orientation using implicit volumetric representations. The secondstage then estimates a strand-level hair reconstruction by reconciling in asingle optimization process the coarse volumetric constraints with hair strandand hairstyle priors learned from the synthetic data. To further increase thereconstruction fidelity, we incorporate image-based losses into the fittingprocess using a new differentiable renderer. The combined system, named NeuralHaircut, achieves high realism and personalization of the reconstructedhairstyles.</description><author>Vanessa Sklyarova, Jenya Chelishev, Andreea Dogaru, Igor Medvedev, Victor Lempitsky, Egor Zakharov</author><pubDate>Fri, 09 Jun 2023 14:08:34 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.05872v1</guid></item><item><title>Towards a Robust Detection of Language Model Generated Text: Is ChatGPT that Easy to Detect?</title><link>http://arxiv.org/abs/2306.05871v1</link><description>Recent advances in natural language processing (NLP) have led to thedevelopment of large language models (LLMs) such as ChatGPT. This paperproposes a methodology for developing and evaluating ChatGPT detectors forFrench text, with a focus on investigating their robustness on out-of-domaindata and against common attack schemes. The proposed method involvestranslating an English dataset into French and training a classifier on thetranslated data. Results show that the detectors can effectively detectChatGPT-generated text, with a degree of robustness against basic attacktechniques in in-domain settings. However, vulnerabilities are evident inout-of-domain contexts, highlighting the challenge of detecting adversarialtext. The study emphasizes caution when applying in-domain testing results to awider variety of content. We provide our translated datasets and models asopen-source resources. https://gitlab.inria.fr/wantoun/robust-chatgpt-detection</description><author>Wissam Antoun, Virginie Mouilleron, Benoît Sagot, Djamé Seddah</author><pubDate>Fri, 09 Jun 2023 14:03:53 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.05871v1</guid></item><item><title>Leaving the Lines Behind: Vision-Based Crop Row Exit for Agricultural Robot Navigation</title><link>http://arxiv.org/abs/2306.05869v1</link><description>Usage of purely vision based solutions for row switching is not well exploredin existing vision based crop row navigation frameworks. This method only usesRGB images for local feature matching based visual feedback to exit crop row.Depth images were used at crop row end to estimate the navigation distancewithin headland. The algorithm was tested on diverse headland areas with soiland vegetation. The proposed method could reach the end of the crop row andthen navigate into the headland completely leaving behind the crop row with anerror margin of 50 cm.</description><author>Rajitha de Silva, Grzegorz Cielniak, Junfeng Gao</author><pubDate>Fri, 09 Jun 2023 14:02:31 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.05869v1</guid></item></channel></rss>