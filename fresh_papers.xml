<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/"><channel><title>Arxivfresh papers</title><link></link><description>Arxiv paper</description><language>en-US</language><lastBuildDate>Fri, 17 Nov 2023 14:00:25 GMT</lastBuildDate><generator>rfeed v1.0.0</generator><docs>https://github.com/svpino/rfeed/blob/master/README.md</docs><item><title>The Chosen One: Consistent Characters in Text-to-Image Diffusion Models</title><link>http://arxiv.org/abs/2311.10093v1</link><description>Recent advances in text-to-image generation models have unlocked vastpotential for visual creativity. However, these models struggle with generationof consistent characters, a crucial aspect for numerous real-world applicationssuch as story visualization, game development asset design, advertising, andmore. Current methods typically rely on multiple pre-existing images of thetarget character or involve labor-intensive manual processes. In this work, wepropose a fully automated solution for consistent character generation, withthe sole input being a text prompt. We introduce an iterative procedure that,at each stage, identifies a coherent set of images sharing a similar identityand extracts a more consistent identity from this set. Our quantitativeanalysis demonstrates that our method strikes a better balance between promptalignment and identity consistency compared to the baseline methods, and thesefindings are reinforced by a user study. To conclude, we showcase severalpractical applications of our approach. Project page is available athttps://omriavrahami.com/the-chosen-one</description><author>Omri Avrahami, Amir Hertz, Yael Vinker, Moab Arar, Shlomi Fruchter, Ohad Fried, Daniel Cohen-Or, Dani Lischinski</author><pubDate>Thu, 16 Nov 2023 18:59:51 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.10093v1</guid></item><item><title>Traffic Video Object Detection using Motion Prior</title><link>http://arxiv.org/abs/2311.10092v1</link><description>Traffic videos inherently differ from generic videos in their stationarycamera setup, thus providing a strong motion prior where objects often move ina specific direction over a short time interval. Existing works predominantlyemploy generic video object detection framework for traffic video objectdetection, which yield certain advantages such as broad applicability androbustness to diverse scenarios. However, they fail to harness the strength ofmotion prior to enhance detection accuracy. In this work, we propose twoinnovative methods to exploit the motion prior and boost the performance ofboth fully-supervised and semi-supervised traffic video object detection.Firstly, we introduce a new self-attention module that leverages the motionprior to guide temporal information integration in the fully-supervisedsetting. Secondly, we utilise the motion prior to develop a pseudo-labellingmechanism to eliminate noisy pseudo labels for the semi-supervised setting.Both of our motion-prior-centred methods consistently demonstrates superiorperformance, outperforming existing state-of-the-art approaches by a margin of2% in terms of mAP.</description><author>Lihao Liu, Yanqi Cheng, Dongdong Chen, Jing He, Pietro Liò, Carola-Bibiane Schönlieb, Angelica I Aviles-Rivero</author><pubDate>Thu, 16 Nov 2023 18:59:46 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.10092v1</guid></item><item><title>Adaptive Shells for Efficient Neural Radiance Field Rendering</title><link>http://arxiv.org/abs/2311.10091v1</link><description>Neural radiance fields achieve unprecedented quality for novel viewsynthesis, but their volumetric formulation remains expensive, requiring a hugenumber of samples to render high-resolution images. Volumetric encodings areessential to represent fuzzy geometry such as foliage and hair, and they arewell-suited for stochastic optimization. Yet, many scenes ultimately consistlargely of solid surfaces which can be accurately rendered by a single sampleper pixel. Based on this insight, we propose a neural radiance formulation thatsmoothly transitions between volumetric- and surface-based rendering, greatlyaccelerating rendering speed and even improving visual fidelity. Our methodconstructs an explicit mesh envelope which spatially bounds a neural volumetricrepresentation. In solid regions, the envelope nearly converges to a surfaceand can often be rendered with a single sample. To this end, we generalize theNeuS formulation with a learned spatially-varying kernel size which encodes thespread of the density, fitting a wide kernel to volume-like regions and a tightkernel to surface-like regions. We then extract an explicit mesh of a narrowband around the surface, with width determined by the kernel size, andfine-tune the radiance field within this band. At inference time, we cast raysagainst the mesh and evaluate the radiance field only within the enclosedregion, greatly reducing the number of samples required. Experiments show thatour approach enables efficient rendering at very high fidelity. We alsodemonstrate that the extracted envelope enables downstream applications such asanimation and simulation.</description><author>Zian Wang, Tianchang Shen, Merlin Nimier-David, Nicholas Sharp, Jun Gao, Alexander Keller, Sanja Fidler, Thomas Müller, Zan Gojcic</author><pubDate>Thu, 16 Nov 2023 18:58:55 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.10091v1</guid></item><item><title>JaxMARL: Multi-Agent RL Environments in JAX</title><link>http://arxiv.org/abs/2311.10090v1</link><description>Benchmarks play an important role in the development of machine learningalgorithms. For example, research in reinforcement learning (RL) has beenheavily influenced by available environments and benchmarks. However, RLenvironments are traditionally run on the CPU, limiting their scalability withtypical academic compute. Recent advancements in JAX have enabled the wider useof hardware acceleration to overcome these computational hurdles, enablingmassively parallel RL training pipelines and environments. This is particularlyuseful for multi-agent reinforcement learning (MARL) research. First of all,multiple agents must be considered at each environment step, addingcomputational burden, and secondly, the sample complexity is increased due tonon-stationarity, decentralised partial observability, or other MARLchallenges. In this paper, we present JaxMARL, the first open-source code basethat combines ease-of-use with GPU enabled efficiency, and supports a largenumber of commonly used MARL environments as well as popular baselinealgorithms. When considering wall clock time, our experiments show that per-runour JAX-based training pipeline is up to 12500x faster than existingapproaches. This enables efficient and thorough evaluations, with the potentialto alleviate the evaluation crisis of the field. We also introduce andbenchmark SMAX, a vectorised, simplified version of the popular StarCraftMulti-Agent Challenge, which removes the need to run the StarCraft II gameengine. This not only enables GPU acceleration, but also provides a moreflexible MARL environment, unlocking the potential for self-play,meta-learning, and other future applications in MARL. We provide code athttps://github.com/flairox/jaxmarl.</description><author>Alexander Rutherford, Benjamin Ellis, Matteo Gallici, Jonathan Cook, Andrei Lupu, Gardar Ingvarsson, Timon Willi, Akbir Khan, Christian Schroeder de Witt, Alexandra Souly, Saptarashmi Bandyopadhyay, Mikayel Samvelyan, Minqi Jiang, Robert Tjarko Lange, Shimon Whiteson, Bruno Lacerda, Nick Hawes, Tim Rocktaschel, Chris Lu, Jakob Nicolaus Foerster</author><pubDate>Thu, 16 Nov 2023 18:58:43 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.10090v1</guid></item><item><title>Emu Edit: Precise Image Editing via Recognition and Generation Tasks</title><link>http://arxiv.org/abs/2311.10089v1</link><description>Instruction-based image editing holds immense potential for a variety ofapplications, as it enables users to perform any editing operation using anatural language instruction. However, current models in this domain oftenstruggle with accurately executing user instructions. We present Emu Edit, amulti-task image editing model which sets state-of-the-art results ininstruction-based image editing. To develop Emu Edit we train it to multi-taskacross an unprecedented range of tasks, such as region-based editing, free-formediting, and Computer Vision tasks, all of which are formulated as generativetasks. Additionally, to enhance Emu Edit's multi-task learning abilities, weprovide it with learned task embeddings which guide the generation processtowards the correct edit type. Both these elements are essential for Emu Edit'soutstanding performance. Furthermore, we show that Emu Edit can generalize tonew tasks, such as image inpainting, super-resolution, and compositions ofediting tasks, with just a few labeled examples. This capability offers asignificant advantage in scenarios where high-quality samples are scarce.Lastly, to facilitate a more rigorous and informed assessment of instructableimage editing models, we release a new challenging and versatile benchmark thatincludes seven different image editing tasks.</description><author>Shelly Sheynin, Adam Polyak, Uriel Singer, Yuval Kirstain, Amit Zohar, Oron Ashual, Devi Parikh, Yaniv Taigman</author><pubDate>Thu, 16 Nov 2023 18:55:58 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.10089v1</guid></item><item><title>A Computationally Efficient Sparsified Online Newton Method</title><link>http://arxiv.org/abs/2311.10085v1</link><description>Second-order methods hold significant promise for enhancing the convergenceof deep neural network training; however, their large memory and computationaldemands have limited their practicality. Thus there is a need for scalablesecond-order methods that can efficiently train large models. In this paper, weintroduce the Sparsified Online Newton (SONew) method, a memory-efficientsecond-order algorithm that yields a sparsified yet effective preconditioner.The algorithm emerges from a novel use of the LogDet matrix divergence measure;we combine it with sparsity constraints to minimize regret in the online convexoptimization framework. Empirically, we test our method on large scalebenchmarks of up to 1B parameters. We achieve up to 30% faster convergence,3.4% relative improvement in validation performance, and 80% relativeimprovement in training loss, in comparison to memory efficient optimizersincluding first order methods. Powering the method is a surprising fact --imposing structured sparsity patterns, like tridiagonal and banded structure,requires little to no overhead, making it as efficient and parallelizable asfirst-order methods. In wall-clock time, tridiagonal SONew is only about 3%slower per step than first-order methods but gives overall gains due to muchfaster convergence. In contrast, one of the state-of-the-art (SOTA)memory-intensive second-order methods, Shampoo, is unable to scale to largebenchmarks. Additionally, while Shampoo necessitates significant engineeringefforts to scale to large benchmarks, SONew offers a more straightforwardimplementation, increasing its practical appeal. SONew code is available at:https://github.com/devvrit/SONew</description><author>Fnu Devvrit, Sai Surya Duvvuri, Rohan Anil, Vineet Gupta, Cho-Jui Hsieh, Inderjit Dhillon</author><pubDate>Thu, 16 Nov 2023 18:44:22 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.10085v1</guid></item><item><title>Characterizing Tradeoffs in Language Model Decoding with Informational Interpretations</title><link>http://arxiv.org/abs/2311.10083v1</link><description>We propose a theoretical framework for formulating language model decoderalgorithms with dynamic programming and information theory. With dynamicprogramming, we lift the design of decoder algorithms from the logit space tothe action-state value function space, and show that the decoding algorithmsare consequences of optimizing the action-state value functions. Each componentin the action-state value function space has an information theoreticalinterpretation. With the lifting and interpretation, it becomes evident whatthe decoder algorithm is optimized for, and hence facilitating the arbitrationof the tradeoffs in sensibleness, diversity, and attribution.</description><author>Chung-Ching Chang, William W. Cohen, Yun-Hsuan Sung</author><pubDate>Thu, 16 Nov 2023 18:38:25 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.10083v1</guid></item><item><title>DRESS: Instructing Large Vision-Language Models to Align and Interact with Humans via Natural Language Feedback</title><link>http://arxiv.org/abs/2311.10081v1</link><description>We present DRESS, a large vision language model (LVLM) that innovativelyexploits Natural Language feedback (NLF) from Large Language Models to enhanceits alignment and interactions by addressing two key limitations in thestate-of-the-art LVLMs. First, prior LVLMs generally rely only on theinstruction finetuning stage to enhance alignment with human preferences.Without incorporating extra feedback, they are still prone to generateunhelpful, hallucinated, or harmful responses. Second, while the visualinstruction tuning data is generally structured in a multi-turn dialogueformat, the connections and dependencies among consecutive conversational turnsare weak. This reduces the capacity for effective multi-turn interactions. Totackle these, we propose a novel categorization of the NLF into two key types:critique and refinement. The critique NLF identifies the strengths andweaknesses of the responses and is used to align the LVLMs with humanpreferences. The refinement NLF offers concrete suggestions for improvement andis adopted to improve the interaction ability of the LVLMs-- which focuses onLVLMs' ability to refine responses by incorporating feedback in multi-turninteractions. To address the non-differentiable nature of NLF, we generalizeconditional reinforcement learning for training. Our experimental resultsdemonstrate that DRESS can generate more helpful (9.76%), honest (11.52%), andharmless (21.03%) responses, and more effectively learn from feedback duringmulti-turn interactions compared to SOTA LVMLs.</description><author>Yangyi Chen, Karan Sikka, Michael Cogswell, Heng Ji, Ajay Divakaran</author><pubDate>Thu, 16 Nov 2023 18:37:29 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.10081v1</guid></item><item><title>ChatGPT-3.5, ChatGPT-4, Google Bard, and Microsoft Bing to Improve Health Literacy and Communication in Pediatric Populations and Beyond</title><link>http://arxiv.org/abs/2311.10075v1</link><description>Purpose: Enhanced health literacy has been linked to better health outcomes;however, few interventions have been studied. We investigate whether largelanguage models (LLMs) can serve as a medium to improve health literacy inchildren and other populations. Methods: We ran 288 conditions using 26 different prompts throughChatGPT-3.5, Microsoft Bing, and Google Bard. Given constraints imposed by ratelimits, we tested a subset of 150 conditions through ChatGPT-4. The primaryoutcome measurements were the reading grade level (RGL) and word counts ofoutput. Results: Across all models, output for basic prompts such as "Explain" and"What is (are)" were at, or exceeded, a 10th-grade RGL. When prompts werespecified to explain conditions from the 1st to 12th RGL, we found that LLMshad varying abilities to tailor responses based on RGL. ChatGPT-3.5 providedresponses that ranged from the 7th-grade to college freshmen RGL whileChatGPT-4 outputted responses from the 6th-grade to the college-senior RGL.Microsoft Bing provided responses from the 9th to 11th RGL while Google Bardprovided responses from the 7th to 10th RGL. Discussion: ChatGPT-3.5 and ChatGPT-4 did better in achieving lower-gradelevel outputs. Meanwhile Bard and Bing tended to consistently produce an RGLthat is at the high school level regardless of prompt. Additionally, Bard'shesitancy in providing certain outputs indicates a cautious approach towardshealth information. LLMs demonstrate promise in enhancing health communication,but future research should verify the accuracy and effectiveness of such toolsin this context. Implications: LLMs face challenges in crafting outputs below a sixth-gradereading level. However, their capability to modify outputs above this thresholdprovides a potential mechanism to improve health literacy and communication ina pediatric population and beyond.</description><author>Kanhai S. Amin, Linda Mayes, Pavan Khosla, Rushabh Doshi</author><pubDate>Thu, 16 Nov 2023 18:30:14 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.10075v1</guid></item><item><title>EvoPrompting: Language Models for Code-Level Neural Architecture Search</title><link>http://arxiv.org/abs/2302.14838v3</link><description>Given the recent impressive accomplishments of language models (LMs) for codegeneration, we explore the use of LMs as adaptive mutation and crossoveroperators for an evolutionary neural architecture search (NAS) algorithm. WhileNAS still proves too difficult a task for LMs to succeed at solely throughprompting, we find that the combination of evolutionary prompt engineering withsoft prompt-tuning, a method we term EvoPrompting, consistently finds diverseand high performing models. We first demonstrate that EvoPrompting is effectiveon the computationally efficient MNIST-1D dataset, where EvoPrompting producesconvolutional architecture variants that outperform both those designed byhuman experts and naive few-shot prompting in terms of accuracy and model size.We then apply our method to searching for graph neural networks on the CLRSAlgorithmic Reasoning Benchmark, where EvoPrompting is able to design novelarchitectures that outperform current state-of-the-art models on 21 out of 30algorithmic reasoning tasks while maintaining similar model size. EvoPromptingis successful at designing accurate and efficient neural network architecturesacross a variety of machine learning tasks, while also being general enough foreasy adaptation to other tasks beyond neural network design.</description><author>Angelica Chen, David M. Dohan, David R. So</author><pubDate>Thu, 16 Nov 2023 18:02:19 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2302.14838v3</guid></item><item><title>Visual Environment Assessment for Safe Autonomous Quadrotor Landing</title><link>http://arxiv.org/abs/2311.10065v1</link><description>Autonomous identification and evaluation of safe landing zones are ofparamount importance for ensuring the safety and effectiveness of aerial robotsin the event of system failures, low battery, or the successful completion ofspecific tasks. In this paper, we present a novel approach for detection andassessment of potential landing sites for safe quadrotor landing. Our solutionefficiently integrates 2D and 3D environmental information, eliminating theneed for external aids such as GPS and computationally intensive elevationmaps. The proposed pipeline combines semantic data derived from a NeuralNetwork (NN), to extract environmental features, with geometric data obtainedfrom a disparity map, to extract critical geometric attributes such as slope,flatness, and roughness. We define several cost metrics based on theseattributes to evaluate safety, stability, and suitability of regions in theenvironments and identify the most suitable landing area. Our approach runs inreal-time on quadrotors equipped with limited computational capabilities.Experimental results conducted in diverse environments demonstrate that theproposed method can effectively assess and identify suitable landing areas,enabling the safe and autonomous landing of a quadrotor.</description><author>Mattia Secchiero, Nishanth Bobbili, Yang Zhou, Giuseppe Loianno</author><pubDate>Thu, 16 Nov 2023 18:02:10 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.10065v1</guid></item><item><title>Analyzing Deviations of Dyadic Lines in Fast Hough Transform</title><link>http://arxiv.org/abs/2311.10064v1</link><description>Fast Hough transform is a widely used algorithm in pattern recognition. Thealgorithm relies on approximating lines using a specific discrete line modelcalled dyadic lines. The worst-case deviation of a dyadic line from the idealline it used to construct grows as $O(log(n))$, where $n$ is the linear size ofthe image. But few lines actually reach the worst-case bound. The present paperaddresses a statistical analysis of the deviation of a dyadic line from itsideal counterpart. Specifically, our findings show that the mean deviation iszero, and the variance grows as $O(log(n))$. As $n$ increases, the distributionof these (suitably normalized) deviations converges towards a normaldistribution with zero mean and a small variance. This limiting result makes anessential use of ergodic theory.</description><author>Gleb Smirnov, Simon Karpenko</author><pubDate>Thu, 16 Nov 2023 18:00:38 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.10064v1</guid></item><item><title>Differentiable JPEG: The Devil is in the Details</title><link>http://arxiv.org/abs/2309.06978v2</link><description>JPEG remains one of the most widespread lossy image coding methods. However,the non-differentiable nature of JPEG restricts the application in deeplearning pipelines. Several differentiable approximations of JPEG have recentlybeen proposed to address this issue. This paper conducts a comprehensive reviewof existing diff. JPEG approaches and identifies critical details that havebeen missed by previous methods. To this end, we propose a novel diff. JPEGapproach, overcoming previous limitations. Our approach is differentiablew.r.t. the input image, the JPEG quality, the quantization tables, and thecolor conversion parameters. We evaluate the forward and backward performanceof our diff. JPEG approach against existing methods. Additionally, extensiveablations are performed to evaluate crucial design choices. Our proposed diff.JPEG resembles the (non-diff.) reference implementation best, significantlysurpassing the recent-best diff. approach by $3.47$dB (PSNR) on average. Forstrong compression rates, we can even improve PSNR by $9.51$dB. Strongadversarial attack results are yielded by our diff. JPEG, demonstrating theeffective gradient approximation. Our code is available athttps://github.com/necla-ml/Diff-JPEG.</description><author>Christoph Reich, Biplob Debnath, Deep Patel, Srimat Chakradhar</author><pubDate>Thu, 16 Nov 2023 17:59:20 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2309.06978v2</guid></item><item><title>Information-Theoretic Bounds on The Removal of Attribute-Specific Bias From Neural Networks</title><link>http://arxiv.org/abs/2310.04955v2</link><description>Ensuring a neural network is not relying on protected attributes (e.g., race,sex, age) for predictions is crucial in advancing fair and trustworthy AI.While several promising methods for removing attribute bias in neural networkshave been proposed, their limitations remain under-explored. In this work, wemathematically and empirically reveal an important limitation of attribute biasremoval methods in presence of strong bias. Specifically, we derive a generalnon-vacuous information-theoretical upper bound on the performance of anyattribute bias removal method in terms of the bias strength. We provideextensive experiments on synthetic, image, and census datasets to verify thetheoretical bound and its consequences in practice. Our findings show thatexisting attribute bias removal methods are effective only when the inherentbias in the dataset is relatively weak, thus cautioning against the use ofthese methods in smaller datasets where strong attribute bias can occur, andadvocating the need for methods that can overcome this limitation.</description><author>Jiazhi Li, Mahyar Khayatkhoei, Jiageng Zhu, Hanchen Xie, Mohamed E. Hussein, Wael AbdAlmageed</author><pubDate>Thu, 16 Nov 2023 17:57:45 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.04955v2</guid></item><item><title>Approximation Theory, Computing, and Deep Learning on the Wasserstein Space</title><link>http://arxiv.org/abs/2310.19548v2</link><description>The challenge of approximating functions in infinite-dimensional spaces fromfinite samples is widely regarded as formidable. In this study, we delve intothe challenging problem of the numerical approximation of Sobolev-smoothfunctions defined on probability spaces. Our particular focus centers on theWasserstein distance function, which serves as a relevant example. In contrastto the existing body of literature focused on approximating efficientlypointwise evaluations, we chart a new course to define functional approximantsby adopting three machine learning-based approaches: 1. Solving a finite numberof optimal transport problems and computing the corresponding Wassersteinpotentials. 2. Employing empirical risk minimization with Tikhonovregularization in Wasserstein Sobolev spaces. 3. Addressing the problem throughthe saddle point formulation that characterizes the weak form of the Tikhonovfunctional's Euler-Lagrange equation. As a theoretical contribution, we furnishexplicit and quantitative bounds on generalization errors for each of thesesolutions. In the proofs, we leverage the theory of metric Sobolev spaces andwe combine it with techniques of optimal transport, variational calculus, andlarge deviation bounds. In our numerical implementation, we harnessappropriately designed neural networks to serve as basis functions. Thesenetworks undergo training using diverse methodologies. This approach allows usto obtain approximating functions that can be rapidly evaluated after training.Consequently, our constructive solutions significantly enhance at equalaccuracy the evaluation speed, surpassing that of state-of-the-art methods byseveral orders of magnitude.</description><author>Massimo Fornasier, Pascal Heid, Giacomo Enrico Sodini</author><pubDate>Thu, 16 Nov 2023 17:57:02 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.19548v2</guid></item><item><title>The Song Describer Dataset: a Corpus of Audio Captions for Music-and-Language Evaluation</title><link>http://arxiv.org/abs/2311.10057v1</link><description>We introduce the Song Describer dataset (SDD), a new crowdsourced corpus ofhigh-quality audio-caption pairs, designed for the evaluation ofmusic-and-language models. The dataset consists of 1.1k human-written naturallanguage descriptions of 706 music recordings, all publicly accessible andreleased under Creative Common licenses. To showcase the use of our dataset, webenchmark popular models on three key music-and-language tasks (musiccaptioning, text-to-music generation and music-language retrieval). Ourexperiments highlight the importance of cross-dataset evaluation and offerinsights into how researchers can use SDD to gain a broader understanding ofmodel performance.</description><author>Ilaria Manco, Benno Weck, SeungHeon Doh, Minz Won, Yixiao Zhang, Dmitry Bodganov, Yusong Wu, Ke Chen, Philip Tovstogan, Emmanouil Benetos, Elio Quinton, György Fazekas, Juhan Nam</author><pubDate>Thu, 16 Nov 2023 17:52:21 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.10057v1</guid></item><item><title>Is "A Helpful Assistant" the Best Role for Large Language Models? A Systematic Evaluation of Social Roles in System Prompts</title><link>http://arxiv.org/abs/2311.10054v1</link><description>Prompting serves as the major way humans interact with Large Language Models(LLM). Commercial AI systems commonly define the role of the LLM in systemprompts. For example, ChatGPT uses "You are a helpful assistant" as part of thedefault system prompt. But is "a helpful assistant" the best role for LLMs? Inthis study, we present a systematic evaluation of how social roles in systemprompts affect model performance. We curate a list of 162 roles covering 6types of interpersonal relationships and 8 types of occupations. Throughextensive analysis of 3 popular LLMs and 2457 questions, we show that addinginterpersonal roles in prompts consistently improves the models' performanceover a range of questions. Moreover, while we find that using gender-neutralroles and specifying the role as the audience leads to better performances,predicting which role leads to the best performance remains a challenging task,and that frequency, similarity, and perplexity do not fully explain the effectof social roles on model performances. Our results can help inform the designof system prompts for AI systems. Code and data are available athttps://github.com/Jiaxin-Pei/Prompting-with-Social-Roles.</description><author>Mingqian Zheng, Jiaxin Pei, David Jurgens</author><pubDate>Thu, 16 Nov 2023 17:48:55 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.10054v1</guid></item><item><title>Near-optimal Closed-loop Method via Lyapunov Damping for Convex Optimization</title><link>http://arxiv.org/abs/2311.10053v1</link><description>We introduce an autonomous system with closed-loop damping for first-orderconvex optimization. While, to this day, optimal rates of convergence are onlyachieved by non-autonomous methods via open-loop damping (e.g., Nesterov'salgorithm), we show that our system is the first one featuring a closed-loopdamping while exhibiting a rate arbitrarily close to the optimal one. We do soby coupling the damping and the speed of convergence of the system via awell-chosen Lyapunov function. We then derive a practical first-order algorithmcalled LYDIA by discretizing our system, and present numerical experimentssupporting our theoretical findings.</description><author>Severin Maier, Camille Castera, Peter Ochs</author><pubDate>Thu, 16 Nov 2023 17:48:06 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.10053v1</guid></item><item><title>Widely Applicable Strong Baseline for Sports Ball Detection and Tracking</title><link>http://arxiv.org/abs/2311.05237v2</link><description>In this work, we present a novel Sports Ball Detection and Tracking (SBDT)method that can be applied to various sports categories. Our approach iscomposed of (1) high-resolution feature extraction, (2) position-aware modeltraining, and (3) inference considering temporal consistency, all of which areput together as a new SBDT baseline. Besides, to validate thewide-applicability of our approach, we compare our baseline with 6state-of-the-art SBDT methods on 5 datasets from different sports categories.We achieve this by newly introducing two SBDT datasets, providing new ballannotations for two datasets, and re-implementing all the methods to easeextensive comparison. Experimental results demonstrate that our approach issubstantially superior to existing methods on all the sports categories coveredby the datasets. We believe our proposed method can play as a Widely ApplicableStrong Baseline (WASB) of SBDT, and our datasets and codebase will promotefuture SBDT research. Datasets and codes are available athttps://github.com/nttcom/WASB-SBDT .</description><author>Shuhei Tarashima, Muhammad Abdul Haq, Yushan Wang, Norio Tagawa</author><pubDate>Thu, 16 Nov 2023 17:46:58 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.05237v2</guid></item><item><title>Tabular Few-Shot Generalization Across Heterogeneous Feature Spaces</title><link>http://arxiv.org/abs/2311.10051v1</link><description>Despite the prevalence of tabular datasets, few-shot learning remainsunder-explored within this domain. Existing few-shot methods are not directlyapplicable to tabular datasets due to varying column relationships, meanings,and permutational invariance. To address these challenges, we propose FLAT-anovel approach to tabular few-shot learning, encompassing knowledge sharingbetween datasets with heterogeneous feature spaces. Utilizing an encoderinspired by Dataset2Vec, FLAT learns low-dimensional embeddings of datasets andtheir individual columns, which facilitate knowledge transfer andgeneralization to previously unseen datasets. A decoder network parametrizesthe predictive target network, implemented as a Graph Attention Network, toaccommodate the heterogeneous nature of tabular datasets. Experiments on adiverse collection of 118 UCI datasets demonstrate FLAT's successfulgeneralization to new tabular datasets and a considerable improvement over thebaselines.</description><author>Max Zhu, Katarzyna Kobalczyk, Andrija Petrovic, Mladen Nikolic, Mihaela van der Schaar, Boris Delibasic, Petro Lio</author><pubDate>Thu, 16 Nov 2023 17:45:59 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.10051v1</guid></item><item><title>Inherently Interpretable Time Series Classification via Multiple Instance Learning</title><link>http://arxiv.org/abs/2311.10049v1</link><description>Conventional Time Series Classification (TSC) methods are often black boxesthat obscure inherent interpretation of their decision-making processes. Inthis work, we leverage Multiple Instance Learning (MIL) to overcome this issue,and propose a new framework called MILLET: Multiple Instance Learning forLocally Explainable Time series classification. We apply MILLET to existingdeep learning TSC models and show how they become inherently interpretablewithout compromising (and in some cases, even improving) predictiveperformance. We evaluate MILLET on 85 UCR TSC datasets and also present a novelsynthetic dataset that is specially designed to facilitate interpretabilityevaluation. On these datasets, we show MILLET produces sparse explanationsquickly that are of higher quality than other well-known interpretabilitymethods. To the best of our knowledge, our work with MILLET, which is availableon GitHub (https://github.com/JAEarly/MILTimeSeriesClassification), is thefirst to develop general MIL methods for TSC and apply them to an extensivevariety of domains</description><author>Joseph Early, Gavin KC Cheung, Kurt Cutajar, Hanting Xie, Jas Kandola, Niall Twomey</author><pubDate>Thu, 16 Nov 2023 17:45:37 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.10049v1</guid></item><item><title>Depth Insight -- Contribution of Different Features to Indoor Single-image Depth Estimation</title><link>http://arxiv.org/abs/2311.10042v1</link><description>Depth estimation from a single image is a challenging problem in computervision because binocular disparity or motion information is absent. Whereasimpressive performances have been reported in this area recently usingend-to-end trained deep neural architectures, as to what cues in the imagesthat are being exploited by these black box systems is hard to know. To thisend, in this work, we quantify the relative contributions of the known cues ofdepth in a monocular depth estimation setting using an indoor scene data set.Our work uses feature extraction techniques to relate the single features ofshape, texture, colour and saturation, taken in isolation, to predict depth. Wefind that the shape of objects extracted by edge detection substantiallycontributes more than others in the indoor setting considered, while the otherfeatures also have contributions in varying degrees. These insights will helpoptimise depth estimation models, boosting their accuracy and robustness. Theypromise to broaden the practical applications of vision-based depth estimation.The project code is attached to the supplementary material and will bepublished on GitHub.</description><author>Yihong Wu, Yuwen Heng, Mahesan Niranjan, Hansung Kim</author><pubDate>Thu, 16 Nov 2023 17:38:21 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.10042v1</guid></item><item><title>Match and Locate: low-frequency monocular odometry based on deep feature matching</title><link>http://arxiv.org/abs/2311.10034v1</link><description>Accurate and robust pose estimation plays a crucial role in many roboticsystems. Popular algorithms for pose estimation typically rely on high-fidelityand high-frequency signals from various sensors. Inclusion of these sensorsmakes the system less affordable and much more complicated. In this work weintroduce a novel approach for the robotic odometry which only requires asingle camera and, importantly, can produce reliable estimates given evenextremely low-frequency signal of around one frame per second. The approach isbased on matching image features between the consecutive frames of the videostream using deep feature matching models. The resulting coarse estimate isthen adjusted by a convolutional neural network, which is also responsible forestimating the scale of the transition, otherwise irretrievable using only thefeature matching information. We evaluate the performance of the approach inthe AISG-SLA Visual Localisation Challenge and find that while beingcomputationally efficient and easy to implement our method shows competitiveresults with only around $3^{\circ}$ of orientation estimation error and $2m$of translation estimation error taking the third place in the challenge.</description><author>Stepan Konev, Yuriy Biktairov</author><pubDate>Thu, 16 Nov 2023 17:32:58 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.10034v1</guid></item><item><title>Generating Infinite-Resolution Texture using GANs with Patch-by-Patch Paradigm</title><link>http://arxiv.org/abs/2309.02340v2</link><description>In this paper, we introduce a novel approach for generating texture images ofinfinite resolutions using Generative Adversarial Networks (GANs) based on apatch-by-patch paradigm. Existing texture synthesis techniques often rely ongenerating a large-scale texture using a one-forward pass to the generatingmodel, this limits the scalability and flexibility of the generated images. Incontrast, the proposed approach trains GANs models on a single texture image togenerate relatively small patches that are locally correlated and can beseamlessly concatenated to form a larger image while using a constant GPUmemory footprint. Our method learns the local texture structure and is able togenerate arbitrary-size textures, while also maintaining coherence anddiversity. The proposed method relies on local padding in the generator toensure consistency between patches and utilizes spatial stochastic modulationto allow for local variations and diversity within the large-scale image.Experimental results demonstrate superior scalability compared to existingapproaches while maintaining visual coherence of generated textures.</description><author>Alhasan Abdellatif, Ahmed H. Elsheikh</author><pubDate>Thu, 16 Nov 2023 17:31:07 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2309.02340v2</guid></item><item><title>LM-Infinite: Simple On-the-Fly Length Generalization for Large Language Models</title><link>http://arxiv.org/abs/2308.16137v5</link><description>In recent years, there have been remarkable advancements in the performanceof Transformer-based Large Language Models (LLMs) across various domains. Asthese LLMs are deployed for increasingly complex domains, they often face theneed to follow longer user prompts or generate longer texts. In thesesituations, the $\textit{length generalization failure}$ of LLMs on longsequences becomes more prominent. Most pre-training schemes truncate trainingsequences to a fixed length. LLMs often struggle to generate fluent andcoherent texts after longer contexts, even with relative positional encodingspecifically designed to cope with this problem. Common solutions such asfinetuning on longer corpora often involve daunting hardware and time costs andrequire careful training process design. To more efficiently extrapolateexisting LLMs' generation quality to longer texts, we theoretically andempirically investigate the main out-of-distribution (OOD) factors contributingto this problem. Inspired by this diagnosis, we propose a simple yet effectivesolution for on-the-fly length generalization, LM-Infinite. It involves only a$\mathbf{\Lambda}$-shaped attention mask (to avoid excessive attended tokens)and a distance limit (to avoid unseen distances) while requiring no parameterupdates or learning. We find it applicable to a variety of LLMs usingrelative-position encoding methods. LM-Infinite is computationally efficientwith $O(n)$ time and space, and demonstrates consistent text generation fluencyand quality to as long as 128k tokens on ArXiv and OpenWebText2 datasets, with2.72x decoding speedup. We will make the codes publicly available followingpublication.</description><author>Chi Han, Qifan Wang, Wenhan Xiong, Yu Chen, Heng Ji, Sinong Wang</author><pubDate>Thu, 16 Nov 2023 17:26:20 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2308.16137v5</guid></item><item><title>AutoML for Large Capacity Modeling of Meta's Ranking Systems</title><link>http://arxiv.org/abs/2311.07870v2</link><description>Web-scale ranking systems at Meta serving billions of users is complex.Improving ranking models is essential but engineering heavy. Automated MachineLearning (AutoML) can release engineers from labor intensive work of tuningranking models; however, it is unknown if AutoML is efficient enough to meettight production timeline in real-world and, at the same time, bring additionalimprovements to the strong baselines. Moreover, to achieve higher rankingperformance, there is an ever-increasing demand to scale up ranking models toeven larger capacity, which imposes more challenges on the efficiency. Thelarge scale of models and tight production schedule requires AutoML tooutperform human baselines by only using a small number of model evaluationtrials (around 100). We presents a sampling-based AutoML method, focusing onneural architecture search and hyperparameter optimization, addressing thesechallenges in Meta-scale production when building large capacity models. Ourapproach efficiently handles large-scale data demands. It leverages alightweight predictor-based searcher and reinforcement learning to explore vastsearch spaces, significantly reducing the number of model evaluations. Throughexperiments in large capacity modeling for CTR and CVR applications, we showthat our method achieves outstanding Return on Investment (ROI) versus humantuned baselines, with up to 0.09% Normalized Entropy (NE) loss reduction or$25\%$ Query per Second (QPS) increase by only sampling one hundred models onaverage from a curated search space. The proposed AutoML method has alreadymade real-world impact where a discovered Instagram CTR model with up to -0.36%NE gain (over existing production baseline) was selected for large-scale onlineA/B test and show statistically significant gain. These production resultsproved AutoML efficacy and accelerated its adoption in ranking systems at Meta.</description><author>Hang Yin, Kuang-Hung Liu, Mengying Sun, Yuxin Chen, Buyun Zhang, Jiang Liu, Vivek Sehgal, Rudresh Rajnikant Panchal, Eugen Hotaj, Xi Liu, Daifeng Guo, Jamey Zhang, Zhou Wang, Shali Jiang, Huayu Li, Zhengxing Chen, Wen-Yen Chen, Jiyan Yang, Wei Wen</author><pubDate>Thu, 16 Nov 2023 17:21:15 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.07870v2</guid></item><item><title>Guaranteeing Control Requirements via Reward Shaping in Reinforcement Learning</title><link>http://arxiv.org/abs/2311.10026v1</link><description>In addressing control problems such as regulation and tracking throughreinforcement learning, it is often required to guarantee that the acquiredpolicy meets essential performance and stability criteria such as a desiredsettling time and steady-state error prior to deployment. Motivated by thisnecessity, we present a set of results and a systematic reward shapingprocedure that (i) ensures the optimal policy generates trajectories that alignwith specified control requirements and (ii) allows to assess whether any givenpolicy satisfies them. We validate our approach through comprehensive numericalexperiments conducted in two representative environments from OpenAI Gym: theInverted Pendulum swing-up problem and the Lunar Lander. Utilizing both tabularand deep reinforcement learning methods, our experiments consistently affirmthe efficacy of our proposed framework, highlighting its effectiveness inensuring policy adherence to the prescribed control requirements.</description><author>Francesco De Lellis, Marco Coraggio, Giovanni Russo, Mirco Musolesi, Mario di Bernardo</author><pubDate>Thu, 16 Nov 2023 17:14:26 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.10026v1</guid></item><item><title>A Novel Neural Network-Based Federated Learning System for Imbalanced and Non-IID Data</title><link>http://arxiv.org/abs/2311.10025v1</link><description>With the growth of machine learning techniques, privacy of data of users hasbecome a major concern. Most of the machine learning algorithms rely heavily onlarge amount of data which may be collected from various sources. Collectingthese data yet maintaining privacy policies has become one of the mostchallenging tasks for the researchers. To combat this issue, researchers haveintroduced federated learning, where a prediction model is learnt by ensuringthe privacy of data of clients data. However, the prevalent federated learningalgorithms possess an accuracy and efficiency trade-off, especially for non-IIDdata. In this research, we propose a centralized, neural network-basedfederated learning system. The centralized algorithm incorporates micro-levelparallel processing inspired by the traditional mini-batch algorithm where theclient devices and the server handle the forward and backward propagationrespectively. We also devise a semi-centralized version of our proposedalgorithm. This algorithm takes advantage of edge computing for minimizing theload from the central server, where clients handle both the forward andbackward propagation while sacrificing the overall train time to some extent.We evaluate our proposed systems on five well-known benchmark datasets andachieve satisfactory performance in a reasonable time across various datadistribution settings as compared to some existing benchmark algorithms.</description><author>Mahfuzur Rahman Chowdhury, Muhammad Ibrahim</author><pubDate>Thu, 16 Nov 2023 17:14:07 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.10025v1</guid></item><item><title>Online Optimization for Network Resource Allocation and Comparison with Reinforcement Learning Techniques</title><link>http://arxiv.org/abs/2311.10023v1</link><description>We tackle in this paper an online network resource allocation problem withjob transfers. The network is composed of many servers connected bycommunication links. The system operates in discrete time; at each time slot,the administrator reserves resources at servers for future job requests, and acost is incurred for the reservations made. Then, after receptions, the jobsmay be transferred between the servers to best accommodate the demands. Thisincurs an additional transport cost. Finally, if a job request cannot besatisfied, there is a violation that engenders a cost to pay for the blockedjob. We propose a randomized online algorithm based on the exponentiallyweighted method. We prove that our algorithm enjoys a sub-linear in timeregret, which indicates that the algorithm is adapting and learning from itsexperiences and is becoming more efficient in its decision-making as itaccumulates more data. Moreover, we test the performance of our algorithm onartificial data and compare it against a reinforcement learning method where weshow that our proposed method outperforms the latter.</description><author>Ahmed Sid-Ali, Ioannis Lambadaris, Yiqiang Q. Zhao, Gennady Shaikhet, Amirhossein Asgharnia</author><pubDate>Thu, 16 Nov 2023 17:08:27 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.10023v1</guid></item><item><title>On the Overconfidence Problem in Semantic 3D Mapping</title><link>http://arxiv.org/abs/2311.10018v1</link><description>Semantic 3D mapping, the process of fusing depth and image segmentationinformation between multiple views to build 3D maps annotated with objectclasses in real-time, is a recent topic of interest. This paper highlights thefusion overconfidence problem, in which conventional mapping methods assignhigh confidence to the entire map even when they are incorrect, leading tomiscalibrated outputs. Several methods to improve uncertainty calibration atdifferent stages in the fusion pipeline are presented and compared on theScanNet dataset. We show that the most widely used Bayesian fusion strategy isamong the worst calibrated, and propose a learned pipeline that combines fusionand calibration, GLFS, which achieves simultaneously higher accuracy and 3D mapcalibration while retaining real-time capability. We further illustrate theimportance of map calibration on a downstream task by showing thatincorporating proper semantic fusion on a modular ObjectNav agent improves itssuccess rates. Our code will be provided on Github for reproducibility uponacceptance.</description><author>Joao Marcos Correia Marques, Albert Zhai, Shenlong Wang, Kris Hauser</author><pubDate>Thu, 16 Nov 2023 17:02:34 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.10018v1</guid></item><item><title>Finding Real-World Orbital Motion Laws from Data</title><link>http://arxiv.org/abs/2311.10012v1</link><description>A novel approach is presented for discovering PDEs that govern the motion ofsatellites in space. The method is based on SINDy, a data-driven techniquecapable of identifying the underlying dynamics of complex physical systems fromtime series data. SINDy is utilized to uncover PDEs that describe the laws ofphysics in space, which are non-deterministic and influenced by various factorssuch as drag or the reference area (related to the attitude of the satellite).In contrast to prior works, the physically interpretable coordinate system ismaintained, and no dimensionality reduction technique is applied to the data.By training the model with multiple representative trajectories of LEO -encompassing various inclinations, eccentricities, and altitudes - and testingit with unseen orbital motion patterns, a mean error of around 140 km for thepositions and 0.12 km/s for the velocities is achieved. The method offers theadvantage of delivering interpretable, accurate, and complex models of orbitalmotion that can be employed for propagation or as inputs to predictive modelsfor other variables of interest, such as atmospheric drag or the probability ofcollision in an encounter with a spacecraft or space objects. In conclusion,the work demonstrates the promising potential of using SINDy to discover theequations governing the behaviour of satellites in space. The technique hasbeen successfully applied to uncover PDEs describing the motion of satellitesin LEO with high accuracy. The method possesses several advantages overtraditional models, including the ability to provide physically interpretable,accurate, and complex models of orbital motion derived from high-entropydatasets. These models can be utilised for propagation or as inputs topredictive models for other variables of interest.</description><author>João Funenga, Marta Guimarães, Henrique Costa, Cláudia Soares</author><pubDate>Thu, 16 Nov 2023 16:53:52 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.10012v1</guid></item><item><title>SQLNet: Scale-Modulated Query and Localization Network for Few-Shot Class-Agnostic Counting</title><link>http://arxiv.org/abs/2311.10011v1</link><description>The class-agnostic counting (CAC) task has recently been proposed to solvethe problem of counting all objects of an arbitrary class with severalexemplars given in the input image. To address this challenging task, existingleading methods all resort to density map regression, which renders themimpractical for downstream tasks that require object locations and restrictstheir ability to well explore the scale information of exemplars forsupervision. To address the limitations, we propose a novel localization-basedCAC approach, termed Scale-modulated Query and Localization Network (SQLNet).It fully explores the scales of exemplars in both the query and localizationstages and achieves effective counting by accurately locating each object andpredicting its approximate size. Specifically, during the query stage, richdiscriminative representations of the target class are acquired by theHierarchical Exemplars Collaborative Enhancement (HECE) module from the fewexemplars through multi-scale exemplar cooperation with equifrequent sizeprompt embedding. These representations are then fed into the Exemplars-UnifiedQuery Correlation (EUQC) module to interact with the query features in aunified manner and produce the correlated query tensor. In the localizationstage, the Scale-aware Multi-head Localization (SAML) module utilizes the querytensor to predict the confidence, location, and size of each potential object.Moreover, a scale-aware localization loss is introduced, which exploitsflexible location associations and exemplar scales for supervision to optimizethe model performance. Extensive experiments demonstrate that SQLNetoutperforms state-of-the-art methods on popular CAC benchmarks, achievingexcellent performance not only in counting accuracy but also in localizationand bounding box generation. Our codes will be available athttps://github.com/HCPLab-SYSU/SQLNet</description><author>Hefeng Wu, Yandong Chen, Lingbo Liu, Tianshui Chen, Keze Wang, Liang Lin</author><pubDate>Thu, 16 Nov 2023 16:50:56 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.10011v1</guid></item><item><title>Let's Sample Step by Step: Adaptive-Consistency for Efficient Reasoning and Coding with LLMs</title><link>http://arxiv.org/abs/2305.11860v2</link><description>A popular approach for improving the correctness of output from largelanguage models (LLMs) is Self-Consistency - poll the LLM multiple times andoutput the most frequent solution. Existing Self-Consistency techniques alwaysgenerate a constant number of samples per question, where a better approachwill be to non-uniformly distribute the available budget based on the amount ofagreement in the samples generated so far. In response, we introduceAdaptive-Consistency, a cost-efficient, model-agnostic technique thatdynamically adjusts the number of samples per question using a lightweightstopping criterion. Our experiments over 17 reasoning and code generationdatasets and three LLMs demonstrate that Adaptive-Consistency reduces samplebudget by up to 7.9 times with an average accuracy drop of less than 0.1%. Ourcode and data are available at https://www.sample-step-by-step.info</description><author>Pranjal Aggarwal, Aman Madaan, Yiming Yang, Mausam</author><pubDate>Thu, 16 Nov 2023 16:47:05 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.11860v2</guid></item><item><title>Reversible Graph Neural Network-based Reaction Distribution Learning for Multiple Appropriate Facial Reactions Generation</title><link>http://arxiv.org/abs/2305.15270v3</link><description>Generating facial reactions in a human-human dyadic interaction is complexand highly dependent on the context since more than one facial reactions can beappropriate for the speaker's behaviour. This has challenged existing machinelearning (ML) methods, whose training strategies enforce models to reproduce aspecific (not multiple) facial reaction from each input speaker behaviour. Thispaper proposes the first multiple appropriate facial reaction generationframework that re-formulates the one-to-many mapping facial reaction generationproblem as a one-to-one mapping problem. This means that we approach thisproblem by considering the generation of a distribution of the listener'sappropriate facial reactions instead of multiple different appropriate facialreactions, i.e., 'many' appropriate facial reaction labels are summarised as'one' distribution label during training. Our model consists of a perceptualprocessor, a cognitive processor, and a motor processor. The motor processor isimplemented with a novel Reversible Multi-dimensional Edge Graph Neural Network(REGNN). This allows us to obtain a distribution of appropriate real facialreactions during the training process, enabling the cognitive processor to betrained to predict the appropriate facial reaction distribution. At theinference stage, the REGNN decodes an appropriate facial reaction by using thisdistribution as input. Experimental results demonstrate that our approachoutperforms existing models in generating more appropriate, realistic, andsynchronized facial reactions. The improved performance is largely attributedto the proposed appropriate facial reaction distribution learning strategy andthe use of a REGNN. The code is available athttps://github.com/TongXu-05/REGNN-Multiple-Appropriate-Facial-Reaction-Generation.</description><author>Tong Xu, Micol Spitale, Hao Tang, Lu Liu, Hatice Gunes, Siyang Song</author><pubDate>Thu, 16 Nov 2023 16:45:45 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.15270v3</guid></item><item><title>Investigating the Corruption Robustness of Image Classifiers with Random Lp-norm Corruptions</title><link>http://arxiv.org/abs/2305.05400v2</link><description>Robustness is a fundamental property of machine learning classifiers toachieve safety and reliability. In the fields of adversarial robustness andformal robustness verification of image classification models, robustness iscommonly defined as the stability to all input variations within an Lp-normdistance. However, robustness to random corruptions is usually improved andevaluated using variations observed in the real-world, while mathematicallydefined Lp-norm corruptions are rarely considered. This study investigates theuse of random Lp-norm corruptions to augment the training and test data ofimage classifiers. We adapt an approach from the field of adversarialrobustness to assess the model robustness to imperceptible random corruptions.We empirically and theoretically investigate whether robustness is transferableacross different Lp-norms and derive conclusions on which Lp-norm corruptions amodel should be trained and evaluated on. We find that training dataaugmentation with L0-norm corruptions improves corruption robustness whilemaintaining accuracy compared to standard training and when applied on top ofselected state-of-the-art data augmentation techniques.</description><author>Georg Siedel, Weijia Shao, Silvia Vock, Andrey Morozov</author><pubDate>Thu, 16 Nov 2023 16:37:06 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.05400v2</guid></item><item><title>Straggler-resilient Federated Learning: Tackling Computation Heterogeneity with Layer-wise Partial Model Training in Mobile Edge Network</title><link>http://arxiv.org/abs/2311.10002v1</link><description>Federated Learning (FL) enables many resource-limited devices to train amodel collaboratively without data sharing. However, many existing works focuson model-homogeneous FL, where the global and local models are the same size,ignoring the inherently heterogeneous computational capabilities of differentdevices and restricting resource-constrained devices from contributing to FL.In this paper, we consider model-heterogeneous FL and propose Federated PartialModel Training (FedPMT), where devices with smaller computational capabilitieswork on partial models (subsets of the global model) and contribute to theglobal model. Different from Dropout-based partial model generation, whichremoves neurons in hidden layers at random, model training in FedPMT isachieved from the back-propagation perspective. As such, all devices in FedPMTprioritize the most crucial parts of the global model. Theoretical analysisshows that the proposed partial model training design has a similar convergencerate to the widely adopted Federated Averaging (FedAvg) algorithm,$\mathcal{O}(1/T)$, with the sub-optimality gap enlarged by a constant factorrelated to the model splitting design in FedPMT. Empirical results show thatFedPMT significantly outperforms the existing benchmark FedDrop. Meanwhile,compared to the popular model-homogeneous benchmark, FedAvg, FedPMT reaches thelearning target in a shorter completion time, thus achieving a better trade-offbetween learning accuracy and completion time.</description><author>Hongda Wu, Ping Wang, C V Aswartha Narayana</author><pubDate>Thu, 16 Nov 2023 16:30:04 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.10002v1</guid></item><item><title>TransFusion -- A Transparency-Based Diffusion Model for Anomaly Detection</title><link>http://arxiv.org/abs/2311.09999v1</link><description>Surface anomaly detection is a vital component in manufacturing inspection.Reconstructive anomaly detection methods restore the normal appearance of anobject, ideally modifying only the anomalous regions. Due to the limitations ofcommonly used reconstruction architectures, the produced reconstructions areoften poor and either still contain anomalies or lack details in anomaly-freeregions. Recent reconstructive methods adopt diffusion models, however with thestandard diffusion process the problems are not adequately addressed. Wepropose a novel transparency-based diffusion process, where the transparency ofanomalous regions is progressively increased, restoring their normal appearanceaccurately and maintaining the appearance of anomaly-free regions without lossof detail. We propose TRANSparency DifFUSION (TransFusion), a discriminativeanomaly detection method that implements the proposed diffusion process,enabling accurate downstream anomaly detection. TransFusion achievesstate-of-the-art performance on both the VisA and the MVTec AD datasets, withan image-level AUROC of 98.5% and 99.2%, respectively.</description><author>Matic Fučka, Vitjan Zavrtanik, Danijel Skočaj</author><pubDate>Thu, 16 Nov 2023 16:23:11 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.09999v1</guid></item><item><title>Learning to Reconstruct Signals From Binary Measurements</title><link>http://arxiv.org/abs/2303.08691v3</link><description>Recent advances in unsupervised learning have highlighted the possibility oflearning to reconstruct signals from noisy and incomplete linear measurementsalone. These methods play a key role in medical and scientific imaging andsensing, where ground truth data is often scarce or difficult to obtain.However, in practice, measurements are not only noisy and incomplete but alsoquantized. Here we explore the extreme case of learning from binaryobservations and provide necessary and sufficient conditions on the number ofmeasurements required for identifying a set of signals from incomplete binarydata. Our results are complementary to existing bounds on signal recovery frombinary measurements. Furthermore, we introduce a novel self-supervised learningapproach, which we name SSBM, that only requires binary data for training. Wedemonstrate in a series of experiments with real datasets that SSBM performs onpar with supervised learning and outperforms sparse reconstruction methods witha fixed wavelet basis by a large margin.</description><author>Julián Tachella, Laurent Jacques</author><pubDate>Thu, 16 Nov 2023 16:17:09 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2303.08691v3</guid></item><item><title>DeepEMD: A Transformer-based Fast Estimation of the Earth Mover's Distance</title><link>http://arxiv.org/abs/2311.09998v1</link><description>The Earth Mover's Distance (EMD) is the measure of choice between pointclouds. However the computational cost to compute it makes it prohibitive as atraining loss, and the standard approach is to use a surrogate such as theChamfer distance. We propose an attention-based model to compute an accurateapproximation of the EMD that can be used as a training loss for generativemodels. To get the necessary accurate estimation of the gradients we train ourmodel to explicitly compute the matching between point clouds instead of EMDitself. We cast this new objective as the estimation of an attention matrixthat approximates the ground truth matching matrix. Experiments show that thismodel provides an accurate estimate of the EMD and its gradient with a wallclock speed-up of more than two orders of magnitude with respect to the exactHungarian matching algorithm and one order of magnitude with respect to thestandard approximate Sinkhorn algorithm, allowing in particular to train apoint cloud VAE with the EMD itself. Extensive evaluation show the remarkablebehaviour of this model when operating out-of-distribution, a key requirementfor a distance surrogate. Finally, the model generalizes very well to pointclouds during inference several times larger than during training.</description><author>Atul Kumar Sinha, Francois Fleuret</author><pubDate>Thu, 16 Nov 2023 16:14:58 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.09998v1</guid></item><item><title>Co-data Learning for Bayesian Additive Regression Trees</title><link>http://arxiv.org/abs/2311.09997v1</link><description>Medical prediction applications often need to deal with small sample sizescompared to the number of covariates. Such data pose problems for predictionand variable selection, especially when the covariate-response relationship iscomplicated. To address these challenges, we propose to incorporate co-data,i.e. external information on the covariates, into Bayesian additive regressiontrees (BART), a sum-of-trees prediction model that utilizes priors on the treeparameters to prevent overfitting. To incorporate co-data, an empirical Bayes(EB) framework is developed that estimates, assisted by a co-data model, priorcovariate weights in the BART model. The proposed method can handle multipletypes of co-data simultaneously. Furthermore, the proposed EB framework enablesthe estimation of the other hyperparameters of BART as well, rendering anappealing alternative to cross-validation. We show that the method findsrelevant covariates and that it improves prediction compared to default BART insimulations. If the covariate-response relationship is nonlinear, the methodbenefits from the flexibility of BART to outperform regression-based co-datalearners. Finally, the use of co-data enhances prediction in an application todiffuse large B-cell lymphoma prognosis based on clinical covariates, genemutations, DNA translocations, and DNA copy number data. Keywords: Bayesian additive regression trees; Empirical Bayes; Co-data;High-dimensional data; Omics; Prediction</description><author>Jeroen M. Goedhart, Thomas Klausch, Jurriaan Janssen, Mark A. van de Wiel</author><pubDate>Thu, 16 Nov 2023 16:14:39 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.09997v1</guid></item><item><title>Making first order linear logic a generating grammar</title><link>http://arxiv.org/abs/2206.08955v5</link><description>It is known that different categorial grammars have surface representation ina fragment of first order multiplicative linear logic (MLL1). We show that thefragment of interest is equivalent to the recently introduced extended tensortype calculus (ETTC). ETTC is a calculus of specific typed terms, whichrepresent tuples of strings, more precisely bipartite graphs decorated withstrings. Types are derived from linear logic formulas, and rules correspond toconcrete operations on these string-labeled graphs, so that they can beconveniently visualized. This provides the above mentioned fragment of MLL1that is relevant for language modeling not only with some alternative syntaxand intuitive geometric representation, but also with an intrinsic deductivesystem, which has been absent. In this work we consider a non-trivial notationally enriched variation of thepreviously introduced ETTC, which allows more concise and transparentcomputations. We present both a cut-free sequent calculus and a naturaldeduction formalism.</description><author>Sergey Slavnov</author><pubDate>Thu, 16 Nov 2023 16:13:27 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2206.08955v5</guid></item><item><title>SonoSAMTrack -- Segment and Track Anything on Ultrasound Images</title><link>http://arxiv.org/abs/2310.16872v3</link><description>In this paper, we present SonoSAMTrack - that combines a promptablefoundational model for segmenting objects of interest on ultrasound imagescalled SonoSAM, with a state-of-the art contour tracking model to propagatesegmentations on 2D+t and 3D ultrasound datasets. Fine-tuned and testedexclusively on a rich, diverse set of objects from $\approx200$k ultrasoundimage-mask pairs, SonoSAM demonstrates state-of-the-art performance on 7 unseenultrasound data-sets, outperforming competing methods by a significant margin.We also extend SonoSAM to 2-D +t applications and demonstrate superiorperformance making it a valuable tool for generating dense annotations andsegmentation of anatomical structures in clinical workflows. Further, toincrease practical utility of the work, we propose a two-step process offine-tuning followed by knowledge distillation to a smaller footprint modelwithout comprising the performance. We present detailed qualitative andquantitative comparisons of SonoSAM with state-of-the-art methods showcasingefficacy of the method. This is followed by demonstrating the reduction innumber of clicks in a dense video annotation problem of adult cardiacultrasound chamber segmentation using SonoSAMTrack.</description><author>Hariharan Ravishankar, Rohan Patil, Vikram Melapudi, Harsh Suthar, Stephan Anzengruber, Parminder Bhatia, Kass-Hout Taha, Pavan Annangi</author><pubDate>Thu, 16 Nov 2023 16:12:46 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.16872v3</guid></item><item><title>Towards more Practical Threat Models in Artificial Intelligence Security</title><link>http://arxiv.org/abs/2311.09994v1</link><description>Recent works have identified a gap between research and practice inartificial intelligence security: threats studied in academia do not alwaysreflect the practical use and security risks of AI. For example, while modelsare often studied in isolation, they form part of larger ML pipelines inpractice. Recent works also brought forward that adversarial manipulationsintroduced by academic attacks are impractical. We take a first step towardsdescribing the full extent of this disparity. To this end, we revisit thethreat models of the six most studied attacks in AI security research and matchthem to AI usage in practice via a survey with \textbf{271} industrialpractitioners. On the one hand, we find that all existing threat models areindeed applicable. On the other hand, there are significant mismatches:research is often too generous with the attacker, assuming access toinformation not frequently available in real-world settings. Our paper is thusa call for action to study more practical threat models in artificialintelligence security.</description><author>Kathrin Grosse, Lukas Bieringer, Tarek Richard Besold, Alexandre Alahi</author><pubDate>Thu, 16 Nov 2023 16:09:44 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.09994v1</guid></item><item><title>Generative AI for Hate Speech Detection: Evaluation and Findings</title><link>http://arxiv.org/abs/2311.09993v1</link><description>Automatic hate speech detection using deep neural models is hampered by thescarcity of labeled datasets, leading to poor generalization. To mitigate thisproblem, generative AI has been utilized to generate large amounts of synthetichate speech sequences from available labeled examples, leveraging the generateddata in finetuning large pre-trained language models (LLMs). In this chapter,we provide a review of relevant methods, experimental setups and evaluation ofthis approach. In addition to general LLMs, such as BERT, RoBERTa and ALBERT,we apply and evaluate the impact of train set augmentation with generated datausing LLMs that have been already adapted for hate detection, includingRoBERTa-Toxicity, HateBERT, HateXplain, ToxDect, and ToxiGen. An empiricalstudy corroborates our previous findings, showing that this approach improveshate speech generalization, boosting recall performance across datadistributions. In addition, we explore and compare the performance of thefinetuned LLMs with zero-shot hate detection using a GPT-3.5 model. Our resultsdemonstrate that while better generalization is achieved using the GPT-3.5model, it achieves mediocre recall and low precision on most datasets. It is anopen question whether the sensitivity of models such as GPT-3.5, and onward,can be improved using similar techniques of text generation.</description><author>Sagi Pendzel, Tomer Wullach, Amir Adler, Einat Minkov</author><pubDate>Thu, 16 Nov 2023 16:09:43 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.09993v1</guid></item><item><title>Xputer: Bridging Data Gaps with NMF, XGBoost, and a Streamlined GUI Experience</title><link>http://arxiv.org/abs/2311.09989v1</link><description>The rapid proliferation of data across diverse fields has accentuated theimportance of accurate imputation for missing values. This task is crucial forensuring data integrity and deriving meaningful insights. In response to thischallenge, we present Xputer, a novel imputation tool that adeptly integratesNon-negative Matrix Factorization (NMF) with the predictive strengths ofXGBoost. One of Xputer's standout features is its versatility: it supports zeroimputation, enables hyperparameter optimization through Optuna, and allowsusers to define the number of iterations. For enhanced user experience andaccessibility, we have equipped Xputer with an intuitive Graphical UserInterface (GUI) ensuring ease of handling, even for those less familiar withcomputational tools. In performance benchmarks, Xputer not only rivals thecomputational speed of established tools such as IterativeImputer but alsooften outperforms them in terms of imputation accuracy. Furthermore, Xputerautonomously handles a diverse spectrum of data types, including categorical,continuous, and Boolean, eliminating the need for prior preprocessing. Givenits blend of performance, flexibility, and user-friendly design, Xputer emergesas a state-of-the-art solution in the realm of data imputation.</description><author>Saleena Younus, Lars Rönnstrand, Julhash U. Kazi</author><pubDate>Thu, 16 Nov 2023 16:07:19 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.09989v1</guid></item><item><title>Emotionally Numb or Empathetic? Evaluating How LLMs Feel Using EmotionBench</title><link>http://arxiv.org/abs/2308.03656v2</link><description>Recently, the community has witnessed the advancement of Large LanguageModels (LLMs), which have shown remarkable performance on various downstreamtasks. Led by powerful models like ChatGPT and Claude, LLMs are revolutionizinghow users engage with software, assuming more than mere tools but intelligentassistants. Consequently, evaluating LLMs' anthropomorphic capabilities becomesincreasingly important in contemporary discourse. Utilizing the emotionappraisal theory from psychology, we propose to evaluate the empathy ability ofLLMs, i.e., how their feelings change when presented with specific situations.After a careful and comprehensive survey, we collect a dataset containing over400 situations that have proven effective in eliciting the eight emotionscentral to our study. Categorizing the situations into 36 factors, we conduct ahuman evaluation involving more than 1,200 subjects worldwide. With the humanevaluation results as references, our evaluation includes five LLMs, coveringboth commercial and open-source models, including variations in model sizes,featuring the latest iterations, such as GPT-4 and LLaMA 2. A conclusion can bedrawn from the results that, despite several misalignments, LLMs can generallyrespond appropriately to certain situations. Nevertheless, they fall short inalignment with the emotional behaviors of human beings and cannot establishconnections between similar situations. Our collected dataset of situations,the human evaluation results, and the code of our testing framework, dubbedEmotionBench, is made publicly in https://github.com/CUHK-ARISE/EmotionBench.We aspire to contribute to the advancement of LLMs regarding better alignmentwith the emotional behaviors of human beings, thereby enhancing their utilityand applicability as intelligent assistants.</description><author>Jen-tse Huang, Man Ho Lam, Eric John Li, Shujie Ren, Wenxuan Wang, Wenxiang Jiao, Zhaopeng Tu, Michael R. Lyu</author><pubDate>Thu, 16 Nov 2023 16:04:22 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2308.03656v2</guid></item><item><title>Unambiguity and Fewness for Nonuniform Families of Polynomial-Size Nondeterministic Finite Automata</title><link>http://arxiv.org/abs/2311.09979v1</link><description>Nonuniform families of polynomial-size finite automata, which are series ofindexed finite automata having polynomially many inner states, are used in thepast literature to solve nonuniform families of promise decision problems.Among such nonuniform families of finite automata, we focus our attention, inparticular, on the variants of nondeterministic finite automata, which have atmost "one" (unambiguous), "polynomially many" (few) accepting computationpaths, or unambiguous/few computation paths leading to each fixedconfiguration. When such machines are limited to make only one-way head moves,we can prove with no unproven hardness assumptions that some of these variantsare different in computational power from each other. As for two-way machinesrestricted to instances of polynomially-bounded length, families of two-waypolynomial-size nondeterministic finite automata are equivalent in power tofamilies of polynomial-size unambiguous finite automata.</description><author>Tomoyuki Yamakami</author><pubDate>Thu, 16 Nov 2023 15:52:24 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.09979v1</guid></item><item><title>From Pretext to Purpose: Batch-Adaptive Self-Supervised Learning</title><link>http://arxiv.org/abs/2311.09974v1</link><description>In recent years, self-supervised contrastive learning has emerged as adistinguished paradigm in the artificial intelligence landscape. It facilitatesunsupervised feature learning through contrastive delineations at the instancelevel. However, crafting an effective self-supervised paradigm remains apivotal challenge within this field. This paper delves into two crucial factorsimpacting self-supervised contrastive learning-bach size and pretext tasks, andfrom a data processing standpoint, proposes an adaptive technique of batchfusion. The proposed method, via dimensionality reduction and reconstruction ofbatch data, enables formerly isolated individual data to partake in intra-batchcommunication through the Embedding Layer. Moreover, it adaptively amplifiesthe self-supervised feature encoding capability as the training progresses. Weconducted a linear classification test of this method based on the classiccontrastive learning framework on ImageNet-1k. The empirical findingsillustrate that our approach achieves state-of-the-art performance underequitable comparisons. Benefiting from its "plug-and-play" characteristics, wefurther explored other contrastive learning methods. On the ImageNet-100,compared to the original performance, the top1 has seen a maximum increase of1.25%. We suggest that the proposed method may contribute to the advancement ofdata-driven self-supervised learning research, bringing a fresh perspective tothis community.</description><author>Jiansong Zhang, Peizhong Liu</author><pubDate>Thu, 16 Nov 2023 15:47:49 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.09974v1</guid></item><item><title>One-Shot Federated Learning with Classifier-Guided Diffusion Models</title><link>http://arxiv.org/abs/2311.08870v2</link><description>One-shot federated learning (OSFL) has gained attention in recent years dueto its low communication cost. However, most of the existing methods requireauxiliary datasets or training generators, which hinders their practicality inreal-world scenarios. In this paper, we explore the novel opportunities thatdiffusion models bring to OSFL and propose FedCADO, utilizing guidance fromclient classifiers to generate data that complies with clients' distributionsand subsequently training the aggregated model on the server. Specifically, ourmethod involves targeted optimizations in two aspects. On one hand, weconditionally edit the randomly sampled initial noises, embedding them withspecified semantics and distributions, resulting in a significant improvementin both the quality and stability of generation. On the other hand, we employthe BN statistics from the classifiers to provide detailed guidance duringgeneration. These tailored optimizations enable us to limitlessly generatedatasets, which closely resemble the distribution and quality of the originalclient dataset. Our method effectively handles the heterogeneous client modelsand the problems of non-IID features or labels. In terms of privacy protection,our method avoids training any generator or transferring any auxiliaryinformation on clients, eliminating any additional privacy leakage risks.Leveraging the extensive knowledge stored in the pre-trained diffusion model,the synthetic datasets can assist us in surpassing the knowledge limitations ofthe client samples, resulting in aggregation models that even outperform theperformance ceiling of centralized training in some cases, which isconvincingly demonstrated in the sufficient quantification and visualizationexperiments conducted on three large-scale multi-domain image datasets.</description><author>Mingzhao Yang, Shangchao Su, Bin Li, Xiangyang Xue</author><pubDate>Thu, 16 Nov 2023 15:43:52 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.08870v2</guid></item><item><title>SurgPLAN: Surgical Phase Localization Network for Phase Recognition</title><link>http://arxiv.org/abs/2311.09965v1</link><description>Surgical phase recognition is crucial to providing surgery understanding insmart operating rooms. Despite great progress in automatic surgical phaserecognition, most existing methods are still restricted by two problems. First,these methods cannot capture discriminative visual features for each frame andmotion information with simple 2D networks. Second, the frame-by-framerecognition paradigm degrades the performance due to unstable predictionswithin each phase, termed as phase shaking. To address these two challenges, wepropose a Surgical Phase LocAlization Network, named SurgPLAN, to facilitate amore accurate and stable surgical phase recognition with the principle oftemporal detection. Specifically, we first devise a Pyramid SlowFast (PSF)architecture to serve as the visual backbone to capture multi-scale spatial andtemporal features by two branches with different frame sampling rates.Moreover, we propose a Temporal Phase Localization (TPL) module to generate thephase prediction based on temporal region proposals, which ensures accurate andconsistent predictions within each surgical phase. Extensive experimentsconfirm the significant advantages of our SurgPLAN over frame-by-frameapproaches in terms of both accuracy and stability.</description><author>Xingjian Luo, You Pang, Zhen Chen, Jinlin Wu, Zongmin Zhang, Zhen Lei, Hongbin Liu</author><pubDate>Thu, 16 Nov 2023 15:39:01 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.09965v1</guid></item><item><title>Self-supervised learning of multi-omics embeddings in the low-label, high-data regime</title><link>http://arxiv.org/abs/2311.09962v1</link><description>Contrastive, self-supervised learning (SSL) is used to train a model thatpredicts cancer type from miRNA, mRNA or RPPA expression data. This model, apretrained FT-Transformer, is shown to outperform XGBoost and CatBoost,standard benchmarks for tabular data, when labelled samples are scarce but thenumber of unlabelled samples is high. This is despite the fact that thedatasets we use have $\mathcal{O}(10^{1})$ classes and$\mathcal{O}(10^{2})-\mathcal{O}(10^{4})$ features. After demonstrating theefficacy of our chosen method of self-supervised pretraining, we investigateSSL for multi-modal models. A late-fusion model is proposed, where each omicsis passed through its own sub-network, the outputs of which are averaged andpassed to the pretraining or downstream objective function. Multi-modalpretraining is shown to improve predictions from a single omics, and we arguethat this is useful for datasets with many unlabelled multi-modal samples, butfew labelled unimodal samples. Additionally, we show that pretraining eachomics-specific module individually is highly effective. This enables theapplication of the proposed model in a variety of contexts where a large amountof unlabelled data is available from each omics, but only a few labelledsamples.</description><author>Christian John Hurry, Emma Slade</author><pubDate>Thu, 16 Nov 2023 15:32:22 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.09962v1</guid></item><item><title>VertDetect: Fully End-to-End 3D Vertebral Instance Segmentation Model</title><link>http://arxiv.org/abs/2311.09958v1</link><description>Vertebral detection and segmentation are critical steps for treatmentplanning in spine surgery and radiation therapy. Accurate identification andsegmentation are complicated in imaging that does not include the full spine,in cases with variations in anatomy (T13 and/or L6 vertebrae), and in thepresence of fracture or hardware. This paper proposes VertDetect, a fullyautomated end-to-end 3D vertebral instance segmentation Convolutional NeuralNetwork (CNN) model to predict vertebral level labels and segmentations for allvertebrae present in a CT scan. The utilization of a shared CNN backboneprovides the detection and segmentation branches of the network with featuremaps containing both spinal and vertebral level information. A GraphConvolutional Network (GCN) layer is used to improve vertebral labelling byusing the known structure of the spine. This model achieved a Dice SimilarityCoefficient (DSC) of 0.883 (95% CI, 0.843-0.906) and 0.882 (95% CI,0.835-0.909) in the VerSe 2019 and 0.868 (95\% CI, 0.834-0.890) and 0.869 (95\%CI, 0.832-0.891) in the VerSe 2020 public and hidden test sets, respectively.This model achieved state-of-the-art performance for an end-to-endarchitecture, whose design facilitates the extraction of features that can besubsequently used for downstream tasks.</description><author>Geoff Klein, Michael Hardisty, Cari Whyne, Anne L. Martel</author><pubDate>Thu, 16 Nov 2023 15:29:21 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.09958v1</guid></item><item><title>Shared Growth of Graph Neural Networks via Prompted Free-direction Knowledge Distillation</title><link>http://arxiv.org/abs/2307.00534v3</link><description>Knowledge distillation (KD) has shown to be effective to boost theperformance of graph neural networks (GNNs), where the typical objective is todistill knowledge from a deeper teacher GNN into a shallower student GNN.However, it is often quite challenging to train a satisfactory deeper GNN dueto the well-known over-parametrized and over-smoothing issues, leading toinvalid knowledge transfer in practical applications. In this paper, we proposethe first Free-direction Knowledge Distillation framework via reinforcementlearning for GNNs, called FreeKD, which is no longer required to provide adeeper well-optimized teacher GNN. Our core idea is to collaboratively learntwo shallower GNNs to exchange knowledge between them. As we observe that onetypical GNN model often exhibits better and worse performances at differentnodes during training, we devise a dynamic and free-direction knowledgetransfer strategy that involves two levels of actions: 1) node-level actiondetermines the directions of knowledge transfer between the corresponding nodesof two networks; and then 2) structure-level action determines which of thelocal structures generated by the node-level actions to be propagated.Additionally, considering that different augmented graphs can potentiallycapture distinct perspectives of the graph data, we propose FreeKD-Prompt thatlearns undistorted and diverse augmentations based on prompt learning forexchanging varied knowledge. Furthermore, instead of confining knowledgeexchange within two GNNs, we develop FreeKD++ to enable free-directionknowledge transfer among multiple GNNs. Extensive experiments on five benchmarkdatasets demonstrate our approaches outperform the base GNNs in a large margin.More surprisingly, our FreeKD has comparable or even better performance thantraditional KD algorithms that distill knowledge from a deeper and strongerteacher GNN.</description><author>Kaituo Feng, Yikun Miao, Changsheng Li, Ye Yuan, Guoren Wang</author><pubDate>Thu, 16 Nov 2023 15:22:45 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.00534v3</guid></item><item><title>Score-based generative models learn manifold-like structures with constrained mixing</title><link>http://arxiv.org/abs/2311.09952v1</link><description>How do score-based generative models (SBMs) learn the data distributionsupported on a low-dimensional manifold? We investigate the score model of atrained SBM through its linear approximations and subspaces spanned by localfeature vectors. During diffusion as the noise decreases, the localdimensionality increases and becomes more varied between different samplesequences. Importantly, we find that the learned vector field mixes samples bya non-conservative field within the manifold, although it denoises with normalprojections as if there is an energy function in off-manifold directions. Ateach noise level, the subspace spanned by the local features overlap with aneffective density function. These observations suggest that SBMs can flexiblymix samples with the learned score field while carefully maintaining amanifold-like structure of the data distribution.</description><author>Li Kevin Wenliang, Ben Moran</author><pubDate>Thu, 16 Nov 2023 15:15:15 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.09952v1</guid></item><item><title>Hijacking Large Language Models via Adversarial In-Context Learning</title><link>http://arxiv.org/abs/2311.09948v1</link><description>In-context learning (ICL) has emerged as a powerful paradigm leveraging LLMsfor specific tasks by utilizing labeled examples as demonstrations in theprecondition prompts. Despite its promising performance, ICL suffers frominstability with the choice and arrangement of examples. Additionally, craftedadversarial attacks pose a notable threat to the robustness of ICL. However,existing attacks are either easy to detect, rely on external models, or lackspecificity towards ICL. To address these issues, this work introduces a noveltransferable attack for ICL, aiming to hijack LLMs to generate the targetedresponse. The proposed LLM hijacking attack leverages a gradient-based promptsearch method to learn and append imperceptible adversarial suffixes to thein-context demonstrations. Extensive experimental results on various tasks anddatasets demonstrate the effectiveness of our LLM hijacking attack, resultingin a distracted attention towards adversarial tokens, consequently leading tothe targeted unwanted outputs.</description><author>Yao Qiang, Xiangyu Zhou, Dongxiao Zhu</author><pubDate>Thu, 16 Nov 2023 15:01:48 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.09948v1</guid></item><item><title>Natural Disaster Analysis using Satellite Imagery and Social-Media Data for Emergency Response Situations</title><link>http://arxiv.org/abs/2311.09947v1</link><description>Disaster Management is one of the most promising research areas because ofits significant economic, environmental and social repercussions. This researchfocuses on analyzing different types of data (pre and post satellite images andtwitter data) related to disaster management for in-depth analysis oflocation-wise emergency requirements. This research has been divided into twostages, namely, satellite image analysis and twitter data analysis followed byintegration using location. The first stage involves pre and post disastersatellite image analysis of the location using multi-class land coversegmentation technique based on U-Net architecture. The second stage focuses onmapping the region with essential information about the disaster situation andimmediate requirements for relief operations. The severely affected regions aredemarcated and twitter data is extracted using keywords respective to thatlocation. The extraction of situational information from a large corpus of rawtweets adopts Content Word based Tweet Summarization (COWTS) technique. Anintegration of these modules using real-time location-based mapping andfrequency analysis technique gathers multi-dimensional information in theadvent of disaster occurrence such as the Kerala and Mississippi floods thatwere analyzed and validated as test cases. The novelty of this research lies inthe application of segmented satellite images for disaster relief usinghighlighted land cover changes and integration of twitter data by mapping theseregion-specific filters for obtaining a complete overview of the disaster.</description><author>Sukeerthi Mandyam, Shanmuga Priya MG, Shalini Suresh, Kavitha Srinivasan</author><pubDate>Thu, 16 Nov 2023 15:01:26 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.09947v1</guid></item><item><title>Towards More Realistic Membership Inference Attacks on Large Diffusion Models</title><link>http://arxiv.org/abs/2306.12983v2</link><description>Generative diffusion models, including Stable Diffusion and Midjourney, cangenerate visually appealing, diverse, and high-resolution images for variousapplications. These models are trained on billions of internet-sourced images,raising significant concerns about the potential unauthorized use ofcopyright-protected images. In this paper, we examine whether it is possible todetermine if a specific image was used in the training set, a problem known inthe cybersecurity community and referred to as a membership inference attack.Our focus is on Stable Diffusion, and we address the challenge of designing afair evaluation framework to answer this membership question. We propose amethodology to establish a fair evaluation setup and apply it to StableDiffusion, enabling potential extensions to other generative models. Utilizingthis evaluation setup, we execute membership attacks (both known and newlyintroduced). Our research reveals that previously proposed evaluation setups donot provide a full understanding of the effectiveness of membership inferenceattacks. We conclude that the membership inference attack remains a significantchallenge for large diffusion models (often deployed as black-box systems),indicating that related privacy and copyright issues will persist in theforeseeable future.</description><author>Jan Dubiński, Antoni Kowalczuk, Stanisław Pawlak, Przemysław Rokita, Tomasz Trzciński, Paweł Morawiecki</author><pubDate>Thu, 16 Nov 2023 14:57:58 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.12983v2</guid></item><item><title>An Attention-Based Denoising Framework for Personality Detection in Social Media Texts</title><link>http://arxiv.org/abs/2311.09945v1</link><description>In social media networks, users produce a large amount of text contentanytime, providing researchers with a valuable approach to digging forpersonality-related information. Personality detection based on user-generatedtexts is a universal method that can be used to build user portraits. Thepresence of noise in social media texts hinders personality detection. However,previous studies have not fully addressed this challenge. Inspired by thescanning reading technique, we propose an attention-based informationextraction mechanism (AIEM) for long texts, which is applied to quickly locatevaluable pieces of information, and focus more attention on the deep semanticsof key pieces. Then, we provide a novel attention-based denoising framework(ADF) for personality detection tasks and achieve state-of-the-art performanceon two commonly used datasets. Notably, we obtain an average accuracyimprovement of 10.2% on the gold standard Twitter-Myers-Briggs Type Indicator(Twitter-MBTI) dataset. We made our code publicly available on GitHub. We shedlight on how AIEM works to magnify personality-related signals.</description><author>Qirui Tang, Wenkang Jiang, Yihua Du, Lei Lin</author><pubDate>Thu, 16 Nov 2023 14:56:09 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.09945v1</guid></item><item><title>Classification of developmental and brain disorders via graph convolutional aggregation</title><link>http://arxiv.org/abs/2311.07370v2</link><description>While graph convolution based methods have become the de-facto standard forgraph representation learning, their applications to disease prediction tasksremain quite limited, particularly in the classification of neurodevelopmentaland neurodegenerative brain disorders. In this paper, we introduce anaggregator normalization graph convolutional network by leveraging aggregationin graph sampling, as well as skip connections and identity mapping. Theproposed model learns discriminative graph node representations byincorporating both imaging and non-imaging features into the graph nodes andedges, respectively, with the aim of augmenting predictive capabilities andproviding a holistic perspective on the underlying mechanisms of braindisorders. Skip connections enable the direct flow of information from theinput features to later layers of the network, while identity mapping helpsmaintain the structural information of the graph during feature learning. Webenchmark our model against several recent baseline methods on two largedatasets, Autism Brain Imaging Data Exchange (ABIDE) and Alzheimer's DiseaseNeuroimaging Initiative (ADNI), for the prediction of autism spectrum disorderand Alzheimer's disease, respectively. Experimental results demonstrate thecompetitive performance of our approach in comparison with recent baselines interms of several evaluation metrics, achieving relative improvements of 50% and13.56% in classification accuracy over graph convolutional networks on ABIDEand ADNI, respectively.</description><author>Ibrahim Salim, A. Ben Hamza</author><pubDate>Thu, 16 Nov 2023 14:55:15 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.07370v2</guid></item><item><title>Harnessing Transformers: A Leap Forward in Lung Cancer Image Detection</title><link>http://arxiv.org/abs/2311.09942v1</link><description>This paper discusses the role of Transfer Learning (TL) and transformers incancer detection based on image analysis. With the enormous evolution of cancerpatients, the identification of cancer cells in a patient's body has emerged asa trend in the field of Artificial Intelligence (AI). This process involvesanalyzing medical images, such as Computed Tomography (CT) scans and MagneticResonance Imaging (MRIs), to identify abnormal growths that may help in cancerdetection. Many techniques and methods have been realized to improve thequality and performance of cancer classification and detection, such as TL,which allows the transfer of knowledge from one task to another with the sametask or domain. TL englobes many methods, particularly those used in imageanalysis, such as transformers and Convolutional Neural Network (CNN) modelstrained on the ImageNet dataset. This paper analyzes and criticizes each methodof TL based on image analysis and compares the results of each method, showingthat transformers have achieved the best results with an accuracy of 97.41% forcolon cancer detection and 94.71% for Histopathological Lung cancer. Futuredirections for cancer detection based on image analysis are also discussed.</description><author>Amine Bechar, Youssef Elmir, Rafik Medjoudj, Yassine Himeur, Abbes Amira</author><pubDate>Thu, 16 Nov 2023 14:50:42 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.09942v1</guid></item><item><title>Representational Strengths and Limitations of Transformers</title><link>http://arxiv.org/abs/2306.02896v2</link><description>Attention layers, as commonly used in transformers, form the backbone ofmodern deep learning, yet there is no mathematical description of theirbenefits and deficiencies as compared with other architectures. In this work weestablish both positive and negative results on the representation power ofattention layers, with a focus on intrinsic complexity parameters such aswidth, depth, and embedding dimension. On the positive side, we present asparse averaging task, where recurrent networks and feedforward networks allhave complexity scaling polynomially in the input size, whereas transformersscale merely logarithmically in the input size; furthermore, we use the sameconstruction to show the necessity and role of a large embedding dimension in atransformer. On the negative side, we present a triple detection task, whereattention layers in turn have complexity scaling linearly in the input size; asthis scenario seems rare in practice, we also present natural variants that canbe efficiently solved by attention layers. The proof techniques emphasize thevalue of communication complexity in the analysis of transformers and relatedmodels, and the role of sparse averaging as a prototypical attention task,which even finds use in the analysis of triple detection.</description><author>Clayton Sanford, Daniel Hsu, Matus Telgarsky</author><pubDate>Thu, 16 Nov 2023 14:48:16 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.02896v2</guid></item><item><title>RED-DOT: Multimodal Fact-checking via Relevant Evidence Detection</title><link>http://arxiv.org/abs/2311.09939v1</link><description>Online misinformation is often multimodal in nature, i.e., it is caused bymisleading associations between texts and accompanying images. To support thefact-checking process, researchers have been recently developing automaticmultimodal methods that gather and analyze external information, evidence,related to the image-text pairs under examination. However, prior works assumedall collected evidence to be relevant. In this study, we introduce a "RelevantEvidence Detection" (RED) module to discern whether each piece of evidence isrelevant, to support or refute the claim. Specifically, we develop the"Relevant Evidence Detection Directed Transformer" (RED-DOT) and exploremultiple architectural variants (e.g., single or dual-stage) and mechanisms(e.g., "guided attention"). Extensive ablation and comparative experimentsdemonstrate that RED-DOT achieves significant improvements over thestate-of-the-art on the VERITE benchmark by up to 28.5%. Furthermore, ourevidence re-ranking and element-wise modality fusion led to RED-DOT achievingcompetitive and even improved performance on NewsCLIPings+, without the needfor numerous evidence or multiple backbone encoders. Finally, our qualitativeanalysis demonstrates that the proposed "guided attention" module has thepotential to enhance the architecture's interpretability. We release our codeat: https://github.com/stevejpapad/relevant-evidence-detection</description><author>Stefanos-Iordanis Papadopoulos, Christos Koutlis, Symeon Papadopoulos, Panagiotis C. Petrantonakis</author><pubDate>Thu, 16 Nov 2023 14:43:45 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.09939v1</guid></item><item><title>A Framework for Monitoring and Retraining Language Models in Real-World Applications</title><link>http://arxiv.org/abs/2311.09930v1</link><description>In the Machine Learning (ML) model development lifecycle, training candidatemodels using an offline holdout dataset and identifying the best model for thegiven task is only the first step. After the deployment of the selected model,continuous model monitoring and model retraining is required in many real-worldapplications. There are multiple reasons for retraining, including data orconcept drift, which may be reflected on the model performance as monitored byan appropriate metric. Another motivation for retraining is the acquisition ofincreasing amounts of data over time, which may be used to retrain and improvethe model performance even in the absence of drifts. We examine the impact ofvarious retraining decision points on crucial factors, such as modelperformance and resource utilization, in the context of MultilabelClassification models. We explain our key decision points and propose areference framework for designing an effective model retraining strategy.</description><author>Jaykumar Kasundra, Claudia Schulz, Melicaalsadat Mirsafian, Stavroula Skylaki</author><pubDate>Thu, 16 Nov 2023 14:32:18 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.09930v1</guid></item><item><title>Fast multiplication by two's complement addition of numbers represented as a set of polynomial radix 2 indexes, stored as an integer list for massively parallel computation</title><link>http://arxiv.org/abs/2311.09922v1</link><description>We demonstrate a multiplication method based on numbers represented as set ofpolynomial radix 2 indices stored as an integer list. The 'polynomial integerindex multiplication' method is a set of algorithms implemented in python code.We demonstrate the method to be faster than both the Number Theoretic Transform(NTT) and Karatsuba for multiplication within a certain bit range. Alsoimplemented in python code for comparison purposes with the polynomial radix 2integer method. We demonstrate that it is possible to express any integer orreal number as a list of integer indices, representing a finite series in basetwo. The finite series of integer index representation of a number can then bestored and distributed across multiple CPUs / GPUs. We show that operations ofaddition and multiplication can be applied as two's complement additionsoperating on the index integer representations and can be fully distributedacross a given CPU / GPU architecture. We demonstrate fully distributedarithmetic operations such that the 'polynomial integer index multiplication'method overcomes the current limitation of parallel multiplication methods. Ie,the need to share common core memory and common disk for the calculation ofresults and intermediate results.</description><author>Mark Stocks</author><pubDate>Thu, 16 Nov 2023 14:21:13 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.09922v1</guid></item><item><title>DSR-Diff: Depth Map Super-Resolution with Diffusion Model</title><link>http://arxiv.org/abs/2311.09919v1</link><description>Color-guided depth map super-resolution (CDSR) improve the spatial resolutionof a low-quality depth map with the corresponding high-quality color map,benefiting various applications such as 3D reconstruction, virtual reality, andaugmented reality. While conventional CDSR methods typically rely onconvolutional neural networks or transformers, diffusion models (DMs) havedemonstrated notable effectiveness in high-level vision tasks. In this work, wepresent a novel CDSR paradigm that utilizes a diffusion model within the latentspace to generate guidance for depth map super-resolution. The proposed methodcomprises a guidance generation network (GGN), a depth map super-resolutionnetwork (DSRN), and a guidance recovery network (GRN). The GGN is specificallydesigned to generate the guidance while managing its compactness. Additionally,we integrate a simple but effective feature fusion module and atransformer-style feature extraction module into the DSRN, enabling it toleverage guided priors in the extraction, fusion, and reconstruction ofmulti-model images. Taking into account both accuracy and efficiency, ourproposed method has shown superior performance in extensive experiments whencompared to state-of-the-art methods. Our codes will be made available athttps://github.com/shiyuan7/DSR-Diff.</description><author>Yuan Shi, Bin Xia, Rui Zhu, Qingmin Liao, Wenming Yang</author><pubDate>Thu, 16 Nov 2023 14:18:10 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.09919v1</guid></item><item><title>Impact of Spatial Frequency Based Constraints on Adversarial Robustness</title><link>http://arxiv.org/abs/2104.12679v3</link><description>Adversarial examples mainly exploit changes to input pixels to which humansare not sensitive to, and arise from the fact that models make decisions basedon uninterpretable features. Interestingly, cognitive science reports that theprocess of interpretability for human classification decision reliespredominantly on low spatial frequency components. In this paper, weinvestigate the robustness to adversarial perturbations of models enforcedduring training to leverage information corresponding to different spatialfrequency ranges. We show that it is tightly linked to the spatial frequencycharacteristics of the data at stake. Indeed, depending on the data set, thesame constraint may results in very different level of robustness (up to 0.41adversarial accuracy difference). To explain this phenomenon, we conductseveral experiments to enlighten influential factors such as the level ofsensitivity to high frequencies, and the transferability of adversarialperturbations between original and low-pass filtered inputs.</description><author>Rémi Bernhard, Pierre-Alain Moellic, Martial Mermillod, Yannick Bourrier, Romain Cohendet, Miguel Solinas, Marina Reyboz</author><pubDate>Thu, 16 Nov 2023 14:13:12 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2104.12679v3</guid></item><item><title>AMLB: an AutoML Benchmark</title><link>http://arxiv.org/abs/2207.12560v2</link><description>Comparing different AutoML frameworks is notoriously challenging and oftendone incorrectly. We introduce an open and extensible benchmark that followsbest practices and avoids common mistakes when comparing AutoML frameworks. Weconduct a thorough comparison of 9 well-known AutoML frameworks across 71classification and 33 regression tasks. The differences between the AutoMLframeworks are explored with a multi-faceted analysis, evaluating modelaccuracy, its trade-offs with inference time, and framework failures. We alsouse Bradley-Terry trees to discover subsets of tasks where the relative AutoMLframework rankings differ. The benchmark comes with an open-source tool thatintegrates with many AutoML frameworks and automates the empirical evaluationprocess end-to-end: from framework installation and resource allocation toin-depth evaluation. The benchmark uses public data sets, can be easilyextended with other AutoML frameworks and tasks, and has a website withup-to-date results.</description><author>Pieter Gijsbers, Marcos L. P. Bueno, Stefan Coors, Erin LeDell, Sébastien Poirier, Janek Thomas, Bernd Bischl, Joaquin Vanschoren</author><pubDate>Thu, 16 Nov 2023 14:12:10 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2207.12560v2</guid></item><item><title>GADBench: Revisiting and Benchmarking Supervised Graph Anomaly Detection</title><link>http://arxiv.org/abs/2306.12251v2</link><description>With a long history of traditional Graph Anomaly Detection (GAD) algorithmsand recently popular Graph Neural Networks (GNNs), it is still not clear (1)how they perform under a standard comprehensive setting, (2) whether GNNs canoutperform traditional algorithms such as tree ensembles, and (3) how abouttheir efficiency on large-scale graphs. In response, we introduce GADBench -- abenchmark tool dedicated to supervised anomalous node detection in staticgraphs. GADBench facilitates a detailed comparison across 29 distinct models onten real-world GAD datasets, encompassing thousands to millions ($\sim$6M)nodes. Our main finding is that tree ensembles with simple neighborhoodaggregation can outperform the latest GNNs tailored for the GAD task. We shedlight on the current progress of GAD, setting a robust groundwork forsubsequent investigations in this domain. GADBench is open-sourced athttps://github.com/squareRoot3/GADBench.</description><author>Jianheng Tang, Fengrui Hua, Ziqi Gao, Peilin Zhao, Jia Li</author><pubDate>Thu, 16 Nov 2023 14:05:25 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.12251v2</guid></item><item><title>Evaluating the Symbol Binding Ability of Large Language Models for Multiple-Choice Questions in Vietnamese General Education</title><link>http://arxiv.org/abs/2310.12059v3</link><description>In this paper, we evaluate the ability of large language models (LLMs) toperform multiple choice symbol binding (MCSB) for multiple choice questionanswering (MCQA) tasks in zero-shot, one-shot, and few-shot settings. We focuson Vietnamese, with fewer challenging MCQA datasets than in English. The twoexisting datasets, ViMMRC 1.0 and ViMMRC 2.0, focus on literature. Recentresearch in Vietnamese natural language processing (NLP) has focused on theVietnamese National High School Graduation Examination (VNHSGE) from 2019 to2023 to evaluate ChatGPT. However, these studies have mainly focused on howChatGPT solves the VNHSGE step by step. We aim to create a novel andhigh-quality dataset by providing structured guidelines for typing LaTeXformulas for mathematics, physics, chemistry, and biology. This dataset can beused to evaluate the MCSB ability of LLMs and smaller language models (LMs)because it is typed in a strict LaTeX style. We focus on predicting thecharacter (A, B, C, or D) that is the most likely answer to a question, giventhe context of the question. Our evaluation of six well-known LLMs, namelyBLOOMZ-7.1B-MT, LLaMA-2-7B, LLaMA-2-70B, GPT-3, GPT-3.5, and GPT-4.0, on theViMMRC 1.0 and ViMMRC 2.0 benchmarks and our proposed dataset shows promisingresults on the MCSB ability of LLMs for Vietnamese. The dataset is availablefor research purposes only.</description><author>Duc-Vu Nguyen, Quoc-Nam Nguyen</author><pubDate>Thu, 16 Nov 2023 14:04:15 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.12059v3</guid></item><item><title>Representations of epistemic uncertainty and its perception in data-driven strategies</title><link>http://arxiv.org/abs/2110.11482v6</link><description>The diffusion of AI and big data is reshaping decision-making processes byincreasing the amount of information that supports decisions while reducingdirect interaction with data and empirical evidence. This paradigm shiftintroduces new sources of uncertainty, as limited data observability results inambiguity and a lack of interpretability. The need for the proper analysis ofdata-driven strategies motivates the search for new models that can describethis type of bounded access to knowledge. This contribution presents a noveltheoretical model for uncertainty in knowledge representation and its transfermediated by agents. We provide a dynamical description of knowledge states byendowing our model with a structure to compare and combine them. Specifically,an update is represented through combinations, and its explainability is basedon its consistency in different dimensional representations. We look atinequivalent knowledge representations in terms of multiplicity of inferences,preference relations, and information measures. Furthermore, we define a formalanalogy with two scenarios that illustrate non-classical uncertainty in termsof ambiguity (Ellsberg's model) and reasoning about knowledge mediated by otheragents observing data (Wigner's friend). Finally, we discuss some implicationsof the proposed model for data-driven strategies, with special attention toreasoning under uncertainty about business value dimensions and the design ofmeasurement tools for their assessment.</description><author>Mario Angelelli, Massimiliano Gervasi</author><pubDate>Thu, 16 Nov 2023 13:58:11 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2110.11482v6</guid></item><item><title>Conditional Matrix Flows for Gaussian Graphical Models</title><link>http://arxiv.org/abs/2306.07255v2</link><description>Studying conditional independence among many variables with few observationsis a challenging task. Gaussian Graphical Models (GGMs) tackle this problem byencouraging sparsity in the precision matrix through $l_q$ regularization with$q\leq1$. However, most GMMs rely on the $l_1$ norm because the objective ishighly non-convex for sub-$l_1$ pseudo-norms. In the frequentist formulation,the $l_1$ norm relaxation provides the solution path as a function of theshrinkage parameter $\lambda$. In the Bayesian formulation, sparsity is insteadencouraged through a Laplace prior, but posterior inference for different$\lambda$ requires repeated runs of expensive Gibbs samplers. Here we propose ageneral framework for variational inference with matrix-variate NormalizingFlow in GGMs, which unifies the benefits of frequentist and Bayesianframeworks. As a key improvement on previous work, we train with one flow acontinuum of sparse regression models jointly for all regularization parameters$\lambda$ and all $l_q$ norms, including non-convex sub-$l_1$ pseudo-norms.Within one model we thus have access to (i) the evolution of the posterior forany $\lambda$ and any $l_q$ (pseudo-) norm, (ii) the marginal log-likelihoodfor model selection, and (iii) the frequentist solution paths through simulatedannealing in the MAP limit.</description><author>Marcello Massimo Negri, F. Arend Torres, Volker Roth</author><pubDate>Thu, 16 Nov 2023 13:54:59 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.07255v2</guid></item><item><title>Selection of Distinct Morphologies to Divide &amp; Conquer Gigapixel Pathology Images</title><link>http://arxiv.org/abs/2311.09902v1</link><description>Whole slide images (WSIs) are massive digital pathology files illustratingintricate tissue structures. Selecting a small, representative subset ofpatches from each WSI is essential yet challenging. Therefore, following the"Divide &amp; Conquer" approach becomes essential to facilitate WSI analysisincluding the classification and the WSI matching in computational pathology.To this end, we propose a novel method termed "Selection of DistinctMorphologies" (SDM) to choose a subset of WSI patches. The aim is to encompassall inherent morphological variations within a given WSI while simultaneouslyminimizing the number of selected patches to represent these variations,ensuring a compact yet comprehensive set of patches. This systematicallycurated patch set forms what we term a "montage". We assess therepresentativeness of the SDM montage across various public and privatehistopathology datasets. This is conducted by using the leave-one-out WSIsearch and matching evaluation method, comparing it with the state-of-the-artYottixel's mosaic. SDM demonstrates remarkable efficacy across all datasetsduring its evaluation. Furthermore, SDM eliminates the necessity for empiricalparameterization, a crucial aspect of Yottixel's mosaic, by inherentlyoptimizing the selection process to capture the distinct morphological featureswithin the WSI.</description><author>Abubakr Shafique, Saghir Alfasly, Areej Alsaafin, Peyman Nejat, Jibran A. Khan, H. R. Tizhoosh</author><pubDate>Thu, 16 Nov 2023 13:54:38 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.09902v1</guid></item><item><title>Open Problem: Learning with Variational Objectives on Measures</title><link>http://arxiv.org/abs/2306.11928v2</link><description>The theory of statistical learning has focused on variational objectivesexpressed on functions. In this note, we discuss motivations to write similarobjectives on measures, in particular to discuss out-of-distributiongeneralization and weakly-supervised learning. It raises a natural question:can one cast usual statistical learning results to objectives expressed onmeasures? Does the resulting construction lead to new algorithms of practicalinterest?</description><author>Vivien Cabannes, Carles Domingo-Enrich</author><pubDate>Thu, 16 Nov 2023 13:38:20 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.11928v2</guid></item><item><title>On some elusive aspects of databases hindering AI based discovery: A case study on superconducting materials</title><link>http://arxiv.org/abs/2311.09891v1</link><description>It stands to reason that the amount and the quality of big data is of keyimportance for setting up accurate AI-driven models. Nonetheless, we believethere are still critical roadblocks in the inherent generation of databases,that are often underestimated and poorly discussed in the literature. In ourview, such issues can seriously hinder the AI-based discovery process, evenwhen high quality, sufficiently large and highly reputable data sources areavailable. Here, considering superconducting and thermoelectric materials astwo representative case studies, we specifically discuss three aspects, namelyintrinsically biased sample selection, possible hidden variables, disparatedata age. Importantly, to our knowledge, we suggest and test a first strategycapable of detecting and quantifying the presence of the intrinsic data bias.</description><author>Giovanni Trezza, Eliodoro Chiavazzo</author><pubDate>Thu, 16 Nov 2023 13:38:00 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.09891v1</guid></item><item><title>Language Generation from Human Brain Activities</title><link>http://arxiv.org/abs/2311.09889v1</link><description>Generating human language through non-invasive brain-computer interfaces(BCIs) has the potential to unlock many applications, such as serving disabledpatients and improving communication. Currently, however, generating languagevia BCIs has been previously successful only within a classification setup forselecting pre-generated sentence continuation candidates with the most likelycortical semantic representation. Inspired by recent research that revealedassociations between the brain and the large computational language models, wepropose a generative language BCI that utilizes the capacity of a largelanguage model (LLM) jointly with a semantic brain decoder to directly generatelanguage from functional magnetic resonance imaging (fMRI) input. The proposedmodel can generate coherent language sequences aligned with the semanticcontent of visual or auditory language stimuli perceived, without priorknowledge of any pre-generated candidates. We compare the language generatedfrom the presented model with a random control, pre-generated languageselection approach, and a standard LLM, which generates common coherent textsolely based on the next word likelihood according to statistical languagetraining data. The proposed model is found to generate language that is morealigned with semantic stimulus in response to which brain input is sampled. Ourfindings demonstrate the potential and feasibility of employing BCIs in directlanguage generation.</description><author>Ziyi Ye, Qingyao Ai, Yiqun Liu, Min Zhang, Christina Lioma, Tuukka Ruotsalo</author><pubDate>Thu, 16 Nov 2023 13:37:21 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.09889v1</guid></item><item><title>Sibyl: Adaptive and Extensible Data Placement in Hybrid Storage Systems Using Online Reinforcement Learning</title><link>http://arxiv.org/abs/2205.07394v2</link><description>Hybrid storage systems (HSS) use multiple different storage devices toprovide high and scalable storage capacity at high performance. Recent researchproposes various techniques that aim to accurately identifyperformance-critical data to place it in a "best-fit" storage device.Unfortunately, most of these techniques are rigid, which (1) limits theiradaptivity to perform well for a wide range of workloads and storage deviceconfigurations, and (2) makes it difficult for designers to extend thesetechniques to different storage system configurations (e.g., with a differentnumber or different types of storage devices) than the configuration they aredesigned for. We introduce Sibyl, the first technique that uses reinforcementlearning for data placement in hybrid storage systems. Sibyl observes differentfeatures of the running workload as well as the storage devices to makesystem-aware data placement decisions. For every decision it makes, Sibylreceives a reward from the system that it uses to evaluate the long-termperformance impact of its decision and continuously optimizes its dataplacement policy online. We implement Sibyl on real systems with various HSSconfigurations. Our results show that Sibyl provides 21.6%/19.9% performanceimprovement in a performance-oriented/cost-oriented HSS configuration comparedto the best previous data placement technique. Our evaluation using an HSSconfiguration with three different storage devices shows that Sibyl outperformsthe state-of-the-art data placement policy by 23.9%-48.2%, while significantlyreducing the system architect's burden in designing a data placement mechanismthat can simultaneously incorporate three storage devices. We show that Sibylachieves 80% of the performance of an oracle policy that has complete knowledgeof future access patterns while incurring a very modest storage overhead ofonly 124.4 KiB.</description><author>Gagandeep Singh, Rakesh Nadig, Jisung Park, Rahul Bera, Nastaran Hajinazar, David Novo, Juan Gómez-Luna, Sander Stuijk, Henk Corporaal, Onur Mutlu</author><pubDate>Thu, 16 Nov 2023 13:28:25 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2205.07394v2</guid></item><item><title>On the Intrinsic Structures of Spiking Neural Networks</title><link>http://arxiv.org/abs/2207.04876v3</link><description>Recent years have emerged a surge of interest in SNNs owing to theirremarkable potential to handle time-dependent and event-driven data. Theperformance of SNNs hinges not only on selecting an apposite architecture andfine-tuning connection weights, similar to conventional ANNs, but also on themeticulous configuration of intrinsic structures within spiking computations.However, there has been a dearth of comprehensive studies examining the impactof intrinsic structures. Consequently, developers often find it challenging toapply a standardized configuration of SNNs across diverse datasets or tasks.This work delves deep into the intrinsic structures of SNNs. Initially, weunveil two pivotal components of intrinsic structures: the integrationoperation and firing-reset mechanism, by elucidating their influence on theexpressivity of SNNs. Furthermore, we draw two key conclusions: the membranetime hyper-parameter is intimately linked to the eigenvalues of the integrationoperation, dictating the functional topology of spiking dynamics, and varioushyper-parameters of the firing-reset mechanism govern the overall firingcapacity of an SNN, mitigating the injection ratio or sampling density of inputdata. These findings elucidate why the efficacy of SNNs hinges heavily on theconfiguration of intrinsic structures and lead to a recommendation thatenhancing the adaptability of these structures contributes to improving theoverall performance and applicability of SNNs. Inspired by this recognition, wepropose two feasible approaches to enhance SNN learning. These involveleveraging self-connection architectures and employing stochastic spikingneurons to augment the adaptability of the integration operation andfiring-reset mechanism, respectively. We verify the effectiveness of theproposed methods from perspectives of theory and practice.</description><author>Shao-Qun Zhang, Jia-Yi Chen, Jin-Hui Wu, Gao Zhang, Huan Xiong, Bin Gu, Zhi-Hua Zhou</author><pubDate>Thu, 16 Nov 2023 13:17:44 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2207.04876v3</guid></item><item><title>Safety Aware Autonomous Path Planning Using Model Predictive Reinforcement Learning for Inland Waterways</title><link>http://arxiv.org/abs/2311.09878v1</link><description>In recent years, interest in autonomous shipping in urban waterways hasincreased significantly due to the trend of keeping cars and trucks out of citycenters. Classical approaches such as Frenet frame based planning and potentialfield navigation often require tuning of many configuration parameters andsometimes even require a different configuration depending on the situation. Inthis paper, we propose a novel path planning approach based on reinforcementlearning called Model Predictive Reinforcement Learning (MPRL). MPRL calculatesa series of waypoints for the vessel to follow. The environment is representedas an occupancy grid map, allowing us to deal with any shape of waterway andany number and shape of obstacles. We demonstrate our approach on two scenariosand compare the resulting path with path planning using a Frenet frame and pathplanning based on a proximal policy optimization (PPO) agent. Our results showthat MPRL outperforms both baselines in both test scenarios. The PPO basedapproach was not able to reach the goal in either scenario while the Frenetframe approach failed in the scenario consisting of a corner with obstacles.MPRL was able to safely (collision free) navigate to the goal in both of thetest scenarios.</description><author>Astrid Vanneste, Simon Vanneste, Olivier Vasseur, Robin Janssens, Mattias Billast, Ali Anwar, Kevin Mets, Tom De Schepper, Siegfried Mercelis, Peter Hellinckx</author><pubDate>Thu, 16 Nov 2023 13:12:58 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.09878v1</guid></item><item><title>End-to-end Hyperspectral Image Change Detection Network Based on Band Selection</title><link>http://arxiv.org/abs/2307.12327v2</link><description>For hyperspectral image change detection (HSI-CD), one key challenge is toreduce band redundancy, as only a few bands are crucial for change detectionwhile other bands may be adverse to it. However, most existing HSI-CD methodsdirectly extract change feature from full-dimensional HSIs, suffering from adegradation of feature discrimination. To address this issue, we propose anend-to-end hyperspectral image change detection network with band selection(ECDBS), which effectively retains the critical bands to promote changedetection. The main ingredients of the network are a deep learning based bandselection module and cascading band-specific spatial attention (BSA) blocks.The band selection module can be seamlessly integrated with subsequent CDmodels for joint optimization and end-to-end reasoning, rather than as a stepseparate from change detection. The BSA block extracts features from each bandusing a tailored strategy. Unlike the typically used feature extractionstrategy that uniformly processes all bands, the BSA blocks considers thedifferences in feature distributions among widely spaced bands, thereuponextracting more sufficient change feature. Experimental evaluations conductedon three widely used HSI-CD datasets demonstrate the effectiveness andsuperiority of our proposed method over other state-of-the-art techniques.</description><author>Qingren Yao, Yuan Zhou, Chang Tang, Wei Xiang</author><pubDate>Thu, 16 Nov 2023 13:06:47 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.12327v2</guid></item><item><title>INTERVENOR: Prompt the Coding Ability of Large Language Models with the Interactive Chain of Repairing</title><link>http://arxiv.org/abs/2311.09868v1</link><description>This paper proposes INTERactiVE chaiN Of Repairing (INTERVENOR), which mimicshuman code repairing behavior (iteratively judging, rethinking, and repairing)and prompts the coding ability of regard Large Language Models (LLMs).Specifically, INTERVENOR employs two LLM based agents, Code Learner and CodeTeacher, to play different roles in code repairing and work interactively torepair the generated codes. The Code Learner is asked to generate and repaircode according to the instructions from the Code Teacher. The Code Teacherrethinks the code errors according to the corresponding feedback from compilersand iteratively generates the chain-of-repairing (CoR) to guide the coderepairing process for Code Learner. Our experiments show that INTERVENORoutperforms the state-of-the-art methods and achieves about 13% and 4.5%improvements over the GPT-3.5 model in code generation and code translationtasks, respectively. Our further analyses show that CoR can illuminate the bugreasons and solution plans via natural language. Thanks to the feedback of codecompilers, INTERVENOR can accurately identify the syntax errors and assertionerrors in the code and provide precise instructions to repair codes, makingLLMs achieve the plateau performance with only three repairing turns. All dataand codes are available at https://github.com/NEUIR/INTERVENOR</description><author>Hanbin Wang, Zhenghao Liu, Shuo Wang, Ganqu Cui, Ning Ding, Zhiyuan Liu, Ge Yu</author><pubDate>Thu, 16 Nov 2023 12:55:20 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.09868v1</guid></item><item><title>AmQA: Amharic Question Answering Dataset</title><link>http://arxiv.org/abs/2303.03290v2</link><description>Question Answering (QA) returns concise answers or answer lists from naturallanguage text given a context document. Many resources go into curating QAdatasets to advance robust models' development. There is a surge of QA datasetsfor languages like English, however, this is not true for Amharic. Amharic, theofficial language of Ethiopia, is the second most spoken Semitic language inthe world. There is no published or publicly available Amharic QA dataset.Hence, to foster the research in Amharic QA, we present the first Amharic QA(AmQA) dataset. We crowdsourced 2628 question-answer pairs over 378 Wikipediaarticles. Additionally, we run an XLMR Large-based baseline model to sparkopen-domain QA research interest. The best-performing baseline achieves anF-score of 69.58 and 71.74 in reader-retriever QA and reading comprehensionsettings respectively.</description><author>Tilahun Abedissa, Ricardo Usbeck, Yaregal Assabie</author><pubDate>Thu, 16 Nov 2023 12:47:29 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2303.03290v2</guid></item><item><title>Which Modality should I use -- Text, Motif, or Image? : Understanding Graphs with Large Language Models</title><link>http://arxiv.org/abs/2311.09862v1</link><description>Large language models (LLMs) are revolutionizing various fields by leveraginglarge text corpora for context-aware intelligence. Due to the context size,however, encoding an entire graph with LLMs is fundamentally limited. Thispaper explores how to better integrate graph data with LLMs and presents anovel approach using various encoding modalities (e.g., text, image, and motif)and approximation of global connectivity of a graph using different promptingmethods to enhance LLMs' effectiveness in handling complex graph structures.The study also introduces GraphTMI, a new benchmark for evaluating LLMs ingraph structure analysis, focusing on factors such as homophily, motifpresence, and graph difficulty. Key findings reveal that image modality,supported by advanced vision-language models like GPT-4V, is more effectivethan text in managing token limits while retaining critical information. Theresearch also examines the influence of different factors on each encodingmodality's performance. This study highlights the current limitations andcharts future directions for LLMs in graph understanding and reasoning tasks.</description><author>Debarati Das, Ishaan Gupta, Jaideep Srivastava, Dongyeop Kang</author><pubDate>Thu, 16 Nov 2023 12:45:41 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.09862v1</guid></item><item><title>PsyBench: a balanced and in-depth Psychological Chinese Evaluation Benchmark for Foundation Models</title><link>http://arxiv.org/abs/2311.09861v1</link><description>As Large Language Models (LLMs) are becoming prevalent in various fields,there is an urgent need for improved NLP benchmarks that encompass all thenecessary knowledge of individual discipline. Many contemporary benchmarks forfoundational models emphasize a broad range of subjects but often fall short inpresenting all the critical subjects and encompassing necessary professionalknowledge of them. This shortfall has led to skewed results, given that LLMsexhibit varying performance across different subjects and knowledge areas. Toaddress this issue, we present psybench, the first comprehensive Chineseevaluation suite that covers all the necessary knowledge required for graduateentrance exams. psybench offers a deep evaluation of a model's strengths andweaknesses in psychology through multiple-choice questions. Our findings showsignificant differences in performance across different sections of a subject,highlighting the risk of skewed results when the knowledge in test sets is notbalanced. Notably, only the ChatGPT model reaches an average accuracy above$70\%$, indicating that there is still plenty of room for improvement. Weexpect that psybench will help to conduct thorough evaluations of base models'strengths and weaknesses and assist in practical application in the field ofpsychology.</description><author>Junlei Zhang, Hongliang He, Nirui Song, Shuyuan He, \\Shuai Zhang, Huachuan Qiu, Anqi Li, Lizhi Ma, Zhenzhong Lan</author><pubDate>Thu, 16 Nov 2023 12:43:18 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.09861v1</guid></item><item><title>GSAP-NER: A Novel Task, Corpus, and Baseline for Scholarly Entity Extraction Focused on Machine Learning Models and Datasets</title><link>http://arxiv.org/abs/2311.09860v1</link><description>Named Entity Recognition (NER) models play a crucial role in various NLPtasks, including information extraction (IE) and text understanding. Inacademic writing, references to machine learning models and datasets arefundamental components of various computer science publications and necessitateaccurate models for identification. Despite the advancements in NER, existingground truth datasets do not treat fine-grained types like ML model and modelarchitecture as separate entity types, and consequently, baseline models cannotrecognize them as such. In this paper, we release a corpus of 100 manuallyannotated full-text scientific publications and a first baseline model for 10entity types centered around ML models and datasets. In order to provide anuanced understanding of how ML models and datasets are mentioned and utilized,our dataset also contains annotations for informal mentions like "ourBERT-based model" or "an image CNN". You can find the ground truth dataset andcode to replicate model training at https://data.gesis.org/gsap/gsap-ner.</description><author>Wolfgang Otto, Matthäus Zloch, Lu Gan, Saurav Karmakar, Stefan Dietze</author><pubDate>Thu, 16 Nov 2023 12:43:02 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.09860v1</guid></item><item><title>Towards Generalist Foundation Model for Radiology by Leveraging Web-scale 2D&amp;3D Medical Data</title><link>http://arxiv.org/abs/2308.02463v5</link><description>In this study, we aim to initiate the development of Radiology FoundationModel, termed as RadFM. We consider the construction of foundational modelsfrom three perspectives, namely, dataset construction, model design, andthorough evaluation. Our contribution can be concluded as follows: (i), weconstruct a large-scale Medical Multi-modal Dataset, MedMD, which consists of16M 2D and 3D medical scans with high-quality text descriptions or reportsacross various data formats, modalities, and tasks, covering over 5000 distinctdiseases. To the best of our knowledge, this is the first large-scale,high-quality, medical visual-language dataset, with both 2D and 3D scans; (ii),we propose an architecture that enables visually conditioned generativepre-training, i.e., allowing for integration of text input with 2D or 3Dmedical scans, and generate responses for diverse radiologic tasks. The modelwas initially pre-trained on MedMD and subsequently fine-tuned on thedomain-specific dataset, which is a radiologic cleaned version of MedMD,containing 3M radiologic visual-language pairs, termed as RadMD; (iii), wepropose a new evaluation benchmark, RadBench, that comprises five tasks,including modality recognition, disease diagnosis, visual question answering,report generation and rationale diagnosis, aiming to comprehensively assess thecapability of foundation models in handling practical clinical problems. Weconduct both automatic and human evaluation on RadBench, in both cases, RadFMoutperforms existing multi-modal foundation models, that are publicalyaccessible, including Openflamingo, MedFlamingo, MedVInT and GPT-4V.Additionally, we also adapt RadFM for different public benchmarks, surpassingexisting SOTAs on diverse datasets. All codes, data, and model checkpoint willall be made publicly available to promote further research and development inthe field.</description><author>Chaoyi Wu, Xiaoman Zhang, Ya Zhang, Yanfeng Wang, Weidi Xie</author><pubDate>Thu, 16 Nov 2023 12:38:46 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2308.02463v5</guid></item><item><title>Polynomially Over-Parameterized Convolutional Neural Networks Contain Structured Strong Winning Lottery Tickets</title><link>http://arxiv.org/abs/2311.09858v1</link><description>The Strong Lottery Ticket Hypothesis (SLTH) states that randomly-initialisedneural networks likely contain subnetworks that perform well without anytraining. Although unstructured pruning has been extensively studied in thiscontext, its structured counterpart, which can deliver significantcomputational and memory efficiency gains, has been largely unexplored. One ofthe main reasons for this gap is the limitations of the underlying mathematicaltools used in formal analyses of the SLTH. In this paper, we overcome theselimitations: we leverage recent advances in the multidimensional generalisationof the Random Subset-Sum Problem and obtain a variant that admits thestochastic dependencies that arise when addressing structured pruning in theSLTH. We apply this result to prove, for a wide class of random ConvolutionalNeural Networks, the existence of structured subnetworks that can approximateany sufficiently smaller network. This result provides the first sub-exponential bound around the SLTH forstructured pruning, opening up new avenues for further research on thehypothesis and contributing to the understanding of the role ofover-parameterization in deep learning.</description><author>Arthur da Cunha, Francesco d'Amore, Emanuele Natale</author><pubDate>Thu, 16 Nov 2023 12:38:45 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.09858v1</guid></item><item><title>A Critical Survey on Fairness Benefits of XAI</title><link>http://arxiv.org/abs/2310.13007v3</link><description>In this critical survey, we analyze typical claims on the relationshipbetween explainable AI (XAI) and fairness to disentangle the multidimensionalrelationship between these two concepts. Based on a systematic literaturereview and a subsequent qualitative content analysis, we identify sevenarchetypal claims from 175 papers on the alleged fairness benefits of XAI. Wepresent crucial caveats with respect to these claims and provide an entry pointfor future discussions around the potentials and limitations of XAI forspecific fairness desiderata. While the literature often suggests XAI to be anenabler for several fairness desiderata, we notice a divide between thesedesiderata and the capabilities of XAI. We encourage to conceive XAI as one ofmany tools to approach the multidimensional, sociotechnical challenge ofalgorithmic fairness and to be more specific about how exactly what kind of XAImethod enables whom to address which fairness desideratum.</description><author>Luca Deck, Jakob Schoeffer, Maria De-Arteaga, Niklas Kühl</author><pubDate>Thu, 16 Nov 2023 12:35:41 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.13007v3</guid></item><item><title>An Overview Of Temporal Commonsense Reasoning and Acquisition</title><link>http://arxiv.org/abs/2308.00002v3</link><description>Temporal commonsense reasoning refers to the ability to understand thetypical temporal context of phrases, actions, and events, and use it to reasonover problems requiring such knowledge. This trait is essential in temporalnatural language processing tasks, with possible applications such as timelinesummarization, temporal question answering, and temporal natural languageinference. Recent research on the performance of large language models suggeststhat, although they are adept at generating syntactically correct sentences andsolving classification tasks, they often take shortcuts in their reasoning andfall prey to simple linguistic traps. This article provides an overview ofresearch in the domain of temporal commonsense reasoning, particularly focusingon enhancing language model performance through a variety of augmentations andtheir evaluation across a growing number of datasets. However, these augmentedmodels still struggle to approach human performance on reasoning tasks overtemporal common sense properties, such as the typical occurrence times,orderings, or durations of events. We further emphasize the need for carefulinterpretation of research to guard against overpromising evaluation results inlight of the shallow reasoning present in transformers. This can be achieved byappropriately preparing datasets and suitable evaluation metrics.</description><author>Georg Wenzel, Adam Jatowt</author><pubDate>Thu, 16 Nov 2023 12:33:12 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2308.00002v3</guid></item><item><title>Contribution Evaluation in Federated Learning: Examining Current Approaches</title><link>http://arxiv.org/abs/2311.09856v1</link><description>Federated Learning (FL) has seen increasing interest in cases where entitieswant to collaboratively train models while maintaining privacy and governanceover their data. In FL, clients with private and potentially heterogeneous dataand compute resources come together to train a common model without raw dataever leaving their locale. Instead, the participants contribute by sharinglocal model updates, which, naturally, differ in quality. Quantitativelyevaluating the worth of these contributions is termed the ContributionEvaluation (CE) problem. We review current CE approaches from the underlyingmathematical framework to efficiently calculate a fair value for each client.Furthermore, we benchmark some of the most promising state-of-the-artapproaches, along with a new one we introduce, on MNIST and CIFAR-10, toshowcase their differences. Designing a fair and efficient CE method, while asmall part of the overall FL system design, is tantamount to the mainstreamadoption of FL.</description><author>Vasilis Siomos, Jonathan Passerat-Palmbach</author><pubDate>Thu, 16 Nov 2023 12:32:44 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.09856v1</guid></item><item><title>SurvTimeSurvival: Survival Analysis On The Patient With Multiple Visits/Records</title><link>http://arxiv.org/abs/2311.09854v1</link><description>The accurate prediction of survival times for patients with severe diseasesremains a critical challenge despite recent advances in artificialintelligence. This study introduces "SurvTimeSurvival: Survival Analysis OnPatients With Multiple Visits/Records", utilizing the Transformer model to notonly handle the complexities of time-varying covariates but also covariatesdata. We also tackle the data sparsity issue common to survival analysisdatasets by integrating synthetic data generation into the learning process ofour model. We show that our method outperforms state-of-the-art deep learningapproaches on both covariates and time-varying covariates datasets. Ourapproach aims not only to enhance the understanding of individual patientsurvival trajectories across various medical conditions, thereby improvingprediction accuracy, but also to play a pivotal role in designing clinicaltrials and creating new treatments.</description><author>Hung Le, Ong Eng-Jon, Bober Miroslaw</author><pubDate>Thu, 16 Nov 2023 12:30:14 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.09854v1</guid></item><item><title>Short vs. Long-term Coordination of Drones: When Distributed Optimization Meets Deep Reinforcement Learning</title><link>http://arxiv.org/abs/2311.09852v1</link><description>Swarms of smart drones, with the support of charging technology, can providecompleting sensing capabilities in Smart Cities, such as traffic monitoring anddisaster response. Existing approaches, including distributed optimization anddeep reinforcement learning (DRL), aim to coordinate drones to achievecost-effective, high-quality navigation, sensing, and recharging. However, theyhave distinct challenges: short-term optimization struggles to providesustained benefits, while long-term DRL lacks scalability, resilience, andflexibility. To bridge this gap, this paper introduces a new progressiveapproach that encompasses the planning and selection based on distributedoptimization, as well as DRL-based flying direction scheduling. Extensiveexperiment with datasets generated from realisitic urban mobility demonstratethe outstanding performance of the proposed solution in traffic monitoringcompared to three baseline methods.</description><author>Chuhao Qin, Evangelos Pournaras</author><pubDate>Thu, 16 Nov 2023 12:28:31 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.09852v1</guid></item><item><title>Urban traffic congestion control: a DeePC change</title><link>http://arxiv.org/abs/2311.09851v1</link><description>Urban traffic congestion remains a pressing challenge in our rapidlyexpanding cities, despite the abundance of available data and the efforts ofpolicymakers. By leveraging behavioral system theory and data-driven control,this paper exploits the DeePC algorithm in the context of urban traffic controlperformed via dynamic traffic lights. To validate our approach, we consider ahigh-fidelity case study using the state-of-the-art simulation software packageSimulation of Urban MObility (SUMO). Preliminary results indicate that DeePCoutperforms existing approaches across various key metrics, including traveltime and CO$_2$ emissions, demonstrating its potential for effective trafficmanagement</description><author>Alessio Rimoldi, Carlo Cenedese, Alberto Padoan, Florian Dörfler, John Lygeros</author><pubDate>Thu, 16 Nov 2023 12:26:55 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.09851v1</guid></item><item><title>Clinical Characteristics and Laboratory Biomarkers in ICU-admitted Septic Patients with and without Bacteremia</title><link>http://arxiv.org/abs/2311.08433v2</link><description>Few studies have investigated the diagnostic utilities of biomarkers forpredicting bacteremia among septic patients admitted to intensive care units(ICU). Therefore, this study evaluated the prediction power of laboratorybiomarkers to utilize those markers with high performance to optimize thepredictive model for bacteremia. This retrospective cross-sectional study wasconducted at the ICU department of Gyeongsang National University ChangwonHospital in 2019. Adult patients qualifying SEPSIS-3 (increase in sequentialorgan failure score greater than or equal to 2) criteria with at least two setsof blood culture were selected. Collected data was initially analyzedindependently to identify the significant predictors, which was then used tobuild the multivariable logistic regression (MLR) model. A total of 218patients with 48 cases of true bacteremia were analyzed in this research. BothCRP and PCT showed a substantial area under the curve (AUC) value fordiscriminating bacteremia among septic patients (0.757 and 0.845,respectively). To further enhance the predictive accuracy, we combined PCT,bilirubin, neutrophil lymphocyte ratio (NLR), platelets, lactic acid,erythrocyte sedimentation rate (ESR), and Glasgow Coma Scale (GCS) score tobuild the predictive model with an AUC of 0.907 (95% CI, 0.843 to 0.956). Inaddition, a high association between bacteremia and mortality rate wasdiscovered through the survival analysis (0.004). While PCT is certainly auseful index for distinguishing patients with and without bacteremia by itself,our MLR model indicates that the accuracy of bacteremia predictionsubstantially improves by the combined use of PCT, bilirubin, NLR, platelets,lactic acid, ESR, and GCS score.</description><author>Sangwon Baek, Seung Jun Lee</author><pubDate>Thu, 16 Nov 2023 12:21:56 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.08433v2</guid></item><item><title>Rusty Detection Using Image Processing For Maintenance Of Stations</title><link>http://arxiv.org/abs/2311.09849v1</link><description>This study addresses the challenge of accurately seg-menting rusted areas onpainted construction surfaces. A method leveraging digital image processing isexplored to calculate the percentage of rust present on painted coatings. Theproposed segmentation approach is based on the HSV color model. To equalizeluminosity and mitigate the influence of illumination, a fundamental model ofsingle-scale Retinex is applied specifically to the saturation component. Subsequently, the image undergoes further processing, involv-ing manual colorfiltering. This step is crucial for refining the identification of rustedregions. To enhance precision and filter out noise, the pixel areas selectedthrough color filtering are subjected to the DBScan algorithm. This multi-stepprocess aims to achieve a robust segmentation of rusted areas on paintedconstruction surfaces, providing a valuable contribution to the field ofcorrosion detection and analysis.</description><author>Dao Duy Tung, Ho Xuan Hung</author><pubDate>Thu, 16 Nov 2023 12:21:54 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.09849v1</guid></item><item><title>Diffusion-Augmented Neural Processes</title><link>http://arxiv.org/abs/2311.09848v1</link><description>Over the last few years, Neural Processes have become a useful modelling toolin many application areas, such as healthcare and climate sciences, in whichdata are scarce and prediction uncertainty estimates are indispensable.However, the current state of the art in the field (AR CNPs; Bruinsma et al.,2023) presents a few issues that prevent its widespread deployment. This workproposes an alternative, diffusion-based approach to NPs which, throughconditioning on noised datasets, addresses many of these limitations, whilstalso exceeding SOTA performance.</description><author>Lorenzo Bonito, James Requeima, Aliaksandra Shysheya, Richard E. Turner</author><pubDate>Thu, 16 Nov 2023 12:21:06 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.09848v1</guid></item><item><title>Overcoming Data Scarcity in Biomedical Imaging with a Foundational Multi-Task Model</title><link>http://arxiv.org/abs/2311.09847v1</link><description>Foundational models, pretrained on a large scale, have demonstratedsubstantial success across non-medical domains. However, training these modelstypically requires large, comprehensive datasets, which contrasts with thesmaller and more heterogeneous datasets common in biomedical imaging. Here, wepropose a multi-task learning strategy that decouples the number of trainingtasks from memory requirements. We trained a Universal bioMedical PreTrainedmodel (UMedPT) on a multi-task database including tomographic, microscopic, andX-ray images, with various labelling strategies such as classification,segmentation, and object detection. The UMedPT foundational model outperformedImageNet pretraining and the previous state-of-the-art models. For tasksrelated to the pretraining database, it maintained its performance with only 1%of the original training data and without fine-tuning. For out-of-domain tasksit required not more than 50% of the original training data. In an externalindependent validation imaging features extracted using UMedPT proved to be anew standard for cross-center transferability.</description><author>Raphael Schäfer, Till Nicke, Henning Höfener, Annkristin Lange, Dorit Merhof, Friedrich Feuerhake, Volkmar Schulz, Johannes Lotz, Fabian Kiessling</author><pubDate>Thu, 16 Nov 2023 12:20:25 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.09847v1</guid></item><item><title>GroupMixer: Patch-based Group Convolutional Neural Network for Breast Cancer Detection from Histopathological Images</title><link>http://arxiv.org/abs/2311.09846v1</link><description>Diagnosis of breast cancer malignancy at the early stages is a crucial stepfor controlling its side effects. Histopathological analysis provides a uniqueopportunity for malignant breast cancer detection. However, such a task wouldbe tedious and time-consuming for the histopathologists. Deep Neural Networksenable us to learn informative features directly from raw histopathologicalimages without manual feature extraction. Although Convolutional NeuralNetworks (CNNs) have been the dominant architectures in the computer visionrealm, Transformer-based architectures have shown promising results indifferent computer vision tasks. Although harnessing the capability ofTransformer-based architectures for medical image analysis seems interesting,these architectures are large, have a significant number of trainableparameters, and require large datasets to be trained on, which are usually rarein the medical domain. It has been claimed and empirically proved that at leastpart of the superior performance of Transformer-based architectures in ComputerVision domain originates from patch embedding operation. In this paper, weborrowed the previously introduced idea of integrating a fully ConvolutionalNeural Network architecture with Patch Embedding operation and presented anefficient CNN architecture for breast cancer malignancy detection fromhistopathological images. Despite the number of parameters that issignificantly smaller than other methods, the accuracy performance metricsachieved 97.65%, 98.92%, 99.21%, and 98.01% for 40x, 100x, 200x, and 400xmagnifications respectively. We took a step forward and modified thearchitecture using Group Convolution and Channel Shuffling ideas and reducedthe number of trainable parameters even more with a negligible decline inperformance and achieved 95.42%, 98.16%, 96.05%, and 97.92% accuracy for thementioned magnifications respectively.</description><author>Ardavan Modarres, Erfan Ebrahim Esfahani, Mahsa Bahrami</author><pubDate>Thu, 16 Nov 2023 12:19:48 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.09846v1</guid></item><item><title>Leveraging LLMs in Scholarly Knowledge Graph Question Answering</title><link>http://arxiv.org/abs/2311.09841v1</link><description>This paper presents a scholarly Knowledge Graph Question Answering (KGQA)that answers bibliographic natural language questions by leveraging a largelanguage model (LLM) in a few-shot manner. The model initially identifies thetop-n similar training questions related to a given test question via aBERT-based sentence encoder and retrieves their corresponding SPARQL. Using thetop-n similar question-SPARQL pairs as an example and the test question createsa prompt. Then pass the prompt to the LLM and generate a SPARQL. Finally, runsthe SPARQL against the underlying KG - ORKG (Open Research KG) endpoint andreturns an answer. Our system achieves an F1 score of 99.0%, on SciQA - one ofthe Scholarly-QALD-23 challenge benchmarks.</description><author>Tilahun Abedissa Taffa, Ricardo Usbeck</author><pubDate>Thu, 16 Nov 2023 12:13:49 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.09841v1</guid></item><item><title>Towards AI-controlled FES-restoration of movements: Learning cycling stimulation pattern with reinforcement learning</title><link>http://arxiv.org/abs/2303.09986v3</link><description>Functional electrical stimulation (FES) has been increasingly integrated withother rehabilitation devices, including robots. FES cycling is one of thecommon FES applications in rehabilitation, which is performed by stimulatingleg muscles in a certain pattern. The appropriate pattern varies acrossindividuals and requires manual tuning which can be time-consuming andchallenging for the individual user. Here, we present an AI-based method forfinding the patterns, which requires no extra hardware or sensors. Our methodhas two phases, starting with finding model-based patterns using reinforcementlearning and detailed musculoskeletal models. The models, built usingopen-source software, can be customised through our automated script and can betherefore used by non-technical individuals without extra cost. Next, ourmethod fine-tunes the pattern using real cycling data. We test our both insimulation and experimentally on a stationary tricycle. In the simulation test,our method can robustly deliver model-based patterns for different cyclingconfigurations. The experimental evaluation shows that our method can find amodel-based pattern that induces higher cycling speed than an EMG-basedpattern. By using just 100 seconds of cycling data, our method can deliver afine-tuned pattern that gives better cycling performance. Beyond FES cycling,this work is a showcase, displaying the feasibility and potential ofhuman-in-the-loop AI in real-world rehabilitation.</description><author>Nat Wannawas, A. Aldo Faisal</author><pubDate>Thu, 16 Nov 2023 12:12:37 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2303.09986v3</guid></item><item><title>PELMS: Pre-training for Effective Low-Shot Multi-Document Summarization</title><link>http://arxiv.org/abs/2311.09836v1</link><description>We investigate pre-training techniques for abstractive multi-documentsummarization (MDS), which is much less studied than summarizing singledocuments. Though recent work has demonstrated the effectiveness ofhighlighting information salience for pre-training strategy design, itstruggles to generate abstractive and reflective summaries, which are criticalproperties for MDS. To this end, we present PELMS, a pre-trained model thatuses objectives based on semantic coherence heuristics and faithfulnessconstraints with un-labeled multi-document inputs, to promote the generation ofconcise, fluent, and faithful summaries. To support the training of PELMS, wecompile MultiPT, a multi-document pre-training corpus containing over 93million documents to form more than 3 million unlabeled topic-centric documentclusters, covering diverse genres such as product reviews, news, and generalknowledge. We perform extensive evaluation of PELMS in low-shot settings on awide range of MDS datasets. Our approach consistently outperforms competitivecomparisons with respect to overall informativeness, abstractiveness,coherence, and faithfulness.</description><author>Joseph J. Peper, Wenzhao Qiu, Lu Wang</author><pubDate>Thu, 16 Nov 2023 12:05:23 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.09836v1</guid></item></channel></rss>