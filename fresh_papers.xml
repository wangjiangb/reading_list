<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/"><channel><title>Arxivfresh papers</title><link></link><description>Arxiv paper</description><language>en-US</language><lastBuildDate>Thu, 09 May 2024 06:00:13 GMT</lastBuildDate><generator>rfeed v1.0.0</generator><docs>https://github.com/svpino/rfeed/blob/master/README.md</docs><item><title>OpenESS: Event-based Semantic Scene Understanding with Open Vocabularies</title><link>http://arxiv.org/abs/2405.05259v1</link><description>Event-based semantic segmentation (ESS) is a fundamental yet challenging taskfor event camera sensing. The difficulties in interpreting and annotating eventdata limit its scalability. While domain adaptation from images to event datacan help to mitigate this issue, there exist data representational differencesthat require additional effort to resolve. In this work, for the first time, wesynergize information from image, text, and event-data domains and introduceOpenESS to enable scalable ESS in an open-world, annotation-efficient manner.We achieve this goal by transferring the semantically rich CLIP knowledge fromimage-text pairs to event streams. To pursue better cross-modality adaptation,we propose a frame-to-event contrastive distillation and a text-to-eventsemantic consistency regularization. Experimental results on popular ESSbenchmarks showed our approach outperforms existing methods. Notably, weachieve 53.93% and 43.31% mIoU on DDD17 and DSEC-Semantic without using eitherevent or frame labels.</description><author>Lingdong Kong, Youquan Liu, Lai Xing Ng, Benoit R. Cottereau, Wei Tsang Ooi</author><pubDate>Wed, 08 May 2024 18:59:58 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.05259v1</guid></item><item><title>Multi-Modal Data-Efficient 3D Scene Understanding for Autonomous Driving</title><link>http://arxiv.org/abs/2405.05258v1</link><description>Efficient data utilization is crucial for advancing 3D scene understanding inautonomous driving, where reliance on heavily human-annotated LiDAR pointclouds challenges fully supervised methods. Addressing this, our study extendsinto semi-supervised learning for LiDAR semantic segmentation, leveraging theintrinsic spatial priors of driving scenes and multi-sensor complements toaugment the efficacy of unlabeled datasets. We introduce LaserMix++, an evolvedframework that integrates laser beam manipulations from disparate LiDAR scansand incorporates LiDAR-camera correspondences to further assist data-efficientlearning. Our framework is tailored to enhance 3D scene consistencyregularization by incorporating multi-modality, including 1) multi-modalLaserMix operation for fine-grained cross-sensor interactions; 2)camera-to-LiDAR feature distillation that enhances LiDAR feature learning; and3) language-driven knowledge guidance generating auxiliary supervisions usingopen-vocabulary models. The versatility of LaserMix++ enables applicationsacross LiDAR representations, establishing it as a universally applicablesolution. Our framework is rigorously validated through theoretical analysisand extensive experiments on popular driving perception datasets. Resultsdemonstrate that LaserMix++ markedly outperforms fully supervised alternatives,achieving comparable accuracy with five times fewer annotations andsignificantly improving the supervised-only baselines. This substantialadvancement underscores the potential of semi-supervised approaches in reducingthe reliance on extensive labeled data in LiDAR-based 3D scene understandingsystems.</description><author>Lingdong Kong, Xiang Xu, Jiawei Ren, Wenwei Zhang, Liang Pan, Kai Chen, Wei Tsang Ooi, Ziwei Liu</author><pubDate>Wed, 08 May 2024 18:59:53 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.05258v1</guid></item><item><title>THRONE: An Object-based Hallucination Benchmark for the Free-form Generations of Large Vision-Language Models</title><link>http://arxiv.org/abs/2405.05256v1</link><description>Mitigating hallucinations in large vision-language models (LVLMs) remains anopen problem. Recent benchmarks do not address hallucinations in open-endedfree-form responses, which we term "Type I hallucinations". Instead, they focuson hallucinations responding to very specific question formats -- typically amultiple-choice response regarding a particular object or attribute -- which weterm "Type II hallucinations". Additionally, such benchmarks often requireexternal API calls to models which are subject to change. In practice, weobserve that a reduction in Type II hallucinations does not lead to a reductionin Type I hallucinations but rather that the two forms of hallucinations areoften anti-correlated. To address this, we propose THRONE, a novel object-basedautomatic framework for quantitatively evaluating Type I hallucinations in LVLMfree-form outputs. We use public language models (LMs) to identifyhallucinations in LVLM responses and compute informative metrics. By evaluatinga large selection of recent LVLMs using public datasets, we show that animprovement in existing metrics do not lead to a reduction in Type Ihallucinations, and that established benchmarks for measuring Type Ihallucinations are incomplete. Finally, we provide a simple and effective dataaugmentation method to reduce Type I and Type II hallucinations as a strongbaseline.</description><author>Prannay Kaul, Zhizhong Li, Hao Yang, Yonatan Dukler, Ashwin Swaminathan, C. J. Taylor, Stefano Soatto</author><pubDate>Wed, 08 May 2024 18:59:11 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.05256v1</guid></item><item><title>Diffusion-HMC: Parameter Inference with Diffusion Model driven Hamiltonian Monte Carlo</title><link>http://arxiv.org/abs/2405.05255v1</link><description>Diffusion generative models have excelled at diverse image generation andreconstruction tasks across fields. A less explored avenue is their applicationto discriminative tasks involving regression or classification problems. Thecornerstone of modern cosmology is the ability to generate predictions forobserved astrophysical fields from theory and constrain physical models fromobservations using these predictions. This work uses a single diffusiongenerative model to address these interlinked objectives -- as a surrogatemodel or emulator for cold dark matter density fields conditional on inputcosmological parameters, and as a parameter inference model that solves theinverse problem of constraining the cosmological parameters of an input field.The model is able to emulate fields with summary statistics consistent withthose of the simulated target distribution. We then leverage the approximatelikelihood of the diffusion generative model to derive tight constraints oncosmology by using the Hamiltonian Monte Carlo method to sample the posterioron cosmological parameters for a given test image. Finally, we demonstrate thatthis parameter inference approach is more robust to the addition of noise thanbaseline parameter inference networks.</description><author>Nayantara Mudur, Carolina Cuesta-Lazaro, Douglas P. Finkbeiner</author><pubDate>Wed, 08 May 2024 18:59:03 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.05255v1</guid></item><item><title>You Only Cache Once: Decoder-Decoder Architectures for Language Models</title><link>http://arxiv.org/abs/2405.05254v1</link><description>We introduce a decoder-decoder architecture, YOCO, for large language models,which only caches key-value pairs once. It consists of two components, i.e., across-decoder stacked upon a self-decoder. The self-decoder efficiently encodesglobal key-value (KV) caches that are reused by the cross-decoder viacross-attention. The overall model behaves like a decoder-only Transformer,although YOCO only caches once. The design substantially reduces GPU memorydemands, yet retains global attention capability. Additionally, the computationflow enables prefilling to early exit without changing the final output,thereby significantly speeding up the prefill stage. Experimental resultsdemonstrate that YOCO achieves favorable performance compared to Transformer invarious settings of scaling up model size and number of training tokens. Wealso extend YOCO to 1M context length with near-perfect needle retrievalaccuracy. The profiling results show that YOCO improves inference memory,prefill latency, and throughput by orders of magnitude across context lengthsand model sizes. Code is available at https://aka.ms/YOCO.</description><author>Yutao Sun, Li Dong, Yi Zhu, Shaohan Huang, Wenhui Wang, Shuming Ma, Quanlu Zhang, Jianyong Wang, Furu Wei</author><pubDate>Wed, 08 May 2024 18:57:39 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.05254v1</guid></item><item><title>Open Source Language Models Can Provide Feedback: Evaluating LLMs' Ability to Help Students Using GPT-4-As-A-Judge</title><link>http://arxiv.org/abs/2405.05253v1</link><description>Large language models (LLMs) have shown great potential for the automaticgeneration of feedback in a wide range of computing contexts. However, concernshave been voiced around the privacy and ethical implications of sending studentwork to proprietary models. This has sparked considerable interest in the useof open source LLMs in education, but the quality of the feedback that suchopen models can produce remains understudied. This is a concern as providingflawed or misleading generated feedback could be detrimental to studentlearning. Inspired by recent work that has utilised very powerful LLMs, such asGPT-4, to evaluate the outputs produced by less powerful models, we conduct anautomated analysis of the quality of the feedback produced by several opensource models using a dataset from an introductory programming course. First,we investigate the viability of employing GPT-4 as an automated evaluator bycomparing its evaluations with those of a human expert. We observe that GPT-4demonstrates a bias toward positively rating feedback while exhibiting moderateagreement with human raters, showcasing its potential as a feedback evaluator.Second, we explore the quality of feedback generated by several leadingopen-source LLMs by using GPT-4 to evaluate the feedback. We find that somemodels offer competitive performance with popular proprietary LLMs, such asChatGPT, indicating opportunities for their responsible use in educationalsettings.</description><author>Charles Koutcheme, Nicola Dainese, Sami Sarsa, Arto Hellas, Juho Leinonen, Paul Denny</author><pubDate>Wed, 08 May 2024 18:57:39 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.05253v1</guid></item><item><title>Attention-Driven Training-Free Efficiency Enhancement of Diffusion Models</title><link>http://arxiv.org/abs/2405.05252v1</link><description>Diffusion Models (DMs) have exhibited superior performance in generatinghigh-quality and diverse images. However, this exceptional performance comes atthe cost of expensive architectural design, particularly due to the attentionmodule heavily used in leading models. Existing works mainly adopt a retrainingprocess to enhance DM efficiency. This is computationally expensive and notvery scalable. To this end, we introduce the Attention-driven Training-freeEfficient Diffusion Model (AT-EDM) framework that leverages attention maps toperform run-time pruning of redundant tokens, without the need for anyretraining. Specifically, for single-denoising-step pruning, we develop a novelranking algorithm, Generalized Weighted Page Rank (G-WPR), to identifyredundant tokens, and a similarity-based recovery method to restore tokens forthe convolution operation. In addition, we propose a Denoising-Steps-AwarePruning (DSAP) approach to adjust the pruning budget across different denoisingtimesteps for better generation quality. Extensive evaluations show that AT-EDMperforms favorably against prior art in terms of efficiency (e.g., 38.8% FLOPssaving and up to 1.53x speed-up over Stable Diffusion XL) while maintainingnearly the same FID and CLIP scores as the full model. Project webpage:https://atedm.github.io.</description><author>Hongjie Wang, Difan Liu, Yan Kang, Yijun Li, Zhe Lin, Niraj K. Jha, Yuchen Liu</author><pubDate>Wed, 08 May 2024 18:56:47 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.05252v1</guid></item><item><title>LLMs with Personalities in Multi-issue Negotiation Games</title><link>http://arxiv.org/abs/2405.05248v1</link><description>Powered by large language models (LLMs), AI agents have become capable ofmany human tasks. Using the most canonical definitions of the Big Fivepersonality, we measure the ability of LLMs to negotiate within agame-theoretical framework, as well as methodological challenges to measuringnotions of fairness and risk. Simulations (n=1,500) for both single-issue andmulti-issue negotiation reveal increase in domain complexity with asymmetricissue valuations improve agreement rates but decrease surplus from aggressivenegotiation. Through gradient-boosted regression and Shapley explainers, wefind high openness, conscientiousness, and neuroticism are associated with fairtendencies; low agreeableness and low openness are associated with rationaltendencies. Low conscientiousness is associated with high toxicity. Theseresults indicate that LLMs may have built-in guardrails that default to fairbehavior, but can be "jail broken" to exploit agreeable opponents. We alsooffer pragmatic insight in how negotiation bots can be designed, and aframework of assessing negotiation behavior based on game theory andcomputational social science.</description><author>Sean Noh, Ho-Chun Herbert Chang</author><pubDate>Wed, 08 May 2024 18:51:53 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.05248v1</guid></item><item><title>Sensitivity-Aware Amortized Bayesian Inference</title><link>http://arxiv.org/abs/2310.11122v5</link><description>Sensitivity analyses reveal the influence of various modeling choices on theoutcomes of statistical analyses. While theoretically appealing, they areoverwhelmingly inefficient for complex Bayesian models. In this work, wepropose sensitivity-aware amortized Bayesian inference (SA-ABI), a multifacetedapproach to efficiently integrate sensitivity analyses into simulation-basedinference with neural networks. First, we utilize weight sharing to encode thestructural similarities between alternative likelihood and prior specificationsin the training process with minimal computational overhead. Second, weleverage the rapid inference of neural networks to assess sensitivity to dataperturbations and preprocessing steps. In contrast to most other Bayesianapproaches, both steps circumvent the costly bottleneck of refitting the modelfor each choice of likelihood, prior, or data set. Finally, we propose to usedeep ensembles to detect sensitivity arising from unreliable approximation(e.g., due to model misspecification). We demonstrate the effectiveness of ourmethod in applied modeling problems, ranging from disease outbreak dynamics andglobal warming thresholds to human decision-making. Our results supportsensitivity-aware inference as a default choice for amortized Bayesianworkflows, automatically providing modelers with insights into otherwise hiddendimensions.</description><author>Lasse Elsemüller, Hans Olischläger, Marvin Schmitt, Paul-Christian Bürkner, Ullrich Köthe, Stefan T. Radev</author><pubDate>Wed, 08 May 2024 18:50:06 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.11122v5</guid></item><item><title>D4C Glove-train: Solving the RPM and Bongard-logo Problem by Circumscribing and Building Distribution for Concepts</title><link>http://arxiv.org/abs/2403.03452v6</link><description>This paper achieves noteworthy progress in the realm of abstract reasoning,particularly in addressing Raven's Progressive Matrices (RPM) and Bongard-Logochallenges. Initially, we introduce Lico-Net, a novel baseline model thatresolves RPM problems with remarkable accuracy. Leveraging this foundation, weadvance with the D3C approach, which advocates representing the underlyingconcepts in abstract reasoning problems through distributions. This perspectiveenhances the performance of both Lico-Net and a baseline model excelling inBongard-Logo tasks. To bolster the computational efficiency of D3C, we presentthe D3C-cos variant, offering a streamlined yet precise solution. Furthermore,we propose the D2C method, redefining conceptual boundaries within thesedomains and bridging the divide between high-level abstractions and theirlower-dimensional counterparts. Finally, we extend our methodology to D4C,employing adversarial techniques to refine conceptual boundaries further anddemonstrate substantial improvements in both RPM and Bongard-Logo challenges.Overall, our contributions present a fresh outlook and practical advancementsin the field of abstract reasoning.</description><author>Ruizhuo Song, Beiming Yuan</author><pubDate>Wed, 08 May 2024 18:46:09 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.03452v6</guid></item><item><title>SVDD Challenge 2024: A Singing Voice Deepfake Detection Challenge Evaluation Plan</title><link>http://arxiv.org/abs/2405.05244v1</link><description>The rapid advancement of AI-generated singing voices, which now closely mimicnatural human singing and align seamlessly with musical scores, has led toheightened concerns for artists and the music industry. Unlike spoken voice,singing voice presents unique challenges due to its musical nature and thepresence of strong background music, making singing voice deepfake detection(SVDD) a specialized field requiring focused attention. To promote SVDDresearch, we recently proposed the "SVDD Challenge," the very first researchchallenge focusing on SVDD for lab-controlled and in-the-wild bonafide anddeepfake singing voice recordings. The challenge will be held in conjunctionwith the 2024 IEEE Spoken Language Technology Workshop (SLT 2024).</description><author>You Zhang, Yongyi Zang, Jiatong Shi, Ryuichi Yamamoto, Jionghao Han, Yuxun Tang, Tomoki Toda, Zhiyao Duan</author><pubDate>Wed, 08 May 2024 18:40:12 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.05244v1</guid></item><item><title>Deep learning-based variational autoencoder for classification of quantum and classical states of light</title><link>http://arxiv.org/abs/2405.05243v1</link><description>Advancements in optical quantum technologies have been enabled by thegeneration, manipulation, and characterization of light, with identificationbased on its photon statistics. However, characterizing light and its sourcesthrough single photon measurements often requires efficient detectors andlonger measurement times to obtain high-quality photon statistics. Here weintroduce a deep learning-based variational autoencoder (VAE) method forclassifying single photon added coherent state (SPACS), single photon addedthermal state (SPACS), mixed states between coherent/SPACS and thermal/SPATS oflight. Our semisupervised learning-based VAE efficiently maps the photonstatistics features of light to a lower dimension, enabling quasi-instantaneousclassification with low average photon counts. The proposed VAE method isrobust and maintains classification accuracy in the presence of losses inherentin an experiment, such as finite collection efficiency, non-unity quantumefficiency, finite number of detectors, etc. Additionally, leveraging thetransfer learning capabilities of VAE enables successful classification of dataof any quality using a single trained model. We envision that such a deeplearning methodology will enable better classification of quantum light andlight sources even in the presence of poor detection quality.</description><author>Mahesh Bhupati, Abhishek Mall, Anshuman Kumar, Pankaj K. Jha</author><pubDate>Wed, 08 May 2024 18:40:03 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.05243v1</guid></item><item><title>BenthicNet: A global compilation of seafloor images for deep learning applications</title><link>http://arxiv.org/abs/2405.05241v1</link><description>Advances in underwater imaging enable the collection of extensive seafloorimage datasets that are necessary for monitoring important benthic ecosystems.The ability to collect seafloor imagery has outpaced our capacity to analyzeit, hindering expedient mobilization of this crucial environmental information.Recent machine learning approaches provide opportunities to increase theefficiency with which seafloor image datasets are analyzed, yet large andconsistent datasets necessary to support development of such approaches arescarce. Here we present BenthicNet: a global compilation of seafloor imagerydesigned to support the training and evaluation of large-scale imagerecognition models. An initial set of over 11.4 million images was collectedand curated to represent a diversity of seafloor environments using arepresentative subset of 1.3 million images. These are accompanied by 2.6million annotations translated to the CATAMI scheme, which span 190,000 of theimages. A large deep learning model was trained on this compilation andpreliminary results suggest it has utility for automating large and small-scaleimage analysis tasks. The compilation and model are made openly available foruse by the scientific community at https://doi.org/10.20383/103.0614.</description><author>Scott C. Lowe, Benjamin Misiuk, Isaac Xu, Shakhboz Abdulazizov, Amit R. Baroi, Alex C. Bastos, Merlin Best, Vicki Ferrini, Ariell Friedman, Deborah Hart, Ove Hoegh-Guldberg, Daniel Ierodiaconou, Julia Mackin-McLaughlin, Kathryn Markey, Pedro S. Menandro, Jacquomo Monk, Shreya Nemani, John O'Brien, Elizabeth Oh, Luba Y. Reshitnyk, Katleen Robert, Chris M. Roelfsema, Jessica A. Sameoto, Alexandre C. G. Schimel, Jordan A. Thomson, Brittany R. Wilson, Melisa C. Wong, Craig J. Brown, Thomas Trappenberg</author><pubDate>Wed, 08 May 2024 18:37:57 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.05241v1</guid></item><item><title>An LSTM-Based Chord Generation System Using Chroma Histogram Representations</title><link>http://arxiv.org/abs/2405.05240v1</link><description>This paper proposes a system for chord generation to monophonic symbolicmelodies using an LSTM-based model trained on chroma histogram representationsof chords. Chroma representations promise more harmonically rich generationthan chord label-based approaches, whilst maintaining a small number ofdimensions in the dataset. This system is shown to be suitable for limitedreal-time use. While it does not meet the state-of-the-art for coherentlong-term generation, it does show diatonic generation with cadential chordrelationships. The need for further study into chroma histograms as anextracted feature in chord generation tasks is highlighted.</description><author>Jack Hardwick</author><pubDate>Wed, 08 May 2024 18:36:29 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.05240v1</guid></item><item><title>Cellular Traffic Prediction Using Online Prediction Algorithms</title><link>http://arxiv.org/abs/2405.05239v1</link><description>The advent of 5G technology promises a paradigm shift in the realm oftelecommunications, offering unprecedented speeds and connectivity. However,the efficient management of traffic in 5G networks remains a criticalchallenge. It is due to the dynamic and heterogeneous nature of networktraffic, varying user behaviors, extended network size, and diverseapplications, all of which demand highly accurate and adaptable predictionmodels to optimize network resource allocation and management. This paperinvestigates the efficacy of live prediction algorithms for forecastingcellular network traffic in real-time scenarios. We apply two live predictionalgorithms on machine learning models, one of which is recently proposed FastLiveStream Prediction (FLSP) algorithm. We examine the performance of thesealgorithms under two distinct data gathering methodologies: synchronous, whereall network cells report statistics simultaneously, and asynchronous, wherereporting occurs across consecutive time slots. Our study delves into theimpact of these gathering scenarios on the predictive performance of trafficmodels. Our study reveals that the FLSP algorithm can halve the requiredbandwidth for asynchronous data reporting compared to conventional onlineprediction algorithms, while simultaneously enhancing prediction accuracy andreducing processing load. Additionally, we conduct a thorough analysis ofalgorithmic complexity and memory requirements across various machine learningmodels. Through empirical evaluation, we provide insights into the trade-offsinherent in different prediction strategies, offering valuable guidance fornetwork optimization and resource allocation in dynamic environments.</description><author>Hossein Mehri, Hao Chen, Hani Mehrpouyan</author><pubDate>Wed, 08 May 2024 18:36:14 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.05239v1</guid></item><item><title>EVA-X: A Foundation Model for General Chest X-ray Analysis with Self-supervised Learning</title><link>http://arxiv.org/abs/2405.05237v1</link><description>The diagnosis and treatment of chest diseases play a crucial role inmaintaining human health. X-ray examination has become the most common clinicalexamination means due to its efficiency and cost-effectiveness. Artificialintelligence analysis methods for chest X-ray images are limited byinsufficient annotation data and varying levels of annotation, resulting inweak generalization ability and difficulty in clinical dissemination. Here wepresent EVA-X, an innovative foundational model based on X-ray images withbroad applicability to various chest disease detection tasks. EVA-X is thefirst X-ray image based self-supervised learning method capable of capturingboth semantic and geometric information from unlabeled images for universalX-ray image representation. Through extensive experimentation, EVA-X hasdemonstrated exceptional performance in chest disease analysis andlocalization, becoming the first model capable of spanning over 20 differentchest diseases and achieving leading results in over 11 different detectiontasks in the medical field. Additionally, EVA-X significantly reduces theburden of data annotation in the medical AI field, showcasing strong potentialin the domain of few-shot learning. The emergence of EVA-X will greatly propelthe development and application of foundational medical models, bringing aboutrevolutionary changes in future medical research and clinical practice. Ourcodes and models are available at: https://github.com/hustvl/EVA-X.</description><author>Jingfeng Yao, Xinggang Wang, Yuehao Song, Huangxuan Zhao, Jun Ma, Yajie Chen, Wenyu Liu, Bo Wang</author><pubDate>Wed, 08 May 2024 18:33:42 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.05237v1</guid></item><item><title>Stability and Performance Analysis of Discrete-Time ReLU Recurrent Neural Networks</title><link>http://arxiv.org/abs/2405.05236v1</link><description>This paper presents sufficient conditions for the stability and $\ell_2$-gainperformance of recurrent neural networks (RNNs) with ReLU activation functions.These conditions are derived by combining Lyapunov/dissipativity theory withQuadratic Constraints (QCs) satisfied by repeated ReLUs. We write a generalclass of QCs for repeated RELUs using known properties for the scalar ReLU. Ourstability and performance condition uses these QCs along with a "lifted"representation for the ReLU RNN. We show that the positive homogeneity propertysatisfied by a scalar ReLU does not expand the class of QCs for the repeatedReLU. We present examples to demonstrate the stability / performance conditionand study the effect of the lifting horizon.</description><author>Sahel Vahedi Noori, Bin Hu, Geir Dullerud, Peter Seiler</author><pubDate>Wed, 08 May 2024 18:30:50 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.05236v1</guid></item><item><title>RACH Traffic Prediction in Massive Machine Type Communications</title><link>http://arxiv.org/abs/2405.05235v1</link><description>Traffic pattern prediction has emerged as a promising approach forefficiently managing and mitigating the impacts of event-driven bursty trafficin massive machine-type communication (mMTC) networks. However, achievingaccurate predictions of bursty traffic remains a non-trivial task due to theinherent randomness of events, and these challenges intensify within livenetwork environments. Consequently, there is a compelling imperative to designa lightweight and agile framework capable of assimilating continuouslycollected data from the network and accurately forecasting bursty traffic inmMTC networks. This paper addresses these challenges by presenting a machinelearning-based framework tailored for forecasting bursty traffic inmulti-channel slotted ALOHA networks. The proposed machine learning networkcomprises long-term short-term memory (LSTM) and a DenseNet with feed-forwardneural network (FFNN) layers, where the residual connections enhance thetraining ability of the machine learning network in capturing complicatedpatterns. Furthermore, we develop a new low-complexity online predictionalgorithm that updates the states of the LSTM network by leveraging frequentlycollected data from the mMTC network. Simulation results and complexityanalysis demonstrate the superiority of our proposed algorithm in terms of bothaccuracy and complexity, making it well-suited for time-critical livescenarios. We evaluate the performance of the proposed framework in a networkwith a single base station and thousands of devices organized into groups withdistinct traffic-generating characteristics. Comprehensive evaluations andsimulations indicate that our proposed machine learning approach achieves aremarkable $52\%$ higher accuracy in long-term predictions compared totraditional methods, without imposing additional processing load on the system.</description><author>Hossein Mehri, Hao Chen, Hani Mehrpouyan</author><pubDate>Wed, 08 May 2024 18:28:07 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.05235v1</guid></item><item><title>DiskGNN: Bridging I/O Efficiency and Model Accuracy for Out-of-Core GNN Training</title><link>http://arxiv.org/abs/2405.05231v1</link><description>Graph neural networks (GNNs) are machine learning models specialized forgraph data and widely used in many applications. To train GNNs on large graphsthat exceed CPU memory, several systems store data on disk and conductout-of-core processing. However, these systems suffer from either readamplification when reading node features that are usually smaller than a diskpage or degraded model accuracy by treating the graph as disconnectedpartitions. To close this gap, we build a system called DiskGNN, which achieveshigh I/O efficiency and thus fast training without hurting model accuracy. Thekey technique used by DiskGNN is offline sampling, which helps decouple graphsampling from model computation. In particular, by conducting graph samplingbeforehand, DiskGNN acquires the node features that will be accessed by modelcomputation, and such information is utilized to pack the target node featurescontiguously on disk to avoid read amplification. Besides, \name{} also adoptsdesigns including four-level feature store to fully utilize the memoryhierarchy to cache node features and reduce disk access, batched packing toaccelerate the feature packing process, and pipelined training to overlap diskaccess with other operations. We compare DiskGNN with Ginex and MariusGNN,which are state-of-the-art systems for out-of-core GNN training. The resultsshow that DiskGNN can speed up the baselines by over 8x while matching theirbest model accuracy.</description><author>Renjie Liu, Yichuan Wang, Xiao Yan, Zhenkun Cai, Minjie Wang, Haitian Jiang, Bo Tang, Jinyang Li</author><pubDate>Wed, 08 May 2024 18:27:11 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.05231v1</guid></item><item><title>Personalized Autonomous Driving with Large Language Models: Field Experiments</title><link>http://arxiv.org/abs/2312.09397v3</link><description>Integrating large language models (LLMs) in autonomous vehicles enablesconversation with AI systems to drive the vehicle. However, it also emphasizesthe requirement for such systems to comprehend commands accurately and achievehigher-level personalization to adapt to the preferences of drivers orpassengers over a more extended period. In this paper, we introduce anLLM-based framework, Talk2Drive, capable of translating natural verbal commandsinto executable controls and learning to satisfy personal preferences forsafety, efficiency, and comfort with a proposed memory module. This is thefirst-of-its-kind multi-scenario field experiment that deploys LLMs on areal-world autonomous vehicle. Experiments showcase that the proposed systemcan comprehend human intentions at different intuition levels, ranging fromdirect commands like "can you drive faster" to indirect commands like "I amreally in a hurry now". Additionally, we use the takeover rate to quantify thetrust of human drivers in the LLM-based autonomous driving system, whereTalk2Drive significantly reduces the takeover rate in highway, intersection,and parking scenarios. We also validate that the proposed memory moduleconsiders personalized preferences and further reduces the takeover rate by upto 65.2% compared with those without a memory module. The experiment video canbe watched at https://www.youtube.com/watch?v=4BWsfPaq1Ro</description><author>Can Cui, Zichong Yang, Yupeng Zhou, Yunsheng Ma, Juanwu Lu, Lingxi Li, Yaobin Chen, Jitesh Panchal, Ziran Wang</author><pubDate>Wed, 08 May 2024 18:24:33 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.09397v3</guid></item><item><title>Contrastive Learning Method for Sequential Recommendation based on Multi-Intention Disentanglement</title><link>http://arxiv.org/abs/2404.18214v2</link><description>Sequential recommendation is one of the important branches of recommendersystem, aiming to achieve personalized recommended items for the future throughthe analysis and prediction of users' ordered historical interactive behaviors.However, along with the growth of the user volume and the increasingly richbehavioral information, how to understand and disentangle the user'sinteractive multi-intention effectively also poses challenges to behaviorprediction and sequential recommendation. In light of these challenges, wepropose a Contrastive Learning sequential recommendation method based onMulti-Intention Disentanglement (MIDCL). In our work, intentions are recognizedas dynamic and diverse, and user behaviors are often driven by currentmulti-intentions, which means that the model needs to not only mine the mostrelevant implicit intention for each user, but also impair the influence fromirrelevant intentions. Therefore, we choose Variational Auto-Encoder (VAE) torealize the disentanglement of users' multi-intentions. We propose two types ofcontrastive learning paradigms for finding the most relevant user's interactiveintention, and maximizing the mutual information of positive sample pairs,respectively. Experimental results show that MIDCL not only has significantsuperiority over most existing baseline methods, but also brings a moreinterpretable case to the research about intention-based prediction andrecommendation.</description><author>Zeyu Hu, Yuzhi Xiao, Tao Huang, Xuanrong Huo</author><pubDate>Wed, 08 May 2024 18:23:11 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.18214v2</guid></item><item><title>Test-Time Adaptation for Depth Completion</title><link>http://arxiv.org/abs/2402.03312v3</link><description>It is common to observe performance degradation when transferring modelstrained on some (source) datasets to target testing data due to a domain gapbetween them. Existing methods for bridging this gap, such as domain adaptation(DA), may require the source data on which the model was trained (often notavailable), while others, i.e., source-free DA, require many passes through thetesting data. We propose an online test-time adaptation method for depthcompletion, the task of inferring a dense depth map from a single image andassociated sparse depth map, that closes the performance gap in a single pass.We first present a study on how the domain shift in each data modality affectsmodel performance. Based on our observations that the sparse depth modalityexhibits a much smaller covariate shift than the image, we design an embeddingmodule trained in the source domain that preserves a mapping from featuresencoding only sparse depth to those encoding image and sparse depth. Duringtest time, sparse depth features are projected using this map as a proxy forsource domain features and are used as guidance to train a set of auxiliaryparameters (i.e., adaptation layer) to align image and sparse depth featuresfrom the target test domain to that of the source domain. We evaluate ourmethod on indoor and outdoor scenarios and show that it improves over baselinesby an average of 21.1%.</description><author>Hyoungseob Park, Anjali Gupta, Alex Wong</author><pubDate>Wed, 08 May 2024 18:20:55 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.03312v3</guid></item><item><title>Imagine Flash: Accelerating Emu Diffusion Models with Backward Distillation</title><link>http://arxiv.org/abs/2405.05224v1</link><description>Diffusion models are a powerful generative framework, but come with expensiveinference. Existing acceleration methods often compromise image quality or failunder complex conditioning when operating in an extremely low-step regime. Inthis work, we propose a novel distillation framework tailored to enablehigh-fidelity, diverse sample generation using just one to three steps. Ourapproach comprises three key components: (i) Backward Distillation, whichmitigates training-inference discrepancies by calibrating the student on itsown backward trajectory; (ii) Shifted Reconstruction Loss that dynamicallyadapts knowledge transfer based on the current time step; and (iii) NoiseCorrection, an inference-time technique that enhances sample quality byaddressing singularities in noise prediction. Through extensive experiments, wedemonstrate that our method outperforms existing competitors in quantitativemetrics and human evaluations. Remarkably, it achieves performance comparableto the teacher model using only three denoising steps, enabling efficienthigh-quality generation.</description><author>Jonas Kohler, Albert Pumarola, Edgar Schönfeld, Artsiom Sanakoyeu, Roshan Sumbaly, Peter Vajda, Ali Thabet</author><pubDate>Wed, 08 May 2024 18:15:18 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.05224v1</guid></item><item><title>The Impact of Imperfect XAI on Human-AI Decision-Making</title><link>http://arxiv.org/abs/2307.13566v4</link><description>Explainability techniques are rapidly being developed to improve human-AIdecision-making across various cooperative work settings. Consequently,previous research has evaluated how decision-makers collaborate with imperfectAI by investigating appropriate reliance and task performance with the aim ofdesigning more human-centered computer-supported collaborative tools. Severalhuman-centered explainable AI (XAI) techniques have been proposed in hopes ofimproving decision-makers' collaboration with AI; however, these techniques aregrounded in findings from previous studies that primarily focus on the impactof incorrect AI advice. Few studies acknowledge the possibility of theexplanations being incorrect even if the AI advice is correct. Thus, it iscrucial to understand how imperfect XAI affects human-AI decision-making. Inthis work, we contribute a robust, mixed-methods user study with 136participants to evaluate how incorrect explanations influence humans'decision-making behavior in a bird species identification task, taking intoaccount their level of expertise and an explanation's level of assertiveness.Our findings reveal the influence of imperfect XAI and humans' level ofexpertise on their reliance on AI and human-AI team performance. We alsodiscuss how explanations can deceive decision-makers during human-AIcollaboration. Hence, we shed light on the impacts of imperfect XAI in thefield of computer-supported cooperative work and provide guidelines fordesigners of human-AI collaboration systems.</description><author>Katelyn Morrison, Philipp Spitzer, Violet Turri, Michelle Feng, Niklas Kühl, Adam Perer</author><pubDate>Wed, 08 May 2024 18:14:25 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.13566v4</guid></item><item><title>Conv-Basis: A New Paradigm for Efficient Attention Inference and Gradient Computation in Transformers</title><link>http://arxiv.org/abs/2405.05219v1</link><description>Large Language Models (LLMs) have profoundly changed the world. Theirself-attention mechanism is the key to the success of transformers in LLMs.However, the quadratic computational cost $O(n^2)$ to the length $n$ inputsequence is the notorious obstacle for further improvement and scalability inthe longer context. In this work, we leverage the convolution-like structure ofattention matrices to develop an efficient approximation method for attentioncomputation using convolution matrices. We propose a $\mathsf{conv}$ basissystem, "similar" to the rank basis, and show that any lower triangular(attention) matrix can always be decomposed as a sum of $k$ structuredconvolution matrices in this basis system. We then design an algorithm toquickly decompose the attention matrix into $k$ convolution matrices. Thanks toFast Fourier Transforms (FFT), the attention {\it inference} can be computed in$O(knd \log n)$ time, where $d$ is the hidden dimension. In practice, we have $d \ll n$, i.e., $d=3,072$ and $n=1,000,000$ for Gemma. Thus, when $kd =n^{o(1)}$, our algorithm achieve almost linear time, i.e., $n^{1+o(1)}$.Furthermore, the attention {\it training forward} and {\it backward gradient}can be computed in $n^{1+o(1)}$ as well. Our approach can avoid explicitlycomputing the $n \times n$ attention matrix, which may largely alleviate thequadratic computational complexity. Furthermore, our algorithm works on anyinput matrices. This work provides a new paradigm for accelerating attentioncomputation in transformers to enable their application to longer contexts.</description><author>Jiuxiang Gu, Yingyu Liang, Heshan Liu, Zhenmei Shi, Zhao Song, Junze Yin</author><pubDate>Wed, 08 May 2024 18:11:38 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.05219v1</guid></item><item><title>Locally Differentially Private In-Context Learning</title><link>http://arxiv.org/abs/2405.04032v2</link><description>Large pretrained language models (LLMs) have shown surprising In-ContextLearning (ICL) ability. An important application in deploying large languagemodels is to augment LLMs with a private database for some specific task. Themain problem with this promising commercial use is that LLMs have been shown tomemorize their training data and their prompt data are vulnerable to membershipinference attacks (MIA) and prompt leaking attacks. In order to deal with thisproblem, we treat LLMs as untrusted in privacy and propose a locallydifferentially private framework of in-context learning(LDP-ICL) in thesettings where labels are sensitive. Considering the mechanisms of in-contextlearning in Transformers by gradient descent, we provide an analysis of thetrade-off between privacy and utility in such LDP-ICL for classification.Moreover, we apply LDP-ICL to the discrete distribution estimation problem. Inthe end, we perform several experiments to demonstrate our analysis results.</description><author>Chunyan Zheng, Keke Sun, Wenhao Zhao, Haibo Zhou, Lixin Jiang, Shaoyang Song, Chunlai Zhou</author><pubDate>Wed, 08 May 2024 18:10:23 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.04032v2</guid></item><item><title>FinePOSE: Fine-Grained Prompt-Driven 3D Human Pose Estimation via Diffusion Models</title><link>http://arxiv.org/abs/2405.05216v1</link><description>The 3D Human Pose Estimation (3D HPE) task uses 2D images or videos topredict human joint coordinates in 3D space. Despite recent advancements indeep learning-based methods, they mostly ignore the capability of couplingaccessible texts and naturally feasible knowledge of humans, missing out onvaluable implicit supervision to guide the 3D HPE task. Moreover, previousefforts often study this task from the perspective of the whole human body,neglecting fine-grained guidance hidden in different body parts. To this end,we present a new Fine-Grained Prompt-Driven Denoiser based on a diffusion modelfor 3D HPE, named \textbf{FinePOSE}. It consists of three core blocks enhancingthe reverse process of the diffusion model: (1) Fine-grained Part-aware Promptlearning (FPP) block constructs fine-grained part-aware prompts via couplingaccessible texts and naturally feasible knowledge of body parts with learnableprompts to model implicit guidance. (2) Fine-grained Prompt-pose Communication(FPC) block establishes fine-grained communications between learned part-awareprompts and poses to improve the denoising quality. (3) Prompt-driven TimestampStylization (PTS) block integrates learned prompt embedding and temporalinformation related to the noise level to enable adaptive adjustment at eachdenoising step. Extensive experiments on public single-human pose estimationdatasets show that FinePOSE outperforms state-of-the-art methods. We furtherextend FinePOSE to multi-human pose estimation. Achieving 34.3mm average MPJPEon the EgoHumans dataset demonstrates the potential of FinePOSE to deal withcomplex multi-human scenarios. Code is available athttps://github.com/PKU-ICST-MIPL/FinePOSE_CVPR2024.</description><author>Jinglin Xu, Yijie Guo, Yuxin Peng</author><pubDate>Wed, 08 May 2024 18:09:03 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.05216v1</guid></item><item><title>Speech Understanding on Tiny Devices with A Learning Cache</title><link>http://arxiv.org/abs/2311.18188v4</link><description>This paper addresses spoken language understanding (SLU) onmicrocontroller-like embedded devices, integrating on-device execution withcloud offloading in a novel fashion. We leverage temporal locality in thespeech inputs to a device and reuse recent SLU inferences accordingly. Our ideais simple: let the device match incoming inputs against cached results, andonly offload inputs not matched to any cached ones to the cloud for fullinference. Realization of this idea, however, is non-trivial: the device needsto compare acoustic features in a robust yet low-cost way. To this end, wepresent SpeechCache (or SC), a speech cache for tiny devices. It matches speechinputs at two levels of representations: first by sequences of clustered rawsound units, then as sequences of phonemes. Working in tandem, the tworepresentations offer complementary tradeoffs between cost and efficiency. Toboost accuracy even further, our cache learns to personalize: with themismatched and then offloaded inputs, it continuously finetunes the device'sfeature extractors with the assistance of the cloud. We implement SC on anoff-the-shelf STM32 microcontroller. The complete implementation has a smallmemory footprint of 2MB. Evaluated on challenging speech benchmarks, our systemresolves 45%-90% of inputs on device, reducing the average latency by up to 80%compared to offloading to popular cloud speech recognition services. Thebenefit brought by our proposed SC is notable even in adversarial settings -noisy environments, cold cache, or one device shared by a number of users.</description><author>Afsara Benazir, Zhiming Xu, Felix Xiaozhu Lin</author><pubDate>Wed, 08 May 2024 18:08:52 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.18188v4</guid></item><item><title>Fast Abstracts and Student Forum Proceedings -- EDCC 2024 -- 19th European Dependable Computing Conference</title><link>http://arxiv.org/abs/2404.17465v4</link><description>The goal of the Fast Abstracts track is to bring together researchers andpractitioners working on dependable computing to discuss work in progress oropinion pieces. Contributions are welcome from academia and industry. FastAbstracts aim to serve as a rapid and flexible mechanism to: (i) Report oncurrent work that may or may not be complete; (ii) Introduce new ideas to thecommunity; (iii) State positions on controversial issues or open problems; (iv)Share lessons learnt from real-word dependability engineering; and (v) Debunkor question results from other papers based on contra-indications. The StudentForum aims at creating a vibrant and friendly environment where students canpresent and discuss their work, and exchange ideas and experiences with otherstudents, researchers and industry. One of the key goals of the Forum is toprovide students with feedback on their preliminary results that might helpwith their future research directions.</description><author>Simona Bernardi, Tommaso Zoppi</author><pubDate>Wed, 08 May 2024 18:05:10 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.17465v4</guid></item><item><title>FAQ-Gen: An automated system to generate domain-specific FAQs to aid content comprehension</title><link>http://arxiv.org/abs/2402.05812v2</link><description>Frequently Asked Questions (FAQs) refer to the most common inquiries aboutspecific content. They serve as content comprehension aids by simplifyingtopics and enhancing understanding through succinct presentation ofinformation. In this paper, we address FAQ generation as a well-defined NaturalLanguage Processing task through the development of an end-to-end systemleveraging text-to-text transformation models. We present a literature reviewcovering traditional question-answering systems, highlighting their limitationswhen applied directly to the FAQ generation task. We propose a system capableof building FAQs from textual content tailored to specific domains, enhancingtheir accuracy and relevance. We utilise self-curated algorithms to obtain anoptimal representation of information to be provided as input and also to rankthe question-answer pairs to maximise human comprehension. Qualitative humanevaluation showcases the generated FAQs as well-constructed and readable whilealso utilising domain-specific constructs to highlight domain-based nuances andjargon in the original content.</description><author>Sahil Kale, Gautam Khaire, Jay Patankar</author><pubDate>Wed, 08 May 2024 18:01:30 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.05812v2</guid></item><item><title>Random Alloy Codes and the Fundamental Limits of Coded Distributed Tensors</title><link>http://arxiv.org/abs/2202.03469v6</link><description>Tensors are a fundamental operation in distributed and are commonlydistributed into multiple parallel tasks for large datasets. Stragglers andother failures can severely impact the overall completion time. Recent works incoded computing provide a novel strategy to mitigate stragglers with codedtasks, with an objective of minimizing the number of tasks needed to recoverthe overall result, known as the recovery threshold. However, we demonstratethat this strict combinatorial definition does not directly optimize theprobability of failure. In this paper, we focus on the most likely event and measure the optimalityof a coding scheme more directly by its probability of decoding. Ourprobabilistic approach leads us to a practical construction of random codes formatrix multiplication, i.e., locally random alloy codes, which are optimal withrespect to the measures. Furthermore, the probabilistic approach allows us todiscover a surprising impossibility theorem about both random and deterministiccoded distributed tensors.</description><author>Pedro Soto</author><pubDate>Wed, 08 May 2024 18:00:13 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2202.03469v6</guid></item><item><title>Leafy Spurge Dataset: Real-world Weed Classification Within Aerial Drone Imagery</title><link>http://arxiv.org/abs/2405.03702v2</link><description>Invasive plant species are detrimental to the ecology of both agriculturaland wildland areas. Euphorbia esula, or leafy spurge, is one such plant thathas spread through much of North America from Eastern Europe. When paired withcontemporary computer vision systems, unmanned aerial vehicles, or drones,offer the means to track expansion of problem plants, such as leafy spurge, andimprove chances of controlling these weeds. We gathered a dataset of leafyspurge presence and absence in grasslands of western Montana, USA, thensurveyed these areas with a commercial drone. We trained image classifiers onthese data, and our best performing model, a pre-trained DINOv2 visiontransformer, identified leafy spurge with 0.84 accuracy (test set). This resultindicates that classification of leafy spurge is tractable, but not solved. Werelease this unique dataset of labelled and unlabelled, aerial drone imageryfor the machine learning community to explore. Improving classificationperformance of leafy spurge would benefit the fields of ecology, conservation,and remote sensing alike. Code and data are available at our website:leafy-spurge-dataset.github.io.</description><author>Kyle Doherty, Max Gurinas, Erik Samsoe, Charles Casper, Beau Larkin, Philip Ramsey, Brandon Trabucco, Ruslan Salakhutdinov</author><pubDate>Wed, 08 May 2024 17:59:05 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.03702v2</guid></item><item><title>Cooperative Students: Navigating Unsupervised Domain Adaptation in Nighttime Object Detection</title><link>http://arxiv.org/abs/2404.01988v3</link><description>Unsupervised Domain Adaptation (UDA) has shown significant advancements inobject detection under well-lit conditions; however, its performance degradesnotably in low-visibility scenarios, especially at night, posing challenges notonly for its adaptability in low signal-to-noise ratio (SNR) conditions butalso for the reliability and efficiency of automated vehicles. To address thisproblem, we propose a \textbf{Co}operative \textbf{S}tudents (\textbf{CoS})framework that innovatively employs global-local transformations (GLT) and aproxy-based target consistency (PTC) mechanism to capture the spatialconsistency in day- and night-time scenarios effectively, and thus bridge thesignificant domain shift across contexts. Building upon this, we further devisean adaptive IoU-informed thresholding (AIT) module to gradually avoidoverlooking potential true positives and enrich the latent information in thetarget domain. Comprehensive experiments show that CoS essentially enhanced UDAperformance in low-visibility conditions and surpasses current state-of-the-arttechniques, achieving an increase in mAP of 3.0\%, 1.9\%, and 2.5\% on BDD100K,SHIFT, and ACDC datasets, respectively. Code is available athttps://github.com/jichengyuan/Cooperitive_Students.</description><author>Jicheng Yuan, Anh Le-Tuan, Manfred Hauswirth, Danh Le-Phuoc</author><pubDate>Wed, 08 May 2024 17:54:39 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.01988v3</guid></item><item><title>Anomaly Detection in Certificate Transparency Logs</title><link>http://arxiv.org/abs/2405.05206v1</link><description>We propose an anomaly detection technique for X.509 certificates utilizingIsolation Forest. This method can be beneficial when compliance testing withX.509 linters proves unsatisfactory, and we seek to identify anomalies beyondstandards compliance. The technique is validated on a sample of certificatesfrom Certificate Transparency logs.</description><author>Richard Ostertág, Martin Stanek</author><pubDate>Wed, 08 May 2024 17:43:50 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.05206v1</guid></item><item><title>Hybrid Quantum Graph Neural Network for Molecular Property Prediction</title><link>http://arxiv.org/abs/2405.05205v1</link><description>To accelerate the process of materials design, materials science hasincreasingly used data driven techniques to extract information from collecteddata. Specially, machine learning (ML) algorithms, which span the MLdiscipline, have demonstrated ability to predict various properties ofmaterials with the level of accuracy similar to explicit calculation of quantummechanical theories, but with significantly reduced run time and computationalresources. Within ML, graph neural networks have emerged as an importantalgorithm within the field of machine learning, since they are capable ofpredicting accurately a wide range of important physical, chemical andelectronic properties due to their higher learning ability based on the graphrepresentation of material and molecular descriptors through the aggregation ofinformation embedded within the graph. In parallel with the development ofstate of the art classical machine learning applications, the fusion of quantumcomputing and machine learning have created a new paradigm where classicalmachine learning model can be augmented with quantum layers which are able toencode high dimensional data more efficiently. Leveraging the structure ofexisting algorithms, we developed a unique and novel gradient free hybridquantum classical convoluted graph neural network (HyQCGNN) to predictformation energies of perovskite materials. The performance of our hybridstatistical model is competitive with the results obtained purely from aclassical convoluted graph neural network, and other classical machine learningalgorithms, such as XGBoost. Consequently, our study suggests a new pathway toexplore how quantum feature encoding and parametric quantum circuits can yielddrastic improvements of complex ML algorithm like graph neural network.</description><author>Michael Vitz, Hamed Mohammadbagherpoor, Samarth Sandeep, Andrew Vlasic, Richard Padbury, Anh Pham</author><pubDate>Wed, 08 May 2024 17:43:25 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.05205v1</guid></item><item><title>CARE-SD: Classifier-based analysis for recognizing and eliminating stigmatizing and doubt marker labels in electronic health records: model development and validation</title><link>http://arxiv.org/abs/2405.05204v1</link><description>Objective: To detect and classify features of stigmatizing and biasedlanguage in intensive care electronic health records (EHRs) using naturallanguage processing techniques. Materials and Methods: We first created alexicon and regular expression lists from literature-driven stem words forlinguistic features of stigmatizing patient labels, doubt markers, and scarequotes within EHRs. The lexicon was further extended using Word2Vec and GPT3.5, and refined through human evaluation. These lexicons were used to searchfor matches across 18 million sentences from the de-identified MedicalInformation Mart for Intensive Care-III (MIMIC-III) dataset. For eachlinguistic bias feature, 1000 sentence matches were sampled, labeled by expertclinical and public health annotators, and used to supervised learningclassifiers. Results: Lexicon development from expanded literature stem-wordlists resulted in a doubt marker lexicon containing 58 expressions, and astigmatizing labels lexicon containing 127 expressions. Classifiers for doubtmarkers and stigmatizing labels had the highest performance, with macroF1-scores of .84 and .79, positive-label recall and precision values rangingfrom .71 to .86, and accuracies aligning closely with human annotator agreement(.87). Discussion: This study demonstrated the feasibility of supervisedclassifiers in automatically identifying stigmatizing labels and doubt markersin medical text, and identified trends in stigmatizing language use in an EHRsetting. Additional labeled data may help improve lower scare quote modelperformance. Conclusions: Classifiers developed in this study showed high modelperformance and can be applied to identify patterns and target interventions toreduce stigmatizing labels and doubt markers in healthcare systems.</description><author>Drew Walker, Annie Thorne, Sudeshna Das, Jennifer Love, Hannah LF Cooper, Melvin Livingston III, Abeed Sarker</author><pubDate>Wed, 08 May 2024 17:40:18 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.05204v1</guid></item><item><title>Guided Combinatorial Algorithms for Submodular Maximization</title><link>http://arxiv.org/abs/2405.05202v1</link><description>For constrained, not necessarily monotone submodular maximization, guidingthe measured continuous greedy algorithm with a local search algorithmcurrently obtains the state-of-the-art approximation factor of 0.401\citep{buchbinder2023constrained}. These algorithms rely upon the multilinearextension and the Lovasz extension of a submodular set function. However, thestate-of-the-art approximation factor of combinatorial algorithms has remained$1/e \approx 0.367$ \citep{buchbinder2014submodular}. In this work, we developcombinatorial analogues of the guided measured continuous greedy algorithm andobtain approximation ratio of $0.385$ in $\oh{ kn }$ queries to the submodularset function for size constraint, and $0.305$ for a general matroid constraint.Further, we derandomize these algorithms, maintaining the same ratio andasymptotic time complexity. Finally, we develop a deterministic, nearly lineartime algorithm with ratio $0.377$.</description><author>Yixin Chen, Ankur Nath, Chunli Peng, Alan Kuhnle</author><pubDate>Wed, 08 May 2024 17:39:59 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.05202v1</guid></item><item><title>SINBAD: Saliency-informed detection of breakage caused by ad blocking</title><link>http://arxiv.org/abs/2405.05196v1</link><description>Privacy-enhancing blocking tools based on filter-list rules tend to breaklegitimate functionality. Filter-list maintainers could benefit from automatedbreakage detection tools that allow them to proactively fix problematic rulesbefore deploying them to millions of users. We introduce SINBAD, an automatedbreakage detector that improves the accuracy over the state of the art by 20%,and is the first to detect dynamic breakage and breakage caused bystyle-oriented filter rules. The success of SINBAD is rooted in threeinnovations: (1) the use of user-reported breakage issues in forums that enablethe creation of a high-quality dataset for training in which only breakage thatusers perceive as an issue is included; (2) the use of 'web saliency' toautomatically identify user-relevant regions of a website on which toprioritize automated interactions aimed at triggering breakage; and (3) theanalysis of webpages via subtrees which enables fine-grained identification ofproblematic filter rules.</description><author>Saiid El Hajj Chehade, Sandra Siby, Carmela Troncoso</author><pubDate>Wed, 08 May 2024 17:35:06 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.05196v1</guid></item><item><title>Improved Generalization Bounds for Communication Efficient Federated Learning</title><link>http://arxiv.org/abs/2404.11754v2</link><description>This paper focuses on reducing the communication cost of federated learningby exploring generalization bounds and representation learning. We firstcharacterize a tighter generalization bound for one-round federated learningbased on local clients' generalizations and heterogeneity of data distribution(non-iid scenario). We also characterize a generalization bound in R-roundfederated learning and its relation to the number of local updates (localstochastic gradient descents (SGDs)). Then, based on our generalization boundanalysis and our representation learning interpretation of this analysis, weshow for the first time that less frequent aggregations, hence more localupdates, for the representation extractor (usually corresponds to initiallayers) leads to the creation of more generalizable models, particularly fornon-iid scenarios. We design a novel Federated Learning with Adaptive LocalSteps (FedALS) algorithm based on our generalization bound and representationlearning analysis. FedALS employs varying aggregation frequencies for differentparts of the model, so reduces the communication cost. The paper is followedwith experimental results showing the effectiveness of FedALS.</description><author>Peyman Gholami, Hulya Seferoglu</author><pubDate>Wed, 08 May 2024 17:31:03 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.11754v2</guid></item><item><title>Full error analysis of the random deep splitting method for nonlinear parabolic PDEs and PIDEs with infinite activity</title><link>http://arxiv.org/abs/2405.05192v1</link><description>In this paper, we present a randomized extension of the deep splittingalgorithm introduced in [Beck, Becker, Cheridito, Jentzen, and Neufeld (2021)]using random neural networks suitable to approximately solve bothhigh-dimensional nonlinear parabolic PDEs and PIDEs with jumps having(possibly) infinite activity. We provide a full error analysis of our so-calledrandom deep splitting method. In particular, we prove that our random deepsplitting method converges to the (unique viscosity) solution of the nonlinearPDE or PIDE under consideration. Moreover, we empirically analyze our randomdeep splitting method by considering several numerical examples including bothnonlinear PDEs and nonlinear PIDEs relevant in the context of pricing offinancial derivatives under default risk. In particular, we empiricallydemonstrate in all examples that our random deep splitting method canapproximately solve nonlinear PDEs and PIDEs in 10'000 dimensions withinseconds.</description><author>Ariel Neufeld, Philipp Schmocker, Sizhou Wu</author><pubDate>Wed, 08 May 2024 17:30:45 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.05192v1</guid></item><item><title>Triple-CFN: Restructuring Conceptual Spaces for Enhancing Abstract Reasoning process</title><link>http://arxiv.org/abs/2403.03190v6</link><description>Abstract reasoning poses significant challenges to artificial intelligencealgorithms, demanding a higher level of cognitive ability than that requiredfor perceptual tasks. In this study, we introduce the Triple-CFN method totackle the Bongard Logo problem, achieving remarkable reasoning accuracy byimplicitly reorganizing the conflicting concept spaces of instances.Furthermore, with necessary modifications, the Triple-CFN paradigm has alsoproven effective on the RPM (Raven's Progressive Matrices) problem, yieldingcompetitive results. To further enhance Triple-CFN's performance on the RPMproblem, we have upgraded it to the Meta Triple-CFN network, which explicitlyconstructs the concept space of RPM problems, ensuring high reasoning accuracywhile achieving conceptual interpretability. The success of Meta Triple-CFN canbe attributed to its paradigm of modeling the concept space, which istantamount to normalizing reasoning information. Based on this idea, we haveintroduced the Re-space layer, boosting the performance of both Meta Triple-CFNand Triple-CFN. This paper aims to contribute to the advancement of machineintelligence and pave the way for further breakthroughs in this field byexploring innovative network designs for solving abstract reasoning problems.</description><author>Ruizhuo Song, Beiming Yuan</author><pubDate>Wed, 08 May 2024 17:28:54 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.03190v6</guid></item><item><title>Is Transductive Learning Equivalent to PAC Learning?</title><link>http://arxiv.org/abs/2405.05190v1</link><description>Most work in the area of learning theory has focused on designing effectiveProbably Approximately Correct (PAC) learners. Recently, other models oflearning such as transductive error have seen more scrutiny. We move towardshowing that these problems are equivalent by reducing agnostic learning with aPAC guarantee to agnostic learning with a transductive guarantee by adding asmall number of samples to the dataset. We first rederive the result ofAden-Ali et al. arXiv:2304.09167 reducing PAC learning to transductive learningin the realizable setting using simpler techniques and at more generality asbackground for our main positive result. Our agnostic transductive to PACconversion technique extends the aforementioned argument to the agnostic case,showing that an agnostic transductive learner can be efficiently converted toan agnostic PAC learner. Finally, we characterize the performance of theagnostic one inclusion graph algorithm of Asilis et al. arXiv:2309.13692 forbinary classification, and show that plugging it into our reduction leads to anagnostic PAC learner that is essentially optimal. Our results imply thattransductive and PAC learning are essentially equivalent for supervisedlearning with pseudometric losses in the realizable setting, and for binaryclassification in the agnostic setting. We conjecture this is true moregenerally for the agnostic setting.</description><author>Shaddin Dughmi, Yusuf Kalayci, Grayson York</author><pubDate>Wed, 08 May 2024 17:26:49 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.05190v1</guid></item><item><title>MIDGARD: Self-Consistency Using Minimum Description Length for Structured Commonsense Reasoning</title><link>http://arxiv.org/abs/2405.05189v1</link><description>We study the task of conducting structured reasoning as generating areasoning graph from natural language input using large language models (LLMs).Previous approaches have explored various prompting schemes, yet they sufferfrom error propagation due to the autoregressive nature and single-pass-baseddecoding, which lack error correction capability. Additionally, relying solelyon a single sample may result in the omission of true nodes and edges. Tocounter this, we draw inspiration from self-consistency (SC), which involvessampling a diverse set of reasoning chains and taking the majority vote as thefinal answer. To tackle the substantial challenge of applying SC on generatedgraphs, we propose MIDGARD (MInimum Description length Guided Aggregation ofReasoning in Directed acyclic graph) that leverages Minimum Description Length(MDL)-based formulation to identify consistent properties among the differentgraph samples generated by an LLM. This formulation helps reject propertiesthat appear in only a few samples, which are likely to be erroneous, whileenabling the inclusion of missing elements without compromising precision. Ourmethod demonstrates superior performance than comparisons across variousstructured reasoning tasks, including argument structure extraction,explanation graph generation, inferring dependency relations among actions foreveryday tasks, and semantic graph generation from natural texts.</description><author>Inderjeet Nair, Lu Wang</author><pubDate>Wed, 08 May 2024 17:25:42 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.05189v1</guid></item><item><title>A score-based particle method for homogeneous Landau equation</title><link>http://arxiv.org/abs/2405.05187v1</link><description>We propose a novel score-based particle method for solving the Landauequation in plasmas, that seamlessly integrates learning withstructure-preserving particle methods [arXiv:1910.03080]. Building upon theLagrangian viewpoint of the Landau equation, a central challenge stems from thenonlinear dependence of the velocity field on the density. Our primaryinnovation lies in recognizing that this nonlinearity is in the form of thescore function, which can be approximated dynamically via techniques fromscore-matching. The resulting method inherits the conservation properties ofthe deterministic particle method while sidestepping the necessity for kerneldensity estimation in [arXiv:1910.03080]. This streamlines computation andenhances scalability with dimensionality. Furthermore, we provide a theoreticalestimate by demonstrating that the KL divergence between our approximation andthe true solution can be effectively controlled by the score-matching loss.Additionally, by adopting the flow map viewpoint, we derive an update formulafor exact density computation. Extensive examples have been provided to showthe efficiency of the method, including a physically relevant case of Coulombinteraction.</description><author>Yan Huang, Li Wang</author><pubDate>Wed, 08 May 2024 17:22:47 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.05187v1</guid></item><item><title>Machine Learning Assisted Dynamical Classification of Trans-Neptunian Objects</title><link>http://arxiv.org/abs/2405.05185v1</link><description>Trans-Neptunian objects (TNOs) are small, icy bodies in the outer solarsystem. They are observed to have a complex orbital distribution that wasshaped by the early dynamical history and migration of the giant planets.Comparisons between the different dynamical classes of modeled and observedTNOs can help constrain the history of the outer solar system. Because of thecomplex dynamics of TNOs, particularly those in and near mean motion resonanceswith Neptune, classification has traditionally been done by human inspection ofplots of the time evolution of orbital parameters. This is very inefficient.The Vera Rubin Observatory's Legacy Survey of Space and Time (LSST) is expectedto increase the number of known TNOs by a factor of $\sim$10, necessitating amuch more automated process. In this chapter we present an improved supervisedmachine learning classifier for TNOs. Using a large and diverse training set aswell as carefully chosen, dynamically motivated data features calculated fromnumerical integrations of TNO orbits, our classifier returns results that matchthose of a human classifier 98% of the time, and dynamically relevantclassifications 99.7% of the time. This classifier is dramatically moreefficient than human classification, and it will improve classification of bothobserved and modeled TNO data.</description><author>Kathryn Volk, Renu Malhotra</author><pubDate>Wed, 08 May 2024 17:20:47 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.05185v1</guid></item><item><title>Encoder-Decoder Framework for Interactive Free Verses with Generation with Controllable High-Quality Rhyming</title><link>http://arxiv.org/abs/2405.05176v1</link><description>Composing poetry or lyrics involves several creative factors, but achallenging aspect of generation is the adherence to a more or less strictmetric and rhyming pattern. To address this challenge specifically, previouswork on the task has mainly focused on reverse language modeling, which bringsthe critical selection of each rhyming word to the forefront of each verse. Onthe other hand, reversing the word order requires that models be trained fromscratch with this task-specific goal and cannot take advantage of transferlearning from a Pretrained Language Model (PLM). We propose a novel fine-tuningapproach that prepends the rhyming word at the start of each lyric, whichallows the critical rhyming decision to be made before the model commits to thecontent of the lyric (as during reverse language modeling), but maintainscompatibility with the word order of regular PLMs as the lyric itself is stillgenerated in left-to-right order. We conducted extensive experiments to comparethis fine-tuning against the current state-of-the-art strategies for rhyming,finding that our approach generates more readable text and better rhymingcapabilities. Furthermore, we furnish a high-quality dataset in English and 12other languages, analyse the approach's feasibility in a multilingual context,provide extensive experimental results shedding light on good and bad practicesfor lyrics generation, and propose metrics to compare methods in the future.</description><author>Tommaso Pasini, Alejo López-Ávila, Husam Quteineh, Gerasimos Lampouras, Jinhua Du, Yubing Wang, Ze Li, Yusen Sun</author><pubDate>Wed, 08 May 2024 17:13:40 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.05176v1</guid></item><item><title>Air Gap: Protecting Privacy-Conscious Conversational Agents</title><link>http://arxiv.org/abs/2405.05175v1</link><description>The growing use of large language model (LLM)-based conversational agents tomanage sensitive user data raises significant privacy concerns. While theseagents excel at understanding and acting on context, this capability can beexploited by malicious actors. We introduce a novel threat model whereadversarial third-party apps manipulate the context of interaction to trickLLM-based agents into revealing private information not relevant to the task athand. Grounded in the framework of contextual integrity, we introduce AirGapAgent,a privacy-conscious agent designed to prevent unintended data leakage byrestricting the agent's access to only the data necessary for a specific task.Extensive experiments using Gemini, GPT, and Mistral models as agents validateour approach's effectiveness in mitigating this form of context hijacking whilemaintaining core agent functionality. For example, we show that a single-querycontext hijacking attack on a Gemini Ultra agent reduces its ability to protectuser data from 94% to 45%, while an AirGapAgent achieves 97% protection,rendering the same attack ineffective.</description><author>Eugene Bagdasaryan, Ren Yi, Sahra Ghalebikesabi, Peter Kairouz, Marco Gruteser, Sewoong Oh, Borja Balle, Daniel Ramage</author><pubDate>Wed, 08 May 2024 17:12:45 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.05175v1</guid></item><item><title>A Survey on Occupancy Perception for Autonomous Driving: The Information Fusion Perspective</title><link>http://arxiv.org/abs/2405.05173v1</link><description>3D occupancy perception technology aims to observe and understand dense 3Denvironments for autonomous vehicles. Owing to its comprehensive perceptioncapability, this technology is emerging as a trend in autonomous drivingperception systems, and is attracting significant attention from both industryand academia. Similar to traditional bird's-eye view (BEV) perception, 3Doccupancy perception has the nature of multi-source input and the necessity forinformation fusion. However, the difference is that it captures verticalstructures that are ignored by 2D BEV. In this survey, we review the mostrecent works on 3D occupancy perception, and provide in-depth analyses ofmethodologies with various input modalities. Specifically, we summarize generalnetwork pipelines, highlight information fusion techniques, and discusseffective network training. We evaluate and analyze the occupancy perceptionperformance of the state-of-the-art on the most popular datasets. Furthermore,challenges and future research directions are discussed. We hope this reportwill inspire the community and encourage more research work on 3D occupancyperception. A comprehensive list of studies in this survey is available in anactive repository that continuously collects the latest work:https://github.com/HuaiyuanXu/3D-Occupancy-Perception.</description><author>Huaiyuan Xu, Junliang Chen, Shiyu Meng, Yi Wang, Lap-Pui Chau</author><pubDate>Wed, 08 May 2024 17:10:46 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.05173v1</guid></item><item><title>Custom Gradient Estimators are Straight-Through Estimators in Disguise</title><link>http://arxiv.org/abs/2405.05171v1</link><description>Quantization-aware training comes with a fundamental challenge: thederivative of quantization functions such as rounding are zero almosteverywhere and nonexistent elsewhere. Various differentiable approximations ofquantization functions have been proposed to address this issue. In this paper,we prove that when the learning rate is sufficiently small, a large class ofweight gradient estimators is equivalent with the straight through estimator(STE). Specifically, after swapping in the STE and adjusting both the weightinitialization and the learning rate in SGD, the model will train in almostexactly the same way as it did with the original gradient estimator. Moreover,we show that for adaptive learning rate algorithms like Adam, the same resultcan be seen without any modifications to the weight initialization and learningrate. We experimentally show that these results hold for both a smallconvolutional model trained on the MNIST dataset and for a ResNet50 modeltrained on ImageNet.</description><author>Matt Schoenbauer, Daniele Moro, Lukasz Lew, Andrew Howard</author><pubDate>Wed, 08 May 2024 17:07:56 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.05171v1</guid></item><item><title>Picking watermarks from noise (PWFN): an improved robust watermarking model against intensive distortions</title><link>http://arxiv.org/abs/2405.05170v1</link><description>Digital watermarking is the process of embedding secret information byaltering images in a way that is undetectable to the human eye. To increase therobustness of the model, many deep learning-based watermarking methods use theencoder-decoder architecture by adding different noises to the noise layer. Thedecoder then extracts the watermarked information from the distorted image.However, this method can only resist weak noise attacks. To improve therobustness of the algorithm against stronger noise, this paper proposes tointroduce a denoise module between the noise layer and the decoder. The moduleis aimed at reducing noise and recovering some of the information lost duringan attack. Additionally, the paper introduces the SE module to fuse thewatermarking information pixel-wise and channel dimensions-wise, improving theencoder's efficiency. Experimental results show that our proposed method iscomparable to existing models and outperforms state-of-the-art under differentnoise intensities. In addition, ablation experiments show the superiority ofour proposed module.</description><author>Sijing Xie, Chengxin Zhao, Nan Sun, Wei Li, Hefei Ling</author><pubDate>Wed, 08 May 2024 17:06:57 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.05170v1</guid></item><item><title>Data-Error Scaling in Machine Learning on Natural Discrete Combinatorial Mutation-prone Sets: Case Studies on Peptides and Small Molecules</title><link>http://arxiv.org/abs/2405.05167v1</link><description>We investigate trends in the data-error scaling behavior of machine learning(ML) models trained on discrete combinatorial spaces that areprone-to-mutation, such as proteins or organic small molecules. We trained andevaluated kernel ridge regression machines using variable amounts ofcomputationally generated training data. Our synthetic datasets comprise i) twona\"ive functions based on many-body theory; ii) binding energy estimatesbetween a protein and a mutagenised peptide; and iii) solvation energies of two6-heavy atom structural graphs. In contrast to typical data-error scaling, ourresults showed discontinuous monotonic phase transitions during learning,observed as rapid drops in the test error at particular thresholds of trainingdata. We observed two learning regimes, which we call saturated and asymptoticdecay, and found that they are conditioned by the level of complexity (i.e.number of mutations) enclosed in the training set. We show that during trainingon this class of problems, the predictions were clustered by the ML modelsemployed in the calibration plots. Furthermore, we present an alternativestrategy to normalize learning curves (LCs) and the concept of mutant basedshuffling. This work has implications for machine learning on mutagenisablediscrete spaces such as chemical properties or protein phenotype prediction,and improves basic understanding of concepts in statistical learning theory.</description><author>Vanni Doffini, O. Anatole von Lilienfeld, Michael A. Nash</author><pubDate>Wed, 08 May 2024 17:04:50 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.05167v1</guid></item><item><title>Reinforcement Learning from Diverse Human Preferences</title><link>http://arxiv.org/abs/2301.11774v3</link><description>The complexity of designing reward functions has been a major obstacle to thewide application of deep reinforcement learning (RL) techniques. Describing anagent's desired behaviors and properties can be difficult, even for experts. Anew paradigm called reinforcement learning from human preferences (orpreference-based RL) has emerged as a promising solution, in which rewardfunctions are learned from human preference labels among behavior trajectories.However, existing methods for preference-based RL are limited by the need foraccurate oracle preference labels. This paper addresses this limitation bydeveloping a method for crowd-sourcing preference labels and learning fromdiverse human preferences. The key idea is to stabilize reward learning throughregularization and correction in a latent space. To ensure temporalconsistency, a strong constraint is imposed on the reward model that forces itslatent space to be close to the prior distribution. Additionally, aconfidence-based reward model ensembling method is designed to generate morestable and reliable predictions. The proposed method is tested on a variety oftasks in DMcontrol and Meta-world and has shown consistent and significantimprovements over existing preference-based RL algorithms when learning fromdiverse feedback, paving the way for real-world applications of RL methods.</description><author>Wanqi Xue, Bo An, Shuicheng Yan, Zhongwen Xu</author><pubDate>Wed, 08 May 2024 16:58:02 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2301.11774v3</guid></item><item><title>Bayesian taut splines for estimating the number of modes</title><link>http://arxiv.org/abs/2307.05825v3</link><description>The number of modes in a probability density function is representative ofthe complexity of a model and can also be viewed as the number ofsubpopulations. Despite its relevance, there has been limited research in thisarea. A novel approach to estimating the number of modes in the univariatesetting is presented, focusing on prediction accuracy and inspired by someoverlooked aspects of the problem: the need for structure in the solutions, thesubjective and uncertain nature of modes, and the convenience of a holisticview that blends local and global density properties. The technique combinesflexible kernel estimators and parsimonious compositional splines in theBayesian inference paradigm, providing soft solutions and incorporating expertjudgment. The procedure includes feature exploration, model selection, and modetesting, illustrated in a sports analytics case study showcasing multiplecompanion visualisation tools. A thorough simulation study also demonstratesthat traditional modality-driven approaches paradoxically struggle to provideaccurate results. In this context, the new method emerges as a top-tieralternative, offering innovative solutions for analysts.</description><author>José E. Chacón, Javier Fernández Serrano</author><pubDate>Wed, 08 May 2024 16:56:13 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.05825v3</guid></item><item><title>ProbRadarM3F: mmWave Radar based Human Skeletal Pose Estimation with Probability Map Guided Multi-Format Feature Fusion</title><link>http://arxiv.org/abs/2405.05164v1</link><description>Millimetre wave (mmWave) radar is a non-intrusive privacy and relativelyconvenient and inexpensive device, which has been demonstrated to be applicablein place of RGB cameras in human indoor pose estimation tasks. However, mmWaveradar relies on the collection of reflected signals from the target, and theradar signals containing information is difficult to be fully applied. This hasbeen a long-standing hindrance to the improvement of pose estimation accuracy.To address this major challenge, this paper introduces a probability map guidedmulti-format feature fusion model, ProbRadarM3F. This is a novel radar featureextraction framework using a traditional FFT method in parallel with aprobability map based positional encoding method. ProbRadarM3F fuses thetraditional heatmap features and the positional features, then effectivelyachieves the estimation of 14 keypoints of the human body. Experimentalevaluation on the HuPR dataset proves the effectiveness of the model proposedin this paper, outperforming other methods experimented on this dataset with anAP of 69.9 %. The emphasis of our study is focusing on the position informationthat is not exploited before in radar singal. This provides direction toinvestigate other potential non-redundant information from mmWave rader.</description><author>Bing Zhu, Zixin He, Weiyi Xiong, Guanhua Ding, Jianan Liu, Tao Huang, Wei Chen, Wei Xiang</author><pubDate>Wed, 08 May 2024 16:54:57 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.05164v1</guid></item><item><title>Motion Capture Analysis of Verb and Adjective Types in Austrian Sign Language</title><link>http://arxiv.org/abs/2405.05161v1</link><description>Across a number of sign languages, temporal and spatial characteristics ofdominant hand articulation are used to express semantic and grammaticalfeatures. In this study of Austrian Sign Language (\"OsterreichischeGeb\"ardensprache, or \"OGS), motion capture data of four Deaf signers is usedto quantitatively characterize the kinematic parameters of sign production inverbs and adjectives. We investigate (1) the difference in production betweenverbs involving a natural endpoint (telic verbs; e.g. arrive) and verbs lackingan endpoint (atelic verbs; e.g. analyze), and (2) adjective signs inintensified vs. non-intensified (plain) forms. Motion capture data analysisusing linear-mixed effects models (LME) indicates that both the endpointmarking in verbs, as well as marking of intensification in adjectives, areexpressed by movement modulation in \"OGS. While the semantic distinctionbetween verb types (telic/atelic) is marked by higher peak velocity and shorterduration for telic signs compared to atelic ones, the grammatical distinction(intensification) in adjectives is expressed by longer duration for intensifiedcompared to non-intensified adjectives. The observed individual differences ofsigners might be interpreted as personal signing style.</description><author>Julia Krebs, Evie Malaia, Ronnie B. Wilbur, Isabella Fessl, Hans-Peter Wiesinger, Hermann Schwameder, Dietmar Roehm</author><pubDate>Wed, 08 May 2024 16:54:12 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.05161v1</guid></item><item><title>Selective Classification Under Distribution Shifts</title><link>http://arxiv.org/abs/2405.05160v1</link><description>In selective classification (SC), a classifier abstains from makingpredictions that are likely to be wrong to avoid excessive errors. To deployimperfect classifiers -- imperfect either due to intrinsic statistical noise ofdata or for robustness issue of the classifier or beyond -- in high-stakesscenarios, SC appears to be an attractive and necessary path to follow. Despitedecades of research in SC, most previous SC methods still focus on the idealstatistical setting only, i.e., the data distribution at deployment is the sameas that of training, although practical data can come from the wild. To bridgethis gap, in this paper, we propose an SC framework that takes into accountdistribution shifts, termed generalized selective classification, that coverslabel-shifted (or out-of-distribution) and covariate-shifted samples, inaddition to typical in-distribution samples, the first of its kind in the SCliterature. We focus on non-training-based confidence-score functions forgeneralized SC on deep learning (DL) classifiers and propose two novelmargin-based score functions. Through extensive analysis and experiments, weshow that our proposed score functions are more effective and reliable than theexisting ones for generalized SC on a variety of classification tasks and DLclassifiers.</description><author>Hengyue Liang, Le Peng, Ju Sun</author><pubDate>Wed, 08 May 2024 16:52:50 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.05160v1</guid></item><item><title>Few-Shot Detection of Machine-Generated Text using Style Representations</title><link>http://arxiv.org/abs/2401.06712v3</link><description>The advent of instruction-tuned language models that convincingly mimic humanwriting poses a significant risk of abuse. However, such abuse may becounteracted with the ability to detect whether a piece of text was composed bya language model rather than a human author. Some previous approaches to thisproblem have relied on supervised methods by training on corpora of confirmedhuman- and machine- written documents. Unfortunately, model under-specificationposes an unavoidable challenge for neural network-based detectors, making thembrittle in the face of data shifts, such as the release of newer languagemodels producing still more fluent text than the models used to train thedetectors. Other approaches require access to the models that may havegenerated a document in question, which is often impractical. In light of thesechallenges, we pursue a fundamentally different approach not relying on samplesfrom language models of concern at training time. Instead, we propose toleverage representations of writing style estimated from human-authored text.Indeed, we find that features effective at distinguishing among human authorsare also effective at distinguishing human from machine authors, includingstate-of-the-art large language models like Llama-2, ChatGPT, and GPT-4.Furthermore, given a handful of examples composed by each of several specificlanguage models of interest, our approach affords the ability to predict whichmodel generated a given document. The code and data to reproduce ourexperiments are available athttps://github.com/LLNL/LUAR/tree/main/fewshot_iclr2024.</description><author>Rafael Rivera Soto, Kailin Koch, Aleem Khan, Barry Chen, Marcus Bishop, Nicholas Andrews</author><pubDate>Wed, 08 May 2024 16:50:40 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.06712v3</guid></item><item><title>Analytical results for uncertainty propagation through trained machine learning regression models</title><link>http://arxiv.org/abs/2404.11224v2</link><description>Machine learning (ML) models are increasingly being used in metrologyapplications. However, for ML models to be credible in a metrology context theyshould be accompanied by principled uncertainty quantification. This paperaddresses the challenge of uncertainty propagation through trained/fixedmachine learning (ML) regression models. Analytical expressions for the meanand variance of the model output are obtained/presented for certain input datadistributions and for a variety of ML models. Our results cover several popularML models including linear regression, penalised linear regression, kernelridge regression, Gaussian Processes (GPs), support vector machines (SVMs) andrelevance vector machines (RVMs). We present numerical experiments in which wevalidate our methods and compare them with a Monte Carlo approach from acomputational efficiency point of view. We also illustrate our methods in thecontext of a metrology application, namely modelling the state-of-health oflithium-ion cells based upon Electrical Impedance Spectroscopy (EIS) data</description><author>Andrew Thompson</author><pubDate>Wed, 08 May 2024 16:50:31 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.11224v2</guid></item><item><title>HEAL-SWIN: A Vision Transformer On The Sphere</title><link>http://arxiv.org/abs/2307.07313v2</link><description>High-resolution wide-angle fisheye images are becoming more and moreimportant for robotics applications such as autonomous driving. However, usingordinary convolutional neural networks or vision transformers on this data isproblematic due to projection and distortion losses introduced when projectingto a rectangular grid on the plane. We introduce the HEAL-SWIN transformer,which combines the highly uniform Hierarchical Equal Area iso-LatitudePixelation (HEALPix) grid used in astrophysics and cosmology with theHierarchical Shifted-Window (SWIN) transformer to yield an efficient andflexible model capable of training on high-resolution, distortion-freespherical data. In HEAL-SWIN, the nested structure of the HEALPix grid is usedto perform the patching and windowing operations of the SWIN transformer,enabling the network to process spherical representations with minimalcomputational overhead. We demonstrate the superior performance of our model onboth synthetic and real automotive datasets, as well as a selection of otherimage datasets, for semantic segmentation, depth regression and classificationtasks. Our code is publicly available athttps://github.com/JanEGerken/HEAL-SWIN.</description><author>Oscar Carlsson, Jan E. Gerken, Hampus Linander, Heiner Spieß, Fredrik Ohlsson, Christoffer Petersson, Daniel Persson</author><pubDate>Wed, 08 May 2024 16:49:58 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.07313v2</guid></item><item><title>PACIA: Parameter-Efficient Adapter for Few-Shot Molecular Property Prediction</title><link>http://arxiv.org/abs/2310.00614v2</link><description>Molecular property prediction (MPP) plays a crucial role in biomedicalapplications, but it often encounters challenges due to a scarcity of labeleddata. Existing works commonly adopt gradient-based strategy to update a largeamount of parameters for task-level adaptation. However, the increase ofadaptive parameters can lead to overfitting and poor performance. Observingthat graph neural network (GNN) performs well as both encoder and predictor, wepropose PACIA, a parameter-efficient GNN adapter for few-shot MPP. We design aunified adapter to generate a few adaptive parameters to modulate the messagepassing process of GNN. We then adopt a hierarchical adaptation mechanism toadapt the encoder at task-level and the predictor at query-level by the unifiedGNN adapter. Extensive results show that PACIA obtains the state-of-the-artperformance in few-shot MPP problems, and our proposed hierarchical adaptationmechanism is rational and effective.</description><author>Shiguang Wu, Yaqing Wang, Quanming Yao</author><pubDate>Wed, 08 May 2024 16:49:54 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.00614v2</guid></item><item><title>The Potential and Implications of Generative AI on HCI Education</title><link>http://arxiv.org/abs/2405.05154v1</link><description>Generative AI (GAI) is impacting teaching and learning directly or indirectlyacross a range of subjects and disciplines. As educators, we need to understandthe potential and limitations of AI in HCI education and ensure our graduatingHCI students are aware of the potential and limitations of AI in HCI. In thispaper, we report on the main pedagogical insights gained from the inclusion ofgenerative AI into a 10 week undergraduate module. We designed the module toencourage student experimentation with GAI models as part of the design briefrequirement and planned practical sessions and discussions. Our insights arebased on replies to a survey sent out to the students after completing themodule. Our key findings, for HCI educators, report on the use of AI as apersona for developing project ideas and creating resources for design, and AIas a mirror for reflecting students' understanding of key concepts and ideasand highlighting knowledge gaps. We also discuss potential pitfalls that shouldbe considered and the need to assess students' literacies and assumptions ofGAIs as pedagogical tools. Finally, we put forward the case for educators totake the opportunities GAI presents as an educational tool and be experimental,creative, and courageous in their practice. We end with a discussion of ourfindings in relation to the TPACK framework in HCI.</description><author>Ahmed Kharrufa, Ian G Johnson</author><pubDate>Wed, 08 May 2024 16:46:31 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.05154v1</guid></item><item><title>VRMM: A Volumetric Relightable Morphable Head Model</title><link>http://arxiv.org/abs/2402.04101v2</link><description>In this paper, we introduce the Volumetric Relightable Morphable Model(VRMM), a novel volumetric and parametric facial prior for 3D face modeling.While recent volumetric prior models offer improvements over traditionalmethods like 3D Morphable Models (3DMMs), they face challenges in modellearning and personalized reconstructions. Our VRMM overcomes these byemploying a novel training framework that efficiently disentangles and encodeslatent spaces of identity, expression, and lighting into low-dimensionalrepresentations. This framework, designed with self-supervised learning,significantly reduces the constraints for training data, making it morefeasible in practice. The learned VRMM offers relighting capabilities andencompasses a comprehensive range of expressions. We demonstrate theversatility and effectiveness of VRMM through various applications like avatargeneration, facial reconstruction, and animation. Additionally, we address thecommon issue of overfitting in generative volumetric models with a novelprior-preserving personalization framework based on VRMM. Such an approachenables high-quality 3D face reconstruction from even a single portrait input.Our experiments showcase the potential of VRMM to significantly enhance thefield of 3D face modeling.</description><author>Haotian Yang, Mingwu Zheng, Chongyang Ma, Yu-Kun Lai, Pengfei Wan, Haibin Huang</author><pubDate>Wed, 08 May 2024 16:45:34 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.04101v2</guid></item><item><title>Hybrid Convolutional Neural Networks with Reliability Guarantee</title><link>http://arxiv.org/abs/2405.05146v1</link><description>Making AI safe and dependable requires the generation of dependable modelsand dependable execution of those models. We propose redundant execution as awell-known technique that can be used to ensure reliable execution of the AImodel. This generic technique will extend the application scope ofAI-accelerators that do not feature well-documented safety or dependabilityproperties. Typical redundancy techniques incur at least double or triple thecomputational expense of the original. We adopt a co-design approach,integrating reliable model execution with non-reliable execution, focusing thatadditional computational expense only where it is strictly necessary. Wedescribe the design, implementation and some preliminary results of a hybridCNN.</description><author>Hans Dermot Doran, Suzana Veljanovska</author><pubDate>Wed, 08 May 2024 16:39:38 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.05146v1</guid></item><item><title>Provable Acceleration of Nesterov's Accelerated Gradient Method over Heavy Ball Method in Training Over-Parameterized Neural Networks</title><link>http://arxiv.org/abs/2208.03941v4</link><description>Due to its simplicity and efficiency, the first-order gradient method hasbeen extensively employed in training neural networks. Although theoptimization problem of the neural network is non-convex, recent research hasproved that the first-order method is capable of attaining a global minimumduring training over-parameterized neural networks, where the number ofparameters is significantly larger than that of training instances. Momentummethods, including the heavy ball (HB) method and Nesterov's acceleratedgradient (NAG) method, are the workhorse of first-order gradient methods owningto their accelerated convergence. In practice, NAG often exhibits superiorperformance than HB. However, current theoretical works fail to distinguishtheir convergence difference in training neural networks. To fill this gap, weconsider the training problem of the two-layer ReLU neural network underover-parameterization and random initialization. Leveraging high-resolutiondynamical systems and neural tangent kernel (NTK) theory, our result not onlyestablishes tighter upper bounds of the convergence rate for both HB and NAG,but also provides the first theoretical guarantee for the acceleration of NAGover HB in training neural networks. Finally, we validate our theoreticalresults on three benchmark datasets.</description><author>Xin Liu, Wei Tao, Wei Li, Dazhi Zhan, Jun Wang, Zhisong Pan</author><pubDate>Wed, 08 May 2024 16:34:45 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2208.03941v4</guid></item><item><title>Bake off redux: a review and experimental evaluation of recent time series classification algorithms</title><link>http://arxiv.org/abs/2304.13029v3</link><description>In 2017, a research paper compared 18 Time Series Classification (TSC)algorithms on 85 datasets from the University of California, Riverside (UCR)archive. This study, commonly referred to as a `bake off', identified that onlynine algorithms performed significantly better than the Dynamic Time Warping(DTW) and Rotation Forest benchmarks that were used. The study categorised eachalgorithm by the type of feature they extract from time series data, forming ataxonomy of five main algorithm types. This categorisation of algorithmsalongside the provision of code and accessible results for reproducibility hashelped fuel an increase in popularity of the TSC field. Over six years havepassed since this bake off, the UCR archive has expanded to 112 datasets andthere have been a large number of new algorithms proposed. We revisit the bakeoff, seeing how each of the proposed categories have advanced since theoriginal publication, and evaluate the performance of newer algorithms againstthe previous best-of-category using an expanded UCR archive. We extend thetaxonomy to include three new categories to reflect recent developments.Alongside the originally proposed distance, interval, shapelet, dictionary andhybrid based algorithms, we compare newer convolution and feature basedalgorithms as well as deep learning approaches. We introduce 30 classificationdatasets either recently donated to the archive or reformatted to the TSCformat, and use these to further evaluate the best performing algorithm fromeach category. Overall, we find that two recently proposed algorithms,Hydra+MultiROCKET and HIVE-COTEv2, perform significantly better than otherapproaches on both the current and new TSC problems.</description><author>Matthew Middlehurst, Patrick Schäfer, Anthony Bagnall</author><pubDate>Wed, 08 May 2024 16:33:11 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2304.13029v3</guid></item><item><title>Identifying every building's function in large-scale urban areas with multi-modality remote-sensing data</title><link>http://arxiv.org/abs/2405.05133v1</link><description>Buildings, as fundamental man-made structures in urban environments, serve ascrucial indicators for understanding various city function zones. Rapidurbanization has raised an urgent need for efficiently surveying buildingfootprints and functions. In this study, we proposed a semi-supervisedframework to identify every building's function in large-scale urban areas withmulti-modality remote-sensing data. In detail, optical images, building height,and nighttime-light data are collected to describe the morphological attributesof buildings. Then, the area of interest (AOI) and building masks from thevolunteered geographic information (VGI) data are collected to form sparselylabeled samples. Furthermore, the multi-modality data and weak labels areutilized to train a segmentation model with a semi-supervised strategy.Finally, results are evaluated by 20,000 validation points and statisticalsurvey reports from the government. The evaluations reveal that the producedfunction maps achieve an OA of 82% and Kappa of 71% among 1,616,796 buildingsin Shanghai, China. This study has the potential to support large-scale urbanmanagement and sustainable urban development. All collected data and producedmaps are open access at https://github.com/LiZhuoHong/BuildingMap.</description><author>Zhuohong Li, Wei He, Jiepan Li, Hongyan Zhang</author><pubDate>Wed, 08 May 2024 16:32:20 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.05133v1</guid></item><item><title>Multi-scale Bottleneck Transformer for Weakly Supervised Multimodal Violence Detection</title><link>http://arxiv.org/abs/2405.05130v1</link><description>Weakly supervised multimodal violence detection aims to learn a violencedetection model by leveraging multiple modalities such as RGB, optical flow,and audio, while only video-level annotations are available. In the pursuit ofeffective multimodal violence detection (MVD), information redundancy, modalityimbalance, and modality asynchrony are identified as three key challenges. Inthis work, we propose a new weakly supervised MVD method that explicitlyaddresses these challenges. Specifically, we introduce a multi-scale bottlenecktransformer (MSBT) based fusion module that employs a reduced number ofbottleneck tokens to gradually condense information and fuse each pair ofmodalities and utilizes a bottleneck token-based weighting scheme to highlightmore important fused features. Furthermore, we propose a temporal consistencycontrast loss to semantically align pairwise fused features. Experiments on thelargest-scale XD-Violence dataset demonstrate that the proposed method achievesstate-of-the-art performance. Code is available athttps://github.com/shengyangsun/MSBT.</description><author>Shengyang Sun, Xiaojin Gong</author><pubDate>Wed, 08 May 2024 16:27:08 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.05130v1</guid></item><item><title>Ethical Implications of ChatGPT in Higher Education: A Scoping Review</title><link>http://arxiv.org/abs/2311.14378v2</link><description>This scoping review explores the ethical challenges of using ChatGPT inhigher education. By reviewing recent academic articles in English, Chinese,and Japanese, we aimed to provide a deep dive review and identify gaps in theliterature. Drawing on Arksey and O'Malley's (2005) scoping review framework,we defined search terms and identified relevant publications from fourdatabases in the three target languages. The research results showed that themajority of the papers were discussion papers, but there was some earlyempirical work. The ethical issues highlighted in these works mainly concernacademic integrity, assessment issues, and data protection. Given the rapiddeployment of generative artificial intelligence, it is imperative foreducators to conduct more empirical studies to develop sound ethical policiesfor its use.</description><author>Ming Li, Ariunaa Enkhtur, Fei Cheng, Beverley Anne Yamamoto</author><pubDate>Wed, 08 May 2024 16:24:17 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.14378v2</guid></item><item><title>XAMPLER: Learning to Retrieve Cross-Lingual In-Context Examples</title><link>http://arxiv.org/abs/2405.05116v1</link><description>Recent studies have shown that leveraging off-the-shelf or fine-tunedretrievers, capable of retrieving high-quality in-context examples,significantly improves in-context learning of English. However, adapting thesemethods to other languages, especially low-resource ones, presents challengesdue to the scarcity of available cross-lingual retrievers and annotated data.In this paper, we introduce XAMPLER: Cross-Lingual Example Retrieval, a methodtailored to tackle the challenge of cross-lingual in-context learning usingonly annotated English data. XAMPLER first trains a retriever withpositive/negative English samples, which are constructed based on thepredictions of the multilingual large language model for in-context learning.Then, the trained retriever is directly employed to retrieve English examplesas few-shot examples for in-context learning of target languages. Experimentson the massively multilingual text classification benchmark of SIB200 with 176languages demonstrate that XAMPLER substantially improves the in-contextlearning performance across languages. Our code is available athttps://github.com/cisnlp/XAMPLER.</description><author>Peiqin Lin, André F. T. Martins, Hinrich Schütze</author><pubDate>Wed, 08 May 2024 16:13:33 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.05116v1</guid></item><item><title>Bump hunting through density curvature features</title><link>http://arxiv.org/abs/2208.00174v3</link><description>Bump hunting deals with finding in sample spaces meaningful data subsetsknown as bumps. These have traditionally been conceived as modal or concaveregions in the graph of the underlying density function. We define an abstractbump construct based on curvature functionals of the probability density. Then,we explore several alternative characterizations involving derivatives up tosecond order. In particular, a suitable implementation of Good and Gaskins'original concave bumps is proposed in the multivariate case. Moreover, we bringto exploratory data analysis concepts like the mean curvature and the Laplacianthat have produced good results in applied domains. Our methodology addressesthe approximation of the curvature functional with a plug-in kernel densityestimator. We provide theoretical results that assure the asymptoticconsistency of bump boundaries in the Hausdorff distance with affordableconvergence rates. We also present asymptotically valid and consistentconfidence regions bounding curvature bumps. The theory is illustrated throughseveral use cases in sports analytics with datasets from the NBA, MLB and NFL.We conclude that the different curvature instances effectively combine togenerate insightful visualizations.</description><author>José E. Chacón, Javier Fernández Serrano</author><pubDate>Wed, 08 May 2024 16:09:28 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2208.00174v3</guid></item><item><title>Uncertainty quantification in metric spaces</title><link>http://arxiv.org/abs/2405.05110v1</link><description>This paper introduces a novel uncertainty quantification framework forregression models where the response takes values in a separable metric space,and the predictors are in a Euclidean space. The proposed algorithms canefficiently handle large datasets and are agnostic to the predictive base modelused. Furthermore, the algorithms possess asymptotic consistency guaranteesand, in some special homoscedastic cases, we provide non-asymptotic guarantees.To illustrate the effectiveness of the proposed uncertainty quantificationframework, we use a linear regression model for metric responses (known as theglobal Fr\'echet model) in various clinical applications related to precisionand digital medicine. The different clinical outcomes analyzed are representedas complex statistical objects, including multivariate Euclidean data,Laplacian graphs, and probability distributions.</description><author>Gábor Lugosi, Marcos Matabuena</author><pubDate>Wed, 08 May 2024 16:06:02 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.05110v1</guid></item><item><title>QFMTS: Generating Query-Focused Summaries over Multi-Table Inputs</title><link>http://arxiv.org/abs/2405.05109v1</link><description>Table summarization is a crucial task aimed at condensing information fromtabular data into concise and comprehensible textual summaries. However,existing approaches often fall short of adequately meeting users' informationand quality requirements and tend to overlook the complexities of real-worldqueries. In this paper, we propose a novel method to address these limitationsby introducing query-focused multi-table summarization. Our approach, whichcomprises a table serialization module, a summarization controller, and a largelanguage model (LLM), utilizes textual queries and multiple tables to generatequery-dependent table summaries tailored to users' information needs. Tofacilitate research in this area, we present a comprehensive datasetspecifically tailored for this task, consisting of 4909 query-summary pairs,each associated with multiple tables. Through extensive experiments using ourcurated dataset, we demonstrate the effectiveness of our proposed methodcompared to baseline approaches. Our findings offer insights into thechallenges of complex table reasoning for precise summarization, contributingto the advancement of research in query-focused multi-table summarization.</description><author>Weijia Zhang, Vaishali Pal, Jia-Hong Huang, Evangelos Kanoulas, Maarten de Rijke</author><pubDate>Wed, 08 May 2024 16:05:55 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.05109v1</guid></item><item><title>Unveiling Molecular Moieties through Hierarchical Graph Explainability</title><link>http://arxiv.org/abs/2402.01744v3</link><description>Background: Graph Neural Networks (GNN) have emerged in very recent years asa powerful tool for supporting in silico Virtual Screening. In this work wepresent a GNN which uses Graph Convolutional architectures to achieve veryaccurate multi-target screening. We also devised a hierarchical ExplainableArtificial Intelligence (XAI) technique to catch information directly at atom,ring, and whole molecule level by leveraging the message passing mechanism. Inthis way, we find the most relevant moieties involved in bioactivityprediction. Results: We report a state-of-the-art GNN classifier on twentyCyclin-dependent Kinase targets in support of VS. Our classifier outperformsprevious SOTA approaches proposed by the authors. Moreover, a CDK1-onlyhigh-sensitivity version of the GNN has been designed to use our explainer inorder to avoid the inherent bias of multi-class models. The hierarchicalexplainer has been validated by an expert chemist on 19 approved drugs on CDK1.Our explainer provided information in accordance to the docking analysis for 17out of the 19 test drugs. Conclusion: Our approach is a valid support forshortening both the screening and the hit-to-lead phase. Detailed knowledgeabout the molecular substructures that play a role in the inhibitory action,can help the computational chemist to gain insights into the pharmacophoricfunction of the molecule also for repurposing purposes. Scientific ContributionStatement: The core scientific innovation of our work is the use of ahierarchical XAI approach on a GNN trained for a ligand-based VS task. Theapplication of the hierarchical explainer allows for eliciting also structuralinformation...</description><author>Paolo Sortino, Salvatore Contino, Ugo Perricone, Roberto Pirrone</author><pubDate>Wed, 08 May 2024 16:04:37 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.01744v3</guid></item><item><title>Biology-inspired joint distribution neurons based on Hierarchical Correlation Reconstruction allowing for multidirectional neural networks</title><link>http://arxiv.org/abs/2405.05097v1</link><description>Popular artificial neural networks (ANN) optimize parameters forunidirectional value propagation, assuming some guessed parametrization typelike Multi-Layer Perceptron (MLP) or Kolmogorov-Arnold Network (KAN). Incontrast, for biological neurons e.g. "it is not uncommon for axonalpropagation of action potentials to happen in both directions" \cite{axon} -suggesting they are optimized to continuously operate in multidirectional way.Additionally, statistical dependencies a single neuron could model is not just(expected) value dependence, but entire joint distributions including alsohigher moments. Such agnostic joint distribution neuron would allow formultidirectional propagation (of distributions or values) e.g. $\rho(x|y,z)$ or$\rho(y,z|x)$ by substituting to $\rho(x,y,z)$ and normalizing. There will bediscussed Hierarchical Correlation Reconstruction (HCR) for such neuron model:assuming $\rho(x,y,z)=\sum_{ijk} a_{ijk} f_i(x) f_j(y) f_k(z)$ typeparametrization of joint distribution with polynomial basis $f_i$, which allowsfor flexible, inexpensive processing including nonlinearities, direct modelestimation and update, trained through standard backpropagation or novel waysfor such structure up to tensor decomposition. Using only pairwise(input-output) dependencies, its expected value prediction becomes KAN-likewith trained activation functions as polynomials, can be extended by addinghigher order dependencies through included products - in consciousinterpretable way, allowing for multidirectional propagation of both values andprobability densities.</description><author>Jarek Duda</author><pubDate>Wed, 08 May 2024 15:49:27 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.05097v1</guid></item><item><title>Cultural Alignment in Large Language Models: An Explanatory Analysis Based on Hofstede's Cultural Dimensions</title><link>http://arxiv.org/abs/2309.12342v2</link><description>The deployment of large language models (LLMs) raises concerns regardingtheir cultural misalignment and potential ramifications on individuals andsocieties with diverse cultural backgrounds. While the discourse has focusedmainly on political and social biases, our research proposes a CulturalAlignment Test (Hoftede's CAT) to quantify cultural alignment using Hofstede'scultural dimension framework, which offers an explanatory cross-culturalcomparison through the latent variable analysis. We apply our approach toquantitatively evaluate LLMs, namely Llama 2, GPT-3.5, and GPT-4, against thecultural dimensions of regions like the United States, China, and Arabcountries, using different prompting styles and exploring the effects oflanguage-specific fine-tuning on the models' behavioural tendencies andcultural values. Our results quantify the cultural alignment of LLMs and revealthe difference between LLMs in explanatory cultural dimensions. Our studydemonstrates that while all LLMs struggle to grasp cultural values, GPT-4 showsa unique capability to adapt to cultural nuances, particularly in Chinesesettings. However, it faces challenges with American and Arab cultures. Theresearch also highlights that fine-tuning LLama 2 models with differentlanguages changes their responses to cultural questions, emphasizing the needfor culturally diverse development in AI for worldwide acceptance and ethicaluse. For more details or to contribute to this research, visit our GitHub pagehttps://github.com/reemim/Hofstedes_CAT/</description><author>Reem I. Masoud, Ziquan Liu, Martin Ferianc, Philip Treleaven, Miguel Rodrigues</author><pubDate>Wed, 08 May 2024 15:48:39 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2309.12342v2</guid></item><item><title>Legally Binding but Unfair? Towards Assessing Fairness of Privacy Policies</title><link>http://arxiv.org/abs/2403.08115v2</link><description>Privacy policies are expected to inform data subjects about their dataprotection rights and should explain the data controller's data managementpractices. Privacy policies only fulfill their purpose, if they are correctlyinterpreted, understood, and trusted by the data subject. This implies that aprivacy policy is written in a fair way, e.g., it does not use polarizingterms, does not require a certain education, or does not assume a particularsocial background. We outline our approach to assessing fairness in privacypolicies. We identify from fundamental legal sources and fairness research, howthe dimensions informational fairness, representational fairness and ethics /morality are related to privacy policies. We propose options to automaticallyassess policies in these fairness dimensions, based on text statistics,linguistic methods and artificial intelligence. We conduct initial experimentswith German privacy policies to provide evidence that our approach isapplicable. Our experiments indicate that there are issues in all threedimensions of fairness. This is important, as future privacy policies may beused in a corpus for legal artificial intelligence models.</description><author>Vincent Freiberger, Erik Buchmann</author><pubDate>Wed, 08 May 2024 15:47:39 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.08115v2</guid></item><item><title>Approximation properties relative to continuous scale space for hybrid discretizations of Gaussian derivative operators</title><link>http://arxiv.org/abs/2405.05095v1</link><description>This paper presents an analysis of properties of two hybrid discretizationmethods for Gaussian derivatives, based on convolutions with either thenormalized sampled Gaussian kernel or the integrated Gaussian kernel followedby central differences. The motivation for studying these discretizationmethods is that in situations when multiple spatial derivatives of differentorder are needed at the same scale level, they can be computed significantlymore efficiently compared to more direct derivative approximations based onexplicit convolutions with either sampled Gaussian kernels or integratedGaussian kernels. While these computational benefits do also hold for the genuinely discreteapproach for computing discrete analogues of Gaussian derivatives, based onconvolution with the discrete analogue of the Gaussian kernel followed bycentral differences, the underlying mathematical primitives for the discreteanalogue of the Gaussian kernel, in terms of modified Bessel functions ofinteger order, may not be available in certain frameworks for image processing,such as when performing deep learning based on scale-parameterized filters interms of Gaussian derivatives, with learning of the scale levels. In this paper, we present a characterization of the properties of thesehybrid discretization methods, in terms of quantitative performance measuresconcerning the amount of spatial smoothing that they imply, as well as therelative consistency of scale estimates obtained from scale-invariant featuredetectors with automatic scale selection, with an emphasis on the behaviour forvery small values of the scale parameter, which may differ significantly fromcorresponding results obtained from the fully continuous scale-space theory, aswell as between different types of discretization methods.</description><author>Tony Lindeberg</author><pubDate>Wed, 08 May 2024 15:44:34 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.05095v1</guid></item><item><title>Unravelling Responsibility for AI</title><link>http://arxiv.org/abs/2308.02608v2</link><description>It is widely acknowledged that we need to establish where responsibility liesfor the outputs and impacts of AI-enabled systems. But without a clear andprecise understanding of what "responsibility" means, deliberations about whereresponsibility lies will be, at best, unfocused and incomplete and, at worst,misguided. To address this concern, this paper draws upon central distinctionsin philosophy and law to clarify the concept of responsibility for AI forpolicymakers, practitioners, researchers and students from non-philosophicaland non-legal backgrounds. Taking the three-part formulation "Actor A isresponsible for Occurrence O," the paper unravels the concept of responsibilityto clarify that there are different possibilities of who is responsible for AI,the senses in which they are responsible, and aspects of events they areresponsible for. Criteria and conditions for fitting attributions ofresponsibility in the core senses (causal responsibility, role-responsibility,liability responsibility and moral responsibility) are articulated to promotean understanding of when responsibility attributions would be inappropriate orunjust. The analysis is presented with a graphical notation to facilitateinformal diagrammatic reasoning and discussion about specific cases. It isillustrated by application to a scenario of a fatal collision between anautonomous AI-enabled ship and a traditional, crewed vessel at sea.</description><author>Zoe Porter, Philippa Ryan, Phillip Morgan, Joanna Al-Qaddoumi, Bernard Twomey, John McDermid, Ibrahim Habli</author><pubDate>Wed, 08 May 2024 15:37:59 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2308.02608v2</guid></item><item><title>DistGrid: Scalable Scene Reconstruction with Distributed Multi-resolution Hash Grid</title><link>http://arxiv.org/abs/2405.04416v2</link><description>Neural Radiance Field~(NeRF) achieves extremely high quality in object-scaledand indoor scene reconstruction. However, there exist some challenges whenreconstructing large-scale scenes. MLP-based NeRFs suffer from limited networkcapacity, while volume-based NeRFs are heavily memory-consuming when the sceneresolution increases. Recent approaches propose to geographically partition thescene and learn each sub-region using an individual NeRF. Such partitioningstrategies help volume-based NeRF exceed the single GPU memory limit and scaleto larger scenes. However, this approach requires multiple background NeRF tohandle out-of-partition rays, which leads to redundancy of learning. Inspiredby the fact that the background of current partition is the foreground ofadjacent partition, we propose a scalable scene reconstruction method based onjoint Multi-resolution Hash Grids, named DistGrid. In this method, the scene isdivided into multiple closely-paved yet non-overlapped Axis-Aligned BoundingBoxes, and a novel segmented volume rendering method is proposed to handlecross-boundary rays, thereby eliminating the need for background NeRFs. Theexperiments demonstrate that our method outperforms existing methods on allevaluated large-scale scenes, and provides visually plausible scenereconstruction. The scalability of our method on reconstruction quality isfurther evaluated qualitatively and quantitatively.</description><author>Sidun Liu, Peng Qiao, Zongxin Ye, Wenyu Li, Yong Dou</author><pubDate>Wed, 08 May 2024 15:27:52 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.04416v2</guid></item><item><title>Variational Self-Supervised Contrastive Learning Using Beta Divergence</title><link>http://arxiv.org/abs/2312.00824v3</link><description>Learning a discriminative semantic space using unlabelled and noisy dataremains unaddressed in a multi-label setting. We present a contrastiveself-supervised learning method which is robust to data noise, grounded in thedomain of variational methods. The method (VCL) utilizes variationalcontrastive learning with beta-divergence to learn robustly from unlabelleddatasets, including uncurated and noisy datasets. We demonstrate theeffectiveness of the proposed method through rigorous experiments includinglinear evaluation and fine-tuning scenarios with multi-label datasets in theface understanding domain. In almost all tested scenarios, VCL surpasses theperformance of state-of-the-art self-supervised methods, achieving a noteworthyincrease in accuracy.</description><author>Mehmet Can Yavuz, Berrin Yanikoglu</author><pubDate>Wed, 08 May 2024 15:27:20 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.00824v3</guid></item><item><title>Robust deep learning from weakly dependent data</title><link>http://arxiv.org/abs/2405.05081v1</link><description>Recent developments on deep learning established some theoretical propertiesof deep neural networks estimators. However, most of the existing works on thistopic are restricted to bounded loss functions or (sub)-Gaussian or boundedinput. This paper considers robust deep learning from weakly dependentobservations, with unbounded loss function and unbounded input/output. It isonly assumed that the output variable has a finite $r$ order moment, with $r&gt;1$. Non asymptotic bounds for the expected excess risk of the deep neuralnetwork estimator are established under strong mixing, and $\psi$-weakdependence assumptions on the observations. We derive a relationship betweenthese bounds and $r$, and when the data have moments of any order (that is$r=\infty$), the convergence rate is close to some well-known results. When thetarget predictor belongs to the class of H\"older smooth functions withsufficiently large smoothness index, the rate of the expected excess risk forexponentially strongly mixing data is close to or as same as those for obtainedwith i.i.d. samples. Application to robust nonparametric regression and robustnonparametric autoregression are considered. The simulation study for modelswith heavy-tailed errors shows that, robust estimators with absolute loss andHuber loss function outperform the least squares method.</description><author>William Kengne, Modou Wade</author><pubDate>Wed, 08 May 2024 15:25:40 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.05081v1</guid></item><item><title>Concerns on Bias in Large Language Models when Creating Synthetic Personae</title><link>http://arxiv.org/abs/2405.05080v1</link><description>This position paper explores the benefits, drawbacks, and ethicalconsiderations of incorporating synthetic personae in HCI research,particularly focusing on the customization challenges beyond the limitations ofcurrent Large Language Models (LLMs). These perspectives are derived from theinitial results of a sub-study employing vignettes to showcase the existence ofbias within black-box LLMs and explore methods for manipulating them. The studyaims to establish a foundation for understanding the challenges associated withthese models, emphasizing the necessity of thorough testing before utilizingthem to create synthetic personae for HCI research.</description><author>Helena A. Haxvig</author><pubDate>Wed, 08 May 2024 15:24:11 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.05080v1</guid></item><item><title>Power Variable Projection for Initialization-Free Large-Scale Bundle Adjustment</title><link>http://arxiv.org/abs/2405.05079v1</link><description>Initialization-free bundle adjustment (BA) remains largely uncharted. WhileLevenberg-Marquardt algorithm is the golden method to solve the BA problem, itgenerally relies on a good initialization. In contrast, the under-exploredVariable Projection algorithm (VarPro) exhibits a wide convergence basin evenwithout initialization. Coupled with object space error formulation, recentworks have shown its ability to solve (small-scale) initialization-free bundleadjustment problem. We introduce Power Variable Projection (PoVar), extending arecent inverse expansion method based on power series. Importantly, we link thepower series expansion to Riemannian manifold optimization. This projectiveframework is crucial to solve large-scale bundle adjustment problem withoutinitialization. Using the real-world BAL dataset, we experimentally demonstratethat our solver achieves state-of-the-art results in terms of speed andaccuracy. In particular, our work is the first, to our knowledge, thataddresses the scalability of BA without initialization and opens new venues forinitialization-free Structure-from-Motion.</description><author>Simon Weber, Je Hyeong Hong, Daniel Cremers</author><pubDate>Wed, 08 May 2024 15:22:39 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.05079v1</guid></item><item><title>Towards Efficient Training and Evaluation of Robust Models against $l_0$ Bounded Adversarial Perturbations</title><link>http://arxiv.org/abs/2405.05075v1</link><description>This work studies sparse adversarial perturbations bounded by $l_0$ norm. Wepropose a white-box PGD-like attack method named sparse-PGD to effectively andefficiently generate such perturbations. Furthermore, we combine sparse-PGDwith a black-box attack to comprehensively and more reliably evaluate themodels' robustness against $l_0$ bounded adversarial perturbations. Moreover,the efficiency of sparse-PGD enables us to conduct adversarial training tobuild robust models against sparse perturbations. Extensive experimentsdemonstrate that our proposed attack algorithm exhibits strong performance indifferent scenarios. More importantly, compared with other robust models, ouradversarially trained model demonstrates state-of-the-art robustness againstvarious sparse attacks. Codes are available athttps://github.com/CityU-MLO/sPGD.</description><author>Xuyang Zhong, Yixiao Huang, Chen Liu</author><pubDate>Wed, 08 May 2024 15:18:13 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.05075v1</guid></item><item><title>Novel Actor-Critic Algorithm for Robust Decision Making of CAV under Delays and Loss of V2X Data</title><link>http://arxiv.org/abs/2405.05072v1</link><description>Current autonomous driving systems heavily rely on V2X communication data toenhance situational awareness and the cooperation between vehicles. However, amajor challenge when using V2X data is that it may not be availableperiodically because of unpredictable delays and data loss during wirelesstransmission between road stations and the receiver vehicle. This issue shouldbe considered when designing control strategies for connected and autonomousvehicles. Therefore, this paper proposes a novel 'Blind Actor-Critic' algorithmthat guarantees robust driving performance in V2X environment with delayedand/or lost data. The novel algorithm incorporates three key mechanisms: avirtual fixed sampling period, a combination of Temporal-Difference and MonteCarlo learning, and a numerical approximation of immediate reward values. Toaddress the temporal aperiodicity problem of V2X data, we first illustrate thischallenge. Then, we provide a detailed explanation of the Blind Actor-Criticalgorithm where we highlight the proposed components to compensate for thetemporal aperiodicity problem of V2X data. We evaluate the performance of ouralgorithm in a simulation environment and compare it to benchmark approaches.The results demonstrate that training metrics are improved compared toconventional actor-critic algorithms. Additionally, testing results show thatour approach provides robust control, even under low V2X network reliabilitylevels.</description><author>Zine el abidine Kherroubi</author><pubDate>Wed, 08 May 2024 15:14:03 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.05072v1</guid></item><item><title>Particle density and critical point for studying site percolation by finite size scaling</title><link>http://arxiv.org/abs/2311.14725v2</link><description>Machine learning has recently achieved remarkable success in studying phasetransitions. It is generally believed that the latent variables of unsupervisedlearning can capture the information related to phase transitions, which isusually achieved through the so-called order parameter. In most models, forinstance the Ising, the order parameters are simply the particle numberdensities. The percolation, the simplest model which can generate a phasetransition, however, has a unique order parameter which is not particle numberdensity. In this paper, we use unsupervised learning to study the relationshipbetween particle number density, critical point, and latent variables in thesite percolation model. It is found that if the input of learning is theoriginal configuration, then the output of unsupervised learning does notconvey any information related to the phase transition. Therefore, the maximumcluster is employed in order to effectively capture the critical point of themodel. Unsupervised learning yields reliable results consistent with MonteCarlo simulations. We also propose a method called Fake Finite Size Scaling(FFSS) to calculate the critical value, which improves the accuracy of fittingto a great extent.</description><author>Dian Xu, Shanshan Wang, Feng Gao, Wei Li, Jianmin Shen</author><pubDate>Wed, 08 May 2024 15:13:14 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.14725v2</guid></item><item><title>Causal Flow-based Variational Auto-Encoder for Disentangled Causal Representation Learning</title><link>http://arxiv.org/abs/2304.09010v4</link><description>Disentangled representation learning aims to learn low-dimensionalrepresentations of data, where each dimension corresponds to an underlyinggenerative factor. Currently, Variational Auto-Encoder (VAE) are widely usedfor disentangled representation learning, with the majority of methods assumingindependence among generative factors. However, in real-world scenarios,generative factors typically exhibit complex causal relationships. We thusdesign a new VAE-based framework named Disentangled Causal VariationalAuto-Encoder (DCVAE), which includes a variant of autoregressive flows known ascausal flows, capable of learning effective causal disentangledrepresentations. We provide a theoretical analysis of the disentanglementidentifiability of DCVAE, ensuring that our model can effectively learn causaldisentangled representations. The performance of DCVAE is evaluated on bothsynthetic and real-world datasets, demonstrating its outstanding capability inachieving causal disentanglement and performing intervention experiments.Moreover, DCVAE exhibits remarkable performance on downstream tasks and has thepotential to learn the true causal structure among factors.</description><author>Di Fan, Yannian Kou, Chuanhou Gao</author><pubDate>Wed, 08 May 2024 15:12:47 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2304.09010v4</guid></item><item><title>Designing Skill-Compatible AI: Methodologies and Frameworks in Chess</title><link>http://arxiv.org/abs/2405.05066v1</link><description>Powerful artificial intelligence systems are often used in settings wherethey must interact with agents that are computationally much weaker, forexample when they work alongside humans or operate in complex environmentswhere some tasks are handled by algorithms, heuristics, or other entities ofvarying computational power. For AI agents to successfully interact in thesesettings, however, achieving superhuman performance alone is not sufficient;they also need to account for suboptimal actions or idiosyncratic style fromtheir less-skilled counterparts. We propose a formal evaluation framework forassessing the compatibility of near-optimal AI with interaction partners whomay have much lower levels of skill; we use popular collaborative chessvariants as model systems to study and develop AI agents that can successfullyinteract with lower-skill entities. Traditional chess engines designed tooutput near-optimal moves prove to be inadequate partners when paired withengines of various lower skill levels in this domain, as they are not designedto consider the presence of other agents. We contribute three methodologies toexplicitly create skill-compatible AI agents in complex decision-makingsettings, and two chess game frameworks designed to foster collaborationbetween powerful AI agents and less-skilled partners. On these frameworks, ouragents outperform state-of-the-art chess AI (based on AlphaZero) despite beingweaker in conventional chess, demonstrating that skill-compatibility is atangible trait that is qualitatively and measurably distinct from rawperformance. Our evaluations further explore and clarify the mechanisms bywhich our agents achieve skill-compatibility.</description><author>Karim Hamade, Reid McIlroy-Young, Siddhartha Sen, Jon Kleinberg, Ashton Anderson</author><pubDate>Wed, 08 May 2024 15:04:35 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.05066v1</guid></item><item><title>Scalable Mechanism Design for Multi-Agent Path Finding</title><link>http://arxiv.org/abs/2401.17044v2</link><description>Multi-Agent Path Finding (MAPF) involves determining paths for multipleagents to travel simultaneously and collision-free through a shared area towardgiven goal locations. This problem is computationally complex, especially whendealing with large numbers of agents, as is common in realistic applicationslike autonomous vehicle coordination. Finding an optimal solution is oftencomputationally infeasible, making the use of approximate, suboptimalalgorithms essential. Adding to the complexity, agents might act in aself-interested and strategic way, possibly misrepresenting their goals to theMAPF algorithm if it benefits them. Although the field of mechanism designoffers tools to align incentives, using these tools without carefulconsideration can fail when only having access to approximately optimaloutcomes. In this work, we introduce the problem of scalable mechanism designfor MAPF and propose three strategyproof mechanisms, two of which even useapproximate MAPF algorithms. We test our mechanisms on realistic MAPF domainswith problem sizes ranging from dozens to hundreds of agents. We find that theyimprove welfare beyond a simple baseline.</description><author>Paul Friedrich, Yulun Zhang, Michael Curry, Ludwig Dierks, Stephen McAleer, Jiaoyang Li, Tuomas Sandholm, Sven Seuken</author><pubDate>Wed, 08 May 2024 15:03:20 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.17044v2</guid></item><item><title>Conversational Topic Recommendation in Counseling and Psychotherapy with Decision Transformer and Large Language Models</title><link>http://arxiv.org/abs/2405.05060v1</link><description>Given the increasing demand for mental health assistance, artificialintelligence (AI), particularly large language models (LLMs), may be valuablefor integration into automated clinical support systems. In this work, weleverage a decision transformer architecture for topic recommendation incounseling conversations between patients and mental health professionals. Thearchitecture is utilized for offline reinforcement learning, and we extractstates (dialogue turn embeddings), actions (conversation topics), and rewards(scores measuring the alignment between patient and therapist) from previousturns within a conversation to train a decision transformer model. Wedemonstrate an improvement over baseline reinforcement learning methods, andpropose a novel system of utilizing our model's output as synthetic labels forfine-tuning a large language model for the same task. Although ourimplementation based on LLaMA-2 7B has mixed results, future work canundoubtedly build on the design.</description><author>Aylin Gunal, Baihan Lin, Djallel Bouneffouf</author><pubDate>Wed, 08 May 2024 14:55:25 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.05060v1</guid></item><item><title>UniBEV: Multi-modal 3D Object Detection with Uniform BEV Encoders for Robustness against Missing Sensor Modalities</title><link>http://arxiv.org/abs/2309.14516v3</link><description>Multi-sensor object detection is an active research topic in automateddriving, but the robustness of such detection models against missing sensorinput (modality missing), e.g., due to a sudden sensor failure, is a criticalproblem which remains under-studied. In this work, we propose UniBEV, anend-to-end multi-modal 3D object detection framework designed for robustnessagainst missing modalities: UniBEV can operate on LiDAR plus camera input, butalso on LiDAR-only or camera-only input without retraining. To facilitate itsdetector head to handle different input combinations, UniBEV aims to createwell-aligned Bird's Eye View (BEV) feature maps from each available modality.Unlike prior BEV-based multi-modal detection methods, all sensor modalitiesfollow a uniform approach to resample features from the native sensorcoordinate systems to the BEV features. We furthermore investigate therobustness of various fusion strategies w.r.t. missing modalities: the commonlyused feature concatenation, but also channel-wise averaging, and ageneralization to weighted averaging termed Channel Normalized Weights. Tovalidate its effectiveness, we compare UniBEV to state-of-the-art BEVFusion andMetaBEV on nuScenes over all sensor input combinations. In this setting, UniBEVachieves $52.5 \%$ mAP on average over all input combinations, significantlyimproving over the baselines ($43.5 \%$ mAP on average for BEVFusion, $48.7 \%$mAP on average for MetaBEV). An ablation study shows the robustness benefits offusing by weighted averaging over regular concatenation, and of sharing queriesbetween the BEV encoders of each modality. Our code is available athttps://github.com/tudelft-iv/UniBEV.</description><author>Shiming Wang, Holger Caesar, Liangliang Nan, Julian F. P. Kooij</author><pubDate>Wed, 08 May 2024 14:53:33 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2309.14516v3</guid></item><item><title>Real-Time Motion Detection Using Dynamic Mode Decomposition</title><link>http://arxiv.org/abs/2405.05057v1</link><description>Dynamic Mode Decomposition (DMD) is a numerical method that seeks to fittimeseries data to a linear dynamical system. In doing so, DMD decomposesdynamic data into spatially coherent modes that evolve in time according toexponential growth/decay or with a fixed frequency of oscillation. A prolificapplication of DMD has been to video, where one interprets the high-dimensionalpixel space evolving through time as the video plays. In this work, we proposea simple and interpretable motion detection algorithm for streaming video datarooted in DMD. Our method leverages the fact that there exists a correspondencebetween the evolution of important video features, such as foreground motion,and the eigenvalues of the matrix which results from applying DMD to segmentsof video. We apply the method to a database of test videos which emulatesecurity footage under varying realistic conditions. Effectiveness is analyzedusing receiver operating characteristic curves, while we use cross-validationto optimize the threshold parameter that identifies movement.</description><author>Marco Mignacca, Simone Brugiapaglia, Jason J. Bramburger</author><pubDate>Wed, 08 May 2024 14:52:14 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.05057v1</guid></item><item><title>ADELT: Transpilation Between Deep Learning Frameworks</title><link>http://arxiv.org/abs/2303.03593v3</link><description>We propose the Adversarial DEep Learning Transpiler (ADELT), a novel approachto source-to-source transpilation between deep learning frameworks. ADELTuniquely decouples code skeleton transpilation and API keyword mapping. Forcode skeleton transpilation, it uses few-shot prompting on large languagemodels (LLMs), while for API keyword mapping, it uses contextual embeddingsfrom a code-specific BERT. These embeddings are trained in a domain-adversarialsetup to generate a keyword translation dictionary. ADELT is trained on anunlabeled web-crawled deep learning corpus, without relying on any hand-craftedrules or parallel data. It outperforms state-of-the-art transpilers, improvingpass@1 rate by 17.4 pts and 15.0 pts for PyTorch-Keras and PyTorch-MXNettranspilation pairs respectively. We provide open access to our code athttps://github.com/gonglinyuan/adelt.</description><author>Linyuan Gong, Jiayi Wang, Alvin Cheung</author><pubDate>Wed, 08 May 2024 14:51:44 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2303.03593v3</guid></item><item><title>Rethinking recidivism through a causal lens</title><link>http://arxiv.org/abs/2011.11483v4</link><description>Predictive modeling of criminal recidivism, or whether people will re-offendin the future, has a long and contentious history. Modern causal inferencemethods allow us to move beyond prediction and target the "treatment effect" ofa specific intervention on an outcome in an observational dataset. In thispaper, we look specifically at the effect of incarceration (prison time) onrecidivism, using a well-known dataset from North Carolina. Two popular causalmethods for addressing confounding bias are explained and demonstrated:directed acyclic graph (DAG) adjustment and double machine learning (DML),including a sensitivity analysis for unobserved confounders. We find thatincarceration has a detrimental effect on recidivism, i.e., longer prisonsentences make it more likely that individuals will re-offend after release,although this conclusion should not be generalized beyond the scope of ourdata. We hope that this case study can inform future applications of causalinference to criminal justice analysis.</description><author>Vik Shirvaikar, Choudur Lakshminarayan</author><pubDate>Wed, 08 May 2024 14:48:23 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2011.11483v4</guid></item><item><title>Seeds of Stereotypes: A Large-Scale Textual Analysis of Race and Gender Associations with Diseases in Online Sources</title><link>http://arxiv.org/abs/2405.05049v1</link><description>Background Advancements in Large Language Models (LLMs) hold transformativepotential in healthcare, however, recent work has raised concern about thetendency of these models to produce outputs that display racial or genderbiases. Although training data is a likely source of such biases, explorationof disease and demographic associations in text data at scale has been limited. Methods We conducted a large-scale textual analysis using a datasetcomprising diverse web sources, including Arxiv, Wikipedia, and Common Crawl.The study analyzed the context in which various diseases are discussedalongside markers of race and gender. Given that LLMs are pre-trained onsimilar datasets, this approach allowed us to examine the potential biases thatLLMs may learn and internalize. We compared these findings with actualdemographic disease prevalence as well as GPT-4 outputs in order to evaluatethe extent of bias representation. Results Our findings indicate that demographic terms are disproportionatelyassociated with specific disease concepts in online texts. gender terms areprominently associated with disease concepts, while racial terms are much lessfrequently associated. We find widespread disparities in the associations ofspecific racial and gender terms with the 18 diseases analyzed. Mostprominently, we see an overall significant overrepresentation of Black racementions in comparison to population proportions. Conclusions Our results highlight the need for critical examination andtransparent reporting of biases in LLM pretraining datasets. Our study suggeststhe need to develop mitigation strategies to counteract the influence of biasedtraining data in LLMs, particularly in sensitive domains such as healthcare.</description><author>Lasse Hyldig Hansen, Nikolaj Andersen, Jack Gallifant, Liam G. McCoy, James K Stone, Nura Izath, Marcela Aguirre-Jerez, Danielle S Bitterman, Judy Gichoya, Leo Anthony Celi</author><pubDate>Wed, 08 May 2024 14:38:56 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.05049v1</guid></item><item><title>HeadArtist: Text-conditioned 3D Head Generation with Self Score Distillation</title><link>http://arxiv.org/abs/2312.07539v2</link><description>This work presents HeadArtist for 3D head generation from text descriptions.With a landmark-guided ControlNet serving as the generative prior, we come upwith an efficient pipeline that optimizes a parameterized 3D head model underthe supervision of the prior distillation itself. We call such a process selfscore distillation (SSD). In detail, given a sampled camera pose, we firstrender an image and its corresponding landmarks from the head model, and addsome particular level of noise onto the image. The noisy image, landmarks, andtext condition are then fed into the frozen ControlNet twice for noiseprediction. Two different classifier-free guidance (CFG) weights are appliedduring these two predictions, and the prediction difference offers a directionon how the rendered image can better match the text of interest. Experimentalresults suggest that our approach delivers high-quality 3D head sculptures withadequate geometry and photorealistic appearance, significantly outperformingstate-ofthe-art methods. We also show that the same pipeline well supportsediting the generated heads, including both geometry deformation and appearancechange.</description><author>Hongyu Liu, Xuan Wang, Ziyu Wan, Yujun Shen, Yibing Song, Jing Liao, Qifeng Chen</author><pubDate>Wed, 08 May 2024 14:29:25 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.07539v2</guid></item><item><title>WavePlanes: A compact Wavelet representation for Dynamic Neural Radiance Fields</title><link>http://arxiv.org/abs/2312.02218v3</link><description>Dynamic Neural Radiance Fields (Dynamic NeRF) enhance NeRF technology tomodel moving scenes. However, they are resource intensive and challenging tocompress. To address these issues, this paper presents WavePlanes, a fast andmore compact explicit model. We propose a multi-scale space and space-timefeature plane representation using N-level 2-D wavelet coefficients. Theinverse discrete wavelet transform reconstructs feature signals at varyingdetail, which are linearly decoded to approximate the color and density ofvolumes in a 4-D grid. Exploiting the sparsity of wavelet coefficients, wecompress the model using a Hash Map containing only non-zero coefficients andtheir locations on each plane. Compared to the state-of-the-art (SotA)plane-based models, WavePlanes is up to 15x smaller while being less resourcedemanding and competitive in performance and training time. Compared to othersmall SotA models WavePlanes preserves details better without requiring customCUDA code or high performance computing resources. Our code is available at:https://github.com/azzarelli/waveplanes/</description><author>Adrian Azzarelli, Nantheera Anantrasirichai, David R Bull</author><pubDate>Wed, 08 May 2024 14:24:32 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.02218v3</guid></item><item><title>StepMix: A Python Package for Pseudo-Likelihood Estimation of Generalized Mixture Models with External Variables</title><link>http://arxiv.org/abs/2304.03853v5</link><description>StepMix is an open-source Python package for the pseudo-likelihood estimation(one-, two- and three-step approaches) of generalized finite mixture models(latent profile and latent class analysis) with external variables (covariatesand distal outcomes). In many applications in social sciences, the mainobjective is not only to cluster individuals into latent classes, but also touse these classes to develop more complex statistical models. These modelsgenerally divide into a measurement model that relates the latent classes toobserved indicators, and a structural model that relates covariates and outcomevariables to the latent classes. The measurement and structural models can beestimated jointly using the so-called one-step approach or sequentially usingstepwise methods, which present significant advantages for practitionersregarding the interpretability of the estimated latent classes. In addition tothe one-step approach, StepMix implements the most important stepwiseestimation methods from the literature, including the bias-adjusted three-stepmethods with Bolk-Croon-Hagenaars and maximum likelihood corrections and themore recent two-step approach. These pseudo-likelihood estimators are presentedin this paper under a unified framework as specific expectation-maximizationsubroutines. To facilitate and promote their adoption among the data sciencecommunity, StepMix follows the object-oriented design of the scikit-learnlibrary and provides an additional R wrapper.</description><author>Sacha Morin, Robin Legault, Félix Laliberté, Zsuzsa Bakk, Charles-Édouard Giguère, Roxane de la Sablonnière, Éric Lacourse</author><pubDate>Wed, 08 May 2024 14:22:34 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2304.03853v5</guid></item><item><title>Reviewing Intelligent Cinematography: AI research for camera-based video production</title><link>http://arxiv.org/abs/2405.05039v1</link><description>This paper offers a comprehensive review of artificial intelligence (AI)research in the context of real camera content acquisition for entertainmentpurposes and is aimed at both researchers and cinematographers. Considering thebreadth of computer vision research and the lack of review papers tied tointelligent cinematography (IC), this review introduces a holistic view of theIC landscape while providing the technical insight for experts across acrossdisciplines. We preface the main discussion with technical background ongenerative AI, object detection, automated camera calibration and 3-D contentacquisition, and link explanatory articles to assist non-technical readers. Themain discussion categorizes work by four production types: General Production,Virtual Production, Live Production and Aerial Production. Note that forVirtual Production we do not discuss research relating to virtual contentacquisition, including work on automated video generation, like StableDiffusion. Within each section, we (1) sub-classify work by the technical fieldof research - reflected by the subsections, and (2) evaluate the trends andchallenge w.r.t to each type of production. In the final chapter, we presentour concluding remarks on the greater scope of IC research and outline workthat we believe has significant potential to influence the whole industry. Wefind that work relating to virtual production has the greatest potential toimpact other mediums of production, driven by the growing interest in LEDvolumes/stages for in-camera virtual effects (ICVFX) and automated 3-D capturefor a virtual modelling of real world scenes and actors. This is the firstpiece of literature to offer a structured and comprehensive examination of ICresearch. Consequently, we address ethical and legal concerns regarding the useof creative AI involving artists, actors and the general public, in the...</description><author>Adrian Azzarelli, Nantheera Anantrasirichai, David R Bull</author><pubDate>Wed, 08 May 2024 14:13:02 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.05039v1</guid></item><item><title>Multi-fidelity Hamiltonian Monte Carlo</title><link>http://arxiv.org/abs/2405.05033v1</link><description>Numerous applications in biology, statistics, science, and engineeringrequire generating samples from high-dimensional probability distributions. Inrecent years, the Hamiltonian Monte Carlo (HMC) method has emerged as astate-of-the-art Markov chain Monte Carlo technique, exploiting the shape ofsuch high-dimensional target distributions to efficiently generate samples.Despite its impressive empirical success and increasing popularity, itswide-scale adoption remains limited due to the high computational cost ofgradient calculation. Moreover, applying this method is impossible when thegradient of the posterior cannot be computed (for example, with black-boxsimulators). To overcome these challenges, we propose a novel two-stageHamiltonian Monte Carlo algorithm with a surrogate model. In thismulti-fidelity algorithm, the acceptance probability is computed in the firststage via a standard HMC proposal using an inexpensive differentiable surrogatemodel, and if the proposal is accepted, the posterior is evaluated in thesecond stage using the high-fidelity (HF) numerical solver. Splitting thestandard HMC algorithm into these two stages allows for approximating thegradient of the posterior efficiently, while producing accurate posteriorsamples by using HF numerical solvers in the second stage. We demonstrate theeffectiveness of this algorithm for a range of problems, including linear andnonlinear Bayesian inverse problems with in-silico data and experimental data.The proposed algorithm is shown to seamlessly integrate with variouslow-fidelity and HF models, priors, and datasets. Remarkably, our proposedmethod outperforms the traditional HMC algorithm in both computational andstatistical efficiency by several orders of magnitude, all while retaining orimproving the accuracy in computed posterior statistics.</description><author>Dhruv V. Patel, Jonghyun Lee, Matthew W. Farthing, Peter K. Kitanidis, Eric F. Darve</author><pubDate>Wed, 08 May 2024 14:03:55 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.05033v1</guid></item></channel></rss>