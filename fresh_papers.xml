<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/"><channel><title>Arxivfresh papers</title><link></link><description>Arxiv paper</description><language>en-US</language><lastBuildDate>Wed, 29 May 2024 06:00:19 GMT</lastBuildDate><generator>rfeed v1.0.0</generator><docs>https://github.com/svpino/rfeed/blob/master/README.md</docs><item><title>Notes on Applicability of GPT-4 to Document Understanding</title><link>http://arxiv.org/abs/2405.18433v1</link><description>We perform a missing, reproducible evaluation of all publicly available GPT-4family models concerning the Document Understanding field, where it isfrequently required to comprehend text spacial arrangement and visual clues inaddition to textual semantics. Benchmark results indicate that though it ishard to achieve satisfactory results with text-only models, GPT-4 Vision Turboperforms well when one provides both text recognized by an external OCR engineand document images on the input. Evaluation is followed by analyses thatsuggest possible contamination of textual GPT-4 models and indicate thesignificant performance drop for lengthy documents.</description><author>≈Åukasz Borchmann</author><pubDate>Tue, 28 May 2024 18:59:53 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.18433v1</guid></item><item><title>On the Origin of Llamas: Model Tree Heritage Recovery</title><link>http://arxiv.org/abs/2405.18432v1</link><description>The rapid growth of neural network models shared on the internet has mademodel weights an important data modality. However, this information isunderutilized as the weights are uninterpretable, and publicly available modelsare disorganized. Inspired by Darwin's tree of life, we define the Model Treewhich describes the origin of models i.e., the parent model that was used tofine-tune the target model. Similarly to the natural world, the tree structureis unknown. In this paper, we introduce the task of Model Tree HeritageRecovery (MoTHer Recovery) for discovering Model Trees in the ever-growinguniverse of neural networks. Our hypothesis is that model weights encode thisinformation, the challenge is to decode the underlying tree structure given theweights. Beyond the immediate application of model authorship attribution,MoTHer recovery holds exciting long-term applications akin to indexing theinternet by search engines. Practically, for each pair of models, this taskrequires: i) determining if they are related, and ii) establishing thedirection of the relationship. We find that certain distributional propertiesof the weights evolve monotonically during training, which enables us toclassify the relationship between two given models. MoTHer recoveryreconstructs entire model hierarchies, represented by a directed tree, where aparent model gives rise to multiple child models through additional training.Our approach successfully reconstructs complex Model Trees, as well as thestructure of "in-the-wild" model families such as Llama 2 and Stable Diffusion.</description><author>Eliahu Horwitz, Asaf Shul, Yedid Hoshen</author><pubDate>Tue, 28 May 2024 18:59:51 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.18432v1</guid></item><item><title>DiG: Scalable and Efficient Diffusion Models with Gated Linear Attention</title><link>http://arxiv.org/abs/2405.18428v1</link><description>Diffusion models with large-scale pre-training have achieved significantsuccess in the field of visual content generation, particularly exemplified byDiffusion Transformers (DiT). However, DiT models have faced challenges withscalability and quadratic complexity efficiency. In this paper, we aim toleverage the long sequence modeling capability of Gated Linear Attention (GLA)Transformers, expanding its applicability to diffusion models. We introduceDiffusion Gated Linear Attention Transformers (DiG), a simple, adoptablesolution with minimal parameter overhead, following the DiT design, butoffering superior efficiency and effectiveness. In addition to betterperformance than DiT, DiG-S/2 exhibits $2.5\times$ higher training speed thanDiT-S/2 and saves $75.7\%$ GPU memory at a resolution of $1792 \times 1792$.Moreover, we analyze the scalability of DiG across a variety of computationalcomplexity. DiG models, with increased depth/width or augmentation of inputtokens, consistently exhibit decreasing FID. We further compare DiG with othersubquadratic-time diffusion models. With the same model size, DiG-XL/2 is$4.2\times$ faster than the recent Mamba-based diffusion model at a $1024$resolution, and is $1.8\times$ faster than DiT with CUDA-optimizedFlashAttention-2 under the $2048$ resolution. All these results demonstrate itssuperior efficiency among the latest diffusion models. Code is released athttps://github.com/hustvl/DiG.</description><author>Lianghui Zhu, Zilong Huang, Bencheng Liao, Jun Hao Liew, Hanshu Yan, Jiashi Feng, Xinggang Wang</author><pubDate>Tue, 28 May 2024 18:59:33 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.18428v1</guid></item><item><title>Classifying Overlapping Gaussian Mixtures in High Dimensions: From Optimal Classifiers to Neural Nets</title><link>http://arxiv.org/abs/2405.18427v1</link><description>We derive closed-form expressions for the Bayes optimal decision boundariesin binary classification of high dimensional overlapping Gaussian mixture model(GMM) data, and show how they depend on the eigenstructure of the classcovariances, for particularly interesting structured data. We empiricallydemonstrate, through experiments on synthetic GMMs inspired by real-world data,that deep neural networks trained for classification, learn predictors whichapproximate the derived optimal classifiers. We further extend our study tonetworks trained on authentic data, observing that decision thresholdscorrelate with the covariance eigenvectors rather than the eigenvalues,mirroring our GMM analysis. This provides theoretical insights regarding neuralnetworks' ability to perform probabilistic inference and distill statisticalpatterns from intricate distributions.</description><author>Khen Cohen, Noam Levi, Yaron Oz</author><pubDate>Tue, 28 May 2024 18:59:31 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.18427v1</guid></item><item><title>GFlow: Recovering 4D World from Monocular Video</title><link>http://arxiv.org/abs/2405.18426v1</link><description>Reconstructing 4D scenes from video inputs is a crucial yet challenging task.Conventional methods usually rely on the assumptions of multi-view videoinputs, known camera parameters, or static scenes, all of which are typicallyabsent under in-the-wild scenarios. In this paper, we relax all theseconstraints and tackle a highly ambitious but practical task, which we termedas AnyV4D: we assume only one monocular video is available without any cameraparameters as input, and we aim to recover the dynamic 4D world alongside thecamera poses. To this end, we introduce GFlow, a new framework that utilizesonly 2D priors (depth and optical flow) to lift a video (3D) to a 4D explicitrepresentation, entailing a flow of Gaussian splatting through space and time.GFlow first clusters the scene into still and moving parts, then applies asequential optimization process that optimizes camera poses and the dynamics of3D Gaussian points based on 2D priors and scene clustering, ensuring fidelityamong neighboring points and smooth movement across frames. Since dynamicscenes always introduce new content, we also propose a new pixel-wisedensification strategy for Gaussian points to integrate new visual content.Moreover, GFlow transcends the boundaries of mere 4D reconstruction; it alsoenables tracking of any points across frames without the need for priortraining and segments moving objects from the scene in an unsupervised way.Additionally, the camera poses of each frame can be derived from GFlow,allowing for rendering novel views of a video scene through changing camerapose. By employing the explicit representation, we may readily conductscene-level or object-level editing as desired, underscoring its versatilityand power. Visit our project website at: https://littlepure2333.github.io/GFlow</description><author>Shizun Wang, Xingyi Yang, Qiuhong Shen, Zhenxiang Jiang, Xinchao Wang</author><pubDate>Tue, 28 May 2024 18:59:22 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.18426v1</guid></item><item><title>ViG: Linear-complexity Visual Sequence Learning with Gated Linear Attention</title><link>http://arxiv.org/abs/2405.18425v1</link><description>Recently, linear complexity sequence modeling networks have achieved modelingcapabilities similar to Vision Transformers on a variety of computer visiontasks, while using fewer FLOPs and less memory. However, their advantage interms of actual runtime speed is not significant. To address this issue, weintroduce Gated Linear Attention (GLA) for vision, leveraging its superiorhardware-awareness and efficiency. We propose direction-wise gating to capture1D global context through bidirectional modeling and a 2D gating localityinjection to adaptively inject 2D local details into 1D global context. Ourhardware-aware implementation further merges forward and backward scanning intoa single kernel, enhancing parallelism and reducing memory cost and latency.The proposed model, \name{}, offers a favorable trade-off in accuracy,parameters, and FLOPs on ImageNet and downstream tasks, outperforming popularTransformer and CNN-based models. Notably, \name{}-S matches DeiT-B's accuracywhile using only 27\% of the parameters and 20\% of the FLOPs, running2$\times$ faster on $224\times224$ images. At $1024\times1024$ resolution,\name{}-T uses 5.2$\times$ fewer FLOPs, saves 90\% GPU memory, runs 4.8$\times$faster, and achieves 20.7\% higher top-1 accuracy than DeiT-T. These resultsposition \name{} as an efficient and scalable solution for visualrepresentation learning. Code is available at\url{https://github.com/hustvl/ViG}.</description><author>Bencheng Liao, Xinggang Wang, Lianghui Zhu, Qian Zhang, Chang Huang</author><pubDate>Tue, 28 May 2024 18:59:21 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.18425v1</guid></item><item><title>3DitScene: Editing Any Scene via Language-guided Disentangled Gaussian Splatting</title><link>http://arxiv.org/abs/2405.18424v1</link><description>Scene image editing is crucial for entertainment, photography, andadvertising design. Existing methods solely focus on either 2D individualobject or 3D global scene editing. This results in a lack of a unified approachto effectively control and manipulate scenes at the 3D level with differentlevels of granularity. In this work, we propose 3DitScene, a novel and unifiedscene editing framework leveraging language-guided disentangled GaussianSplatting that enables seamless editing from 2D to 3D, allowing precise controlover scene composition and individual objects. We first incorporate 3DGaussians that are refined through generative priors and optimizationtechniques. Language features from CLIP then introduce semantics into 3Dgeometry for object disentanglement. With the disentangled Gaussians, 3DitSceneallows for manipulation at both the global and individual levels,revolutionizing creative expression and empowering control over scenes andobjects. Experimental results demonstrate the effectiveness and versatility of3DitScene in scene image editing. Code and online demo can be found at ourproject homepage: https://zqh0253.github.io/3DitScene/.</description><author>Qihang Zhang, Yinghao Xu, Chaoyang Wang, Hsin-Ying Lee, Gordon Wetzstein, Bolei Zhou, Ceyuan Yang</author><pubDate>Tue, 28 May 2024 18:59:01 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.18424v1</guid></item><item><title>Hierarchical World Models as Visual Whole-Body Humanoid Controllers</title><link>http://arxiv.org/abs/2405.18418v1</link><description>Whole-body control for humanoids is challenging due to the high-dimensionalnature of the problem, coupled with the inherent instability of a bipedalmorphology. Learning from visual observations further exacerbates thisdifficulty. In this work, we explore highly data-driven approaches to visualwhole-body humanoid control based on reinforcement learning, without anysimplifying assumptions, reward design, or skill primitives. Specifically, wepropose a hierarchical world model in which a high-level agent generatescommands based on visual observations for a low-level agent to execute, both ofwhich are trained with rewards. Our approach produces highly performant controlpolicies in 8 tasks with a simulated 56-DoF humanoid, while synthesizingmotions that are broadly preferred by humans. Code and videos:https://nicklashansen.com/rlpuppeteer</description><author>Nicklas Hansen, Jyothir S V, Vlad Sobal, Yann LeCun, Xiaolong Wang, Hao Su</author><pubDate>Tue, 28 May 2024 18:57:23 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.18418v1</guid></item><item><title>3D StreetUnveiler with Semantic-Aware 2DGS</title><link>http://arxiv.org/abs/2405.18416v1</link><description>Unveiling an empty street from crowded observations captured by in-carcameras is crucial for autonomous driving. However, removing all temporarystatic objects, such as stopped vehicles and standing pedestrians, presents asignificant challenge. Unlike object-centric 3D inpainting, which relies onthorough observation in a small scene, street scenes involve long trajectoriesthat differ from previous 3D inpainting tasks. The camera-centric movingenvironment of captured videos further complicates the task due to the limiteddegree and time duration of object observation. To address these obstacles, weintroduce StreetUnveiler to reconstruct an empty street. StreetUnveiler learnsa 3D representation of the empty street from crowded observations. Ourrepresentation is based on the hard-label semantic 2D Gaussian Splatting (2DGS)for its scalability and ability to identify Gaussians to be removed. We inpaintrendered image after removing unwanted Gaussians to provide pseudo-labels andsubsequently re-optimize the 2DGS. Given its temporal continuous movement, wedivide the empty street scene into observed, partial-observed, and unobservedregions, which we propose to locate through a rendered alpha map. Thisdecomposition helps us to minimize the regions that need to be inpainted. Toenhance the temporal consistency of the inpainting, we introduce a noveltime-reversal framework to inpaint frames in reverse order and use later framesas references for earlier frames to fully utilize the long-trajectoryobservations. Our experiments conducted on the street scene datasetsuccessfully reconstructed a 3D representation of the empty street. The meshrepresentation of the empty street can be extracted for further applications.Project page and more visualizations can be found at:https://streetunveiler.github.io</description><author>Jingwei Xu, Yikai Wang, Yiqun Zhao, Yanwei Fu, Shenghua Gao</author><pubDate>Tue, 28 May 2024 18:57:12 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.18416v1</guid></item><item><title>Why are Visually-Grounded Language Models Bad at Image Classification?</title><link>http://arxiv.org/abs/2405.18415v1</link><description>Image classification is one of the most fundamental capabilities of machinevision intelligence. In this work, we revisit the image classification taskusing visually-grounded language models (VLMs) such as GPT-4V and LLaVA. Wefind that existing proprietary and public VLMs, despite often using CLIP as avision encoder and having many more parameters, significantly underperform CLIPon standard image classification benchmarks like ImageNet. To understand thereason, we explore several hypotheses concerning the inference algorithms,training objectives, and data processing in VLMs. Our analysis reveals that theprimary cause is data-related: critical information for image classification isencoded in the VLM's latent space but can only be effectively decoded withenough training data. Specifically, there is a strong correlation between thefrequency of class exposure during VLM training and instruction-tuning and theVLM's performance in those classes; when trained with sufficient data, VLMs canmatch the accuracy of state-of-the-art classification models. Based on thesefindings, we enhance a VLM by integrating classification-focused datasets intoits training, and demonstrate that the enhanced classification performance ofthe VLM transfers to its general capabilities, resulting in an improvement of11.8% on the newly collected ImageWikiQA dataset.</description><author>Yuhui Zhang, Alyssa Unell, Xiaohan Wang, Dhruba Ghosh, Yuchang Su, Ludwig Schmidt, Serena Yeung-Levy</author><pubDate>Tue, 28 May 2024 18:57:06 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.18415v1</guid></item><item><title>Don't Forget to Connect! Improving RAG with Graph-based Reranking</title><link>http://arxiv.org/abs/2405.18414v1</link><description>Retrieval Augmented Generation (RAG) has greatly improved the performance ofLarge Language Model (LLM) responses by grounding generation with context fromexisting documents. These systems work well when documents are clearly relevantto a question context. But what about when a document has partial information,or less obvious connections to the context? And how should we reason aboutconnections between documents? In this work, we seek to answer these two corequestions about RAG generation. We introduce G-RAG, a reranker based on graphneural networks (GNNs) between the retriever and reader in RAG. Our methodcombines both connections between documents and semantic information (viaAbstract Meaning Representation graphs) to provide a context-informed rankerfor RAG. G-RAG outperforms state-of-the-art approaches while having smallercomputational footprint. Additionally, we assess the performance of PaLM 2 as areranker and find it to significantly underperform G-RAG. This resultemphasizes the importance of reranking for RAG even when using Large LanguageModels.</description><author>Jialin Dong, Bahare Fatemi, Bryan Perozzi, Lin F. Yang, Anton Tsitsulin</author><pubDate>Tue, 28 May 2024 18:56:46 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.18414v1</guid></item><item><title>DCT-Based Decorrelated Attention for Vision Transformers</title><link>http://arxiv.org/abs/2405.13901v2</link><description>Central to the Transformer architectures' effectiveness is the self-attentionmechanism, a function that maps queries, keys, and values into ahigh-dimensional vector space. However, training the attention weights ofqueries, keys, and values is non-trivial from a state of random initialization.In this paper, we propose two methods. (i) We first address the initializationproblem of Vision Transformers by introducing a simple, yet highly innovative,initialization approach utilizing Discrete Cosine Transform (DCT) coefficients.Our proposed DCT-based attention initialization marks a significant gaincompared to traditional initialization strategies; offering a robust foundationfor the attention mechanism. Our experiments reveal that the DCT-basedinitialization enhances the accuracy of Vision Transformers in classificationtasks. (ii) We also recognize that since DCT effectively decorrelates imageinformation in the frequency domain, this decorrelation is useful forcompression because it allows the quantization step to discard many of thehigher-frequency components. Based on this observation, we propose a novelDCT-based compression technique for the attention function of VisionTransformers. Since high-frequency DCT coefficients usually correspond tonoise, we truncate the high-frequency DCT components of the input patches. OurDCT-based compression reduces the size of weight matrices for queries, keys,and values. While maintaining the same level of accuracy, our DCT compressedSwin Transformers obtain a considerable decrease in the computational overhead.</description><author>Hongyi Pan, Emadeldeen Hamdan, Xin Zhu, Koushik Biswas, Ahmet Enis Cetin, Ulas Bagci</author><pubDate>Tue, 28 May 2024 18:56:12 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.13901v2</guid></item><item><title>Eliciting Informative Text Evaluations with Large Language Models</title><link>http://arxiv.org/abs/2405.15077v2</link><description>Peer prediction mechanisms motivate high-quality feedback with provableguarantees. However, current methods only apply to rather simple reports, likemultiple-choice or scalar numbers. We aim to broaden these techniques to thelarger domain of text-based reports, drawing on the recent developments inlarge language models. This vastly increases the applicability of peerprediction mechanisms as textual feedback is the norm in a large variety offeedback channels: peer reviews, e-commerce customer reviews, and comments onsocial media. We introduce two mechanisms, the Generative Peer Prediction Mechanism (GPPM)and the Generative Synopsis Peer Prediction Mechanism (GSPPM). These mechanismsutilize LLMs as predictors, mapping from one agent's report to a prediction ofher peer's report. Theoretically, we show that when the LLM prediction issufficiently accurate, our mechanisms can incentivize high effort andtruth-telling as an (approximate) Bayesian Nash equilibrium. Empirically, weconfirm the efficacy of our mechanisms through experiments conducted on tworeal datasets: the Yelp review dataset and the ICLR OpenReview dataset. Wehighlight the results that on the ICLR dataset, our mechanisms candifferentiate three quality levels -- human-written reviews, GPT-4-generatedreviews, and GPT-3.5-generated reviews in terms of expected scores.Additionally, GSPPM penalizes LLM-generated reviews more effectively than GPPM.</description><author>Yuxuan Lu, Shengwei Xu, Yichi Zhang, Yuqing Kong, Grant Schoenebeck</author><pubDate>Tue, 28 May 2024 18:55:40 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.15077v2</guid></item><item><title>Tensor Methods in High Dimensional Data Analysis: Opportunities and Challenges</title><link>http://arxiv.org/abs/2405.18412v1</link><description>Large amount of multidimensional data represented by multiway arrays ortensors are prevalent in modern applications across various fields such aschemometrics, genomics, physics, psychology, and signal processing. Thestructural complexity of such data provides vast new opportunities for modelingand analysis, but efficiently extracting information content from them, bothstatistically and computationally, presents unique and fundamental challenges.Addressing these challenges requires an interdisciplinary approach that bringstogether tools and insights from statistics, optimization and numerical linearalgebra among other fields. Despite these hurdles, significant progress hasbeen made in the last decade. This review seeks to examine some of the keyadvancements and identify common threads among them, under eight differentstatistical settings.</description><author>Arnab Auddy, Dong Xia, Ming Yuan</author><pubDate>Tue, 28 May 2024 18:54:03 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.18412v1</guid></item><item><title>DOLOMITES: Domain-Specific Long-Form Methodical Tasks</title><link>http://arxiv.org/abs/2405.05938v2</link><description>Experts in various fields routinely perform methodical writing tasks to plan,organize, and report their work. From a clinician writing a differentialdiagnosis for a patient, to a teacher writing a lesson plan for students, thesetasks are pervasive, requiring to methodically generate structured long-formoutput for a given input. We develop a typology of methodical tasks structuredin the form of a task objective, procedure, input, and output, and introduceDoLoMiTes, a novel benchmark with specifications for 519 such tasks elicitedfrom hundreds of experts from across 25 fields. Our benchmark further containsspecific instantiations of methodical tasks with concrete input and outputexamples (1,857 in total) which we obtain by collecting expert revisions of upto 10 model-generated examples of each task. We use these examples to evaluatecontemporary language models highlighting that automating methodical tasks is achallenging long-form generation problem, as it requires performing complexinferences, while drawing upon the given context as well as domain knowledge.</description><author>Chaitanya Malaviya, Priyanka Agrawal, Kuzman Ganchev, Pranesh Srinivasan, Fantine Huot, Jonathan Berant, Mark Yatskar, Dipanjan Das, Mirella Lapata, Chris Alberti</author><pubDate>Tue, 28 May 2024 18:53:48 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.05938v2</guid></item><item><title>Towards a Sampling Theory for Implicit Neural Representations</title><link>http://arxiv.org/abs/2405.18410v1</link><description>Implicit neural representations (INRs) have emerged as a powerful tool forsolving inverse problems in computer vision and computational imaging. INRsrepresent images as continuous domain functions realized by a neural networktaking spatial coordinates as inputs. However, unlike traditional pixelrepresentations, little is known about the sample complexity of estimatingimages using INRs in the context of linear inverse problems. Towards this end,we study the sampling requirements for recovery of a continuous domain imagefrom its low-pass Fourier coefficients by fitting a single hidden-layer INRwith ReLU activation and a Fourier features layer using a generalized form ofweight decay regularization. Our key insight is to relate minimizers of thisnon-convex parameter space optimization problem to minimizers of a convexpenalty defined over an infinite-dimensional space of measures. We identify asufficient number of samples for which an image realized by a width-1 INR isexactly recoverable by solving the INR training problem, and give a conjecturefor the general width-$W$ case. To validate our theory, we empirically assessthe probability of achieving exact recovery of images realized by low-widthsingle hidden-layer INRs, and illustrate the performance of INR onsuper-resolution recovery of more realistic continuous domain phantom images.</description><author>Mahrokh Najaf, Gregory Ongie</author><pubDate>Tue, 28 May 2024 18:53:47 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.18410v1</guid></item><item><title>Phased Consistency Model</title><link>http://arxiv.org/abs/2405.18407v1</link><description>The consistency model (CM) has recently made significant progress inaccelerating the generation of diffusion models. However, its application tohigh-resolution, text-conditioned image generation in the latent space (a.k.a.,LCM) remains unsatisfactory. In this paper, we identify three key flaws in thecurrent design of LCM. We investigate the reasons behind these limitations andpropose the Phased Consistency Model (PCM), which generalizes the design spaceand addresses all identified limitations. Our evaluations demonstrate that PCMsignificantly outperforms LCM across 1--16 step generation settings. While PCMis specifically designed for multi-step refinement, it achieves even superioror comparable 1-step generation results to previously state-of-the-artspecifically designed 1-step methods. Furthermore, we show that PCM'smethodology is versatile and applicable to video generation, enabling us totrain the state-of-the-art few-step text-to-video generator. More details areavailable at https://g-u-n.github.io/projects/pcm/.</description><author>Fu-Yun Wang, Zhaoyang Huang, Alexander William Bergman, Dazhong Shen, Peng Gao, Michael Lingelbach, Keqiang Sun, Weikang Bian, Guanglu Song, Yu Liu, Hongsheng Li, Xiaogang Wang</author><pubDate>Tue, 28 May 2024 18:47:19 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.18407v1</guid></item><item><title>RACCooN: Remove, Add, and Change Video Content with Auto-Generated Narratives</title><link>http://arxiv.org/abs/2405.18406v1</link><description>Recent video generative models primarily rely on carefully written textprompts for specific tasks, like inpainting or style editing. They requirelabor-intensive textual descriptions for input videos, hindering theirflexibility to adapt personal/raw videos to user specifications. This paperproposes RACCooN, a versatile and user-friendly video-to-paragraph-to-videogenerative framework that supports multiple video editing capabilities such asremoval, addition, and modification, through a unified pipeline. RACCooNconsists of two principal stages: Video-to-Paragraph (V2P) andParagraph-to-Video (P2V). In the V2P stage, we automatically describe videoscenes in well-structured natural language, capturing both the holistic contextand focused object details. Subsequently, in the P2V stage, users canoptionally refine these descriptions to guide the video diffusion model,enabling various modifications to the input video, such as removing, changingsubjects, and/or adding new objects. The proposed approach stands out fromother methods through several significant contributions: (1) RACCooN suggests amulti-granular spatiotemporal pooling strategy to generate well-structuredvideo descriptions, capturing both the broad context and object details withoutrequiring complex human annotations, simplifying precise video content editingbased on text for users. (2) Our video generative model incorporatesauto-generated narratives or instructions to enhance the quality and accuracyof the generated content. It supports the addition of video objects,inpainting, and attribute modification within a unified framework, surpassingexisting video editing and inpainting benchmarks. The proposed frameworkdemonstrates impressive versatile capabilities in video-to-paragraphgeneration, video content editing, and can be incorporated into other SoTAvideo generative models for further enhancement.</description><author>Jaehong Yoon, Shoubin Yu, Mohit Bansal</author><pubDate>Tue, 28 May 2024 18:46:36 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.18406v1</guid></item><item><title>WIDIn: Wording Image for Domain-Invariant Representation in Single-Source Domain Generalization</title><link>http://arxiv.org/abs/2405.18405v1</link><description>Language has been useful in extending the vision encoder to data from diversedistributions without empirical discovery in training domains. However, as theimage description is mostly at coarse-grained level and ignores visual details,the resulted embeddings are still ineffective in overcoming complexity ofdomains at inference time. We present a self-supervision framework WIDIn,Wording Images for Domain-Invariant representation, to disentanglediscriminative visual representation, by only leveraging data in a singledomain and without any test prior. Specifically, for each image, we firstestimate the language embedding with fine-grained alignment, which can beconsequently used to adaptively identify and then remove domain-specificcounterpart from the raw visual embedding. WIDIn can be applied to bothpretrained vision-language models like CLIP, and separately trained uni-modalmodels like MoCo and BERT. Experimental studies on three domain generalizationdatasets demonstrate the effectiveness of our approach.</description><author>Jiawei Ma, Yulei Niu, Shiyuan Huang, Guangxing Han, Shih-Fu Chang</author><pubDate>Tue, 28 May 2024 18:46:27 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.18405v1</guid></item><item><title>CARL: A Framework for Equivariant Image Registration</title><link>http://arxiv.org/abs/2405.16738v2</link><description>Image registration estimates spatial correspondences between a pair ofimages. These estimates are typically obtained via numerical optimization orregression by a deep network. A desirable property of such estimators is that acorrespondence estimate (e.g., the true oracle correspondence) for an imagepair is maintained under deformations of the input images. Formally, theestimator should be equivariant to a desired class of image transformations. Inthis work, we present careful analyses of the desired equivariance propertiesin the context of multi-step deep registration networks. Based on theseanalyses we 1) introduce the notions of $[U,U]$ equivariance (networkequivariance to the same deformations of the input images) and $[W,U]$equivariance (where input images can undergo different deformations); we 2)show that in a suitable multi-step registration setup it is sufficient foroverall $[W,U]$ equivariance if the first step has $[W,U]$ equivariance and allothers have $[U,U]$ equivariance; we 3) show that commondisplacement-predicting networks only exhibit $[U,U]$ equivariance totranslations instead of the more powerful $[W,U]$ equivariance; and we 4) showhow to achieve multi-step $[W,U]$ equivariance via a coordinate-attentionmechanism combined with displacement-predicting refinement layers (CARL).Overall, our approach obtains excellent practical registration performance onseveral 3D medical image registration tasks and outperforms existingunsupervised approaches for the challenging problem of abdomen registration.</description><author>Hastings Greer, Lin Tian, Francois-Xavier Vialard, Roland Kwitt, Raul San Jose Estepar, Marc Niethammer</author><pubDate>Tue, 28 May 2024 18:44:15 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.16738v2</guid></item><item><title>Explicit Formulae to Interchangeably use Hyperplanes and Hyperballs using Inversive Geometry</title><link>http://arxiv.org/abs/2405.18401v1</link><description>Many algorithms require discriminative boundaries, such as separatinghyperplanes or hyperballs, or are specifically designed to work on sphericaldata. By applying inversive geometry, we show that the two discriminativeboundaries can be used interchangeably, and that general Euclidean data can betransformed into spherical data, whenever a change in point distances isacceptable. We provide explicit formulae to embed general Euclidean data intospherical data and to unembed it back. We further show a duality betweenhyperspherical caps, i.e., the volume created by a separating hyperplane onspherical data, and hyperballs and provide explicit formulae to map between thetwo. We further provide equations to translate inner products and Euclideandistances between the two spaces, to avoid explicit embedding and unembedding.We also provide a method to enforce projections of the general Euclidean spaceonto hemi-hyperspheres and propose an intrinsic dimensionality based method toobtain "all-purpose" parameters. To show the usefulness of thecap-ball-duality, we discuss example applications in machine learning andvector similarity search.</description><author>Erik Thordsen, Erich Schubert</author><pubDate>Tue, 28 May 2024 18:43:16 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.18401v1</guid></item><item><title>Superposed Decoding: Multiple Generations from a Single Autoregressive Inference Pass</title><link>http://arxiv.org/abs/2405.18400v1</link><description>Many applications today provide users with multiple auto-complete drafts asthey type, including GitHub's code completion, Gmail's smart compose, andApple's messaging auto-suggestions. Under the hood, language models supportthis by running an autoregressive inference pass to provide a draft.Consequently, providing $k$ drafts to the user requires running an expensivelanguage model $k$ times. To alleviate the computation cost of running $k$inference passes, we propose Superposed Decoding, a new decoding algorithm thatgenerates $k$ drafts at the computation cost of one autoregressive inferencepass. We achieve this by feeding a superposition of the $k$ most recent tokenembeddings from the drafts as input to the next decoding step of the languagemodel. At every inference step we combine the $k$ drafts with the top-$k$tokens to get $k^2$ new drafts and cache the $k$ most likely options, using ann-gram interpolation with minimal compute overhead to filter out incoherentgenerations. Our experiments show that $k$ drafts from Superposed Decoding areat least as coherent and factual as Nucleus Sampling and Greedy Decodingrespectively, while being at least $2.44\times$ faster for $k\ge3$. In acompute-normalized setting, user evaluations demonstrably favor text generatedby Superposed Decoding over Nucleus Sampling. Code and more examplesopen-sourced at https://github.com/RAIVNLab/SuperposedDecoding.</description><author>Ethan Shen, Alan Fan, Sarah M Pratt, Jae Sung Park, Matthew Wallingford, Sham M. Kakade, Ari Holtzman, Ranjay Krishna, Ali Farhadi, Aditya Kusupati</author><pubDate>Tue, 28 May 2024 18:40:48 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.18400v1</guid></item><item><title>MC-GTA: Metric-Constrained Model-Based Clustering using Goodness-of-fit Tests with Autocorrelations</title><link>http://arxiv.org/abs/2405.18395v1</link><description>A wide range of (multivariate) temporal (1D) and spatial (2D) data analysistasks, such as grouping vehicle sensor trajectories, can be formulated asclustering with given metric constraints. Existing metric-constrainedclustering algorithms overlook the rich correlation between feature similarityand metric distance, i.e., metric autocorrelation. The model-based variationsof these clustering algorithms (e.g. TICC and STICC) achieve SOTA performance,yet suffer from computational instability and complexity by using ametric-constrained Expectation-Maximization procedure. In order to addressthese two problems, we propose a novel clustering algorithm, MC-GTA(Model-based Clustering via Goodness-of-fit Tests with Autocorrelations). Itsobjective is only composed of pairwise weighted sums of feature similarityterms (square Wasserstein-2 distance) and metric autocorrelation terms (a novelmultivariate generalization of classic semivariogram). We show that MC-GTA iseffectively minimizing the total hinge loss for intra-cluster observation pairsnot passing goodness-of-fit tests, i.e., statistically not originating from thesame distribution. Experiments on 1D/2D synthetic and real-world datasetsdemonstrate that MC-GTA successfully incorporates metric autocorrelation. Itoutperforms strong baselines by large margins (up to 14.3% in ARI and 32.1% inNMI) with faster and stabler optimization (&gt;10x speedup).</description><author>Zhangyu Wang, Gengchen Mai, Krzysztof Janowicz, Ni Lao</author><pubDate>Tue, 28 May 2024 18:35:05 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.18395v1</guid></item><item><title>Scaling Laws and Compute-Optimal Training Beyond Fixed Training Durations</title><link>http://arxiv.org/abs/2405.18392v1</link><description>Scale has become a main ingredient in obtaining strong machine learningmodels. As a result, understanding a model's scaling properties is key toeffectively designing both the right training setup as well as futuregenerations of architectures. In this work, we argue that scale and trainingresearch has been needlessly complex due to reliance on the cosine schedule,which prevents training across different lengths for the same model size. Weinvestigate the training behavior of a direct alternative - constant learningrate and cooldowns - and find that it scales predictably and reliably similarto cosine. Additionally, we show that stochastic weight averaging yieldsimproved performance along the training trajectory, without additional trainingcosts, across different scales. Importantly, with these findings we demonstratethat scaling experiments can be performed with significantly reduced computeand GPU hours by utilizing fewer but reusable training runs.</description><author>Alexander H√§gele, Elie Bakouch, Atli Kosson, Loubna Ben Allal, Leandro Von Werra, Martin Jaggi</author><pubDate>Tue, 28 May 2024 18:33:54 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.18392v1</guid></item><item><title>A Review and Implementation of Object Detection Models and Optimizations for Real-time Medical Mask Detection during the COVID-19 Pandemic</title><link>http://arxiv.org/abs/2405.18387v1</link><description>Convolutional Neural Networks (CNN) are commonly used for the problem ofobject detection thanks to their increased accuracy. Nevertheless, theperformance of CNN-based detection models is ambiguous when detection speed isconsidered. To the best of our knowledge, there has not been sufficientevaluation of the available methods in terms of the speed/accuracy trade-off inrelated literature. This work assesses the most fundamental object detectionmodels on the Common Objects in Context (COCO) dataset with respect to thistrade-off, their memory consumption, and computational and storage cost. Next,we select a highly efficient model called YOLOv5 to train on the topical andunexplored dataset of human faces with medical masks, the Properly-WearingMasked Faces Dataset (PWMFD), and analyze the benefits of specific optimizationtechniques for real-time medical mask detection: transfer learning, dataaugmentations, and a Squeeze-and-Excitation attention mechanism. Using ourfindings in the context of the COVID-19 pandemic, we propose an optimized modelbased on YOLOv5s using transfer learning for the detection of correctly andincorrectly worn medical masks that surpassed more than two times in speed (69frames per second) the state-of-the-art model SE-YOLOv3 on the PWMFD datasetwhile maintaining the same level of mean Average Precision (67%).</description><author>Ioanna Gogou, Dimitrios Koutsomitropoulos</author><pubDate>Tue, 28 May 2024 18:27:24 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.18387v1</guid></item><item><title>Instruct-MusicGen: Unlocking Text-to-Music Editing for Music Language Models via Instruction Tuning</title><link>http://arxiv.org/abs/2405.18386v1</link><description>Recent advances in text-to-music editing, which employ text queries to modifymusic (e.g.\ by changing its style or adjusting instrumental components),present unique challenges and opportunities for AI-assisted music creation.Previous approaches in this domain have been constrained by the necessity totrain specific editing models from scratch, which is both resource-intensiveand inefficient; other research uses large language models to predict editedmusic, resulting in imprecise audio reconstruction. To Combine the strengthsand address these limitations, we introduce Instruct-MusicGen, a novel approachthat finetunes a pretrained MusicGen model to efficiently follow editinginstructions such as adding, removing, or separating stems. Our approachinvolves a modification of the original MusicGen architecture by incorporatinga text fusion module and an audio fusion module, which allow the model toprocess instruction texts and audio inputs concurrently and yield the desirededited music. Remarkably, Instruct-MusicGen only introduces 8% new parametersto the original MusicGen model and only trains for 5K steps, yet it achievessuperior performance across all tasks compared to existing baselines, anddemonstrates performance comparable to the models trained for specific tasks.This advancement not only enhances the efficiency of text-to-music editing butalso broadens the applicability of music language models in dynamic musicproduction environments.</description><author>Yixiao Zhang, Yukara Ikemiya, Woosung Choi, Naoki Murata, Marco A. Mart√≠nez-Ram√≠rez, Liwei Lin, Gus Xia, Wei-Hsiang Liao, Yuki Mitsufuji, Simon Dixon</author><pubDate>Tue, 28 May 2024 18:27:20 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.18386v1</guid></item><item><title>Brain Tumor Segmentation (BraTS) Challenge 2024: Meningioma Radiotherapy Planning Automated Segmentation</title><link>http://arxiv.org/abs/2405.18383v1</link><description>The 2024 Brain Tumor Segmentation Meningioma Radiotherapy (BraTS-MEN-RT)challenge aims to advance automated segmentation algorithms using the largestknown multi-institutional dataset of radiotherapy planning brain MRIs withexpert-annotated target labels for patients with intact or post-operativemeningioma that underwent either conventional external beam radiotherapy orstereotactic radiosurgery. Each case includes a defaced 3D post-contrastT1-weighted radiotherapy planning MRI in its native acquisition space,accompanied by a single-label "target volume" representing the gross tumorvolume (GTV) and any at-risk post-operative site. Target volume annotationsadhere to established radiotherapy planning protocols, ensuring consistencyacross cases and institutions. For pre-operative meningiomas, the target volumeencompasses the entire GTV and associated nodular dural tail, while forpost-operative cases, it includes at-risk resection cavity margins asdetermined by the treating institution. Case annotations were reviewed andapproved by expert neuroradiologists and radiation oncologists. Participatingteams will develop, containerize, and evaluate automated segmentation modelsusing this comprehensive dataset. Model performance will be assessed using thelesion-wise Dice Similarity Coefficient and the 95% Hausdorff distance. Thetop-performing teams will be recognized at the Medical Image Computing andComputer Assisted Intervention Conference in October 2024. BraTS-MEN-RT isexpected to significantly advance automated radiotherapy planning by enablingprecise tumor segmentation and facilitating tailored treatment, ultimatelyimproving patient outcomes.</description><author>Dominic LaBella, Katherine Schumacher, Michael Mix, Kevin Leu, Shan McBurney-Lin, Pierre Nedelec, Javier Villanueva-Meyer, Jonathan Shapey, Tom Vercauteren, Kazumi Chia, Omar Al-Salihi, Justin Leu, Lia Halasz, Yury Velichko, Chunhao Wang, John Kirkpatrick, Scott Floyd, Zachary J. Reitman, Trey Mullikin, Ulas Bagci, Sean Sachdev, Jona A. Hattangadi-Gluth, Tyler Seibert, Nikdokht Farid, Connor Puett, Matthew W. Pease, Kevin Shiue, Syed Muhammad Anwar, Shahriar Faghani, Muhammad Ammar Haider, Pranav Warman, Jake Albrecht, Andr√°s Jakab, Mana Moassefi, Verena Chung, Alejandro Aristizabal, Alexandros Karargyris, Hasan Kassem, Sarthak Pati, Micah Sheller, Christina Huang, Aaron Coley, Siddharth Ghanta, Alex Schneider, Conrad Sharp, Rachit Saluja, Florian Kofler, Philipp Lohmann, Phillipp Vollmuth</author><pubDate>Tue, 28 May 2024 18:25:43 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.18383v1</guid></item><item><title>OwLore: Outlier-weighed Layerwise Sampled Low-Rank Projection for Memory-Efficient LLM Fine-tuning</title><link>http://arxiv.org/abs/2405.18380v1</link><description>The rapid advancements in Large Language Models (LLMs) have revolutionizedvarious natural language processing tasks. However, the substantial size ofLLMs presents significant challenges in training or fine-tuning. Whileparameter-efficient approaches such as low-rank adaptation (LoRA) have gainedpopularity, they often compromise performance compared to full-rankfine-tuning. In this paper, we propose Outlier-weighed Layerwise SampledLow-Rank Projection (OwLore), a new memory-efficient fine-tuning approach,inspired by the layerwise outlier distribution of LLMs, which dynamicallysamples pre-trained layers to fine-tune instead of adding additional adaptors.We first interpret the outlier phenomenon through the lens of Heavy-TailedSelf-Regularization theory (HT-SR), discovering that layers with more outlierstend to be more heavy-tailed and consequently better trained. Inspired by thisfinding, OwLore strategically assigns higher sampling probabilities to layerswith more outliers to better leverage the knowledge stored in pre-trained LLMs.To further mitigate the memory demands of fine-tuning, we integrate gradientlow-rank projection into our approach, which facilitates each layer to beefficiently trained in a low-rank manner. By incorporating the efficientcharacteristics of low-rank and optimal layerwise sampling, OwLoresignificantly improves the memory-performance trade-off in LLM pruning. Ourextensive experiments across various architectures, including LLaMa2, LLaMa3,and Mistral, demonstrate that OwLore consistently outperforms baselineapproaches, including full fine-tuning. Specifically, it achieves up to a 1.1%average accuracy gain on the Commonsense Reasoning benchmark, a 3.0%improvement on MMLU, and a notable 10% boost on MT-Bench, while being morememory efficient. OwLore allows us to fine-tune LLaMa2-7B with only 21GB ofmemory.</description><author>Pengxiang Li, Lu Yin, Xiaowei Gao, Shiwei Liu</author><pubDate>Tue, 28 May 2024 18:22:22 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.18380v1</guid></item><item><title>A Note on the Prediction-Powered Bootstrap</title><link>http://arxiv.org/abs/2405.18379v1</link><description>We introduce PPBoot: a bootstrap-based method for prediction-poweredinference. PPBoot is applicable to arbitrary estimation problems and is verysimple to implement, essentially only requiring one application of thebootstrap. Through a series of examples, we demonstrate that PPBoot oftenperforms nearly identically to (and sometimes better than) the earlier PPI(++)method based on asymptotic normality$\unicode{x2013}$when the latter isapplicable$\unicode{x2013}$without requiring any asymptotic characterizations.Given its versatility, PPBoot could simplify and expand the scope ofapplication of prediction-powered inference to problems where central limittheorems are hard to prove.</description><author>Tijana Zrnic</author><pubDate>Tue, 28 May 2024 18:22:15 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.18379v1</guid></item><item><title>A Canonization Perspective on Invariant and Equivariant Learning</title><link>http://arxiv.org/abs/2405.18378v1</link><description>In many applications, we desire neural networks to exhibit invariance orequivariance to certain groups due to symmetries inherent in the data.Recently, frame-averaging methods emerged to be a unified framework forattaining symmetries efficiently by averaging over input-dependent subsets ofthe group, i.e., frames. What we currently lack is a principled understandingof the design of frames. In this work, we introduce a canonization perspectivethat provides an essential and complete view of the design of frames.Canonization is a classic approach for attaining invariance by mapping inputsto their canonical forms. We show that there exists an inherent connectionbetween frames and canonical forms. Leveraging this connection, we canefficiently compare the complexity of frames as well as determine theoptimality of certain frames. Guided by this principle, we design novel framesfor eigenvectors that are strictly superior to existing methods -- some areeven optimal -- both theoretically and empirically. The reduction to thecanonization perspective further uncovers equivalences between previousmethods. These observations suggest that canonization provides a fundamentalunderstanding of existing frame-averaging methods and unifies existingequivariant and invariant learning methods.</description><author>George Ma, Yifei Wang, Derek Lim, Stefanie Jegelka, Yisen Wang</author><pubDate>Tue, 28 May 2024 18:22:15 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.18378v1</guid></item><item><title>LLaMA-NAS: Efficient Neural Architecture Search for Large Language Models</title><link>http://arxiv.org/abs/2405.18377v1</link><description>The abilities of modern large language models (LLMs) in solving naturallanguage processing, complex reasoning, sentiment analysis and other tasks havebeen extraordinary which has prompted their extensive adoption. Unfortunately,these abilities come with very high memory and computational costs whichprecludes the use of LLMs on most hardware platforms. To mitigate this, wepropose an effective method of finding Pareto-optimal network architecturesbased on LLaMA2-7B using one-shot NAS. In particular, we fine-tune LLaMA2-7Bonly once and then apply genetic algorithm-based search to find smaller, lesscomputationally complex network architectures. We show that, for certainstandard benchmark tasks, the pre-trained LLaMA2-7B network is unnecessarilylarge and complex. More specifically, we demonstrate a 1.5x reduction in modelsize and 1.3x speedup in throughput for certain tasks with negligible drop inaccuracy. In addition to finding smaller, higher-performing networkarchitectures, our method does so more effectively and efficiently than certainpruning or sparsification techniques. Finally, we demonstrate how quantizationis complementary to our method and that the size and complexity of the networkswe find can be further decreased using quantization. We believe that our workprovides a way to automatically create LLMs which can be used on less expensiveand more readily available hardware platforms.</description><author>Anthony Sarah, Sharath Nittur Sridhar, Maciej Szankin, Sairam Sundaresan</author><pubDate>Tue, 28 May 2024 18:20:44 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.18377v1</guid></item><item><title>REBORN: Reinforcement-Learned Boundary Segmentation with Iterative Training for Unsupervised ASR</title><link>http://arxiv.org/abs/2402.03988v2</link><description>Unsupervised automatic speech recognition (ASR) aims to learn the mappingbetween the speech signal and its corresponding textual transcription withoutthe supervision of paired speech-text data. A word/phoneme in the speech signalis represented by a segment of speech signal with variable length and unknownboundary, and this segmental structure makes learning the mapping betweenspeech and text challenging, especially without paired data. In this paper, wepropose REBORN,Reinforcement-Learned Boundary Segmentation with IterativeTraining for Unsupervised ASR. REBORN alternates between (1) training asegmentation model that predicts the boundaries of the segmental structures inspeech signals and (2) training the phoneme prediction model, whose input isthe speech feature segmented by the segmentation model, to predict a phonemetranscription. Since supervised data for training the segmentation model is notavailable, we use reinforcement learning to train the segmentation model tofavor segmentations that yield phoneme sequence predictions with a lowerperplexity. We conduct extensive experiments and find that under the samesetting, REBORN outperforms all prior unsupervised ASR models on LibriSpeech,TIMIT, and five non-English languages in Multilingual LibriSpeech. Wecomprehensively analyze why the boundaries learned by REBORN improve theunsupervised ASR performance.</description><author>Liang-Hsuan Tseng, En-Pei Hu, Cheng-Han Chiang, Yuan Tseng, Hung-yi Lee, Lin-shan Lee, Shao-Hua Sun</author><pubDate>Tue, 28 May 2024 18:19:59 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.03988v2</guid></item><item><title>Empowering Source-Free Domain Adaptation with MLLM-driven Curriculum Learning</title><link>http://arxiv.org/abs/2405.18376v1</link><description>Source-Free Domain Adaptation (SFDA) aims to adapt a pre-trained source modelto a target domain using only unlabeled target data. Current SFDA methods facechallenges in effectively leveraging pre-trained knowledge and exploitingtarget domain data. Multimodal Large Language Models (MLLMs) offer remarkablecapabilities in understanding visual and textual information, but theirapplicability to SFDA poses challenges such as instruction-following failures,intensive computational demands, and difficulties in performance measurementprior to adaptation. To alleviate these issues, we propose Reliability-basedCurriculum Learning (RCL), a novel framework that integrates multiple MLLMs forknowledge exploitation via pseudo-labeling in SFDA. Our framework incorporatesproposed Reliable Knowledge Transfer, Self-correcting and MLLM-guided KnowledgeExpansion, and Multi-hot Masking Refinement to progressively exploit unlabeleddata in the target domain. RCL achieves state-of-the-art (SOTA) performance onmultiple SFDA benchmarks, e.g., $\textbf{+9.4%}$ on DomainNet, demonstratingits effectiveness in enhancing adaptability and robustness without requiringaccess to source data. Code: https://github.com/Dong-Jie-Chen/RCL.</description><author>Dongjie Chen, Kartik Patwari, Zhengfeng Lai, Sen-ching Cheung, Chen-Nee Chuah</author><pubDate>Tue, 28 May 2024 18:18:17 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.18376v1</guid></item><item><title>Thai Winograd Schemas: A Benchmark for Thai Commonsense Reasoning</title><link>http://arxiv.org/abs/2405.18375v1</link><description>Commonsense reasoning is one of the important aspect of natural languageunderstanding, with several benchmarks developed to evaluate it. However, onlya few of these benchmarks are available in languages other than English.Developing parallel benchmarks facilitates cross-lingual evaluation, enabling abetter understanding of different languages. This research introduces acollection of Winograd Schemas in Thai, a novel dataset designed to evaluatecommonsense reasoning capabilities in the context of the Thai language. Through a methodology involving native speakers, professional translators,and thorough validation, the schemas aim to closely reflect Thai languagenuances, idioms, and cultural references while maintaining ambiguity andcommonsense challenges. We evaluate the performance of popular large languagemodels on this benchmark, revealing their strengths, limitations, and providinginsights into the current state-of-the-art. Results indicate that while modelslike GPT-4 and Claude-3-Opus achieve high accuracy in English, theirperformance significantly drops in Thai, highlighting the need for furtheradvancements in multilingual commonsense reasoning.</description><author>Phakphum Artkaew</author><pubDate>Tue, 28 May 2024 18:14:02 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.18375v1</guid></item><item><title>ReFIT: Relevance Feedback from a Reranker during Inference</title><link>http://arxiv.org/abs/2305.11744v2</link><description>Retrieve-and-rerank is a prevalent framework in neural information retrieval,wherein a bi-encoder network initially retrieves a pre-defined number ofcandidates (e.g., K=100), which are then reranked by a more powerfulcross-encoder model. While the reranker often yields improved candidate scorescompared to the retriever, its scope is confined to only the top K retrievedcandidates. As a result, the reranker cannot improve retrieval performance interms of Recall@K. In this work, we propose to leverage the reranker to improverecall by making it provide relevance feedback to the retriever at inferencetime. Specifically, given a test instance during inference, we distill thereranker's predictions for that instance into the retriever's queryrepresentation using a lightweight update mechanism. The aim of thedistillation loss is to align the retriever's candidate scores more closelywith those produced by the reranker. The algorithm then proceeds by executing asecond retrieval step using the updated query vector. We empiricallydemonstrate that this method, applicable to various retrieve-and-rerankframeworks, substantially enhances retrieval recall across multiple domains,languages, and modalities.</description><author>Revanth Gangi Reddy, Pradeep Dasigi, Md Arafat Sultan, Arman Cohan, Avirup Sil, Heng Ji, Hannaneh Hajishirzi</author><pubDate>Tue, 28 May 2024 18:12:02 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.11744v2</guid></item><item><title>ROPO: Robust Preference Optimization for Large Language Models</title><link>http://arxiv.org/abs/2404.04102v2</link><description>Preference alignment is pivotal for empowering large language models (LLMs)to generate helpful and harmless responses. However, the performance ofpreference alignment is highly sensitive to the prevalent noise in thepreference data. Recent efforts for this problem either marginally alleviatethe impact of noise without the ability to actually reduce its presence, orrely on costly teacher LLMs prone to reward misgeneralization. To address thesechallenges, we propose the RObust Preference Optimization (ROPO) framework, aniterative alignment approach that integrates noise-tolerance and filtering ofnoisy samples without the aid of external models. Specifically, ROPOiteratively solves a constrained optimization problem, where we dynamicallyassign a quality-aware weight for each sample and constrain the sum of theweights to the number of samples we intend to retain. For noise-toleranttraining and effective noise identification, we derive a robust loss bysuppressing the gradients of samples with high uncertainty. We demonstrate bothempirically and theoretically that the derived loss is critical fordistinguishing noisy samples from clean ones. Furthermore, inspired by ourderived loss, we propose a robustness-guided rejection sampling technique tocompensate for the potential important information in discarded queries.Experiments on three widely-used datasets with Mistral-7B and Llama-2-7Bdemonstrate that ROPO significantly outperforms existing preference alignmentmethods, with its superiority growing as the noise rate increases.</description><author>Xize Liang, Chao Chen, Shuang Qiu, Jie Wang, Yue Wu, Zhihang Fu, Zhihao Shi, Feng Wu, Jieping Ye</author><pubDate>Tue, 28 May 2024 18:11:53 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.04102v2</guid></item><item><title>Assessing Economic Viability: A Comparative Analysis of Total Cost of Ownership for Domain-Adapted Large Language Models versus State-of-the-art Counterparts in Chip Design Coding Assistance</title><link>http://arxiv.org/abs/2404.08850v2</link><description>This paper presents a comparative analysis of total cost of ownership (TCO)and performance between domain-adapted large language models (LLM) andstate-of-the-art (SoTA) LLMs , with a particular emphasis on tasks related tocoding assistance for chip design. We examine the TCO and performance metricsof a domain-adaptive LLM, ChipNeMo, against two leading LLMs, Claude 3 Opus andChatGPT-4 Turbo, to assess their efficacy in chip design coding generation.Through a detailed evaluation of the accuracy of the model, trainingmethodologies, and operational expenditures, this study aims to providestakeholders with critical information to select the most economically viableand performance-efficient solutions for their specific needs. Our resultsunderscore the benefits of employing domain-adapted models, such as ChipNeMo,that demonstrate improved performance at significantly reduced costs comparedto their general-purpose counterparts. In particular, we reveal the potentialof domain-adapted LLMs to decrease TCO by approximately 90%-95%, with the costadvantages becoming increasingly evident as the deployment scale expands. Withexpansion of deployment, the cost benefits of ChipNeMo become more pronounced,making domain-adaptive LLMs an attractive option for organizations withsubstantial coding needs supported by LLMs</description><author>Amit Sharma, Teodor-Dumitru Ene, Kishor Kunal, Mingjie Liu, Zafar Hasan, Haoxing Ren</author><pubDate>Tue, 28 May 2024 18:11:44 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.08850v2</guid></item><item><title>A Hessian-Aware Stochastic Differential Equation for Modelling SGD</title><link>http://arxiv.org/abs/2405.18373v1</link><description>Continuous-time approximation of Stochastic Gradient Descent (SGD) is acrucial tool to study its escaping behaviors from stationary points. However,existing stochastic differential equation (SDE) models fail to fully capturethese behaviors, even for simple quadratic objectives. Built on a novelstochastic backward error analysis framework, we derive the Hessian-AwareStochastic Modified Equation (HA-SME), an SDE that incorporates Hessianinformation of the objective function into both its drift and diffusion terms.Our analysis shows that HA-SME matches the order-best approximation errorguarantee among existing SDE models in the literature, while achieving asignificantly reduced dependence on the smoothness parameter of the objective.Further, for quadratic objectives, under mild conditions, HA-SME is proved tobe the first SDE model that recovers exactly the SGD dynamics in thedistributional sense. Consequently, when the local landscape near a stationarypoint can be approximated by quadratics, HA-SME is expected to accuratelypredict the local escaping behaviors of SGD.</description><author>Xiang Li, Zebang Shen, Liang Zhang, Niao He</author><pubDate>Tue, 28 May 2024 18:11:34 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.18373v1</guid></item><item><title>PromptWizard: Task-Aware Agent-driven Prompt Optimization Framework</title><link>http://arxiv.org/abs/2405.18369v1</link><description>Large language models (LLMs) have revolutionized AI across diverse domains,showcasing remarkable capabilities. Central to their success is the concept ofprompting, which guides model output generation. However, manual promptengineering is labor-intensive and domain-specific, necessitating automatedsolutions. This paper introduces PromptWizard, a novel framework leveragingLLMs to iteratively synthesize and refine prompts tailored to specific tasks.Unlike existing approaches, PromptWizard optimizes both prompt instructions andin-context examples, maximizing model performance. The framework iterativelyrefines prompts by mutating instructions and incorporating negative examples todeepen understanding and ensure diversity. It further enhances bothinstructions and examples with the aid of a critic, synthesizing newinstructions and examples enriched with detailed reasoning steps for optimalperformance. PromptWizard offers several key features and capabilities,including computational efficiency compared to state-of-the-art approaches,adaptability to scenarios with varying amounts of training data, andeffectiveness with smaller LLMs. Rigorous evaluation across 35 tasks on 8datasets demonstrates PromptWizard's superiority over existing promptstrategies, showcasing its efficacy and scalability in prompt optimization.</description><author>Eshaan Agarwal, Vivek Dani, Tanuja Ganu, Akshay Nambi</author><pubDate>Tue, 28 May 2024 18:08:31 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.18369v1</guid></item><item><title>The 2024 Brain Tumor Segmentation (BraTS) Challenge: Glioma Segmentation on Post-treatment MRI</title><link>http://arxiv.org/abs/2405.18368v1</link><description>Gliomas are the most common malignant primary brain tumors in adults and oneof the deadliest types of cancer. There are many challenges in treatment andmonitoring due to the genetic diversity and high intrinsic heterogeneity inappearance, shape, histology, and treatment response. Treatments includesurgery, radiation, and systemic therapies, with magnetic resonance imaging(MRI) playing a key role in treatment planning and post-treatment longitudinalassessment. The 2024 Brain Tumor Segmentation (BraTS) challenge onpost-treatment glioma MRI will provide a community standard and benchmark forstate-of-the-art automated segmentation models based on the largestexpert-annotated post-treatment glioma MRI dataset. Challenge competitors willdevelop automated segmentation models to predict four distinct tumorsub-regions consisting of enhancing tissue (ET), surrounding non-enhancingT2/fluid-attenuated inversion recovery (FLAIR) hyperintensity (SNFH),non-enhancing tumor core (NETC), and resection cavity (RC). Models will beevaluated on separate validation and test datasets using standardizedperformance metrics utilized across the BraTS 2024 cluster of challenges,including lesion-wise Dice Similarity Coefficient and Hausdorff Distance.Models developed during this challenge will advance the field of automated MRIsegmentation and contribute to their integration into clinical practice,ultimately enhancing patient care.</description><author>Maria Correia de Verdier, Rachit Saluja, Louis Gagnon, Dominic LaBella, Ujjwall Baid, Nourel Hoda Tahon, Martha Foltyn-Dumitru, Jikai Zhang, Maram Alafif, Saif Baig, Ken Chang, Gennaro D'Anna, Lisa Deptula, Diviya Gupta, Muhammad Ammar Haider, Ali Hussain, Michael Iv, Marinos Kontzialis, Paul Manning, Farzan Moodi, Teresa Nunes, Aaron Simon, Nico Sollmann, David Vu, Maruf Adewole, Jake Albrecht, Udunna Anazodo, Rongrong Chai, Verena Chung, Shahriar Faghani, Keyvan Farahani, Anahita Fathi Kazerooni, Eugenio Iglesias, Florian Kofler, Hongwei Li, Marius George Linguraru, Bjoern Menze, Ahmed W. Moawad, Yury Velichko, Benedikt Wiestler, Talissa Altes, Patil Basavasagar, Martin Bendszus, Gianluca Brugnara, Jaeyoung Cho, Yaseen Dhemesh, Brandon K. K. Fields, Filip Garrett, Jaime Gass, Lubomir Had</author><pubDate>Tue, 28 May 2024 18:07:55 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.18368v1</guid></item><item><title>BBox-Adapter: Lightweight Adapting for Black-Box Large Language Models</title><link>http://arxiv.org/abs/2402.08219v2</link><description>Adapting state-of-the-art Large Language Models (LLMs) like GPT-4 and Geminifor specific tasks is challenging. Due to the opacity in their parameters,embeddings, and even output probabilities, existing fine-tuning adaptationmethods are inapplicable. Consequently, adapting these black-box LLMs is onlypossible through their API services, raising concerns about transparency,privacy, and cost. To address these challenges, we introduce BBox-Adapter, anovel lightweight adapter for black-box LLMs. BBox-Adapter distinguishes targetand source domain data by treating target data as positive and source data asnegative. It employs a ranking-based Noise Contrastive Estimation (NCE) loss topromote the likelihood of target domain data while penalizing that of thesource domain. Furthermore, it features an online adaptation mechanism, whichincorporates real-time positive data sampling from ground-truth, human, or AIfeedback, coupled with negative data from previous adaptations. Extensiveexperiments demonstrate BBox-Adapter's effectiveness and cost efficiency. Itimproves model performance by up to 6.77% across diverse tasks and domains,while reducing training and inference costs by 31.30x and 1.84x, respectively.</description><author>Haotian Sun, Yuchen Zhuang, Wei Wei, Chao Zhang, Bo Dai</author><pubDate>Tue, 28 May 2024 18:04:45 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.08219v2</guid></item><item><title>GMTalker: Gaussian Mixture-based Audio-Driven Emotional talking video Portraits</title><link>http://arxiv.org/abs/2312.07669v2</link><description>Synthesizing high-fidelity and emotion-controllable talking video portraits,with audio-lip sync, vivid expressions, realistic head poses, and eye blinks,has been an important and challenging task in recent years. Most existingmethods suffer in achieving personalized and precise emotion control, smoothtransitions between different emotion states, and the generation of diversemotions. To tackle these challenges, we present GMTalker, a Gaussianmixture-based emotional talking portraits generation framework. Specifically,we propose a Gaussian mixture-based expression generator that can construct acontinuous and disentangled latent space, achieving more flexible emotionmanipulation. Furthermore, we introduce a normalizing flow-based motiongenerator pretrained on a large dataset with a wide-range motion to generatediverse head poses, blinks, and eyeball movements. Finally, we propose apersonalized emotion-guided head generator with an emotion mapping network thatcan synthesize high-fidelity and faithful emotional video portraits. Bothquantitative and qualitative experiments demonstrate our method outperformsprevious methods in image quality, photo-realism, emotion accuracy, and motiondiversity.</description><author>Yibo Xia, Lizhen Wang, Xiang Deng, Xiaoyan Luo, Yebin Liu</author><pubDate>Tue, 28 May 2024 18:01:00 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.07669v2</guid></item><item><title>A General Framework for Learning from Weak Supervision</title><link>http://arxiv.org/abs/2402.01922v2</link><description>Weakly supervised learning generally faces challenges in applicability tovarious scenarios with diverse weak supervision and in scalability due to thecomplexity of existing algorithms, thereby hindering the practical deployment.This paper introduces a general framework for learning from weak supervision(GLWS) with a novel algorithm. Central to GLWS is an Expectation-Maximization(EM) formulation, adeptly accommodating various weak supervision sources,including instance partial labels, aggregate statistics, pairwise observations,and unlabeled data. We further present an advanced algorithm that significantlysimplifies the EM computational demands using a Non-deterministic FiniteAutomaton (NFA) along with a forward-backward algorithm, which effectivelyreduces time complexity from quadratic or factorial often required in existingsolutions to linear scale. The problem of learning from arbitrary weaksupervision is therefore converted to the NFA modeling of them. GLWS not onlyenhances the scalability of machine learning models but also demonstratessuperior performance and versatility across 11 weak supervision scenarios. Wehope our work paves the way for further advancements and practical deploymentin this field.</description><author>Hao Chen, Jindong Wang, Lei Feng, Xiang Li, Yidong Wang, Xing Xie, Masashi Sugiyama, Rita Singh, Bhiksha Raj</author><pubDate>Tue, 28 May 2024 17:59:30 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.01922v2</guid></item><item><title>Is a 3D-Tokenized LLM the Key to Reliable Autonomous Driving?</title><link>http://arxiv.org/abs/2405.18361v1</link><description>Rapid advancements in Autonomous Driving (AD) tasks turned a significantshift toward end-to-end fashion, particularly in the utilization ofvision-language models (VLMs) that integrate robust logical reasoning andcognitive abilities to enable comprehensive end-to-end planning. However, theseVLM-based approaches tend to integrate 2D vision tokenizers and a largelanguage model (LLM) for ego-car planning, which lack 3D geometric priors as acornerstone of reliable planning. Naturally, this observation raises a criticalconcern: Can a 2D-tokenized LLM accurately perceive the 3D environment? Ourevaluation of current VLM-based methods across 3D object detection, vectorizedmap construction, and environmental caption suggests that the answer is,unfortunately, NO. In other words, 2D-tokenized LLM fails to provide reliableautonomous driving. In response, we introduce DETR-style 3D perceptrons as 3Dtokenizers, which connect LLM with a one-layer linear projector. This simpleyet elegant strategy, termed Atlas, harnesses the inherent priors of the 3Dphysical world, enabling it to simultaneously process high-resolutionmulti-view images and employ spatiotemporal modeling. Despite its simplicity,Atlas demonstrates superior performance in both 3D detection and ego planningtasks on nuScenes dataset, proving that 3D-tokenized LLM is the key to reliableautonomous driving. The code and datasets will be released.</description><author>Yifan Bai, Dongming Wu, Yingfei Liu, Fan Jia, Weixin Mao, Ziheng Zhang, Yucheng Zhao, Jianbing Shen, Xing Wei, Tiancai Wang, Xiangyu Zhang</author><pubDate>Tue, 28 May 2024 17:57:44 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.18361v1</guid></item><item><title>Bridging the Gap: Dynamic Learning Strategies for Improving Multilingual Performance in LLMs</title><link>http://arxiv.org/abs/2405.18359v1</link><description>Large language models (LLMs) are at the forefront of transforming numerousdomains globally. However, their inclusivity and effectiveness remain limitedfor non-Latin scripts and low-resource languages. This paper tackles theimperative challenge of enhancing the multilingual performance of LLMs withoutextensive training or fine-tuning. Through systematic investigation andevaluation of diverse languages using popular question-answering (QA) datasets,we present novel techniques that unlock the true potential of LLMs in apolyglot landscape. Our approach encompasses three key strategies that yieldsignificant improvements in multilingual proficiency. First, by meticulouslyoptimizing prompts tailored for polyglot LLMs, we unlock their latentcapabilities, resulting in substantial performance boosts across languages.Second, we introduce a new hybrid approach that synergizes LLM RetrievalAugmented Generation (RAG) with multilingual embeddings and achieves improvedmultilingual task performance. Finally, we introduce a novel learning approachthat dynamically selects the optimal prompt strategy, LLM model, and embeddingmodel per query at run-time. This dynamic adaptation maximizes the efficacy ofLLMs across languages, outperforming best static and random strategies.Additionally, our approach adapts configurations in both offline and onlinesettings, and can seamlessly adapt to new languages and datasets, leading tosubstantial advancements in multilingual understanding and generation acrossdiverse languages.</description><author>Somnath Kumar, Vaibhav Balloli, Mercy Ranjit, Kabir Ahuja, Tanuja Ganu, Sunayana Sitaram, Kalika Bali, Akshay Nambi</author><pubDate>Tue, 28 May 2024 17:56:42 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.18359v1</guid></item><item><title>MMCTAgent: Multi-modal Critical Thinking Agent Framework for Complex Visual Reasoning</title><link>http://arxiv.org/abs/2405.18358v1</link><description>Recent advancements in Multi-modal Large Language Models (MLLMs) havesignificantly improved their performance in tasks combining vision andlanguage. However, challenges persist in detailed multi-modal understanding,comprehension of complex tasks, and reasoning over multi-modal information.This paper introduces MMCTAgent, a novel multi-modal critical thinking agentframework designed to address the inherent limitations of current MLLMs incomplex visual reasoning tasks. Inspired by human cognitive processes andcritical thinking, MMCTAgent iteratively analyzes multi-modal information,decomposes queries, plans strategies, and dynamically evolves its reasoning.Additionally, MMCTAgent incorporates critical thinking elements such asverification of final answers and self-reflection through a novel approach thatdefines a vision-based critic and identifies task-specific evaluation criteria,thereby enhancing its decision-making abilities. Through rigorous evaluationsacross various image and video understanding benchmarks, we demonstrate thatMMCTAgent (with and without the critic) outperforms both foundational MLLMs andother tool-augmented pipelines.</description><author>Somnath Kumar, Yash Gadhia, Tanuja Ganu, Akshay Nambi</author><pubDate>Tue, 28 May 2024 17:55:41 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.18358v1</guid></item><item><title>Faithful Logical Reasoning via Symbolic Chain-of-Thought</title><link>http://arxiv.org/abs/2405.18357v1</link><description>While the recent Chain-of-Thought (CoT) technique enhances the reasoningability of large language models (LLMs) with the theory of mind, it might stillstruggle in handling logical reasoning that relies much on symbolic expressionsand rigid deducing rules. To strengthen the logical reasoning capability ofLLMs, we propose a novel Symbolic Chain-of-Thought, namely SymbCoT, a fullyLLM-based framework that integrates symbolic expressions and logic rules withCoT prompting. Technically, building upon an LLM, SymbCoT 1) first translatesthe natural language context into the symbolic format, and then 2) derives astep-by-step plan to solve the problem with symbolic logical rules, 3) followedby a verifier to check the translation and reasoning chain. Via thoroughevaluations on 5 standard datasets with both First-Order Logic and ConstraintOptimization symbolic expressions, SymbCoT shows striking improvements over theCoT method consistently, meanwhile refreshing the current state-of-the-artperformances. We further demonstrate that our system advances in more faithful,flexible, and explainable logical reasoning. To our knowledge, this is thefirst to combine symbolic expressions and rules into CoT for logical reasoningwith LLMs. Code is open at https://github.com/Aiden0526/SymbCoT.</description><author>Jundong Xu, Hao Fei, Liangming Pan, Qian Liu, Mong-Li Lee, Wynne Hsu</author><pubDate>Tue, 28 May 2024 17:55:33 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.18357v1</guid></item><item><title>Universal and Extensible Language-Vision Models for Organ Segmentation and Tumor Detection from Abdominal Computed Tomography</title><link>http://arxiv.org/abs/2405.18356v1</link><description>The advancement of artificial intelligence (AI) for organ segmentation andtumor detection is propelled by the growing availability of computed tomography(CT) datasets with detailed, per-voxel annotations. However, these AI modelsoften struggle with flexibility for partially annotated datasets andextensibility for new classes due to limitations in the one-hot encoding,architectural design, and learning scheme. To overcome these limitations, wepropose a universal, extensible framework enabling a single model, termedUniversal Model, to deal with multiple public datasets and adapt to new classes(e.g., organs/tumors). Firstly, we introduce a novel language-driven parametergenerator that leverages language embeddings from large language models,enriching semantic encoding compared with one-hot encoding. Secondly, theconventional output layers are replaced with lightweight, class-specific heads,allowing Universal Model to simultaneously segment 25 organs and six types oftumors and ease the addition of new classes. We train our Universal Model on3,410 CT volumes assembled from 14 publicly available datasets and then test iton 6,173 CT volumes from four external datasets. Universal Model achieves firstplace on six CT tasks in the Medical Segmentation Decathlon (MSD) publicleaderboard and leading performance on the Beyond The Cranial Vault (BTCV)dataset. In summary, Universal Model exhibits remarkable computationalefficiency (6x faster than other dataset-specific models), demonstrates stronggeneralization across different hospitals, transfers well to numerousdownstream tasks, and more importantly, facilitates the extensibility to newclasses while alleviating the catastrophic forgetting of previously learnedclasses. Codes, models, and datasets are available athttps://github.com/ljwztc/CLIP-Driven-Universal-Model</description><author>Jie Liu, Yixiao Zhang, Kang Wang, Mehmet Can Yavuz, Xiaoxi Chen, Yixuan Yuan, Haoliang Li, Yang Yang, Alan Yuille, Yucheng Tang, Zongwei Zhou</author><pubDate>Tue, 28 May 2024 17:55:15 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.18356v1</guid></item><item><title>Simulating infinite-dimensional nonlinear diffusion bridges</title><link>http://arxiv.org/abs/2405.18353v1</link><description>The diffusion bridge is a type of diffusion process that conditions onhitting a specific state within a finite time period. It has broad applicationsin fields such as Bayesian inference, financial mathematics, control theory,and shape analysis. However, simulating the diffusion bridge for natural datacan be challenging due to both the intractability of the drift term andcontinuous representations of the data. Although several methods are availableto simulate finite-dimensional diffusion bridges, infinite-dimensional casesremain unresolved. In the paper, we present a solution to this problem bymerging score-matching techniques with operator learning, enabling a directapproach to score-matching for the infinite-dimensional bridge. We constructthe score to be discretization invariant, which is natural given the underlyingspatially continuous process. We conduct a series of experiments, ranging fromsynthetic examples with closed-form solutions to the stochastic nonlinearevolution of real-world biological shape data, and our method demonstrates highefficacy, particularly due to its ability to adapt to any resolution withoutextra training.</description><author>Gefan Yang, Elizabeth Louise Baker, Michael L. Severinsen, Christy Anna Hipsley, Stefan Sommer</author><pubDate>Tue, 28 May 2024 17:52:52 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.18353v1</guid></item><item><title>Evolutionary Algorithms for Optimizing Emergency Exit Placement in Indoor Environments</title><link>http://arxiv.org/abs/2405.18352v1</link><description>The problem of finding the optimal placement of emergency exits in an indoorenvironment to facilitate the rapid and orderly evacuation of crowds isaddressed in this work. A cellular-automaton model is used to simulate thebehavior of pedestrians in such scenarios, taking into account factors such asthe environment, the pedestrians themselves, and the interactions among them. Ametric is proposed to determine how successful or satisfactory an evacuationwas. Subsequently, two metaheuristic algorithms, namely an iterated greedyheuristic and an evolutionary algorithm (EA) are proposed to solve theoptimization problem. A comparative analysis shows that the proposed EA is ableto find effective solutions for different scenarios, and that an island-basedversion of it outperforms the other two algorithms in terms of solutionquality.</description><author>Carlos Cotta, Jos√© E. Gallardo</author><pubDate>Tue, 28 May 2024 17:50:42 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.18352v1</guid></item><item><title>Evaluating Bayesian deep learning for radio galaxy classification</title><link>http://arxiv.org/abs/2405.18351v1</link><description>The radio astronomy community is rapidly adopting deep learning techniques todeal with the huge data volumes expected from the next generation of radioobservatories. Bayesian neural networks (BNNs) provide a principled way tomodel uncertainty in the predictions made by such deep learning models and willplay an important role in extracting well-calibrated uncertainty estimates ontheir outputs. In this work, we evaluate the performance of different BNNsagainst the following criteria: predictive performance, uncertainty calibrationand distribution-shift detection for the radio galaxy classification problem.</description><author>Devina Mohan, Anna M. M. Scaife</author><pubDate>Tue, 28 May 2024 17:49:28 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.18351v1</guid></item><item><title>A System for Automatic English Text Expansion</title><link>http://arxiv.org/abs/2405.18350v1</link><description>We present an automatic text expansion system to generate English sentences,which performs automatic Natural Language Generation (NLG) by combininglinguistic rules with statistical approaches. Here, "automatic" means that thesystem can generate coherent and correct sentences from a minimum set of words.From its inception, the design is modular and adaptable to other languages.This adaptability is one of its greatest advantages. For English, we havecreated the highly precise aLexiE lexicon with wide coverage, which representsa contribution on its own. We have evaluated the resulting NLG library in anAugmentative and Alternative Communication (AAC) proof of concept, bothdirectly (by regenerating corpus sentences) and manually (from annotations)using a popular corpus in the NLG field. We performed a second analysis bycomparing the quality of text expansion in English to Spanish, using an ad-hocSpanish-English parallel corpus. The system might also be applied to otherdomains such as report and news generation.</description><author>Silvia Garc√≠a M√©ndez, Milagros Fern√°ndez Gavilanes, Enrique Costa Montenegro, Jonathan Juncal Mart√≠nez, Francisco Javier Gonz√°lez Casta√±o, Ehud Reiter</author><pubDate>Tue, 28 May 2024 17:48:05 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.18350v1</guid></item><item><title>MusicMagus: Zero-Shot Text-to-Music Editing via Diffusion Models</title><link>http://arxiv.org/abs/2402.06178v3</link><description>Recent advances in text-to-music generation models have opened new avenues inmusical creativity. However, music generation usually involves iterativerefinements, and how to edit the generated music remains a significantchallenge. This paper introduces a novel approach to the editing of musicgenerated by such models, enabling the modification of specific attributes,such as genre, mood and instrument, while maintaining other aspects unchanged.Our method transforms text editing to \textit{latent space manipulation} whileadding an extra constraint to enforce consistency. It seamlessly integrateswith existing pretrained text-to-music diffusion models without requiringadditional training. Experimental results demonstrate superior performance overboth zero-shot and certain supervised baselines in style and timbre transferevaluations. Additionally, we showcase the practical applicability of ourapproach in real-world music editing scenarios.</description><author>Yixiao Zhang, Yukara Ikemiya, Gus Xia, Naoki Murata, Marco A. Mart√≠nez-Ram√≠rez, Wei-Hsiang Liao, Yuki Mitsufuji, Simon Dixon</author><pubDate>Tue, 28 May 2024 17:47:25 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.06178v3</guid></item><item><title>MF-AED-AEC: Speech Emotion Recognition by Leveraging Multimodal Fusion, Asr Error Detection, and Asr Error Correction</title><link>http://arxiv.org/abs/2401.13260v2</link><description>The prevalent approach in speech emotion recognition (SER) involvesintegrating both audio and textual information to comprehensively identify thespeaker's emotion, with the text generally obtained through automatic speechrecognition (ASR). An essential issue of this approach is that ASR errors fromthe text modality can worsen the performance of SER. Previous studies haveproposed using an auxiliary ASR error detection task to adaptively assignweights of each word in ASR hypotheses. However, this approach has limitedimprovement potential because it does not address the coherence of semanticinformation in the text. Additionally, the inherent heterogeneity of differentmodalities leads to distribution gaps between their representations, makingtheir fusion challenging. Therefore, in this paper, we incorporate twoauxiliary tasks, ASR error detection (AED) and ASR error correction (AEC), toenhance the semantic coherence of ASR text, and further introduce a novelmulti-modal fusion (MF) method to learn shared representations acrossmodalities. We refer to our method as MF-AED-AEC. Experimental results indicatethat MF-AED-AEC significantly outperforms the baseline model by a margin of4.1\%.</description><author>Jiajun He, Xiaohan Shi, Xingfeng Li, Tomoki Toda</author><pubDate>Tue, 28 May 2024 17:47:15 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.13260v2</guid></item><item><title>Can Automatic Metrics Assess High-Quality Translations?</title><link>http://arxiv.org/abs/2405.18348v1</link><description>Automatic metrics for evaluating translation quality are typically validatedby measuring how well they correlate with human assessments. However,correlation methods tend to capture only the ability of metrics todifferentiate between good and bad source-translation pairs, overlooking theirreliability in distinguishing alternative translations for the same source. Inthis paper, we confirm that this is indeed the case by showing that currentmetrics are insensitive to nuanced differences in translation quality. Thiseffect is most pronounced when the quality is high and the variance amongalternatives is low. Given this finding, we shift towards detectinghigh-quality correct translations, an important problem in practicaldecision-making scenarios where a binary check of correctness is prioritizedover a nuanced evaluation of quality. Using the MQM framework as the goldstandard, we systematically stress-test the ability of current metrics toidentify translations with no errors as marked by humans. Our findings revealthat current metrics often over or underestimate translation quality,indicating significant room for improvement in automatic evaluation methods.</description><author>Sweta Agrawal, Ant√≥nio Farinhas, Ricardo Rei, Andr√© F. T. Martins</author><pubDate>Tue, 28 May 2024 17:44:02 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.18348v1</guid></item><item><title>Dataset Growth</title><link>http://arxiv.org/abs/2405.18347v1</link><description>Deep learning benefits from the growing abundance of available data.Meanwhile, efficiently dealing with the growing data scale has become achallenge. Data publicly available are from different sources with variousqualities, and it is impractical to do manual cleaning against noise andredundancy given today's data scale. There are existing techniques forcleaning/selecting the collected data. However, these methods are mainlyproposed for offline settings that target one of the cleanness and redundancyproblems. In practice, data are growing exponentially with both problems. Thisleads to repeated data curation with sub-optimal efficiency. To tackle thischallenge, we propose InfoGrowth, an efficient online algorithm for datacleaning and selection, resulting in a growing dataset that keeps up to datewith awareness of cleanliness and diversity. InfoGrowth can improve dataquality/efficiency on both single-modal and multi-modal tasks, with anefficient and scalable design. Its framework makes it practical for real-worlddata engines.</description><author>Ziheng Qin, Zhaopan Xu, Yukun Zhou, Zangwei Zheng, Zebang Cheng, Hao Tang, Lei Shang, Baigui Sun, Xiaojiang Peng, Radu Timofte, Hongxun Yao, Kai Wang, Yang You</author><pubDate>Tue, 28 May 2024 17:43:57 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.18347v1</guid></item><item><title>Intelligent Clinical Documentation: Harnessing Generative AI for Patient-Centric Clinical Note Generation</title><link>http://arxiv.org/abs/2405.18346v1</link><description>Comprehensive clinical documentation is crucial for effective healthcaredelivery, yet it poses a significant burden on healthcare professionals,leading to burnout, increased medical errors, and compromised patient safety.This paper explores the potential of generative AI (Artificial Intelligence) tostreamline the clinical documentation process, specifically focusing ongenerating SOAP (Subjective, Objective, Assessment, Plan) and BIRP (Behavior,Intervention, Response, Plan) notes. We present a case study demonstrating theapplication of natural language processing (NLP) and automatic speechrecognition (ASR) technologies to transcribe patient-clinician interactions,coupled with advanced prompting techniques to generate draft clinical notesusing large language models (LLMs). The study highlights the benefits of thisapproach, including time savings, improved documentation quality, and enhancedpatient-centered care. Additionally, we discuss ethical considerations, such asmaintaining patient confidentiality and addressing model biases, underscoringthe need for responsible deployment of generative AI in healthcare settings.The findings suggest that generative AI has the potential to revolutionizeclinical documentation practices, alleviating administrative burdens andenabling healthcare professionals to focus more on direct patient care.</description><author>Anjanava Biswas, Wrick Talukdar</author><pubDate>Tue, 28 May 2024 17:43:41 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.18346v1</guid></item><item><title>The Battle of LLMs: A Comparative Study in Conversational QA Tasks</title><link>http://arxiv.org/abs/2405.18344v1</link><description>Large language models have gained considerable interest for their impressiveperformance on various tasks. Within this domain, ChatGPT and GPT-4, developedby OpenAI, and the Gemini, developed by Google, have emerged as particularlypopular among early adopters. Additionally, Mixtral by Mistral AI and Claude byAnthropic are newly released, further expanding the landscape of advancedlanguage models. These models are viewed as disruptive technologies withapplications spanning customer service, education, healthcare, and finance.More recently, Mistral has entered the scene, captivating users with its uniqueability to generate creative content. Understanding the perspectives of theseusers is crucial, as they can offer valuable insights into the potentialstrengths, weaknesses, and overall success or failure of these technologies invarious domains. This research delves into the responses generated by ChatGPT,GPT-4, Gemini, Mixtral and Claude across different Conversational QA corpora.Evaluation scores were meticulously computed and subsequently compared toascertain the overall performance of these models. Our study pinpointedinstances where these models provided inaccurate answers to questions, offeringinsights into potential areas where they might be susceptible to errors. Inessence, this research provides a comprehensive comparison and evaluation ofthese state of-the-art language models, shedding light on their capabilitieswhile also highlighting potential areas for improvement</description><author>Aryan Rangapur, Aman Rangapur</author><pubDate>Tue, 28 May 2024 17:42:43 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.18344v1</guid></item><item><title>CHGNN: A Semi-Supervised Contrastive Hypergraph Learning Network</title><link>http://arxiv.org/abs/2303.06213v2</link><description>Hypergraphs can model higher-order relationships among data objects that arefound in applications such as social networks and bioinformatics. However,recent studies on hypergraph learning that extend graph convolutional networksto hypergraphs cannot learn effectively from features of unlabeled data. Tosuch learning, we propose a contrastive hypergraph neural network, CHGNN, thatexploits self-supervised contrastive learning techniques to learn from labeledand unlabeled data. First, CHGNN includes an adaptive hypergraph view generatorthat adopts an auto-augmentation strategy and learns a perturbed probabilitydistribution of minimal sufficient views. Second, CHGNN encompasses an improvedhypergraph encoder that considers hyperedge homogeneity to fuse informationeffectively. Third, CHGNN is equipped with a joint loss function that combinesa similarity loss for the view generator, a node classification loss, and ahyperedge homogeneity loss to inject supervision signals. It also includesbasic and cross-validation contrastive losses, associated with an enhancedcontrastive loss training process. Experimental results on nine real datasetsoffer insight into the effectiveness of CHGNN, showing that it outperforms 13competitors in terms of classification accuracy consistently.</description><author>Yumeng Song, Yu Gu, Tianyi Li, Jianzhong Qi, Zhenghao Liu, Christian S. Jensen, Ge Yu</author><pubDate>Tue, 28 May 2024 17:42:06 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2303.06213v2</guid></item><item><title>Unleashing the potential of prompt engineering: a comprehensive review</title><link>http://arxiv.org/abs/2310.14735v3</link><description>This comprehensive review explores the transformative potential of promptengineering within the realm of large language models (LLMs) and multimodallanguage models (MMLMs). The development of AI, from its inception in the 1950sto the emergence of neural networks and deep learning architectures, hasculminated in sophisticated LLMs like GPT-4 and BERT, as well as MMLMs likeDALL-E and CLIP. These models have revolutionized tasks in diverse fields suchas workplace automation, healthcare, and education. Prompt engineering emergesas a crucial technique to maximize the utility and accuracy of these models.This paper delves into both foundational and advanced methodologies of promptengineering, including techniques like Chain of Thought, Self-consistency, andGenerated Knowledge, which significantly enhance model performance.Additionally, it examines the integration of multimodal data through innovativeapproaches such as Multi-modal Prompt Learning (MaPLe), Conditional PromptLearning, and Context Optimization. Critical to this discussion is the aspectof AI security, particularly adversarial attacks that exploit vulnerabilitiesin prompt engineering. Strategies to mitigate these risks and enhance modelrobustness are thoroughly reviewed. The evaluation of prompt methods isaddressed through both subjective and objective metrics, ensuring a robustanalysis of their efficacy. This review underscores the pivotal role of promptengineering in advancing AI capabilities, providing a structured framework forfuture research and application.</description><author>Banghao Chen, Zhaofeng Zhang, Nicolas Langren√©, Shengxin Zhu</author><pubDate>Tue, 28 May 2024 17:38:19 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.14735v3</guid></item><item><title>DoRA: Enhancing Parameter-Efficient Fine-Tuning with Dynamic Rank Distribution</title><link>http://arxiv.org/abs/2405.17357v2</link><description>Fine-tuning large-scale pre-trained models is inherently a resource-intensivetask. While it can enhance the capabilities of the model, it also incurssubstantial computational costs, posing challenges to the practical applicationof downstream tasks. Existing parameter-efficient fine-tuning (PEFT) methodssuch as Low-Rank Adaptation (LoRA) rely on a bypass framework that ignores thedifferential parameter budget requirements across weight matrices, which maylead to suboptimal fine-tuning outcomes. To address this issue, we introducethe Dynamic Low-Rank Adaptation (DoRA) method. DoRA decomposes high-rank LoRAlayers into structured single-rank components, allowing for dynamic pruning ofparameter budget based on their importance to specific tasks during training,which makes the most of the limited parameter budget. Experimental resultsdemonstrate that DoRA can achieve competitive performance compared with LoRAand full model fine-tuning, and outperform various strong baselines with thesame storage parameter budget. Our code is available athttps://github.com/MIkumikumi0116/DoRA</description><author>Yulong Mao, Kaiyu Huang, Changhao Guan, Ganglin Bao, Fengran Mo, Jinan Xu</author><pubDate>Tue, 28 May 2024 17:35:19 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.17357v2</guid></item><item><title>Stochastic Spiking Neural Networks with First-to-Spike Coding</title><link>http://arxiv.org/abs/2404.17719v2</link><description>Spiking Neural Networks (SNNs), recognized as the third generation of neuralnetworks, are known for their bio-plausibility and energy efficiency,especially when implemented on neuromorphic hardware. However, the majority ofexisting studies on SNNs have concentrated on deterministic neurons with ratecoding, a method that incurs substantial computational overhead due to lengthyinformation integration times and fails to fully harness the brain'sprobabilistic inference capabilities and temporal dynamics. In this work, weexplore the merger of novel computing and information encoding schemes in SNNarchitectures where we integrate stochastic spiking neuron models with temporalcoding techniques. Through extensive benchmarking with other deterministic SNNsand rate-based coding, we investigate the tradeoffs of our proposal in terms ofaccuracy, inference latency, spiking sparsity, energy consumption, androbustness. Our work is the first to extend the scalability of direct trainingapproaches of stochastic SNNs with temporal encoding to VGG architectures andbeyond-MNIST datasets.</description><author>Yi Jiang, Sen Lu, Abhronil Sengupta</author><pubDate>Tue, 28 May 2024 17:33:58 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.17719v2</guid></item><item><title>AI-Assisted Detector Design for the EIC (AID(2)E)</title><link>http://arxiv.org/abs/2405.16279v2</link><description>Artificial Intelligence is poised to transform the design of complex,large-scale detectors like the ePIC at the future Electron Ion Collider.Featuring a central detector with additional detecting systems in the farforward and far backward regions, the ePIC experiment incorporates numerousdesign parameters and objectives, including performance, physics reach, andcost, constrained by mechanical and geometric limits. This project aims todevelop a scalable, distributed AI-assisted detector design for the EIC(AID(2)E), employing state-of-the-art multiobjective optimization to tacklecomplex designs. Supported by the ePIC software stack and using Geant4simulations, our approach benefits from transparent parameterization andadvanced AI features. The workflow leverages the PanDA and iDDS systems, usedin major experiments such as ATLAS at CERN LHC, the Rubin Observatory, andsPHENIX at RHIC, to manage the compute intensive demands of ePIC detectorsimulations. Tailored enhancements to the PanDA system focus on usability,scalability, automation, and monitoring. Ultimately, this project aims toestablish a robust design capability, apply a distributed AI-assisted workflowto the ePIC detector, and extend its applications to the design of the seconddetector (Detector-2) in the EIC, as well as to calibration and alignmenttasks. Additionally, we are developing advanced data science tools toefficiently navigate the complex, multidimensional trade-offs identifiedthrough this optimization process.</description><author>M. Diefenthaler, C. Fanelli, L. O. Gerlach, W. Guan, T. Horn, A. Jentsch, M. Lin, K. Nagai, H. Nayak, C. Pecar, K. Suresh, A. Vossen, T. Wang, T. Wenaus</author><pubDate>Tue, 28 May 2024 17:31:59 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.16279v2</guid></item><item><title>Interpretable classification of wiki-review streams</title><link>http://arxiv.org/abs/2405.18335v1</link><description>Wiki articles are created and maintained by a crowd of editors, producing acontinuous stream of reviews. Reviews can take the form of additions, reverts,or both. This crowdsourcing model is exposed to manipulation since neitherreviews nor editors are automatically screened and purged. To protect articlesagainst vandalism or damage, the stream of reviews can be mined to classifyreviews and profile editors in real-time. The goal of this work is toanticipate and explain which reviews to revert. This way, editors are informedwhy their edits will be reverted. The proposed method employs stream-basedprocessing, updating the profiling and classification models on each incomingevent. The profiling uses side and content-based features employing NaturalLanguage Processing, and editor profiles are incrementally updated based ontheir reviews. Since the proposed method relies on self-explainableclassification algorithms, it is possible to understand why a review has beenclassified as a revert or a non-revert. In addition, this work contributes analgorithm for generating synthetic data for class balancing, making the finalclassification fairer. The proposed online method was tested with a real dataset from Wikivoyage, which was balanced through the aforementioned syntheticdata generation. The results attained near-90 % values for all evaluationmetrics (accuracy, precision, recall, and F-measure).</description><author>Silvia Garc√≠a M√©ndez, F√°tima Leal, Benedita Malheiro, Juan Carlos Burguillo Rial</author><pubDate>Tue, 28 May 2024 17:28:58 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.18335v1</guid></item><item><title>SketchQL Demonstration: Zero-shot Video Moment Querying with Sketches</title><link>http://arxiv.org/abs/2405.18334v1</link><description>In this paper, we will present SketchQL, a video database management system(VDBMS) for retrieving video moments with a sketch-based query interface. Thisnovel interface allows users to specify object trajectory events with simplemouse drag-and-drop operations. Users can use trajectories of single objects asbuilding blocks to compose complex events. Using a pre-trained model thatencodes trajectory similarity, SketchQL achieves zero-shot video momentsretrieval by performing similarity searches over the video to identify clipsthat are the most similar to the visual query. In this demonstration, weintroduce the graphic user interface of SketchQL and detail its functionalitiesand interaction mechanisms. We also demonstrate the end-to-end usage ofSketchQL from query composition to video moments retrieval using real-worldscenarios.</description><author>Renzhi Wu, Pramod Chunduri, Dristi J Shah, Ashmitha Julius Aravind, Ali Payani, Xu Chu, Joy Arulraj, Kexin Rong</author><pubDate>Tue, 28 May 2024 17:28:51 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.18334v1</guid></item><item><title>STEER: Assessing the Economic Rationality of Large Language Models</title><link>http://arxiv.org/abs/2402.09552v2</link><description>There is increasing interest in using LLMs as decision-making "agents." Doingso includes many degrees of freedom: which model should be used; how should itbe prompted; should it be asked to introspect, conduct chain-of-thoughtreasoning, etc? Settling these questions -- and more broadly, determiningwhether an LLM agent is reliable enough to be trusted -- requires a methodologyfor assessing such an agent's economic rationality. In this paper, we provideone. We begin by surveying the economic literature on rational decision making,taxonomizing a large set of fine-grained "elements" that an agent shouldexhibit, along with dependencies between them. We then propose a benchmarkdistribution that quantitatively scores an LLMs performance on these elementsand, combined with a user-provided rubric, produces a "STEER report card."Finally, we describe the results of a large-scale empirical experiment with 14different LLMs, characterizing the both current state of the art and the impactof different model sizes on models' ability to exhibit rational behavior.</description><author>Narun Raman, Taylor Lundy, Samuel Amouyal, Yoav Levine, Kevin Leyton-Brown, Moshe Tennenholtz</author><pubDate>Tue, 28 May 2024 17:27:56 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.09552v2</guid></item><item><title>Frustratingly Easy Test-Time Adaptation of Vision-Language Models</title><link>http://arxiv.org/abs/2405.18330v1</link><description>Vision-Language Models seamlessly discriminate among arbitrary semanticcategories, yet they still suffer from poor generalization when presented withchallenging examples. For this reason, Episodic Test-Time Adaptation (TTA)strategies have recently emerged as powerful techniques to adapt VLMs in thepresence of a single unlabeled image. The recent literature on TTA is dominatedby the paradigm of prompt tuning by Marginal Entropy Minimization, which,relying on online backpropagation, inevitably slows down inference whileincreasing memory. In this work, we theoretically investigate the properties ofthis approach and unveil that a surprisingly strong TTA method lies dormant andhidden within it. We term this approach ZERO (TTA with "zero" temperature),whose design is both incredibly effective and frustratingly simple: augment Ntimes, predict, retain the most confident predictions, and marginalize aftersetting the Softmax temperature to zero. Remarkably, ZERO requires a singlebatched forward pass through the vision encoder only and no backward passes. Wethoroughly evaluate our approach following the experimental protocolestablished in the literature and show that ZERO largely surpasses or comparesfavorably w.r.t. the state-of-the-art while being almost 10x faster and 13xmore memory-friendly than standard Test-Time Prompt Tuning. Thanks to itssimplicity and comparatively negligible computation, ZERO can serve as a strongbaseline for future work in this field. The code is available athttps://github.com/FarinaMatteo/zero.</description><author>Matteo Farina, Gianni Franchi, Giovanni Iacca, Massimiliano Mancini, Elisa Ricci</author><pubDate>Tue, 28 May 2024 17:24:47 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.18330v1</guid></item><item><title>Latent Plan Transformer: Planning as Latent Variable Inference</title><link>http://arxiv.org/abs/2402.04647v2</link><description>In tasks aiming for long-term returns, planning becomes essential. We studygenerative modeling for planning with datasets repurposed from offlinereinforcement learning. Specifically, we identify temporal consistency in theabsence of step-wise rewards as one key technical challenge. We introduce theLatent Plan Transformer (LPT), a novel model that leverages a latent space toconnect a Transformer-based trajectory generator and the final return. LPT canbe learned with maximum likelihood estimation on trajectory-return pairs. Inlearning, posterior sampling of the latent variable naturally integratessub-trajectories to form a consistent abstraction despite the finite context.At test time, the latent variable is inferred from an expected return beforepolicy execution, realizing the idea of planning as inference. Our experimentsdemonstrate that LPT can discover improved decisions from suboptimaltrajectories, achieving competitive performance across several benchmarks,including Gym-Mujoco, Franka Kitchen, Maze2D, and Connect Four. It exhibitscapabilities in nuanced credit assignments, trajectory stitching, andadaptation to environmental contingencies. These results validate that latentvariable inference can be a strong alternative to step-wise reward prompting.</description><author>Deqian Kong, Dehong Xu, Minglu Zhao, Bo Pang, Jianwen Xie, Andrew Lizarraga, Yuhao Huang, Sirui Xie, Ying Nian Wu</author><pubDate>Tue, 28 May 2024 17:24:41 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.04647v2</guid></item><item><title>Efficient Remote Sensing with Harmonized Transfer Learning and Modality Alignment</title><link>http://arxiv.org/abs/2404.18253v5</link><description>With the rise of Visual and Language Pretraining (VLP), an increasing numberof downstream tasks are adopting the paradigm of pretraining followed byfine-tuning. Although this paradigm has demonstrated potential in variousmultimodal downstream tasks, its implementation in the remote sensing domainencounters some obstacles. Specifically, the tendency for same-modalityembeddings to cluster together impedes efficient transfer learning. To tacklethis issue, we review the aim of multimodal transfer learning for downstreamtasks from a unified perspective, and rethink the optimization process based onthree distinct objectives. We propose "Harmonized Transfer Learning andModality Alignment (HarMA)", a method that simultaneously satisfies taskconstraints, modality alignment, and single-modality uniform alignment, whileminimizing training overhead through parameter-efficient fine-tuning.Remarkably, without the need for external data for training, HarMA achievesstate-of-the-art performance in two popular multimodal retrieval tasks in thefield of remote sensing. Our experiments reveal that HarMA achieves competitiveand even superior performance to fully fine-tuned models with only minimaladjustable parameters. Due to its simplicity, HarMA can be integrated intoalmost all existing multimodal pretraining models. We hope this method canfacilitate the efficient application of large models to a wide range ofdownstream tasks while significantly reducing the resource consumption. Code isavailable at https://github.com/seekerhuang/HarMA.</description><author>Tengjun Huang</author><pubDate>Tue, 28 May 2024 17:24:03 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.18253v5</guid></item><item><title>Warm Start Marginal Likelihood Optimisation for Iterative Gaussian Processes</title><link>http://arxiv.org/abs/2405.18328v1</link><description>Gaussian processes are a versatile probabilistic machine learning model whoseeffectiveness often depends on good hyperparameters, which are typicallylearned by maximising the marginal likelihood. In this work, we consideriterative methods, which use iterative linear system solvers to approximatemarginal likelihood gradients up to a specified numerical precision, allowing atrade-off between compute time and accuracy of a solution. We introduce athree-level hierarchy of marginal likelihood optimisation for iterativeGaussian processes, and identify that the computational costs are dominated bysolving sequential batches of large positive-definite systems of linearequations. We then propose to amortise computations by reusing solutions oflinear system solvers as initialisations in the next step, providing a$\textit{warm start}$. Finally, we discuss the necessary conditions andquantify the consequences of warm starts and demonstrate their effectiveness onregression tasks, where warm starts achieve the same results as theconventional procedure while providing up to a $16 \times$ average speed-upamong datasets.</description><author>Jihao Andreas Lin, Shreyas Padhy, Bruno Mlodozeniec, Jos√© Miguel Hern√°ndez-Lobato</author><pubDate>Tue, 28 May 2024 17:22:18 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.18328v1</guid></item><item><title>Histopathology Based AI Model Predicts Anti-Angiogenic Therapy Response in Renal Cancer Clinical Trial</title><link>http://arxiv.org/abs/2405.18327v1</link><description>Predictive biomarkers of treatment response are lacking for metastatic clearcell renal cell carcinoma (ccRCC), a tumor type that is treated withangiogenesis inhibitors, immune checkpoint inhibitors, mTOR inhibitors and aHIF2 inhibitor. The Angioscore, an RNA-based quantification of angiogenesis, isarguably the best candidate to predict anti-angiogenic (AA) response. However,the clinical adoption of transcriptomic assays faces several challengesincluding standardization, time delay, and high cost. Further, ccRCC tumors arehighly heterogenous, and sampling multiple areas for sequencing is impractical.Here we present a novel deep learning (DL) approach to predict the Angioscorefrom ubiquitous histopathology slides. To overcome the lack ofinterpretability, one of the biggest limitations of typical DL models, ourmodel produces a visual vascular network which is the basis of the model'sprediction. To test its reliability, we applied this model to multiple cohortsincluding a clinical trial dataset. Our model accurately predicts the RNA-basedAngioscore on multiple independent cohorts (spearman correlations of 0.77 and0.73). Further, the predictions help unravel meaningful biology such asassociation of angiogenesis with grade, stage, and driver mutation status.Finally, we find our model can predict response to AA therapy, in both areal-world cohort and the IMmotion150 clinical trial. The predictive power ofour model vastly exceeds that of CD31, a marker of vasculature, and nearlyrivals the performance (c-index 0.66 vs 0.67) of the ground truth RNA-basedAngioscore at a fraction of the cost. By providing a robust yet interpretableprediction of the Angioscore from histopathology slides alone, our approachoffers insights into angiogenesis biology and AA treatment response.</description><author>Jay Jasti, Hua Zhong, Vandana Panwar, Vipul Jarmale, Jeffrey Miyata, Deyssy Carrillo, Alana Christie, Dinesh Rakheja, Zora Modrusan, Edward Ernest Kadel III, Niha Beig, Mahrukh Huseni, James Brugarolas, Payal Kapur, Satwik Rajaram</author><pubDate>Tue, 28 May 2024 17:21:20 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.18327v1</guid></item><item><title>VITON-DiT: Learning In-the-Wild Video Try-On from Human Dance Videos via Diffusion Transformers</title><link>http://arxiv.org/abs/2405.18326v1</link><description>Video try-on stands as a promising area for its tremendous real-worldpotential. Prior works are limited to transferring product clothing images ontoperson videos with simple poses and backgrounds, while underperforming oncasually captured videos. Recently, Sora revealed the scalability of DiffusionTransformer (DiT) in generating lifelike videos featuring real-world scenarios.Inspired by this, we explore and propose the first DiT-based video try-onframework for practical in-the-wild applications, named VITON-DiT.Specifically, VITON-DiT consists of a garment extractor, a Spatial-Temporaldenoising DiT, and an identity preservation ControlNet. To faithfully recoverthe clothing details, the extracted garment features are fused with theself-attention outputs of the denoising DiT and the ControlNet. We alsointroduce novel random selection strategies during training and an InterpolatedAuto-Regressive (IAR) technique at inference to facilitate long videogeneration. Unlike existing attempts that require the laborious and restrictiveconstruction of a paired training dataset, severely limiting their scalability,VITON-DiT alleviates this by relying solely on unpaired human dance videos anda carefully designed multi-stage training strategy. Furthermore, we curate achallenging benchmark dataset to evaluate the performance of casual videotry-on. Extensive experiments demonstrate the superiority of VITON-DiT ingenerating spatio-temporal consistent try-on results for in-the-wild videoswith complicated human poses.</description><author>Jun Zheng, Fuwei Zhao, Youjiang Xu, Xin Dong, Xiaodan Liang</author><pubDate>Tue, 28 May 2024 17:21:03 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.18326v1</guid></item><item><title>Selecting Large Language Model to Fine-tune via Rectified Scaling Law</title><link>http://arxiv.org/abs/2402.02314v3</link><description>The ever-growing ecosystem of LLMs has posed a challenge in selecting themost appropriate pre-trained model to fine-tune amidst a sea of options. Givenconstrained resources, fine-tuning all models and making selections afterwardis unrealistic. In this work, we formulate this resource-constrained selectiontask into predicting fine-tuning performance and illustrate its naturalconnection with Scaling Law. Unlike pre-training, we find that the fine-tuningscaling curve includes not just the well-known "power phase" but also thepreviously unobserved "pre-power phase". We also explain why existing ScalingLaw fails to capture this phase transition phenomenon both theoretically andempirically. To address this, we introduce the concept of "pre-learned datasize" into our Rectified Scaling Law, which overcomes theoretical limitationsand fits experimental results much better. By leveraging our law, we propose anovel LLM selection algorithm that selects the near-optimal model with hundredsof times less resource consumption, while other methods may provide negativelycorrelated selection. The project page is available atrectified-scaling-law.github.io.</description><author>Haowei Lin, Baizhou Huang, Haotian Ye, Qinyu Chen, Zihao Wang, Sujian Li, Jianzhu Ma, Xiaojun Wan, James Zou, Yitao Liang</author><pubDate>Tue, 28 May 2024 17:16:42 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.02314v3</guid></item><item><title>Intuitive Fine-Tuning: Towards Simplifying Alignment into a Single Process</title><link>http://arxiv.org/abs/2405.11870v2</link><description>Supervised Fine-Tuning (SFT) and Preference Optimization (PO) are twofundamental processes for enhancing the capabilities of Language Models (LMs)post pre-training, aligning them better with human preferences. Although SFTadvances in training efficiency, PO delivers better alignment, thus they areoften combined. However, common practices simply apply them sequentiallywithout integrating their optimization objectives, ignoring the opportunitiesto bridge their paradigm gap and take the strengths from both. To obtain aunified understanding, we interpret SFT and PO with two sub-processes --Preference Estimation and Transition Optimization -- defined at token levelwithin the Markov Decision Process (MDP) framework. This modeling shows thatSFT is only a specialized case of PO with inferior estimation and optimization.PO evaluates the quality of model's entire generated answer, whereas SFT onlyscores predicted tokens based on preceding tokens from target answers.Therefore, SFT overestimates the ability of model, leading to inferioroptimization. Building on this view, we introduce Intuitive Fine-Tuning (IFT)to integrate SFT and Preference Optimization into a single process. IFTcaptures LMs' intuitive sense of the entire answers through a temporal residualconnection, but it solely relies on a single policy and the same volume ofnon-preference-labeled data as SFT. Our experiments show that IFT performscomparably or even superiorly to sequential recipes of SFT and some typicalPreference Optimization methods across several tasks, particularly thoserequires generation, reasoning, and fact-following abilities. An explainableFrozen Lake game further validates the effectiveness of IFT for gettingcompetitive policy.</description><author>Ermo Hua, Biqing Qi, Kaiyan Zhang, Yue Yu, Ning Ding, Xingtai Lv, Kai Tian, Bowen Zhou</author><pubDate>Tue, 28 May 2024 17:14:58 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.11870v2</guid></item><item><title>SCE-MAE: Selective Correspondence Enhancement with Masked Autoencoder for Self-Supervised Landmark Estimation</title><link>http://arxiv.org/abs/2405.18322v1</link><description>Self-supervised landmark estimation is a challenging task that demands theformation of locally distinct feature representations to identify sparse faciallandmarks in the absence of annotated data. To tackle this task, existingstate-of-the-art (SOTA) methods (1) extract coarse features from backbones thatare trained with instance-level self-supervised learning (SSL) paradigms, whichneglect the dense prediction nature of the task, (2) aggregate them intomemory-intensive hypercolumn formations, and (3) supervise lightweightprojector networks to naively establish full local correspondences among allpairs of spatial features. In this paper, we introduce SCE-MAE, a frameworkthat (1) leverages the MAE, a region-level SSL method that naturally bettersuits the landmark prediction task, (2) operates on the vanilla feature mapinstead of on expensive hypercolumns, and (3) employs a CorrespondenceApproximation and Refinement Block (CARB) that utilizes a simple density peakclustering algorithm and our proposed Locality-Constrained Repellence Loss todirectly hone only select local correspondences. We demonstrate throughextensive experiments that SCE-MAE is highly effective and robust,outperforming existing SOTA methods by large margins of approximately 20%-44%on the landmark matching and approximately 9%-15% on the landmark detectiontasks.</description><author>Kejia Yin, Varshanth R. Rao, Ruowei Jiang, Xudong Liu, Parham Aarabi, David B. Lindell</author><pubDate>Tue, 28 May 2024 17:14:10 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.18322v1</guid></item><item><title>Good Tools are Half the Work: Tool Usage in Deep Learning Projects</title><link>http://arxiv.org/abs/2310.19124v2</link><description>The rising popularity of deep learning (DL) methods and techniques hasinvigorated interest in the topic of SE4DL (Software Engineering for DeepLearning), the application of software engineering (SE) practices on deeplearning software. Despite the novel engineering challenges brought on by thedata-driven and non-deterministic paradigm of DL software, little work has beeninvested into developing DL-targeted SE tools. On the other hand, toolstackling non-SE issues specific to DL are actively used and referred to underthe umbrella term "MLOps (Machine Learning Operations) tools". Nevertheless,the available literature supports the utility of conventional SE tooling in DLsoftware development. Building upon previous mining software repositories (MSR)research on tool usage in open-source software works, we identify conventionaland MLOps tools adopted in popular applied DL projects that use Python as themain programming language. About 63\% of the GitHub repositories we examinedcontained at least one conventional SE tool. Software construction tools arethe most widely adopted, while the opposite applies to management andmaintenance tools. Relatively few MLOps tools were found to be use, with only20 tools out of a sample of 74 used in at least one repository. The majority ofthem were open-source rather than proprietary. One of these tools, TensorBoard,was found to be adopted in about half of the repositories in our study.Consequently, the widespread use of conventional SE tooling demonstrates itsrelevance to DL software. Further research is recommended on the adoption ofMLOps tooling, focusing on the relevance of particular tool types, thedevelopment of required tools, as well as ways to promote the use of alreadyavailable tools.</description><author>Evangelia Panourgia, Theodoros Plessas, Ilias Balampanis, Diomidis Spinellis</author><pubDate>Tue, 28 May 2024 17:13:22 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.19124v2</guid></item><item><title>Self-Supervised Learning Based Handwriting Verification</title><link>http://arxiv.org/abs/2405.18320v1</link><description>We present SSL-HV: Self-Supervised Learning approaches applied to the task ofHandwriting Verification. This task involves determining whether a given pairof handwritten images originate from the same or different writer distribution.We have compared the performance of multiple generative, contrastive SSLapproaches against handcrafted feature extractors and supervised learning onCEDAR AND dataset. We show that ResNet based Variational Auto-Encoder (VAE)outperforms other generative approaches achieving 76.3% accuracy, whileResNet-18 fine-tuned using Variance-Invariance-Covariance Regularization(VICReg) outperforms other contrastive approaches achieving 78% accuracy. Usinga pre-trained VAE and VICReg for the downstream task of writer verification weobserved a relative improvement in accuracy of 6.7% and 9% over ResNet-18supervised baseline with 10% writer labels.</description><author>Mihir Chauhan, Mohammad Abuzar Shaikh, Bina Ramamurthy, Mingchen Gao, Siwei Lyu, Sargur Srihari</author><pubDate>Tue, 28 May 2024 17:11:11 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.18320v1</guid></item><item><title>Efficient Detection of LLM-generated Texts with a Bayesian Surrogate Model</title><link>http://arxiv.org/abs/2305.16617v2</link><description>The detection of machine-generated text, especially from large languagemodels (LLMs), is crucial in preventing serious social problems resulting fromtheir misuse. Some methods train dedicated detectors on specific datasets butfall short in generalizing to unseen test data, while other zero-shot onesoften yield suboptimal performance. Although the recent DetectGPT has shownpromising detection performance, it suffers from significant inefficiencyissues, as detecting a single candidate requires querying the source LLM withhundreds of its perturbations. This paper aims to bridge this gap. Concretely,we propose to incorporate a Bayesian surrogate model, which allows us to selecttypical samples based on Bayesian uncertainty and interpolate scores fromtypical samples to other samples, to improve query efficiency. Empiricalresults demonstrate that our method significantly outperforms existingapproaches under a low query budget. Notably, when detecting the text generatedby LLaMA family models, our method with just 2 or 3 queries can outperformDetectGPT with 200 queries.</description><author>Yibo Miao, Hongcheng Gao, Hao Zhang, Zhijie Deng</author><pubDate>Tue, 28 May 2024 17:10:59 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.16617v2</guid></item><item><title>DSDL: Data Set Description Language for Bridging Modalities and Tasks in AI Data</title><link>http://arxiv.org/abs/2405.18315v1</link><description>In the era of artificial intelligence, the diversity of data modalities andannotation formats often renders data unusable directly, requiringunderstanding and format conversion before it can be used by researchers ordevelopers with different needs. To tackle this problem, this articleintroduces a framework called Dataset Description Language (DSDL) that aims tosimplify dataset processing by providing a unified standard for AI datasets.DSDL adheres to the three basic practical principles of generic, portable, andextensible, using a unified standard to express data of different modalitiesand structures, facilitating the dissemination of AI data, and easily extendingto new modalities and tasks. The standardized specifications of DSDL reduce theworkload for users in data dissemination, processing, and usage. To furtherimprove user convenience, we provide predefined DSDL templates for varioustasks, convert mainstream datasets to comply with DSDL specifications, andprovide comprehensive documentation and DSDL tools. These efforts aim tosimplify the use of AI data, thereby improving the efficiency of AIdevelopment.</description><author>Bin Wang, Linke Ouyang, Fan Wu, Wenchang Ning, Xiao Han, Zhiyuan Zhao, Jiahui Peng, Yiying Jiang, Dahua Lin, Conghui He</author><pubDate>Tue, 28 May 2024 17:07:45 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.18315v1</guid></item><item><title>Deriving Causal Order from Single-Variable Interventions: Guarantees &amp; Algorithm</title><link>http://arxiv.org/abs/2405.18314v1</link><description>Targeted and uniform interventions to a system are crucial for unveilingcausal relationships. While several methods have been developed to leverageinterventional data for causal structure learning, their practical applicationin real-world scenarios often remains challenging. Recent benchmark studieshave highlighted these difficulties, even when large numbers of single-variableintervention samples are available. In this work, we demonstrate, boththeoretically and empirically, that such datasets contain a wealth of causalinformation that can be effectively extracted under realistic assumptions aboutthe data distribution. More specifically, we introduce the notion ofinterventional faithfulness, which relies on comparisons between the marginaldistributions of each variable across observational and interventionalsettings, and we introduce a score on causal orders. Under this assumption, weare able to prove strong theoretical guarantees on the optimum of our scorethat also hold for large-scale settings. To empirically verify our theory, weintroduce Intersort, an algorithm designed to infer the causal order fromdatasets containing large numbers of single-variable interventions byapproximately optimizing our score. Intersort outperforms baselines (GIES, PCand EASE) on almost all simulated data settings replicating common benchmarksin the field. Our proposed novel approach to modeling interventional datasetsthus offers a promising avenue for advancing causal inference, highlightingsignificant potential for further enhancements under realistic assumptions.</description><author>Mathieu Chevalley, Patrick Schwab, Arash Mehrjou</author><pubDate>Tue, 28 May 2024 17:07:17 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.18314v1</guid></item><item><title>Mind-to-Image: Projecting Visual Mental Imagination of the Brain from fMRI</title><link>http://arxiv.org/abs/2404.05468v5</link><description>The reconstruction of images observed by subjects from fMRI data collectedduring visual stimuli has made strong progress in the past decade, thanks tothe availability of extensive fMRI datasets and advancements in generativemodels for image generation. However, the application of visual reconstructionhas remained limited. Reconstructing visual imagination presents a greaterchallenge, with potentially revolutionary applications ranging from aidingindividuals with disabilities to verifying witness accounts in court. Theprimary hurdles in this field are the absence of data collection protocols forvisual imagery and the lack of datasets on the subject. Traditionally,fMRI-to-image relies on data collected from subjects exposed to visual stimuli,which poses issues for generating visual imagery based on the difference ofbrain activity between visual stimulation and visual imagery. For the firsttime, we have compiled a substantial dataset (around 6h of scans) on visualimagery along with a proposed data collection protocol. We then train amodified version of an fMRI-to-image model and demonstrate the feasibility ofreconstructing images from two modes of imagination: from memory and from pureimagination. The resulting pipeline we call Mind-to-Image marks a step towardscreating a technology that allow direct reconstruction of visual imagery.</description><author>Hugo Caselles-Dupr√©, Charles Mellerio, Paul H√©rent, Aliz√©e Lopez-Persem, Benoit B√©ranger, Mathieu Soularue, Pierre Fautrel, Gauthier Vernier, Matthieu Cord</author><pubDate>Tue, 28 May 2024 17:03:21 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.05468v5</guid></item><item><title>Aurora: A Foundation Model of the Atmosphere</title><link>http://arxiv.org/abs/2405.13063v2</link><description>Deep learning foundation models are revolutionizing many facets of science byleveraging vast amounts of data to learn general-purpose representations thatcan be adapted to tackle diverse downstream tasks. Foundation models hold thepromise to also transform our ability to model our planet and its subsystems byexploiting the vast expanse of Earth system data. Here we introduce Aurora, alarge-scale foundation model of the atmosphere trained on over a million hoursof diverse weather and climate data. Aurora leverages the strengths of thefoundation modelling approach to produce operational forecasts for a widevariety of atmospheric prediction problems, including those with limitedtraining data, heterogeneous variables, and extreme events. In under a minute,Aurora produces 5-day global air pollution predictions and 10-dayhigh-resolution weather forecasts that outperform state-of-the-art classicalsimulation tools and the best specialized deep learning models. Taken together,these results indicate that foundation models can transform environmentalforecasting.</description><author>Cristian Bodnar, Wessel P. Bruinsma, Ana Lucic, Megan Stanley, Johannes Brandstetter, Patrick Garvan, Maik Riechert, Jonathan Weyn, Haiyu Dong, Anna Vaughan, Jayesh K. Gupta, Kit Tambiratnam, Alex Archibald, Elizabeth Heider, Max Welling, Richard E. Turner, Paris Perdikaris</author><pubDate>Tue, 28 May 2024 17:03:20 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.13063v2</guid></item><item><title>Deterministic and statistical calibration of constitutive models from full-field data with parametric physics-informed neural networks</title><link>http://arxiv.org/abs/2405.18311v1</link><description>The calibration of constitutive models from full-field data has recentlygained increasing interest due to improvements in full-field measurementcapabilities. In addition to the experimental characterization of novelmaterials, continuous structural health monitoring is another application thatis of great interest. However, monitoring is usually associated with severetime constraints, difficult to meet with standard numerical approaches.Therefore, parametric physics-informed neural networks (PINNs) for constitutivemodel calibration from full-field displacement data are investigated. In anoffline stage, a parametric PINN can be trained to learn a parameterizedsolution of the underlying partial differential equation. In the subsequentonline stage, the parametric PINN then acts as a surrogate for theparameters-to-state map in calibration. We test the proposed approach for thedeterministic least-squares calibration of a linear elastic as well as ahyperelastic constitutive model from noisy synthetic displacement data. Wefurther carry out Markov chain Monte Carlo-based Bayesian inference to quantifythe uncertainty. A proper statistical evaluation of the results underlines thehigh accuracy of the deterministic calibration and that the estimateduncertainty is valid. Finally, we consider experimental data and show that theresults are in good agreement with a Finite Element Method-based calibration.Due to the fast evaluation of PINNs, calibration can be performed in nearreal-time. This advantage is particularly evident in many-query applicationssuch as Markov chain Monte Carlo-based Bayesian inference.</description><author>David Anton, Jendrik-Alexander Tr√∂ger, Henning Wessels, Ulrich R√∂mer, Alexander Henkes, Stefan Hartmann</author><pubDate>Tue, 28 May 2024 17:02:11 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.18311v1</guid></item><item><title>Joint Lemmatization and Morphological Tagging with LEMMING</title><link>http://arxiv.org/abs/2405.18308v1</link><description>We present LEMMING, a modular log-linear model that jointly modelslemmatization and tagging and supports the integration of arbitrary globalfeatures. It is trainable on corpora annotated with gold standard tags andlemmata and does not rely on morphological dictionaries or analyzers. LEMMINGsets the new state of the art in token-based statistical lemmatization on sixlanguages; e.g., for Czech lemmatization, we reduce the error by 60%, from 4.05to 1.58. We also give empirical evidence that jointly modeling morphologicaltags and lemmata is mutually beneficial.</description><author>Thomas Muller, Ryan Cotterell, Alexander Fraser, Hinrich Sch√ºtze</author><pubDate>Tue, 28 May 2024 17:01:19 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.18308v1</guid></item><item><title>Speakers Fill Lexical Semantic Gaps with Context</title><link>http://arxiv.org/abs/2010.02172v4</link><description>Lexical ambiguity is widespread in language, allowing for the reuse ofeconomical word forms and therefore making language more efficient. Ifambiguous words cannot be disambiguated from context, however, this gain inefficiency might make language less clear -- resulting in frequentmiscommunication. For a language to be clear and efficiently encoded, we positthat the lexical ambiguity of a word type should correlate with how muchinformation context provides about it, on average. To investigate whether thisis the case, we operationalise the lexical ambiguity of a word as the entropyof meanings it can take, and provide two ways to estimate this -- one whichrequires human annotation (using WordNet), and one which does not (using BERT),making it readily applicable to a large number of languages. We validate thesemeasures by showing that, on six high-resource languages, there are significantPearson correlations between our BERT-based estimate of ambiguity and thenumber of synonyms a word has in WordNet (e.g. $\rho = 0.40$ in English). Wethen test our main hypothesis -- that a word's lexical ambiguity shouldnegatively correlate with its contextual uncertainty -- and find significantcorrelations on all 18 typologically diverse languages we analyse. Thissuggests that, in the presence of ambiguity, speakers compensate by makingcontexts more informative.</description><author>Tiago Pimentel, Rowan Hall Maudslay, Dami√°n Blasi, Ryan Cotterell</author><pubDate>Tue, 28 May 2024 17:00:24 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2010.02172v4</guid></item><item><title>Learning Staged Trees from Incomplete Data</title><link>http://arxiv.org/abs/2405.18306v1</link><description>Staged trees are probabilistic graphical models capable of representing anyclass of non-symmetric independence via a coloring of its vertices. Severalstructural learning routines have been defined and implemented to learn stagedtrees from data, under the frequentist or Bayesian paradigm. They assume a dataset has been observed fully and, in practice, observations with missing entriesare either dropped or imputed before learning the model. Here, we introduce thefirst algorithms for staged trees that handle missingness within the learningof the model. To this end, we characterize the likelihood of staged tree modelsin the presence of missing data and discuss pseudo-likelihoods that approximateit. A structural expectation-maximization algorithm estimating the modeldirectly from the full likelihood is also implemented and evaluated. Acomputational experiment showcases the performance of the novel learningalgorithms, demonstrating that it is feasible to account for differentmissingness patterns when learning staged trees.</description><author>Jack Storror Carter, Manuele Leonelli, Eva Riccomagno, Gherardo Varando</author><pubDate>Tue, 28 May 2024 17:00:23 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.18306v1</guid></item><item><title>Multi-modal Generation via Cross-Modal In-Context Learning</title><link>http://arxiv.org/abs/2405.18304v1</link><description>In this work, we study the problem of generating novel images from complexmultimodal prompt sequences. While existing methods achieve promising resultsfor text-to-image generation, they often struggle to capture fine-graineddetails from lengthy prompts and maintain contextual coherence within promptsequences. Moreover, they often result in misaligned image generation forprompt sequences featuring multiple objects. To address this, we propose aMulti-modal Generation via Cross-Modal In-Context Learning (MGCC) method thatgenerates novel images from complex multimodal prompt sequences by leveragingthe combined capabilities of large language models (LLMs) and diffusion models.Our MGCC comprises a novel Cross-Modal Refinement module to explicitly learncross-modal dependencies between the text and image in the LLM embedding space,and a contextual object grounding module to generate object bounding boxesspecifically targeting scenes with multiple objects. Our MGCC demonstrates adiverse range of multimodal capabilities, like novel image generation, thefacilitation of multimodal dialogue, and generation of texts. Experimentalevaluations on two benchmark datasets, demonstrate the effectiveness of ourmethod. On Visual Story Generation (VIST) dataset with multimodal inputs, ourMGCC achieves a CLIP Similarity score of $0.652$ compared to SOTA GILL $0.641$.Similarly, on Visual Dialogue Context (VisDial) having lengthy dialoguesequences, our MGCC achieves an impressive CLIP score of $0.660$, largelyoutperforming existing SOTA method scoring $0.645$. Code:https://github.com/VIROBO-15/MGCC</description><author>Amandeep Kumar, Muzammal Naseer, Sanath Narayan, Rao Muhammad Anwer, Salman Khan, Hisham Cholakkal</author><pubDate>Tue, 28 May 2024 16:58:31 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.18304v1</guid></item><item><title>Deep Network Pruning: A Comparative Study on CNNs in Face Recognition</title><link>http://arxiv.org/abs/2405.18302v1</link><description>The widespread use of mobile devices for all kind of transactions makesnecessary reliable and real-time identity authentication, leading to theadoption of face recognition (FR) via the cameras embedded in such devices.Progress of deep Convolutional Neural Networks (CNNs) has provided substantialadvances in FR. Nonetheless, the size of state-of-the-art architectures isunsuitable for mobile deployment, since they often encompass hundreds ofmegabytes and millions of parameters. We address this by studying methods fordeep network compression applied to FR. In particular, we apply network pruningbased on Taylor scores, where less important filters are removed iteratively.The method is tested on three networks based on the small SqueezeNet (1.24Mparameters) and the popular MobileNetv2 (3.5M) and ResNet50 (23.5M)architectures. These have been selected to showcase the method on CNNs withdifferent complexities and sizes. We observe that a substantial percentage offilters can be removed with minimal performance loss. Also, filters with thehighest amount of output channels tend to be removed first, suggesting thathigh-dimensional spaces within popular CNNs are over-dimensionated.</description><author>Fernando Alonso-Fernandez, Kevin Hernandez-Diaz, Jose Maria Buades Rubio, Prayag Tiwari, Josef Bigun</author><pubDate>Tue, 28 May 2024 16:57:58 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.18302v1</guid></item><item><title>Adapting Static Fairness to Sequential Decision-Making: Bias Mitigation Strategies towards Equal Long-term Benefit Rate</title><link>http://arxiv.org/abs/2309.03426v3</link><description>Decisions made by machine learning models can have lasting impacts, makinglong-term fairness a critical consideration. It has been observed that ignoringthe long-term effect and directly applying fairness criterion in staticsettings can actually worsen bias over time. To address biases in sequentialdecision-making, we introduce a long-term fairness concept named EqualLong-term Benefit Rate (ELBERT). This concept is seamlessly integrated into aMarkov Decision Process (MDP) to consider the future effects of actions onlong-term fairness, thus providing a unified framework for fair sequentialdecision-making problems. ELBERT effectively addresses the temporaldiscrimination issues found in previous long-term fairness notions.Additionally, we demonstrate that the policy gradient of Long-term Benefit Ratecan be analytically simplified to standard policy gradients. Thissimplification makes conventional policy optimization methods viable forreducing bias, leading to our bias mitigation approach ELBERT-PO. Extensiveexperiments across various diverse sequential decision-making environmentsconsistently reveal that ELBERT-PO significantly diminishes bias whilemaintaining high utility. Code is available athttps://github.com/umd-huang-lab/ELBERT.</description><author>Yuancheng Xu, Chenghao Deng, Yanchao Sun, Ruijie Zheng, Xiyao Wang, Jieyu Zhao, Furong Huang</author><pubDate>Tue, 28 May 2024 16:55:36 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2309.03426v3</guid></item><item><title>CompetEvo: Towards Morphological Evolution from Competition</title><link>http://arxiv.org/abs/2405.18300v1</link><description>Training an agent to adapt to specific tasks through co-optimization ofmorphology and control has widely attracted attention. However, whether thereexists an optimal configuration and tactics for agents in a multiagentcompetition scenario is still an issue that is challenging to definitivelyconclude. In this context, we propose competitive evolution (CompetEvo), whichco-evolves agents' designs and tactics in confrontation. We build arenasconsisting of three animals and their evolved derivatives, placing agents withdifferent morphologies in direct competition with each other. The resultsreveal that our method enables agents to evolve a more suitable design andstrategy for fighting compared to fixed-morph agents, allowing them to obtainadvantages in combat scenarios. Moreover, we demonstrate the amazing andimpressive behaviors that emerge when confrontations are conducted underasymmetrical morphs.</description><author>Kangyao Huang, Di Guo, Xinyu Zhang, Xiangyang Ji, Huaping Liu</author><pubDate>Tue, 28 May 2024 16:53:02 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.18300v1</guid></item><item><title>Weisfeiler-Leman at the margin: When more expressivity matters</title><link>http://arxiv.org/abs/2402.07568v2</link><description>The Weisfeiler-Leman algorithm ($1$-WL) is a well-studied heuristic for thegraph isomorphism problem. Recently, the algorithm has played a prominent rolein understanding the expressive power of message-passing graph neural networks(MPNNs) and being effective as a graph kernel. Despite its success, $1$-WLfaces challenges in distinguishing non-isomorphic graphs, leading to thedevelopment of more expressive MPNN and kernel architectures. However, therelationship between enhanced expressivity and improved generalizationperformance remains unclear. Here, we show that an architecture's expressivityoffers limited insights into its generalization performance when viewed throughgraph isomorphism. Moreover, we focus on augmenting $1$-WL and MPNNs withsubgraph information and employ classical margin theory to investigate theconditions under which an architecture's increased expressivity aligns withimproved generalization performance. In addition, we show that gradient flowpushes the MPNN's weights toward the maximum margin solution. Further, weintroduce variations of expressive $1$-WL-based kernel and MPNN architectureswith provable generalization properties. Our empirical study confirms thevalidity of our theoretical findings.</description><author>Billy J. Franks, Christopher Morris, Ameya Velingker, Floris Geerts</author><pubDate>Tue, 28 May 2024 16:52:02 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.07568v2</guid></item><item><title>Deep Learning Innovations for Underwater Waste Detection: An In-Depth Analysis</title><link>http://arxiv.org/abs/2405.18299v1</link><description>Addressing the issue of submerged underwater trash is crucial forsafeguarding aquatic ecosystems and preserving marine life. While identifyingdebris present on the surface of water bodies is straightforward, assessing theunderwater submerged waste is a challenge due to the image distortions causedby factors such as light refraction, absorption, suspended particles, colorshifts, and occlusion. This paper conducts a comprehensive review ofstate-of-the-art architectures and on the existing datasets to establish abaseline for submerged waste and trash detection. The primary goal remains toestablish the benchmark of the object localization techniques to be leveragedby advanced underwater sensors and autonomous underwater vehicles. The ultimateobjective is to explore the underwater environment, to identify, and removeunderwater debris. The absence of benchmarks (dataset or algorithm) in manyresearches emphasizes the need for a more robust algorithmic solution. Throughthis research, we aim to give performance comparative analysis of variousunderwater trash detection algorithms.</description><author>Jaskaran Singh Walia, Pavithra L K</author><pubDate>Tue, 28 May 2024 16:51:18 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.18299v1</guid></item><item><title>Context-Specific Refinements of Bayesian Network Classifiers</title><link>http://arxiv.org/abs/2405.18298v1</link><description>Supervised classification is one of the most ubiquitous tasks in machinelearning. Generative classifiers based on Bayesian networks are often usedbecause of their interpretability and competitive accuracy. The widely usednaive and TAN classifiers are specific instances of Bayesian networkclassifiers with a constrained underlying graph. This paper introduces novelclasses of generative classifiers extending TAN and other famous types ofBayesian network classifiers. Our approach is based on staged tree models,which extend Bayesian networks by allowing for complex, context-specificpatterns of dependence. We formally study the relationship between our novelclasses of classifiers and Bayesian networks. We introduce and implementdata-driven learning routines for our models and investigate their accuracy inan extensive computational study. The study demonstrates that models embeddingasymmetric information can enhance classification accuracy.</description><author>Manuele Leonelli, Gherardo Varando</author><pubDate>Tue, 28 May 2024 16:50:50 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.18298v1</guid></item><item><title>Bias in Motion: Theoretical Insights into the Dynamics of Bias in SGD Training</title><link>http://arxiv.org/abs/2405.18296v1</link><description>Machine learning systems often acquire biases by leveraging undesiredfeatures in the data, impacting accuracy variably across differentsub-populations. Current understanding of bias formation mostly focuses on theinitial and final stages of learning, leaving a gap in knowledge regarding thetransient dynamics. To address this gap, this paper explores the evolution ofbias in a teacher-student setup modeling different data sub-populations with aGaussian-mixture model. We provide an analytical description of the stochasticgradient descent dynamics of a linear classifier in this setting, which weprove to be exact in high dimension. Notably, our analysis reveals howdifferent properties of sub-populations influence bias at different timescales,showing a shifting preference of the classifier during training. Applying ourfindings to fairness and robustness, we delineate how and when heterogeneousdata and spurious features can generate and amplify bias. We empiricallyvalidate our results in more complex scenarios by training deeper networks onsynthetic and real datasets, including CIFAR10, MNIST, and CelebA.</description><author>Anchit Jain, Rozhin Nobahari, Aristide Baratin, Stefano Sarao Mannelli</author><pubDate>Tue, 28 May 2024 16:50:10 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.18296v1</guid></item><item><title>Intent3D: 3D Object Detection in RGB-D Scans Based on Human Intention</title><link>http://arxiv.org/abs/2405.18295v1</link><description>In real-life scenarios, humans seek out objects in the 3D world to fulfilltheir daily needs or intentions. This inspires us to introduce 3D intentiongrounding, a new task in 3D object detection employing RGB-D, based on humanintention, such as "I want something to support my back". Closely related, 3Dvisual grounding focuses on understanding human reference. To achieve detectionbased on human intention, it relies on humans to observe the scene, reason outthe target that aligns with their intention ("pillow" in this case), andfinally provide a reference to the AI system, such as "A pillow on the couch".Instead, 3D intention grounding challenges AI agents to automatically observe,reason and detect the desired target solely based on human intention. To tacklethis challenge, we introduce the new Intent3D dataset, consisting of 44,990intention texts associated with 209 fine-grained classes from 1,042 scenes ofthe ScanNet dataset. We also establish several baselines based on differentlanguage-based 3D object detection models on our benchmark. Finally, we proposeIntentNet, our unique approach, designed to tackle this intention-baseddetection problem. It focuses on three key aspects: intention understanding,reasoning to identify object candidates, and cascaded adaptive learning thatleverages the intrinsic priority logic of different losses for multipleobjective optimization.</description><author>Weitai Kang, Mengxue Qu, Jyoti Kini, Yunchao Wei, Mubarak Shah, Yan Yan</author><pubDate>Tue, 28 May 2024 16:48:39 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.18295v1</guid></item><item><title>CF-OPT: Counterfactual Explanations for Structured Prediction</title><link>http://arxiv.org/abs/2405.18293v1</link><description>Optimization layers in deep neural networks have enjoyed a growing popularityin structured learning, improving the state of the art on a variety ofapplications. Yet, these pipelines lack interpretability since they are made oftwo opaque layers: a highly non-linear prediction model, such as a deep neuralnetwork, and an optimization layer, which is typically a complex black-boxsolver. Our goal is to improve the transparency of such methods by providingcounterfactual explanations. We build upon variational autoencoders aprincipled way of obtaining counterfactuals: working in the latent space leadsto a natural notion of plausibility of explanations. We finally introduce avariant of the classic loss for VAE training that improves their performance inour specific structured context. These provide the foundations of CF-OPT, afirst-order optimization algorithm that can find counterfactual explanationsfor a broad class of structured learning architectures. Our numerical resultsshow that both close and plausible explanations can be obtained for problemsfrom the recent literature.</description><author>Germain Vivier--Ardisson, Alexandre Forel, Axel Parmentier, Thibaut Vidal</author><pubDate>Tue, 28 May 2024 16:48:27 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.18293v1</guid></item><item><title>Large Scale Knowledge Washing</title><link>http://arxiv.org/abs/2405.16720v2</link><description>Large language models show impressive abilities in memorizing worldknowledge, which leads to concerns regarding memorization of privateinformation, toxic or sensitive knowledge, and copyrighted content. Weintroduce the problem of Large Scale Knowledge Washing, focusing on unlearningan extensive amount of factual knowledge. Previous unlearning methods usuallydefine the reverse loss and update the model via backpropagation, which mayaffect the model's fluency and reasoning ability or even destroy the model dueto extensive training with the reverse loss. Existing works introduceadditional data from downstream tasks to prevent the model from losingcapabilities, which requires downstream task awareness. Controlling thetradeoff of unlearning and maintaining existing capabilities is alsochallenging. To this end, we propose LAW (Large Scale Washing) to update theMLP layers in decoder-only large language models to perform knowledge washing,as inspired by model editing methods and based on the hypothesis that knowledgeand reasoning are disentanglable. We derive a new objective with the knowledgeto be unlearned to update the weights of certain MLP layers. Experimentalresults demonstrate the effectiveness of LAW in forgetting target knowledgewhile maintaining reasoning ability. The code will be open-sourced athttps://github.com/wangyu-ustc/LargeScaleWashing.</description><author>Yu Wang, Ruihan Wu, Zexue He, Xiusi Chen, Julian McAuley</author><pubDate>Tue, 28 May 2024 16:48:12 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.16720v2</guid></item><item><title>Semantic are Beacons: A Semantic Perspective for Unveiling Parameter-Efficient Fine-Tuning in Knowledge Learning</title><link>http://arxiv.org/abs/2405.18292v1</link><description>Parameter-Efficient Fine-Tuning (PEFT) methods enable efficient adaptation ofLarge Language Models (LLMs) to various downstream applications. However, theeffectiveness of the PEFT diminishes notably when downstream tasks requireaccurate learning of factual knowledge. In this paper, we adopt a semanticperspective to investigate this phenomenon, uncovering the reasons behindPEFT's limitations in knowledge learning task. Our findings reveal that: (1)PEFT presents a notable risk of pushing the model away from the intendedknowledge target; (2) multiple knowledge interfere with each other, and suchinterference suppresses the learning and expression of knowledge features.Based on these insights, we introduce a data filtering strategy to exclude datathat is detrimental to knowledge learning and a re-weighted learning strategyto make the model attentive to semantic distance during knowledge learning.Experimental results demonstrate the effectiveness of the proposed method onopen-source large language model, further validate the semantic challenge inPEFT, thus paving the way for future research.</description><author>Renzhi Wang, Piji Li</author><pubDate>Tue, 28 May 2024 16:47:11 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.18292v1</guid></item><item><title>FedSAC: Dynamic Submodel Allocation for Collaborative Fairness in Federated Learning</title><link>http://arxiv.org/abs/2405.18291v1</link><description>Collaborative fairness stands as an essential element in federated learningto encourage client participation by equitably distributing rewards based onindividual contributions. Existing methods primarily focus on adjustinggradient allocations among clients to achieve collaborative fairness. However,they frequently overlook crucial factors such as maintaining consistency acrosslocal models and catering to the diverse requirements of high-contributingclients. This oversight inevitably decreases both fairness and model accuracyin practice. To address these issues, we propose FedSAC, a novel Federatedlearning framework with dynamic Submodel Allocation for Collaborative fairness,backed by a theoretical convergence guarantee. First, we present the concept of"bounded collaborative fairness (BCF)", which ensures fairness by tailoringrewards to individual clients based on their contributions. Second, toimplement the BCF, we design a submodel allocation module with a theoreticalguarantee of fairness. This module incentivizes high-contributing clients withhigh-performance submodels containing a diverse range of crucial neurons,thereby preserving consistency across local models. Third, we further develop adynamic aggregation module to adaptively aggregate submodels, ensuring theequitable treatment of low-frequency neurons and consequently enhancing overallmodel accuracy. Extensive experiments conducted on three public benchmarksdemonstrate that FedSAC outperforms all baseline methods in both fairness andmodel accuracy. We see this work as a significant step towards incentivizingbroader client participation in federated learning. The source code isavailable at https://github.com/wangzihuixmu/FedSAC.</description><author>Zihui Wang, Zheng Wang, Lingjuan Lyu, Zhaopeng Peng, Zhicheng Yang, Chenglu Wen, Rongshan Yu, Cheng Wang, Xiaoliang Fan</author><pubDate>Tue, 28 May 2024 16:43:29 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.18291v1</guid></item><item><title>Highway Reinforcement Learning</title><link>http://arxiv.org/abs/2405.18289v1</link><description>Learning from multi-step off-policy data collected by a set of policies is acore problem of reinforcement learning (RL). Approaches based on importancesampling (IS) often suffer from large variances due to products of IS ratios.Typical IS-free methods, such as $n$-step Q-learning, look ahead for $n$ timesteps along the trajectory of actions (where $n$ is called the lookahead depth)and utilize off-policy data directly without any additional adjustment. Theywork well for proper choices of $n$. We show, however, that such IS-freemethods underestimate the optimal value function (VF), especially for large$n$, restricting their capacity to efficiently utilize information from distantfuture time steps. To overcome this problem, we introduce a novel, IS-free,multi-step off-policy method that avoids the underestimation issue andconverges to the optimal VF. At its core lies a simple but non-trivial\emph{highway gate}, which controls the information flow from the distantfuture by comparing it to a threshold. The highway gate guarantees convergenceto the optimal VF for arbitrary $n$ and arbitrary behavioral policies. It givesrise to a novel family of off-policy RL algorithms that safely learn even when$n$ is very large, facilitating rapid credit assignment from the far future tothe past. On tasks with greatly delayed rewards, including video games wherethe reward is given only at the end of the game, our new methods outperformmany existing multi-step off-policy algorithms.</description><author>Yuhui Wang, Miroslav Strupl, Francesco Faccio, Qingyuan Wu, Haozhe Liu, Micha≈Ç Grudzie≈Ñ, Xiaoyang Tan, J√ºrgen Schmidhuber</author><pubDate>Tue, 28 May 2024 16:42:45 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.18289v1</guid></item></channel></rss>