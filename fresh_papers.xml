<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/"><channel><title>Arxivfresh papers</title><link></link><description>Arxiv paper</description><language>en-US</language><lastBuildDate>Thu, 31 Oct 2024 13:00:10 GMT</lastBuildDate><generator>rfeed v1.0.0</generator><docs>https://github.com/svpino/rfeed/blob/master/README.md</docs><item><title>Bridging the Human to Robot Dexterity Gap through Object-Oriented Rewards</title><link>http://arxiv.org/abs/2410.23289v1</link><description>Training robots directly from human videos is an emerging area in roboticsand computer vision. While there has been notable progress with two-fingeredgrippers, learning autonomous tasks for multi-fingered robot hands in this wayremains challenging. A key reason for this difficulty is that a policy trainedon human hands may not directly transfer to a robot hand due to morphologydifferences. In this work, we present HuDOR, a technique that enables onlinefine-tuning of policies by directly computing rewards from human videos.Importantly, this reward function is built using object-oriented trajectoriesderived from off-the-shelf point trackers, providing meaningful learningsignals despite the morphology gap and visual differences between human androbot hands. Given a single video of a human solving a task, such as gentlyopening a music box, HuDOR enables our four-fingered Allegro hand to learn thetask with just an hour of online interaction. Our experiments across four tasksshow that HuDOR achieves a 4x improvement over baselines. Code and videos areavailable on our website, https://object-rewards.github.io.</description><author>Irmak Guzey, Yinlong Dai, Georgy Savva, Raunaq Bhirangi, Lerrel Pinto</author><pubDate>Wed, 30 Oct 2024 17:59:41 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.23289v1</guid></item><item><title>ReferEverything: Towards Segmenting Everything We Can Speak of in Videos</title><link>http://arxiv.org/abs/2410.23287v1</link><description>We present REM, a framework for segmenting a wide range of concepts in videothat can be described through natural language. Our method capitalizes onvisual-language representations learned by video diffusion models onInternet-scale datasets. A key insight of our approach is preserving as much ofthe generative model's original representation as possible, while fine-tuningit on narrow-domain Referral Object Segmentation datasets. As a result, ourframework can accurately segment and track rare and unseen objects, despitebeing trained on object masks from a limited set of categories. Additionally,it can generalize to non-object dynamic concepts, such as waves crashing in theocean, as demonstrated in our newly introduced benchmark for Referral VideoProcess Segmentation (Ref-VPS). Our experiments show that REM performs on parwith state-of-the-art approaches on in-domain datasets, like Ref-DAVIS, whileoutperforming them by up to twelve points in terms of region similarity onout-of-domain data, leveraging the power of Internet-scale pre-training.</description><author>Anurag Bagchi, Zhipeng Bao, Yu-Xiong Wang, Pavel Tokmakov, Martial Hebert</author><pubDate>Wed, 30 Oct 2024 17:59:26 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.23287v1</guid></item><item><title>Data Contamination Can Cross Language Barriers</title><link>http://arxiv.org/abs/2406.13236v2</link><description>The opacity in developing large language models (LLMs) is raising growingconcerns about the potential contamination of public benchmarks in thepre-training data. Existing contamination detection methods are typically basedon the text overlap between training and evaluation data, which can be toosuperficial to reflect deeper forms of contamination. In this paper, we firstpresent a cross-lingual form of contamination that inflates LLMs' performancewhile evading current detection methods, deliberately injected by overfittingLLMs on the translated versions of benchmark test sets. Then, we proposegeneralization-based approaches to unmask such deeply concealed contamination.Specifically, we examine the LLM's performance change after modifying theoriginal benchmark by replacing the false answer choices with correct ones fromother questions. Contaminated models can hardly generalize to such easiersituations, where the false choices can be \emph{not even wrong}, as allchoices are correct in their memorization. Experimental results demonstratethat cross-lingual contamination can easily fool existing detection methods,but not ours. In addition, we discuss the potential utilization ofcross-lingual contamination in interpreting LLMs' working mechanisms and inpost-training LLMs for enhanced multilingual capabilities. The code and datasetwe use can be obtained from \url{https://github.com/ShangDataLab/Deep-Contam}.</description><author>Feng Yao, Yufan Zhuang, Zihao Sun, Sunan Xu, Animesh Kumar, Jingbo Shang</author><pubDate>Wed, 30 Oct 2024 17:59:08 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.13236v2</guid></item><item><title>Provable acceleration for diffusion models under minimal assumptions</title><link>http://arxiv.org/abs/2410.23285v1</link><description>While score-based diffusion models have achieved exceptional samplingquality, their sampling speeds are often limited by the high computationalburden of score function evaluations. Despite the recent remarkable empiricaladvances in speeding up the score-based samplers, theoretical understanding ofacceleration techniques remains largely limited. To bridge this gap, we proposea novel training-free acceleration scheme for stochastic samplers. Underminimal assumptions -- namely, $L^2$-accurate score estimates and a finitesecond-moment condition on the target distribution -- our accelerated samplerprovably achieves $\varepsilon$-accuracy in total variation within$\widetilde{O}(d^{5/4}/\sqrt{\varepsilon})$ iterations, thereby significantlyimproving upon the $\widetilde{O}(d/\varepsilon)$ iteration complexity ofstandard score-based samplers. Notably, our convergence theory does not rely onrestrictive assumptions on the target distribution or higher-order scoreestimation guarantees.</description><author>Gen Li, Changxiao Cai</author><pubDate>Wed, 30 Oct 2024 17:59:06 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.23285v1</guid></item><item><title>RelationBooth: Towards Relation-Aware Customized Object Generation</title><link>http://arxiv.org/abs/2410.23280v1</link><description>Customized image generation is crucial for delivering personalized contentbased on user-provided image prompts, aligning large-scale text-to-imagediffusion models with individual needs. However, existing models often overlookthe relationships between customized objects in generated images. Instead, thiswork addresses that gap by focusing on relation-aware customized imagegeneration, which aims to preserve the identities from image prompts whilemaintaining the predicate relations described in text prompts. Specifically, weintroduce RelationBooth, a framework that disentangles identity and relationlearning through a well-curated dataset. Our training data consists ofrelation-specific images, independent object images containing identityinformation, and text prompts to guide relation generation. Then, we proposetwo key modules to tackle the two main challenges: generating accurate andnatural relations, especially when significant pose adjustments are required,and avoiding object confusion in cases of overlap. First, we introduce akeypoint matching loss that effectively guides the model in adjusting objectposes closely tied to their relationships. Second, we incorporate localfeatures from the image prompts to better distinguish between objects,preventing confusion in overlapping cases. Extensive results on threebenchmarks demonstrate the superiority of RelationBooth in generating preciserelations while preserving object identities across a diverse set of objectsand relations. The source code and trained models will be made available to thepublic.</description><author>Qingyu Shi, Lu Qi, Jianzong Wu, Jinbin Bai, Jingbo Wang, Yunhai Tong, Xiangtai Li, Ming-Husang Yang</author><pubDate>Wed, 30 Oct 2024 17:57:21 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.23280v1</guid></item><item><title>A Neural Transformer Framework for Simultaneous Tasks of Segmentation, Classification, and Caller Identification of Marmoset Vocalization</title><link>http://arxiv.org/abs/2410.23279v1</link><description>Marmoset, a highly vocalized primate, has become a popular animal model forstudying social-communicative behavior and its underlying mechanism. In thestudy of vocal communication, it is vital to know the caller identities, callcontents, and vocal exchanges. Previous work of a CNN has achieved a jointmodel for call segmentation, classification, and caller identification formarmoset vocalizations. However, the CNN has limitations in modeling long-rangeacoustic patterns; the Transformer architecture that has been shown tooutperform CNNs, utilizes the self-attention mechanism that efficientlysegregates information parallelly over long distances and captures the globalstructure of marmoset vocalization. We propose using the Transformer to jointlysegment and classify the marmoset calls and identify the callers for eachvocalization.</description><author>Bin Wu, Sakriani Sakti, Shinnosuke Takamichi, Satoshi Nakamura</author><pubDate>Wed, 30 Oct 2024 17:57:13 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.23279v1</guid></item><item><title>Guiding Through Complexity: What Makes Good Supervision for Hard Reasoning Tasks?</title><link>http://arxiv.org/abs/2410.20533v2</link><description>How can "weak teacher models" such as average human annotators or existing AIsystems, effectively supervise LLMs to improve performance on hard reasoningtasks, especially those that challenge and requires expertise or daily practicefrom the teacher models? In this paper, we seek for empirical answers to thisquestion by investigating various data-driven strategies that offer supervisiondata at different quality levels upon tasks of varying complexity. Twointuitive strategies emerge for teacher models to provide supervision duringalignment training: 1) using lower-quality supervision from complete tasks thatmatch the difficulty of the target reasoning tasks, and 2) leveraginghigher-quality supervision from easier subtasks that are less challenging.Interestingly, we find that even when the outcome error rate for hard tasksupervision is high (e.g., 90\%), training on such data can outperformperfectly correct supervision on easier subtasks on multiple hard mathbenchmarks. We further identify a more critical factor influencing trainingperformance: step-wise error rates, which indicate the severity of errors insolutions. Specifically, training on hard task supervision with the sameoutcome error rates but disparate step-wise error rates can lead to a 30\%accuracy gap on MATH benchmark. Our results also reveal that supplementing hardtask supervision with the corresponding subtask supervision can yield notableperformance improvements than simply combining rephrased hard full tasksupervision, suggesting new avenues for data augmentation. Data and code arereleased at \url{https://github.com/hexuan21/Weak-to-Strong}.</description><author>Xuan He, Da Yin, Nanyun Peng</author><pubDate>Wed, 30 Oct 2024 17:56:22 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.20533v2</guid></item><item><title>OpenSatMap: A Fine-grained High-resolution Satellite Dataset for Large-scale Map Construction</title><link>http://arxiv.org/abs/2410.23278v1</link><description>In this paper, we propose OpenSatMap, a fine-grained, high-resolutionsatellite dataset for large-scale map construction. Map construction is one ofthe foundations of the transportation industry, such as navigation andautonomous driving. Extracting road structures from satellite images is anefficient way to construct large-scale maps. However, existing satellitedatasets provide only coarse semantic-level labels with a relatively lowresolution (up to level 19), impeding the advancement of this field. Incontrast, the proposed OpenSatMap (1) has fine-grained instance-levelannotations; (2) consists of high-resolution images (level 20); (3) iscurrently the largest one of its kind; (4) collects data with high diversity.Moreover, OpenSatMap covers and aligns with the popular nuScenes dataset andArgoverse 2 dataset to potentially advance autonomous driving technologies. Bypublishing and maintaining the dataset, we provide a high-quality benchmark forsatellite-based map construction and downstream tasks like autonomous driving.</description><author>Hongbo Zhao, Lue Fan, Yuntao Chen, Haochen Wang, yuran Yang, Xiaojuan Jin, Yixin Zhang, Gaofeng Meng, Zhaoxiang Zhang</author><pubDate>Wed, 30 Oct 2024 17:56:02 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.23278v1</guid></item><item><title>SlowFast-VGen: Slow-Fast Learning for Action-Driven Long Video Generation</title><link>http://arxiv.org/abs/2410.23277v1</link><description>Human beings are endowed with a complementary learning system, which bridgesthe slow learning of general world dynamics with fast storage of episodicmemory from a new experience. Previous video generation models, however,primarily focus on slow learning by pre-training on vast amounts of data,overlooking the fast learning phase crucial for episodic memory storage. Thisoversight leads to inconsistencies across temporally distant frames whengenerating longer videos, as these frames fall beyond the model's contextwindow. To this end, we introduce SlowFast-VGen, a novel dual-speed learningsystem for action-driven long video generation. Our approach incorporates amasked conditional video diffusion model for the slow learning of worlddynamics, alongside an inference-time fast learning strategy based on atemporal LoRA module. Specifically, the fast learning process updates itstemporal LoRA parameters based on local inputs and outputs, thereby efficientlystoring episodic memory in its parameters. We further propose a slow-fastlearning loop algorithm that seamlessly integrates the inner fast learning loopinto the outer slow learning loop, enabling the recall of prior multi-episodeexperiences for context-aware skill learning. To facilitate the slow learningof an approximate world model, we collect a large-scale dataset of 200k videoswith language action annotations, covering a wide range of scenarios. Extensiveexperiments show that SlowFast-VGen outperforms baselines across variousmetrics for action-driven video generation, achieving an FVD score of 514compared to 782, and maintaining consistency in longer videos, with an averageof 0.37 scene cuts versus 0.89. The slow-fast learning loop algorithmsignificantly enhances performances on long-horizon planning tasks as well.Project Website: https://slowfast-vgen.github.io</description><author>Yining Hong, Beide Liu, Maxine Wu, Yuanhao Zhai, Kai-Wei Chang, Lingjie Li, Kevin Lin, Chung-Ching Lin, Jianfeng Wang, Zhengyuan Yang, Yingnian Wu, Lijuan Wang</author><pubDate>Wed, 30 Oct 2024 17:55:52 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.23277v1</guid></item><item><title>Emergent mechanisms for long timescales depend on training curriculum and affect performance in memory tasks</title><link>http://arxiv.org/abs/2309.12927v3</link><description>Recurrent neural networks (RNNs) in the brain and in silico excel at solvingtasks with intricate temporal dependencies. Long timescales required forsolving such tasks can arise from properties of individual neurons(single-neuron timescale, $\tau$, e.g., membrane time constant in biologicalneurons) or recurrent interactions among them (network-mediated timescale).However, the contribution of each mechanism for optimally solvingmemory-dependent tasks remains poorly understood. Here, we train RNNs to solve$N$-parity and $N$-delayed match-to-sample tasks with increasing memoryrequirements controlled by $N$ by simultaneously optimizing recurrent weightsand $\tau$s. We find that for both tasks RNNs develop longer timescales withincreasing $N$, but depending on the learning objective, they use differentmechanisms. Two distinct curricula define learning objectives: sequentiallearning of a single-$N$ (single-head) or simultaneous learning of multiple$N$s (multi-head). Single-head networks increase their $\tau$ with $N$ and areable to solve tasks for large $N$, but they suffer from catastrophicforgetting. However, multi-head networks, which are explicitly required to holdmultiple concurrent memories, keep $\tau$ constant and develop longertimescales through recurrent connectivity. Moreover, we show that themulti-head curriculum increases training speed and network stability toablations and perturbations, and allows RNNs to generalize better to tasksbeyond their training regime. This curriculum also significantly improvestraining GRUs and LSTMs for large-$N$ tasks. Our results suggest that adaptingtimescales to task requirements via recurrent interactions allows learning morecomplex objectives and improves the RNN's performance.</description><author>Sina Khajehabdollahi, Roxana Zeraati, Emmanouil Giannakakis, Tim Jakob Schäfer, Georg Martius, Anna Levina</author><pubDate>Wed, 30 Oct 2024 17:55:47 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2309.12927v3</guid></item><item><title>Lorentz-Equivariant Geometric Algebra Transformers for High-Energy Physics</title><link>http://arxiv.org/abs/2405.14806v3</link><description>Extracting scientific understanding from particle-physics experimentsrequires solving diverse learning problems with high precision and good dataefficiency. We propose the Lorentz Geometric Algebra Transformer (L-GATr), anew multi-purpose architecture for high-energy physics. L-GATr representshigh-energy data in a geometric algebra over four-dimensional space-time and isequivariant under Lorentz transformations, the symmetry group of relativistickinematics. At the same time, the architecture is a Transformer, which makes itversatile and scalable to large systems. L-GATr is first demonstrated onregression and classification tasks from particle physics. We then constructthe first Lorentz-equivariant generative model: a continuous normalizing flowbased on an L-GATr network, trained with Riemannian flow matching. Across ourexperiments, L-GATr is on par with or outperforms strong domain-specificbaselines.</description><author>Jonas Spinner, Victor Bresó, Pim de Haan, Tilman Plehn, Jesse Thaler, Johann Brehmer</author><pubDate>Wed, 30 Oct 2024 15:50:21 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.14806v3</guid></item><item><title>Human Expertise in Algorithmic Prediction</title><link>http://arxiv.org/abs/2402.00793v3</link><description>We introduce a novel framework for incorporating human expertise intoalgorithmic predictions. Our approach leverages human judgment to distinguishinputs which are algorithmically indistinguishable, or "look the same" topredictive algorithms. We argue that this framing clarifies the problem ofhuman-AI collaboration in prediction tasks, as experts often form judgments bydrawing on information which is not encoded in an algorithm's training data.Algorithmic indistinguishability yields a natural test for assessing whetherexperts incorporate this kind of "side information", and further provides asimple but principled method for selectively incorporating human feedback intoalgorithmic predictions. We show that this method provably improves theperformance of any feasible algorithmic predictor and precisely quantify thisimprovement. We find empirically that although algorithms often outperformtheir human counterparts on average, human judgment can improve algorithmicpredictions on specific instances (which can be identified ex-ante). In anX-ray classification task, we find that this subset constitutes nearly $30\%$of the patient population. Our approach provides a natural way of uncoveringthis heterogeneity and thus enabling effective human-AI collaboration.</description><author>Rohan Alur, Manish Raghavan, Devavrat Shah</author><pubDate>Wed, 30 Oct 2024 15:45:32 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.00793v3</guid></item><item><title>Crowdsourcing Lexical Diversity</title><link>http://arxiv.org/abs/2410.23133v1</link><description>Lexical-semantic resources (LSRs), such as online lexicons or wordnets, arefundamental for natural language processing applications. In many languages,however, such resources suffer from quality issues: incorrect entries,incompleteness, but also, the rarely addressed issue of bias towards theEnglish language and Anglo-Saxon culture. Such bias manifests itself in theabsence of concepts specific to the language or culture at hand, the presenceof foreign (Anglo-Saxon) concepts, as well as in the lack of an explicitindication of untranslatability, also known as cross-lingual \emph{lexicalgaps}, when a term has no equivalent in another language. This paper proposes anovel crowdsourcing methodology for reducing bias in LSRs. Crowd workerscompare lexemes from two languages, focusing on domains rich in lexicaldiversity, such as kinship or food. Our LingoGap crowdsourcing tool facilitatescomparisons through microtasks identifying equivalent terms, language-specificterms, and lexical gaps across languages. We validated our method by applyingit to two case studies focused on food-related terminology: (1) English andArabic, and (2) Standard Indonesian and Banjarese. These experiments identified2,140 lexical gaps in the first case study and 951 in the second. The successof these experiments confirmed the usability of our method and tool for futurelarge-scale lexicon enrichment tasks.</description><author>Hadi Khalilia, Jahna Otterbacher, Gabor Bella, Rusma Noortyani, Shandy Darma, Fausto Giunchiglia</author><pubDate>Wed, 30 Oct 2024 15:45:09 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.23133v1</guid></item><item><title>Revisiting MAE pre-training for 3D medical image segmentation</title><link>http://arxiv.org/abs/2410.23132v1</link><description>Self-Supervised Learning (SSL) presents an exciting opportunity to unlock thepotential of vast, untapped clinical datasets, for various downstreamapplications that suffer from the scarcity of labeled data. While SSL hasrevolutionized fields like natural language processing and computer vision,their adoption in 3D medical image computing has been limited by three keypitfalls: Small pre-training dataset sizes, architectures inadequate for 3Dmedical image analysis, and insufficient evaluation practices. We address theseissues by i) leveraging a large-scale dataset of 44k 3D brain MRI volumes andii) using a Residual Encoder U-Net architecture within the state-of-the-artnnU-Net framework. iii) A robust development framework, incorporating 5development and 8 testing brain MRI segmentation datasets, allowedperformance-driven design decisions to optimize the simple concept of MaskedAuto Encoders (MAEs) for 3D CNNs. The resulting model not only surpassesprevious SSL methods but also outperforms the strong nnU-Net baseline by anaverage of approximately 3 Dice points. Furthermore, our model demonstratesexceptional stability, achieving the highest average rank of 2 out of 7methods, compared to the second-best method's mean rank of 3.</description><author>Tassilo Wald, Constantin Ulrich, Stanislav Lukyanenko, Andrei Goncharov, Alberto Paderno, Leander Maerkisch, Paul F. Jäger, Klaus Maier-Hein</author><pubDate>Wed, 30 Oct 2024 15:42:59 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.23132v1</guid></item><item><title>Recent Trends of Multimodal Affective Computing: A Survey from NLP Perspective</title><link>http://arxiv.org/abs/2409.07388v2</link><description>Multimodal affective computing (MAC) has garnered increasing attention due toits broad applications in analyzing human behaviors and intentions, especiallyin text-dominated multimodal affective computing field. This survey presentsthe recent trends of multimodal affective computing from NLP perspectivethrough four hot tasks: multimodal sentiment analysis, multimodal emotionrecognition in conversation, multimodal aspect-based sentiment analysis andmultimodal multi-label emotion recognition. The goal of this survey is toexplore the current landscape of multimodal affective research, identifydevelopment trends, and highlight the similarities and differences acrossvarious tasks, offering a comprehensive report on the recent progress inmultimodal affective computing from an NLP perspective. This survey covers theformalization of tasks, provides an overview of relevant works, describesbenchmark datasets, and details the evaluation metrics for each task.Additionally, it briefly discusses research in multimodal affective computinginvolving facial expressions, acoustic signals, physiological signals, andemotion causes. Additionally, we discuss the technical approaches, challenges,and future directions in multimodal affective computing. To support furtherresearch, we released a repository that compiles related works in multimodalaffective computing, providing detailed resources and references for thecommunity.</description><author>Guimin Hu, Yi Xin, Weimin Lyu, Haojian Huang, Chang Sun, Zhihong Zhu, Lin Gui, Ruichu Cai, Erik Cambria, Hasti Seifi</author><pubDate>Wed, 30 Oct 2024 15:42:55 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2409.07388v2</guid></item><item><title>Quantum Boltzmann machine learning of ground-state energies</title><link>http://arxiv.org/abs/2410.12935v2</link><description>Estimating the ground-state energy of Hamiltonians is a fundamental task forwhich it is believed that quantum computers can be helpful. Several approacheshave been proposed toward this goal, including algorithms based on quantumphase estimation and hybrid quantum-classical optimizers involvingparameterized quantum circuits, the latter falling under the umbrella of thevariational quantum eigensolver. Here, we analyze the performance of quantumBoltzmann machines for this task, which is a less explored ansatz based onparameterized thermal states and which is not known to suffer from thebarren-plateau problem. We delineate a hybrid quantum-classical algorithm forthis task and rigorously prove that it converges to an$\varepsilon$-approximate stationary point of the energy function optimizedover parameter space, while using a number of parameterized-thermal-statesamples that is polynomial in $\varepsilon^{-1}$, the number of parameters, andthe norm of the Hamiltonian being optimized. Our algorithm estimates thegradient of the energy function efficiently by means of a novel quantum circuitconstruction that combines classical sampling, Hamiltonian simulation, and theHadamard test, thus overcoming a key obstacle to quantum Boltzmann machinelearning that has been left open since [Amin et al., Phys. Rev. X 8, 021050(2018)]. Additionally supporting our main claims are calculations of thegradient and Hessian of the energy function, as well as an upper bound on thematrix elements of the latter that is used in the convergence analysis.</description><author>Dhrumil Patel, Daniel Koch, Saahil Patel, Mark M. Wilde</author><pubDate>Wed, 30 Oct 2024 15:42:01 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.12935v2</guid></item><item><title>Federated Learning under Periodic Client Participation and Heterogeneous Data: A New Communication-Efficient Algorithm and Analysis</title><link>http://arxiv.org/abs/2410.23131v1</link><description>In federated learning, it is common to assume that clients are alwaysavailable to participate in training, which may not be feasible with userdevices in practice. Recent works analyze federated learning under morerealistic participation patterns, such as cyclic client availability orarbitrary participation. However, all such works either require strongassumptions (e.g., all clients participate almost surely within a boundedwindow), do not achieve linear speedup and reduced communication rounds, or arenot applicable in the general non-convex setting. In this work, we focus onnonconvex optimization and consider participation patterns in which the chanceof participation over a fixed window of rounds is equal among all clients,which includes cyclic client availability as a special case. Under thissetting, we propose a new algorithm, named Amplified SCAFFOLD, and prove thatit achieves linear speedup, reduced communication, and resilience to dataheterogeneity simultaneously. In particular, for cyclic participation, ouralgorithm is proved to enjoy $\mathcal{O}(\epsilon^{-2})$ communication roundsto find an $\epsilon$-stationary point in the non-convex stochastic setting. Incontrast, the prior work under the same setting requires $\mathcal{O}(\kappa^2\epsilon^{-4})$ communication rounds, where $\kappa$ denotes the dataheterogeneity. Therefore, our algorithm significantly reduces communicationrounds due to better dependency in terms of $\epsilon$ and $\kappa$. Ouranalysis relies on a fine-grained treatment of the nested dependence betweenclient participation and errors in the control variates, which results intighter guarantees than previous work. We also provide experimental resultswith (1) synthetic data and (2) real-world data with a large number of clients$(N = 250)$, demonstrating the effectiveness of our algorithm under periodicclient participation.</description><author>Michael Crawshaw, Mingrui Liu</author><pubDate>Wed, 30 Oct 2024 15:41:35 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.23131v1</guid></item><item><title>Compositional Segmentation of Cardiac Images Leveraging Metadata</title><link>http://arxiv.org/abs/2410.23130v1</link><description>Cardiac image segmentation is essential for automated cardiac functionassessment and monitoring of changes in cardiac structures over time. Inspiredby coarse-to-fine approaches in image analysis, we propose a novel multitaskcompositional segmentation approach that can simultaneously localize the heartin a cardiac image and perform part-based segmentation of different regions ofinterest. We demonstrate that this compositional approach achieves betterresults than direct segmentation of the anatomies. Further, we propose a novelCross-Modal Feature Integration (CMFI) module to leverage the metadata relatedto cardiac imaging collected during image acquisition. We perform experimentson two different modalities, MRI and ultrasound, using public datasets,Multi-disease, Multi-View, and Multi-Centre (M&amp;Ms-2) and Multi-structureUltrasound Segmentation (CAMUS) data, to showcase the efficiency of theproposed compositional segmentation method and Cross-Modal Feature Integrationmodule incorporating metadata within the proposed compositional segmentationnetwork. The source code is available:https://github.com/kabbas570/CompSeg-MetaData.</description><author>Abbas Khan, Muhammad Asad, Martin Benning, Caroline Roney, Gregory Slabaugh</author><pubDate>Wed, 30 Oct 2024 15:41:35 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.23130v1</guid></item><item><title>Why Fine-grained Labels in Pretraining Benefit Generalization?</title><link>http://arxiv.org/abs/2410.23129v1</link><description>Recent studies show that pretraining a deep neural network with fine-grainedlabeled data, followed by fine-tuning on coarse-labeled data for downstreamtasks, often yields better generalization than pretraining with coarse-labeleddata. While there is ample empirical evidence supporting this, the theoreticaljustification remains an open problem. This paper addresses this gap byintroducing a "hierarchical multi-view" structure to confine the input datadistribution. Under this framework, we prove that: 1) coarse-grainedpretraining only allows a neural network to learn the common features well,while 2) fine-grained pretraining helps the network learn the rare features inaddition to the common ones, leading to improved accuracy on hard downstreamtest samples.</description><author>Guan Zhe Hong, Yin Cui, Ariel Fuxman, Stanely Chan, Enming Luo</author><pubDate>Wed, 30 Oct 2024 15:41:30 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.23129v1</guid></item><item><title>Reassessing Noise Augmentation Methods in the Context of Adversarial Speech</title><link>http://arxiv.org/abs/2409.01813v2</link><description>In this study, we investigate if noise-augmented training can concurrentlyimprove adversarial robustness in automatic speech recognition (ASR) systems.We conduct a comparative analysis of the adversarial robustness of fourdifferent state-of-the-art ASR architectures, where each of the ASRarchitectures is trained under three different augmentation conditions: onesubject to background noise, speed variations, and reverberations, anothersubject to speed variations only, and a third without any form of dataaugmentation. The results demonstrate that noise augmentation not only improvesmodel performance on noisy speech but also the model's robustness toadversarial attacks.</description><author>Karla Pizzi, Matías Pizarro, Asja Fischer</author><pubDate>Wed, 30 Oct 2024 15:40:38 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2409.01813v2</guid></item><item><title>DenoiseRep: Denoising Model for Representation Learning</title><link>http://arxiv.org/abs/2406.08773v2</link><description>The denoising model has been proven a powerful generative model but haslittle exploration of discriminative tasks. Representation learning isimportant in discriminative tasks, which is defined as "learningrepresentations (or features) of the data that make it easier to extract usefulinformation when building classifiers or other predictors". In this paper, wepropose a novel Denoising Model for Representation Learning (DenoiseRep) toimprove feature discrimination with joint feature extraction and denoising.DenoiseRep views each embedding layer in a backbone as a denoising layer,processing the cascaded embedding layers as if we are recursively denoisefeatures step-by-step. This unifies the frameworks of feature extraction anddenoising, where the former progressively embeds features from low-level tohigh-level, and the latter recursively denoises features step-by-step. Afterthat, DenoiseRep fuses the parameters of feature extraction and denoisinglayers, and theoretically demonstrates its equivalence before and after thefusion, thus making feature denoising computation-free. DenoiseRep is alabel-free algorithm that incrementally improves features but alsocomplementary to the label if available. Experimental results on variousdiscriminative vision tasks, including re-identification (Market-1501,DukeMTMC-reID, MSMT17, CUHK-03, vehicleID), image classification (ImageNet,UB200, Oxford-Pet, Flowers), object detection (COCO), image segmentation(ADE20K) show stability and impressive improvements. We also validate itseffectiveness on the CNN (ResNet) and Transformer (ViT, Swin, Vmamda)architectures.</description><author>Zhengrui Xu, Guan'an Wang, Xiaowen Huang, Jitao Sang</author><pubDate>Wed, 30 Oct 2024 15:40:28 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.08773v2</guid></item><item><title>Copycats: the many lives of a publicly available medical imaging dataset</title><link>http://arxiv.org/abs/2402.06353v3</link><description>Medical Imaging (MI) datasets are fundamental to artificial intelligence inhealthcare. The accuracy, robustness, and fairness of diagnostic algorithmsdepend on the data (and its quality) used to train and evaluate the models. MIdatasets used to be proprietary, but have become increasingly available to thepublic, including on community-contributed platforms (CCPs) like Kaggle orHuggingFace. While open data is important to enhance the redistribution ofdata's public value, we find that the current CCP governance model fails touphold the quality needed and recommended practices for sharing, documenting,and evaluating datasets. In this paper, we conduct an analysis of publiclyavailable machine learning datasets on CCPs, discussing datasets' context, andidentifying limitations and gaps in the current CCP landscape. We highlightdifferences between MI and computer vision datasets, particularly in thepotentially harmful downstream effects from poor adoption of recommendeddataset management practices. We compare the analyzed datasets across severaldimensions, including data sharing, data documentation, and maintenance. Wefind vague licenses, lack of persistent identifiers and storage, duplicates,and missing metadata, with differences between the platforms. Our researchcontributes to efforts in responsible data curation and AI algorithms forhealthcare.</description><author>Amelia Jiménez-Sánchez, Natalia-Rozalia Avlona, Dovile Juodelyte, Théo Sourget, Caroline Vang-Larsen, Anna Rogers, Hubert Dariusz Zając, Veronika Cheplygina</author><pubDate>Wed, 30 Oct 2024 15:40:11 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.06353v3</guid></item><item><title>Provably Optimal Memory Capacity for Modern Hopfield Models: Transformer-Compatible Dense Associative Memories as Spherical Codes</title><link>http://arxiv.org/abs/2410.23126v1</link><description>We study the optimal memorization capacity of modern Hopfield models andKernelized Hopfield Models (KHMs), a transformer-compatible class of DenseAssociative Memories. We present a tight analysis by establishing a connectionbetween the memory configuration of KHMs and spherical codes from informationtheory. Specifically, we treat the stored memory set as a specialized sphericalcode. This enables us to cast the memorization problem in KHMs into a pointarrangement problem on a hypersphere. We show that the optimal capacity of KHMsoccurs when the feature space allows memories to form an optimal sphericalcode. This unique perspective leads to: (i) An analysis of how KHMs achieveoptimal memory capacity, and identify corresponding necessary conditions.Importantly, we establish an upper capacity bound that matches the well-knownexponential lower bound in the literature. This provides the first tight andoptimal asymptotic memory capacity for modern Hopfield models. (ii) Asub-linear time algorithm $\mathtt{U}\text{-}\mathtt{Hop}$+ to reach KHMs'optimal capacity. (iii) An analysis of the scaling behavior of the requiredfeature dimension relative to the number of stored memories. These effortsimprove both the retrieval capability of KHMs and the representation learningof corresponding transformers. Experimentally, we provide thorough numericalresults to back up theoretical findings.</description><author>Jerry Yao-Chieh Hu, Dennis Wu, Han Liu</author><pubDate>Wed, 30 Oct 2024 15:35:51 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.23126v1</guid></item><item><title>Robustness of data-driven approaches in limited angle tomography</title><link>http://arxiv.org/abs/2403.11350v2</link><description>The limited angle Radon transform is notoriously difficult to invert due toits ill-posedness. In this work, we give a mathematical explanation thatdata-driven approaches can stably reconstruct more information compared totraditional methods like filtered backprojection. In addition, we useexperiments based on the U-Net neural network to validate our theory.</description><author>Yiran Wang, Yimin Zhong</author><pubDate>Wed, 30 Oct 2024 15:34:53 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.11350v2</guid></item><item><title>Optimal deep learning of holomorphic operators between Banach spaces</title><link>http://arxiv.org/abs/2406.13928v2</link><description>Operator learning problems arise in many key areas of scientific computingwhere Partial Differential Equations (PDEs) are used to model physical systems.In such scenarios, the operators map between Banach or Hilbert spaces. In thiswork, we tackle the problem of learning operators between Banach spaces, incontrast to the vast majority of past works considering only Hilbert spaces. Wefocus on learning holomorphic operators - an important class of problems withmany applications. We combine arbitrary approximate encoders and decoders withstandard feedforward Deep Neural Network (DNN) architectures - specifically,those with constant width exceeding the depth - under standard $\ell^2$-lossminimization. We first identify a family of DNNs such that the resulting DeepLearning (DL) procedure achieves optimal generalization bounds for suchoperators. For standard fully-connected architectures, we then show that thereare uncountably many minimizers of the training problem that yield equivalentoptimal performance. The DNN architectures we consider are `problem agnostic',with width and depth only depending on the amount of training data $m$ and noton regularity assumptions of the target operator. Next, we show that DL isoptimal for this problem: no recovery procedure can surpass thesegeneralization bounds up to log terms. Finally, we present numerical resultsdemonstrating the practical performance on challenging problems including theparametric diffusion, Navier-Stokes-Brinkman and Boussinesq PDEs.</description><author>Ben Adcock, Nick Dexter, Sebastian Moraga</author><pubDate>Wed, 30 Oct 2024 15:34:22 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.13928v2</guid></item><item><title>On Memorization of Large Language Models in Logical Reasoning</title><link>http://arxiv.org/abs/2410.23123v1</link><description>Large language models (LLMs) achieve good performance on challengingreasoning benchmarks, yet could also make basic reasoning mistakes. Thiscontrasting behavior is puzzling when it comes to understanding the mechanismsbehind LLMs' reasoning capabilities. One hypothesis is that the increasinglyhigh and nearly saturated performance on common reasoning benchmarks could bedue to the memorization of similar problems. In this paper, we systematicallyinvestigate this hypothesis with a quantitative measurement of memorization inreasoning tasks, using a dynamically generated logical reasoning benchmarkbased on Knights and Knaves (K&amp;K) puzzles. We found that LLMs could interpolatethe training puzzles (achieving near-perfect accuracy) after fine-tuning, yetfail when those puzzles are slightly perturbed, suggesting that the modelsheavily rely on memorization to solve those training puzzles. On the otherhand, we show that while fine-tuning leads to heavy memorization, it alsoconsistently improves generalization performance. In-depth analyses withperturbation tests, cross difficulty-level transferability, probing modelinternals, and fine-tuning with wrong answers suggest that the LLMs learn toreason on K&amp;K puzzles despite training data memorization. This phenomenonindicates that LLMs exhibit a complex interplay between memorization andgenuine reasoning abilities. Finally, our analysis with per-sample memorizationscore sheds light on how LLMs switch between reasoning and memorization insolving logical puzzles. Our code and data are available athttps://memkklogic.github.io.</description><author>Chulin Xie, Yangsibo Huang, Chiyuan Zhang, Da Yu, Xinyun Chen, Bill Yuchen Lin, Bo Li, Badih Ghazi, Ravi Kumar</author><pubDate>Wed, 30 Oct 2024 15:31:54 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.23123v1</guid></item><item><title>Gaussian process-based online health monitoring and fault analysis of lithium-ion battery systems from field data</title><link>http://arxiv.org/abs/2406.19015v3</link><description>Health monitoring, fault analysis, and detection are critical for the safeand sustainable operation of battery systems. We apply Gaussian processresistance models on lithium iron phosphate battery field data to effectivelyseparate the time-dependent and operating point-dependent resistance. The dataset contains 29 battery systems returned to the manufacturer for warranty, eachwith eight cells in series, totaling 232 cells and 131 million data rows. Wedevelop probabilistic fault detection rules using recursive spatiotemporalGaussian processes. These processes allow the quick processing of over amillion data points, enabling advanced online monitoring and furthering theunderstanding of battery pack failure in the field. The analysis underlinesthat often, only a single cell shows abnormal behavior or a knee point,consistent with weakest-link failure for cells connected in series, amplifiedby local resistive heating. The results further the understanding of howbatteries degrade and fail in the field and demonstrate the potential ofefficient online monitoring based on data. We open-source the code and publishthe large data set upon completion of the review of this article.</description><author>Joachim Schaeffer, Eric Lenz, Duncan Gulla, Martin Z. Bazant, Richard D. Braatz, Rolf Findeisen</author><pubDate>Wed, 30 Oct 2024 15:28:05 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.19015v3</guid></item><item><title>Dynamic Vocabulary Pruning in Early-Exit LLMs</title><link>http://arxiv.org/abs/2410.18952v2</link><description>Increasing the size of large language models (LLMs) has been shown to lead tobetter performance. However, this comes at the cost of slower and moreexpensive inference. Early-exiting is a promising approach for improving theefficiency of LLM inference by enabling next token prediction at intermediatelayers. Yet, the large vocabulary size in modern LLMs makes the confidenceestimation required for exit decisions computationally expensive, diminishingthe efficiency gains. To address this, we propose dynamically pruning thevocabulary at test time for each token. Specifically, the vocabulary is prunedat one of the initial layers, and the smaller vocabulary is then usedthroughout the rest of the forward pass. Our experiments demonstrate that suchpost-hoc dynamic vocabulary pruning improves the efficiency of confidenceestimation in early-exit LLMs while maintaining competitive performance.</description><author>Jort Vincenti, Karim Abdel Sadek, Joan Velja, Matteo Nulli, Metod Jazbec</author><pubDate>Wed, 30 Oct 2024 15:28:02 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.18952v2</guid></item><item><title>Teaching a Language Model to Distinguish Between Similar Details using a Small Adversarial Training Set</title><link>http://arxiv.org/abs/2410.23118v1</link><description>Language models can achieve high accuracy on natural language tasks such asNLI, but performance suffers on manually created adversarial examples. Weinvestigate the performance of a language model trained on the Stanford NaturalLanguage Inference (SNLI) corpus on a manually created adversarial test set. Wethen improve the model's performance by fine tuning the model on a small,manually created adversarial training set, designed to help the language modelto learn to differentiate between similar words and phrases in the data. Weshow an increase in accuracy on the adversarial test set (+ 13%) while stillmaintaining good performance on the original NLI task. We also show an increasein accuracy from 91.2% to 92.9% on the most similar contradictions in the SNLItest set (as judged by cosine similarity).</description><author>Chris Achard</author><pubDate>Wed, 30 Oct 2024 15:27:55 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.23118v1</guid></item><item><title>DistriBlock: Identifying adversarial audio samples by leveraging characteristics of the output distribution</title><link>http://arxiv.org/abs/2305.17000v7</link><description>Adversarial attacks can mislead automatic speech recognition (ASR) systemsinto predicting an arbitrary target text, thus posing a clear security threat.To prevent such attacks, we propose DistriBlock, an efficient detectionstrategy applicable to any ASR system that predicts a probability distributionover output tokens in each time step. We measure a set of characteristics ofthis distribution: the median, maximum, and minimum over the outputprobabilities, the entropy of the distribution, as well as the Kullback-Leiblerand the Jensen-Shannon divergence with respect to the distributions of thesubsequent time step. Then, by leveraging the characteristics observed for bothbenign and adversarial data, we apply binary classifiers, including simplethreshold-based classification, ensembles of such classifiers, and neuralnetworks. Through extensive analysis across different state-of-the-art ASRsystems and language data sets, we demonstrate the supreme performance of thisapproach, with a mean area under the receiver operating characteristic curvefor distinguishing target adversarial examples against clean and noisy data of99% and 97%, respectively. To assess the robustness of our method, we show thatadaptive adversarial examples that can circumvent DistriBlock are much noisier,which makes them easier to detect through filtering and creates another avenuefor preserving the system's robustness.</description><author>Matías Pizarro, Dorothea Kolossa, Asja Fischer</author><pubDate>Wed, 30 Oct 2024 15:25:54 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.17000v7</guid></item><item><title>Continuous Product Graph Neural Networks</title><link>http://arxiv.org/abs/2405.18877v2</link><description>Processing multidomain data defined on multiple graphs holds significantpotential in various practical applications in computer science. However,current methods are mostly limited to discrete graph filtering operations.Tensorial partial differential equations on graphs (TPDEGs) provide aprincipled framework for modeling structured data across multiple interactinggraphs, addressing the limitations of the existing discrete methodologies. Inthis paper, we introduce Continuous Product Graph Neural Networks (CITRUS) thatemerge as a natural solution to the TPDEG. CITRUS leverages the separability ofcontinuous heat kernels from Cartesian graph products to efficiently implementgraph spectral decomposition. We conduct thorough theoretical analyses of thestability and over-smoothing properties of CITRUS in response todomain-specific graph perturbations and graph spectra effects on theperformance. We evaluate CITRUS on well-known traffic and weatherspatiotemporal forecasting datasets, demonstrating superior performance overexisting approaches. The implementation codes are available athttps://github.com/ArefEinizade2/CITRUS.</description><author>Aref Einizade, Fragkiskos D. Malliaros, Jhony H. Giraldo</author><pubDate>Wed, 30 Oct 2024 15:25:38 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.18877v2</guid></item><item><title>Unified Triplet-Level Hallucination Evaluation for Large Vision-Language Models</title><link>http://arxiv.org/abs/2410.23114v1</link><description>Despite the outstanding performance in vision-language reasoning, LargeVision-Language Models (LVLMs) might generate hallucinated contents that do notexist in the given image. Most existing LVLM hallucination benchmarks areconstrained to evaluate the object-related hallucinations. However, thepotential hallucination on the relations between two objects, i.e., relationhallucination, still lacks investigation. To remedy that, in this paper wedesign a unified framework to measure object and relation hallucination inLVLMs simultaneously. The core idea of our framework is to conducthallucination evaluation on (object, relation, object) triplets extracted fromLVLMs' responses, and thus, could be easily generalized to differentvision-language tasks. Based on our framework, we further introduce Tri-HE, anovel Triplet-level Hallucination Evaluation benchmark which can be used tostudy both object and relation hallucination at the same time. We conductcomprehensive evaluations on Tri-HE and observe that the relation hallucinationissue is even more serious than object hallucination among existing LVLMs,highlighting a previously neglected problem towards reliable LVLMs. Moreover,based on our findings, we design a simple yet effective training-free approachto mitigate hallucinations for LVLMs, with which, we exceed all open-sourcedcounterparts on Tri-HE, achieving comparable performance with the powerfulGPT-4V. Our dataset and code for the reproduction of our experiments areavailable publicly at https://github.com/wujunjie1998/Tri-HE.</description><author>Junjie Wu, Tsz Ting Chung, Kai Chen, Dit-Yan Yeung</author><pubDate>Wed, 30 Oct 2024 15:25:06 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.23114v1</guid></item><item><title>Why Gradient Subspace? Identifying and Mitigating LoRA's Bottlenecks in Federated Fine-Tuning of Large Language Models</title><link>http://arxiv.org/abs/2410.23111v1</link><description>Large Language Models (LLMs) have demonstrated remarkable capabilities acrossvarious domains, particularly in task generalization for both text and visiondata. While fine-tuning these models can significantly enhance theirperformance on specific downstream tasks, it often requires high-quality datathat cannot be shared due to privacy concerns. Federated Learning (FL) offers apromising solution for collaborative training without direct data sharing.However, many parameter-efficient fine-tuning strategies for LLMs in FL,particularly those based on Low-Rank Adaptation (LoRA), face limitations. Inthis paper, we critically analyze the convergence and performance guarantees ofpopular FL frameworks utilizing LoRA, highlighting its suboptimal nature due toconstrained subspace learning of low-rank matrices. This limitation hinderseffective fine-tuning of LLMs in federated settings. Through rigorousanalytical and empirical evaluations, we demonstrate that direct weightaveraging outperforms LoRA-based strategies, leading to superior performancefor fine-tuned models. Our comprehensive comparison exposes inefficiencies inLoRA approaches and underscores the advantages of full-rank weight aggregation.We extend our analysis to low-rank gradient-based optimizers, such as GaLore,used during local training steps. Our findings show that GaLore is a moreeffective alternative, outperforming federated LoRA methods like FlexLoRA andFFA-LoRA across both text and image modalities. While privacy remains paramountin FL discourse, our focus is on assessing performance outcomes of federatedfine-tuned models and evaluating various FL frameworks from both theoreticaland empirical perspectives. Our findings advocate reassessing the reliance onLoRA within FL contexts, paving the way for more efficient trainingmethodologies.</description><author>Navyansh Mahla, Ganesh Ramakrishnan</author><pubDate>Wed, 30 Oct 2024 15:23:44 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.23111v1</guid></item><item><title>Accelerating Transformers with Spectrum-Preserving Token Merging</title><link>http://arxiv.org/abs/2405.16148v2</link><description>Increasing the throughput of the Transformer architecture, a foundationalcomponent used in numerous state-of-the-art models for vision and languagetasks (e.g., GPT, LLaVa), is an important problem in machine learning. Onerecent and effective strategy is to merge token representations withinTransformer models, aiming to reduce computational and memory requirementswhile maintaining accuracy. Prior works have proposed algorithms based onBipartite Soft Matching (BSM), which divides tokens into distinct sets andmerges the top k similar tokens. However, these methods have significantdrawbacks, such as sensitivity to token-splitting strategies and damage toinformative tokens in later layers. This paper presents a novel paradigm calledPiToMe, which prioritizes the preservation of informative tokens using anadditional metric termed the energy score. This score identifies large clustersof similar tokens as high-energy, indicating potential candidates for merging,while smaller (unique and isolated) clusters are considered as low-energy andpreserved. Experimental findings demonstrate that PiToMe saved from 40-60\%FLOPs of the base models while exhibiting superior off-the-shelf performance onimage classification (0.5\% average performance drop of ViT-MAE-H compared to2.6\% as baselines), image-text retrieval (0.3\% average performance drop ofCLIP on Flickr30k compared to 4.5\% as others), and analogously in visualquestions answering with LLaVa-7B. Furthermore, PiToMe is theoretically shownto preserve intrinsic spectral properties of the original token space undermild conditions</description><author>Hoai-Chau Tran, Duy M. H. Nguyen, Duy M. Nguyen, Trung-Tin Nguyen, Ngan Le, Pengtao Xie, Daniel Sonntag, James Y. Zou, Binh T. Nguyen, Mathias Niepert</author><pubDate>Wed, 30 Oct 2024 15:22:53 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.16148v2</guid></item><item><title>ChatKBQA: A Generate-then-Retrieve Framework for Knowledge Base Question Answering with Fine-tuned Large Language Models</title><link>http://arxiv.org/abs/2310.08975v3</link><description>Knowledge Base Question Answering (KBQA) aims to answer natural languagequestions over large-scale knowledge bases (KBs), which can be summarized intotwo crucial steps: knowledge retrieval and semantic parsing. However, threecore challenges remain: inefficient knowledge retrieval, mistakes of retrievaladversely impacting semantic parsing, and the complexity of previous KBQAmethods. To tackle these challenges, we introduce ChatKBQA, a novel and simplegenerate-then-retrieve KBQA framework, which proposes first generating thelogical form with fine-tuned LLMs, then retrieving and replacing entities andrelations with an unsupervised retrieval method, to improve both generation andretrieval more directly. Experimental results show that ChatKBQA achieves newstate-of-the-art performance on standard KBQA datasets, WebQSP, and CWQ. Thiswork can also be regarded as a new paradigm for combining LLMs with knowledgegraphs (KGs) for interpretable and knowledge-required question answering. Ourcode is publicly available.</description><author>Haoran Luo, Haihong E, Zichen Tang, Shiyao Peng, Yikai Guo, Wentai Zhang, Chenghao Ma, Guanting Dong, Meina Song, Wei Lin, Yifan Zhu, Luu Anh Tuan</author><pubDate>Wed, 30 Oct 2024 15:22:12 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.08975v3</guid></item><item><title>NASM: Neural Anisotropic Surface Meshing</title><link>http://arxiv.org/abs/2410.23109v1</link><description>This paper introduces a new learning-based method, NASM, for anisotropicsurface meshing. Our key idea is to propose a graph neural network to embed aninput mesh into a high-dimensional (high-d) Euclidean embedding space topreserve curvature-based anisotropic metric by using a dot product loss betweenhigh-d edge vectors. This can dramatically reduce the computational time andincrease the scalability. Then, we propose a novel feature-sensitive remeshingon the generated high-d embedding to automatically capture sharp geometricfeatures. We define a high-d normal metric, and then derive an automaticdifferentiation on a high-d centroidal Voronoi tessellation (CVT) optimizationwith the normal metric to simultaneously preserve geometric features andcurvature anisotropy that exhibit in the original 3D shapes. To our knowledge,this is the first time that a deep learning framework and a large dataset areproposed to construct a high-d Euclidean embedding space for 3D anisotropicsurface meshing. Experimental results are evaluated and compared with thestate-of-the-art in anisotropic surface meshing on a large number of surfacemodels from Thingi10K dataset as well as tested on extensive unseen 3D shapesfrom Multi-Garment Network dataset and FAUST human dataset.</description><author>Hongbo Li, Haikuan Zhu, Sikai Zhong, Ningna Wang, Cheng Lin, Xiaohu Guo, Shiqing Xin, Wenping Wang, Jing Hua, Zichun Zhong</author><pubDate>Wed, 30 Oct 2024 15:20:10 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.23109v1</guid></item><item><title>Controllable Game Level Generation: Assessing the Effect of Negative Examples in GAN Models</title><link>http://arxiv.org/abs/2410.23108v1</link><description>Generative Adversarial Networks (GANs) are unsupervised models designed tolearn and replicate a target distribution. The vanilla versions of these modelscan be extended to more controllable models. Conditional Generative AdversarialNetworks (CGANs) extend vanilla GANs by conditioning both the generator anddiscriminator on some additional information (labels). Controllable modelsbased on complementary learning, such as Rumi-GAN, have been introduced.Rumi-GANs leverage negative examples to enhance the generator's ability tolearn positive examples. We evaluate the performance of two controllable GANvariants, CGAN and Rumi-GAN, in generating game levels targeting specificconstraints of interest: playability and controllability. This evaluation isconducted under two scenarios: with and without the inclusion of negativeexamples. The goal is to determine whether incorporating negative exampleshelps the GAN models avoid generating undesirable outputs. Our findingshighlight the strengths and weaknesses of each method in enforcing thegeneration of specific conditions when generating outputs based on givenpositive and negative examples.</description><author>Mahsa Bazzaz, Seth Cooper</author><pubDate>Wed, 30 Oct 2024 15:18:26 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.23108v1</guid></item><item><title>Segment, Shuffle, and Stitch: A Simple Layer for Improving Time-Series Representations</title><link>http://arxiv.org/abs/2405.20082v3</link><description>Existing approaches for learning representations of time-series keep thetemporal arrangement of the time-steps intact with the presumption that theoriginal order is the most optimal for learning. However, non-adjacent sectionsof real-world time-series may have strong dependencies. Accordingly, we raisethe question: Is there an alternative arrangement for time-series which couldenable more effective representation learning? To address this, we propose asimple plug-and-play neural network layer called Segment, Shuffle, and Stitch(S3) designed to improve representation learning in time-series models. S3works by creating non-overlapping segments from the original sequence andshuffling them in a learned manner that is optimal for the task at hand. Itthen re-attaches the shuffled segments back together and performs a learnedweighted sum with the original input to capture both the newly shuffledsequence along with the original sequence. S3 is modular and can be stacked toachieve different levels of granularity, and can be added to many forms ofneural architectures including CNNs or Transformers with negligible computationoverhead. Through extensive experiments on several datasets andstate-of-the-art baselines, we show that incorporating S3 results insignificant improvements for the tasks of time-series classification,forecasting, and anomaly detection, improving performance on certain datasetsby up to 68\%. We also show that S3 makes the learning more stable with asmoother training loss curve and loss landscape compared to the originalbaseline. The code is available athttps://github.com/shivam-grover/S3-TimeSeries.</description><author>Shivam Grover, Amin Jalali, Ali Etemad</author><pubDate>Wed, 30 Oct 2024 15:18:22 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.20082v3</guid></item><item><title>Text2NKG: Fine-Grained N-ary Relation Extraction for N-ary relational Knowledge Graph Construction</title><link>http://arxiv.org/abs/2310.05185v3</link><description>Beyond traditional binary relational facts, n-ary relational knowledge graphs(NKGs) are comprised of n-ary relational facts containing more than twoentities, which are closer to real-world facts with broader applications.However, the construction of NKGs remains at a coarse-grained level, which isalways in a single schema, ignoring the order and variable arity of entities.To address these restrictions, we propose Text2NKG, a novel fine-grained n-aryrelation extraction framework for n-ary relational knowledge graphconstruction. We introduce a span-tuple classification approach withhetero-ordered merging and output merging to accomplish fine-grained n-aryrelation extraction in different arity. Furthermore, Text2NKG supports fourtypical NKG schemas: hyper-relational schema, event-based schema, role-basedschema, and hypergraph-based schema, with high flexibility and practicality.The experimental results demonstrate that Text2NKG achieves state-of-the-artperformance in F1 scores on the fine-grained n-ary relation extractionbenchmark. Our code and datasets are publicly available.</description><author>Haoran Luo, Haihong E, Yuhao Yang, Tianyu Yao, Yikai Guo, Zichen Tang, Wentai Zhang, Kaiyang Wan, Shiyao Peng, Meina Song, Wei Lin, Yifan Zhu, Luu Anh Tuan</author><pubDate>Wed, 30 Oct 2024 15:18:14 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.05185v3</guid></item><item><title>Decoupling Semantic Similarity from Spatial Alignment for Neural Networks</title><link>http://arxiv.org/abs/2410.23107v1</link><description>What representation do deep neural networks learn? How similar are images toeach other for neural networks? Despite the overwhelming success of deeplearning methods key questions about their internal workings still remainlargely unanswered, due to their internal high dimensionality and complexity.To address this, one approach is to measure the similarity of activationresponses to various inputs. Representational Similarity Matrices (RSMs)distill this similarity into scalar values for each input pair. These matricesencapsulate the entire similarity structure of a system, indicating which inputleads to similar responses. While the similarity between images is ambiguous,we argue that the spatial location of semantic objects does neither influencehuman perception nor deep learning classifiers. Thus this should be reflectedin the definition of similarity between image responses for computer visionsystems. Revisiting the established similarity calculations for RSMs we exposetheir sensitivity to spatial alignment. In this paper, we propose to solve thisthrough semantic RSMs, which are invariant to spatial permutation. We measuresemantic similarity between input responses by formulating it as a set-matchingproblem. Further, we quantify the superiority of semantic RSMs overspatio-semantic RSMs through image retrieval and by comparing the similaritybetween representations to the similarity between predicted classprobabilities.</description><author>Tassilo Wald, Constantin Ulrich, Gregor Köhler, David Zimmerer, Stefan Denner, Michael Baumgartner, Fabian Isensee, Priyank Jaini, Klaus H. Maier-Hein</author><pubDate>Wed, 30 Oct 2024 15:17:58 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.23107v1</guid></item><item><title>Towards Heterogeneous Long-tailed Learning: Benchmarking, Metrics, and Toolbox</title><link>http://arxiv.org/abs/2307.08235v2</link><description>Long-tailed data distributions pose challenges for a variety of domains likee-commerce, finance, biomedical science, and cyber security, where theperformance of machine learning models is often dominated by head categorieswhile tail categories are inadequately learned. This work aims to provide asystematic view of long-tailed learning with regard to three pivotal angles:(A1) the characterization of data long-tailedness, (A2) the data complexity ofvarious domains, and (A3) the heterogeneity of emerging tasks. We developHeroLT, a comprehensive long-tailed learning benchmark integrating 18state-of-the-art algorithms, 10 evaluation metrics, and 17 real-world datasetsacross 6 tasks and 4 data modalities. HeroLT with novel angles and extensiveexperiments (315 in total) enables effective and fair evaluation of newlyproposed methods compared with existing baselines on varying dataset types.Finally, we conclude by highlighting the significant applications oflong-tailed learning and identifying several promising future directions. Foraccessibility and reproducibility, we open-source our benchmark HeroLT andcorresponding results at https://github.com/SSSKJ/HeroLT.</description><author>Haohui Wang, Weijie Guan, Jianpeng Chen, Zi Wang, Dawei Zhou</author><pubDate>Wed, 30 Oct 2024 15:17:00 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.08235v2</guid></item><item><title>Detection of Micromobility Vehicles in Urban Traffic Videos</title><link>http://arxiv.org/abs/2402.18503v2</link><description>Urban traffic environments present unique challenges for object detection,particularly with the increasing presence of micromobility vehicles likee-scooters and bikes. To address this object detection problem, this workintroduces an adapted detection model that combines the accuracy and speed ofsingle-frame object detection with the richer features offered by video objectdetection frameworks. This is done by applying aggregated feature maps fromconsecutive frames processed through motion flow to the YOLOX architecture.This fusion brings a temporal perspective to YOLOX detection abilities,allowing for a better understanding of urban mobility patterns andsubstantially improving detection reliability. Tested on a custom datasetcurated for urban micromobility scenarios, our model showcases substantialimprovement over existing state-of-the-art methods, demonstrating the need toconsider spatio-temporal information for detecting such small and thin objects.Our approach enhances detection in challenging conditions, includingocclusions, ensuring temporal consistency, and effectively mitigating motionblur.</description><author>Khalil Sabri, Célia Djilali, Guillaume-Alexandre Bilodeau, Nicolas Saunier, Wassim Bouachir</author><pubDate>Wed, 30 Oct 2024 15:16:52 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.18503v2</guid></item><item><title>WaveMixSR-V2: Enhancing Super-resolution with Higher Efficiency</title><link>http://arxiv.org/abs/2409.10582v3</link><description>Recent advancements in single image super-resolution have been predominantlydriven by token mixers and transformer architectures. WaveMixSR utilized theWaveMix architecture, employing a two-dimensional discrete wavelet transformfor spatial token mixing, achieving superior performance in super-resolutiontasks with remarkable resource efficiency. In this work, we present an enhancedversion of the WaveMixSR architecture by (1) replacing the traditionaltranspose convolution layer with a pixel shuffle operation and (2) implementinga multistage design for higher resolution tasks ($4\times$). Our experimentsdemonstrate that our enhanced model -- WaveMixSR-V2 -- outperforms otherarchitectures in multiple super-resolution tasks, achieving state-of-the-artfor the BSD100 dataset, while also consuming fewer resources, exhibits higherparameter efficiency, lower latency and higher throughput. Our code isavailable at https://github.com/pranavphoenix/WaveMixSR.</description><author>Pranav Jeevan, Neeraj Nixon, Amit Sethi</author><pubDate>Wed, 30 Oct 2024 15:16:43 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2409.10582v3</guid></item><item><title>Automated Image-Based Identification and Consistent Classification of Fire Patterns with Quantitative Shape Analysis and Spatial Location Identification</title><link>http://arxiv.org/abs/2410.23105v1</link><description>Fire patterns, consisting of fire effects that offer insights into firebehavior and origin, are traditionally classified based on investigators'visual observations, leading to subjective interpretations. This study proposesa framework for quantitative fire pattern classification to support fireinvestigators, aiming for consistency and accuracy. The framework integratesfour components. First, it leverages human-computer interaction to extract firepatterns from surfaces, combining investigator expertise with computationalanalysis. Second, it employs an aspect ratio-based random forest model toclassify fire pattern shapes. Third, fire scene point cloud segmentationenables precise identification of fire-affected areas and the mapping of 2Dfire patterns to 3D scenes. Lastly, spatial relationships between fire patternsand indoor elements support an interpretation of the fire scene. Thesecomponents provide a method for fire pattern analysis that synthesizesqualitative and quantitative data. The framework's classification resultsachieve 93% precision on synthetic data and 83% on real fire patterns.</description><author>Pengkun Liu, Shuna Ni, Stanislav I. Stoliarov, Pingbo Tang</author><pubDate>Wed, 30 Oct 2024 15:15:41 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.23105v1</guid></item><item><title>Bayesian Optimisation with Unknown Hyperparameters: Regret Bounds Logarithmically Closer to Optimal</title><link>http://arxiv.org/abs/2410.10384v2</link><description>Bayesian Optimization (BO) is widely used for optimising black-box functionsbut requires us to specify the length scale hyperparameter, which defines thesmoothness of the functions the optimizer will consider. Most current BOalgorithms choose this hyperparameter by maximizing the marginal likelihood ofthe observed data, albeit risking misspecification if the objective function isless smooth in regions we have not yet explored. The only prior solutionaddressing this problem with theoretical guarantees was A-GP-UCB, proposed byBerkenkamp et al. (2019). This algorithm progressively decreases the lengthscale, expanding the class of functions considered by the optimizer. However,A-GP-UCB lacks a stopping mechanism, leading to over-exploration and slowconvergence. To overcome this, we introduce Length scale Balancing (LB) - anovel approach, aggregating multiple base surrogate models with varying lengthscales. LB intermittently adds smaller length scale candidate values whileretaining longer scales, balancing exploration and exploitation. We formallyderive a cumulative regret bound of LB and compare it with the regret of anoracle BO algorithm using the optimal length scale. Denoting the factor bywhich the regret bound of A-GP-UCB was away from oracle as $g(T)$, we show thatLB is only $\log g(T)$ away from oracle regret. We also empirically evaluateour algorithm on synthetic and real-world benchmarks and show it outperformsA-GP-UCB, maximum likelihood estimation and MCMC.</description><author>Juliusz Ziomek, Masaki Adachi, Michael A. Osborne</author><pubDate>Wed, 30 Oct 2024 15:15:37 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.10384v2</guid></item><item><title>Guided Game Level Repair via Explainable AI</title><link>http://arxiv.org/abs/2410.23101v1</link><description>Procedurally generated levels created by machine learning models can beunsolvable without further editing. Various methods have been developed toautomatically repair these levels by enforcing hard constraints during thepost-processing step. However, as levels increase in size, theseconstraint-based repairs become increasingly slow. This paper proposes usingexplainability methods to identify specific regions of a level that contributeto its unsolvability. By assigning higher weights to these regions,constraint-based solvers can prioritize these problematic areas, enabling moreefficient repairs. Our results, tested across three games, demonstrate thatthis approach can help to repair procedurally generated levels faster.</description><author>Mahsa Bazzaz, Seth Cooper</author><pubDate>Wed, 30 Oct 2024 15:12:36 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.23101v1</guid></item><item><title>Comparative Analysis of Demonstration Selection Algorithms for LLM In-Context Learning</title><link>http://arxiv.org/abs/2410.23099v1</link><description>In-context learning can help Large Language Models (LLMs) to adapt new taskswithout additional training. However, this performance heavily depends on thequality of the demonstrations, driving research into effective demonstrationselection algorithms to optimize this process. These algorithms assist users inselecting the best $k$ input-label pairs (demonstration examples) based on agiven test input, enabling LLMs to in-context learn the relationship betweenthe provided examples and the test inputs. Despite all the proposeddemonstration selection algorithms, their efficiency and effectiveness remainunclear. This lack of clarity make it difficult to apply these algorithms inreal-world scenarios and poses challenges for future research aimed atdeveloping improved methods. This paper revisits six proposed algorithms,evaluating them on five datasets from both efficiency and effectivenessperspectives. Our experiments reveal significant variations in algorithmperformance across different tasks, with some methods struggling to outperformrandom selection in certain scenarios. We also find that increasing the numberof demonstrations does not always lead to better performance, and that thereare often trade-offs between accuracy and computational efficiency. Our code isavailable at https://github.com/Tizzzzy/Demonstration_Selection_Overview.</description><author>Dong Shu, Mengnan Du</author><pubDate>Wed, 30 Oct 2024 15:11:58 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.23099v1</guid></item><item><title>Non-Invasive Suicide Risk Prediction Through Speech Analysis</title><link>http://arxiv.org/abs/2404.12132v3</link><description>The delayed access to specialized psychiatric assessments and care forpatients at risk of suicidal tendencies in emergency departments creates anotable gap in timely intervention, hindering the provision of adequate mentalhealth support during critical situations. To address this, we present anon-invasive, speech-based approach for automatic suicide risk assessment. Forour study, we collected a novel speech recording dataset from $20$ patients. Weextract three sets of features, including wav2vec, interpretable speech andacoustic features, and deep learning-based spectral representations. We proceedby conducting a binary classification to assess suicide risk in aleave-one-subject-out fashion. Our most effective speech model achieves abalanced accuracy of $66.2\,\%$. Moreover, we show that integrating our speechmodel with a series of patients' metadata, such as the history of suicideattempts or access to firearms, improves the overall result. The metadataintegration yields a balanced accuracy of $94.4\,\%$, marking an absoluteimprovement of $28.2\,\%$, demonstrating the efficacy of our proposedapproaches for automatic suicide risk assessment in emergency medicine.</description><author>Shahin Amiriparian, Maurice Gerczuk, Justina Lutz, Wolfgang Strube, Irina Papazova, Alkomiet Hasan, Alexander Kathan, Björn W. Schuller</author><pubDate>Wed, 30 Oct 2024 15:08:51 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.12132v3</guid></item><item><title>IMITATE: Clinical Prior Guided Hierarchical Vision-Language Pre-training</title><link>http://arxiv.org/abs/2310.07355v5</link><description>In the field of medical Vision-Language Pre-training (VLP), significantefforts have been devoted to deriving text and image features from bothclinical reports and associated medical images. However, most existing methodsmay have overlooked the opportunity in leveraging the inherent hierarchicalstructure of clinical reports, which are generally split into `findings' fordescriptive content and `impressions' for conclusive observation. Instead ofutilizing this rich, structured format, current medical VLP approaches oftensimplify the report into either a unified entity or fragmented tokens. In thiswork, we propose a novel clinical prior guided VLP framework named IMITATE tolearn the structure information from medical reports with hierarchicalvision-language alignment. The framework derives multi-level visual featuresfrom the chest X-ray (CXR) images and separately aligns these features with thedescriptive and the conclusive text encoded in the hierarchical medical report.Furthermore, a new clinical-informed contrastive loss is introduced forcross-modal learning, which accounts for clinical prior knowledge informulating sample correlations in contrastive learning. The proposed model,IMITATE, outperforms baseline VLP methods across six different datasets,spanning five medical imaging downstream tasks. Comprehensive experimentalresults highlight the advantages of integrating the hierarchical structure ofmedical reports for vision-language alignment. The code related to this paperis available at https://github.com/cheliu-computation/IMITATE-TMI2024.</description><author>Che Liu, Sibo Cheng, Miaojing Shi, Anand Shah, Wenjia Bai, Rossella Arcucci</author><pubDate>Wed, 30 Oct 2024 15:08:37 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.07355v5</guid></item><item><title>First Place Solution to the ECCV 2024 ROAD++ Challenge @ ROAD++ Atomic Activity Recognition 2024</title><link>http://arxiv.org/abs/2410.23092v1</link><description>This report presents our team's technical solution for participating in Track3 of the 2024 ECCV ROAD++ Challenge. The task of Track 3 is atomic activityrecognition, which aims to identify 64 types of atomic activities in roadscenes based on video content. Our approach primarily addresses the challengesof small objects, discriminating between single object and a group of objects,as well as model overfitting in this task. Firstly, we construct a multi-branchactivity recognition framework that not only separates different objectcategories but also the tasks of single object and object group recognition,thereby enhancing recognition accuracy. Subsequently, we develop various modelensembling strategies, including integrations of multiple frame samplingsequences, different frame sampling sequence lengths, multiple training epochs,and different backbone networks. Furthermore, we propose an atomic activityrecognition data augmentation method, which greatly expands the sample space byflipping video frames and road topology, effectively mitigating modeloverfitting. Our methods rank first in the test set of Track 3 for the ROAD++Challenge 2024, and achieve 69% mAP.</description><author>Ruyang Li, Tengfei Zhang, Heng Zhang, Tiejun Liu, Yanwei Wang, Xuelei Li</author><pubDate>Wed, 30 Oct 2024 15:06:58 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.23092v1</guid></item><item><title>CausalDiff: Causality-Inspired Disentanglement via Diffusion Model for Adversarial Defense</title><link>http://arxiv.org/abs/2410.23091v1</link><description>Despite ongoing efforts to defend neural classifiers from adversarialattacks, they remain vulnerable, especially to unseen attacks. In contrast,humans are difficult to be cheated by subtle manipulations, since we makejudgments only based on essential factors. Inspired by this observation, weattempt to model label generation with essential label-causative factors andincorporate label-non-causative factors to assist data generation. For anadversarial example, we aim to discriminate the perturbations as non-causativefactors and make predictions only based on the label-causative factors.Concretely, we propose a casual diffusion model (CausalDiff) that adaptsdiffusion models for conditional data generation and disentangles the two typesof casual factors by learning towards a novel casual information bottleneckobjective. Empirically, CausalDiff has significantly outperformedstate-of-the-art defense methods on various unseen attacks, achieving anaverage robustness of 86.39% (+4.01%) on CIFAR-10, 56.25% (+3.13%) onCIFAR-100, and 82.62% (+4.93%) on GTSRB (German Traffic Sign RecognitionBenchmark).</description><author>Mingkun Zhang, Keping Bi, Wei Chen, Quanrun Chen, Jiafeng Guo, Xueqi Cheng</author><pubDate>Wed, 30 Oct 2024 15:06:44 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.23091v1</guid></item><item><title>CORAL: Benchmarking Multi-turn Conversational Retrieval-Augmentation Generation</title><link>http://arxiv.org/abs/2410.23090v1</link><description>Retrieval-Augmented Generation (RAG) has become a powerful paradigm forenhancing large language models (LLMs) through external knowledge retrieval.Despite its widespread attention, existing academic research predominantlyfocuses on single-turn RAG, leaving a significant gap in addressing thecomplexities of multi-turn conversations found in real-world applications. Tobridge this gap, we introduce CORAL, a large-scale benchmark designed to assessRAG systems in realistic multi-turn conversational settings. CORAL includesdiverse information-seeking conversations automatically derived from Wikipediaand tackles key challenges such as open-domain coverage, knowledge intensity,free-form responses, and topic shifts. It supports three core tasks ofconversational RAG: passage retrieval, response generation, and citationlabeling. We propose a unified framework to standardize various conversationalRAG methods and conduct a comprehensive evaluation of these methods on CORAL,demonstrating substantial opportunities for improving existing approaches.</description><author>Yiruo Cheng, Kelong Mao, Ziliang Zhao, Guanting Dong, Hongjin Qian, Yongkang Wu, Tetsuya Sakai, Ji-Rong Wen, Zhicheng Dou</author><pubDate>Wed, 30 Oct 2024 15:06:32 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.23090v1</guid></item><item><title>PIP-MM: Pre-Integrating Prompt Information into Visual Encoding via Existing MLLM Structures</title><link>http://arxiv.org/abs/2410.23089v1</link><description>The Multimodal Large Language Models (MLLMs) have activated thecapabilitiesof Large Language Models (LLMs) in solving visual-language tasks byintegratingvisual information. The prevailing approach in existing MLLMsinvolvesemploying an image encoder to extract visual features, convertingthesefeatures into visual tokens via an adapter, and then integrating them withtheprompt into the LLM. However, because the process of image encodingisprompt-agnostic, the extracted visual features only provide acoarsedescription of the image, impossible to focus on the requirements oftheprompt. On one hand, it is easy for image features to lack informationaboutthe prompt-specified objects, resulting in unsatisfactory responses. Ontheother hand, the visual features contain a large amount ofirrelevantinformation, which not only increases the burden on memory but alsoworsens thegeneration effectiveness. To address the aforementioned issues, wepropose\textbf{PIP-MM}, a framework that\textbf{P}re-\textbf{I}ntegrates\textbf{P}rompt information into the visualencoding process using existingmodules of MLLMs. Specifically, We utilize thefrozen LLM in the MLLM tovectorize the input prompt, which summarizes therequirements of the prompt.Then, we input the prompt vector into our trainedMulti-Layer Perceptron (MLP)to align with the visual input requirements, andsubsequently replace the classembedding in the image encoder. Since our modelonly requires adding atrainable MLP, it can be applied to any MLLM. To validatethe effectiveness ofPIP-MM, we conducted experiments on multiple benchmarks.Automated evaluationmetrics and manual assessments demonstrate the strongperformance of PIP-MM.Particularly noteworthy is that our model maintainsexcellent generationresults even when half of the visual tokens are reduced.</description><author>Tianxiang Wu, Minxin Nie, Ziqiang Cao</author><pubDate>Wed, 30 Oct 2024 15:05:17 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.23089v1</guid></item><item><title>No imputation without representation</title><link>http://arxiv.org/abs/2206.14254v4</link><description>By filling in missing values in datasets, imputation allows these datasets tobe used with algorithms that cannot handle missing values by themselves.However, missing values may in principle contribute useful information that islost through imputation. The missing-indicator approach can be used incombination with imputation to instead represent this information as a part ofthe dataset. There are several theoretical considerations whymissing-indicators may or may not be beneficial, but there has not been anylarge-scale practical experiment on real-life datasets to test this questionfor machine learning predictions. We perform this experiment for threeimputation strategies and a range of different classification algorithms, onthe basis of twenty real-life datasets. In a follow-up experiment, we determineattribute-specific missingness thresholds for each classifier above whichmissing-indicators are more likely than not to increase classificationperformance. And in a second follow-up experiment, we evaluate numericalimputation of one-hot encoded categorical attributes. We reach the followingconclusions. Firstly, missing-indicators generally increase classificationperformance. Secondly, with missing-indicators, nearest neighbour and iterativeimputation do not lead to better performance than simple mean/mode imputation.Thirdly, for decision trees, pruning is necessary to prevent overfitting.Fourthly, the thresholds above which missing-indicators are more likely thannot to improve performance are lower for categorical attributes than fornumerical attributes. Lastly, mean imputation of numerical attributes preservessome of the information from missing values. Consequently, when not usingmissing-indicators it can be advantageous to apply mean imputation to one-hotencoded categorical attributes instead of mode imputation.</description><author>Oliver Urs Lenz, Daniel Peralta, Chris Cornelis</author><pubDate>Wed, 30 Oct 2024 15:03:44 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2206.14254v4</guid></item><item><title>Statistical-Computational Trade-offs for Density Estimation</title><link>http://arxiv.org/abs/2410.23087v1</link><description>We study the density estimation problem defined as follows: given $k$distributions $p_1, \ldots, p_k$ over a discrete domain $[n]$, as well as acollection of samples chosen from a ``query'' distribution $q$ over $[n]$,output $p_i$ that is ``close'' to $q$. Recently~\cite{aamand2023data} gave thefirst and only known result that achieves sublinear bounds in {\em both} thesampling complexity and the query time while preserving polynomial datastructure space. However, their improvement over linear samples and time isonly by subpolynomial factors. Our main result is a lower bound showing that, for a broad class of datastructures, their bounds cannot be significantly improved. In particular, if analgorithm uses $O(n/\log^c k)$ samples for some constant $c&gt;0$ and polynomialspace, then the query time of the data structure must be at least$k^{1-O(1)/\log \log k}$, i.e., close to linear in the number of distributions$k$. This is a novel \emph{statistical-computational} trade-off for densityestimation, demonstrating that any data structure must use close to a linearnumber of samples or take close to linear query time. The lower bound holdseven in the realizable case where $q=p_i$ for some $i$, and when thedistributions are flat (specifically, all distributions are uniform over halfof the domain $[n]$). We also give a simple data structure for our lower boundinstance with asymptotically matching upper bounds. Experiments show that thedata structure is quite efficient in practice.</description><author>Anders Aamand, Alexandr Andoni, Justin Y. Chen, Piotr Indyk, Shyam Narayanan, Sandeep Silwal, Haike Xu</author><pubDate>Wed, 30 Oct 2024 15:03:33 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.23087v1</guid></item><item><title>MemControl: Mitigating Memorization in Diffusion Models via Automated Parameter Selection</title><link>http://arxiv.org/abs/2405.19458v2</link><description>Diffusion models excel in generating images that closely resemble theirtraining data but are also susceptible to data memorization, raising privacy,ethical, and legal concerns, particularly in sensitive domains such as medicalimaging. We hypothesize that this memorization stems from theoverparameterization of deep models and propose that regularizing modelcapacity during fine-tuning can mitigate this issue. Firstly, we empiricallyshow that regulating the model capacity via Parameter-efficient fine-tuning(PEFT) mitigates memorization to some extent, however, it further requires theidentification of the exact parameter subsets to be fine-tuned for high-qualitygeneration. To identify these subsets, we introduce a bi-level optimizationframework, MemControl, that automates parameter selection using memorizationand generation quality metrics as rewards during fine-tuning. The parametersubsets discovered through MemControl achieve a superior tradeoff betweengeneration quality and memorization. For the task of medical image generation,our approach outperforms existing state-of-the-art memorization mitigationstrategies by fine-tuning as few as 0.019% of model parameters. Moreover, wedemonstrate that the discovered parameter subsets are transferable tonon-medical domains. Our framework is scalable to large datasets, agnostic toreward functions, and can be integrated with existing approaches for furthermemorization mitigation. To the best of our knowledge, this is the first studyto empirically evaluate memorization in medical images and propose a targetedyet universal mitigation strategy. The code is available athttps://github.com/Raman1121/Diffusion_Memorization_HPO</description><author>Raman Dutt, Ondrej Bohdal, Pedro Sanchez, Sotirios A. Tsaftaris, Timothy Hospedales</author><pubDate>Wed, 30 Oct 2024 15:02:54 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.19458v2</guid></item><item><title>From Hype to Reality: The Road Ahead of Deploying DRL in 6G Networks</title><link>http://arxiv.org/abs/2410.23086v1</link><description>The industrial landscape is rapidly evolving with the advent of 6Gapplications, which demand massive connectivity, high computational capacity,and ultra-low latency. These requirements present new challenges, which can nolonger be efficiently addressed by conventional strategies. In response, thisarticle underscores the transformative potential of Deep Reinforcement Learning(DRL) for 6G, highlighting its advantages over classic machine learningsolutions in meeting the demands of 6G. The necessity of DRL is furthervalidated through three DRL applications in an end-to-end communicationprocedure, including wireless access control, baseband function placement, andnetwork slicing coordination. However, DRL-based network management initiativesare far from mature. We extend the discussion to identify the challenges ofapplying DRL in practical networks and explore potential solutions along withtheir respective limitations. In the end, these insights are validated througha practical DRL deployment in managing network slices on the testbed.</description><author>Haiyuan Li, Hari Madhukumar, Peizheng Li, Yiran Teng, Shuangyi Yan, Dimitra Simeonidou</author><pubDate>Wed, 30 Oct 2024 15:02:54 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.23086v1</guid></item><item><title>Robustifying automatic speech recognition by extracting slowly varying features</title><link>http://arxiv.org/abs/2112.07400v2</link><description>In the past few years, it has been shown that deep learning systems arehighly vulnerable under attacks with adversarial examples. Neural-network-basedautomatic speech recognition (ASR) systems are no exception. Targeted anduntargeted attacks can modify an audio input signal in such a way that humansstill recognise the same words, while ASR systems are steered to predict adifferent transcription. In this paper, we propose a defense mechanism againsttargeted adversarial attacks consisting in removing fast-changing features fromthe audio signals, either by applying slow feature analysis, a low-pass filter,or both, before feeding the input to the ASR system. We perform an empiricalanalysis of hybrid ASR models trained on data pre-processed in such a way.While the resulting models perform quite well on benign data, they aresignificantly more robust against targeted adversarial attacks: Our final,proposed model shows a performance on clean data similar to the baseline model,while being more than four times more robust.</description><author>Matías Pizarro, Dorothea Kolossa, Asja Fischer</author><pubDate>Wed, 30 Oct 2024 15:02:41 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2112.07400v2</guid></item><item><title>S3PT: Scene Semantics and Structure Guided Clustering to Boost Self-Supervised Pre-Training for Autonomous Driving</title><link>http://arxiv.org/abs/2410.23085v1</link><description>Recent self-supervised clustering-based pre-training techniques like DINO andCribo have shown impressive results for downstream detection and segmentationtasks. However, real-world applications such as autonomous driving facechallenges with imbalanced object class and size distributions and complexscene geometries. In this paper, we propose S3PT a novel scene semantics andstructure guided clustering to provide more scene-consistent objectives forself-supervised training. Specifically, our contributions are threefold: First,we incorporate semantic distribution consistent clustering to encourage betterrepresentation of rare classes such as motorcycles or animals. Second, weintroduce object diversity consistent spatial clustering, to handle imbalancedand diverse object sizes, ranging from large background areas to small objectssuch as pedestrians and traffic signs. Third, we propose a depth-guided spatialclustering to regularize learning based on geometric information of the scene,thus further refining region separation on the feature level. Our learnedrepresentations significantly improve performance in downstream semanticsegmentation and 3D object detection tasks on the nuScenes, nuImages, andCityscapes datasets and show promising domain translation properties.</description><author>Maciej K. Wozniak, Hariprasath Govindarajan, Marvin Klingner, Camille Maurice, Ravi Kiran, Senthil Yogamani</author><pubDate>Wed, 30 Oct 2024 15:00:06 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.23085v1</guid></item><item><title>AI-assisted prostate cancer detection and localisation on biparametric MR by classifying radiologist-positives</title><link>http://arxiv.org/abs/2410.23084v1</link><description>Prostate cancer diagnosis through MR imaging have currently relied onradiologists' interpretation, whilst modern AI-based methods have beendeveloped to detect clinically significant cancers independent of radiologists.In this study, we propose to develop deep learning models that improve theoverall cancer diagnostic accuracy, by classifying radiologist-identifiedpatients or lesions (i.e. radiologist-positives), as opposed to the existingmodels that are trained to discriminate over all patients. We develop a singlevoxel-level classification model, with a simple percentage threshold todetermine positive cases, at levels of lesions, Barzell-zones and patients.Based on the presented experiments from two clinical data sets, consisting ofhistopathology-labelled MR images from more than 800 and 500 patients in therespective UCLA and UCL PROMIS studies, we show that the proposed strategy canimprove the diagnostic accuracy, by augmenting the radiologist reading of theMR imaging. Among varying definition of clinical significance, the proposedstrategy, for example, achieved a specificity of 44.1% (with AI assistance)from 36.3% (by radiologists alone), at a controlled sensitivity of 80.0% on thepublicly available UCLA data set. This provides measurable clinical values in arange of applications such as reducing unnecessary biopsies, lowering cost incancer screening and quantifying risk in therapies.</description><author>Xiangcen Wu, Yipei Wang, Qianye Yang, Natasha Thorley, Shonit Punwani, Veeru Kasivisvanathan, Ester Bonmati, Yipeng Hu</author><pubDate>Wed, 30 Oct 2024 14:59:57 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.23084v1</guid></item><item><title>Scientific and Technological Information Oriented Semantics-adversarial and Media-adversarial Cross-media Retrieval</title><link>http://arxiv.org/abs/2203.08615v3</link><description>Cross-media retrieval of scientific and technological information is one ofthe important tasks in the cross-media study. Cross-media scientific andtechnological information retrieval obtain target information from massivemulti-source and heterogeneous scientific and technological resources, whichhelps to design applications that meet users' needs, including scientific andtechnological information recommendation, personalized scientific andtechnological information retrieval, etc. The core of cross-media retrieval isto learn a common subspace, so that data from different media can be directlycompared with each other after being mapped into this subspace. In subspacelearning, existing methods often focus on modeling the discrimination ofintra-media data and the invariance of inter-media data after mapping; however,they ignore the semantic consistency of inter-media data before and aftermapping and media discrimination of intra-semantics data, which limit theresult of cross-media retrieval. In light of this, we propose a scientific andtechnological information oriented Semantics-adversarial and Media-adversarialCross-media Retrieval method (SMCR) to find an effective common subspace.Specifically, SMCR minimizes the loss of inter-media semantic consistency inaddition to modeling intra-media semantic discrimination, to preserve semanticsimilarity before and after mapping. Furthermore, SMCR constructs a basicfeature mapping network and a refined feature mapping network to jointlyminimize the media discriminative loss within semantics, so as to enhance thefeature mapping network's ability to confuse the media discriminant network.Experimental results on two datasets demonstrate that the proposed SMCRoutperforms state-of-the-art methods in cross-media retrieval.</description><author>Ang Li, Junping Du, Feifei Kou, Zhe Xue, Xin Xu, Mingying Xu, Yang Jiang</author><pubDate>Wed, 30 Oct 2024 14:56:09 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2203.08615v3</guid></item><item><title>Differentially Private Representation Learning via Image Captioning</title><link>http://arxiv.org/abs/2403.02506v2</link><description>Differentially private (DP) machine learning is considered the gold-standardsolution for training a model from sensitive data while still preservingprivacy. However, a major barrier to achieving this ideal is its sub-optimalprivacy-accuracy trade-off, which is particularly visible in DP representationlearning. Specifically, it has been shown that under modest privacy budgets,most models learn representations that are not significantly better thanhand-crafted features. In this work, we show that effective DP representationlearning can be done via image captioning and scaling up to internet-scalemultimodal datasets. Through a series of engineering tricks, we successfullytrain a DP image captioner (DP-Cap) on a 233M subset of LAION-2B from scratchusing a reasonable amount of computation, and obtaining unprecedentedhigh-quality image features that can be used in a variety of downstream visionand vision-language tasks. For example, under a privacy budget of$\varepsilon=8$ for the LAION dataset, a linear classifier trained on top oflearned DP-Cap features attains $65.8\%$ accuracy on ImageNet-1K, considerablyimproving the previous SOTA of $56.5\%$.</description><author>Tom Sander, Yaodong Yu, Maziar Sanjabi, Alain Durmus, Yi Ma, Kamalika Chaudhuri, Chuan Guo</author><pubDate>Wed, 30 Oct 2024 14:55:58 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.02506v2</guid></item><item><title>An Event-Based Digital Compute-In-Memory Accelerator with Flexible Operand Resolution and Layer-Wise Weight/Output Stationarity</title><link>http://arxiv.org/abs/2410.23082v1</link><description>Compute-in-memory (CIM) accelerators for spiking neural networks (SNNs) arepromising solutions to enable $\mu$s-level inference latency and ultra-lowenergy in edge vision applications. Yet, their current lack of flexibility atboth the circuit and system levels prevents their deployment in a wide range ofreal-life scenarios. In this work, we propose a novel digital CIM macro thatsupports arbitrary operand resolution and shape, with a unified CIM storage forweights and membrane potentials. These circuit-level techniques enable a hybridweight- and output-stationary dataflow at the system level to maximize operandreuse, thereby minimizing costly on- and off-chip data movements during the SNNexecution. Measurement results of a fabricated FlexSpIM prototype in 40-nm CMOSdemonstrate a 2$\times$ increase in bit-normalized energy efficiency comparedto prior fixed-precision digital CIM-SNNs, while providing resolutionreconfiguration with bitwise granularity. Our approach can save up to 90%energy in large-scale systems, while reaching a state-of-the-art classificationaccuracy of 95.8% on the IBM DVS gesture dataset.</description><author>Nicolas Chauvaux, Adrian Kneip, Christoph Posch, Kofi Makinwa, Charlotte Frenkel</author><pubDate>Wed, 30 Oct 2024 14:55:13 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.23082v1</guid></item><item><title>Utilizing Large Language Models in an iterative paradigm with Domain feedback for Zero-shot Molecule optimization</title><link>http://arxiv.org/abs/2410.13147v4</link><description>Molecule optimization is a critical task in drug discovery to optimizedesired properties of a given molecule through chemical modification. DespiteLarge Language Models (LLMs) holding the potential to efficiently simulate thistask by using natural language to direct the optimization, straightforwardlyutilizing shows limited performance. In this work, we facilitate utilizing LLMsin an iterative paradigm by proposing a simple yet highly effective domainfeedback provider, namely $\text{Re}^3$DF. In detail, $\text{Re}^3$DF harnessesan external toolkit, RDKit, to handle the molecule hallucination, if themodified molecule is chemically invalid. Otherwise, its desired properties arecomputed and compared to the original one, establishing reliable domainfeedback with correct direction and distance towards the objective, followed bya retrieved example, to explicitly guide the LLM to refine the modifiedmolecule. We conduct experiments across both single- and multi-propertyobjectives with 2 thresholds, where $\text{Re}^3$DF shows significantimprovements. Particularly, for 20 single-property objectives, $\text{Re}^3$DFenhances Hit ratio by 16.95% and 20.76% under loose and strict thresholds,respectively. For 32 multi-property objectives, $\text{Re}^3$DF enhances Hitratio by 6.04% and 5.25%.</description><author>Khiem Le, Nitesh V. Chawla</author><pubDate>Wed, 30 Oct 2024 14:54:25 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.13147v4</guid></item><item><title>BUZZ: Beehive-structured Sparse KV Cache with Segmented Heavy Hitters for Efficient LLM Inference</title><link>http://arxiv.org/abs/2410.23079v1</link><description>Large language models (LLMs) are essential in natural language processing butoften struggle with inference speed and computational efficiency, limitingreal-time deployment. The key-value (KV) cache mechanism reduces computationaloverhead in transformer models, but challenges in maintaining contextualunderstanding remain. In this paper, we propose BUZZ, a novel KV cachingalgorithm that leverages structured contextual information to minimize cachememory usage while enhancing inference speed. BUZZ employs a beehive-structuredsparse cache, incorporating a sliding window to capture recent information anddynamically segmenting historical tokens into chunks to prioritize importanttokens in local neighborhoods. We evaluate BUZZ on four real-world datasets:CNN/Daily Mail, XSUM, Wikitext, and 10-QA. Our results demonstrate that BUZZ(1) reduces cache memory usage by $\textbf{2.5}\times$ in LLM inference whilemaintaining over 99% accuracy in long-text summarization, and (2) surpassesstate-of-the-art performance in multi-document question answering by$\textbf{7.69%}$ under the same memory limit, where full cache methodsencounter out-of-memory issues. Additionally, BUZZ achieves significantinference speedup with a $\log{n}$ time complexity. The code is available athttps://github.com/JunqiZhao888/buzz-llm.</description><author>Junqi Zhao, Zhijin Fang, Shu Li, Shaohui Yang, Shichao He</author><pubDate>Wed, 30 Oct 2024 14:53:37 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.23079v1</guid></item><item><title>MInference 1.0: Accelerating Pre-filling for Long-Context LLMs via Dynamic Sparse Attention</title><link>http://arxiv.org/abs/2407.02490v2</link><description>The computational challenges of Large Language Model (LLM) inference remain asignificant barrier to their widespread deployment, especially as promptlengths continue to increase. Due to the quadratic complexity of the attentioncomputation, it takes 30 minutes for an 8B LLM to process a prompt of 1M tokens(i.e., the pre-filling stage) on a single A100 GPU. Existing methods forspeeding up prefilling often fail to maintain acceptable accuracy or efficiencywhen applied to long-context LLMs. To address this gap, we introduce MInference(Milliontokens Inference), a sparse calculation method designed to acceleratepre-filling of long-sequence processing. Specifically, we identify three uniquepatterns in long-context attention matrices-the A-shape, Vertical-Slash, andBlock-Sparsethat can be leveraged for efficient sparse computation on GPUs. Wedetermine the optimal pattern for each attention head offline and dynamicallybuild sparse indices based on the assigned pattern during inference. With thepattern and sparse indices, we perform efficient sparse attention calculationsvia our optimized GPU kernels to significantly reduce the latency in thepre-filling stage of long-context LLMs. Our proposed technique can be directlyapplied to existing LLMs without any modifications to the pre-training setup oradditional fine-tuning. By evaluating on a wide range of downstream tasks,including InfiniteBench, RULER, PG-19, and Needle In A Haystack, and modelsincluding LLaMA-3-1M, GLM4-1M, Yi-200K, Phi-3-128K, and Qwen2-128K, wedemonstrate that MInference effectively reduces inference latency by up to 10xfor pre-filling on an A100, while maintaining accuracy. Our code is availableat https://aka.ms/MInference.</description><author>Huiqiang Jiang, Yucheng Li, Chengruidong Zhang, Qianhui Wu, Xufang Luo, Surin Ahn, Zhenhua Han, Amir H. Abdi, Dongsheng Li, Chin-Yew Lin, Yuqing Yang, Lili Qiu</author><pubDate>Wed, 30 Oct 2024 14:53:22 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.02490v2</guid></item><item><title>First Place Solution to the ECCV 2024 ROAD++ Challenge @ ROAD++ Spatiotemporal Agent Detection 2024</title><link>http://arxiv.org/abs/2410.23077v1</link><description>This report presents our team's solutions for the Track 1 of the 2024 ECCVROAD++ Challenge. The task of Track 1 is spatiotemporal agent detection, whichaims to construct an "agent tube" for road agents in consecutive video frames.Our solutions focus on the challenges in this task, including extreme-sizeobjects, low-light scenarios, class imbalance, and fine-grained classification.Firstly, the extreme-size object detection heads are introduced to improve thedetection performance of large and small objects. Secondly, we design adual-stream detection model with a low-light enhancement stream to improve theperformance of spatiotemporal agent detection in low-light scenes, and thefeature fusion module to integrate features from different branches.Subsequently, we develop a multi-branch detection framework to mitigate theissues of class imbalance and fine-grained classification, and we design apre-training and fine-tuning approach to optimize the above multi-branchframework. Besides, we employ some common data augmentation techniques, andimprove the loss function and upsampling operation. We rank first in the testset of Track 1 for the ROAD++ Challenge 2024, and achieve 30.82% averagevideo-mAP.</description><author>Tengfei Zhang, Heng Zhang, Ruyang Li, Qi Deng, Yaqian Zhao, Rengang Li</author><pubDate>Wed, 30 Oct 2024 14:52:43 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.23077v1</guid></item><item><title>Benchmarking Agentic Workflow Generation</title><link>http://arxiv.org/abs/2410.07869v2</link><description>Large Language Models (LLMs), with their exceptional ability to handle a widerange of tasks, have driven significant advancements in tackling reasoning andplanning tasks, wherein decomposing complex problems into executable workflowsis a crucial step in this process. Existing workflow evaluation frameworkseither focus solely on holistic performance or suffer from limitations such asrestricted scenario coverage, simplistic workflow structures, and laxevaluation standards. To this end, we introduce WorFBench, a unified workflowgeneration benchmark with multi-faceted scenarios and intricate graph workflowstructures. Additionally, we present WorFEval, a systemic evaluation protocolutilizing subsequence and subgraph matching algorithms to accurately quantifythe LLM agent's workflow generation capabilities. Through comprehensiveevaluations across different types of LLMs, we discover distinct gaps betweenthe sequence planning capabilities and graph planning capabilities of LLMagents, with even GPT-4 exhibiting a gap of around 15%. We also train twoopen-source models and evaluate their generalization abilities on held-outtasks. Furthermore, we observe that the generated workflows can enhancedownstream tasks, enabling them to achieve superior performance with less timeduring inference. Code and dataset are available athttps://github.com/zjunlp/WorFBench.</description><author>Shuofei Qiao, Runnan Fang, Zhisong Qiu, Xiaobin Wang, Ningyu Zhang, Yong Jiang, Pengjun Xie, Fei Huang, Huajun Chen</author><pubDate>Wed, 30 Oct 2024 14:49:49 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.07869v2</guid></item><item><title>Multi-Programming Language Sandbox for LLMs</title><link>http://arxiv.org/abs/2410.23074v1</link><description>We introduce MPLSandbox, an out-of-the-box multi-programming language sandboxdesigned to provide unified and comprehensive feedback from compiler andanalysis tools for Large Language Models (LLMs). It can automatically identifythe programming language of the code, compiling and executing it within anisolated sub-sandbox to ensure safety and stability. In addition, MPLSandboxalso integrates both traditional and LLM-based code analysis tools, providing acomprehensive analysis of generated code. MPLSandbox can be effortlesslyintegrated into the training and deployment of LLMs to improve the quality andcorrectness of their generated code. It also helps researchers streamline theirworkflows for various LLM-based code-related tasks, reducing the developmentcost. To validate the effectiveness of MPLSandbox, we integrate it intotraining and deployment approaches, and also employ it to optimize workflowsfor a wide range of real-world code-related tasks. Our goal is to enhanceresearcher productivity on LLM-based code-related tasks by simplifying andautomating workflows through delegation to MPLSandbox.</description><author>Shihan Dou, Jiazheng Zhang, Jianxiang Zang, Yunbo Tao, Haoxiang Jia, Shichun Liu, Yuming Yang, Shenxi Wu, Shaoqing Zhang, Muling Wu, Changze Lv, Limao Xiong, Wenyu Zhan, Lin Zhang, Rongxiang Weng, Jingang Wang, Xunliang Cai, Yueming Wu, Ming Wen, Rui Zheng, Tao Ji, Yixin Cao, Tao Gui, Xipeng Qiu, Qi Zhang, Xuanjing Huang</author><pubDate>Wed, 30 Oct 2024 14:46:43 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.23074v1</guid></item><item><title>RSNet: A Light Framework for The Detection of Multi-scale Remote Sensing Targets</title><link>http://arxiv.org/abs/2410.23073v1</link><description>Recent developments in synthetic aperture radar (SAR) ship detection haveseen deep learning techniques achieve remarkable progress in accuracy andspeed. However, the detection of small targets against complex backgroundsremains a significant challenge. To tackle these difficulties, this letterpresents RSNet, a lightweight framework aimed at enhancing ship detectioncapabilities in SAR imagery. RSNet features the Waveletpool-ContextGuided (WCG)backbone for enhanced accuracy with fewer parameters, and theWaveletpool-StarFusion (WSF) head for efficient parameter reduction.Additionally, a Lightweight-Shared (LS) module minimizes the detection head'sparameter load. Experiments on the SAR Ship Detection Dataset (SSDD) andHigh-Resolution SAR Image Dataset (HRSID) demonstrate that RSNet achieves astrong balance between lightweight design and detection performance, surpassingmany state-of-the-art detectors, reaching 72.5\% and 67.6\% in\textbf{\(\mathbf{mAP_{.50:95}}\) }respectively with 1.49M parameters. Our codewill be released soon.</description><author>Hongyu Chen, Chengcheng Chen, Fei Wang, Yuhu Shi, Weiming Zeng</author><pubDate>Wed, 30 Oct 2024 14:46:35 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.23073v1</guid></item><item><title>CNN Explainability with Multivector Tucker Saliency Maps for Self-Supervised Models</title><link>http://arxiv.org/abs/2410.23072v1</link><description>Interpreting the decisions of Convolutional Neural Networks (CNNs) isessential for understanding their behavior, yet explainability remains asignificant challenge, particularly for self-supervised models. Most existingmethods for generating saliency maps rely on ground truth labels, restrictingtheir use to supervised tasks. EigenCAM is the only notable label-independentalternative, leveraging Singular Value Decomposition to generate saliency mapsapplicable across CNN models, but it does not fully exploit the tensorialstructure of feature maps. In this work, we introduce the Tucker Saliency Map(TSM) method, which applies Tucker tensor decomposition to better capture theinherent structure of feature maps, producing more accurate singular vectorsand values. These are used to generate high-fidelity saliency maps, effectivelyhighlighting objects of interest in the input. We further extend EigenCAM andTSM into multivector variants -Multivec-EigenCAM and Multivector TuckerSaliency Maps (MTSM)- which utilize all singular vectors and values, furtherimproving saliency map quality. Quantitative evaluations on supervisedclassification models demonstrate that TSM, Multivec-EigenCAM, and MTSM achievecompetitive performance with label-dependent methods. Moreover, TSM enhancesexplainability by approximately 50% over EigenCAM for both supervised andself-supervised models. Multivec-EigenCAM and MTSM further advancestate-of-the-art explainability performance on self-supervised models, withMTSM achieving the best results.</description><author>Aymene Mohammed Bouayed, Samuel Deslauriers-Gauthier, Adrian Iaccovelli, David Naccache</author><pubDate>Wed, 30 Oct 2024 14:46:34 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.23072v1</guid></item><item><title>MiniPLM: Knowledge Distillation for Pre-Training Language Models</title><link>http://arxiv.org/abs/2410.17215v2</link><description>Knowledge distillation (KD) is widely used to train small, high-performingstudent language models (LMs) using large teacher LMs. While effective infine-tuning, KD during pre-training faces challenges in efficiency,flexibility, and effectiveness. Existing methods either incur highcomputational costs due to online teacher inference, require tokenizationmatching between teacher and student LMs, or risk losing the difficulty anddiversity of the teacher-generated training data. To address these issues, wepropose MiniPLM, a KD framework for pre-training LMs by refining the trainingdata distribution with the teacher's knowledge. For efficiency, MiniPLMperforms offline teacher LM inference, allowing KD for multiple student LMswithout adding training-time costs. For flexibility, MiniPLM operates solely onthe training corpus, enabling KD across model families. For effectiveness,MiniPLM leverages the differences between large and small LMs to enhance thedifficulty and diversity of the training data, helping student LMs acquireversatile and sophisticated knowledge. Extensive experiments demonstrate thatMiniPLM boosts the student LMs' performance on 9 widely used downstream tasks,improves the language modeling capabilities, and reduces pre-trainingcomputation. The benefit of MiniPLM extends to large pre-training scales,evidenced by the extrapolation of the scaling curves. Further analysis revealsthat MiniPLM supports KD across model families and enhances the utilization ofpre-training data. Our model, code, and data are available athttps://github.com/thu-coai/MiniPLM.</description><author>Yuxian Gu, Hao Zhou, Fandong Meng, Jie Zhou, Minlie Huang</author><pubDate>Wed, 30 Oct 2024 14:45:26 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.17215v2</guid></item><item><title>LLMs Integration in Software Engineering Team Projects: Roles, Impact, and a Pedagogical Design Space for AI Tools in Computing Education</title><link>http://arxiv.org/abs/2410.23069v1</link><description>This work takes a pedagogical lens to explore the implications of generativeAI (GenAI) models and tools, such as ChatGPT and GitHub Copilot, in asemester-long 2nd-year undergraduate Software Engineering Team Project.Qualitative findings from survey (39 students) and interviews (eight students)provide insights into the students' views on the impact of GenAI use on theircoding experience, learning, and self-efficacy. Our results address aparticular gap in understanding the role and implications of GenAI on teamwork,team-efficacy, and team dynamics. The analysis of the learning aspects isdistinguished by the application of learning and pedagogy informed lenses todiscuss the data. We propose a preliminary design space for GenAI-basedprogramming learning tools highlighting the importance of considering the rolesthat GenAI can play during the learning process, the varying support-abilitypatterns that can be applied to each role, and the importance of supportingtransparency in GenAI for team members and students in addition to educators.</description><author>Ahmed Kharrufa, Sami Alghamdi, Abeer Aziz, Christopher Bull</author><pubDate>Wed, 30 Oct 2024 14:43:33 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.23069v1</guid></item><item><title>Don't Just Pay Attention, PLANT It: Transfer L2R Models to Fine-tune Attention in Extreme Multi-Label Text Classification</title><link>http://arxiv.org/abs/2410.23066v1</link><description>State-of-the-art Extreme Multi-Label Text Classification (XMTC) models relyheavily on multi-label attention layers to focus on key tokens in input text,but obtaining optimal attention weights is challenging and resource-intensive.To address this, we introduce PLANT -- Pretrained and Leveraged AtteNTion -- anovel transfer learning strategy for fine-tuning XMTC decoders. PLANT surpassesexisting state-of-the-art methods across all metrics on mimicfull, mimicfifty,mimicfour, eurlex, and wikiten datasets. It particularly excels in few-shotscenarios, outperforming previous models specifically designed for few-shotscenarios by over 50 percentage points in F1 scores on mimicrare and by over 36percentage points on mimicfew, demonstrating its superior capability inhandling rare codes. PLANT also shows remarkable data efficiency in few-shotscenarios, achieving precision comparable to traditional models withsignificantly less data. These results are achieved through key technicalinnovations: leveraging a pretrained Learning-to-Rank model as the plantedattention layer, integrating mutual-information gain to enhance attention,introducing an inattention mechanism, and implementing a stateful-decoder tomaintain context. Comprehensive ablation studies validate the importance ofthese contributions in realizing the performance gains.</description><author>Debjyoti Saharoy, Javed A. Aslam, Virgil Pavlu</author><pubDate>Wed, 30 Oct 2024 14:41:23 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.23066v1</guid></item><item><title>Full Event Particle-Level Unfolding with Variable-Length Latent Variational Diffusion</title><link>http://arxiv.org/abs/2404.14332v2</link><description>The measurements performed by particle physics experiments must account forthe imperfect response of the detectors used to observe the interactions. Oneapproach, unfolding, statistically adjusts the experimental data for detectoreffects. Recently, generative machine learning models have shown promise forperforming unbinned unfolding in a high number of dimensions. However, allcurrent generative approaches are limited to unfolding a fixed set ofobservables, making them unable to perform full-event unfolding in the variabledimensional environment of collider data. A novel modification to thevariational latent diffusion model (VLD) approach to generative unfolding ispresented, which allows for unfolding of high- and variable-dimensional featurespaces. The performance of this method is evaluated in the context ofsemi-leptonic top quark pair production at the Large Hadron Collider.</description><author>Alexander Shmakov, Kevin Greif, Michael James Fenton, Aishik Ghosh, Pierre Baldi, Daniel Whiteson</author><pubDate>Wed, 30 Oct 2024 14:39:15 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.14332v2</guid></item><item><title>Certified Minimax Unlearning with Generalization Rates and Deletion Capacity</title><link>http://arxiv.org/abs/2312.10336v2</link><description>We study the problem of $(\epsilon,\delta)$-certified machine unlearning forminimax models. Most of the existing works focus on unlearning from standardstatistical learning models that have a single variable and their unlearningsteps hinge on the direct Hessian-based conventional Newton update. We developa new $(\epsilon,\delta)$-certified machine unlearning algorithm for minimaxmodels. It proposes a minimax unlearning step consisting of atotal-Hessian-based complete Newton update and the Gaussian mechanism borrowedfrom differential privacy. To obtain the unlearning certification, our methodinjects calibrated Gaussian noises by carefully analyzing the "sensitivity" ofthe minimax unlearning step (i.e., the closeness between the minimax unlearningvariables and the retraining-from-scratch variables). We derive thegeneralization rates in terms of population strong and weak primal-dual riskfor three different cases of loss functions, i.e.,(strongly-)convex-(strongly-)concave losses. We also provide the deletioncapacity to guarantee that a desired population risk can be maintained as longas the number of deleted samples does not exceed the derived amount. Withtraining samples $n$ and model dimension $d$, it yields the order $\mathcalO(n/d^{1/4})$, which shows a strict gap over the baseline method ofdifferentially private minimax learning that has $\mathcal O(n/d^{1/2})$. Inaddition, our rates of generalization and deletion capacity match thestate-of-the-art rates derived previously for standard statistical learningmodels.</description><author>Jiaqi Liu, Jian Lou, Zhan Qin, Kui Ren</author><pubDate>Wed, 30 Oct 2024 14:37:32 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.10336v2</guid></item><item><title>Diffusion for World Modeling: Visual Details Matter in Atari</title><link>http://arxiv.org/abs/2405.12399v2</link><description>World models constitute a promising approach for training reinforcementlearning agents in a safe and sample-efficient manner. Recent world modelspredominantly operate on sequences of discrete latent variables to modelenvironment dynamics. However, this compression into a compact discreterepresentation may ignore visual details that are important for reinforcementlearning. Concurrently, diffusion models have become a dominant approach forimage generation, challenging well-established methods modeling discretelatents. Motivated by this paradigm shift, we introduce DIAMOND (DIffusion As aModel Of eNvironment Dreams), a reinforcement learning agent trained in adiffusion world model. We analyze the key design choices that are required tomake diffusion suitable for world modeling, and demonstrate how improved visualdetails can lead to improved agent performance. DIAMOND achieves a mean humannormalized score of 1.46 on the competitive Atari 100k benchmark; a new bestfor agents trained entirely within a world model. We further demonstrate thatDIAMOND's diffusion world model can stand alone as an interactive neural gameengine by training on static Counter-Strike: Global Offensive gameplay. Tofoster future research on diffusion for world modeling, we release our code,agents, videos and playable world models at https://diamond-wm.github.io.</description><author>Eloi Alonso, Adam Jelley, Vincent Micheli, Anssi Kanervisto, Amos Storkey, Tim Pearce, François Fleuret</author><pubDate>Wed, 30 Oct 2024 14:34:49 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.12399v2</guid></item><item><title>Predicting Molecular Ground-State Conformation via Conformation Optimization</title><link>http://arxiv.org/abs/2410.09795v2</link><description>Predicting ground-state conformation from the corresponding molecular graphis crucial for many chemical applications, such as molecular modeling,molecular docking, and molecular property prediction. Recently, manylearning-based methods have been proposed to replace time-consuming simulationsfor this task. However, these methods are often inefficient and sub-optimal asthey merely rely on molecular graph information to make predictions fromscratch. In this work, considering that molecular low-quality conformations arereadily available, we propose a novel framework called ConfOpt to predictmolecular ground-state conformation from the perspective of conformationoptimization. Specifically, ConfOpt takes the molecular graph and correspondinglow-quality 3D conformation as inputs, and then derives the ground-stateconformation by iteratively optimizing the low-quality conformation under theguidance of the molecular graph. During training, ConfOpt concurrentlyoptimizes the predicted atomic 3D coordinates and the corresponding interatomicdistances, resulting in a strong predictive model. Extensive experimentsdemonstrate that ConfOpt significantly outperforms existing methods, thusproviding a new paradigm for efficiently and accurately predicting molecularground-state conformation.</description><author>Fanmeng Wang, Minjie Cheng, Hongteng Xu</author><pubDate>Wed, 30 Oct 2024 14:33:37 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.09795v2</guid></item><item><title>Diff-A-Riff: Musical Accompaniment Co-creation via Latent Diffusion Models</title><link>http://arxiv.org/abs/2406.08384v2</link><description>Recent advancements in deep generative models present new opportunities formusic production but also pose challenges, such as high computational demandsand limited audio quality. Moreover, current systems frequently rely solely ontext input and typically focus on producing complete musical pieces, which isincompatible with existing workflows in music production. To address theseissues, we introduce "Diff-A-Riff," a Latent Diffusion Model designed togenerate high-quality instrumental accompaniments adaptable to any musicalcontext. This model offers control through either audio references, textprompts, or both, and produces 48kHz pseudo-stereo audio while significantlyreducing inference time and memory usage. We demonstrate the model'scapabilities through objective metrics and subjective listening tests, withextensive examples available on the accompanying website:sonycslparis.github.io/diffariff-companion/</description><author>Javier Nistal, Marco Pasini, Cyran Aouameur, Maarten Grachten, Stefan Lattner</author><pubDate>Wed, 30 Oct 2024 14:33:27 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.08384v2</guid></item><item><title>SECURE: Benchmarking Large Language Models for Cybersecurity</title><link>http://arxiv.org/abs/2405.20441v4</link><description>Large Language Models (LLMs) have demonstrated potential in cybersecurityapplications but have also caused lower confidence due to problems likehallucinations and a lack of truthfulness. Existing benchmarks provide generalevaluations but do not sufficiently address the practical and applied aspectsof LLM performance in cybersecurity-specific tasks. To address this gap, weintroduce the SECURE (Security Extraction, Understanding \&amp; ReasoningEvaluation), a benchmark designed to assess LLMs performance in realisticcybersecurity scenarios. SECURE includes six datasets focussed on theIndustrial Control System sector to evaluate knowledge extraction,understanding, and reasoning based on industry-standard sources. Our studyevaluates seven state-of-the-art models on these tasks, providing insights intotheir strengths and weaknesses in cybersecurity contexts, and offerrecommendations for improving LLMs reliability as cyber advisory tools.</description><author>Dipkamal Bhusal, Md Tanvirul Alam, Le Nguyen, Ashim Mahara, Zachary Lightcap, Rodney Frazier, Romy Fieblinger, Grace Long Torales, Benjamin A. Blakely, Nidhi Rastogi</author><pubDate>Wed, 30 Oct 2024 14:29:37 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.20441v4</guid></item><item><title>Improved Particle Approximation Error for Mean Field Neural Networks</title><link>http://arxiv.org/abs/2405.15767v3</link><description>Mean-field Langevin dynamics (MFLD) minimizes an entropy-regularizednonlinear convex functional defined over the space of probabilitydistributions. MFLD has gained attention due to its connection with noisygradient descent for mean-field two-layer neural networks. Unlike standardLangevin dynamics, the nonlinearity of the objective functional inducesparticle interactions, necessitating multiple particles to approximate thedynamics in a finite-particle setting. Recent works (Chen et al., 2022; Suzukiet al., 2023b) have demonstrated the uniform-in-time propagation of chaos forMFLD, showing that the gap between the particle system and its mean-field limituniformly shrinks over time as the number of particles increases. In this work,we improve the dependence on logarithmic Sobolev inequality (LSI) constants intheir particle approximation errors, which can exponentially deteriorate withthe regularization coefficient. Specifically, we establish an LSI-constant-freeparticle approximation error concerning the objective gap by leveraging theproblem structure in risk minimization. As the application, we demonstrateimproved convergence of MFLD, sampling guarantee for the mean-field stationarydistribution, and uniform-in-time Wasserstein propagation of chaos in terms ofparticle complexity.</description><author>Atsushi Nitanda</author><pubDate>Wed, 30 Oct 2024 14:24:34 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.15767v3</guid></item><item><title>Measuring Progress in Dictionary Learning for Language Model Interpretability with Board Game Models</title><link>http://arxiv.org/abs/2408.00113v2</link><description>What latent features are encoded in language model (LM) representations?Recent work on training sparse autoencoders (SAEs) to disentangle interpretablefeatures in LM representations has shown significant promise. However,evaluating the quality of these SAEs is difficult because we lack aground-truth collection of interpretable features that we expect good SAEs torecover. We thus propose to measure progress in interpretable dictionarylearning by working in the setting of LMs trained on chess and Othellotranscripts. These settings carry natural collections of interpretable features-- for example, "there is a knight on F3" -- which we leverage into$\textit{supervised}$ metrics for SAE quality. To guide progress ininterpretable dictionary learning, we introduce a new SAE training technique,$\textit{p-annealing}$, which improves performance on prior unsupervisedmetrics as well as our new metrics.</description><author>Adam Karvonen, Benjamin Wright, Can Rager, Rico Angell, Jannik Brinkmann, Logan Smith, Claudio Mayrink Verdun, David Bau, Samuel Marks</author><pubDate>Wed, 30 Oct 2024 14:21:59 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.00113v2</guid></item><item><title>Controlling Language and Diffusion Models by Transporting Activations</title><link>http://arxiv.org/abs/2410.23054v1</link><description>The increasing capabilities of large generative models and their ever morewidespread deployment have raised concerns about their reliability, safety, andpotential misuse. To address these issues, recent works have proposed tocontrol model generation by steering model activations in order to effectivelyinduce or prevent the emergence of concepts or behaviors in the generatedoutput. In this paper we introduce Activation Transport (AcT), a generalframework to steer activations guided by optimal transport theory thatgeneralizes many previous activation-steering works. AcT is modality-agnosticand provides fine-grained control over the model behavior with negligiblecomputational overhead, while minimally impacting model abilities. Weexperimentally show the effectiveness and versatility of our approach byaddressing key challenges in large language models (LLMs) and text-to-imagediffusion models (T2Is). For LLMs, we show that AcT can effectively mitigatetoxicity, induce arbitrary concepts, and increase their truthfulness. In T2Is,we show how AcT enables fine-grained style control and concept negation.</description><author>Pau Rodriguez, Arno Blaas, Michal Klein, Luca Zappella, Nicholas Apostoloff, Marco Cuturi, Xavier Suau</author><pubDate>Wed, 30 Oct 2024 14:21:33 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.23054v1</guid></item><item><title>Generating Code World Models with Large Language Models Guided by Monte Carlo Tree Search</title><link>http://arxiv.org/abs/2405.15383v2</link><description>In this work we consider Code World Models, world models generated by a LargeLanguage Model (LLM) in the form of Python code for model-based ReinforcementLearning (RL). Calling code instead of LLMs for planning has potential to bemore precise, reliable, interpretable, and extremely efficient. However,writing appropriate Code World Models requires the ability to understandcomplex instructions, to generate exact code with non-trivial logic and toself-debug a long program with feedback from unit tests and environmenttrajectories. To address these challenges, we propose Generate, Improve and Fixwith Monte Carlo Tree Search (GIF-MCTS), a new code generation strategy forLLMs. To test our approach in an offline RL setting, we introduce the CodeWorld Models Benchmark (CWMB), a suite of program synthesis and planning taskscomprised of 18 diverse RL environments paired with corresponding textualdescriptions and curated trajectories. GIF-MCTS surpasses all baselines on theCWMB and two other benchmarks, and we show that the Code World Modelssynthesized with it can be successfully used for planning, resulting inmodel-based RL agents with greatly improved sample efficiency and inferencespeed.</description><author>Nicola Dainese, Matteo Merler, Minttu Alakuijala, Pekka Marttinen</author><pubDate>Wed, 30 Oct 2024 14:19:57 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.15383v2</guid></item><item><title>Reward Centering</title><link>http://arxiv.org/abs/2405.09999v2</link><description>We show that discounted methods for solving continuing reinforcement learningproblems can perform significantly better if they center their rewards bysubtracting out the rewards' empirical average. The improvement is substantialat commonly used discount factors and increases further as the discount factorapproaches one. In addition, we show that if a problem's rewards are shifted bya constant, then standard methods perform much worse, whereas methods withreward centering are unaffected. Estimating the average reward isstraightforward in the on-policy setting; we propose a slightly moresophisticated method for the off-policy setting. Reward centering is a generalidea, so we expect almost every reinforcement-learning algorithm to benefit bythe addition of reward centering.</description><author>Abhishek Naik, Yi Wan, Manan Tomar, Richard S. Sutton</author><pubDate>Wed, 30 Oct 2024 14:18:42 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.09999v2</guid></item><item><title>Spectral Graph Pruning Against Over-Squashing and Over-Smoothing</title><link>http://arxiv.org/abs/2404.04612v2</link><description>Message Passing Graph Neural Networks are known to suffer from two problemsthat are sometimes believed to be diametrically opposed: over-squashing andover-smoothing. The former results from topological bottlenecks that hamper theinformation flow from distant nodes and are mitigated by spectral gapmaximization, primarily, by means of edge additions. However, such additionsoften promote over-smoothing that renders nodes of different classes lessdistinguishable. Inspired by the Braess phenomenon, we argue that deletingedges can address over-squashing and over-smoothing simultaneously. Thisinsight explains how edge deletions can improve generalization, thus connectingspectral gap optimization to a seemingly disconnected objective of reducingcomputational resources by pruning graphs for lottery tickets. To this end, wepropose a more effective spectral gap optimization framework to add or deleteedges and demonstrate its effectiveness on large heterophilic datasets.</description><author>Adarsh Jamadandi, Celia Rubio-Madrigal, Rebekka Burkholz</author><pubDate>Wed, 30 Oct 2024 14:17:02 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.04612v2</guid></item><item><title>PromptExp: Multi-granularity Prompt Explanation of Large Language Models</title><link>http://arxiv.org/abs/2410.13073v3</link><description>Large Language Models excel in tasks like natural language understanding andtext generation. Prompt engineering plays a critical role in leveraging LLMeffectively. However, LLMs black-box nature hinders its interpretability andeffective prompting engineering. A wide range of model explanation approacheshave been developed for deep learning models, However, these local explanationsare designed for single-output tasks like classification and regression,andcannot be directly applied to LLMs, which generate sequences of tokens. Recentefforts in LLM explanation focus on natural language explanations, but they areprone to hallucinations and inaccuracies. To address this, we introducePromptExp , a framework for multi-granularity prompt explanations byaggregating token-level insights. PromptExp introduces two token-levelexplanation approaches: 1. an aggregation-based approach combining localexplanation techniques, and 2. a perturbation-based approach with noveltechniques to evaluate token masking impact. PromptExp supports both white-boxand black-box explanations and extends explanations to higher granularitylevels, enabling flexible analysis. We evaluate PromptExp in case studies suchas sentiment analysis, showing the perturbation-based approach performs bestusing semantic similarity to assess perturbation impact. Furthermore, weconducted a user study to confirm PromptExp's accuracy and practical value, anddemonstrate its potential to enhance LLM interpretability.</description><author>Ximing Dong, Shaowei Wang, Dayi Lin, Gopi Krishnan Rajbahadur, Boquan Zhou, Shichao Liu, Ahmed E. Hassan</author><pubDate>Wed, 30 Oct 2024 14:15:49 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.13073v3</guid></item><item><title>Legitimate ground-truth-free metrics for deep uncertainty classification scoring</title><link>http://arxiv.org/abs/2410.23046v1</link><description>Despite the increasing demand for safer machine learning practices, the useof Uncertainty Quantification (UQ) methods in production remains limited. Thislimitation is exacerbated by the challenge of validating UQ methods in absenceof UQ ground truth. In classification tasks, when only a usual set of test datais at hand, several authors suggested different metrics that can be computedfrom such test points while assessing the quality of quantified uncertainties.This paper investigates such metrics and proves that they are theoreticallywell-behaved and actually tied to some uncertainty ground truth which is easilyinterpretable in terms of model prediction trustworthiness ranking. Equippedwith those new results, and given the applicability of those metrics in theusual supervised paradigm, we argue that our contributions will help promotinga broader use of UQ in deep learning.</description><author>Arthur Pignet, Chiara Regniez, John Klein</author><pubDate>Wed, 30 Oct 2024 14:14:32 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.23046v1</guid></item><item><title>Response Estimation and System Identification of Dynamical Systems via Physics-Informed Neural Networks</title><link>http://arxiv.org/abs/2410.01340v2</link><description>The accurate modelling of structural dynamics is crucial across numerousengineering applications, such as Structural Health Monitoring (SHM), seismicanalysis, and vibration control. Often, these models originate fromphysics-based principles and can be derived from corresponding governingequations, often of differential equation form. However, complex systemcharacteristics, such as nonlinearities and energy dissipation mechanisms,often imply that such models are approximative and often imprecise. Thischallenge is further compounded in SHM, where sensor data is often sparse,making it difficult to fully observe the system's states. To address theseissues, this paper explores the use of Physics-Informed Neural Networks(PINNs), a class of physics-enhanced machine learning (PEML) techniques, forthe identification and estimation of dynamical systems. PINNs offer a uniqueadvantage by embedding known physical laws directly into the neural network'sloss function, allowing for simple embedding of complex phenomena, even in thepresence of uncertainties. This study specifically investigates three keyapplications of PINNs: state estimation in systems with sparse sensing, jointstate-parameter estimation, when both system response and parameters areunknown, and parameter estimation within a Bayesian framework to quantifyuncertainties. The results demonstrate that PINNs deliver an efficient toolacross all aforementioned tasks, even in presence of modelling errors. However,these errors tend to have a more significant impact on parameter estimation, asthe optimization process must reconcile discrepancies between the prescribedmodel and the true system behavior. Despite these challenges, PINNs showpromise in dynamical system modeling, offering a robust approach to handlinguncertainties.</description><author>Marcus Haywood-Alexander, Giacomo Arcieri, Antonios Kamariotis, Eleni Chatzi</author><pubDate>Wed, 30 Oct 2024 14:10:21 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.01340v2</guid></item><item><title>Toward Understanding In-context vs. In-weight Learning</title><link>http://arxiv.org/abs/2410.23042v1</link><description>It has recently been demonstrated empirically that in-context learningemerges in transformers when certain distributional properties are present inthe training data, but this ability can also diminish upon further training. Weprovide a new theoretical understanding of these phenomena by identifyingsimplified distributional properties that give rise to the emergence andeventual disappearance of in-context learning. We do so by first analyzing asimplified model that uses a gating mechanism to choose between an in-weightand an in-context predictor. Through a combination of a generalization errorand regret analysis we identify conditions where in-context and in-weightlearning emerge. These theoretical findings are then corroboratedexperimentally by comparing the behaviour of a full transformer on thesimplified distributions to that of the stylized model, demonstrating alignedresults. We then extend the study to a full large language model, showing howfine-tuning on various collections of natural language prompts can elicitsimilar in-context and in-weight learning behaviour.</description><author>Bryan Chan, Xinyi Chen, András György, Dale Schuurmans</author><pubDate>Wed, 30 Oct 2024 14:09:00 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.23042v1</guid></item><item><title>Emotional RAG: Enhancing Role-Playing Agents through Emotional Retrieval</title><link>http://arxiv.org/abs/2410.23041v1</link><description>As LLMs exhibit a high degree of human-like capability, increasing attentionhas been paid to role-playing research areas in which responses generated byLLMs are expected to mimic human replies. This has promoted the exploration ofrole-playing agents in various applications, such as chatbots that can engagein natural conversations with users and virtual assistants that can providepersonalized support and guidance. The crucial factor in the role-playing taskis the effective utilization of character memory, which stores characters'profiles, experiences, and historical dialogues. Retrieval Augmented Generation(RAG) technology is used to access the related memory to enhance the responsegeneration of role-playing agents. Most existing studies retrieve relatedinformation based on the semantic similarity of memory to maintain characters'personalized traits, and few attempts have been made to incorporate theemotional factor in the retrieval argument generation (RAG) of LLMs. Inspiredby the Mood-Dependent Memory theory, which indicates that people recall anevent better if they somehow reinstate during recall the original emotion theyexperienced during learning, we propose a novel emotion-aware memory retrievalframework, termed Emotional RAG, which recalls the related memory withconsideration of emotional state in role-playing agents. Specifically, wedesign two kinds of retrieval strategies, i.e., combination strategy andsequential strategy, to incorporate both memory semantic and emotional statesduring the retrieval process. Extensive experiments on three representativerole-playing datasets demonstrate that our Emotional RAG framework outperformsthe method without considering the emotional factor in maintaining thepersonalities of role-playing agents. This provides evidence to furtherreinforce the Mood-Dependent Memory theory in psychology.</description><author>Le Huang, Hengzhi Lan, Zijun Sun, Chuan Shi, Ting Bai</author><pubDate>Wed, 30 Oct 2024 14:08:50 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.23041v1</guid></item><item><title>Neural Attention Field: Emerging Point Relevance in 3D Scenes for One-Shot Dexterous Grasping</title><link>http://arxiv.org/abs/2410.23039v1</link><description>One-shot transfer of dexterous grasps to novel scenes with object and contextvariations has been a challenging problem. While distilled feature fields fromlarge vision models have enabled semantic correspondences across 3D scenes,their features are point-based and restricted to object surfaces, limitingtheir capability of modeling complex semantic feature distributions forhand-object interactions. In this work, we propose the \textit{neural attentionfield} for representing semantic-aware dense feature fields in the 3D space bymodeling inter-point relevance instead of individual point features. Core to itis a transformer decoder that computes the cross-attention between any 3D querypoint with all the scene points, and provides the query point feature with anattention-based aggregation. We further propose a self-supervised framework fortraining the transformer decoder from only a few 3D pointclouds without handdemonstrations. Post-training, the attention field can be applied to novelscenes for semantics-aware dexterous grasping from one-shot demonstration.Experiments show that our method provides better optimization landscapes byencouraging the end-effector to focus on task-relevant scene regions, resultingin significant improvements in success rates on real robots compared with thefeature-field-based methods.</description><author>Qianxu Wang, Congyue Deng, Tyler Ga Wei Lum, Yuanpei Chen, Yaodong Yang, Jeannette Bohg, Yixin Zhu, Leonidas Guibas</author><pubDate>Wed, 30 Oct 2024 14:06:51 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.23039v1</guid></item><item><title>Do LLMs "know" internally when they follow instructions?</title><link>http://arxiv.org/abs/2410.14516v4</link><description>Instruction-following is crucial for building AI agents with large languagemodels (LLMs), as these models must adhere strictly to user-providedconstraints and guidelines. However, LLMs often fail to follow even simple andclear instructions. To improve instruction-following behavior and preventundesirable outputs, a deeper understanding of how LLMs' internal states relateto these outcomes is required. Our analysis of LLM internal states reveal adimension in the input embedding space linked to successfulinstruction-following. We demonstrate that modifying representations along thisdimension improves instruction-following success rates compared to randomchanges, without compromising response quality. Further investigation revealsthat this dimension is more closely related to the phrasing of prompts ratherthan the inherent difficulty of the task or instructions. This discovery alsosuggests explanations for why LLMs sometimes fail to follow clear instructionsand why prompt engineering is often effective, even when the content remainslargely unchanged. This work provides insight into the internal workings ofLLMs' instruction-following, paving the way for reliable LLM agents.</description><author>Juyeon Heo, Christina Heinze-Deml, Oussama Elachqar, Shirley Ren, Udhay Nallasamy, Andy Miller, Kwan Ho Ryan Chan, Jaya Narain</author><pubDate>Wed, 30 Oct 2024 14:06:12 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.14516v4</guid></item><item><title>Advanced Detection of Source Code Clones via an Ensemble of Unsupervised Similarity Measures</title><link>http://arxiv.org/abs/2405.02095v2</link><description>The capability of accurately determining code similarity is crucial in manytasks related to software development. For example, it might be essential toidentify code duplicates for performing software maintenance. This researchintroduces a novel ensemble learning approach for code similarity assessment,combining the strengths of multiple unsupervised similarity measures. The keyidea is that the strengths of a diverse set of similarity measures cancomplement each other and mitigate individual weaknesses, leading to improvedperformance. Preliminary results show that while Transformers-based CodeBERTand its variant GraphCodeBERT are undoubtedly the best option in the presenceof abundant training data, in the case of specific small datasets (up to 500samples), our ensemble achieves similar results, without prejudice to theinterpretability of the resulting solution, and with a much lower associatedcarbon footprint due to training. The source code of this novel approach can bedownloaded from https://github.com/jorge-martinez-gil/ensemble-codesim.</description><author>Jorge Martinez-Gil</author><pubDate>Wed, 30 Oct 2024 14:01:43 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.02095v2</guid></item><item><title>Offline Reinforcement Learning and Sequence Modeling for Downlink Link Adaptation</title><link>http://arxiv.org/abs/2410.23031v1</link><description>Contemporary radio access networks employ link adaption (LA) algorithms tooptimize the modulation and coding schemes to adapt to the prevailingpropagation conditions and are near-optimal in terms of the achieved spectralefficiency. LA is a challenging task in the presence of mobility, fast fading,and imperfect channel quality information and limited knowledge of the receivercharacteristics at the transmitter, which render model-based LA algorithmscomplex and suboptimal. Model-based LA is especially difficult as connecteduser equipment devices become increasingly heterogeneous in terms of receivercapabilities, antenna configurations and hardware characteristics. Recognizingthese difficulties, previous works have proposed reinforcement learning (RL)for LA, which faces deployment difficulties due to their potential negativeimpacts on live performance. To address this challenge, this paper considersoffline RL to learn LA policies from data acquired in live networks withminimal or no intrusive effects on the network operation. We propose three LAdesigns based on batch-constrained deep Q-learning, conservative Q-learning,and decision transformers, showing that offline RL algorithms can achieveperformance of state-of-the-art online RL methods when data is collected with aproper behavioral policy.</description><author>Samuele Peri, Alessio Russo, Gabor Fodor, Pablo Soldati</author><pubDate>Wed, 30 Oct 2024 14:01:31 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.23031v1</guid></item><item><title>Planning and Learning in Risk-Aware Restless Multi-Arm Bandit Problem</title><link>http://arxiv.org/abs/2410.23029v1</link><description>In restless multi-arm bandits, a central agent is tasked with optimallydistributing limited resources across several bandits (arms), with each armbeing a Markov decision process. In this work, we generalize the traditionalrestless multi-arm bandit problem with a risk-neutral objective byincorporating risk-awareness. We establish indexability conditions for the caseof a risk-aware objective and provide a solution based on Whittle index. Inaddition, we address the learning problem when the true transitionprobabilities are unknown by proposing a Thompson sampling approach and showthat it achieves bounded regret that scales sublinearly with the number ofepisodes and quadratically with the number of arms. The efficacy of our methodin reducing risk exposure in restless multi-arm bandits is illustrated througha set of numerical experiments.</description><author>Nima Akbarzadeh, Erick Delage, Yossiri Adulyasak</author><pubDate>Wed, 30 Oct 2024 13:59:30 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.23029v1</guid></item><item><title>Imprecise Label Learning: A Unified Framework for Learning with Various Imprecise Label Configurations</title><link>http://arxiv.org/abs/2305.12715v4</link><description>Learning with reduced labeling standards, such as noisy label, partial label,and multiple label candidates, which we generically refer to as\textit{imprecise} labels, is a commonplace challenge in machine learningtasks. Previous methods tend to propose specific designs for every emergingimprecise label configuration, which is usually unsustainable when multipleconfigurations of imprecision coexist. In this paper, we introduce impreciselabel learning (ILL), a framework for the unification of learning with variousimprecise label configurations. ILL leverages expectation-maximization (EM) formodeling the imprecise label information, treating the precise labels as latentvariables.Instead of approximating the correct labels for training, itconsiders the entire distribution of all possible labeling entailed by theimprecise information. We demonstrate that ILL can seamlessly adapt to partiallabel learning, semi-supervised learning, noisy label learning, and, moreimportantly, a mixture of these settings. Notably, ILL surpasses the existingspecified techniques for handling imprecise labels, marking the first unifiedframework with robust and effective performance across various challengingsettings. We hope our work will inspire further research on this topic,unleashing the full potential of ILL in wider scenarios where precise labelsare expensive and complicated to obtain.</description><author>Hao Chen, Ankit Shah, Jindong Wang, Ran Tao, Yidong Wang, Xing Xie, Masashi Sugiyama, Rita Singh, Bhiksha Raj</author><pubDate>Wed, 30 Oct 2024 13:58:35 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.12715v4</guid></item><item><title>Learning Dynamic Selection and Pricing of Out-of-Home Deliveries</title><link>http://arxiv.org/abs/2311.13983v3</link><description>Home delivery failures, traffic congestion, and relatively large handlingtimes have a negative impact on the profitability of last-mile logistics. Apotential solution is the delivery to parcel lockers or parcel shops, denotedby out-of-home (OOH) delivery. In the academic literature, models for OOHdelivery were so far limited to static settings, contrasting with thesequential nature of the problem. We model the sequential decision-makingproblem of which OOH location to offer against what incentive for each incomingcustomer, taking into account future customer arrivals and choices. We proposeDynamic Selection and Pricing of OOH (DSPO), an algorithmic pipeline that usesa novel spatial-temporal state encoding as input to a convolutional neuralnetwork. We demonstrate the performance of our method by benchmarking itagainst two state-of-the-art approaches. Our extensive numerical study, guidedby real-world data, reveals that DSPO can save 19.9%pt in costs compared to asituation without OOH locations, 7%pt compared to a static selection andpricing policy, and 3.8%pt compared to a state-of-the-art demand managementbenchmark. We provide comprehensive insights into the complex interplay betweenOOH delivery dynamics and customer behavior influenced by pricing strategies.The implications of our findings suggest practitioners to adopt dynamicselection and pricing policies.</description><author>Fabian Akkerman, Peter Dieter, Martijn Mes</author><pubDate>Wed, 30 Oct 2024 13:56:21 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.13983v3</guid></item><item><title>On Unsupervised Partial Shape Correspondence</title><link>http://arxiv.org/abs/2310.14692v3</link><description>While dealing with matching shapes to their parts, we often apply a toolknown as functional maps. The idea is to translate the shape matching probleminto "convenient" spaces by which matching is performed algebraically bysolving a least squares problem. Here, we argue that such formulations, thoughpopular in this field, introduce errors in the estimated match when partialityis invoked. Such errors are unavoidable even for advanced feature extractionnetworks, and they can be shown to escalate with increasing degrees of shapepartiality, adversely affecting the learning capability of such systems. Tocircumvent these limitations, we propose a novel approach for partial shapematching. Our study of functional maps led us to a novel method thatestablishes direct correspondence between partial and full shapes throughfeature matching bypassing the need for functional map intermediate spaces. TheGromov Distance between metric spaces leads to the construction of the firstpart of our loss functions. For regularization we use two options: a term basedon the area preserving property of the mapping, and a relaxed version thatavoids the need to resort to functional maps. The proposed approach showssuperior performance on the SHREC'16 dataset, outperforming existingunsupervised methods for partial shape matching.Notably, it achievesstate-of-the-art results on the SHREC'16 HOLES benchmark, superior alsocompared to supervised methods. We demonstrate the benefits of the proposedunsupervised method when applied to a new dataset PFAUST for part-to-full shapecorrespondence.</description><author>Amit Bracha, Thomas Dagès, Ron Kimmel</author><pubDate>Wed, 30 Oct 2024 13:55:46 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.14692v3</guid></item><item><title>On the stability of gradient descent with second order dynamics for time-varying cost functions</title><link>http://arxiv.org/abs/2405.13765v2</link><description>Gradient based optimization algorithms deployed in Machine Learning (ML)applications are often analyzed and compared by their convergence rates orregret bounds. While these rates and bounds convey valuable information theydon't always directly translate to stability guarantees. Stability and similarconcepts, like robustness, will become ever more important as we move towardsdeploying models in real-time and safety critical systems. In this work webuild upon the results in Gaudio et al. 2021 and Moreu &amp; Annaswamy 2022 forgradient descent with second order dynamics when applied to explicitly timevarying cost functions and provide more general stability guarantees. Thesemore general results can aid in the design and certification of theseoptimization schemes so as to help ensure safe and reliable deployment forreal-time learning applications. We also hope that the techniques provided herewill stimulate and cross-fertilize the analysis that occurs on the samealgorithms from the online learning and stochastic optimization communities.</description><author>Travis E. Gibson, Sawal Acharya, Anjali Parashar, Joseph E. Gaudio, Anurdha M. Annaswamy</author><pubDate>Wed, 30 Oct 2024 13:55:03 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.13765v2</guid></item></channel></rss>