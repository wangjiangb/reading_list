<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/"><channel><title>Arxivfresh papers</title><link></link><description>Arxiv paper</description><language>en-US</language><lastBuildDate>Thu, 18 Jul 2024 13:00:12 GMT</lastBuildDate><generator>rfeed v1.0.0</generator><docs>https://github.com/svpino/rfeed/blob/master/README.md</docs><item><title>AgentPoison: Red-teaming LLM Agents via Poisoning Memory or Knowledge Bases</title><link>http://arxiv.org/abs/2407.12784v1</link><description>LLM agents have demonstrated remarkable performance across variousapplications, primarily due to their advanced capabilities in reasoning,utilizing external knowledge and tools, calling APIs, and executing actions tointeract with environments. Current agents typically utilize a memory module ora retrieval-augmented generation (RAG) mechanism, retrieving past knowledge andinstances with similar embeddings from knowledge bases to inform task planningand execution. However, the reliance on unverified knowledge bases raisessignificant concerns about their safety and trustworthiness. To uncover suchvulnerabilities, we propose a novel red teaming approach AgentPoison, the firstbackdoor attack targeting generic and RAG-based LLM agents by poisoning theirlong-term memory or RAG knowledge base. In particular, we form the triggergeneration process as a constrained optimization to optimize backdoor triggersby mapping the triggered instances to a unique embedding space, so as to ensurethat whenever a user instruction contains the optimized backdoor trigger, themalicious demonstrations are retrieved from the poisoned memory or knowledgebase with high probability. In the meantime, benign instructions without thetrigger will still maintain normal performance. Unlike conventional backdoorattacks, AgentPoison requires no additional model training or fine-tuning, andthe optimized backdoor trigger exhibits superior transferability, in-contextcoherence, and stealthiness. Extensive experiments demonstrate AgentPoison'seffectiveness in attacking three types of real-world LLM agents: RAG-basedautonomous driving agent, knowledge-intensive QA agent, and healthcareEHRAgent. On each agent, AgentPoison achieves an average attack success ratehigher than 80% with minimal impact on benign performance (less than 1%) with apoison rate less than 0.1%.</description><author>Zhaorun Chen, Zhen Xiang, Chaowei Xiao, Dawn Song, Bo Li</author><pubDate>Wed, 17 Jul 2024 17:59:47 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.12784v1</guid></item><item><title>SMooDi: Stylized Motion Diffusion Model</title><link>http://arxiv.org/abs/2407.12783v1</link><description>We introduce a novel Stylized Motion Diffusion model, dubbed SMooDi, togenerate stylized motion driven by content texts and style motion sequences.Unlike existing methods that either generate motion of various content ortransfer style from one sequence to another, SMooDi can rapidly generate motionacross a broad range of content and diverse styles. To this end, we tailor apre-trained text-to-motion model for stylization. Specifically, we proposestyle guidance to ensure that the generated motion closely matches thereference style, alongside a lightweight style adaptor that directs the motiontowards the desired style while ensuring realism. Experiments across variousapplications demonstrate that our proposed framework outperforms existingmethods in stylized motion generation.</description><author>Lei Zhong, Yiming Xie, Varun Jampani, Deqing Sun, Huaizu Jiang</author><pubDate>Wed, 17 Jul 2024 17:59:42 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.12783v1</guid></item><item><title>Contrastive Adversarial Training for Unsupervised Domain Adaptation</title><link>http://arxiv.org/abs/2407.12782v1</link><description>Domain adversarial training has shown its effective capability for findingdomain invariant feature representations and been successfully adopted forvarious domain adaptation tasks. However, recent advances of large models(e.g., vision transformers) and emerging of complex adaptation scenarios (e.g.,DomainNet) make adversarial training being easily biased towards source domainand hardly adapted to target domain. The reason is twofold: relying on largeamount of labelled data from source domain for large model training and lackingof labelled data from target domain for fine-tuning. Existing approaches widelyfocused on either enhancing discriminator or improving the training stabilityfor the backbone networks. Due to unbalanced competition between the featureextractor and the discriminator during the adversarial training, existingsolutions fail to function well on complex datasets. To address this issue, weproposed a novel contrastive adversarial training (CAT) approach that leveragesthe labeled source domain samples to reinforce and regulate the featuregeneration for target domain. Typically, the regulation forces the targetfeature distribution being similar to the source feature distribution. CATaddressed three major challenges in adversarial learning: 1) ensure the featuredistributions from two domains as indistinguishable as possible for thediscriminator, resulting in a more robust domain-invariant feature generation;2) encourage target samples moving closer to the source in the feature space,reducing the requirement for generalizing classifier trained on the labeledsource domain to unlabeled target domain; 3) avoid directly aligning unpairedsource and target samples within mini-batch. CAT can be easily plugged intoexisting models and exhibits significant performance improvements.</description><author>Jiahong Chen, Zhilin Zhang, Lucy Li, Behzad Shahrasbi, Arjun Mishra</author><pubDate>Wed, 17 Jul 2024 17:59:21 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.12782v1</guid></item><item><title>VD3D: Taming Large Video Diffusion Transformers for 3D Camera Control</title><link>http://arxiv.org/abs/2407.12781v1</link><description>Modern text-to-video synthesis models demonstrate coherent, photorealisticgeneration of complex videos from a text description. However, most existingmodels lack fine-grained control over camera movement, which is critical fordownstream applications related to content creation, visual effects, and 3Dvision. Recently, new methods demonstrate the ability to generate videos withcontrollable camera poses these techniques leverage pre-trained U-Net-baseddiffusion models that explicitly disentangle spatial and temporal generation.Still, no existing approach enables camera control for new, transformer-basedvideo diffusion models that process spatial and temporal information jointly.Here, we propose to tame video transformers for 3D camera control using aControlNet-like conditioning mechanism that incorporates spatiotemporal cameraembeddings based on Plucker coordinates. The approach demonstratesstate-of-the-art performance for controllable video generation afterfine-tuning on the RealEstate10K dataset. To the best of our knowledge, ourwork is the first to enable camera control for transformer-based videodiffusion models.</description><author>Sherwin Bahmani, Ivan Skorokhodov, Aliaksandr Siarohin, Willi Menapace, Guocheng Qian, Michael Vasilkovsky, Hsin-Ying Lee, Chaoyang Wang, Jiaxu Zou, Andrea Tagliasacchi, David B. Lindell, Sergey Tulyakov</author><pubDate>Wed, 17 Jul 2024 17:59:05 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.12781v1</guid></item><item><title>Generalizable Human Gaussians for Sparse View Synthesis</title><link>http://arxiv.org/abs/2407.12777v1</link><description>Recent progress in neural rendering has brought forth pioneering methods,such as NeRF and Gaussian Splatting, which revolutionize view rendering acrossvarious domains like AR/VR, gaming, and content creation. While these methodsexcel at interpolating {\em within the training data}, the challenge ofgeneralizing to new scenes and objects from very sparse views persists.Specifically, modeling 3D humans from sparse views presents formidable hurdlesdue to the inherent complexity of human geometry, resulting in inaccuratereconstructions of geometry and textures. To tackle this challenge, this paperleverages recent advancements in Gaussian Splatting and introduces a new methodto learn generalizable human Gaussians that allows photorealistic and accurateview-rendering of a new human subject from a limited set of sparse views in afeed-forward manner. A pivotal innovation of our approach involvesreformulating the learning of 3D Gaussian parameters into a regression processdefined on the 2D UV space of a human template, which allows leveraging thestrong geometry prior and the advantages of 2D convolutions. In addition, amulti-scaffold is proposed to effectively represent the offset details. Ourmethod outperforms recent methods on both within-dataset generalization as wellas cross-dataset generalization settings.</description><author>Youngjoong Kwon, Baole Fang, Yixing Lu, Haoye Dong, Cheng Zhang, Francisco Vicente Carrasco, Albert Mosella-Montoro, Jianjin Xu, Shingo Takagi, Daeil Kim, Aayush Prakash, Fernando De la Torre</author><pubDate>Wed, 17 Jul 2024 17:56:30 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.12777v1</guid></item><item><title>OMG-Net: A Deep Learning Framework Deploying Segment Anything to Detect Pan-Cancer Mitotic Figures from Haematoxylin and Eosin-Stained Slides</title><link>http://arxiv.org/abs/2407.12773v1</link><description>Mitotic activity is an important feature for grading several cancer types.Counting mitotic figures (MFs) is a time-consuming, laborious task prone tointer-observer variation. Inaccurate recognition of MFs can lead to incorrectgrading and hence potential suboptimal treatment. In this study, we propose anartificial intelligence (AI)-aided approach to detect MFs in digitisedhaematoxylin and eosin-stained whole slide images (WSIs). Advances in this areaare hampered by the limited number and types of cancer datasets of MFs. Here weestablish the largest pan-cancer dataset of mitotic figures by combining anin-house dataset of soft tissue tumours (STMF) with five open-source mitoticdatasets comprising multiple human cancers and canine specimens (ICPR, TUPAC,CCMCT, CMC and MIDOG++). This new dataset identifies 74,620 MFs and 105,538mitotic-like figures. We then employed a two-stage framework (the OptimisedMitoses Generator Network (OMG-Net) to classify MFs. The framework firstdeploys the Segment Anything Model (SAM) to automate the contouring of MFs andsurrounding objects. An adapted ResNet18 is subsequently trained to classifyMFs. OMG-Net reaches an F1-score of 0.84 on pan-cancer MF detection (breastcarcinoma, neuroendocrine tumour and melanoma), largely outperforming theprevious state-of-the-art MIDOG++ benchmark model on its hold-out testing set(e.g. +16% F1-score on breast cancer detection, p&lt;0.001) thereby providingsuperior accuracy in detecting MFs on various types of tumours obtained withdifferent scanners.</description><author>Zhuoyan Shen, Mikael Simard, Douglas Brand, Vanghelita Andrei, Ali Al-Khader, Fatine Oumlil, Katherine Trevers, Thomas Butters, Simon Haefliger, Eleanna Kara, Fernanda Amary, Roberto Tirabosco, Paul Cool, Gary Royle, Maria A. Hawkins, Adrienne M. Flanagan, Charles-Antoine Collins Fekete</author><pubDate>Wed, 17 Jul 2024 17:53:37 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.12773v1</guid></item><item><title>Beyond Viewpoint: Robust 3D Object Recognition under Arbitrary Views through Joint Multi-Part Representation</title><link>http://arxiv.org/abs/2407.03842v2</link><description>Existing view-based methods excel at recognizing 3D objects from predefinedviewpoints, but their exploration of recognition under arbitrary views islimited. This is a challenging and realistic setting because each object hasdifferent viewpoint positions and quantities, and their poses are not aligned.However, most view-based methods, which aggregate multiple view features toobtain a global feature representation, hard to address 3D object recognitionunder arbitrary views. Due to the unaligned inputs from arbitrary views, it ischallenging to robustly aggregate features, leading to performance degradation.In this paper, we introduce a novel Part-aware Network (PANet), which is apart-based representation, to address these issues. This part-basedrepresentation aims to localize and understand different parts of 3D objects,such as airplane wings and tails. It has properties such as viewpointinvariance and rotation robustness, which give it an advantage in addressingthe 3D object recognition problem under arbitrary views. Our results onbenchmark datasets clearly demonstrate that our proposed method outperformsexisting view-based aggregation baselines for the task of 3D object recognitionunder arbitrary views, even surpassing most fixed viewpoint methods.</description><author>Linlong Fan, Ye Huang, Yanqi Ge, Wen Li, Lixin Duan</author><pubDate>Wed, 17 Jul 2024 17:52:05 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.03842v2</guid></item><item><title>LMMs-Eval: Reality Check on the Evaluation of Large Multimodal Models</title><link>http://arxiv.org/abs/2407.12772v1</link><description>The advances of large foundation models necessitate wide-coverage, low-cost,and zero-contamination benchmarks. Despite continuous exploration of languagemodel evaluations, comprehensive studies on the evaluation of Large Multi-modalModels (LMMs) remain limited. In this work, we introduce LMMS-EVAL, a unifiedand standardized multimodal benchmark framework with over 50 tasks and morethan 10 models to promote transparent and reproducible evaluations. AlthoughLMMS-EVAL offers comprehensive coverage, we find it still falls short inachieving low cost and zero contamination. To approach this evaluationtrilemma, we further introduce LMMS-EVAL LITE, a pruned evaluation toolkit thatemphasizes both coverage and efficiency. Additionally, we present MultimodalLIVEBENCH that utilizes continuously updating news and online forums to assessmodels' generalization abilities in the wild, featuring a low-cost andzero-contamination evaluation approach. In summary, our work highlights theimportance of considering the evaluation trilemma and provides practicalsolutions to navigate the trade-offs in evaluating large multi-modal models,paving the way for more effective and reliable benchmarking of LMMs. Weopensource our codebase and maintain leaderboard of LIVEBENCH athttps://github.com/EvolvingLMMs-Lab/lmms-eval andhttps://huggingface.co/spaces/lmms-lab/LiveBench.</description><author>Kaichen Zhang, Bo Li, Peiyuan Zhang, Fanyi Pu, Joshua Adrian Cahyono, Kairui Hu, Shuai Liu, Yuanhan Zhang, Jingkang Yang, Chunyuan Li, Ziwei Liu</author><pubDate>Wed, 17 Jul 2024 17:51:53 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.12772v1</guid></item><item><title>The Role of Network and Identity in the Diffusion of Hashtags</title><link>http://arxiv.org/abs/2407.12771v1</link><description>Although the spread of behaviors is influenced by many social factors,existing literature tends to study the effects of single factors -- most often,properties of the social network -- on the final cascade. In order to movetowards a more integrated view of cascades, this paper offers the firstcomprehensive investigation into the role of two social factors in thediffusion of 1,337 popular hashtags representing the production of novelculture on Twitter: 1) the topology of the Twitter social network and 2)performance of each user's probable demographic identity. Here, we show thatcascades are best modeled using a combination of network and identity, ratherthan either factor alone. This combined model best reproduces a composite indexof ten cascade properties across all 1,337 hashtags. However, there isimportant heterogeneity in what social factors are required to reproducedifferent properties of hashtag cascades. For instance, while a combinednetwork+identity model best predicts the popularity of cascades, a network-onlymodel has better performance in predicting cascade growth and an identity-onlymodel in adopter composition. We are able to predict what type of hashtag isbest modeled by each combination of features and use this to further improveperformance. Additionally, consistent with prior literature on the combinednetwork+identity model most outperforms the single-factor counterfactuals amonghashtags used for expressing racial or regional identity, stance-taking,talking about sports, or variants of existing cultural trends with very slow-or fast-growing communicative need. In sum, our results imply the utility ofmulti-factor models in predicting cascades, in order to account for the variedways in which network, identity, and other social factors play a role in thediffusion of hashtags on Twitter.</description><author>Aparna Ananthasubramaniam, Yufei Zhu, David Jurgens, Daniel Romero</author><pubDate>Wed, 17 Jul 2024 17:51:49 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.12771v1</guid></item><item><title>Can You Learn Semantics Through Next-Word Prediction? The Case of Entailment</title><link>http://arxiv.org/abs/2402.13956v3</link><description>Do LMs infer the semantics of text from co-occurrence patterns in theirtraining data? Merrill et al. (2022) argue that, in theory, sentenceco-occurrence probabilities predicted by an optimal LM should reflect theentailment relationship of the constituent sentences, but it is unclear whetherprobabilities predicted by neural LMs encode entailment in this way because ofstrong assumptions made by Merrill et al. (namely, that humans always avoidredundancy). In this work, we investigate whether their theory can be used todecode entailment relations from neural LMs. We find that a test similar totheirs can decode entailment relations between natural sentences, well aboverandom chance, though not perfectly, across many datasets and LMs. Thissuggests LMs implicitly model aspects of semantics to predict semantic effectson sentence co-occurrence patterns. However, we find the test that predictsentailment in practice works in the opposite direction to the theoretical test.We thus revisit the assumptions underlying the original test, finding itsderivation did not adequately account for redundancy in human-written text. Weargue that better accounting for redundancy related to explanations mightderive the observed flipped test and, more generally, improve computationalmodels of speakers in linguistics.</description><author>William Merrill, Zhaofeng Wu, Norihito Naka, Yoon Kim, Tal Linzen</author><pubDate>Wed, 17 Jul 2024 17:49:42 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.13956v3</guid></item><item><title>Jigsaw Game: Federated Clustering</title><link>http://arxiv.org/abs/2407.12764v1</link><description>Federated learning has recently garnered significant attention, especiallywithin the domain of supervised learning. However, despite the abundance ofunlabeled data on end-users, unsupervised learning problems such as clusteringin the federated setting remain underexplored. In this paper, we investigatethe federated clustering problem, with a focus on federated k-means. We outlinethe challenge posed by its non-convex objective and data heterogeneity in thefederated framework. To tackle these challenges, we adopt a new perspective bystudying the structures of local solutions in k-means and propose a one-shotalgorithm called FeCA (Federated Centroid Aggregation). FeCA adaptively refineslocal solutions on clients, then aggregates these refined solutions to recoverthe global solution of the entire dataset in a single round. We empiricallydemonstrate the robustness of FeCA under various federated scenarios on bothsynthetic and real-world data. Additionally, we extend FeCA to representationlearning and present DeepFeCA, which combines DeepCluster and FeCA forunsupervised feature learning in the federated setting.</description><author>Jinxuan Xu, Hong-You Chen, Wei-Lun Chao, Yuqian Zhang</author><pubDate>Wed, 17 Jul 2024 17:42:25 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.12764v1</guid></item><item><title>On the Effect of (Near) Duplicate Subwords in Language Modelling</title><link>http://arxiv.org/abs/2404.06508v3</link><description>Tokenisation is a core part of language models (LMs). It involves splitting acharacter sequence into subwords which are assigned arbitrary indices beforebeing served to the LM. While typically lossless, however, this process maylead to less sample efficient LM training: as it removes character-levelinformation, it could make it harder for LMs to generalise across similarsubwords, such as now and Now. We refer to such subwords as near duplicates. Inthis paper, we study the impact of near duplicate subwords on LM trainingefficiency. First, we design an experiment that gives us an upper bound to howmuch we should expect a model to improve if we could perfectly generaliseacross near duplicates. We do this by duplicating each subword in our LM'svocabulary, creating perfectly equivalent classes of subwords. Experimentally,we find that LMs need roughly 17% more data when trained in a fully duplicatedsetting. Second, we investigate the impact of naturally occurring nearduplicates on LMs. Here, we see that merging them considerably hurts LMperformance. Therefore, although subword duplication negatively impacts LMtraining efficiency, naturally occurring near duplicates may not be as similaras anticipated, limiting the potential for performance improvements.</description><author>Anton Schäfer, Thomas Hofmann, Imanol Schlag, Tiago Pimentel</author><pubDate>Wed, 17 Jul 2024 17:39:39 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.06508v3</guid></item><item><title>A survey and taxonomy of methods interpreting random forest models</title><link>http://arxiv.org/abs/2407.12759v1</link><description>The interpretability of random forest (RF) models is a research topic ofgrowing interest in the machine learning (ML) community. In the state of theart, RF is considered a powerful learning ensemble given its predictiveperformance, flexibility, and ease of use. Furthermore, the inner process ofthe RF model is understandable because it uses an intuitive and intelligibleapproach for building the RF decision tree ensemble. However, the RF resultingmodel is regarded as a "black box" because of its numerous deep decision trees.Gaining visibility over the entire process that induces the final decisions byexploring each decision tree is complicated, if not impossible. This complexitylimits the acceptance and implementation of RF models in several fields ofapplication. Several papers have tackled the interpretation of RF models. Thispaper aims to provide an extensive review of methods used in the literature tointerpret RF resulting models. We have analyzed these methods and classifiedthem based on different axes. Although this review is not exhaustive, itprovides a taxonomy of various techniques that should guide users in choosingthe most appropriate tools for interpreting RF models, depending on theinterpretability aspects sought. It should also be valuable for researchers whoaim to focus their work on the interpretability of RF or ML black boxes ingeneral.</description><author>Maissae Haddouchi, Abdelaziz Berrado</author><pubDate>Wed, 17 Jul 2024 17:33:32 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.12759v1</guid></item><item><title>Mutual Information Guided Optimal Transport for Unsupervised Visible-Infrared Person Re-identification</title><link>http://arxiv.org/abs/2407.12758v1</link><description>Unsupervised visible infrared person re-identification (USVI-ReID) is achallenging retrieval task that aims to retrieve cross-modality pedestrianimages without using any label information. In this task, the largecross-modality variance makes it difficult to generate reliable cross-modalitylabels, and the lack of annotations also provides additional difficulties forlearning modality-invariant features. In this paper, we first deduce anoptimization objective for unsupervised VI-ReID based on the mutual informationbetween the model's cross-modality input and output. With equivalentderivation, three learning principles, i.e., "Sharpness" (entropyminimization), "Fairness" (uniform label distribution), and "Fitness" (reliablecross-modality matching) are obtained. Under their guidance, we design a loopiterative training strategy alternating between model training andcross-modality matching. In the matching stage, a uniform prior guided optimaltransport assignment ("Fitness", "Fairness") is proposed to select matchedvisible and infrared prototypes. In the training stage, we utilize thismatching information to introduce prototype-based contrastive learning forminimizing the intra- and cross-modality entropy ("Sharpness"). Extensiveexperimental results on benchmarks demonstrate the effectiveness of our method,e.g., 60.6% and 90.3% of Rank-1 accuracy on SYSU-MM01 and RegDB without anyannotations.</description><author>Zhizhong Zhang, Jiangming Wang, Xin Tan, Yanyun Qu, Junping Wang, Yong Xie, Yuan Xie</author><pubDate>Wed, 17 Jul 2024 17:32:07 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.12758v1</guid></item><item><title>AI Control: Improving Safety Despite Intentional Subversion</title><link>http://arxiv.org/abs/2312.06942v4</link><description>As large language models (LLMs) become more powerful and are deployed moreautonomously, it will be increasingly important to prevent them from causingharmful outcomes. Researchers have investigated a variety of safety techniquesfor this purpose, e.g. using models to review the outputs of other models, orred-teaming techniques to surface subtle failure modes. However, researchershave not evaluated whether such techniques still ensure safety if the model isitself intentionally trying to subvert them. In this paper, we develop andevaluate pipelines of safety techniques ("protocols") that are robust tointentional subversion. We investigate a scenario in which we want to solve a sequence of programmingproblems, using access to a powerful but untrusted model (in our case, GPT-4),access to a less powerful trusted model (in our case, GPT-3.5), and limitedaccess to high-quality trusted labor. We investigate protocols that aim tonever submit solutions containing backdoors, which we operationalize here aslogical errors that are not caught by test cases. We investigate a range of protocols and test each against strategies that theuntrusted model could use to subvert them. One protocol is what we call trustedediting. This protocol first asks GPT-4 to write code, and then asks GPT-3.5 torate the suspiciousness of that code. If the code is below some suspiciousnessthreshold, it is submitted. Otherwise, GPT-3.5 edits the solution to removeparts that seem suspicious and then submits the edited code. Another protocolis untrusted monitoring. This protocol asks GPT-4 to write code, and then asksanother instance of GPT-4 whether the code is backdoored, using varioustechniques to prevent the GPT-4 instances from colluding. These protocolsimprove substantially on simple baselines.</description><author>Ryan Greenblatt, Buck Shlegeris, Kshitij Sachan, Fabien Roger</author><pubDate>Wed, 17 Jul 2024 17:29:41 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.06942v4</guid></item><item><title>LAB-Bench: Measuring Capabilities of Language Models for Biology Research</title><link>http://arxiv.org/abs/2407.10362v3</link><description>There is widespread optimism that frontier Large Language Models (LLMs) andLLM-augmented systems have the potential to rapidly accelerate scientificdiscovery across disciplines. Today, many benchmarks exist to measure LLMknowledge and reasoning on textbook-style science questions, but few if anybenchmarks are designed to evaluate language model performance on practicaltasks required for scientific research, such as literature search, protocolplanning, and data analysis. As a step toward building such benchmarks, weintroduce the Language Agent Biology Benchmark (LAB-Bench), a broad dataset ofover 2,400 multiple choice questions for evaluating AI systems on a range ofpractical biology research capabilities, including recall and reasoning overliterature, interpretation of figures, access and navigation of databases, andcomprehension and manipulation of DNA and protein sequences. Importantly, incontrast to previous scientific benchmarks, we expect that an AI system thatcan achieve consistently high scores on the more difficult LAB-Bench taskswould serve as a useful assistant for researchers in areas such as literaturesearch and molecular cloning. As an initial assessment of the emergentscientific task capabilities of frontier language models, we measureperformance of several against our benchmark and report results compared tohuman expert biology researchers. We will continue to update and expandLAB-Bench over time, and expect it to serve as a useful tool in the developmentof automated research systems going forward. A public subset of LAB-Bench isavailable for use at the following URL:https://huggingface.co/datasets/futurehouse/lab-bench</description><author>Jon M. Laurent, Joseph D. Janizek, Michael Ruzo, Michaela M. Hinks, Michael J. Hammerling, Siddharth Narayanan, Manvitha Ponnapati, Andrew D. White, Samuel G. Rodriques</author><pubDate>Wed, 17 Jul 2024 17:28:36 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.10362v3</guid></item><item><title>Minimum discrepancy principle strategy for choosing $k$ in $k$-NN regression</title><link>http://arxiv.org/abs/2008.08718v8</link><description>We present a novel data-driven strategy to choose the hyperparameter $k$ inthe $k$-NN regression estimator without using any hold-out data. We treat theproblem of choosing the hyperparameter as an iterative procedure (over $k$) andpropose using an easily implemented in practice strategy based on the idea ofearly stopping and the minimum discrepancy principle. This model selectionstrategy is proven to be minimax-optimal over some smoothness function classes,for instance, the Lipschitz functions class on a bounded domain. The novelmethod often improves statistical performance on artificial and real-world datasets in comparison to other model selection strategies, such as the Hold-outmethod, 5-fold cross-validation, and AIC criterion. The novelty of the strategycomes from reducing the computational time of the model selection procedurewhile preserving the statistical (minimax) optimality of the resultingestimator. More precisely, given a sample of size $n$, if one should choose $k$among $\left\{ 1, \ldots, n \right\}$, and $\left\{ f^1, \ldots, f^n \right\}$are the estimators of the regression function, the minimum discrepancyprinciple requires the calculation of a fraction of the estimators, while thisis not the case for the generalized cross-validation, Akaike's AIC criteria, orLepskii principle.</description><author>Yaroslav Averyanov, Alain Celisse</author><pubDate>Wed, 17 Jul 2024 17:28:01 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2008.08718v8</guid></item><item><title>LookupViT: Compressing visual information to a limited number of tokens</title><link>http://arxiv.org/abs/2407.12753v1</link><description>Vision Transformers (ViT) have emerged as the de-facto choice for numerousindustry grade vision solutions. But their inference cost can be prohibitivefor many settings, as they compute self-attention in each layer which suffersfrom quadratic computational complexity in the number of tokens. On the otherhand, spatial information in images and spatio-temporal information in videosis usually sparse and redundant. In this work, we introduce LookupViT, thataims to exploit this information sparsity to reduce ViT inference cost.LookupViT provides a novel general purpose vision transformer block thatoperates by compressing information from higher resolution tokens to a fixednumber of tokens. These few compressed tokens undergo meticulous processing,while the higher-resolution tokens are passed through computationally cheaperlayers. Information sharing between these two token sets is enabled through abidirectional cross-attention mechanism. The approach offers multipleadvantages - (a) easy to implement on standard ML accelerators (GPUs/TPUs) viastandard high-level operators, (b) applicable to standard ViT and its variants,thus generalizes to various tasks, (c) can handle different tokenization andattention approaches. LookupViT also offers flexibility for the compressedtokens, enabling performance-computation trade-offs in a single trained model.We show LookupViT's effectiveness on multiple domains - (a) forimage-classification (ImageNet-1K and ImageNet-21K), (b) video classification(Kinetics400 and Something-Something V2), (c) image captioning (COCO-Captions)with a frozen encoder. LookupViT provides $2\times$ reduction in FLOPs whileupholding or improving accuracy across these domains. In addition, LookupViTalso demonstrates out-of-the-box robustness and generalization on imageclassification (ImageNet-C,R,A,O), improving by up to $4\%$ over ViT.</description><author>Rajat Koner, Gagan Jain, Prateek Jain, Volker Tresp, Sujoy Paul</author><pubDate>Wed, 17 Jul 2024 17:22:43 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.12753v1</guid></item><item><title>Scalable Monte Carlo for Bayesian Learning</title><link>http://arxiv.org/abs/2407.12751v1</link><description>This book aims to provide a graduate-level introduction to advanced topics inMarkov chain Monte Carlo (MCMC) algorithms, as applied broadly in the Bayesiancomputational context. Most, if not all of these topics (stochastic gradientMCMC, non-reversible MCMC, continuous time MCMC, and new techniques forconvergence assessment) have emerged as recently as the last decade, and havedriven substantial recent practical and theoretical advances in the field. Aparticular focus is on methods that are scalable with respect to either theamount of data, or the data dimension, motivated by the emerging high-priorityapplication areas in machine learning and AI.</description><author>Paul Fearnhead, Christopher Nemeth, Chris J. Oates, Chris Sherlock</author><pubDate>Wed, 17 Jul 2024 17:19:56 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.12751v1</guid></item><item><title>HDLCopilot: Hardware Design Library Querying with Natural Language</title><link>http://arxiv.org/abs/2407.12749v1</link><description>Hardware design engineers routinely work with multiple Process Design Kits(PDKs) from various fabrication labs, each containing several standard celllibraries, optimized for specific metric such as speed, power, or density.These libraries include multiple views such as liberty files for timinginformation, LEF files for abstract layout details, and technology LEF forprocess design rules. Navigating this complex landscape to retrieve specificinformation about gates or design rules is often time-consuming anderror-prone. To address this, we present HDLCopilot, an LLM-powered PDK querysystem that allows engineers to streamline interactions with PDKs in naturallanguage format, making information retrieval accurate and more efficient.HDLCopilot achieves an accuracy of 94.23\% on an evaluation set comprised ofdiverse and complex natural language queries. HDLCopilot positions itself as apowerful assistant in the hardware design process, enhancing productivity andreducing potential human errors.</description><author>Manar Abdelatty, Sherief Reda</author><pubDate>Wed, 17 Jul 2024 17:11:13 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.12749v1</guid></item><item><title>DiverseDream: Diverse Text-to-3D Synthesis with Augmented Text Embedding</title><link>http://arxiv.org/abs/2312.02192v2</link><description>Text-to-3D synthesis has recently emerged as a new approach to sampling 3Dmodels by adopting pretrained text-to-image models as guiding visual priors. Anintriguing but underexplored problem with existing text-to-3D methods is that3D models obtained from the sampling-by-optimization procedure tend to havemode collapses, and hence poor diversity in their results. In this paper, weprovide an analysis and identify potential causes of such a limited diversity,which motivates us to devise a new method that considers the joint generationof different 3D models from the same text prompt. We propose to use augmentedtext prompts via textual inversion of reference images to diversify the jointgeneration. We show that our method leads to improved diversity in text-to-3Dsynthesis qualitatively and quantitatively. Project page:https://diversedream.github.io</description><author>Uy Dieu Tran, Minh Luu, Phong Ha Nguyen, Khoi Nguyen, Binh-Son Hua</author><pubDate>Wed, 17 Jul 2024 17:03:58 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.02192v2</guid></item><item><title>Learning in Deep Factor Graphs with Gaussian Belief Propagation</title><link>http://arxiv.org/abs/2311.14649v3</link><description>We propose an approach to do learning in Gaussian factor graphs. We treat allrelevant quantities (inputs, outputs, parameters, latents) as random variablesin a graphical model, and view both training and prediction as inferenceproblems with different observed nodes. Our experiments show that theseproblems can be efficiently solved with belief propagation (BP), whose updatesare inherently local, presenting exciting opportunities for distributed andasynchronous training. Our approach can be scaled to deep networks and providesa natural means to do continual learning: use the BP-estimated parametermarginals of the current task as parameter priors for the next. On a videodenoising task we demonstrate the benefit of learnable parameters over aclassical factor graph approach and we show encouraging performance of deepfactor graphs for continual image classification.</description><author>Seth Nabarro, Mark van der Wilk, Andrew J Davison</author><pubDate>Wed, 17 Jul 2024 17:03:50 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.14649v3</guid></item><item><title>On Stronger Computational Separations Between Multimodal and Unimodal Machine Learning</title><link>http://arxiv.org/abs/2404.02254v2</link><description>Recently, multimodal machine learning has enjoyed huge empirical success(e.g. GPT-4). Motivated to develop theoretical justification for this empiricalsuccess, Lu (NeurIPS '23, ALT '24) introduces a theory of multimodal learning,and considers possible \textit{separations} between theoretical models ofmultimodal and unimodal learning. In particular, Lu (ALT '24) shows acomputational separation, which is relevant to \textit{worst-case} instances ofthe learning task. In this paper, we give a stronger \textit{average-case}computational separation, where for ``typical'' instances of the learning task,unimodal learning is computationally hard, but multimodal learning is easy. Wethen question how ``natural'' the average-case separation is. Would it beencountered in practice? To this end, we prove that under basic conditions, anygiven computational separation between average-case unimodal and multimodallearning tasks implies a corresponding cryptographic key agreement protocol. Wesuggest to interpret this as evidence that very strong \textit{computational}advantages of multimodal learning may arise \textit{infrequently} in practice,since they exist only for the ``pathological'' case of inherently cryptographicdistributions. However, this does not apply to possible (super-polynomial)\textit{statistical} advantages.</description><author>Ari Karchmer</author><pubDate>Wed, 17 Jul 2024 17:01:45 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.02254v2</guid></item><item><title>Comparing Federated Stochastic Gradient Descent and Federated Averaging for Predicting Hospital Length of Stay</title><link>http://arxiv.org/abs/2407.12741v1</link><description>Predicting hospital length of stay (LOS) reliably is an essential need forefficient resource allocation at hospitals. Traditional predictive modelingtools frequently have difficulty acquiring sufficient and diverse data becausehealthcare institutions have privacy rules in place. In our study, we modeledthis problem as an empirical graph where nodes are the hospitals. This modelingapproach facilitates collaborative model training by modeling decentralizeddata sources from different hospitals without extracting sensitive data outsideof hospitals. A local model is trained on a node (hospital) by aiming thegeneralized total variation minimization (GTVMin). Moreover, we implemented andcompared two different federated learning optimization algorithms namedfederated stochastic gradient descent (FedSGD) and federated averaging(FedAVG). Our results show that federated learning enables accurate predictionof hospital LOS while addressing privacy concerns without extracting dataoutside healthcare institutions.</description><author>Mehmet Yigit Balik</author><pubDate>Wed, 17 Jul 2024 17:00:20 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.12741v1</guid></item><item><title>GroundUp: Rapid Sketch-Based 3D City Massing</title><link>http://arxiv.org/abs/2407.12739v1</link><description>We propose GroundUp, the first sketch-based ideation tool for 3D city massingof urban areas. We focus on early-stage urban design, where sketching is acommon tool and the design starts from balancing building volumes (masses) andopen spaces. With Human-Centered AI in mind, we aim to help architects quicklyrevise their ideas by easily switching between 2D sketches and 3D models,allowing for smoother iteration and sharing of ideas. Inspired by feedback fromarchitects and existing workflows, our system takes as a first input a usersketch of multiple buildings in a top-down view. The user then draws aperspective sketch of the envisioned site. Our method is designed to exploitthe complementarity of information in the two sketches and allows users toquickly preview and adjust the inferred 3D shapes. Our model has two maincomponents. First, we propose a novel sketch-to-depth prediction network forperspective sketches that exploits top-down sketch shapes. Second, we use depthcues derived from the perspective sketch as a condition to our diffusion model,which ultimately completes the geometry in a top-down view. Thus, our final 3Dgeometry is represented as a heightfield, allowing users to construct the city`from the ground up'.</description><author>Gizem Esra Unlu, Mohamed Sayed, Yulia Gryaditskaya, Gabriel Brostow</author><pubDate>Wed, 17 Jul 2024 16:59:29 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.12739v1</guid></item><item><title>The Role of Language Imbalance in Cross-lingual Generalisation: Insights from Cloned Language Experiments</title><link>http://arxiv.org/abs/2404.07982v4</link><description>Multilinguality is crucial for extending recent advancements in languagemodelling to diverse linguistic communities. To maintain high performance whilerepresenting multiple languages, multilingual models ideally alignrepresentations, allowing what is learned in one language to generalise toothers. Prior research has emphasised the importance of parallel data andshared vocabulary elements as key factors for such alignment. In this study, weinvestigate an unintuitive novel driver of cross-lingual generalisation:language imbalance. In controlled experiments on perfectly equivalent clonedlanguages, we observe that the existence of a predominant language duringtraining boosts the performance of less frequent languages and leads tostronger alignment of model representations across languages. Furthermore, wefind that this trend is amplified with scale: with large enough models or longenough training, we observe that bilingual training data with a 90/10 languagesplit yields better performance on both languages than a balanced 50/50 split.Building on these insights, we design training schemes that can improveperformance in all cloned languages, even without altering the training data.As we extend our analysis to real languages, we find that infrequent languagesstill benefit from frequent ones, yet whether language imbalance causescross-lingual generalisation there is not conclusive.</description><author>Anton Schäfer, Shauli Ravfogel, Thomas Hofmann, Tiago Pimentel, Imanol Schlag</author><pubDate>Wed, 17 Jul 2024 16:59:01 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.07982v4</guid></item><item><title>CaBaFL: Asynchronous Federated Learning via Hierarchical Cache and Feature Balance</title><link>http://arxiv.org/abs/2404.12850v2</link><description>Federated Learning (FL) as a promising distributed machine learning paradigmhas been widely adopted in Artificial Intelligence of Things (AIoT)applications. However, the efficiency and inference capability of FL isseriously limited due to the presence of stragglers and data imbalance acrossmassive AIoT devices, respectively. To address the above challenges, we presenta novel asynchronous FL approach named CaBaFL, which includes a hierarchicalCache-based aggregation mechanism and a feature Balance-guided device selectionstrategy. CaBaFL maintains multiple intermediate models simultaneously forlocal training. The hierarchical cache-based aggregation mechanism enables eachintermediate model to be trained on multiple devices to align the training timeand mitigate the straggler issue. In specific, each intermediate model isstored in a low-level cache for local training and when it is trained bysufficient local devices, it will be stored in a high-level cache foraggregation. To address the problem of imbalanced data, the featurebalance-guided device selection strategy in CaBaFL adopts the activationdistribution as a metric, which enables each intermediate model to be trainedacross devices with totally balanced data distributions before aggregation.Experimental results show that compared with the state-of-the-art FL methods,CaBaFL achieves up to 9.26X training acceleration and 19.71\% accuracyimprovements.</description><author>Zeke Xia, Ming Hu, Dengke Yan, Xiaofei Xie, Tianlin Li, Anran Li, Junlong Zhou, Mingsong Chen</author><pubDate>Wed, 17 Jul 2024 16:56:18 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.12850v2</guid></item><item><title>CHOSEN: Compilation to Hardware Optimization Stack for Efficient Vision Transformer Inference</title><link>http://arxiv.org/abs/2407.12736v1</link><description>Vision Transformers (ViTs) represent a groundbreaking shift in machinelearning approaches to computer vision. Unlike traditional approaches, ViTsemploy the self-attention mechanism, which has been widely used in naturallanguage processing, to analyze image patches. Despite their advantages inmodeling visual tasks, deploying ViTs on hardware platforms, notablyField-Programmable Gate Arrays (FPGAs), introduces considerable challenges.These challenges stem primarily from the non-linear calculations and highcomputational and memory demands of ViTs. This paper introduces CHOSEN, asoftware-hardware co-design framework to address these challenges and offer anautomated framework for ViT deployment on the FPGAs in order to maximizeperformance. Our framework is built upon three fundamental contributions:multi-kernel design to maximize the bandwidth, mainly targeting benefits ofmulti DDR memory banks, approximate non-linear functions that exhibit minimalaccuracy degradation, and efficient use of available logic blocks on the FPGA,and efficient compiler to maximize the performance and memory-efficiency of thecomputing kernels by presenting a novel algorithm for design space explorationto find optimal hardware configuration that achieves optimal throughput andlatency. Compared to the state-of-the-art ViT accelerators, CHOSEN achieves a1.5x and 1.42x improvement in the throughput on the DeiT-S and DeiT-B models.</description><author>Mohammad Erfan Sadeghi, Arash Fayyazi, Suhas Somashekar, Massoud Pedram</author><pubDate>Wed, 17 Jul 2024 16:56:06 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.12736v1</guid></item><item><title>EchoSight: Advancing Visual-Language Models with Wiki Knowledge</title><link>http://arxiv.org/abs/2407.12735v1</link><description>Knowledge-based Visual Question Answering (KVQA) tasks require answeringquestions about images using extensive background knowledge. Despitesignificant advancements, generative models often struggle with these tasks dueto the limited integration of external knowledge. In this paper, we introduceEchoSight, a novel multimodal Retrieval-Augmented Generation (RAG) frameworkthat enables large language models (LLMs) to answer visual questions requiringfine-grained encyclopedic knowledge. To strive for high-performing retrieval,EchoSight first searches wiki articles by using visual-only information,subsequently, these candidate articles are further reranked according to theirrelevance to the combined text-image query. This approach significantlyimproves the integration of multimodal knowledge, leading to enhanced retrievaloutcomes and more accurate VQA responses. Our experimental results on theEncyclopedic VQA and InfoSeek datasets demonstrate that EchoSight establishesnew state-of-the-art results in knowledge-based VQA, achieving an accuracy of41.8% on Encyclopedic VQA and 31.3% on InfoSeek.</description><author>Yibin Yan, Weidi Xie</author><pubDate>Wed, 17 Jul 2024 16:55:42 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.12735v1</guid></item><item><title>A LLM Benchmark based on the Minecraft Builder Dialog Agent Task</title><link>http://arxiv.org/abs/2407.12734v1</link><description>In this work we proposing adapting the Minecraft builder task into an LLMbenchmark suitable for evaluating LLM ability in spatially orientated tasks,and informing builder agent design. Previous works have proposed corpora withvarying complex structures, and human written instructions. We instead attemptto provide a comprehensive synthetic benchmark for testing builder agents overa series of distinct tasks that comprise of common building operations. Webelieve this approach allows us to probe specific strengths and weaknesses ofdifferent agents, and test the ability of LLMs in the challenging area ofspatial reasoning and vector based math.</description><author>Chris Madge, Massimo Poesio</author><pubDate>Wed, 17 Jul 2024 16:52:23 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.12734v1</guid></item><item><title>Learning a Sparse Neural Network using IHT</title><link>http://arxiv.org/abs/2404.18414v2</link><description>The core of a good model is in its ability to focus only on importantinformation that reflects the basic patterns and consistencies, thus pullingout a clear, noise-free signal from the dataset. This necessitates using asimplified model defined by fewer parameters. The importance of theoreticalfoundations becomes clear in this context, as this paper relies on establishedresults from the domain of advanced sparse optimization, particularly thoseaddressing nonlinear differentiable functions. The need for such theoreticalfoundations is further highlighted by the trend that as computational power fortraining NNs increases, so does the complexity of the models in terms of ahigher number of parameters. In practical scenarios, these large models areoften simplified to more manageable versions with fewer parameters. Understanding why these simplified models with less number of parametersremain effective raises a crucial question. Understanding why these simplifiedmodels with fewer parameters remain effective raises an important question.This leads to the broader question of whether there is a theoretical frameworkthat can clearly explain these empirical observations. Recent developments,such as establishing necessary conditions for the convergence of iterative hardthresholding (IHT) to a sparse local minimum (a sparse method analogous togradient descent) are promising. The remarkable capacity of the IHT algorithmto accurately identify and learn the locations of nonzero parametersunderscores its practical effectiveness and utility. This paper aims to investigate whether the theoretical prerequisites for suchconvergence are applicable in the realm of neural network (NN) training byproviding justification for all the necessary conditions for convergence. Then,these conditions are validated by experiments on a single-layer NN, using theIRIS dataset as a testbed.</description><author>Saeed Damadi, Soroush Zolfaghari, Mahdi Rezaie, Jinglai Shen</author><pubDate>Wed, 17 Jul 2024 16:51:36 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.18414v2</guid></item><item><title>Unlocking Textual and Visual Wisdom: Open-Vocabulary 3D Object Detection Enhanced by Comprehensive Guidance from Text and Image</title><link>http://arxiv.org/abs/2407.05256v2</link><description>Open-vocabulary 3D object detection (OV-3DDet) aims to localize and recognizeboth seen and previously unseen object categories within any new 3D scene.While language and vision foundation models have achieved success in handlingvarious open-vocabulary tasks with abundant training data, OV-3DDet faces asignificant challenge due to the limited availability of training data.Although some pioneering efforts have integrated vision-language models (VLM)knowledge into OV-3DDet learning, the full potential of these foundationalmodels has yet to be fully exploited. In this paper, we unlock the textual andvisual wisdom to tackle the open-vocabulary 3D detection task by leveraging thelanguage and vision foundation models. We leverage a vision foundation model toprovide image-wise guidance for discovering novel classes in 3D scenes.Specifically, we utilize a object detection vision foundation model to enablethe zero-shot discovery of objects in images, which serves as the initial seedsand filtering guidance to identify novel 3D objects. Additionally, to align the3D space with the powerful vision-language space, we introduce a hierarchicalalignment approach, where the 3D feature space is aligned with thevision-language feature space using a pre-trained VLM at the instance,category, and scene levels. Through extensive experimentation, we demonstratesignificant improvements in accuracy and generalization, highlighting thepotential of foundation models in advancing open-vocabulary 3D object detectionin real-world scenarios.</description><author>Pengkun Jiao, Na Zhao, Jingjing Chen, Yu-Gang Jiang</author><pubDate>Wed, 17 Jul 2024 16:50:09 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.05256v2</guid></item><item><title>RoDE: Linear Rectified Mixture of Diverse Experts for Food Large Multi-Modal Models</title><link>http://arxiv.org/abs/2407.12730v1</link><description>Large Multi-modal Models (LMMs) have significantly advanced a variety ofvision-language tasks. The scalability and availability of high-qualitytraining data play a pivotal role in the success of LMMs. In the realm of food,while comprehensive food datasets such as Recipe1M offer an abundance ofingredient and recipe information, they often fall short of providing ampledata for nutritional analysis. The Recipe1M+ dataset, despite offering a subsetfor nutritional evaluation, is limited in the scale and accuracy of nutritioninformation. To bridge this gap, we introduce Uni-Food, a unified food datasetthat comprises over 100,000 images with various food labels, includingcategories, ingredients, recipes, and ingredient-level nutritional information.Uni-Food is designed to provide a more holistic approach to food data analysis,thereby enhancing the performance and capabilities of LMMs in this domain. Tomitigate the conflicts arising from multi-task supervision during fine-tuningof LMMs, we introduce a novel Linear Rectification Mixture of Diverse Experts(RoDE) approach. RoDE utilizes a diverse array of experts to address tasks ofvarying complexity, thereby facilitating the coordination of trainableparameters, i.e., it allocates more parameters for more complex tasks and,conversely, fewer parameters for simpler tasks. RoDE implements linearrectification union to refine the router's functionality, thereby enhancing theefficiency of sparse task allocation. These design choices endow RoDE withfeatures that ensure GPU memory efficiency and ease of optimization. Ourexperimental results validate the effectiveness of our proposed approach inaddressing the inherent challenges of food-related multitasking.</description><author>Pengkun Jiao, Xinlan Wu, Bin Zhu, Jingjing Chen, Chong-Wah Ngo, Yugang Jiang</author><pubDate>Wed, 17 Jul 2024 16:49:34 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.12730v1</guid></item><item><title>NL2Contact: Natural Language Guided 3D Hand-Object Contact Modeling with Diffusion Model</title><link>http://arxiv.org/abs/2407.12727v1</link><description>Modeling the physical contacts between the hand and object is standard forrefining inaccurate hand poses and generating novel human grasp in 3Dhand-object reconstruction. However, existing methods rely on geometricconstraints that cannot be specified or controlled. This paper introduces anovel task of controllable 3D hand-object contact modeling with naturallanguage descriptions. Challenges include i) the complexity of cross-modalmodeling from language to contact, and ii) a lack of descriptive text forcontact patterns. To address these issues, we propose NL2Contact, a model thatgenerates controllable contacts by leveraging staged diffusion models. Given alanguage description of the hand and contact, NL2Contact generates realisticand faithful 3D hand-object contacts. To train the model, we build\textit{ContactDescribe}, the first dataset with hand-centered contactdescriptions. It contains multi-level and diverse descriptions generated bylarge language models based on carefully designed prompts (e.g., grasp action,grasp type, contact location, free finger status). We show applications of ourmodel to grasp pose optimization and novel human grasp generation, both basedon a textual contact description.</description><author>Zhongqun Zhang, Hengfei Wang, Ziwei Yu, Yihua Cheng, Angela Yao, Hyung Jin Chang</author><pubDate>Wed, 17 Jul 2024 16:46:40 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.12727v1</guid></item><item><title>Learning-assisted Stochastic Capacity Expansion Planning: A Bayesian Optimization Approach</title><link>http://arxiv.org/abs/2401.10451v4</link><description>Solving large-scale capacity expansion problems (CEPs) is central tocost-effective decarbonization of regional-scale energy systems. To ensure theintended outcomes of CEPs, modeling uncertainty due to weather-dependentvariable renewable energy (VRE) supply and energy demand becomes cruciallyimportant. However, the resulting stochastic optimization models are often lesscomputationally tractable than their deterministic counterparts. Here, wepropose a learning-assisted approximate solution method to tractably solvetwo-stage stochastic CEPs. Our method identifies low-cost planning decisions byconstructing and solving a sequence of tractable temporally aggregatedsurrogate problems. We adopt a Bayesian optimization approach to searching thespace of time series aggregation hyperparameters and compute approximatesolutions that minimize costs on a validation set of supply-demand projections.Importantly, we evaluate solved planning outcomes on a held-out set of testprojections. We apply our approach to generation and transmission expansionplanning for a joint power-gas system spanning New England. We show that ourapproach yields an estimated cost savings of up to 3.8% in comparison tobenchmark time series aggregation approaches.</description><author>Aron Brenner, Rahman Khorramfar, Dharik Mallapragada, Saurabh Amin</author><pubDate>Wed, 17 Jul 2024 16:43:25 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.10451v4</guid></item><item><title>Is Sarcasm Detection A Step-by-Step Reasoning Process in Large Language Models?</title><link>http://arxiv.org/abs/2407.12725v1</link><description>Elaborating a series of intermediate reasoning steps significantly improvesthe ability of large language models (LLMs) to solve complex problems, as suchsteps would evoke LLMs to think sequentially. However, human sarcasmunderstanding is often considered an intuitive and holistic cognitive process,in which various linguistic, contextual, and emotional cues are integrated toform a comprehensive understanding of the speaker's true intention, which isargued not be limited to a step-by-step reasoning process. To verify thisargument, we introduce a new prompting framework called SarcasmCue, whichcontains four prompting strategies, $viz.$ chain of contradiction (CoC), graphof cues (GoC), bagging of cues (BoC) and tensor of cues (ToC), which elicitsLLMs to detect human sarcasm by considering sequential and non-sequentialprompting methods. Through a comprehensive empirical comparison on fourbenchmarking datasets, we show that the proposed four prompting methodsoutperforms standard IO prompting, CoT and ToT with a considerable margin, andnon-sequential prompting generally outperforms sequential prompting.</description><author>Ben Yao, Yazhou Zhang, Qiuchi Li, Jing Qin</author><pubDate>Wed, 17 Jul 2024 16:42:03 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.12725v1</guid></item><item><title>An Evaluation of Continual Learning for Advanced Node Semiconductor Defect Inspection</title><link>http://arxiv.org/abs/2407.12724v1</link><description>Deep learning-based semiconductor defect inspection has gained traction inrecent years, offering a powerful and versatile approach that provides highaccuracy, adaptability, and efficiency in detecting and classifying nano-scaledefects. However, semiconductor manufacturing processes are continuallyevolving, leading to the emergence of new types of defects over time. Thispresents a significant challenge for conventional supervised defect detectors,as they may suffer from catastrophic forgetting when trained on new defectdatasets, potentially compromising performance on previously learned tasks. Analternative approach involves the constant storage of previously traineddatasets alongside pre-trained model versions, which can be utilized for(re-)training from scratch or fine-tuning whenever encountering a new defectdataset. However, adhering to such a storage template is impractical in termsof size, particularly when considering High-Volume Manufacturing (HVM).Additionally, semiconductor defect datasets, especially those encompassingstochastic defects, are often limited and expensive to obtain, thus lackingsufficient representation of the entire universal set of defectivity. This workintroduces a task-agnostic, meta-learning approach aimed at addressing thischallenge, which enables the incremental addition of new defect classes andscales to create a more robust and generalized model for semiconductor defectinspection. We have benchmarked our approach using real resist-wafer SEM(Scanning Electron Microscopy) datasets for two process steps, ADI and AEI,demonstrating its superior performance compared to conventional supervisedtraining methods.</description><author>Amit Prasad, Bappaditya Dey, Victor Blanco, Sandip Halder</author><pubDate>Wed, 17 Jul 2024 16:41:22 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.12724v1</guid></item><item><title>CIC-BART-SSA: Controllable Image Captioning with Structured Semantic Augmentation</title><link>http://arxiv.org/abs/2407.11393v2</link><description>Controllable Image Captioning (CIC) aims at generating natural languagedescriptions for an image, conditioned on information provided by end users,e.g., regions, entities or events of interest. However, availableimage-language datasets mainly contain captions that describe the entirety ofan image, making them ineffective for training CIC models that can potentiallyattend to any subset of regions or relationships. To tackle this challenge, wepropose a novel, fully automatic method to sample additional focused andvisually grounded captions using a unified structured semantic representationbuilt on top of the existing set of captions associated with an image. Weleverage Abstract Meaning Representation (AMR), a cross-lingual graph-basedsemantic formalism, to encode all possible spatio-semantic relations betweenentities, beyond the typical spatial-relations-only focus of current methods.We use this Structured Semantic Augmentation (SSA) framework to augmentexisting image-caption datasets with the grounded controlled captions,increasing their spatial and semantic diversity and focal coverage. We thendevelop a new model, CIC-BART-SSA, specifically tailored for the CIC task, thatsources its control signals from SSA-diversified datasets. We empirically showthat, compared to SOTA CIC models, CIC-BART-SSA generates captions that aresuperior in diversity and text quality, are competitive in controllability,and, importantly, minimize the gap between broad and highly focused controlledcaptioning performance by efficiently generalizing to the challenging highlyfocused scenarios. Code is available athttps://github.com/SamsungLabs/CIC-BART-SSA.</description><author>Kalliopi Basioti, Mohamed A. Abdelsalam, Federico Fancellu, Vladimir Pavlovic, Afsaneh Fazly</author><pubDate>Wed, 17 Jul 2024 16:40:05 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.11393v2</guid></item><item><title>SlimFlow: Training Smaller One-Step Diffusion Models with Rectified Flow</title><link>http://arxiv.org/abs/2407.12718v1</link><description>Diffusion models excel in high-quality generation but suffer from slowinference due to iterative sampling. While recent methods have successfullytransformed diffusion models into one-step generators, they neglect model sizereduction, limiting their applicability in compute-constrained scenarios. Thispaper aims to develop small, efficient one-step diffusion models based on thepowerful rectified flow framework, by exploring joint compression of inferencesteps and model size. The rectified flow framework trains one-step generativemodels using two operations, reflow and distillation. Compared with theoriginal framework, squeezing the model size brings two new challenges: (1) theinitialization mismatch between large teachers and small students duringreflow; (2) the underperformance of naive distillation on small student models.To overcome these issues, we propose Annealing Reflow and Flow-GuidedDistillation, which together comprise our SlimFlow framework. With our novelframework, we train a one-step diffusion model with an FID of 5.02 and 15.7Mparameters, outperforming the previous state-of-the-art one-step diffusionmodel (FID=6.47, 19.4M parameters) on CIFAR10. On ImageNet 64$\times$64 andFFHQ 64$\times$64, our method yields small one-step diffusion models that arecomparable to larger models, showcasing the effectiveness of our method increating compact, efficient one-step diffusion models.</description><author>Yuanzhi Zhu, Xingchao Liu, Qiang Liu</author><pubDate>Wed, 17 Jul 2024 16:38:45 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.12718v1</guid></item><item><title>Investigating Adversarial Vulnerability and Implicit Bias through Frequency Analysis</title><link>http://arxiv.org/abs/2305.15203v2</link><description>Despite their impressive performance in classification tasks, neural networksare known to be vulnerable to adversarial attacks, subtle perturbations of theinput data designed to deceive the model. In this work, we investigate therelation between these perturbations and the implicit bias of neural networkstrained with gradient-based algorithms. To this end, we analyse the network'simplicit bias through the lens of the Fourier transform. Specifically, weidentify the minimal and most critical frequencies necessary for accurateclassification or misclassification respectively for each input image and itsadversarially perturbed version, and uncover the correlation among those. Tothis end, among other methods, we use a newly introduced technique capable ofdetecting non-linear correlations between high-dimensional datasets. Ourresults provide empirical evidence that the network bias in Fourier space andthe target frequencies of adversarial attacks are highly correlated and suggestnew potential strategies for adversarial defence.</description><author>Lorenzo Basile, Nikos Karantzas, Alberto D'Onofrio, Luca Bortolussi, Alex Rodriguez, Fabio Anselmi</author><pubDate>Wed, 17 Jul 2024 16:34:48 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.15203v2</guid></item><item><title>PV-S3: Advancing Automatic Photovoltaic Defect Detection using Semi-Supervised Semantic Segmentation of Electroluminescence Images</title><link>http://arxiv.org/abs/2404.13693v2</link><description>Photovoltaic (PV) systems allow us to tap into all abundant solar energy,however they require regular maintenance for high efficiency and to preventdegradation. Traditional manual health check, using Electroluminescence (EL)imaging, is expensive and logistically challenging which makes automated defectdetection essential. Current automation approaches require extensive manualexpert labeling, which is time-consuming, expensive, and prone to errors. Wepropose PV-S3 (Photovoltaic-Semi Supervised Segmentation), a Semi-SupervisedLearning approach for semantic segmentation of defects in EL images thatreduces reliance on extensive labeling. PV-S3 is a Deep learning model trainedusing a few labeled images along with numerous unlabeled images. We evaluatePV-S3 on multiple datasets and demonstrate its effectiveness and adaptability.With merely 20% labeled samples, we achieve an absolute improvement of 9.7% inIoU, 13.5% in Precision, 29.15% in Recall, and 20.42% in F1-Score over priorstate-of-the-art supervised method (which uses 100% labeled samples) on UCF-ELdataset (largest dataset available for semantic segmentation of ELimages)showing improvement in performance while reducing the annotation costsby 80%.</description><author>Abhishek Jha, Yogesh Rawat, Shruti Vyas</author><pubDate>Wed, 17 Jul 2024 16:33:03 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.13693v2</guid></item><item><title>A Unifying Post-Processing Framework for Multi-Objective Learn-to-Defer Problems</title><link>http://arxiv.org/abs/2407.12710v1</link><description>Learn-to-Defer is a paradigm that enables learning algorithms to work not inisolation but as a team with human experts. In this paradigm, we permit thesystem to defer a subset of its tasks to the expert. Although there arecurrently systems that follow this paradigm and are designed to optimize theaccuracy of the final human-AI team, the general methodology for developingsuch systems under a set of constraints (e.g., algorithmic fairness, expertintervention budget, defer of anomaly, etc.) remains largely unexplored. Inthis paper, using a $d$-dimensional generalization to the fundamental lemma ofNeyman and Pearson (d-GNP), we obtain the Bayes optimal solution forlearn-to-defer systems under various constraints. Furthermore, we design ageneralizable algorithm to estimate that solution and apply this algorithm tothe COMPAS and ACSIncome datasets. Our algorithm shows improvements in terms ofconstraint violation over a set of baselines.</description><author>Mohammad-Amin Charusaie, Samira Samadi</author><pubDate>Wed, 17 Jul 2024 16:32:30 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.12710v1</guid></item><item><title>GIVT: Generative Infinite-Vocabulary Transformers</title><link>http://arxiv.org/abs/2312.02116v4</link><description>We introduce Generative Infinite-Vocabulary Transformers (GIVT) whichgenerate vector sequences with real-valued entries, instead of discrete tokensfrom a finite vocabulary. To this end, we propose two surprisingly simplemodifications to decoder-only transformers: 1) at the input, we replace thefinite-vocabulary lookup table with a linear projection of the input vectors;and 2) at the output, we replace the logits prediction (usually mapped to acategorical distribution) with the parameters of a multivariate Gaussianmixture model. Inspired by the image-generation paradigm of VQ-GAN and MaskGIT,where transformers are used to model the discrete latent sequences of a VQ-VAE,we use GIVT to model the unquantized real-valued latent sequences of a$\beta$-VAE. In class-conditional image generation GIVT outperforms VQ-GAN (andimproved variants thereof) as well as MaskGIT, and achieves performancecompetitive with recent latent diffusion models. Finally, we obtain strongresults outside of image generation when applying GIVT to panoptic segmentationand depth estimation with a VAE variant of the UViM framework.</description><author>Michael Tschannen, Cian Eastwood, Fabian Mentzer</author><pubDate>Wed, 17 Jul 2024 16:32:09 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.02116v4</guid></item><item><title>MoME: Mixture of Multimodal Experts for Generalist Multimodal Large Language Models</title><link>http://arxiv.org/abs/2407.12709v1</link><description>Multimodal large language models (MLLMs) have demonstrated impressivecapabilities across various vision-language tasks. However, a generalist MLLMtypically underperforms compared with a specialist MLLM on most VL tasks, whichcan be attributed to task interference. In this paper, we propose a mixture ofmultimodal experts (MoME) to mitigate task interference and obtain a generalistMLLM. Our MoME is composed of two key components, a mixture of vision experts(MoVE) and a mixture of language experts (MoLE). MoVE can adaptively modulatethe features transformed from various vision encoders, and has a strongcompatibility in transformation architecture. MoLE incorporates sparsely gatedexperts into LLMs to achieve painless improvements with roughly unchangedinference costs. In response to task interference, our MoME specializes in bothvision and language modality to adapt to task discrepancies. Extensiveexperiments show that MoME significantly improves the performance of generalistMLLMs across various VL tasks. The source code is released athttps://github.com/JiuTian-VL/MoME</description><author>Leyang Shen, Gongwei Chen, Rui Shao, Weili Guan, Liqiang Nie</author><pubDate>Wed, 17 Jul 2024 16:31:38 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.12709v1</guid></item><item><title>TTSDS -- Text-to-Speech Distribution Score</title><link>http://arxiv.org/abs/2407.12707v1</link><description>Many recently published Text-to-Speech (TTS) systems produce audio close toreal speech. However, TTS evaluation needs to be revisited to make sense of theresults obtained with the new architectures, approaches and datasets. Wepropose evaluating the quality of synthetic speech as a combination of multiplefactors such as prosody, speaker identity, and intelligibility. Our approachassesses how well synthetic speech mirrors real speech by obtaining correlatesof each factor and measuring their distance from both real speech datasets andnoise datasets. We benchmark 35 TTS systems developed between 2008 and 2024 andshow that our score computed as an unweighted average of factors stronglycorrelates with the human evaluations from each time period.</description><author>Christoph Minixhofer, Ondřej Klejch, Peter Bell</author><pubDate>Wed, 17 Jul 2024 16:30:27 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.12707v1</guid></item><item><title>Skywork-Math: Data Scaling Laws for Mathematical Reasoning in Large Language Models -- The Story Goes On</title><link>http://arxiv.org/abs/2407.08348v2</link><description>In this paper, we investigate the underlying factors that potentially enhancethe mathematical reasoning capabilities of large language models (LLMs). Weargue that the data scaling law for math reasoning capabilities in modern LLMsis far from being saturated, highlighting how the model's quality improves withincreases in data quantity. To support this claim, we introduce theSkywork-Math model series, supervised fine-tuned (SFT) on common 7B LLMs usingour proposed 2.5M-instance Skywork-MathQA dataset. Skywork-Math 7B has achievedimpressive accuracies of 51.2% on the competition-level MATH benchmark and83.9% on the GSM8K benchmark using only SFT data, outperforming an earlyversion of GPT-4 on MATH. The superior performance of Skywork-Math modelscontributes to our novel two-stage data synthesis and model SFT pipelines,which include three different augmentation methods and a diverse seed problemset, ensuring both the quantity and quality of Skywork-MathQA dataset acrossvarying difficulty levels. Most importantly, we provide several practicaltakeaways to enhance math reasoning abilities in LLMs for both research andindustry applications.</description><author>Liang Zeng, Liangjun Zhong, Liang Zhao, Tianwen Wei, Liu Yang, Jujie He, Cheng Cheng, Rui Hu, Yang Liu, Shuicheng Yan, Han Fang, Yahui Zhou</author><pubDate>Wed, 17 Jul 2024 16:28:33 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.08348v2</guid></item><item><title>IMAGDressing-v1: Customizable Virtual Dressing</title><link>http://arxiv.org/abs/2407.12705v1</link><description>Latest advances have achieved realistic virtual try-on (VTON) throughlocalized garment inpainting using latent diffusion models, significantlyenhancing consumers' online shopping experience. However, existing VTONtechnologies neglect the need for merchants to showcase garmentscomprehensively, including flexible control over garments, optional faces,poses, and scenes. To address this issue, we define a virtual dressing (VD)task focused on generating freely editable human images with fixed garments andoptional conditions. Meanwhile, we design a comprehensive affinity metric index(CAMI) to evaluate the consistency between generated images and referencegarments. Then, we propose IMAGDressing-v1, which incorporates a garment UNetthat captures semantic features from CLIP and texture features from VAE. Wepresent a hybrid attention module, including a frozen self-attention and atrainable cross-attention, to integrate garment features from the garment UNetinto a frozen denoising UNet, ensuring users can control different scenesthrough text. IMAGDressing-v1 can be combined with other extension plugins,such as ControlNet and IP-Adapter, to enhance the diversity and controllabilityof generated images. Furthermore, to address the lack of data, we release theinteractive garment pairing (IGPair) dataset, containing over 300,000 pairs ofclothing and dressed images, and establish a standard pipeline for dataassembly. Extensive experiments demonstrate that our IMAGDressing-v1 achievesstate-of-the-art human image synthesis performance under various controlledconditions. The code and model will be available athttps://github.com/muzishen/IMAGDressing.</description><author>Fei Shen, Xin Jiang, Xin He, Hu Ye, Cong Wang, Xiaoyu Du, Zechao Li, Jinghui Tang</author><pubDate>Wed, 17 Jul 2024 16:26:30 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.12705v1</guid></item><item><title>Subgraph-Aware Training of Text-based Methods for Knowledge Graph Completion</title><link>http://arxiv.org/abs/2407.12703v1</link><description>Fine-tuning pre-trained language models (PLMs) has recently shown a potentialto improve knowledge graph completion (KGC). However, most PLM-based methodsencode only textual information, neglecting various topological structures ofknowledge graphs (KGs). In this paper, we empirically validate the significantrelations between the structural properties of KGs and the performance of thePLM-based methods. To leverage the structural knowledge, we propose aSubgraph-Aware Training framework for KGC (SATKGC) that combines (i)subgraph-aware mini-batching to encourage hard negative sampling, and (ii) anew contrastive learning method to focus more on harder entities and hardernegative triples in terms of the structural properties. To the best of ourknowledge, this is the first study to comprehensively incorporate thestructural inductive bias of the subgraphs into fine-tuning PLMs. Extensiveexperiments on four KGC benchmarks demonstrate the superiority of SATKGC. Ourcode is available.</description><author>Youmin Ko, Hyemin Yang, Taeuk Kim, Hyunjoon Kim</author><pubDate>Wed, 17 Jul 2024 16:25:37 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.12703v1</guid></item><item><title>TransCAD: A Hierarchical Transformer for CAD Sequence Inference from Point Clouds</title><link>http://arxiv.org/abs/2407.12702v1</link><description>3D reverse engineering, in which a CAD model is inferred given a 3D scan of aphysical object, is a research direction that offers many promising practicalapplications. This paper proposes TransCAD, an end-to-end transformer-basedarchitecture that predicts the CAD sequence from a point cloud. TransCADleverages the structure of CAD sequences by using a hierarchical learningstrategy. A loop refiner is also introduced to regress sketch primitiveparameters. Rigorous experimentation on the DeepCAD and Fusion360 datasets showthat TransCAD achieves state-of-the-art results. The result analysis issupported with a proposed metric for CAD sequence, the mean Average Precisionof CAD Sequence, that addresses the limitations of existing metrics.</description><author>Elona Dupont, Kseniya Cherenkova, Dimitrios Mallis, Gleb Gusev, Anis Kacem, Djamila Aouada</author><pubDate>Wed, 17 Jul 2024 16:24:36 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.12702v1</guid></item><item><title>Importance Weighted Expectation-Maximization for Protein Sequence Design</title><link>http://arxiv.org/abs/2305.00386v3</link><description>Designing protein sequences with desired biological function is crucial inbiology and chemistry. Recent machine learning methods use a surrogatesequence-function model to replace the expensive wet-lab validation. How can weefficiently generate diverse and novel protein sequences with high fitness? Inthis paper, we propose IsEM-Pro, an approach to generate protein sequencestowards a given fitness criterion. At its core, IsEM-Pro is a latent generativemodel, augmented by combinatorial structure features from a separately learnedMarkov random fields (MRFs). We develop an Monte Carlo Expectation-Maximizationmethod (MCEM) to learn the model. During inference, sampling from its latentspace enhances diversity while its MRFs features guide the exploration in highfitness regions. Experiments on eight protein sequence design tasks show thatour IsEM-Pro outperforms the previous best methods by at least 55% on averagefitness score and generates more diverse and novel protein sequences.</description><author>Zhenqiao Song, Lei Li</author><pubDate>Wed, 17 Jul 2024 16:21:28 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.00386v3</guid></item><item><title>Calibrated Diverse Ensemble Entropy Minimization for Robust Test-Time Adaptation in Prostate Cancer Detection</title><link>http://arxiv.org/abs/2407.12697v1</link><description>High resolution micro-ultrasound has demonstrated promise in real-timeprostate cancer detection, with deep learning becoming a prominent tool forlearning complex tissue properties reflected on ultrasound. However, asignificant roadblock to real-world deployment remains, which prior works oftenoverlook: model performance suffers when applied to data from differentclinical centers due to variations in data distribution. This distributionshift significantly impacts the model's robustness, posing major challenge toclinical deployment. Domain adaptation and specifically its test-time adaption(TTA) variant offer a promising solution to address this challenge. In asetting designed to reflect real-world conditions, we compare existing methodsto state-of-the-art TTA approaches adopted for cancer detection, demonstratingthe lack of robustness to distribution shifts in the former. We then proposeDiverse Ensemble Entropy Minimization (DEnEM), questioning the effectiveness ofcurrent TTA methods on ultrasound data. We show that these methods, althoughoutperforming baselines, are suboptimal due to relying on neural networksoutput probabilities, which could be uncalibrated, or relying on dataaugmentation, which is not straightforward to define on ultrasound data. Ourresults show a significant improvement of $5\%$ to $7\%$ in AUROC over theexisting methods and $3\%$ to $5\%$ over TTA methods, demonstrating theadvantage of DEnEM in addressing distribution shift. \keywords{Ultrasound Imaging \and Prostate Cancer \and Computer-aidedDiagnosis \and Distribution Shift Robustness \and Test-time Adaptation.}</description><author>Mahdi Gilany, Mohamed Harmanani, Paul Wilson, Minh Nguyen Nhat To, Amoon Jamzad, Fahimeh Fooladgar, Brian Wodlinger, Purang Abolmaesumi, Parvin Mousavi</author><pubDate>Wed, 17 Jul 2024 16:20:10 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.12697v1</guid></item><item><title>Tango 2: Aligning Diffusion-based Text-to-Audio Generations through Direct Preference Optimization</title><link>http://arxiv.org/abs/2404.09956v4</link><description>Generative multimodal content is increasingly prevalent in much of thecontent creation arena, as it has the potential to allow artists and mediapersonnel to create pre-production mockups by quickly bringing their ideas tolife. The generation of audio from text prompts is an important aspect of suchprocesses in the music and film industry. Many of the recent diffusion-basedtext-to-audio models focus on training increasingly sophisticated diffusionmodels on a large set of datasets of prompt-audio pairs. These models do notexplicitly focus on the presence of concepts or events and their temporalordering in the output audio with respect to the input prompt. Our hypothesisis focusing on how these aspects of audio generation could improve audiogeneration performance in the presence of limited data. As such, in this work,using an existing text-to-audio model Tango, we synthetically create apreference dataset where each prompt has a winner audio output and some loseraudio outputs for the diffusion model to learn from. The loser outputs, intheory, have some concepts from the prompt missing or in an incorrect order. Wefine-tune the publicly available Tango text-to-audio model using diffusion-DPO(direct preference optimization) loss on our preference dataset and show thatit leads to improved audio output over Tango and AudioLDM2, in terms of bothautomatic- and manual-evaluation metrics.</description><author>Navonil Majumder, Chia-Yu Hung, Deepanway Ghosal, Wei-Ning Hsu, Rada Mihalcea, Soujanya Poria</author><pubDate>Wed, 17 Jul 2024 16:17:50 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.09956v4</guid></item><item><title>Chaotic Hedging with Iterated Integrals and Neural Networks</title><link>http://arxiv.org/abs/2209.10166v3</link><description>In this paper, we extend the Wiener-Ito chaos decomposition to the class ofcontinuous semimartingales that are exponentially integrable, which includes inparticular affine and some polynomial diffusion processes. By omitting theorthogonality in the expansion, we are able to show that every $p$-integrablefunctional of the semimartingale, for $p \in [1,\infty)$, can be represented asa sum of iterated integrals thereof. Using finitely many terms of thisexpansion and (possibly random) neural networks for the integrands, whoseparameters are learned in a machine learning setting, we show that everyfinancial derivative can be approximated arbitrarily well in the $L^p$-sense.In particular, for $p = 2$, we recover the optimal hedging strategy in thesense of quadratic hedging. Moreover, since the hedging strategy of theapproximating option can be computed in closed form, we obtain an efficientalgorithm to approximately replicate any sufficiently integrable financialderivative within short runtime.</description><author>Ariel Neufeld, Philipp Schmocker</author><pubDate>Wed, 17 Jul 2024 16:16:15 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2209.10166v3</guid></item><item><title>Towards Learning Contrast Kinetics with Multi-Condition Latent Diffusion Models</title><link>http://arxiv.org/abs/2403.13890v3</link><description>Contrast agents in dynamic contrast enhanced magnetic resonance imaging allowto localize tumors and observe their contrast kinetics, which is essential forcancer characterization and respective treatment decision-making. However,contrast agent administration is not only associated with adverse health risks,but also restricted for patients during pregnancy, and for those with kidneymalfunction, or other adverse reactions. With contrast uptake as key biomarkerfor lesion malignancy, cancer recurrence risk, and treatment response, itbecomes pivotal to reduce the dependency on intravenous contrast agentadministration. To this end, we propose a multi-conditional latent diffusionmodel capable of acquisition time-conditioned image synthesis of DCE-MRItemporal sequences. To evaluate medical image synthesis, we additionallypropose and validate the Fr\'echet radiomics distance as an image qualitymeasure based on biomarker variability between synthetic and real imaging data.Our results demonstrate our method's ability to generate realisticmulti-sequence fat-saturated breast DCE-MRI and uncover the emerging potentialof deep learning based contrast kinetics simulation. We publicly share ouraccessible codebase at https://github.com/RichardObi/ccnet and provide auser-friendly library for Fr\'echet radiomics distance calculation athttps://pypi.org/project/frd-score.</description><author>Richard Osuala, Daniel M. Lang, Preeti Verma, Smriti Joshi, Apostolia Tsirikoglou, Grzegorz Skorupko, Kaisar Kushibar, Lidia Garrucho, Walter H. L. Pinaya, Oliver Diaz, Julia A. Schnabel, Karim Lekadir</author><pubDate>Wed, 17 Jul 2024 16:04:45 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.13890v3</guid></item><item><title>Mode Connectivity in Auction Design</title><link>http://arxiv.org/abs/2305.11005v2</link><description>Optimal auction design is a fundamental problem in algorithmic game theory.This problem is notoriously difficult already in very simple settings. Recentwork in differentiable economics showed that neural networks can efficientlylearn known optimal auction mechanisms and discover interesting new ones. In anattempt to theoretically justify their empirical success, we focus on one ofthe first such networks, RochetNet, and a generalized version for affinemaximizer auctions. We prove that they satisfy mode connectivity, i.e., locallyoptimal solutions are connected by a simple, piecewise linear path such thatevery solution on the path is almost as good as one of the two local optima.Mode connectivity has been recently investigated as an intriguing empirical andtheoretically justifiable property of neural networks used for predictionproblems. Our results give the first such analysis in the context ofdifferentiable economics, where neural networks are used directly for solvingnon-convex optimization problems.</description><author>Christoph Hertrich, Yixin Tao, László A. Végh</author><pubDate>Wed, 17 Jul 2024 16:03:13 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.11005v2</guid></item><item><title>4Dynamic: Text-to-4D Generation with Hybrid Priors</title><link>http://arxiv.org/abs/2407.12684v1</link><description>Due to the fascinating generative performance of text-to-image diffusionmodels, growing text-to-3D generation works explore distilling the 2Dgenerative priors into 3D, using the score distillation sampling (SDS) loss, tobypass the data scarcity problem. The existing text-to-3D methods have achievedpromising results in realism and 3D consistency, but text-to-4D generationstill faces challenges, including lack of realism and insufficient dynamicmotions. In this paper, we propose a novel method for text-to-4D generation,which ensures the dynamic amplitude and authenticity through direct supervisionprovided by a video prior. Specifically, we adopt a text-to-video diffusionmodel to generate a reference video and divide 4D generation into two stages:static generation and dynamic generation. The static 3D generation is achievedunder the guidance of the input text and the first frame of the referencevideo, while in the dynamic generation stage, we introduce a customized SDSloss to ensure multi-view consistency, a video-based SDS loss to improvetemporal consistency, and most importantly, direct priors from the referencevideo to ensure the quality of geometry and texture. Moreover, we design aprior-switching training strategy to avoid conflicts between different priorsand fully leverage the benefits of each prior. In addition, to enrich thegenerated motion, we further introduce a dynamic modeling representationcomposed of a deformation network and a topology network, which ensures dynamiccontinuity while modeling topological changes. Our method not only supportstext-to-4D generation but also enables 4D generation from monocular videos. Thecomparison experiments demonstrate the superiority of our method compared toexisting methods.</description><author>Yu-Jie Yuan, Leif Kobbelt, Jiwen Liu, Yuan Zhang, Pengfei Wan, Yu-Kun Lai, Lin Gao</author><pubDate>Wed, 17 Jul 2024 16:02:55 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.12684v1</guid></item><item><title>In-Situ Infrared Camera Monitoring for Defect and Anomaly Detection in Laser Powder Bed Fusion: Calibration, Data Mapping, and Feature Extraction</title><link>http://arxiv.org/abs/2407.12682v1</link><description>Laser powder bed fusion (LPBF) process can incur defects due to melt poolinstabilities, spattering, temperature increase, and powder spread anomalies.Identifying defects through in-situ monitoring typically requires collecting,storing, and analyzing large amounts of data generated. The first goal of thiswork is to propose a new approach to accurately map in-situ data to athree-dimensional (3D) geometry, aiming to reduce the amount of storage. Thesecond goal of this work is to introduce several new IR features for defectdetection or process model calibration, which include laser scan order, localpreheat temperature, maximum pre-laser scanning temperature, and number ofspatters generated locally and their landing locations. For completeness,processing of other common IR features, such as interpass temperature, heatintensity, cooling rates, and melt pool area, are also presented with theunderlying algorithm and Python implementation. A number of different parts areprinted, monitored, and characterized to provide evidence of process defectsand anomalies that different IR features are capable of detecting.</description><author>Shawn Hinnebusch, David Anderson, Berkay Bostan, Albert C. To</author><pubDate>Wed, 17 Jul 2024 16:02:22 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.12682v1</guid></item><item><title>Lightning Fast Video Anomaly Detection via Adversarial Knowledge Distillation</title><link>http://arxiv.org/abs/2211.15597v4</link><description>We propose a very fast frame-level model for anomaly detection in video,which learns to detect anomalies by distilling knowledge from multiple highlyaccurate object-level teacher models. To improve the fidelity of our student,we distill the low-resolution anomaly maps of the teachers by jointly applyingstandard and adversarial distillation, introducing an adversarial discriminatorfor each teacher to distinguish between target and generated anomaly maps. Weconduct experiments on three benchmarks (Avenue, ShanghaiTech, UCSD Ped2),showing that our method is over 7 times faster than the fastest competingmethod, and between 28 and 62 times faster than object-centric models, whileobtaining comparable results to recent methods. Our evaluation also indicatesthat our model achieves the best trade-off between speed and accuracy, due toits previously unheard-of speed of 1480 FPS. In addition, we carry out acomprehensive ablation study to justify our architectural design choices. Ourcode is freely available at: https://github.com/ristea/fast-aed.</description><author>Florinel-Alin Croitoru, Nicolae-Catalin Ristea, Dana Dascalescu, Radu Tudor Ionescu, Fahad Shahbaz Khan, Mubarak Shah</author><pubDate>Wed, 17 Jul 2024 16:01:00 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2211.15597v4</guid></item><item><title>Few-Shot Class Incremental Learning with Attention-Aware Self-Adaptive Prompt</title><link>http://arxiv.org/abs/2403.09857v3</link><description>Few-Shot Class-Incremental Learning (FSCIL) models aim to incrementally learnnew classes with scarce samples while preserving knowledge of old ones.Existing FSCIL methods usually fine-tune the entire backbone, leading tooverfitting and hindering the potential to learn new classes. On the otherhand, recent prompt-based CIL approaches alleviate forgetting by trainingprompts with sufficient data in each task. In this work, we propose a novelframework named Attention-aware Self-adaptive Prompt (ASP). ASP encouragestask-invariant prompts to capture shared knowledge by reducing specificinformation from the attention aspect. Additionally, self-adaptivetask-specific prompts in ASP provide specific information and transferknowledge from old classes to new classes with an Information Bottlenecklearning objective. In summary, ASP prevents overfitting on base task and doesnot require enormous data in few-shot incremental tasks. Extensive experimentson three benchmark datasets validate that ASP consistently outperformsstate-of-the-art FSCIL and prompt-based CIL methods in terms of both learningnew classes and mitigating forgetting.</description><author>Chenxi Liu, Zhenyi Wang, Tianyi Xiong, Ruibo Chen, Yihan Wu, Junfeng Guo, Heng Huang</author><pubDate>Wed, 17 Jul 2024 16:00:27 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.09857v3</guid></item><item><title>Goldfish: Vision-Language Understanding of Arbitrarily Long Videos</title><link>http://arxiv.org/abs/2407.12679v1</link><description>Most current LLM-based models for video understanding can process videoswithin minutes. However, they struggle with lengthy videos due to challengessuch as "noise and redundancy", as well as "memory and computation"constraints. In this paper, we present Goldfish, a methodology tailored forcomprehending videos of arbitrary lengths. We also introduce the TVQA-longbenchmark, specifically designed to evaluate models' capabilities inunderstanding long videos with questions in both vision and text content.Goldfish approaches these challenges with an efficient retrieval mechanism thatinitially gathers the top-k video clips relevant to the instruction beforeproceeding to provide the desired response. This design of the retrievalmechanism enables the Goldfish to efficiently process arbitrarily long videosequences, facilitating its application in contexts such as movies ortelevision series. To facilitate the retrieval process, we developedMiniGPT4-Video that generates detailed descriptions for the video clips. Inaddressing the scarcity of benchmarks for long video evaluation, we adapted theTVQA short video benchmark for extended content analysis by aggregatingquestions from entire episodes, thereby shifting the evaluation from partial tofull episode comprehension. We attained a 41.78% accuracy rate on the TVQA-longbenchmark, surpassing previous methods by 14.94%. Our MiniGPT4-Video also showsexceptional performance in short video comprehension, exceeding existingstate-of-the-art methods by 3.23%, 2.03%, 16.5% and 23.59% on the MSVD, MSRVTT,TGIF, and TVQA short video benchmarks, respectively. These results indicatethat our models have significant improvements in both long and short-videounderstanding. Our models and code have been made publicly available athttps://vision-cair.github.io/Goldfish_website/</description><author>Kirolos Ataallah, Xiaoqian Shen, Eslam Abdelrahman, Essam Sleiman, Mingchen Zhuge, Jian Ding, Deyao Zhu, Jürgen Schmidhuber, Mohamed Elhoseiny</author><pubDate>Wed, 17 Jul 2024 15:59:32 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.12679v1</guid></item><item><title>Muting Whisper: A Universal Acoustic Adversarial Attack on Speech Foundation Models</title><link>http://arxiv.org/abs/2405.06134v2</link><description>Recent developments in large speech foundation models like Whisper have ledto their widespread use in many automatic speech recognition (ASR)applications. These systems incorporate `special tokens' in their vocabulary,such as $\texttt{&lt;|endoftext|&gt;}$, to guide their language generation process.However, we demonstrate that these tokens can be exploited by adversarialattacks to manipulate the model's behavior. We propose a simple yet effectivemethod to learn a universal acoustic realization of Whisper's$\texttt{&lt;|endoftext|&gt;}$ token, which, when prepended to any speech signal,encourages the model to ignore the speech and only transcribe the specialtoken, effectively `muting' the model. Our experiments demonstrate that thesame, universal 0.64-second adversarial audio segment can successfully mute atarget Whisper ASR model for over 97\% of speech samples. Moreover, we findthat this universal adversarial audio segment often transfers to new datasetsand tasks. Overall this work demonstrates the vulnerability of Whisper modelsto `muting' adversarial attacks, where such attacks can pose both risks andpotential benefits in real-world settings: for example the attack can be usedto bypass speech moderation systems, or conversely the attack can also be usedto protect private speech data.</description><author>Vyas Raina, Rao Ma, Charles McGhee, Kate Knill, Mark Gales</author><pubDate>Wed, 17 Jul 2024 15:59:26 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.06134v2</guid></item><item><title>CoSIGN: Few-Step Guidance of ConSIstency Model to Solve General INverse Problems</title><link>http://arxiv.org/abs/2407.12676v1</link><description>Diffusion models have been demonstrated as strong priors for solving generalinverse problems. Most existing Diffusion model-based Inverse Problem Solvers(DIS) employ a plug-and-play approach to guide the sampling trajectory witheither projections or gradients. Though effective, these methods generallynecessitate hundreds of sampling steps, posing a dilemma between inference timeand reconstruction quality. In this work, we try to push the boundary ofinference steps to 1-2 NFEs while still maintaining high reconstructionquality. To achieve this, we propose to leverage a pretrained distillation ofdiffusion model, namely consistency model, as the data prior. The key toachieving few-step guidance is to enforce two types of constraints during thesampling process of the consistency model: soft measurement constraint withControlNet and hard measurement constraint via optimization. Supporting bothsingle-step reconstruction and multistep refinement, the proposed frameworkfurther provides a way to trade image quality with additional computationalcost. Within comparable NFEs, our method achieves new state-of-the-art indiffusion-based inverse problem solving, showcasing the significant potentialof employing prior-based inverse problem solvers for real-world applications.Code is available at: https://github.com/BioMed-AI-Lab-U-Michgan/cosign.</description><author>Jiankun Zhao, Bowen Song, Liyue Shen</author><pubDate>Wed, 17 Jul 2024 15:57:50 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.12676v1</guid></item><item><title>To Believe or Not to Believe Your LLM</title><link>http://arxiv.org/abs/2406.02543v2</link><description>We explore uncertainty quantification in large language models (LLMs), withthe goal to identify when uncertainty in responses given a query is large. Wesimultaneously consider both epistemic and aleatoric uncertainties, where theformer comes from the lack of knowledge about the ground truth (such as aboutfacts or the language), and the latter comes from irreducible randomness (suchas multiple possible answers). In particular, we derive aninformation-theoretic metric that allows to reliably detect when only epistemicuncertainty is large, in which case the output of the model is unreliable. Thiscondition can be computed based solely on the output of the model obtainedsimply by some special iterative prompting based on the previous responses.Such quantification, for instance, allows to detect hallucinations (cases whenepistemic uncertainty is high) in both single- and multi-answer responses. Thisis in contrast to many standard uncertainty quantification strategies (such asthresholding the log-likelihood of a response) where hallucinations in themulti-answer case cannot be detected. We conduct a series of experiments whichdemonstrate the advantage of our formulation. Further, our investigations shedsome light on how the probabilities assigned to a given output by an LLM can beamplified by iterative prompting, which might be of independent interest.</description><author>Yasin Abbasi Yadkori, Ilja Kuzborskij, András György, Csaba Szepesvári</author><pubDate>Wed, 17 Jul 2024 15:55:51 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.02543v2</guid></item><item><title>GraphMuse: A Library for Symbolic Music Graph Processing</title><link>http://arxiv.org/abs/2407.12671v1</link><description>Graph Neural Networks (GNNs) have recently gained traction in symbolic musictasks, yet a lack of a unified framework impedes progress. Addressing this gap,we present GraphMuse, a graph processing framework and library that facilitatesefficient music graph processing and GNN training for symbolic music tasks.Central to our contribution is a new neighbor sampling technique specificallytargeted toward meaningful behavior in musical scores. Additionally, GraphMuseintegrates hierarchical modeling elements that augment the expressivity andcapabilities of graph networks for musical tasks. Experiments with two specificmusical prediction tasks -- pitch spelling and cadence detection -- demonstratesignificant performance improvement over previous methods. Our hope is thatGraphMuse will lead to a boost in, and standardization of, symbolic musicprocessing based on graph representations. The library is available athttps://github.com/manoskary/graphmuse</description><author>Emmanouil Karystinaios, Gerhard Widmer</author><pubDate>Wed, 17 Jul 2024 15:54:09 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.12671v1</guid></item><item><title>Enhancing the Utility of Privacy-Preserving Cancer Classification using Synthetic Data</title><link>http://arxiv.org/abs/2407.12669v1</link><description>Deep learning holds immense promise for aiding radiologists in breast cancerdetection. However, achieving optimal model performance is hampered bylimitations in availability and sharing of data commonly associated to patientprivacy concerns. Such concerns are further exacerbated, as traditional deeplearning models can inadvertently leak sensitive training information. Thiswork addresses these challenges exploring and quantifying the utility ofprivacy-preserving deep learning techniques, concretely, (i) differentiallyprivate stochastic gradient descent (DP-SGD) and (ii) fully synthetic trainingdata generated by our proposed malignancy-conditioned generative adversarialnetwork. We assess these methods via downstream malignancy classification ofmammography masses using a transformer model. Our experimental results depictthat synthetic data augmentation can improve privacy-utility tradeoffs indifferentially private model training. Further, model pretraining on syntheticdata achieves remarkable performance, which can be further increased withDP-SGD fine-tuning across all privacy guarantees. With this first in-depthexploration of privacy-preserving deep learning in breast imaging, we addresscurrent and emerging clinical privacy requirements and pave the way towards theadoption of private high-utility deep diagnostic models. Our reproduciblecodebase is publicly available at https://github.com/RichardObi/mammo_dp.</description><author>Richard Osuala, Daniel M. Lang, Anneliese Riess, Georgios Kaissis, Zuzanna Szafranowska, Grzegorz Skorupko, Oliver Diaz, Julia A. Schnabel, Karim Lekadir</author><pubDate>Wed, 17 Jul 2024 15:52:45 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.12669v1</guid></item><item><title>SG-NeRF: Neural Surface Reconstruction with Scene Graph Optimization</title><link>http://arxiv.org/abs/2407.12667v1</link><description>3D surface reconstruction from images is essential for numerous applications.Recently, Neural Radiance Fields (NeRFs) have emerged as a promising frameworkfor 3D modeling. However, NeRFs require accurate camera poses as input, andexisting methods struggle to handle significantly noisy pose estimates (i.e.,outliers), which are commonly encountered in real-world scenarios. To tacklethis challenge, we present a novel approach that optimizes radiance fields withscene graphs to mitigate the influence of outlier poses. Our methodincorporates an adaptive inlier-outlier confidence estimation scheme based onscene graphs, emphasizing images of high compatibility with the neighborhoodand consistency in the rendering quality. We also introduce an effectiveintersection-over-union (IoU) loss to optimize the camera pose and surfacegeometry, together with a coarse-to-fine strategy to facilitate the training.Furthermore, we propose a new dataset containing typical outlier poses for adetailed evaluation. Experimental results on various datasets consistentlydemonstrate the effectiveness and superiority of our method over existingapproaches, showcasing its robustness in handling outliers and producinghigh-quality 3D reconstructions. Our code and data are available at:\url{https://github.com/Iris-cyy/SG-NeRF}.</description><author>Yiyang Chen, Siyan Dong, Xulong Wang, Lulu Cai, Youyi Zheng, Yanchao Yang</author><pubDate>Wed, 17 Jul 2024 15:50:17 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.12667v1</guid></item><item><title>Patch-Level Training for Large Language Models</title><link>http://arxiv.org/abs/2407.12665v1</link><description>As Large Language Models (LLMs) achieve remarkable progress in languageunderstanding and generation, their training efficiency has become a criticalconcern. Traditionally, LLMs are trained to predict the next token in asequence. Despite the success of token-level training, it suffers fromconsiderable computational costs due to the need to process an extensive numberof tokens. To mitigate this issue, this paper introduces patch-level trainingfor LLMs, which reduces the sequence length by compressing multiple tokens intoa single patch. During patch-level training, we feed the language model shortersequences of patches and train it to predict the next patch, thereby processingthe majority of the training data at a significantly reduced computationalcost. Following this, the model continues token-level training on the remainingtraining data to align with the inference mode. Experiments on a diverse rangeof models (370M-2.7B parameters) demonstrate that patch-level training canreduce overall computational costs to 0.5$\times$, without compromising themodel performance compared to token-level training. Source code:\url{https://github.com/shaochenze/PatchTrain}.</description><author>Chenze Shao, Fandong Meng, Jie Zhou</author><pubDate>Wed, 17 Jul 2024 15:48:39 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.12665v1</guid></item><item><title>Is That Rain? Understanding Effects on Visual Odometry Performance for Autonomous UAVs and Efficient DNN-based Rain Classification at the Edge</title><link>http://arxiv.org/abs/2407.12663v1</link><description>The development of safe and reliable autonomous unmanned aerial vehiclesrelies on the ability of the system to recognise and adapt to changes in thelocal environment based on sensor inputs. State-of-the-art local tracking andtrajectory planning are typically performed using camera sensor input to theflight control algorithm, but the extent to which environmental disturbanceslike rain affect the performance of these systems is largely unknown. In thispaper, we first describe the development of an open dataset comprising ~335kimages to examine these effects for seven different classes of precipitationconditions and show that a worst-case average tracking error of 1.5 m ispossible for a state-of-the-art visual odometry system (VINS-Fusion). We thenuse the dataset to train a set of deep neural network models suited to mobileand constrained deployment scenarios to determine the extent to which it may bepossible to efficiently and accurately classify these `rainy' conditions. Themost lightweight of these models (MobileNetV3 small) can achieve an accuracy of90% with a memory footprint of just 1.28 MB and a frame rate of 93 FPS, whichis suitable for deployment in resource-constrained and latency-sensitivesystems. We demonstrate a classification latency in the order of millisecondsusing typical flight computer hardware. Accordingly, such a model can feed intothe disturbance estimation component of an autonomous flight controller. Inaddition, data from unmanned aerial vehicles with the ability to accuratelydetermine environmental conditions in real time may contribute to developingmore granular timely localised weather forecasting.</description><author>Andrea Albanese, Yanran Wang, Davide Brunelli, David Boyle</author><pubDate>Wed, 17 Jul 2024 15:47:25 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.12663v1</guid></item><item><title>InfoNorm: Mutual Information Shaping of Normals for Sparse-View Reconstruction</title><link>http://arxiv.org/abs/2407.12661v1</link><description>3D surface reconstruction from multi-view images is essential for sceneunderstanding and interaction. However, complex indoor scenes pose challengessuch as ambiguity due to limited observations. Recent implicit surfacerepresentations, such as Neural Radiance Fields (NeRFs) and signed distancefunctions (SDFs), employ various geometric priors to resolve the lack ofobserved information. Nevertheless, their performance heavily depends on thequality of the pre-trained geometry estimation models. To ease such dependence,we propose regularizing the geometric modeling by explicitly encouraging themutual information among surface normals of highly correlated scene points. Inthis way, the geometry learning process is modulated by the second-ordercorrelations from noisy (first-order) geometric priors, thus eliminating thebias due to poor generalization. Additionally, we introduce a simple yeteffective scheme that utilizes semantic and geometric features to identifycorrelated points, enhancing their mutual information accordingly. The proposedtechnique can serve as a plugin for SDF-based neural surface representations.Our experiments demonstrate the effectiveness of the proposed in improving thesurface reconstruction quality of major states of the arts. Our code isavailable at: \url{https://github.com/Muliphein/InfoNorm}.</description><author>Xulong Wang, Siyan Dong, Youyi Zheng, Yanchao Yang</author><pubDate>Wed, 17 Jul 2024 15:46:25 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.12661v1</guid></item><item><title>Warm-Start Variational Quantum Policy Iteration</title><link>http://arxiv.org/abs/2404.10546v2</link><description>Reinforcement learning is a powerful framework aiming to determine optimalbehavior in highly complex decision-making scenarios. This objective can beachieved using policy iteration, which requires to solve a typically largelinear system of equations. We propose the variational quantum policy iteration(VarQPI) algorithm, realizing this step with a NISQ-compatible quantum-enhancedsubroutine. Its scalability is supported by an analysis of the structure ofgeneric reinforcement learning environments, laying the foundation forpotential quantum advantage with utility-scale quantum computers. Furthermore,we introduce the warm-start initialization variant (WS-VarQPI) thatsignificantly reduces resource overhead. The algorithm solves a largeFrozenLake environment with an underlying 256x256-dimensional linear system,indicating its practical robustness.</description><author>Nico Meyer, Jakob Murauer, Alexander Popov, Christian Ufrecht, Axel Plinge, Christopher Mutschler, Daniel D. Scherer</author><pubDate>Wed, 17 Jul 2024 15:38:33 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.10546v2</guid></item><item><title>Qiskit-Torch-Module: Fast Prototyping of Quantum Neural Networks</title><link>http://arxiv.org/abs/2404.06314v2</link><description>Quantum computer simulation software is an integral tool for the researchefforts in the quantum computing community. An important aspect is theefficiency of respective frameworks, especially for training variationalquantum algorithms. Focusing on the widely used Qiskit software environment, wedevelop the qiskit-torch-module. It improves runtime performance by two ordersof magnitude over comparable libraries, while facilitating low-overheadintegration with existing codebases. Moreover, the framework provides advancedtools for integrating quantum neural networks with PyTorch. The pipeline istailored for single-machine compute systems, which constitute a widely employedsetup in day-to-day research efforts.</description><author>Nico Meyer, Christian Ufrecht, Maniraman Periyasamy, Axel Plinge, Christopher Mutschler, Daniel D. Scherer, Andreas Maier</author><pubDate>Wed, 17 Jul 2024 15:33:08 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.06314v2</guid></item><item><title>Non-Vacuous Generalization Bounds for Large Language Models</title><link>http://arxiv.org/abs/2312.17173v3</link><description>Modern language models can contain billions of parameters, raising thequestion of whether they can generalize beyond the training data or simplyparrot their training corpora. We provide the first non-vacuous generalizationbounds for pretrained large language models (LLMs), indicating that languagemodels are capable of discovering regularities that generalize to unseen data.In particular, we derive a compression bound that is valid for the unboundedlog-likelihood loss using prediction smoothing, and we extend the bound tohandle subsampling, accelerating bound computation by orders of magnitude onmassive datasets. To achieve the extreme level of compression required fornon-vacuous bounds, we devise SubLoRA, a simple low-dimensional nonlinearparameterization that leads to non-vacuous generalization bounds for modelswith nearly a billion parameters. Finally, we use our bounds to understand LLMgeneralization and find that larger models have better generalization boundsand are more compressible than smaller models.</description><author>Sanae Lotfi, Marc Finzi, Yilun Kuang, Tim G. J. Rudner, Micah Goldblum, Andrew Gordon Wilson</author><pubDate>Wed, 17 Jul 2024 15:32:47 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.17173v3</guid></item><item><title>Generative AI for Low-Carbon Artificial Intelligence of Things with Large Language Models</title><link>http://arxiv.org/abs/2404.18077v2</link><description>By integrating Artificial Intelligence (AI) with the Internet of Things(IoT), Artificial Intelligence of Things (AIoT) has revolutionized many fields.However, AIoT is facing the challenges of energy consumption and carbonemissions due to the continuous advancement of mobile technology. Fortunately,Generative AI (GAI) holds immense potential to reduce carbon emissions of AIoTdue to its excellent reasoning and generation capabilities. In this article, weexplore the potential of GAI for carbon emissions reduction and propose a novelGAI-enabled solution for low-carbon AIoT. Specifically, we first study the mainimpacts that cause carbon emissions in AIoT, and then introduce GAI techniquesand their relations to carbon emissions. We then explore the applicationprospects of GAI in low-carbon AIoT, focusing on how GAI can reduce carbonemissions of network components. Subsequently, we propose a Large LanguageModel (LLM)-enabled carbon emission optimization framework, in which we designpluggable LLM and Retrieval Augmented Generation (RAG) modules to generate moreaccurate and reliable optimization problems. Furthermore, we utilize GenerativeDiffusion Models (GDMs) to identify optimal strategies for carbon emissionreduction. Numerical results demonstrate the effectiveness of the proposedframework. Finally, we insightfully provide open research directions forlow-carbon AIoT.</description><author>Jinbo Wen, Ruichen Zhang, Dusit Niyato, Jiawen Kang, Hongyang Du, Yang Zhang, Zhu Han</author><pubDate>Wed, 17 Jul 2024 15:32:46 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.18077v2</guid></item><item><title>MUSES: The Multi-Sensor Semantic Perception Dataset for Driving under Uncertainty</title><link>http://arxiv.org/abs/2401.12761v3</link><description>Achieving level-5 driving automation in autonomous vehicles necessitates arobust semantic visual perception system capable of parsing data from differentsensors across diverse conditions. However, existing semantic perceptiondatasets often lack important non-camera modalities typically used inautonomous vehicles, or they do not exploit such modalities to aid and improvesemantic annotations in challenging conditions. To address this, we introduceMUSES, the MUlti-SEnsor Semantic perception dataset for driving in adverseconditions under increased uncertainty. MUSES includes synchronized multimodalrecordings with 2D panoptic annotations for 2500 images captured under diverseweather and illumination. The dataset integrates a frame camera, a lidar, aradar, an event camera, and an IMU/GNSS sensor. Our new two-stage panopticannotation protocol captures both class-level and instance-level uncertainty inthe ground truth and enables the novel task of uncertainty-aware panopticsegmentation we introduce, along with standard semantic and panopticsegmentation. MUSES proves both effective for training and challenging forevaluating models under diverse visual conditions, and it opens new avenues forresearch in multimodal and uncertainty-aware dense semantic perception. Ourdataset and benchmark are publicly available athttps://muses.vision.ee.ethz.ch.</description><author>Tim Brödermann, David Bruggemann, Christos Sakaridis, Kevin Ta, Odysseas Liagouris, Jason Corkill, Luc Van Gool</author><pubDate>Wed, 17 Jul 2024 15:31:44 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.12761v3</guid></item><item><title>ReLU Neural Networks of Polynomial Size for Exact Maximum Flow Computation</title><link>http://arxiv.org/abs/2102.06635v5</link><description>This paper studies the expressive power of artificial neural networks withrectified linear units. In order to study them as a model of real-valuedcomputation, we introduce the concept of Max-Affine Arithmetic Programs andshow equivalence between them and neural networks concerning natural complexitymeasures. We then use this result to show that two fundamental combinatorialoptimization problems can be solved with polynomial-size neural networks.First, we show that for any undirected graph with $n$ nodes, there is a neuralnetwork (with fixed weights and biases) of size $\mathcal{O}(n^3)$ that takesthe edge weights as input and computes the value of a minimum spanning tree ofthe graph. Second, we show that for any directed graph with $n$ nodes and $m$arcs, there is a neural network of size $\mathcal{O}(m^2n^2)$ that takes thearc capacities as input and computes a maximum flow. Our results imply thatthese two problems can be solved with strongly polynomial time algorithms thatsolely use affine transformations and maxima computations, but nocomparison-based branchings.</description><author>Christoph Hertrich, Leon Sering</author><pubDate>Wed, 17 Jul 2024 15:31:15 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2102.06635v5</guid></item><item><title>In-Context Symbolic Regression: Leveraging Large Language Models for Function Discovery</title><link>http://arxiv.org/abs/2404.19094v2</link><description>State of the art Symbolic Regression (SR) methods currently build specializedmodels, while the application of Large Language Models (LLMs) remains largelyunexplored. In this work, we introduce the first comprehensive framework thatutilizes LLMs for the task of SR. We propose In-Context Symbolic Regression(ICSR), an SR method which iteratively refines a functional form with an LLMand determines its coefficients with an external optimizer. ICSR leveragesLLMs' strong mathematical prior both to propose an initial set of possiblefunctions given the observations and to refine them based on their errors. Ourfindings reveal that LLMs are able to successfully find symbolic equations thatfit the given data, matching or outperforming the overall performance of thebest SR baselines on four popular benchmarks, while yielding simpler equationswith better out of distribution generalization.</description><author>Matteo Merler, Katsiaryna Haitsiukevich, Nicola Dainese, Pekka Marttinen</author><pubDate>Wed, 17 Jul 2024 15:29:18 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.19094v2</guid></item><item><title>Rate-Preserving Reductions for Blackwell Approachability</title><link>http://arxiv.org/abs/2406.07585v2</link><description>Abernethy et al. (2011) showed that Blackwell approachability and no-regretlearning are equivalent, in the sense that any algorithm that solves a specificBlackwell approachability instance can be converted to a sublinear regretalgorithm for a specific no-regret learning instance, and vice versa. In thispaper, we study a more fine-grained form of such reductions, and ask when thistranslation between problems preserves not only a sublinear rate ofconvergence, but also preserves the optimal rate of convergence. That is, inwhich cases does it suffice to find the optimal regret bound for a no-regretlearning instance in order to find the optimal rate of convergence for acorresponding approachability instance? We show that the reduction of Abernethy et al. (2011) does not preserverates: their reduction may reduce a $d$-dimensional approachability instance$I_1$ with optimal convergence rate $R_1$ to a no-regret learning instance$I_2$ with optimal regret-per-round of $R_2$, with $R_{2}/R_{1}$ arbitrarilylarge (in particular, it is possible that $R_1 = 0$ and $R_{2} &gt; 0$). On theother hand, we show that it is possible to tightly reduce any approachabilityinstance to an instance of a generalized form of regret minimization we callimproper $\phi$-regret minimization (a variant of the $\phi$-regretminimization of Gordon et al. (2008) where the transformation functions may mapactions outside of the action set). Finally, we characterize when linear transformations suffice to reduceimproper $\phi$-regret minimization problems to standard classes of regretminimization problems in a rate preserving manner. We prove that some improper$\phi$-regret minimization instances cannot be reduced to either subclass ofinstance in this way, suggesting that approachability can capture some problemsthat cannot be phrased in the language of online learning.</description><author>Christoph Dann, Yishay Mansour, Mehryar Mohri, Jon Schneider, Balasubramanian Sivan</author><pubDate>Wed, 17 Jul 2024 15:28:36 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.07585v2</guid></item><item><title>Instruction-Driven Game Engines on Large Language Models</title><link>http://arxiv.org/abs/2404.00276v3</link><description>The Instruction-Driven Game Engine (IDGE) project aims to democratize gamedevelopment by enabling a large language model (LLM) to follow free-form gamerules and autonomously generate game-play processes. The IDGE allows users tocreate games by issuing simple natural language instructions, whichsignificantly lowers the barrier for game development. We approach the learningprocess for IDGEs as a Next State Prediction task, wherein the modelautoregressively predicts in-game states given player actions. It is achallenging task because the computation of in-game states must be precise;otherwise, slight errors could disrupt the game-play. To address this, we trainthe IDGE in a curriculum manner that progressively increases the model'sexposure to complex scenarios. Our initial progress lies in developing an IDGEfor Poker, a universally cherished card game. The engine we've designed notonly supports a wide range of poker variants but also allows for highcustomization of rules through natural language inputs. Furthermore, it alsofavors rapid prototyping of new games from minimal samples, proposing aninnovative paradigm in game development that relies on minimal prompt and dataengineering. This work lays the groundwork for future advancements ininstruction-driven game creation, potentially transforming how games aredesigned and played.</description><author>Hongqiu Wu, Xingyuan Liu, Hai Zhao, Min Zhang</author><pubDate>Wed, 17 Jul 2024 15:27:37 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.00276v3</guid></item><item><title>MMVR: Millimeter-wave Multi-View Radar Dataset and Benchmark for Indoor Perception</title><link>http://arxiv.org/abs/2406.10708v2</link><description>Compared with an extensive list of automotive radar datasets that supportautonomous driving, indoor radar datasets are scarce at a smaller scale in theformat of low-resolution radar point clouds and usually under an open-spacesingle-room setting. In this paper, we scale up indoor radar data collectionusing multi-view high-resolution radar heatmap in a multi-day, multi-room, andmulti-subject setting, with an emphasis on the diversity of environment andsubjects. Referred to as the millimeter-wave multi-view radar (MMVR) dataset,it consists of $345$K multi-view radar frames collected from $25$ humansubjects over $6$ different rooms, $446$K annotated bounding boxes/segmentationinstances, and $7.59$ million annotated keypoints to support three majorperception tasks of object detection, pose estimation, and instancesegmentation, respectively. For each task, we report performance benchmarksunder two protocols: a single subject in an open space and multiple subjects inseveral cluttered rooms with two data splits: random split andcross-environment split over $395$ 1-min data segments. We anticipate that MMVRfacilitates indoor radar perception development for indoor vehicle(robot/humanoid) navigation, building energy management, and elderly care forbetter efficiency, user experience, and safety. The MMVR dataset is availableat https://doi.org/10.5281/zenodo.12611978.</description><author>M. Mahbubur Rahman, Ryoma Yataka, Sorachi Kato, Pu Perry Wang, Peizhao Li, Adriano Cardace, Petros Boufounos</author><pubDate>Wed, 17 Jul 2024 15:23:17 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.10708v2</guid></item><item><title>TimeDRL: Disentangled Representation Learning for Multivariate Time-Series</title><link>http://arxiv.org/abs/2312.04142v3</link><description>Multivariate time-series data in numerous real-world applications (e.g.,healthcare and industry) are informative but challenging due to the lack oflabels and high dimensionality. Recent studies in self-supervised learning haveshown their potential in learning rich representations without relying onlabels, yet they fall short in learning disentangled embeddings and addressingissues of inductive bias (e.g., transformation-invariance). To tackle thesechallenges, we propose TimeDRL, a generic multivariate time-seriesrepresentation learning framework with disentangled dual-level embeddings.TimeDRL is characterized by three novel features: (i) disentangled derivationof timestamp-level and instance-level embeddings from patched time-series datausing a [CLS] token strategy; (ii) utilization of timestamp-predictive andinstance-contrastive tasks for disentangled representation learning, with theformer optimizing timestamp-level embeddings with predictive loss, and thelatter optimizing instance-level embeddings with contrastive loss; and (iii)avoidance of augmentation methods to eliminate inductive biases, such astransformation-invariance from cropping and masking. Comprehensive experimentson 6 time-series forecasting datasets and 5 time-series classification datasetshave shown that TimeDRL consistently surpasses existing representation learningapproaches, achieving an average improvement of forecasting by 58.02% in MSEand classification by 1.48% in accuracy. Furthermore, extensive ablationstudies confirmed the relative contribution of each component in TimeDRL'sarchitecture, and semi-supervised learning evaluations demonstrated itseffectiveness in real-world scenarios, even with limited labeled data. The codeis available at https://github.com/blacksnail789521/TimeDRL.</description><author>Ching Chang, Chiao-Tung Chan, Wei-Yao Wang, Wen-Chih Peng, Tien-Fu Chen</author><pubDate>Wed, 17 Jul 2024 15:19:17 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.04142v3</guid></item><item><title>Fusion Flow-enhanced Graph Pooling Residual Networks for Unmanned Aerial Vehicles Surveillance in Day and Night Dual Visions</title><link>http://arxiv.org/abs/2407.12647v1</link><description>Recognizing unauthorized Unmanned Aerial Vehicles (UAVs) within designatedno-fly zones throughout the day and night is of paramount importance, where theunauthorized UAVs pose a substantial threat to both civil and military aviationsafety. However, recognizing UAVs day and night with dual-vision cameras isnontrivial, since red-green-blue (RGB) images suffer from a low detection rateunder an insufficient light condition, such as on cloudy or stormy days, whileblack-and-white infrared (IR) images struggle to capture UAVs that overlap withthe background at night. In this paper, we propose a new optical flow-assistedgraph-pooling residual network (OF-GPRN), which significantly enhances the UAVdetection rate in day and night dual visions. The proposed OF-GPRN develops anew optical fusion to remove superfluous backgrounds, which improves RGB/IRimaging clarity. Furthermore, OF-GPRN extends optical fusion by incorporating agraph residual split attention network and a feature pyramid, which refines theperception of UAVs, leading to a higher success rate in UAV detection. Acomprehensive performance evaluation is conducted using a benchmark UAV catchdataset. The results indicate that the proposed OF-GPRN elevates the UAV meanaverage precision (mAP) detection rate to 87.8%, marking a 17.9% advancementcompared to the residual graph neural network (ResGCN)-based approach.</description><author>Alam Noor, Kai Li, Eduardo Tovar, Pei Zhang, Bo Wei</author><pubDate>Wed, 17 Jul 2024 15:16:23 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.12647v1</guid></item><item><title>Generative Enzyme Design Guided by Functionally Important Sites and Small-Molecule Substrates</title><link>http://arxiv.org/abs/2405.08205v3</link><description>Enzymes are genetically encoded biocatalysts capable of accelerating chemicalreactions. How can we automatically design functional enzymes? In this paper,we propose EnzyGen, an approach to learn a unified model to design enzymesacross all functional families. Our key idea is to generate an enzyme's aminoacid sequence and their three-dimensional (3D) coordinates based onfunctionally important sites and substrates corresponding to a desiredcatalytic function. These sites are automatically mined from enzyme databases.EnzyGen consists of a novel interleaving network of attention and neighborhoodequivariant layers, which captures both long-range correlation in an entireprotein sequence and local influence from nearest amino acids in 3D space. Tolearn the generative model, we devise a joint training objective, including asequence generation loss, a position prediction loss and an enzyme-substrateinteraction loss. We further construct EnzyBench, a dataset with 3157 enzymefamilies, covering all available enzymes within the protein data bank (PDB).Experimental results show that our EnzyGen consistently achieves the bestperformance across all 323 testing families, surpassing the best baseline by10.79% in terms of substrate binding affinity. These findings demonstrateEnzyGen's superior capability in designing well-folded and effective enzymesbinding to specific substrates with high affinities.</description><author>Zhenqiao Song, Yunlong Zhao, Wenxian Shi, Wengong Jin, Yang Yang, Lei Li</author><pubDate>Wed, 17 Jul 2024 15:14:32 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.08205v3</guid></item><item><title>Similarity of Neural Architectures using Adversarial Attack Transferability</title><link>http://arxiv.org/abs/2210.11407v4</link><description>In recent years, many deep neural architectures have been developed for imageclassification. Whether they are similar or dissimilar and what factorscontribute to their (dis)similarities remains curious. To address thisquestion, we aim to design a quantitative and scalable similarity measurebetween neural architectures. We propose Similarity by Attack Transferability(SAT) from the observation that adversarial attack transferability containsinformation related to input gradients and decision boundaries widely used tounderstand model behaviors. We conduct a large-scale analysis on 69state-of-the-art ImageNet classifiers using our proposed similarity function toanswer the question. Moreover, we observe neural architecture-related phenomenausing model similarity that model diversity can lead to better performance onmodel ensembles and knowledge distillation under specific conditions. Ourresults provide insights into why developing diverse neural architectures withdistinct components is necessary.</description><author>Jaehui Hwang, Dongyoon Han, Byeongho Heo, Song Park, Sanghyuk Chun, Jong-Seok Lee</author><pubDate>Wed, 17 Jul 2024 15:10:22 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2210.11407v4</guid></item><item><title>Pseudo-keypoint RKHS Learning for Self-supervised 6DoF Pose Estimation</title><link>http://arxiv.org/abs/2311.09500v3</link><description>We address the simulation-to-real domain gap in six degree-of-freedom poseestimation (6DoF PE), and propose a novel self-supervised keypoint voting-based6DoF PE framework, effectively narrowing this gap using a learnable kernel inRKHS. We formulate this domain gap as a distance in high-dimensional featurespace, distinct from previous iterative matching methods. We propose an adapternetwork, which is pre-trained on purely synthetic data with synthetic groundtruth poses, and which evolves the network parameters from this sourcesynthetic domain to the target real domain. Importantly, the real data trainingonly uses pseudo-poses estimated by pseudo-keypoints, and thereby requires noreal ground truth data annotations. Our proposed method is called RKHSPose, andachieves state-of-the-art performance among self-supervised methods on threecommonly used 6DoF PE datasets including LINEMOD (+4.2%), Occlusion LINEMOD(+2%), and YCB-Video (+3%). It also compares favorably to fully supervisedmethods on all six applicable BOP core datasets, achieving within -11.3% to+0.2% of the top fully supervised results.</description><author>Yangzheng Wu, Michael Greenspan</author><pubDate>Wed, 17 Jul 2024 15:10:09 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.09500v3</guid></item><item><title>Zero-shot Text-guided Infinite Image Synthesis with LLM guidance</title><link>http://arxiv.org/abs/2407.12642v1</link><description>Text-guided image editing and generation methods have diverse real-worldapplications. However, text-guided infinite image synthesis faces severalchallenges. First, there is a lack of text-image paired datasets withhigh-resolution and contextual diversity. Second, expanding images based ontext requires global coherence and rich local context understanding. Previousstudies have mainly focused on limited categories, such as natural landscapes,and also required to train on high-resolution images with paired text. Toaddress these challenges, we propose a novel approach utilizing Large LanguageModels (LLMs) for both global coherence and local context understanding,without any high-resolution text-image paired training dataset. We train thediffusion model to expand an image conditioned on global and local captionsgenerated from the LLM and visual feature. At the inference stage, given animage and a global caption, we use the LLM to generate a next local caption toexpand the input image. Then, we expand the image using the global caption,generated local caption and the visual feature to consider global consistencyand spatial local context. In experiments, our model outperforms the baselinesboth quantitatively and qualitatively. Furthermore, our model demonstrates thecapability of text-guided arbitrary-sized image generation in zero-shot mannerwith LLM guidance.</description><author>Soyeong Kwon, Taegyeong Lee, Taehwan Kim</author><pubDate>Wed, 17 Jul 2024 15:10:01 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.12642v1</guid></item><item><title>Profiling quantum circuits for their efficient execution on single- and multi-core architectures</title><link>http://arxiv.org/abs/2407.12640v1</link><description>Application-specific quantum computers offer the most efficient means totackle problems intractable by classical computers. Realizing thesearchitectures necessitates a deep understanding of quantum circuit propertiesand their relationship to execution outcomes on quantum devices. Our study aimsto perform for the first time a rigorous examination of quantum circuits byintroducing graph theory-based metrics extracted from their qubit interactiongraph and gate dependency graph alongside conventional parameters describingthe circuit itself. This methodology facilitates a comprehensive analysis andclustering of quantum circuits. Furthermore, it uncovers a connection betweenparameters rooted in both qubit interaction and gate dependency graphs, and theperformance metrics for quantum circuit mapping, across a range of establishedquantum device and mapping configurations. Among the various deviceconfigurations, we particularly emphasize modular (i.e., multi-core) quantumcomputing architectures due to their high potential as a viable solution forquantum device scalability. This thorough analysis will help us to: i) identifykey attributes of quantum circuits that affect the quantum circuit mappingperformance metrics; ii) predict the performance on a specific chip for similarcircuit structures; iii) determine preferable combinations of mappingtechniques and hardware setups for specific circuits; and iv) definerepresentative benchmark sets by clustering similarly structured circuits.</description><author>Medina Bandic, Pablo le Henaff, Anabel Ovide, Pau Escofet, Sahar Ben Rached, Santiago Rodrigo, Hans van Someren, Sergi Abadal, Eduard Alarcon, Carmen G. Almudever, Sebastian Feld</author><pubDate>Wed, 17 Jul 2024 15:08:50 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.12640v1</guid></item><item><title>ARTEMIS: A Mixed Analog-Stochastic In-DRAM Accelerator for Transformer Neural Networks</title><link>http://arxiv.org/abs/2407.12638v1</link><description>Transformers have emerged as a powerful tool for natural language processing(NLP) and computer vision. Through the attention mechanism, these models haveexhibited remarkable performance gains when compared to conventional approacheslike recurrent neural networks (RNNs) and convolutional neural networks (CNNs).Nevertheless, transformers typically demand substantial execution time due totheir extensive computations and large memory footprint. Processing in-memory(PIM) and near-memory computing (NMC) are promising solutions to acceleratingtransformers as they offer high compute parallelism and memory bandwidth.However, designing PIM/NMC architectures to support the complex operations andmassive amounts of data that need to be moved between layers in transformerneural networks remains a challenge. We propose ARTEMIS, a mixedanalog-stochastic in-DRAM accelerator for transformer models. Through employingminimal changes to the conventional DRAM arrays, ARTEMIS efficiently alleviatesthe costs associated with transformer model execution by supporting stochasticcomputing for multiplications and temporal analog accumulations using a novelin-DRAM metal-on-metal capacitor. Our analysis indicates that ARTEMIS exhibitsat least 3.0x speedup, 1.8x lower energy, and 1.9x better energy efficiencycompared to GPU, TPU, CPU, and state-of-the-art PIM transformer hardwareaccelerators.</description><author>Salma Afifi, Ishan Thakkar, Sudeep Pasricha</author><pubDate>Wed, 17 Jul 2024 15:08:14 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.12638v1</guid></item><item><title>n-Step Temporal Difference Learning with Optimal n</title><link>http://arxiv.org/abs/2303.07068v5</link><description>We consider the problem of finding the optimal value of n in the n-steptemporal difference (TD) learning algorithm. Our objective function for theoptimization problem is the average root mean squared error (RMSE). We find theoptimal n by resorting to a model-free optimization technique involving aone-simulation simultaneous perturbation stochastic approximation (SPSA) basedprocedure. Whereas SPSA is a zeroth-order continuous optimization procedure, weadapt it to the discrete optimization setting by using a random projectionoperator. We prove the asymptotic convergence of the recursion by showing thatthe sequence of n-updates obtained using zeroth-order stochastic gradientsearch converges almost surely to an internally chain transitive invariant setof an associated differential inclusion. This results in convergence of thediscrete parameter sequence to the optimal n in n-step TD. Through experiments,we show that the optimal value of n is achieved with our SDPSA algorithm forarbitrary initial values. We further show using numerical evaluations thatSDPSA outperforms the state-of-the-art discrete parameter stochasticoptimization algorithm Optimal Computing Budget Allocation (OCBA) on benchmarkRL tasks.</description><author>Lakshmi Mandal, Shalabh Bhatnagar</author><pubDate>Wed, 17 Jul 2024 15:07:13 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2303.07068v5</guid></item><item><title>From Fake to Real: Pretraining on Balanced Synthetic Images to Prevent Spurious Correlations in Image Recognition</title><link>http://arxiv.org/abs/2308.04553v3</link><description>Visual recognition models are prone to learning spurious correlations inducedby a biased training set where certain conditions $B$ (\eg, Indoors) areover-represented in certain classes $Y$ (\eg, Big Dogs). Synthetic data fromoff-the-shelf large-scale generative models offers a promising direction tomitigate this issue by augmenting underrepresented subgroups in the realdataset. However, by using a mixed distribution of real and synthetic data, weintroduce another source of bias due to distributional differences betweensynthetic and real data (\eg synthetic artifacts). As we will show, priorwork's approach for using synthetic data to resolve the model's bias toward $B$do not correct the model's bias toward the pair $(B, G)$, where $G$ denoteswhether the sample is real or synthetic. Thus, the model could simply learnsignals based on the pair $(B, G)$ (\eg, Synthetic Indoors) to make predictionsabout $Y$ (\eg, Big Dogs). To address this issue, we propose a simple,easy-to-implement, two-step training pipeline that we call From Fake to Real(FFR). The first step of FFR pre-trains a model on balanced synthetic data tolearn robust representations across subgroups. In the second step, FFRfine-tunes the model on real data using ERM or common loss-based biasmitigation methods. By training on real and synthetic data separately, FFR doesnot expose the model to the statistical differences between real and syntheticdata and thus avoids the issue of bias toward the pair $(B, G)$. Ourexperiments show that FFR improves worst group accuracy over thestate-of-the-art by up to 20\% over three datasets. Code available:\url{https://github.com/mqraitem/From-Fake-to-Real}</description><author>Maan Qraitem, Kate Saenko, Bryan A. Plummer</author><pubDate>Wed, 17 Jul 2024 15:07:01 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2308.04553v3</guid></item><item><title>Toward INT4 Fixed-Point Training via Exploring Quantization Error for Gradients</title><link>http://arxiv.org/abs/2407.12637v1</link><description>Network quantization generally converts full-precision weights and/oractivations into low-bit fixed-point values in order to accelerate an inferenceprocess. Recent approaches to network quantization further discretize thegradients into low-bit fixed-point values, enabling an efficient training. Theytypically set a quantization interval using a min-max range of the gradients oradjust the interval such that the quantization error for entire gradients isminimized. In this paper, we analyze the quantization error of gradients forthe low-bit fixed-point training, and show that lowering the error forlarge-magnitude gradients boosts the quantization performance significantly.Based on this, we derive an upper bound of quantization error for the largegradients in terms of the quantization interval, and obtain an optimalcondition for the interval minimizing the quantization error for largegradients. We also introduce an interval update algorithm that adjusts thequantization interval adaptively to maintain a small quantization error forlarge gradients. Experimental results demonstrate the effectiveness of ourquantization method for various combinations of network architectures andbit-widths on various tasks, including image classification, object detection,and super-resolution.</description><author>Dohyung Kim, Junghyup Lee, Jeimin Jeon, Jaehyeon Moon, Bumsub Ham</author><pubDate>Wed, 17 Jul 2024 15:06:12 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.12637v1</guid></item><item><title>OpenIns3D: Snap and Lookup for 3D Open-vocabulary Instance Segmentation</title><link>http://arxiv.org/abs/2309.00616v4</link><description>In this work, we introduce OpenIns3D, a new 3D-input-only framework for 3Dopen-vocabulary scene understanding. The OpenIns3D framework employs a"Mask-Snap-Lookup" scheme. The "Mask" module learns class-agnostic maskproposals in 3D point clouds, the "Snap" module generates synthetic scene-levelimages at multiple scales and leverages 2D vision-language models to extractinteresting objects, and the "Lookup" module searches through the outcomes of"Snap" to assign category names to the proposed masks. This approach, yetsimple, achieves state-of-the-art performance across a wide range of 3Dopen-vocabulary tasks, including recognition, object detection, and instancesegmentation, on both indoor and outdoor datasets. Moreover, OpenIns3Dfacilitates effortless switching between different 2D detectors withoutrequiring retraining. When integrated with powerful 2D open-world models, itachieves excellent results in scene understanding tasks. Furthermore, whencombined with LLM-powered 2D models, OpenIns3D exhibits an impressivecapability to comprehend and process highly complex text queries that demandintricate reasoning and real-world knowledge. Project page:https://zheninghuang.github.io/OpenIns3D/</description><author>Zhening Huang, Xiaoyang Wu, Xi Chen, Hengshuang Zhao, Lei Zhu, Joan Lasenby</author><pubDate>Wed, 17 Jul 2024 15:05:38 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2309.00616v4</guid></item><item><title>CerberusDet: Unified Multi-Task Object Detection</title><link>http://arxiv.org/abs/2407.12632v1</link><description>Object detection is a core task in computer vision. Over the years, thedevelopment of numerous models has significantly enhanced performance. However,these conventional models are usually limited by the data on which they weretrained and by the category logic they define. With the recent rise ofLanguage-Visual Models, new methods have emerged that are not restricted tothese fixed categories. Despite their flexibility, such Open Vocabularydetection models still fall short in accuracy compared to traditional modelswith fixed classes. At the same time, more accurate data-specific models facechallenges when there is a need to extend classes or merge different datasetsfor training. The latter often cannot be combined due to different logics orconflicting class definitions, making it difficult to improve a model withoutcompromising its performance. In this paper, we introduce CerberusDet, aframework with a multi-headed model designed for handling multiple objectdetection tasks. Proposed model is built on the YOLO architecture andefficiently shares visual features from both backbone and neck components,while maintaining separate task heads. This approach allows CerberusDet toperform very efficiently while still delivering optimal results. We evaluatedthe model on the PASCAL VOC dataset and additional categories from theObjects365 dataset to demonstrate its abilities. CerberusDet achieved resultscomparable to state-of-the-art data-specific models with 36% less inferencetime. The more tasks are trained together, the more efficient the proposedmodel becomes compared to running individual models sequentially. The trainingand inference code, as well as the model, are available as open-source(https://github.com/ai-forever/CerberusDet).</description><author>Irina Tolstykh, Mikhail Chernyshov, Maksim Kuprashevich</author><pubDate>Wed, 17 Jul 2024 15:00:35 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.12632v1</guid></item><item><title>Weighting Pseudo-Labels via High-Activation Feature Index Similarity and Object Detection for Semi-Supervised Segmentation</title><link>http://arxiv.org/abs/2407.12630v1</link><description>Semi-supervised semantic segmentation methods leverage unlabeled data bypseudo-labeling them. Thus the success of these methods hinges on thereliablility of the pseudo-labels. Existing methods mostly choosehigh-confidence pixels in an effort to avoid erroneous pseudo-labels. However,high confidence does not guarantee correct pseudo-labels especially in theinitial training iterations. In this paper, we propose a novel approach toreliably learn from pseudo-labels. First, we unify the predictions from atrained object detector and a semantic segmentation model to identify reliablepseudo-label pixels. Second, we assign different learning weights topseudo-labeled pixels to avoid noisy training signals. To determine theseweights, we first use the reliable pseudo-label pixels identified from thefirst step and labeled pixels to construct a prototype for each class. Then,the per-pixel weight is the structural similarity between the pixel and theprototype measured via rank-statistics similarity. This metric is robust tonoise, making it better suited for comparing features from unlabeled images,particularly in the initial training phases where wrong pseudo labels are proneto occur. We show that our method can be easily integrated into foursemi-supervised semantic segmentation frameworks, and improves them in bothCityscapes and Pascal VOC datasets.</description><author>Prantik Howlader, Hieu Le, Dimitris Samaras</author><pubDate>Wed, 17 Jul 2024 14:58:04 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.12630v1</guid></item><item><title>A Methodology Establishing Linear Convergence of Adaptive Gradient Methods under PL Inequality</title><link>http://arxiv.org/abs/2407.12629v1</link><description>Adaptive gradient-descent optimizers are the standard choice for trainingneural network models. Despite their faster convergence than gradient-descentand remarkable performance in practice, the adaptive optimizers are not as wellunderstood as vanilla gradient-descent. A reason is that the dynamic update ofthe learning rate that helps in faster convergence of these methods also makestheir analysis intricate. Particularly, the simple gradient-descent methodconverges at a linear rate for a class of optimization problems, whereas thepractically faster adaptive gradient methods lack such a theoretical guarantee.The Polyak-{\L}ojasiewicz (PL) inequality is the weakest known class, for whichlinear convergence of gradient-descent and its momentum variants has beenproved. Therefore, in this paper, we prove that AdaGrad and Adam, twowell-known adaptive gradient methods, converge linearly when the cost functionis smooth and satisfies the PL inequality. Our theoretical framework follows asimple and unified approach, applicable to both batch and stochastic gradients,which can potentially be utilized in analyzing linear convergence of othervariants of Adam.</description><author>Kushal Chakrabarti, Mayank Baranwal</author><pubDate>Wed, 17 Jul 2024 14:56:21 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.12629v1</guid></item><item><title>Domain-specific or Uncertainty-aware models: Does it really make a difference for biomedical text classification?</title><link>http://arxiv.org/abs/2407.12626v1</link><description>The success of pretrained language models (PLMs) across a spate of use-caseshas led to significant investment from the NLP community towards buildingdomain-specific foundational models. On the other hand, in mission criticalsettings such as biomedical applications, other aspects also factor in-chief ofwhich is a model's ability to produce reasonable estimates of its ownuncertainty. In the present study, we discuss these two desiderata through thelens of how they shape the entropy of a model's output probabilitydistribution. We find that domain specificity and uncertainty awareness canoften be successfully combined, but the exact task at hand weighs in much morestrongly.</description><author>Aman Sinha, Timothee Mickus, Marianne Clausel, Mathieu Constant, Xavier Coubez</author><pubDate>Wed, 17 Jul 2024 14:52:46 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.12626v1</guid></item><item><title>Rethinking the Architecture Design for Efficient Generic Event Boundary Detection</title><link>http://arxiv.org/abs/2407.12622v1</link><description>Generic event boundary detection (GEBD), inspired by human visual cognitivebehaviors of consistently segmenting videos into meaningful temporal chunks,finds utility in various applications such as video editing and. In this paper,we demonstrate that SOTA GEBD models often prioritize final performance overmodel complexity, resulting in low inference speed and hindering efficientdeployment in real-world scenarios. We contribute to addressing this challengeby experimentally reexamining the architecture of GEBD models and uncoveringseveral surprising findings. Firstly, we reveal that a concise GEBD baselinemodel already achieves promising performance without any sophisticated design.Secondly, we find that the widely applied image-domain backbones in GEBD modelscan contain plenty of architecture redundancy, motivating us to gradually``modernize'' each component to enhance efficiency. Thirdly, we show that theGEBD models using image-domain backbones conducting the spatiotemporal learningin a spatial-then-temporal greedy manner can suffer from a distraction issue,which might be the inefficient villain for GEBD. Using a video-domain backboneto jointly conduct spatiotemporal modeling is an effective solution for thisissue. The outcome of our exploration is a family of GEBD models, namedEfficientGEBD, significantly outperforms the previous SOTA methods by up to1.7\% performance gain and 280\% speedup under the same backbone. Our researchprompts the community to design modern GEBD methods with the consideration ofmodel complexity, particularly in resource-aware applications. The code isavailable at \url{https://github.com/Ziwei-Zheng/EfficientGEBD}.</description><author>Ziwei Zheng, Zechuan Zhang, Yulin Wang, Shiji Song, Gao Huang, Le Yang</author><pubDate>Wed, 17 Jul 2024 14:49:54 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.12622v1</guid></item><item><title>How we won BraTS 2023 Adult Glioma challenge? Just faking it! Enhanced Synthetic Data Augmentation and Model Ensemble for brain tumour segmentation</title><link>http://arxiv.org/abs/2402.17317v2</link><description>Deep Learning is the state-of-the-art technology for segmenting braintumours. However, this requires a lot of high-quality data, which is difficultto obtain, especially in the medical field. Therefore, our solutions addressthis problem by using unconventional mechanisms for data augmentation.Generative adversarial networks and registration are used to massively increasethe amount of available samples for training three different deep learningmodels for brain tumour segmentation, the first task of the BraTS2023challenge. The first model is the standard nnU-Net, the second is the SwinUNETR and the third is the winning solution of the BraTS 2021 Challenge. Theentire pipeline is built on the nnU-Net implementation, except for thegeneration of the synthetic data. The use of convolutional algorithms andtransformers is able to fill each other's knowledge gaps. Using the new metric,our best solution achieves the dice results 0.9005, 0.8673, 0.8509 and HD9514.940, 14.467, 17.699 (whole tumour, tumour core and enhancing tumour) in thevalidation set.</description><author>André Ferreira, Naida Solak, Jianning Li, Philipp Dammann, Jens Kleesiek, Victor Alves, Jan Egger</author><pubDate>Wed, 17 Jul 2024 14:47:18 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.17317v2</guid></item><item><title>Harnessing the Power of Artificial Intelligence to Vitalize Endangered Indigenous Languages: Technologies and Experiences</title><link>http://arxiv.org/abs/2407.12620v1</link><description>Since 2022 we have been exploring application areas and technologies in whichArtificial Intelligence (AI) and modern Natural Language Processing (NLP), suchas Large Language Models (LLMs), can be employed to foster the usage andfacilitate the documentation of Indigenous languages which are in danger ofdisappearing. We start by discussing the decreasing diversity of languages inthe world and how working with Indigenous languages poses unique ethicalchallenges for AI and NLP. To address those challenges, we propose analternative development AI cycle based on community engagement and usage. Then,we report encouraging results in the development of high-quality machinelearning translators for Indigenous languages by fine-tuning state-of-the-art(SOTA) translators with tiny amounts of data and discuss how to avoid somecommon pitfalls in the process. We also present prototypes we have built inprojects done in 2023 and 2024 with Indigenous communities in Brazil, aimed atfacilitating writing, and discuss the development of Indigenous Language Models(ILMs) as a replicable and scalable way to create spell-checkers, next-wordpredictors, and similar tools. Finally, we discuss how we envision a future forlanguage documentation where dying languages are preserved as interactivelanguage models.</description><author>Claudio Pinhanez, Paulo Cavalin, Luciana Storto, Thomas Fimbow, Alexander Cobbinah, Julio Nogima, Marisa Vasconcelos, Pedro Domingues, Priscila de Souza Mizukami, Nicole Grell, Majoí Gongora, Isabel Gonçalves</author><pubDate>Wed, 17 Jul 2024 14:46:37 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.12620v1</guid></item><item><title>MuggleMath: Assessing the Impact of Query and Response Augmentation on Math Reasoning</title><link>http://arxiv.org/abs/2310.05506v3</link><description>In math reasoning with large language models (LLMs), fine-tuning dataaugmentation by query evolution and diverse reasoning paths is empiricallyverified effective, profoundly narrowing the gap between open-sourced LLMs andcutting-edge proprietary LLMs. In this paper, we conduct an investigation forsuch data augmentation in math reasoning and are intended to answer: (1) Whatstrategies of data augmentation are more effective; (2) What is the scalingrelationship between the amount of augmented data and model performance; and(3) Can data augmentation incentivize generalization to out-of-domainmathematical reasoning tasks? To this end, we create two new dataset AugGSM8Kand AugMATH, by complicating and diversifying the queries and sampling multiplereasoning paths from GSM8K and MATH. We obtained a series of LLMs calledMuggleMath by fine-tuning LLaMA models on AugGSM8K and AugMATH. MuggleMathsubstantially achieves new state-of-the-art on GSM8K and MATH. A log-linearrelationship and a segmented log-linear are presented between MuggleMath'sperformance and the amount of augmented data on GSM8K and MATH, respectively.We also find that it is weak in out-of-domain math reasoning generalizationfrom AugGSM8K to MATH and from AugMATH to GSM8K, which suggests that augmentingqueries that cover a broader range of subjects is more beneficial forgeneralization. We release our codes and augmented data inhttps://github.com/OFA-Sys/gsm8k-ScRel.</description><author>Chengpeng Li, Zheng Yuan, Hongyi Yuan, Guanting Dong, Keming Lu, Jiancan Wu, Chuanqi Tan, Xiang Wang, Chang Zhou</author><pubDate>Wed, 17 Jul 2024 14:46:17 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.05506v3</guid></item><item><title>Missing Modality Prediction for Unpaired Multimodal Learning via Joint Embedding of Unimodal Models</title><link>http://arxiv.org/abs/2407.12616v1</link><description>Multimodal learning typically relies on the assumption that all modalitiesare fully available during both the training and inference phases. However, inreal-world scenarios, consistently acquiring complete multimodal data presentssignificant challenges due to various factors. This often leads to the issue ofmissing modalities, where data for certain modalities are absent, posingconsiderable obstacles not only for the availability of multimodal pretrainedmodels but also for their fine-tuning and the preservation of robustness indownstream tasks. To address these challenges, we propose a novel frameworkintegrating parameter-efficient fine-tuning of unimodal pretrained models witha self-supervised joint-embedding learning method. This framework enables themodel to predict the embedding of a missing modality in the representationspace during inference. Our method effectively predicts the missing embeddingthrough prompt tuning, leveraging information from available modalities. Weevaluate our approach on several multimodal benchmark datasets and demonstrateits effectiveness and robustness across various scenarios of missingmodalities.</description><author>Donggeun Kim, Taesup Kim</author><pubDate>Wed, 17 Jul 2024 14:44:25 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.12616v1</guid></item></channel></rss>