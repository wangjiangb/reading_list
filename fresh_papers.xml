<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/"><channel><title>Arxivfresh papers</title><link></link><description>Arxiv paper</description><language>en-US</language><lastBuildDate>Thu, 01 Jun 2023 06:00:12 GMT</lastBuildDate><generator>rfeed v1.0.0</generator><docs>https://github.com/svpino/rfeed/blob/master/README.md</docs><item><title>Humans in 4D: Reconstructing and Tracking Humans with Transformers</title><link>http://arxiv.org/abs/2305.20091v1</link><description>We present an approach to reconstruct humans and track them over time. At thecore of our approach, we propose a fully "transformerized" version of a networkfor human mesh recovery. This network, HMR 2.0, advances the state of the artand shows the capability to analyze unusual poses that have in the past beendifficult to reconstruct from single images. To analyze video, we use 3Dreconstructions from HMR 2.0 as input to a tracking system that operates in 3D.This enables us to deal with multiple people and maintain identities throughocclusion events. Our complete approach, 4DHumans, achieves state-of-the-artresults for tracking people from monocular video. Furthermore, we demonstratethe effectiveness of HMR 2.0 on the downstream task of action recognition,achieving significant improvements over previous pose-based action recognitionapproaches. Our code and models are available on the project website:https://shubham-goel.github.io/4dhumans/.</description><author>Shubham Goel, Georgios Pavlakos, Jathushan Rajasegaran, Angjoo Kanazawa, Jitendra Malik</author><pubDate>Wed, 31 May 2023 18:59:52 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.20091v1</guid></item><item><title>Learning Explicit Contact for Implicit Reconstruction of Hand-held Objects from Monocular Images</title><link>http://arxiv.org/abs/2305.20089v1</link><description>Reconstructing hand-held objects from monocular RGB images is an appealingyet challenging task. In this task, contacts between hands and objects provideimportant cues for recovering the 3D geometry of the hand-held objects. Thoughrecent works have employed implicit functions to achieve impressive progress,they ignore formulating contacts in their frameworks, which results inproducing less realistic object meshes. In this work, we explore how to modelcontacts in an explicit way to benefit the implicit reconstruction of hand-heldobjects. Our method consists of two components: explicit contact prediction andimplicit shape reconstruction. In the first part, we propose a new subtask ofdirectly estimating 3D hand-object contacts from a single image. The part-leveland vertex-level graph-based transformers are cascaded and jointly learned in acoarse-to-fine manner for more accurate contact probabilities. In the secondpart, we introduce a novel method to diffuse estimated contact states from thehand mesh surface to nearby 3D space and leverage diffused contactprobabilities to construct the implicit neural representation for themanipulated object. Benefiting from estimating the interaction patterns betweenthe hand and the object, our method can reconstruct more realistic objectmeshes, especially for object parts that are in contact with hands. Extensiveexperiments on challenging benchmarks show that the proposed method outperformsthe current state of the arts by a great margin.</description><author>Junxing Hu, Hongwen Zhang, Zerui Chen, Mengcheng Li, Yunlong Wang, Yebin Liu, Zhenan Sun</author><pubDate>Wed, 31 May 2023 18:59:26 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.20089v1</guid></item><item><title>Improving CLIP Training with Language Rewrites</title><link>http://arxiv.org/abs/2305.20088v1</link><description>Contrastive Language-Image Pre-training (CLIP) stands as one of the mosteffective and scalable methods for training transferable vision models usingpaired image and text data. CLIP models are trained using contrastive loss,which typically relies on data augmentations to prevent overfitting andshortcuts. However, in the CLIP training paradigm, data augmentations areexclusively applied to image inputs, while language inputs remain unchangedthroughout the entire training process, limiting the exposure of diverse textsto the same image. In this paper, we introduce Language augmented CLIP(LaCLIP), a simple yet highly effective approach to enhance CLIP trainingthrough language rewrites. Leveraging the in-context learning capability oflarge language models, we rewrite the text descriptions associated with eachimage. These rewritten texts exhibit diversity in sentence structure andvocabulary while preserving the original key concepts and meanings. Duringtraining, LaCLIP randomly selects either the original texts or the rewrittenversions as text augmentations for each image. Extensive experiments on CC3M,CC12M, RedCaps and LAION-400M datasets show that CLIP pre-training withlanguage rewrites significantly improves the transfer performance withoutcomputation or memory overhead during training. Specifically for ImageNetzero-shot accuracy, LaCLIP outperforms CLIP by 8.2% on CC12M and 2.4% onLAION-400M. Code is available at https://github.com/LijieFan/LaCLIP.</description><author>Lijie Fan, Dilip Krishnan, Phillip Isola, Dina Katabi, Yonglong Tian</author><pubDate>Wed, 31 May 2023 18:59:04 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.20088v1</guid></item><item><title>Too Large; Data Reduction for Vision-Language Pre-Training</title><link>http://arxiv.org/abs/2305.20087v1</link><description>This paper examines the problems of severe image-text misalignment and highredundancy in the widely-used large-scale Vision-Language Pre-Training (VLP)datasets. To address these issues, we propose an efficient and straightforwardVision-Language learning algorithm called TL;DR, which aims to compress theexisting large VLP data into a small, high-quality set. Our approach consistsof two major steps. First, a codebook-based encoder-decoder captioner isdeveloped to select representative samples. Second, a new caption is generatedto complement the original captions for selected samples, mitigating thetext-image misalignment problem while maintaining uniqueness. As the result,TL;DR enables us to reduce the large dataset into a small set of high-qualitydata, which can serve as an alternative pre-training dataset. This algorithmsignificantly speeds up the time-consuming pretraining process. Specifically,TL;DR can compress the mainstream VLP datasets at a high ratio, e.g., reducewell-cleaned CC3M dataset from 2.82M to 0.67M ($\sim$24\%) and noisy YFCC15Mfrom 15M to 2.5M ($\sim$16.7\%). Extensive experiments with three popular VLPmodels over seven downstream tasks show that VLP model trained on thecompressed dataset provided by TL;DR can perform similar or even better resultscompared with training on the full-scale dataset. The code will be madeavailable at \url{https://github.com/showlab/data-centric.vlp}.</description><author>Alex Jinpeng Wang, Kevin Qinghong Lin, David Junhao Zhang, Stan Weixian Lei, Mike Zheng Shou</author><pubDate>Wed, 31 May 2023 18:59:03 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.20087v1</guid></item><item><title>How to Sift Out a Clean Data Subset in the Presence of Data Poisoning?</title><link>http://arxiv.org/abs/2210.06516v2</link><description>Given the volume of data needed to train modern machine learning models,external suppliers are increasingly used. However, incorporating external dataposes data poisoning risks, wherein attackers manipulate their data to degrademodel utility or integrity. Most poisoning defenses presume access to a set ofclean data (or base set). While this assumption has been taken for granted,given the fast-growing research on stealthy poisoning attacks, a questionarises: can defenders really identify a clean subset within a contaminateddataset to support defenses? This paper starts by examining the impact of poisoned samples on defenseswhen they are mistakenly mixed into the base set. We analyze five defenses andfind that their performance deteriorates dramatically with less than 1%poisoned points in the base set. These findings suggest that sifting out a baseset with high precision is key to these defenses' performance. Motivated bythese observations, we study how precise existing automated tools and humaninspection are at identifying clean data in the presence of data poisoning.Unfortunately, neither effort achieves the precision needed. Worse yet, many ofthe outcomes are worse than random selection. In addition to uncovering the challenge, we propose a practicalcountermeasure, Meta-Sift. Our method is based on the insight that existingattacks' poisoned samples shifts from clean data distributions. Hence, trainingon the clean portion of a dataset and testing on the corrupted portion willresult in high prediction loss. Leveraging the insight, we formulate a bileveloptimization to identify clean data and further introduce a suite of techniquesto improve efficiency and precision. Our evaluation shows that Meta-Sift cansift a clean base set with 100% precision under a wide range of poisoningattacks. The selected base set is large enough to give rise to successfuldefenses.</description><author>Yi Zeng, Minzhou Pan, Himanshu Jahagirdar, Ming Jin, Lingjuan Lyu, Ruoxi Jia</author><pubDate>Wed, 31 May 2023 18:58:32 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2210.06516v2</guid></item><item><title>Understanding and Mitigating Copying in Diffusion Models</title><link>http://arxiv.org/abs/2305.20086v1</link><description>Images generated by diffusion models like Stable Diffusion are increasinglywidespread. Recent works and even lawsuits have shown that these models areprone to replicating their training data, unbeknownst to the user. In thispaper, we first analyze this memorization problem in text-to-image diffusionmodels. While it is widely believed that duplicated images in the training setare responsible for content replication at inference time, we observe that thetext conditioning of the model plays a similarly important role. In fact, wesee in our experiments that data replication often does not happen forunconditional models, while it is common in the text-conditional case.Motivated by our findings, we then propose several techniques for reducing datareplication at both training and inference time by randomizing and augmentingimage captions in the training set.</description><author>Gowthami Somepalli, Vasu Singla, Micah Goldblum, Jonas Geiping, Tom Goldstein</author><pubDate>Wed, 31 May 2023 18:58:02 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.20086v1</guid></item><item><title>Scalable Performance Analysis for Vision-Language Models</title><link>http://arxiv.org/abs/2305.18786v2</link><description>Joint vision-language models have shown great performance over a diverse setof tasks. However, little is known about their limitations, as the highdimensional space learned by these models makes it difficult to identifysemantic errors. Recent work has addressed this problem by designing highlycontrolled probing task benchmarks. Our paper introduces a more scalablesolution that relies on already annotated benchmarks. Our method consists ofextracting a large set of diverse features from a vision-language benchmark andmeasuring their correlation with the output of the target model. We confirmprevious findings that CLIP behaves like a bag of words model and performsbetter with nouns and verbs; we also uncover novel insights such as CLIPgetting confused by concrete words. Our framework is available athttps://github.com/MichiganNLP/Scalable-VLM-Probing and can be used with othermultimodal models and benchmarks.</description><author>Santiago Castro, Oana Ignat, Rada Mihalcea</author><pubDate>Wed, 31 May 2023 18:55:44 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.18786v2</guid></item><item><title>Control4D: Dynamic Portrait Editing by Learning 4D GAN from 2D Diffusion-based Editor</title><link>http://arxiv.org/abs/2305.20082v1</link><description>Recent years have witnessed considerable achievements in editing images withtext instructions. When applying these editors to dynamic scene editing, thenew-style scene tends to be temporally inconsistent due to the frame-by-framenature of these 2D editors. To tackle this issue, we propose Control4D, a novelapproach for high-fidelity and temporally consistent 4D portrait editing.Control4D is built upon an efficient 4D representation with a 2Ddiffusion-based editor. Instead of using direct supervisions from the editor,our method learns a 4D GAN from it and avoids the inconsistent supervisionsignals. Specifically, we employ a discriminator to learn the generationdistribution based on the edited images and then update the generator with thediscrimination signals. For more stable training, multi-level information isextracted from the edited images and used to facilitate the learning of thegenerator. Experimental results show that Control4D surpasses previousapproaches and achieves more photo-realistic and consistent 4D editingperformances. The link to our project website ishttps://control4darxiv.github.io.</description><author>Ruizhi Shao, Jingxiang Sun, Cheng Peng, Zerong Zheng, Boyao Zhou, Hongwen Zhang, Yebin Liu</author><pubDate>Wed, 31 May 2023 18:55:28 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.20082v1</guid></item><item><title>Efficient Diffusion Policies for Offline Reinforcement Learning</title><link>http://arxiv.org/abs/2305.20081v1</link><description>Offline reinforcement learning (RL) aims to learn optimal policies fromoffline datasets, where the parameterization of policies is crucial but oftenoverlooked. Recently, Diffsuion-QL significantly boosts the performance ofoffline RL by representing a policy with a diffusion model, whose successrelies on a parametrized Markov Chain with hundreds of steps for sampling.However, Diffusion-QL suffers from two critical limitations. 1) It iscomputationally inefficient to forward and backward through the whole Markovchain during training. 2) It is incompatible with maximum likelihood-based RLalgorithms (e.g., policy gradient methods) as the likelihood of diffusionmodels is intractable. Therefore, we propose efficient diffusion policy (EDP)to overcome these two challenges. EDP approximately constructs actions fromcorrupted ones at training to avoid running the sampling chain. We conductextensive experiments on the D4RL benchmark. The results show that EDP canreduce the diffusion policy training time from 5 days to 5 hours ongym-locomotion tasks. Moreover, we show that EDP is compatible with variousoffline RL algorithms (TD3, CRR, and IQL) and achieves new state-of-the-art onD4RL by large margins over previous methods. Our code is available athttps://github.com/sail-sg/edp.</description><author>Bingyi Kang, Xiao Ma, Chao Du, Tianyu Pang, Shuicheng Yan</author><pubDate>Wed, 31 May 2023 18:55:21 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.20081v1</guid></item><item><title>Findings of the VarDial Evaluation Campaign 2023</title><link>http://arxiv.org/abs/2305.20080v1</link><description>This report presents the results of the shared tasks organized as part of theVarDial Evaluation Campaign 2023. The campaign is part of the tenth workshop onNatural Language Processing (NLP) for Similar Languages, Varieties and Dialects(VarDial), co-located with EACL 2023. Three separate shared tasks were includedthis year: Slot and intent detection for low-resource language varieties(SID4LR), Discriminating Between Similar Languages -- True Labels (DSL-TL), andDiscriminating Between Similar Languages -- Speech (DSL-S). All three taskswere organized for the first time this year.</description><author>Noëmi Aepli, Çağrı Çöltekin, Rob Van Der Goot, Tommi Jauhiainen, Mourhaf Kazzaz, Nikola Ljubešić, Kai North, Barbara Plank, Yves Scherrer, Marcos Zampieri</author><pubDate>Wed, 31 May 2023 18:55:21 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.20080v1</guid></item><item><title>RARR: Researching and Revising What Language Models Say, Using Language Models</title><link>http://arxiv.org/abs/2210.08726v3</link><description>Language models (LMs) now excel at many tasks such as few-shot learning,question answering, reasoning, and dialog. However, they sometimes generateunsupported or misleading content. A user cannot easily determine whether theiroutputs are trustworthy or not, because most LMs do not have any built-inmechanism for attribution to external evidence. To enable attribution whilestill preserving all the powerful advantages of recent generation models, wepropose RARR (Retrofit Attribution using Research and Revision), a system that1) automatically finds attribution for the output of any text generation modeland 2) post-edits the output to fix unsupported content while preserving theoriginal output as much as possible. When applied to the output of severalstate-of-the-art LMs on a diverse set of generation tasks, we find that RARRsignificantly improves attribution while otherwise preserving the originalinput to a much greater degree than previously explored edit models.Furthermore, the implementation of RARR requires only a handful of trainingexamples, a large language model, and standard web search.</description><author>Luyu Gao, Zhuyun Dai, Panupong Pasupat, Anthony Chen, Arun Tejasvi Chaganty, Yicheng Fan, Vincent Y. Zhao, Ni Lao, Hongrae Lee, Da-Cheng Juan, Kelvin Guu</author><pubDate>Wed, 31 May 2023 18:55:02 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2210.08726v3</guid></item><item><title>Generic Temporal Reasoning with Differential Analysis and Explanation</title><link>http://arxiv.org/abs/2212.10467v2</link><description>Temporal reasoning is the task of predicting temporal relations of eventpairs. While temporal reasoning models can perform reasonably well on in-domainbenchmarks, we have little idea of these systems' generalizability due toexisting datasets' limitations. In this work, we introduce a novel task namedTODAY that bridges this gap with temporal differential analysis, which as thename suggests, evaluates whether systems can correctly understand the effect ofincremental changes. Specifically, TODAY introduces slight contextual changesfor given event pairs, and systems are asked to tell how this subtle contextualchange would affect relevant temporal relation distributions. To facilitatelearning, TODAY also annotates human explanations. We show that existingmodels, including GPT-3.5, drop to random guessing on TODAY, suggesting thatthey heavily rely on spurious information rather than proper reasoning fortemporal predictions. On the other hand, we show that TODAY's supervision styleand explanation annotations can be used in joint learning, encouraging modelsto use more appropriate signals during training and thus outperform acrossseveral benchmarks. TODAY can also be used to train models to solicitincidental supervision from noisy sources such as GPT-3.5, thus moving us moretoward the goal of generic temporal reasoning systems.</description><author>Yu Feng, Ben Zhou, Haoyu Wang, Helen Jin, Dan Roth</author><pubDate>Wed, 31 May 2023 18:54:08 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2212.10467v2</guid></item><item><title>Pythia: A Suite for Analyzing Large Language Models Across Training and Scaling</title><link>http://arxiv.org/abs/2304.01373v2</link><description>How do large language models (LLMs) develop and evolve over the course oftraining? How do these patterns change as models scale? To answer thesequestions, we introduce \textit{Pythia}, a suite of 16 LLMs all trained onpublic data seen in the exact same order and ranging in size from 70M to 12Bparameters. We provide public access to 154 checkpoints for each one of the 16models, alongside tools to download and reconstruct their exact trainingdataloaders for further study. We intend \textit{Pythia} to facilitate researchin many areas, and we present several case studies including novel results inmemorization, term frequency effects on few-shot performance, and reducinggender bias. We demonstrate that this highly controlled setup can be used toyield novel insights toward LLMs and their training dynamics. Trained models,analysis code, training code, and training data can be found at\url{https://github.com/EleutherAI/pythia}.</description><author>Stella Biderman, Hailey Schoelkopf, Quentin Anthony, Herbie Bradley, Kyle O'Brien, Eric Hallahan, Mohammad Aflah Khan, Shivanshu Purohit, USVSN Sai Prashanth, Edward Raff, Aviya Skowron, Lintang Sutawika, Oskar van der Wal</author><pubDate>Wed, 31 May 2023 18:54:07 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2304.01373v2</guid></item><item><title>Managed Geo-Distributed Feature Store: Architecture and System Design</title><link>http://arxiv.org/abs/2305.20077v1</link><description>Companies are using machine learning to solve real-world problems and aredeveloping hundreds to thousands of features in the process. They are buildingfeature engineering pipelines as part of MLOps life cycle to transform datafrom various data sources and materialize the same for future consumption.Without feature stores, different teams across various business groups wouldmaintain the above process independently, which can lead to conflicting andduplicated features in the system. Data scientists find it hard to search forand reuse existing features and it is painful to maintain version control.Furthermore, feature correctness violations related to online (inferencing) -offline (training) skews and data leakage are common. Although the machinelearning community has extensively discussed the need for feature stores andtheir purpose, this paper aims to capture the core architectural componentsthat make up a managed feature store and to share the design learning inbuilding such a system.</description><author>Anya Li, Bhala Ranganathan, Feng Pan, Mickey Zhang, Qianjun Xu, Runhan Li, Sethu Raman, Shail Paragbhai Shah, Vivienne Tang</author><pubDate>Wed, 31 May 2023 18:51:30 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.20077v1</guid></item><item><title>Efficient and Degree-Guided Graph Generation via Discrete Diffusion Modeling</title><link>http://arxiv.org/abs/2305.04111v4</link><description>Diffusion-based generative graph models have been proven effective ingenerating high-quality small graphs. However, they need to be more scalablefor generating large graphs containing thousands of nodes desiring graphstatistics. In this work, we propose EDGE, a new diffusion-based generativegraph model that addresses generative tasks with large graphs. To improvecomputation efficiency, we encourage graph sparsity by using a discretediffusion process that randomly removes edges at each time step and finallyobtains an empty graph. EDGE only focuses on a portion of nodes in the graph ateach denoising step. It makes much fewer edge predictions than previousdiffusion-based models. Moreover, EDGE admits explicitly modeling the nodedegrees of the graphs, further improving the model performance. The empiricalstudy shows that EDGE is much more efficient than competing methods and cangenerate large graphs with thousands of nodes. It also outperforms baselinemodels in generation quality: graphs generated by our approach have moresimilar graph statistics to those of the training graphs.</description><author>Xiaohui Chen, Jiaxing He, Xu Han, Li-Ping Liu</author><pubDate>Wed, 31 May 2023 18:50:17 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.04111v4</guid></item><item><title>Decision-Oriented Dialogue for Human-AI Collaboration</title><link>http://arxiv.org/abs/2305.20076v1</link><description>We describe a class of tasks called dialogue decision problems, in which AIassistants must collaborate with one or more humans via natural language tohelp them make complex decisions. We formalize three domains in which usersface everyday decisions: (1) choosing an assignment of reviewers to conferencepapers, (2) planning a multi-step itinerary in a city, and (3) negotiatingtravel plans for a group of friends. In each of these settings, AI assistantsand users have disparate abilities that they must combine to arrive at the bestdecision: assistants can access and process large amounts of information, whileusers have preferences and constraints external to the system. For each task,we build a dialogue environment where agents receive a reward based on thequality of the final decision they reach. Using these environments, we collecthuman-human dialogues with humans playing the role of assistant. To compare howcurrent AI assistants communicate in these settings, we present baselines usinglarge language models in self-play. Finally, we highlight a number ofchallenges models face in decision-oriented dialogues, ranging from efficientcommunication to reasoning and optimization, and release our environments as atestbed for future modeling work.</description><author>Jessy Lin, Nicholas Tomlin, Jacob Andreas, Jason Eisner</author><pubDate>Wed, 31 May 2023 18:50:02 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.20076v1</guid></item><item><title>Feature Learning in Image Hierarchies using Functional Maximal Correlation</title><link>http://arxiv.org/abs/2305.20074v1</link><description>This paper proposes the Hierarchical Functional Maximal Correlation Algorithm(HFMCA), a hierarchical methodology that characterizes dependencies across twohierarchical levels in multiview systems. By framing view similarities asdependencies and ensuring contrastivity by imposing orthonormality, HFMCAachieves faster convergence and increased stability in self-supervisedlearning. HFMCA defines and measures dependencies within image hierarchies,from pixels and patches to full images. We find that the network topology forapproximating orthonormal basis functions aligns with a vanilla CNN, enablingthe decomposition of density ratios between neighboring layers of feature maps.This approach provides powerful interpretability, revealing the resemblancebetween supervision and self-supervision through the lens of internalrepresentations.</description><author>Bo Hu, Yuheng Bu, José C. Príncipe</author><pubDate>Wed, 31 May 2023 18:48:44 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.20074v1</guid></item><item><title>Dropout Reduces Underfitting</title><link>http://arxiv.org/abs/2303.01500v2</link><description>Introduced by Hinton et al. in 2012, dropout has stood the test of time as aregularizer for preventing overfitting in neural networks. In this study, wedemonstrate that dropout can also mitigate underfitting when used at the startof training. During the early phase, we find dropout reduces the directionalvariance of gradients across mini-batches and helps align the mini-batchgradients with the entire dataset's gradient. This helps counteract thestochasticity of SGD and limit the influence of individual batches on modeltraining. Our findings lead us to a solution for improving performance inunderfitting models - early dropout: dropout is applied only during the initialphases of training, and turned off afterwards. Models equipped with earlydropout achieve lower final training loss compared to their counterpartswithout dropout. Additionally, we explore a symmetric technique forregularizing overfitting models - late dropout, where dropout is not used inthe early iterations and is only activated later in training. Experiments onImageNet and various vision tasks demonstrate that our methods consistentlyimprove generalization accuracy. Our results encourage more research onunderstanding regularization in deep learning and our methods can be usefultools for future neural network training, especially in the era of large data.Code is available at https://github.com/facebookresearch/dropout.</description><author>Zhuang Liu, Zhiqiu Xu, Joseph Jin, Zhiqiang Shen, Trevor Darrell</author><pubDate>Wed, 31 May 2023 18:47:18 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2303.01500v2</guid></item><item><title>Alternating Minimization for Regression with Tropical Rational Functions</title><link>http://arxiv.org/abs/2305.20072v1</link><description>We propose an alternating minimization heuristic for regression over thespace of tropical rational functions with fixed exponents. The methodalternates between fitting the numerator and denominator terms via tropicalpolynomial regression, which is known to admit a closed form solution. Wedemonstrate the behavior of the alternating minimization method experimentally.Experiments demonstrate that the heuristic provides a reasonable approximationof the input data. Our work is motivated by applications to ReLU neuralnetworks, a popular class of network architectures in the machine learningcommunity which are closely related to tropical rational functions.</description><author>Alex Dunbar, Lars Ruthotto</author><pubDate>Wed, 31 May 2023 18:46:14 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.20072v1</guid></item><item><title>A survey on the complexity of learning quantum states</title><link>http://arxiv.org/abs/2305.20069v1</link><description>We survey various recent results that rigorously study the complexity oflearning quantum states. These include progress on quantum tomography, learningphysical quantum states, alternate learning models to tomography and learningclassical functions encoded as quantum states. We highlight how these resultsare paving the way for a highly successful theory with a range of exciting openquestions. To this end, we distill 25 open questions from these results.</description><author>Anurag Anshu, Srinivasan Arunachalam</author><pubDate>Wed, 31 May 2023 18:44:07 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.20069v1</guid></item><item><title>TOFG: A Unified and Fine-Grained Environment Representation in Autonomous Driving</title><link>http://arxiv.org/abs/2305.20068v1</link><description>In autonomous driving, an accurate understanding of environment, e.g., thevehicle-to-vehicle and vehicle-to-lane interactions, plays a critical role inmany driving tasks such as trajectory prediction and motion planning.Environment information comes from high-definition (HD) map and historicaltrajectories of vehicles. Due to the heterogeneity of the map data andtrajectory data, many data-driven models for trajectory prediction and motionplanning extract vehicle-to-vehicle and vehicle-to-lane interactions in aseparate and sequential manner. However, such a manner may capture biasedinterpretation of interactions, causing lower prediction and planning accuracy.Moreover, separate extraction leads to a complicated model structure and hencethe overall efficiency and scalability are sacrificed. To address the aboveissues, we propose an environment representation, Temporal Occupancy Flow Graph(TOFG). Specifically, the occupancy flow-based representation unifies the mapinformation and vehicle trajectories into a homogeneous data format and enablesa consistent prediction. The temporal dependencies among vehicles can helpcapture the change of occupancy flow timely to further promote modelperformance. To demonstrate that TOFG is capable of simplifying the modelarchitecture, we incorporate TOFG with a simple graph attention (GAT) basedneural network and propose TOFG-GAT, which can be used for both trajectoryprediction and motion planning. Experiment results show that TOFG-GAT achievesbetter or competitive performance than all the SOTA baselines with lesstraining time.</description><author>Zihao Wen, Yifan Zhang, Xinhong Chen, Jianping Wang</author><pubDate>Wed, 31 May 2023 18:43:56 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.20068v1</guid></item><item><title>Fast Yet Effective Machine Unlearning</title><link>http://arxiv.org/abs/2111.08947v5</link><description>Unlearning the data observed during the training of a machine learning (ML)model is an important task that can play a pivotal role in fortifying theprivacy and security of ML-based applications. This paper raises the followingquestions: (i) can we unlearn a single or multiple class(es) of data from a MLmodel without looking at the full training data even once? (ii) can we make theprocess of unlearning fast and scalable to large datasets, and generalize it todifferent deep networks? We introduce a novel machine unlearning framework witherror-maximizing noise generation and impair-repair based weight manipulationthat offers an efficient solution to the above questions. An error-maximizingnoise matrix is learned for the class to be unlearned using the original model.The noise matrix is used to manipulate the model weights to unlearn thetargeted class of data. We introduce impair and repair steps for a controlledmanipulation of the network weights. In the impair step, the noise matrix alongwith a very high learning rate is used to induce sharp unlearning in the model.Thereafter, the repair step is used to regain the overall performance. Withvery few update steps, we show excellent unlearning while substantiallyretaining the overall model accuracy. Unlearning multiple classes requires asimilar number of update steps as for a single class, making our approachscalable to large problems. Our method is quite efficient in comparison to theexisting methods, works for multi-class unlearning, does not put anyconstraints on the original optimization mechanism or network design, and workswell in both small and large-scale vision tasks. This work is an important steptowards fast and easy implementation of unlearning in deep networks. Sourcecode: https://github.com/vikram2000b/Fast-Machine-Unlearning</description><author>Ayush K Tarun, Vikram S Chundawat, Murari Mandal, Mohan Kankanhalli</author><pubDate>Wed, 31 May 2023 18:42:15 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2111.08947v5</guid></item><item><title>Accuracy on the Curve: On the Nonlinear Correlation of ML Performance Between Data Subpopulations</title><link>http://arxiv.org/abs/2305.02995v2</link><description>Understanding the performance of machine learning (ML) models across diversedata distributions is critically important for reliable applications. Despiterecent empirical studies positing a near-perfect linear correlation betweenin-distribution (ID) and out-of-distribution (OOD) accuracies, we empiricallydemonstrate that this correlation is more nuanced under subpopulation shifts.Through rigorous experimentation and analysis across a variety of datasets,models, and training epochs, we demonstrate that OOD performance often has anonlinear correlation with ID performance in subpopulation shifts. Ourfindings, which contrast previous studies that have posited a linearcorrelation in model performance during distribution shifts, reveal a "moonshape" correlation (parabolic uptrend curve) between the test performance onthe majority subpopulation and the minority subpopulation. This non-trivialnonlinear correlation holds across model architectures, hyperparameters,training durations, and the imbalance between subpopulations. Furthermore, wefound that the nonlinearity of this "moon shape" is causally influenced by thedegree of spurious correlations in the training data. Our controlledexperiments show that stronger spurious correlation in the training datacreates more nonlinear performance correlation. We provide complementaryexperimental and theoretical analyses for this phenomenon, and discuss itsimplications for ML reliability and fairness. Our work highlights theimportance of understanding the nonlinear effects of model improvement onperformance in different subpopulations, and has the potential to inform thedevelopment of more equitable and responsible machine learning models.</description><author>Weixin Liang, Yining Mao, Yongchan Kwon, Xinyu Yang, James Zou</author><pubDate>Wed, 31 May 2023 18:41:16 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.02995v2</guid></item><item><title>Latent Exploration for Reinforcement Learning</title><link>http://arxiv.org/abs/2305.20065v1</link><description>In Reinforcement Learning, agents learn policies by exploring and interactingwith the environment. Due to the curse of dimensionality, learning policiesthat map high-dimensional sensory input to motor output is particularlychallenging. During training, state of the art methods (SAC, PPO, etc.) explorethe environment by perturbing the actuation with independent Gaussian noise.While this unstructured exploration has proven successful in numerous tasks, itought to be suboptimal for overactuated systems. When multiple actuators, suchas motors or muscles, drive behavior, uncorrelated perturbations riskdiminishing each other's effect, or modifying the behavior in a task-irrelevantway. While solutions to introduce time correlation across action perturbationsexist, introducing correlation across actuators has been largely ignored. Here,we propose LATent TIme-Correlated Exploration (Lattice), a method to injecttemporally-correlated noise into the latent state of the policy network, whichcan be seamlessly integrated with on- and off-policy algorithms. We demonstratethat the noisy actions generated by perturbing the network's activations can bemodeled as a multivariate Gaussian distribution with a full covariance matrix.In the PyBullet locomotion tasks, Lattice-SAC achieves state of the artresults, and reaches 18% higher reward than unstructured exploration in theHumanoid environment. In the musculoskeletal control environments of MyoSuite,Lattice-PPO achieves higher reward in most reaching and object manipulationtasks, while also finding more energy-efficient policies with reductions of20-60%. Overall, we demonstrate the effectiveness of structured action noise intime and actuator space for complex motor control tasks.</description><author>Alberto Silvio Chiappa, Alessandro Marin Vargas, Ann Zixiang Huang, Alexander Mathis</author><pubDate>Wed, 31 May 2023 18:40:43 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.20065v1</guid></item><item><title>Chatting Makes Perfect -- Chat-based Image Retrieval</title><link>http://arxiv.org/abs/2305.20062v1</link><description>Chats emerge as an effective user-friendly approach for informationretrieval, and are successfully employed in many domains, such as customerservice, healthcare, and finance. However, existing image retrieval approachestypically address the case of a single query-to-image round, and the use ofchats for image retrieval has been mostly overlooked. In this work, weintroduce ChatIR: a chat-based image retrieval system that engages in aconversation with the user to elicit information, in addition to an initialquery, in order to clarify the user's search intent. Motivated by thecapabilities of today's foundation models, we leverage Large Language Models togenerate follow-up questions to an initial image description. These questionsform a dialog with the user in order to retrieve the desired image from a largecorpus. In this study, we explore the capabilities of such a system tested on alarge dataset and reveal that engaging in a dialog yields significant gains inimage retrieval. We start by building an evaluation pipeline from an existingmanually generated dataset and explore different modules and trainingstrategies for ChatIR. Our comparison includes strong baselines derived fromrelated applications trained with Reinforcement Learning. Our system is capableof retrieving the target image from a pool of 50K images with over 78% successrate after 5 dialogue rounds, compared to 75% when questions are asked byhumans, and 64% for a single shot text-to-image retrieval. Extensiveevaluations reveal the strong capabilities and examine the limitations ofCharIR under different settings.</description><author>Matan Levy, Rami Ben-Ari, Nir Darshan, Dani Lischinski</author><pubDate>Wed, 31 May 2023 18:38:08 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.20062v1</guid></item><item><title>Exploring Regions of Interest: Visualizing Histological Image Classification for Breast Cancer using Deep Learning</title><link>http://arxiv.org/abs/2305.20058v1</link><description>Computer aided detection and diagnosis systems based on deep learning haveshown promising performance in breast cancer detection. However, there arecases where the obtained results lack justification. In this study, ourobjective is to highlight the regions of interest used by a convolutionalneural network (CNN) for classifying histological images as benign ormalignant. We compare these regions with the regions identified bypathologists. To achieve this, we employed the VGG19 architecture and testedthree visualization methods: Gradient, LRP Z, and LRP Epsilon. Additionally, weexperimented with three pixel selection methods: Bins, K-means, and MeanShift.Based on the results obtained, the Gradient visualization method and theMeanShift selection method yielded satisfactory outcomes for visualizing theimages.</description><author>Imane Nedjar, Mohammed Brahimi, Said Mahmoudi, Khadidja Abi Ayad, Mohammed Amine Chikh</author><pubDate>Wed, 31 May 2023 18:33:28 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.20058v1</guid></item><item><title>Three-Way Trade-Off in Multi-Objective Learning: Optimization, Generalization and Conflict-Avoidance</title><link>http://arxiv.org/abs/2305.20057v1</link><description>Multi-objective learning (MOL) problems often arise in emerging machinelearning problems when there are multiple learning criteria or multiplelearning tasks. Recent works have developed various dynamic weightingalgorithms for MOL such as MGDA and its variants, where the central idea is tofind an update direction that avoids conflicts among objectives. Albeit itsappealing intuition, empirical studies show that dynamic weighting methods maynot always outperform static ones. To understand this theory-practical gap, wefocus on a new stochastic variant of MGDA - the Multi-objective gradient withDouble sampling (MoDo) algorithm, and study the generalization performance ofthe dynamic weighting-based MoDo and its interplay with optimization throughthe lens of algorithm stability. Perhaps surprisingly, we find that the keyrationale behind MGDA -- updating along conflict-avoidant direction - mayhinder dynamic weighting algorithms from achieving the optimal ${\calO}(1/\sqrt{n})$ population risk, where $n$ is the number of training samples.We further demonstrate the variability of dynamic weights on the three-waytrade-off among optimization, generalization, and conflict avoidance that isunique in MOL.</description><author>Lisha Chen, Heshan Fernando, Yiming Ying, Tianyi Chen</author><pubDate>Wed, 31 May 2023 18:31:56 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.20057v1</guid></item><item><title>Rare Life Event Detection via Mobile Sensing Using Multi-Task Learning</title><link>http://arxiv.org/abs/2305.20056v1</link><description>Rare life events significantly impact mental health, and their detection inbehavioral studies is a crucial step towards health-based interventions. Weenvision that mobile sensing data can be used to detect these anomalies.However, the human-centered nature of the problem, combined with theinfrequency and uniqueness of these events makes it challenging forunsupervised machine learning methods. In this paper, we first investigategranger-causality between life events and human behavior using sensing data.Next, we propose a multi-task framework with an unsupervised autoencoder tocapture irregular behavior, and an auxiliary sequence predictor that identifiestransitions in workplace performance to contextualize events. We performexperiments using data from a mobile sensing study comprising N=126 informationworkers from multiple industries, spanning 10106 days with 198 rare events(&lt;2%). Through personalized inference, we detect the exact day of a rare eventwith an F1 of 0.34, demonstrating that our method outperforms severalbaselines. Finally, we discuss the implications of our work from the context ofreal-world deployment.</description><author>Arvind Pillai, Subigya Nepal, Andrew Campbell</author><pubDate>Wed, 31 May 2023 18:29:24 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.20056v1</guid></item><item><title>Cross-Domain Car Detection Model with Integrated Convolutional Block Attention Mechanism</title><link>http://arxiv.org/abs/2305.20055v1</link><description>Car detection, particularly through camera vision, has become a major focusin the field of computer vision and has gained widespread adoption. Whilecurrent car detection systems are capable of good detection, reliable detectioncan still be challenging due to factors such as proximity between the car,light intensity, and environmental visibility. To address these issues, wepropose a cross-domain car detection model that we apply to car recognition forautonomous driving and other areas. Our model includes several novelties:1)Building a complete cross-domain target detection framework. 2)Developing anunpaired target domain picture generation module with an integratedconvolutional attention mechanism. 3)Adopting Generalized Intersection overUnion (GIOU) as the loss function of the target detection framework.4)Designing an object detection model integrated with two-headed ConvolutionalBlock Attention Module(CBAM). 5)Utilizing an effective data enhancement method.To evaluate the model's effectiveness, we performed a reduced will resolutionprocess on the data in the SSLAD dataset and used it as the benchmark datasetfor our task. Experimental results show that the performance of thecross-domain car target detection model improves by 40% over the model withoutour framework, and our improvements have a significant impact on cross-domaincar recognition.</description><author>Haoxuan Xu, Songning Lai, Yang Yang</author><pubDate>Wed, 31 May 2023 18:28:13 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.20055v1</guid></item><item><title>UNSSOR: Unsupervised Neural Speech Separation by Leveraging Over-determined Training Mixtures</title><link>http://arxiv.org/abs/2305.20054v1</link><description>In reverberant conditions with multiple concurrent speakers, each microphoneacquires a mixture signal of multiple speakers at a different location. Inover-determined conditions where the microphones out-number speakers, we cannarrow down the solutions to speaker images and realize unsupervised speechseparation by leveraging each mixture signal as a constraint (i.e., theestimated speaker images at a microphone should add up to the mixture).Equipped with this insight, we propose UNSSOR, an algorithm for$\textbf{u}$nsupervised $\textbf{n}$eural $\textbf{s}$peech$\textbf{s}$eparation by leveraging $\textbf{o}$ver-determined trainingmixtu$\textbf{r}$es. At each training step, we feed an input mixture to a deepneural network (DNN) to produce an intermediate estimate for each speaker,linearly filter the estimates, and optimize a loss so that, at each microphone,the filtered estimates of all the speakers can add up to the mixture to satisfythe above constraint. We show that this loss can promote unsupervisedseparation of speakers. The linear filters are computed in each sub-band basedon the mixture and DNN estimates through the forward convolutive prediction(FCP) algorithm. To address the frequency permutation problem incurred by usingsub-band FCP, a loss term based on minimizing intra-source magnitude scatteringis proposed. Although UNSSOR requires over-determined training mixtures, we cantrain DNNs to achieve under-determined separation (e.g., unsupervised monauralspeech separation). Evaluation results on two-speaker separation in reverberantconditions show the effectiveness and potential of UNSSOR.</description><author>Zhong-Qiu Wang, Shinji Watanabe</author><pubDate>Wed, 31 May 2023 18:28:02 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.20054v1</guid></item><item><title>Rethinking Counterfactual Explanations as Local and Regional Counterfactual Policies</title><link>http://arxiv.org/abs/2209.14568v2</link><description>Counterfactual Explanations (CE) face several unresolved challenges, such asensuring stability, synthesizing multiple CEs, and providing plausibility andsparsity guarantees. From a more practical point of view, recent studies[Pawelczyk et al., 2022] show that the prescribed counterfactual recourses areoften not implemented exactly by individuals and demonstrate that moststate-of-the-art CE algorithms are very likely to fail in this noisyenvironment. To address these issues, we propose a probabilistic framework thatgives a sparse local counterfactual rule for each observation, providing rulesthat give a range of values capable of changing decisions with highprobability. These rules serve as a summary of diverse counterfactualexplanations and yield robust recourses. We further aggregate these local rulesinto a regional counterfactual rule, identifying shared recourses for subgroupsof the data. Our local and regional rules are derived from the Random Forestalgorithm, which offers statistical guarantees and fidelity to datadistribution by selecting recourses in high-density regions. Moreover, ourrules are sparse as we first select the smallest set of variables having a highprobability of changing the decision. We have conducted experiments to validatethe effectiveness of our counterfactual rules in comparison to standard CE andrecent similar attempts. Our methods are available as a Python package.</description><author>Salim I. Amoukou, Nicolas J. B Brunel</author><pubDate>Wed, 31 May 2023 18:27:35 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2209.14568v2</guid></item><item><title>Controlled Text Generation with Hidden Representation Transformations</title><link>http://arxiv.org/abs/2305.19230v2</link><description>We propose CHRT (Control Hidden Representation Transformation) - a controlledlanguage generation framework that steers large language models to generatetext pertaining to certain attributes (such as toxicity). CHRT gains attributecontrol by modifying the hidden representation of the base model throughlearned transformations. We employ a contrastive-learning framework to learnthese transformations that can be combined to gain multi-attribute control. Theeffectiveness of CHRT is experimentally shown by comparing it with sevenbaselines over three attributes. CHRT outperforms all the baselines in the taskof detoxification, positive sentiment steering, and text simplification whileminimizing the loss in linguistic qualities. Further, our approach has thelowest inference latency of only 0.01 seconds more than the base model, makingit the most suitable for high-performance production environments. Weopen-source our code and release two novel datasets to further propelcontrolled language generation research.</description><author>Vaibhav Kumar, Hana Koorehdavoudi, Masud Moshtaghi, Amita Misra, Ankit Chadha, Emilio Ferrara</author><pubDate>Wed, 31 May 2023 18:27:03 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.19230v2</guid></item><item><title>Efficient PDE-Constrained optimization under high-dimensional uncertainty using derivative-informed neural operators</title><link>http://arxiv.org/abs/2305.20053v1</link><description>We propose a novel machine learning framework for solving optimizationproblems governed by large-scale partial differential equations (PDEs) withhigh-dimensional random parameters. Such optimization under uncertainty (OUU)problems may be computational prohibitive using classical methods, particularlywhen a large number of samples is needed to evaluate risk measures at everyiteration of an optimization algorithm, where each sample requires the solutionof an expensive-to-solve PDE. To address this challenge, we propose a newneural operator approximation of the PDE solution operator that has thecombined merits of (1) accurate approximation of not only the map from thejoint inputs of random parameters and optimization variables to the PDE state,but also its derivative with respect to the optimization variables, (2)efficient construction of the neural network using reduced basis architecturesthat are scalable to high-dimensional OUU problems, and (3) requiring only alimited number of training data to achieve high accuracy for both the PDEsolution and the OUU solution. We refer to such neural operators as multi-inputreduced basis derivative informed neural operators (MR-DINOs). We demonstratethe accuracy and efficiency our approach through several numerical experiments,i.e. the risk-averse control of a semilinear elliptic PDE and the steady stateNavier--Stokes equations in two and three spatial dimensions, each involvingrandom field inputs. Across the examples, MR-DINOs offer $10^{3}$--$10^{7}\times$ reductions in execution time, and are able to produce OUU solutions ofcomparable accuracies to those from standard PDE based solutions while beingover $10 \times$ more cost-efficient after factoring in the cost ofconstruction.</description><author>Dingcheng Luo, Thomas O'Leary-Roseberry, Peng Chen, Omar Ghattas</author><pubDate>Wed, 31 May 2023 18:26:20 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.20053v1</guid></item><item><title>Integrated Decision Gradients: Compute Your Attributions Where the Model Makes Its Decision</title><link>http://arxiv.org/abs/2305.20052v1</link><description>Attribution algorithms are frequently employed to explain the decisions ofneural network models. Integrated Gradients (IG) is an influential attributionmethod due to its strong axiomatic foundation. The algorithm is based onintegrating the gradients along a path from a reference image to the inputimage. Unfortunately, it can be observed that gradients computed from regionswhere the output logit changes minimally along the path provide poorexplanations for the model decision, which is called the saturation effectproblem. In this paper, we propose an attribution algorithm called integrateddecision gradients (IDG). The algorithm focuses on integrating gradients fromthe region of the path where the model makes its decision, i.e., the portion ofthe path where the output logit rapidly transitions from zero to its finalvalue. This is practically realized by scaling each gradient by the derivativeof the output logit with respect to the path. The algorithm thereby provides aprincipled solution to the saturation problem. Additionally, we minimize theerrors within the Riemann sum approximation of the path integral by utilizingnon-uniform subdivisions determined by adaptive sampling. In the evaluation onImageNet, it is demonstrated that IDG outperforms IG, left-IG, guided IG, andadversarial gradient integration both qualitatively and quantitatively usingstandard insertion and deletion metrics across three common models.</description><author>Chase Walker, Sumit Jha, Kenny Chen, Rickard Ewetz</author><pubDate>Wed, 31 May 2023 18:25:12 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.20052v1</guid></item><item><title>Simple Disentanglement of Style and Content in Visual Representations</title><link>http://arxiv.org/abs/2302.09795v2</link><description>Learning visual representations with interpretable features, i.e.,disentangled representations, remains a challenging problem. Existing methodsdemonstrate some success but are hard to apply to large-scale vision datasetslike ImageNet. In this work, we propose a simple post-processing framework todisentangle content and style in learned representations from pre-trainedvision models. We model the pre-trained features probabilistically as linearlyentangled combinations of the latent content and style factors and develop asimple disentanglement algorithm based on the probabilistic model. We show thatthe method provably disentangles content and style features and verify itsefficacy empirically. Our post-processed features yield significant domaingeneralization performance improvements when the distribution shift occurs dueto style changes or style-related spurious correlations.</description><author>Lilian Ngweta, Subha Maity, Alex Gittens, Yuekai Sun, Mikhail Yurochkin</author><pubDate>Wed, 31 May 2023 18:25:09 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2302.09795v2</guid></item><item><title>Let's Verify Step by Step</title><link>http://arxiv.org/abs/2305.20050v1</link><description>In recent years, large language models have greatly improved in their abilityto perform complex multi-step reasoning. However, even state-of-the-art modelsstill regularly produce logical mistakes. To train more reliable models, we canturn either to outcome supervision, which provides feedback for a final result,or process supervision, which provides feedback for each intermediate reasoningstep. Given the importance of training reliable models, and given the high costof human feedback, it is important to carefully compare the both methods.Recent work has already begun this comparison, but many questions still remain.We conduct our own investigation, finding that process supervisionsignificantly outperforms outcome supervision for training models to solveproblems from the challenging MATH dataset. Our process-supervised model solves78% of problems from a representative subset of the MATH test set.Additionally, we show that active learning significantly improves the efficacyof process supervision. To support related research, we also release PRM800K,the complete dataset of 800,000 step-level human feedback labels used to trainour best reward model.</description><author>Hunter Lightman, Vineet Kosaraju, Yura Burda, Harri Edwards, Bowen Baker, Teddy Lee, Jan Leike, John Schulman, Ilya Sutskever, Karl Cobbe</author><pubDate>Wed, 31 May 2023 18:24:00 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.20050v1</guid></item><item><title>A Unified Conditional Framework for Diffusion-based Image Restoration</title><link>http://arxiv.org/abs/2305.20049v1</link><description>Diffusion Probabilistic Models (DPMs) have recently shown remarkableperformance in image generation tasks, which are capable of generating highlyrealistic images. When adopting DPMs for image restoration tasks, the crucialaspect lies in how to integrate the conditional information to guide the DPMsto generate accurate and natural output, which has been largely overlooked inexisting works. In this paper, we present a unified conditional framework basedon diffusion models for image restoration. We leverage a lightweight UNet topredict initial guidance and the diffusion model to learn the residual of theguidance. By carefully designing the basic module and integration module forthe diffusion model block, we integrate the guidance and other auxiliaryconditional information into every block of the diffusion model to achievespatially-adaptive generation conditioning. To handle high-resolution images,we propose a simple yet effective inter-step patch-splitting strategy toproduce arbitrary-resolution images without grid artifacts. We evaluate ourconditional framework on three challenging tasks: extreme low-light denoising,deblurring, and JPEG restoration, demonstrating its significant improvements inperceptual quality and the generalization to restoration tasks.</description><author>Yi Zhang, Xiaoyu Shi, Dasong Li, Xiaogang Wang, Jian Wang, Hongsheng Li</author><pubDate>Wed, 31 May 2023 18:22:24 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.20049v1</guid></item><item><title>FD: On understanding the role of deep feature spaces on face generation evaluation</title><link>http://arxiv.org/abs/2305.20048v1</link><description>Perceptual metrics, like the Fr\'echet Inception Distance (FID), are widelyused to assess the similarity between synthetically generated and ground truth(real) images. The key idea behind these metrics is to compute errors in a deepfeature space that captures perceptually and semantically rich image features.Despite their popularity, the effect that different deep features and theirdesign choices have on a perceptual metric has not been well studied. In thiswork, we perform a causal analysis linking differences in semantic attributesand distortions between face image distributions to Fr\'echet distances (FD)using several popular deep feature spaces. A key component of our analysis isthe creation of synthetic counterfactual faces using deep face generators. Ourexperiments show that the FD is heavily influenced by its feature space'straining dataset and objective function. For example, FD using featuresextracted from ImageNet-trained models heavily emphasize hats over regions likethe eyes and mouth. Moreover, FD using features from a face gender classifieremphasize hair length more than distances in an identity (recognition) featurespace. Finally, we evaluate several popular face generation models acrossfeature spaces and find that StyleGAN2 consistently ranks higher than otherface generators, except with respect to identity (recognition) features. Thissuggests the need for considering multiple feature spaces when evaluatinggenerative models and using feature spaces that are tuned to nuances of thedomain of interest.</description><author>Krish Kabra, Guha Balakrishnan</author><pubDate>Wed, 31 May 2023 18:21:58 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.20048v1</guid></item><item><title>LOWA: Localize Objects in the Wild with Attributes</title><link>http://arxiv.org/abs/2305.20047v1</link><description>We present LOWA, a novel method for localizing objects with attributeseffectively in the wild. It aims to address the insufficiency of currentopen-vocabulary object detectors, which are limited by the lack ofinstance-level attribute classification and rare class names. To train LOWA, wepropose a hybrid vision-language training strategy to learn object detectionand recognition with class names as well as attribute information. With LOWA,users can not only detect objects with class names, but also able to localizeobjects by attributes. LOWA is built on top of a two-tower vision-languagearchitecture and consists of a standard vision transformer as the image encoderand a similar transformer as the text encoder. To learn the alignment betweenvisual and text inputs at the instance level, we train LOWA with three trainingsteps: object-level training, attribute-aware learning, and free-text jointtraining of objects and attributes. This hybrid training strategy first ensurescorrect object detection, then incorporates instance-level attributeinformation, and finally balances the object class and attribute sensitivity.We evaluate our model performance of attribute classification and attributelocalization on the Open-Vocabulary Attribute Detection (OVAD) benchmark andthe Visual Attributes in the Wild (VAW) dataset, and experiments indicatestrong zero-shot performance. Ablation studies additionally demonstrate theeffectiveness of each training step of our approach.</description><author>Xiaoyuan Guo, Kezhen Chen, Jinmeng Rao, Yawen Zhang, Baochen Sun, Jie Yang</author><pubDate>Wed, 31 May 2023 18:21:24 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.20047v1</guid></item><item><title>A Hybrid Quantum-Classical Approach based on the Hadamard Transform for the Convolutional Layer</title><link>http://arxiv.org/abs/2305.17510v2</link><description>In this paper, we propose a novel Hadamard Transform (HT)-based neuralnetwork layer for hybrid quantum-classical computing. It implements the regularconvolutional layers in the Hadamard transform domain. The idea is based on theHT convolution theorem which states that the dyadic convolution between twovectors is equivalent to the element-wise multiplication of their HTrepresentation. Computing the HT is simply the application of a Hadamard gateto each qubit individually, so the HT computations of our proposed layer can beimplemented on a quantum computer. Compared to the regular Conv2D layer, theproposed HT-perceptron layer is computationally more efficient. Compared to aCNN with the same number of trainable parameters and 99.26\% test accuracy, ourHT network reaches 99.31\% test accuracy with 57.1\% MACs reduced in the MNISTdataset; and in our ImageNet-1K experiments, our HT-based ResNet-50 exceeds theaccuracy of the baseline ResNet-50 by 0.59\% center-crop top-1 accuracy using11.5\% fewer parameters with 12.6\% fewer MACs.</description><author>Hongyi Pan, Xin Zhu, Salih Atici, Ahmet Enis Cetin</author><pubDate>Wed, 31 May 2023 18:20:48 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.17510v2</guid></item><item><title>Computational Language Assessment in patients with speech, language, and communication impairments</title><link>http://arxiv.org/abs/2305.20046v1</link><description>Speech, language, and communication symptoms enable the early detection,diagnosis, treatment planning, and monitoring of neurocognitive diseaseprogression. Nevertheless, traditional manual neurologic assessment, the speechand language evaluation standard, is time-consuming and resource-intensive forclinicians. We argue that Computational Language Assessment (C.L.A.) is animprovement over conventional manual neurological assessment. Using machinelearning, natural language processing, and signal processing, C.L.A. provides aneuro-cognitive evaluation of speech, language, and communication in elderlyand high-risk individuals for dementia. ii. facilitates the diagnosis,prognosis, and therapy efficacy in at-risk and language-impaired populations;and iii. allows easier extensibility to assess patients from a wide range oflanguages. Also, C.L.A. employs Artificial Intelligence models to inform theoryon the relationship between language symptoms and their neural bases. Itsignificantly advances our ability to optimize the prevention and treatment ofelderly individuals with communication disorders, allowing them to agegracefully with social engagement.</description><author>Charalambos Themistocleous</author><pubDate>Wed, 31 May 2023 18:20:45 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.20046v1</guid></item><item><title>Accurate Shapley Values for explaining tree-based models</title><link>http://arxiv.org/abs/2106.03820v3</link><description>Shapley Values (SV) are widely used in explainable AI, but their estimationand interpretation can be challenging, leading to inaccurate inferences andexplanations. As a starting point, we remind an invariance principle for SV andderive the correct approach for computing the SV of categorical variables thatare particularly sensitive to the encoding used. In the case of tree-basedmodels, we introduce two estimators of Shapley Values that exploit the treestructure efficiently and are more accurate than state-of-the-art methods.Simulations and comparisons are performed with state-of-the-art algorithms andshow the practical gain of our approach. Finally, we discuss the limitations ofShapley Values as a local explanation. These methods are available as a Pythonpackage.</description><author>Salim I. Amoukou, Nicolas J-B. Brunel, Tangi Salaün</author><pubDate>Wed, 31 May 2023 18:19:43 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2106.03820v3</guid></item><item><title>ActiveAED: A Human in the Loop Improves Annotation Error Detection</title><link>http://arxiv.org/abs/2305.20045v1</link><description>Manually annotated datasets are crucial for training and evaluating NaturalLanguage Processing models. However, recent work has discovered that evenwidely-used benchmark datasets contain a substantial number of erroneousannotations. This problem has been addressed with Annotation Error Detection(AED) models, which can flag such errors for human re-annotation. However, eventhough many of these AED methods assume a final curation step in which a humanannotator decides whether the annotation is erroneous, they have been developedas static models without any human-in-the-loop component. In this work, wepropose ActiveAED, an AED method that can detect errors more accurately byrepeatedly querying a human for error corrections in its prediction loop. Weevaluate ActiveAED on eight datasets spanning five different tasks and findthat it leads to improvements over the state of the art on seven of them, withgains of up to six percentage points in average precision.</description><author>Leon Weber, Barbara Plank</author><pubDate>Wed, 31 May 2023 18:18:47 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.20045v1</guid></item><item><title>Surgical tool classification and localization: results and methods from the MICCAI 2022 SurgToolLoc challenge</title><link>http://arxiv.org/abs/2305.07152v2</link><description>The ability to automatically detect and track surgical instruments inendoscopic videos can enable transformational interventions. Assessing surgicalperformance and efficiency, identifying skilled tool use and choreography, andplanning operational and logistical aspects of OR resources are just a few ofthe applications that could benefit. Unfortunately, obtaining the annotationsneeded to train machine learning models to identify and localize surgical toolsis a difficult task. Annotating bounding boxes frame-by-frame is tedious andtime-consuming, yet large amounts of data with a wide variety of surgical toolsand surgeries must be captured for robust training. Moreover, ongoing annotatortraining is needed to stay up to date with surgical instrument innovation. Inrobotic-assisted surgery, however, potentially informative data like timestampsof instrument installation and removal can be programmatically harvested. Theability to rely on tool installation data alone would significantly reduce theworkload to train robust tool-tracking models. With this motivation in mind weinvited the surgical data science community to participate in the challenge,SurgToolLoc 2022. The goal was to leverage tool presence data as weak labelsfor machine learning models trained to detect tools and localize them in videoframes with bounding boxes. We present the results of this challenge along withmany of the team's efforts. We conclude by discussing these results in thebroader context of machine learning and surgical data science. The trainingdata used for this challenge consisting of 24,695 video clips with toolpresence labels is also being released publicly and can be accessed athttps://console.cloud.google.com/storage/browser/isi-surgtoolloc-2022.</description><author>Aneeq Zia, Kiran Bhattacharyya, Xi Liu, Max Berniker, Ziheng Wang, Rogerio Nespolo, Satoshi Kondo, Satoshi Kasai, Kousuke Hirasawa, Bo Liu, David Austin, Yiheng Wang, Michal Futrega, Jean-Francois Puget, Zhenqiang Li, Yoichi Sato, Ryo Fujii, Ryo Hachiuma, Mana Masuda, Hideo Saito, An Wang, Mengya Xu, Mobarakol Islam, Long Bai, Winnie Pang, Hongliang Ren, Chinedu Nwoye, Luca Sestini, Nicolas Padoy, Maximilian Nielsen, Samuel Schüttler, Thilo Sentker, Hümeyra Husseini, Ivo Baltruschat, Rüdiger Schmitz, René Werner, Aleksandr Matsun, Mugariya Farooq, Numan Saaed, Jose Renato Restom Viera, Mohammad Yaqub, Neil Getty, Fangfang Xia, Zixuan Zhao, Xiaotian Duan, Xing Yao, Ange Lou, Hao Yang, Jintong Han, Jack Noble, Jie Ying Wu, Tamer Abdulbaki Alshirbaji, Nour Aldeen Jalal, Herag Arabian, Ning Di</author><pubDate>Wed, 31 May 2023 18:17:21 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.07152v2</guid></item><item><title>Adaptive Conformal Prediction by Reweighting Nonconformity Score</title><link>http://arxiv.org/abs/2303.12695v2</link><description>Despite attractive theoretical guarantees and practical successes, PredictiveInterval (PI) given by Conformal Prediction (CP) may not reflect theuncertainty of a given model. This limitation arises from CP methods using aconstant correction for all test points, disregarding their individualuncertainties, to ensure coverage properties. To address this issue, we proposeusing a Quantile Regression Forest (QRF) to learn the distribution ofnonconformity scores and utilizing the QRF's weights to assign more importanceto samples with residuals similar to the test point. This approach results inPI lengths that are more aligned with the model's uncertainty. In addition, theweights learnt by the QRF provide a partition of the features space, allowingfor more efficient computations and improved adaptiveness of the PI throughgroupwise conformalization. Our approach enjoys an assumption-free finitesample marginal and training-conditional coverage, and under suitableassumptions, it also ensures conditional coverage. Our methods work for anynonconformity score and are available as a Python package. We conductexperiments on simulated and real-world data that demonstrate significantimprovements compared to existing methods.</description><author>Salim I. Amoukou, Nicolas J. B Brunel</author><pubDate>Wed, 31 May 2023 18:15:22 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2303.12695v2</guid></item><item><title>Deception by Omission: Using Adversarial Missingness to Poison Causal Structure Learning</title><link>http://arxiv.org/abs/2305.20043v1</link><description>Inference of causal structures from observational data is a key component ofcausal machine learning; in practice, this data may be incompletely observed.Prior work has demonstrated that adversarial perturbations of completelyobserved training data may be used to force the learning of inaccurate causalstructural models (SCMs). However, when the data can be audited for correctness(e.g., it is crytographically signed by its source), this adversarial mechanismis invalidated. This work introduces a novel attack methodology wherein theadversary deceptively omits a portion of the true training data to bias thelearned causal structures in a desired manner. Theoretically sound attackmechanisms are derived for the case of arbitrary SCMs, and a sample-efficientlearning-based heuristic is given for Gaussian SCMs. Experimental validation ofthese approaches on real and synthetic data sets demonstrates the effectivenessof adversarial missingness attacks at deceiving popular causal structurelearning algorithms.</description><author>Deniz Koyuncu, Alex Gittens, Bülent Yener, Moti Yung</author><pubDate>Wed, 31 May 2023 18:14:20 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.20043v1</guid></item><item><title>Grammar Prompting for Domain-Specific Language Generation with Large Language Models</title><link>http://arxiv.org/abs/2305.19234v2</link><description>Large language models (LLMs) can learn to perform a wide range of naturallanguage tasks from just a handful of in-context examples. However, forgenerating strings from highly structured languages (e.g., semantic parsing tocomplex domain-specific languages), it is challenging for the LLM to generalizefrom just a few exemplars. We explore $\textbf{grammar prompting}$ as a simpleapproach for enabling LLMs to use external knowledge and domain-specificconstraints, expressed through a grammar expressed in Backus--Naur Form (BNF),during in-context learning. Grammar prompting augments each demonstrationexample with a specialized grammar that is minimally sufficient for generatingthe particular output example, where the specialized grammar is a subset of thefull DSL grammar. For inference, the LLM first predicts a BNF grammar given atest input, and then generates the output according to the rules of thegrammar. Experiments demonstrate that grammar prompting can enable LLMs toperform competitively on a diverse set of DSL generation tasks, includingsemantic parsing (SMCalFlow, Overnight, GeoQuery), PDDL planning, and evenmolecule generation (SMILES).</description><author>Bailin Wang, Zi Wang, Xuezhi Wang, Yuan Cao, Rif A. Saurous, Yoon Kim</author><pubDate>Wed, 31 May 2023 18:13:25 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.19234v2</guid></item><item><title>Zero-Shot Machine Unlearning</title><link>http://arxiv.org/abs/2201.05629v3</link><description>Modern privacy regulations grant citizens the right to be forgotten byproducts, services and companies. In case of machine learning (ML)applications, this necessitates deletion of data not only from storage archivesbut also from ML models. Due to an increasing need for regulatory compliancerequired for ML applications, machine unlearning is becoming an emergingresearch problem. The right to be forgotten requests come in the form ofremoval of a certain set or class of data from the already trained ML model.Practical considerations preclude retraining of the model from scratch afterdiscarding the deleted data. The few existing studies use either the wholetraining data, or a subset of training data, or some metadata stored duringtraining to update the model weights for unlearning. However, in many cases, nodata related to the training process or training samples may be accessible forthe unlearning purpose. We therefore ask the question: is it possible toachieve unlearning with zero training samples? In this paper, we introduce thenovel problem of zero-shot machine unlearning that caters for the extreme butpractical scenario where zero original data samples are available for use. Wethen propose two novel solutions for zero-shot machine unlearning based on (a)error minimizing-maximizing noise and (b) gated knowledge transfer. Thesemethods remove the information of the forget data from the model whilemaintaining the model efficacy on the retain data. The zero-shot approachoffers good protection against the model inversion attacks and membershipinference attacks. We introduce a new evaluation metric, Anamnesis Index (AIN)to effectively measure the quality of the unlearning method. The experimentsshow promising results for unlearning in deep learning models on benchmarkvision data-sets. The source code is available here:https://github.com/ayu987/zero-shot-unlearning</description><author>Vikram S Chundawat, Ayush K Tarun, Murari Mandal, Mohan Kankanhalli</author><pubDate>Wed, 31 May 2023 18:13:20 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2201.05629v3</guid></item><item><title>Cooperative Open-ended Learning Framework for Zero-shot Coordination</title><link>http://arxiv.org/abs/2302.04831v2</link><description>Zero-shot coordination in cooperative artificial intelligence (AI) remains asignificant challenge, which means effectively coordinating with a wide rangeof unseen partners. Previous algorithms have attempted to address thischallenge by optimizing fixed objectives within a population to improvestrategy or behaviour diversity. However, these approaches can result in a lossof learning and an inability to cooperate with certain strategies within thepopulation, known as cooperative incompatibility. To address this issue, wepropose the Cooperative Open-ended LEarning (COLE) framework, which constructsopen-ended objectives in cooperative games with two players from theperspective of graph theory to assess and identify the cooperative ability ofeach strategy. We further specify the framework and propose a practicalalgorithm that leverages knowledge from game theory and graph theory.Furthermore, an analysis of the learning process of the algorithm shows that itcan efficiently overcome cooperative incompatibility. The experimental resultsin the Overcooked game environment demonstrate that our method outperformscurrent state-of-the-art methods when coordinating with different-levelpartners. Our demo is available at https://sites.google.com/view/cole-2023.</description><author>Yang Li, Shao Zhang, Jichen Sun, Yali Du, Ying Wen, Xinbing Wang, Wei Pan</author><pubDate>Wed, 31 May 2023 18:04:02 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2302.04831v2</guid></item><item><title>Invariant Scattering Transform for Medical Imaging</title><link>http://arxiv.org/abs/2304.10582v2</link><description>Over the years, the Invariant Scattering Transform (IST) technique has becomepopular for medical image analysis, including using wavelet transformcomputation using Convolutional Neural Networks (CNN) to capture patterns'scale and orientation in the input signal. IST aims to be invariant totransformations that are common in medical images, such as translation,rotation, scaling, and deformation, used to improve the performance in medicalimaging applications such as segmentation, classification, and registration,which can be integrated into machine learning algorithms for disease detection,diagnosis, and treatment planning. Additionally, combining IST with deeplearning approaches has the potential to leverage their strengths and enhancemedical image analysis outcomes. This study provides an overview of IST inmedical imaging by considering the types of IST, their application,limitations, and potential scopes for future researchers and practitioners.</description><author>Md Manjurul Ahsan, Shivakumar Raman, Zahed Siddique</author><pubDate>Wed, 31 May 2023 18:02:48 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2304.10582v2</guid></item><item><title>Tree-Ring Watermarks: Fingerprints for Diffusion Images that are Invisible and Robust</title><link>http://arxiv.org/abs/2305.20030v1</link><description>Watermarking the outputs of generative models is a crucial technique fortracing copyright and preventing potential harm from AI-generated content. Inthis paper, we introduce a novel technique called Tree-Ring Watermarking thatrobustly fingerprints diffusion model outputs. Unlike existing methods thatperform post-hoc modifications to images after sampling, Tree-Ring Watermarkingsubtly influences the entire sampling process, resulting in a model fingerprintthat is invisible to humans. The watermark embeds a pattern into the initialnoise vector used for sampling. These patterns are structured in Fourier spaceso that they are invariant to convolutions, crops, dilations, flips, androtations. After image generation, the watermark signal is detected byinverting the diffusion process to retrieve the noise vector, which is thenchecked for the embedded signal. We demonstrate that this technique can beeasily applied to arbitrary diffusion models, including text-conditioned StableDiffusion, as a plug-in with negligible loss in FID. Our watermark issemantically hidden in the image space and is far more robust than watermarkingalternatives that are currently deployed. Code is available atgithub.com/YuxinWenRick/tree-ring-watermark.</description><author>Yuxin Wen, John Kirchenbauer, Jonas Geiping, Tom Goldstein</author><pubDate>Wed, 31 May 2023 18:00:31 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.20030v1</guid></item><item><title>A Study of Bayesian Neural Network Surrogates for Bayesian Optimization</title><link>http://arxiv.org/abs/2305.20028v1</link><description>Bayesian optimization is a highly efficient approach to optimizing objectivefunctions which are expensive to query. These objectives are typicallyrepresented by Gaussian process (GP) surrogate models which are easy tooptimize and support exact inference. While standard GP surrogates have beenwell-established in Bayesian optimization, Bayesian neural networks (BNNs) haverecently become practical function approximators, with many benefits overstandard GPs such as the ability to naturally handle non-stationarity and learnrepresentations for high-dimensional data. In this paper, we study BNNs asalternatives to standard GP surrogates for optimization. We consider a varietyof approximate inference procedures for finite-width BNNs, includinghigh-quality Hamiltonian Monte Carlo, low-cost stochastic MCMC, and heuristicssuch as deep ensembles. We also consider infinite-width BNNs and partiallystochastic models such as deep kernel learning. We evaluate this collection ofsurrogate models on diverse problems with varying dimensionality, number ofobjectives, non-stationarity, and discrete and continuous inputs. We find: (i)the ranking of methods is highly problem dependent, suggesting the need fortailored inductive biases; (ii) HMC is the most successful approximateinference procedure for fully stochastic BNNs; (iii) full stochasticity may beunnecessary as deep kernel learning is relatively competitive; (iv)infinite-width BNNs are particularly promising, especially in high dimensions.</description><author>Yucen Lily Li, Tim G. J. Rudner, Andrew Gordon Wilson</author><pubDate>Wed, 31 May 2023 18:00:00 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.20028v1</guid></item><item><title>Variational $f$-Divergence and Derangements for Discriminative Mutual Information Estimation</title><link>http://arxiv.org/abs/2305.20025v1</link><description>The accurate estimation of the mutual information is a crucial task invarious applications, including machine learning, communications, and biology,since it enables the understanding of complex systems. High-dimensional datarender the task extremely challenging due to the amount of data to be processedand the presence of convoluted patterns. Neural estimators based on variationallower bounds of the mutual information have gained attention in recent yearsbut they are prone to either high bias or high variance as a consequence of thepartition function. We propose a novel class of discriminative mutualinformation estimators based on the variational representation of the$f$-divergence. We investigate the impact of the permutation function used toobtain the marginal training samples and present a novel architectural solutionbased on derangements. The proposed estimator is flexible as it exhibits anexcellent bias/variance trade-off. Experiments on reference scenariosdemonstrate that our approach outperforms state-of-the-art neural estimatorsboth in terms of accuracy and complexity.</description><author>Nunzio A. Letizia, Nicola Novello, Andrea M. Tonello</author><pubDate>Wed, 31 May 2023 17:54:25 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.20025v1</guid></item><item><title>Bias Mitigation Methods for Binary Classification Decision-Making Systems: Survey and Recommendations</title><link>http://arxiv.org/abs/2305.20020v1</link><description>Bias mitigation methods for binary classification decision-making systemshave been widely researched due to the ever-growing importance of designingfair machine learning processes that are impartial and do not discriminateagainst individuals or groups based on protected personal characteristics. Inthis paper, we present a structured overview of the research landscape for biasmitigation methods, report on their benefits and limitations, and providerecommendations for the development of future bias mitigation methods forbinary classification.</description><author>Madeleine Waller, Odinaldo Rodrigues, Oana Cocarascu</author><pubDate>Wed, 31 May 2023 17:48:34 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.20020v1</guid></item><item><title>Monotonic Location Attention for Length Generalization</title><link>http://arxiv.org/abs/2305.20019v1</link><description>We explore different ways to utilize position-based cross-attention inseq2seq networks to enable length generalization in algorithmic tasks. We showthat a simple approach of interpolating the original and reversed encodedrepresentations combined with relative attention allows near-perfect lengthgeneralization for both forward and reverse lookup tasks or copy tasks that hadbeen generally hard to tackle. We also devise harder diagnostic tasks where therelative distance of the ideal attention position varies with timestep. In suchsettings, the simple interpolation trick with relative attention is notsufficient. We introduce novel variants of location attention building on topof Dubois et al. (2020) to address the new diagnostic tasks. We also show thebenefits of our approaches for length generalization in SCAN (Lake &amp; Baroni,2018) and CFQ (Keysers et al., 2020). Our code is available on GitHub.</description><author>Jishnu Ray Chowdhury, Cornelia Caragea</author><pubDate>Wed, 31 May 2023 17:48:06 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.20019v1</guid></item><item><title>Scalable Learning of Latent Language Structure With Logical Offline Cycle Consistency</title><link>http://arxiv.org/abs/2305.20018v1</link><description>We introduce Logical Offline Cycle Consistency Optimization (LOCCO), ascalable, semi-supervised method for training a neural semantic parser.Conceptually, LOCCO can be viewed as a form of self-learning where the semanticparser being trained is used to generate annotations for unlabeled text thatare then used as new supervision. To increase the quality of annotations, ourmethod utilizes a count-based prior over valid formal meaning representationsand a cycle-consistency score produced by a neural text generation model asadditional signals. Both the prior and semantic parser are updated in analternate fashion from full passes over the training data, which can be seen asapproximating the marginalization of latent structures through stochasticvariational inference. The use of a count-based prior, frozen text generationmodel, and offline annotation process yields an approach with negligiblecomplexity and latency increases as compared to conventional self-learning. Asan added bonus, the annotations produced by LOCCO can be trivially repurposedto train a neural text generation model. We demonstrate the utility of LOCCO onthe well-known WebNLG benchmark where we obtain an improvement of 2 pointsagainst a self-learning parser under equivalent conditions, an improvement of1.3 points against the previous state-of-the-art parser, and competitive textgeneration performance in terms of BLEU score.</description><author>Maxwell Crouse, Ramon Astudillo, Tahira Naseem, Subhajit Chaudhury, Pavan Kapanipathi, Salim Roukos, Alexander Gray</author><pubDate>Wed, 31 May 2023 17:47:20 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.20018v1</guid></item><item><title>AI for Low-Code for AI</title><link>http://arxiv.org/abs/2305.20015v1</link><description>Low-code programming allows citizen developers to create programs withminimal coding effort, typically via visual (e.g. drag-and-drop) interfaces. Inparallel, recent AI-powered tools such as Copilot and ChatGPT generate programsfrom natural language instructions. We argue that these modalities arecomplementary: tools like ChatGPT greatly reduce the need to memorize largeAPIs but still require their users to read (and modify) programs, whereasvisual tools abstract away most or all programming but struggle to provide easyaccess to large APIs. At their intersection, we propose LowCoder, the firstlow-code tool for developing AI pipelines that supports both a visualprogramming interface (LowCoder_VP) and an AI-powered natural languageinterface (LowCoder_NL). We leverage this tool to provide some of the firstinsights into whether and how these two modalities help programmers byconducting a user study. We task 20 developers with varying levels of AIexpertise with implementing four ML pipelines using LowCoder, replacing theLowCoder_NL component with a simple keyword search in half the tasks. Overall,we find that LowCoder is especially useful for (i) Discoverability: usingLowCoder_NL, participants discovered new operators in 75% of the tasks,compared to just 32.5% and 27.5% using web search or scrolling through optionsrespectively in the keyword-search condition, and (ii) Iterative Composition:82.5% of tasks were successfully completed and many initial pipelines werefurther successfully improved. Qualitative analysis shows that AI helps usersdiscover how to implement constructs when they know what to do, but still failsto support novices when they lack clarity on what they want to accomplish.Overall, our work highlights the benefits of combining the power of AI withlow-code programming.</description><author>Nikitha Rao, Jason Tsay, Kiran Kate, Vincent J. Hellendoorn, Martin Hirzel</author><pubDate>Wed, 31 May 2023 17:44:03 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.20015v1</guid></item><item><title>Few Shot Learning for Medical Imaging: A Comparative Analysis of Methodologies and Formal Mathematical Framework</title><link>http://arxiv.org/abs/2305.04401v2</link><description>Deep learning becomes an elevated context regarding disposing of many machinelearning tasks and has shown a breakthrough upliftment to extract features fromunstructured data. Though this flourishing context is developing in the medicalimage processing sector, scarcity of problem-dependent training data has becomea larger issue in the way of easy application of deep learning in the medicalsector. To unravel the confined data source, researchers have developed a modelthat can solve machine learning problems with fewer data called ``Few shotlearning". Few hot learning algorithms determine to solve the data limitationproblems by extracting the characteristics from a small dataset throughclassification and segmentation methods. In the medical sector, there isfrequently a shortage of available datasets in respect of some confidentialdiseases. Therefore, Few shot learning gets the limelight in this data scarcitysector. In this chapter, the background and basic overview of a few shots oflearning is represented. Henceforth, the classification of few-shot learning isdescribed also. Even the paper shows a comparison of methodological approachesthat are applied in medical image analysis over time. The current advancementin the implementation of few-shot learning concerning medical imaging isillustrated. The future scope of this domain in the medical imaging sector isfurther described.</description><author>Jannatul Nayem, Sayed Sahriar Hasan, Noshin Amina, Bristy Das, Md Shahin Ali, Md Manjurul Ahsan, Shivakumar Raman</author><pubDate>Wed, 31 May 2023 17:35:08 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.04401v2</guid></item><item><title>Constrained Causal Bayesian Optimization</title><link>http://arxiv.org/abs/2305.20011v1</link><description>We propose constrained causal Bayesian optimization (cCBO), an approach forfinding interventions in a known causal graph that optimize a target variableunder some constraints. cCBO first reduces the search space by exploiting thegraph structure and, if available, an observational dataset; and then solvesthe restricted optimization problem by modelling target and constraintquantities using Gaussian processes and by sequentially selecting interventionsvia a constrained expected improvement acquisition function. We proposedifferent surrogate models that enable to integrate observational andinterventional data while capturing correlation among effects with increasinglevels of sophistication. We evaluate cCBO on artificial and real-world causalgraphs showing successful trade off between fast convergence and percentage offeasible interventions.</description><author>Virginia Aglietti, Alan Malek, Ira Ktena, Silvia Chiappa</author><pubDate>Wed, 31 May 2023 17:34:58 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.20011v1</guid></item><item><title>HUB: Guiding Learned Optimizers with Continuous Prompt Tuning</title><link>http://arxiv.org/abs/2305.16823v2</link><description>Learned optimizers are a crucial component of meta-learning. Recentadvancements in scalable learned optimizers have demonstrated their superiorperformance over hand-designed optimizers in various tasks. However, certaincharacteristics of these models, such as an unstable learning curve, limitedability to handle unseen tasks and network architectures, difficult-to-controlbehaviours, and poor performance in fine-tuning tasks impede their widespreadadoption. To tackle the issue of generalization in scalable learned optimizers,we propose a hybrid-update-based (HUB) optimization strategy inspired by recentadvancements in hard prompt tuning and result selection techniques used inlarge language and vision models. This approach can be easily applied to anytask that involves hand-designed or learned optimizer. By incorporatinghand-designed optimizers as the second component in our hybrid approach, we areable to retain the benefits of learned optimizers while stabilizing thetraining process and, more importantly, improving testing performance. Wevalidate our design through a total of 17 tasks, consisting of thirteentraining from scratch and four fine-tuning settings. These tasks vary in modelsizes, architectures, or dataset sizes, and the competing optimizers arehyperparameter-tuned. We outperform all competitors in 94% of the tasks withbetter testing performance. Furthermore, we conduct a theoretical analysis toexamine the potential impact of our hybrid strategy on the behaviours andinherited traits of learned optimizers.</description><author>Gaole Dai, Wei Wu, Ziyu Wang, Jie Fu, Shanghang Zhang, Tiejun Huang</author><pubDate>Wed, 31 May 2023 17:33:35 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.16823v2</guid></item><item><title>Human or Not? A Gamified Approach to the Turing Test</title><link>http://arxiv.org/abs/2305.20010v1</link><description>We present "Human or Not?", an online game inspired by the Turing test, thatmeasures the capability of AI chatbots to mimic humans in dialog, and of humansto tell bots from other humans. Over the course of a month, the game was playedby over 1.5 million users who engaged in anonymous two-minute chat sessionswith either another human or an AI language model which was prompted to behavelike humans. The task of the players was to correctly guess whether they spoketo a person or to an AI. This largest scale Turing-style test conducted to daterevealed some interesting facts. For example, overall users guessed theidentity of their partners correctly in only 68% of the games. In the subset ofthe games in which users faced an AI bot, users had even lower correct guessrates of 60% (that is, not much higher than chance). This white paper detailsthe development, deployment, and results of this unique experiment. While thisexperiment calls for many extensions and refinements, these findings alreadybegin to shed light on the inevitable near future which will commingle humansand AI.</description><author>Daniel Jannai, Amos Meron, Barak Lenz, Yoav Levine, Yoav Shoham</author><pubDate>Wed, 31 May 2023 17:32:22 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.20010v1</guid></item><item><title>Protein Design with Guided Discrete Diffusion</title><link>http://arxiv.org/abs/2305.20009v1</link><description>A popular approach to protein design is to combine a generative model with adiscriminative model for conditional sampling. The generative model samplesplausible sequences while the discriminative model guides a search forsequences with high fitness. Given its broad success in conditional sampling,classifier-guided diffusion modeling is a promising foundation for proteindesign, leading many to develop guided diffusion models for structure withinverse folding to recover sequences. In this work, we propose diffusioNOptimized Sampling (NOS), a guidance method for discrete diffusion models thatfollows gradients in the hidden states of the denoising network. NOS makes itpossible to perform design directly in sequence space, circumventingsignificant limitations of structure-based methods, including scarce data andchallenging inverse design. Moreover, we use NOS to generalize LaMBO, aBayesian optimization procedure for sequence design that facilitates multipleobjectives and edit-based constraints. The resulting method, LaMBO-2, enablesdiscrete diffusions and stronger performance with limited edits through a novelapplication of saliency maps. We apply LaMBO-2 to a real-world protein designtask, optimizing antibodies for higher expression yield and binding affinity toa therapeutic target under locality and liability constraints, with 97%expression rate and 25% binding rate in exploratory in vitro experiments.</description><author>Nate Gruver, Samuel Stanton, Nathan C. Frey, Tim G. J. Rudner, Isidro Hotzel, Julien Lafrance-Vanasse, Arvind Rajpal, Kyunghyun Cho, Andrew Gordon Wilson</author><pubDate>Wed, 31 May 2023 17:31:24 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.20009v1</guid></item><item><title>Physics-Informed Ensemble Representation for Light-Field Image Super-Resolution</title><link>http://arxiv.org/abs/2305.20006v1</link><description>Recent learning-based approaches have achieved significant progress in lightfield (LF) image super-resolution (SR) by exploring convolution-based ortransformer-based network structures. However, LF imaging has many intrinsicphysical priors that have not been fully exploited. In this paper, we analyzethe coordinate transformation of the LF imaging process to reveal the geometricrelationship in the LF images. Based on such geometric priors, we introduce anew LF subspace of virtual-slit images (VSI) that provide sub-pixel informationcomplementary to sub-aperture images. To leverage the abundant correlationacross the four-dimensional data with manageable complexity, we proposelearning ensemble representation of all $C_4^2$ LF subspaces for more effectivefeature extraction. To super-resolve image structures from undersampled LFdata, we propose a geometry-aware decoder, named EPIXformer, which constrainsthe transformer's operational searching regions with a LF physical prior.Experimental results on both spatial and angular SR tasks demonstrate that theproposed method outperforms other state-of-the-art schemes, especially inhandling various disparities.</description><author>Manchang Jin, Gaosheng Liu, Kunshu Hu, Xin Luo, Kun Li, Jingyu Yang</author><pubDate>Wed, 31 May 2023 17:27:00 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.20006v1</guid></item><item><title>Learning to solve Bayesian inverse problems: An amortized variational inference approach</title><link>http://arxiv.org/abs/2305.20004v1</link><description>Inverse problems, i.e., estimating parameters of physical models fromexperimental data, are ubiquitous in science and engineering. The Bayesianformulation is the gold standard because it alleviates ill-posedness issues andquantifies epistemic uncertainty. Since analytical posteriors are not typicallyavailable, one resorts to Markov chain Monte Carlo sampling or approximatevariational inference. However, inference needs to be rerun from scratch foreach new set of data. This drawback limits the applicability of the Bayesianformulation to real-time settings, e.g., health monitoring of engineeredsystems, and medical diagnosis. The objective of this paper is to develop amethodology that enables real-time inference by learning the Bayesian inversemap, i.e., the map from data to posteriors. Our approach is as follows. Werepresent the posterior distribution using a parameterization based on deepneural networks. Next, we learn the network parameters by amortized variationalinference method which involves maximizing the expectation of evidence lowerbound over all possible datasets compatible with the model. We demonstrate ourapproach by solving examples a set of benchmark problems from science andengineering. Our results show that the posterior estimates of our approach arein agreement with the corresponding ground truth obtained by Markov chain MonteCarlo. Once trained, our approach provides the posterior parameters ofobservation just at the cost of a forward pass of the neural network.</description><author>Sharmila Karumuri, Ilias Bilionis</author><pubDate>Wed, 31 May 2023 17:25:07 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.20004v1</guid></item><item><title>A Novel Black Box Process Quality Optimization Approach based on Hit Rate</title><link>http://arxiv.org/abs/2305.20003v1</link><description>Hit rate is a key performance metric in predicting process product quality inintegrated industrial processes. It represents the percentage of productsaccepted by downstream processes within a controlled range of quality. However,optimizing hit rate is a non-convex and challenging problem. To address thisissue, we propose a data-driven quasi-convex approach that combines factorialhidden Markov models, multitask elastic net, and quasi-convex optimization. Ourapproach converts the original non-convex problem into a set of convex feasibleproblems, achieving an optimal hit rate. We verify the convex optimizationproperty and quasi-convex frontier through Monte Carlo simulations andreal-world experiments in steel production. Results demonstrate that ourapproach outperforms classical models, improving hit rates by at least 41.11%and 31.01% on two real datasets. Furthermore, the quasi-convex frontierprovides a reference explanation and visualization for the deterioration ofsolutions obtained by conventional models.</description><author>Yang Yang, Jian Wu, Xiangman Song, Derun Wu, Lijie Su, Lixin Tang</author><pubDate>Wed, 31 May 2023 17:24:57 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.20003v1</guid></item><item><title>Representer Point Selection for Explaining Regularized High-dimensional Models</title><link>http://arxiv.org/abs/2305.20002v1</link><description>We introduce a novel class of sample-based explanations we termhigh-dimensional representers, that can be used to explain the predictions of aregularized high-dimensional model in terms of importance weights for each ofthe training samples. Our workhorse is a novel representer theorem for generalregularized high-dimensional models, which decomposes the model prediction interms of contributions from each of the training samples: with positive(negative) values corresponding to positive (negative) impact training samplesto the model's prediction. We derive consequences for the canonical instancesof $\ell_1$ regularized sparse models, and nuclear norm regularized low-rankmodels. As a case study, we further investigate the application of low-rankmodels in the context of collaborative filtering, where we instantiatehigh-dimensional representers for specific popular classes of models. Finally,we study the empirical performance of our proposed methods on three real-worldbinary classification datasets and two recommender system datasets. We alsoshowcase the utility of high-dimensional representers in explaining modelrecommendations.</description><author>Che-Ping Tsai, Jiong Zhang, Eli Chien, Hsiang-Fu Yu, Cho-Jui Hsieh, Pradeep Ravikumar</author><pubDate>Wed, 31 May 2023 17:23:58 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.20002v1</guid></item><item><title>SNeRL: Semantic-aware Neural Radiance Fields for Reinforcement Learning</title><link>http://arxiv.org/abs/2301.11520v3</link><description>As previous representations for reinforcement learning cannot effectivelyincorporate a human-intuitive understanding of the 3D environment, they usuallysuffer from sub-optimal performances. In this paper, we present Semantic-awareNeural Radiance Fields for Reinforcement Learning (SNeRL), which jointlyoptimizes semantic-aware neural radiance fields (NeRF) with a convolutionalencoder to learn 3D-aware neural implicit representation from multi-viewimages. We introduce 3D semantic and distilled feature fields in parallel tothe RGB radiance fields in NeRF to learn semantic and object-centricrepresentation for reinforcement learning. SNeRL outperforms not only previouspixel-based representations but also recent 3D-aware representations both inmodel-free and model-based reinforcement learning.</description><author>Dongseok Shim, Seungjae Lee, H. Jin Kim</author><pubDate>Wed, 31 May 2023 17:21:18 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2301.11520v3</guid></item><item><title>ZeroFlow: Fast Zero Label Scene Flow via Distillation</title><link>http://arxiv.org/abs/2305.10424v3</link><description>Scene flow estimation is the task of describing the 3D motion field betweentemporally successive point clouds. State-of-the-art methods use strong priorsand test-time optimization techniques, but require on the order of tens ofseconds for large-scale point clouds, making them unusable as computer visionprimitives for real-time applications such as open world object detection. Feedforward methods are considerably faster, running on the order of tens tohundreds of milliseconds for large-scale point clouds, but require expensivehuman supervision. To address both limitations, we propose Scene Flow viaDistillation, a simple distillation framework that uses a label-freeoptimization method to produce pseudo-labels to supervise a feed forward model.Our instantiation of this framework, ZeroFlow, produces scene flow estimates inreal-time on large-scale point clouds at quality competitive withstate-of-the-art methods while using zero human labels. Notably, at test-timeZeroFlow is over 1000$\times$ faster than label-free state-of-the-artoptimization-based methods on large-scale point clouds and over 1000$\times$cheaper to train on unlabeled data compared to the cost of human annotation ofthat data. To facilitate research reuse, we release our code, trained modelweights, and high quality pseudo-labels for the Argoverse 2 and Waymo Opendatasets.</description><author>Kyle Vedder, Neehar Peri, Nathaniel Chodosh, Ishan Khatri, Eric Eaton, Dinesh Jayaraman, Yang Liu, Deva Ramanan, James Hays</author><pubDate>Wed, 31 May 2023 17:20:39 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.10424v3</guid></item><item><title>Beam Tree Recursive Cells</title><link>http://arxiv.org/abs/2305.19999v1</link><description>We propose Beam Tree Recursive Cell (BT-Cell) - a backpropagation-friendlyframework to extend Recursive Neural Networks (RvNNs) with beam search forlatent structure induction. We further extend this framework by proposing arelaxation of the hard top-k operators in beam search for better propagation ofgradient signals. We evaluate our proposed models in differentout-of-distribution splits in both synthetic and realistic data. Ourexperiments show that BTCell achieves near-perfect performance on severalchallenging structure-sensitive synthetic tasks like ListOps and logicalinference while maintaining comparable performance in realistic data againstother RvNN-based models. Additionally, we identify a previously unknown failurecase for neural models in generalization to unseen number of arguments inListOps. The code is available at: https://github.com/JRC1995/BeamTreeRecursiveCells.</description><author>Jishnu Ray Chowdhury, Cornelia Caragea</author><pubDate>Wed, 31 May 2023 17:20:04 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.19999v1</guid></item><item><title>Efficient Shapley Values Estimation by Amortization for Text Classification</title><link>http://arxiv.org/abs/2305.19998v1</link><description>Despite the popularity of Shapley Values in explaining neural textclassification models, computing them is prohibitive for large pretrainedmodels due to a large number of model evaluations. In practice, Shapley Valuesare often estimated with a small number of stochastic model evaluations.However, we show that the estimated Shapley Values are sensitive to random seedchoices -- the top-ranked features often have little overlap across differentseeds, especially on examples with longer input texts. This can only bemitigated by aggregating thousands of model evaluations, which on the otherhand, induces substantial computational overheads. To mitigate the trade-offbetween stability and efficiency, we develop an amortized model that directlypredicts each input feature's Shapley Value without additional modelevaluations. It is trained on a set of examples whose Shapley Values areestimated from a large number of model evaluations to ensure stability.Experimental results on two text classification datasets demonstrate that ouramortized model estimates Shapley Values accurately with up to 60 times speedupcompared to traditional methods. Furthermore, the estimated values are stableas the inference is deterministic. We release our code athttps://github.com/yangalan123/Amortized-Interpretability.</description><author>Chenghao Yang, Fan Yin, He He, Kai-Wei Chang, Xiaofei Ma, Bing Xiang</author><pubDate>Wed, 31 May 2023 17:19:13 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.19998v1</guid></item><item><title>Knowledge Graph Embedding with Electronic Health Records Data via Latent Graphical Block Model</title><link>http://arxiv.org/abs/2305.19997v1</link><description>Due to the increasing adoption of electronic health records (EHR), largescale EHRs have become another rich data source for translational clinicalresearch. Despite its potential, deriving generalizable knowledge from EHR dataremains challenging. First, EHR data are generated as part of clinical carewith data elements too detailed and fragmented for research. Despite recentprogress in mapping EHR data to common ontology with hierarchical structures,much development is still needed to enable automatic grouping of local EHRcodes to meaningful clinical concepts at a large scale. Second, the totalnumber of unique EHR features is large, imposing methodological challenges toderive reproducible knowledge graph, especially when interest lies inconditional dependency structure. Third, the detailed EHR data on a very largepatient cohort imposes additional computational challenge to deriving aknowledge network. To overcome these challenges, we propose to infer theconditional dependency structure among EHR features via a latent graphicalblock model (LGBM). The LGBM has a two layer structure with the first providingsemantic embedding vector (SEV) representation for the EHR features and thesecond overlaying a graphical block model on the latent SEVs. The blockstructures on the graphical model also allows us to cluster synonymous featuresin EHR. We propose to learn the LGBM efficiently, in both statistical andcomputational sense, based on the empirical point mutual information matrix. Weestablish the statistical rates of the proposed estimators and show the perfectrecovery of the block structure. Numerical results from simulation studies andreal EHR data analyses suggest that the proposed LGBM estimator performs wellin finite sample.</description><author>Junwei Lu, Jin Yin, Tianxi Cai</author><pubDate>Wed, 31 May 2023 17:18:46 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.19997v1</guid></item><item><title>Unlocking Slot Attention by Changing Optimal Transport Costs</title><link>http://arxiv.org/abs/2301.13197v2</link><description>Slot attention is a powerful method for object-centric modeling in images andvideos. However, its set-equivariance limits its ability to handle videos witha dynamic number of objects because it cannot break ties. To overcome thislimitation, we first establish a connection between slot attention and optimaltransport. Based on this new perspective we propose MESH (Minimize Entropy ofSinkhorn): a cross-attention module that combines the tiebreaking properties ofunregularized optimal transport with the speed of regularized optimaltransport. We evaluate slot attention using MESH on multiple object-centriclearning benchmarks and find significant improvements over slot attention inevery setting.</description><author>Yan Zhang, David W. Zhang, Simon Lacoste-Julien, Gertjan J. Burghouts, Cees G. M. Snoek</author><pubDate>Wed, 31 May 2023 17:14:38 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2301.13197v2</guid></item><item><title>A Nested Matrix-Tensor Model for Noisy Multi-view Clustering</title><link>http://arxiv.org/abs/2305.19992v1</link><description>In this paper, we propose a nested matrix-tensor model which extends thespiked rank-one tensor model of order three. This model is particularlymotivated by a multi-view clustering problem in which multiple noisyobservations of each data point are acquired, with potentially non-uniformvariances along the views. In this case, data can be naturally represented byan order-three tensor where the views are stacked. Given such a tensor, weconsider the estimation of the hidden clusters via performing a best rank-onetensor approximation. In order to study the theoretical performance of thisapproach, we characterize the behavior of this best rank-one approximation interms of the alignments of the obtained component vectors with the hidden modelparameter vectors, in the large-dimensional regime. In particular, we show thatour theoretical results allow us to anticipate the exact accuracy of theproposed clustering approach. Furthermore, numerical experiments indicate thatleveraging our tensor-based approach yields better accuracy compared to a naiveunfolding-based algorithm which ignores the underlying low-rank tensorstructure. Our analysis unveils unexpected and non-trivial phase transitionphenomena depending on the model parameters, ``interpolating'' between thetypical behavior observed for the spiked matrix and tensor models.</description><author>Mohamed El Amine Seddik, Mastane Achab, Henrique Goulart, Merouane Debbah</author><pubDate>Wed, 31 May 2023 17:13:46 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.19992v1</guid></item><item><title>InGram: Inductive Knowledge Graph Embedding via Relation Graphs</title><link>http://arxiv.org/abs/2305.19987v1</link><description>Inductive knowledge graph completion has been considered as the task ofpredicting missing triplets between new entities that are not observed duringtraining. While most inductive knowledge graph completion methods assume thatall entities can be new, they do not allow new relations to appear at inferencetime. This restriction prohibits the existing methods from appropriatelyhandling real-world knowledge graphs where new entities accompany newrelations. In this paper, we propose an INductive knowledge GRAph eMbeddingmethod, InGram, that can generate embeddings of new relations as well as newentities at inference time. Given a knowledge graph, we define a relation graphas a weighted graph consisting of relations and the affinity weights betweenthem. Based on the relation graph and the original knowledge graph, InGramlearns how to aggregate neighboring embeddings to generate relation and entityembeddings using an attention mechanism. Experimental results show that InGramoutperforms 14 different state-of-the-art methods on varied inductive learningscenarios.</description><author>Jaejun Lee, Chanyoung Chung, Joyce Jiyoung Whang</author><pubDate>Wed, 31 May 2023 17:10:42 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.19987v1</guid></item><item><title>Adam Accumulation to Reduce Memory Footprints of both Activations and Gradients for Large-scale DNN Training</title><link>http://arxiv.org/abs/2305.19982v1</link><description>Running out of GPU memory has become a main bottleneck for large-scale DNNtraining. How to reduce the memory footprint during training has receivedintensive research attention. We find that previous gradient accumulationreduces activation memory but fails to be compatible with gradient memoryreduction due to a contradiction between preserving gradients and releasinggradients. To address this issue, we propose a novel optimizer accumulationmethod for Adam, named Adam Accumulation (AdamA), which enables reducing bothactivation and gradient memory. Specifically, AdamA directly integratesgradients into optimizer states and accumulates optimizer states overmicro-batches, so that gradients can be released immediately after use. Wemathematically and experimentally demonstrate AdamA yields the same convergenceproperties as Adam. Evaluated on transformer-based models, AdamA achieves up to23% memory reduction compared to gradient accumulation with less than 2%degradation in training throughput. Notably, AdamA can work together withmemory reduction methods for optimizer states to fit 1.26x~3.14x larger modelsover PyTorch and DeepSpeed baseline on GPUs with different memory capacities.</description><author>Yijia Zhang, Yibo Han, Shijie Cao, Guohao Dai, Youshan Miao, Ting Cao, Fan Yang, Ningyi Xu</author><pubDate>Wed, 31 May 2023 17:06:50 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.19982v1</guid></item><item><title>MedNgage: A Dataset for Understanding Engagement in Patient-Nurse Conversations</title><link>http://arxiv.org/abs/2305.19981v1</link><description>Patients who effectively manage their symptoms often demonstrate higherlevels of engagement in conversations and interventions with healthcarepractitioners. This engagement is multifaceted, encompassing cognitive andsocio-affective dimensions. Consequently, it is crucial for AI systems tounderstand the engagement in natural conversations between patients andpractitioners to better contribute toward patient care. In this paper, wepresent a novel dataset (MedNgage), which consists of patient-nurseconversations about cancer symptom management. We manually annotate the datasetwith a novel framework of categories of patient engagement from two differentangles, namely: i) socio-affective engagement (3.1K spans), and ii) cognitiveengagement (1.8K spans). Through statistical analysis of the data that isannotated using our framework, we show a positive correlation between patientsymptom management outcomes and their engagement in conversations.Additionally, we demonstrate that pre-trained transformer models fine-tuned onour dataset can reliably predict engagement categories in patient-nurseconversations. Lastly, we use LIME (Ribeiro et al., 2016) to analyze theunderlying challenges of the tasks that state-of-the-art transformer modelsencounter. The de-identified data is available for research purposes uponrequest.</description><author>Yan Wang, Heidi Ann Scharf Donovan, Sabit Hassan, Mailhe Alikhani</author><pubDate>Wed, 31 May 2023 17:06:07 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.19981v1</guid></item><item><title>Decepticons: Corrupted Transformers Breach Privacy in Federated Learning for Language Models</title><link>http://arxiv.org/abs/2201.12675v2</link><description>A central tenet of Federated learning (FL), which trains models withoutcentralizing user data, is privacy. However, previous work has shown that thegradient updates used in FL can leak user information. While the mostindustrial uses of FL are for text applications (e.g. keystroke prediction),nearly all attacks on FL privacy have focused on simple image classifiers. Wepropose a novel attack that reveals private user text by deploying maliciousparameter vectors, and which succeeds even with mini-batches, multiple users,and long sequences. Unlike previous attacks on FL, the attack exploitscharacteristics of both the Transformer architecture and the token embedding,separately extracting tokens and positional embeddings to retrievehigh-fidelity text. This work suggests that FL on text, which has historicallybeen resistant to privacy attacks, is far more vulnerable than previouslythought.</description><author>Liam Fowl, Jonas Geiping, Steven Reich, Yuxin Wen, Wojtek Czaja, Micah Goldblum, Tom Goldstein</author><pubDate>Wed, 31 May 2023 17:05:45 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2201.12675v2</guid></item><item><title>MDAMF: Reconstruction of Cardiac Cine MRI under Free-breathing using Motion-guided Deformable Alignment and Multi-resolution Fusion</title><link>http://arxiv.org/abs/2303.04968v2</link><description>Cardiac cine magnetic resonance imaging not only requires higher imagingspeed but also needs to address motion artifacts. Especially in the case offree-breathing, more motion artifacts are inevitably introduced. This poseshigher demands on the reconstruction performance of the model and its abilityto capture temporal information. Previous methods have not effectively utilizedthe temporal dimension information to compensate for motion artifacts. In orderto fully leverage the spatiotemporal information and reduce the impact ofmotion artifacts, this paper proposes a motion-guided deformable alignmentmethod with second-order bidirectional propagation. Furthermore, aligningadjacent frames may lead to low accuracy or misalignment issues, which aredetrimental to subsequent fusion reconstruction. Previous methods have notsufficiently integrated and corrected the aligned feature information. Thispaper proposes a multi-resolution fusion method to further correct alignmenterrors or artifacts. Compared to other advanced methods, the proposed approachachieves better image reconstruction quality in terms of peak signal-to-noiseratio (PSNR), structural similarity index (SSIM), and visual effects. Thesource code will be made available on https://github.com/GtLinyer/MDAMF.</description><author>Xiaoxiang Han, Yiman Liu, Yuanjie Lin, Keyan Chen, Weikun Zhang, Qiaohong Liu</author><pubDate>Wed, 31 May 2023 17:05:15 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2303.04968v2</guid></item><item><title>Knowledge Graph Embeddings in the Biomedical Domain: Are They Useful? A Look at Link Prediction, Rule Learning, and Downstream Polypharmacy Tasks</title><link>http://arxiv.org/abs/2305.19979v1</link><description>Knowledge graphs are powerful tools for representing and organising complexbiomedical data. Several knowledge graph embedding algorithms have beenproposed to learn from and complete knowledge graphs. However, a recent studydemonstrates the limited efficacy of these embedding algorithms when applied tobiomedical knowledge graphs, raising the question of whether knowledge graphembeddings have limitations in biomedical settings. This study aims to applystate-of-the-art knowledge graph embedding models in the context of a recentbiomedical knowledge graph, BioKG, and evaluate their performance and potentialdownstream uses. We achieve a three-fold improvement in terms of performancebased on the HITS@10 score over previous work on the same biomedical knowledgegraph. Additionally, we provide interpretable predictions through a rule-basedmethod. We demonstrate that knowledge graph embedding models are applicable inpractice by evaluating the best-performing model on four tasks that representreal-life polypharmacy situations. Results suggest that knowledge learnt fromlarge biomedical knowledge graphs can be transferred to such downstream usecases. Our code is available at https://github.com/aryopg/biokge.</description><author>Aryo Pradipta Gema, Dominik Grabarczyk, Wolf De Wulf, Piyush Borole, Javier Antonio Alfaro, Pasquale Minervini, Antonio Vergari, Ajitha Rajan</author><pubDate>Wed, 31 May 2023 17:04:25 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.19979v1</guid></item><item><title>Concept Decomposition for Visual Exploration and Inspiration</title><link>http://arxiv.org/abs/2305.18203v2</link><description>A creative idea is often born from transforming, combining, and modifyingideas from existing visual examples capturing various concepts. However, onecannot simply copy the concept as a whole, and inspiration is achieved byexamining certain aspects of the concept. Hence, it is often necessary toseparate a concept into different aspects to provide new perspectives. In thispaper, we propose a method to decompose a visual concept, represented as a setof images, into different visual aspects encoded in a hierarchical treestructure. We utilize large vision-language models and their rich latent spacefor concept decomposition and generation. Each node in the tree represents asub-concept using a learned vector embedding injected into the latent space ofa pretrained text-to-image model. We use a set of regularizations to guide theoptimization of the embedding vectors encoded in the nodes to follow thehierarchical structure of the tree. Our method allows to explore and discovernew concepts derived from the original one. The tree provides the possibilityof endless visual sampling at each node, allowing the user to explore thehidden sub-concepts of the object of interest. The learned aspects in each nodecan be combined within and across trees to create new visual ideas, and can beused in natural language sentences to apply such aspects to new designs.</description><author>Yael Vinker, Andrey Voynov, Daniel Cohen-Or, Ariel Shamir</author><pubDate>Wed, 31 May 2023 17:04:24 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.18203v2</guid></item><item><title>On the Forward Invariance of Neural ODEs</title><link>http://arxiv.org/abs/2210.04763v2</link><description>We propose a new method to ensure neural ordinary differential equations(ODEs) satisfy output specifications by using invariance set propagation. Ourapproach uses a class of control barrier functions to transform outputspecifications into constraints on the parameters and inputs of the learningsystem. This setup allows us to achieve output specification guarantees simplyby changing the constrained parameters/inputs both during training andinference. Moreover, we demonstrate that our invariance set propagation throughdata-controlled neural ODEs not only maintains generalization performance butalso creates an additional degree of robustness by enabling causal manipulationof the system's parameters/inputs. We test our method on a series ofrepresentation learning tasks, including modeling physical dynamics andconvexity portraits, as well as safe collision avoidance for autonomousvehicles.</description><author>Wei Xiao, Tsun-Hsuan Wang, Ramin Hasani, Mathias Lechner, Yutong Ban, Chuang Gan, Daniela Rus</author><pubDate>Wed, 31 May 2023 17:03:26 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2210.04763v2</guid></item><item><title>Diffusion Models as Artists: Are we Closing the Gap between Humans and Machines?</title><link>http://arxiv.org/abs/2301.11722v3</link><description>An important milestone for AI is the development of algorithms that canproduce drawings that are indistinguishable from those of humans. Here, weadapt the 'diversity vs. recognizability' scoring framework from Boutin et al,2022 and find that one-shot diffusion models have indeed started to close thegap between humans and machines. However, using a finer-grained measure of theoriginality of individual samples, we show that strengthening the guidance ofdiffusion models helps improve the humanness of their drawings, but they stillfall short of approximating the originality and recognizability of humandrawings. Comparing human category diagnostic features, collected through anonline psychophysics experiment, against those derived from diffusion modelsreveals that humans rely on fewer and more localized features. Overall, ourstudy suggests that diffusion models have significantly helped improve thequality of machine-generated drawings; however, a gap between humans andmachines remains -- in part explainable by discrepancies in visual strategies.</description><author>Victor Boutin, Thomas Fel, Lakshya Singhal, Rishav Mukherji, Akash Nagaraj, Julien Colin, Thomas Serre</author><pubDate>Wed, 31 May 2023 17:02:39 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2301.11722v3</guid></item><item><title>Correcting Semantic Parses with Natural Language through Dynamic Schema Encoding</title><link>http://arxiv.org/abs/2305.19974v1</link><description>In addressing the task of converting natural language to SQL queries, thereare several semantic and syntactic challenges. It becomes increasinglyimportant to understand and remedy the points of failure as the performance ofsemantic parsing systems improve. We explore semantic parse correction withnatural language feedback, proposing a new solution built on the success ofautoregressive decoders in text-to-SQL tasks. By separating the semantic andsyntactic difficulties of the task, we show that the accuracy of text-to-SQLparsers can be boosted by up to 26% with only one turn of correction withnatural language. Additionally, we show that a T5-base model is capable ofcorrecting the errors of a T5-large model in a zero-shot, cross-parser setting.</description><author>Parker Glenn, Parag Pravin Dakle, Preethi Raghavan</author><pubDate>Wed, 31 May 2023 17:01:57 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.19974v1</guid></item><item><title>ViLaS: Integrating Vision and Language into Automatic Speech Recognition</title><link>http://arxiv.org/abs/2305.19972v1</link><description>Employing additional multimodal information to improve automatic speechrecognition (ASR) performance has been proven effective in previous works.However, many of these works focus only on the utilization of visual cues fromhuman lip motion. In fact, context-dependent visual and linguistic cues canalso be used to improve ASR performance in many scenarios. In this paper, wefirst propose a multimodal ASR model (ViLaS) that can simultaneously orseparately integrate visual and linguistic cues to help recognize the inputspeech, and introduce a training strategy that can improve performance inmodal-incomplete test scenarios. Then, we create a multimodal ASR dataset(VSDial) with visual and linguistic cues to explore the effects of integratingvision and language. Finally, we report empirical results on the publicFlickr8K and self-constructed VSDial datasets, investigate cross-modal fusionschemes, and analyze fine-grained cross-modal alignment on VSDial.</description><author>Minglun Han, Feilong Chen, Ziyi Ni, Linghui Meng, Jing Shi, Shuang Xu, Bo Xu</author><pubDate>Wed, 31 May 2023 17:01:20 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.19972v1</guid></item><item><title>Federated Learning in the Presence of Adversarial Client Unavailability</title><link>http://arxiv.org/abs/2305.19971v1</link><description>Federated learning is a decentralized machine learning framework wherein notall clients are able to participate in each round. An emerging line of researchis devoted to tackling arbitrary client unavailability. Existing theoreticalanalysis imposes restrictive structural assumptions on the unavailabilitypatterns, and their proposed algorithms were tailored to those assumptions. In this paper, we relax those assumptions and consider adversarial clientunavailability. To quantify the degrees of client unavailability, we use thenotion of {\em $\epsilon$-adversary dropout fraction}. For both non-convex andstrongly-convex global objectives, we show that simple variants of FedAvg orFedProx, albeit completely agnostic to $\epsilon$, converge to an estimationerror on the order of $\epsilon (G^2 + \sigma^2)$, where $G$ is a heterogeneityparameter and $\sigma^2$ is the noise level. We prove that this estimationerror is minimax-optimal. We also show that the variants of FedAvg or FedProxhave convergence speeds $O(1/\sqrt{T})$ for non-convex objectives and $O(1/T)$for strongly-convex objectives, both of which are the best possible for anyfirst-order method that only has access to noisy gradients. Our proofs buildupon a tight analysis of the selection bias that persists in the entirelearning process. We validate our theoretical prediction through numericalexperiments on synthetic and real-world datasets.</description><author>Lili Su, Jiaming Xu, Pengkun Yang</author><pubDate>Wed, 31 May 2023 16:57:07 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.19971v1</guid></item><item><title>PEAK: Explainable Privacy Assistant through Automated Knowledge Extraction</title><link>http://arxiv.org/abs/2301.02079v2</link><description>In the realm of online privacy, privacy assistants play a pivotal role inempowering users to manage their privacy effectively. Although recent studieshave shown promising progress in tackling tasks such as privacy violationdetection and personalized privacy recommendations, a crucial aspect forwidespread user adoption is the capability of these systems to provideexplanations for their decision-making processes. This paper presents a privacyassistant for generating explanations for privacy decisions. The privacyassistant focuses on discovering latent topics, identifying explanationcategories, establishing explanation schemes, and generating automatedexplanations. The generated explanations can be used by users to understand therecommendations of the privacy assistant. Our user study of real-world privacydataset of images shows that users find the generated explanations useful andeasy to understand. Additionally, the generated explanations can be used byprivacy assistants themselves to improve their decision-making. We show howthis can be realized by incorporating the generated explanations into astate-of-the-art privacy assistant.</description><author>Gonul Ayci, Arzucan Özgür, Murat Şensoy, Pınar Yolum</author><pubDate>Wed, 31 May 2023 16:55:58 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2301.02079v2</guid></item><item><title>Why Random Pruning Is All We Need to Start Sparse</title><link>http://arxiv.org/abs/2210.02412v2</link><description>Random masks define surprisingly effective sparse neural network models, ashas been shown empirically. The resulting sparse networks can often competewith dense architectures and state-of-the-art lottery ticket pruningalgorithms, even though they do not rely on computationally expensiveprune-train iterations and can be drawn initially without significantcomputational overhead. We offer a theoretical explanation of how random maskscan approximate arbitrary target networks if they are wider by a logarithmicfactor in the inverse sparsity $1 / \log(1/\text{sparsity})$. Thisoverparameterization factor is necessary at least for 3-layer random networks,which elucidates the observed degrading performance of random networks athigher sparsity. At moderate to high sparsity levels, however, our resultsimply that sparser networks are contained within random source networks so thatany dense-to-sparse training scheme can be turned into a computationally moreefficient sparse-to-sparse one by constraining the search to a fixed randommask. We demonstrate the feasibility of this approach in experiments fordifferent pruning methods and propose particularly effective choices of initiallayer-wise sparsity ratios of the random source network. As a special case, weshow theoretically and experimentally that random source networks also containstrong lottery tickets.</description><author>Advait Gadhikar, Sohom Mukherjee, Rebekka Burkholz</author><pubDate>Wed, 31 May 2023 16:51:16 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2210.02412v2</guid></item><item><title>GANDiffFace: Controllable Generation of Synthetic Datasets for Face Recognition with Realistic Variations</title><link>http://arxiv.org/abs/2305.19962v1</link><description>Face recognition systems have significantly advanced in recent years, drivenby the availability of large-scale datasets. However, several issues haverecently came up, including privacy concerns that have led to thediscontinuation of well-established public datasets. Synthetic datasets haveemerged as a solution, even though current synthesis methods present otherdrawbacks such as limited intra-class variations, lack of realism, and unfairrepresentation of demographic groups. This study introduces GANDiffFace, anovel framework for the generation of synthetic datasets for face recognitionthat combines the power of Generative Adversarial Networks (GANs) and Diffusionmodels to overcome the limitations of existing synthetic datasets. InGANDiffFace, we first propose the use of GANs to synthesize highly realisticidentities and meet target demographic distributions. Subsequently, wefine-tune Diffusion models with the images generated with GANs, synthesizingmultiple images of the same identity with a variety of accessories, poses,expressions, and contexts. We generate multiple synthetic datasets by changingGANDiffFace settings, and compare their mated and non-mated score distributionswith the distributions provided by popular real-world datasets for facerecognition, i.e. VGG2 and IJB-C. Our results show the feasibility of theproposed GANDiffFace, in particular the use of Diffusion models to enhance the(limited) intra-class variations provided by GANs towards the level ofreal-world datasets.</description><author>Pietro Melzi, Christian Rathgeb, Ruben Tolosana, Ruben Vera-Rodriguez, Dominik Lawatsch, Florian Domin, Maxim Schaubert</author><pubDate>Wed, 31 May 2023 16:49:12 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.19962v1</guid></item><item><title>What can online reinforcement learning with function approximation benefit from general coverage conditions?</title><link>http://arxiv.org/abs/2304.12886v2</link><description>In online reinforcement learning (RL), instead of employing standardstructural assumptions on Markov decision processes (MDPs), using a certaincoverage condition (original from offline RL) is enough to ensuresample-efficient guarantees (Xie et al. 2023). In this work, we focus on thisnew direction by digging more possible and general coverage conditions, andstudy the potential and the utility of them in efficient online RL. We identifymore concepts, including the $L^p$ variant of concentrability, the densityratio realizability, and trade-off on the partial/rest coverage condition, thatcan be also beneficial to sample-efficient online RL, achieving improved regretbound. Furthermore, if exploratory offline data are used, under our coverageconditions, both statistically and computationally efficient guarantees can beachieved for online RL. Besides, even though the MDP structure is given, e.g.,linear MDP, we elucidate that, good coverage conditions are still beneficial toobtain faster regret bound beyond $\widetilde{O}(\sqrt{T})$ and even alogarithmic order regret. These results provide a good justification for theusage of general coverage conditions in efficient online RL.</description><author>Fanghui Liu, Luca Viano, Volkan Cevher</author><pubDate>Wed, 31 May 2023 16:48:23 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2304.12886v2</guid></item><item><title>Reinforcement Learning with Human Feedback: Learning Dynamic Choices via Pessimism</title><link>http://arxiv.org/abs/2305.18438v2</link><description>In this paper, we study offline Reinforcement Learning with Human Feedback(RLHF) where we aim to learn the human's underlying reward and the MDP'soptimal policy from a set of trajectories induced by human choices. RLHF ischallenging for multiple reasons: large state space but limited human feedback,the bounded rationality of human decisions, and the off-policy distributionshift. In this paper, we focus on the Dynamic Discrete Choice (DDC) model formodeling and understanding human choices. DCC, rooted in econometrics anddecision theory, is widely used to model a human decision-making process withforward-looking and bounded rationality. We propose a\underline{D}ynamic-\underline{C}hoice-\underline{P}essimistic-\underline{P}olicy-\underline{O}ptimization(DCPPO) method. \ The method involves a three-stage process: The first step isto estimate the human behavior policy and the state-action value function viamaximum likelihood estimation (MLE); the second step recovers the human rewardfunction via minimizing Bellman mean squared error using the learned valuefunctions; the third step is to plug in the learned reward and invokepessimistic value iteration for finding a near-optimal policy. With onlysingle-policy coverage (i.e., optimal policy) of the dataset, we prove that thesuboptimality of DCPPO almost matches the classical pessimistic offline RLalgorithm in terms of suboptimality's dependency on distribution shift anddimension. To the best of our knowledge, this paper presents the firsttheoretical guarantees for off-policy offline RLHF with dynamic discrete choicemodel.</description><author>Zihao Li, Zhuoran Yang, Mengdi Wang</author><pubDate>Wed, 31 May 2023 16:47:45 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.18438v2</guid></item><item><title>On Balancing Bias and Variance in Unsupervised Multi-Source-Free Domain Adaptation</title><link>http://arxiv.org/abs/2202.00796v3</link><description>Due to privacy, storage, and other constraints, there is a growing need forunsupervised domain adaptation techniques in machine learning that do notrequire access to the data used to train a collection of source models.Existing methods for multi-source-free domain adaptation (MSFDA) typicallytrain a target model using pseudo-labeled data produced by the source models,which focus on improving the pseudo-labeling techniques or proposing newtraining objectives. Instead, we aim to analyze the fundamental limits ofMSFDA. In particular, we develop an information-theoretic bound on thegeneralization error of the resulting target model, which illustrates aninherent bias-variance trade-off. We then provide insights on how to balancethis trade-off from three perspectives, including domain aggregation, selectivepseudo-labeling, and joint feature alignment, which leads to the design ofnovel algorithms. Experiments on multiple datasets validate our theoreticalanalysis and demonstrate the state-of-art performance of the proposedalgorithm, especially on some of the most challenging datasets, includingOffice-Home and DomainNet.</description><author>Maohao Shen, Yuheng Bu, Gregory Wornell</author><pubDate>Wed, 31 May 2023 16:46:27 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2202.00796v3</guid></item><item><title>Analysing high resolution digital Mars images using machine learning</title><link>http://arxiv.org/abs/2305.19958v1</link><description>The search for ephemeral liquid water on Mars is an ongoing activity. Afterthe recession of the seasonal polar ice cap on Mars, small water ice patchesmay be left behind in shady places due to the low thermal conductivity of theMartian surface and atmosphere. During late spring and early summer, thesepatches may be exposed to direct sunlight and warm up rapidly enough for theliquid phase to emerge. To see the spatial and temporal occurrence of such icepatches, optical images should be searched for and checked. Previously a manualimage analysis was conducted on 110 images from the southern hemisphere,captured by the High Resolution Imaging Science Experiment (HiRISE) cameraonboard the Mars Reconnaissance Orbiter space mission. Out of these, 37 imageswere identified with smaller ice patches, which were distinguishable by theirbrightness, colour and strong connection to local topographic shading. In thisstudy, a convolutional neural network (CNN) is applied to find further imageswith potential water ice patches in the latitude band between -40{\deg} and-60{\deg}, where the seasonal retreat of the polar ice cap happens. Previouslyanalysed HiRISE images are used to train the model, each was split intohundreds of pieces, expanding the training dataset to 6240 images. A test runconducted on 38 new HiRISE images indicates that the program can generallyrecognise small bright patches, however further training might be needed formore precise predictions.Using a CNN model may make it realistic to analyse allavailable surface images, aiding us in selecting areas for furtherinvestigation.</description><author>M. Gergacz, A. Kereszturi</author><pubDate>Wed, 31 May 2023 16:44:55 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.19958v1</guid></item><item><title>DeepSolo++: Let Transformer Decoder with Explicit Points Solo for Text Spotting</title><link>http://arxiv.org/abs/2305.19957v1</link><description>End-to-end text spotting aims to integrate scene text detection andrecognition into a unified framework. Dealing with the relationship between thetwo sub-tasks plays a pivotal role in designing effective spotters. AlthoughTransformer-based methods eliminate the heuristic post-processing, they stillsuffer from the synergy issue between the sub-tasks and low trainingefficiency. In this paper, we present DeepSolo, a simple DETR-like baselinethat lets a single decoder with explicit points solo for text detection andrecognition simultaneously and efficiently. Technically, for each textinstance, we represent the character sequence as ordered points and model themwith learnable explicit point queries. After passing a single decoder, thepoint queries have encoded requisite text semantics and locations. Furthermore,we show the surprisingly good extensibility of our method, in terms ofcharacter class, language type, and task. On the one hand, DeepSolo not onlyperforms well in English scenes but also masters the Chinese transcription withcomplex font structure and a thousand-level character classes. On the otherhand, based on the extensibility of DeepSolo, we launch DeepSolo++ formultilingual text spotting, making a further step to let Transformer decoderwith explicit points solo for multilingual text detection, recognition, andscript identification all at once. Extensive experiments on public benchmarksdemonstrate that our simple approach achieves better training efficiencycompared with Transformer-based models and outperforms the previousstate-of-the-art. In addition, DeepSolo and DeepSolo++ are also compatible withline annotations, which require much less annotation cost than polygons. Thecode is available at \url{https://github.com/ViTAE-Transformer/DeepSolo}.</description><author>Maoyuan Ye, Jing Zhang, Shanshan Zhao, Juhua Liu, Tongliang Liu, Bo Du, Dacheng Tao</author><pubDate>Wed, 31 May 2023 16:44:00 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.19957v1</guid></item><item><title>MicroSegNet: A Deep Learning Approach for Prostate Segmentation on Micro-Ultrasound Images</title><link>http://arxiv.org/abs/2305.19956v1</link><description>Micro-ultrasound (micro-US) is a novel 29-MHz ultrasound technique thatprovides 3-4 times higher resolution than traditional ultrasound, deliveringcomparable accuracy for diagnosing prostate cancer to MRI but at a lower cost.Accurate prostate segmentation is crucial for prostate volume measurement,cancer diagnosis, prostate biopsy, and treatment planning. This paper proposesa deep learning approach for automated, fast, and accurate prostatesegmentation on micro-US images. Prostate segmentation on micro-US ischallenging due to artifacts and indistinct borders between the prostate,bladder, and urethra in the midline. We introduce MicroSegNet, a multi-scaleannotation-guided Transformer UNet model to address this challenge. During thetraining process, MicroSegNet focuses more on regions that are hard to segment(challenging regions), where expert and non-expert annotations showdiscrepancies. We achieve this by proposing an annotation-guided cross entropyloss that assigns larger weight to pixels in hard regions and lower weight topixels in easy regions. We trained our model using micro-US images from 55patients, followed by evaluation on 20 patients. Our MicroSegNet model achieveda Dice coefficient of 0.942 and a Hausdorff distance of 2.11 mm, outperformingseveral state-of-the-art segmentation methods, as well as three humanannotators with different experience levels. We will make our code and datasetpublicly available to promote transparency and collaboration in research.</description><author>Hongxu Jiang, Muhammad Imran, Preethika Muralidharan, Anjali Patel, Jake Pensa, Muxuan Liang, Tarik Benidir, Joseph R. Grajo, Jason P. Joseph, Russell Terry, John Michael DiBianco, Li-Ming Su, Yuyin Zhou, Wayne G. Brisbane, Wei Shao</author><pubDate>Wed, 31 May 2023 16:42:29 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.19956v1</guid></item><item><title>Attend-and-Excite: Attention-Based Semantic Guidance for Text-to-Image Diffusion Models</title><link>http://arxiv.org/abs/2301.13826v2</link><description>Recent text-to-image generative models have demonstrated an unparalleledability to generate diverse and creative imagery guided by a target textprompt. While revolutionary, current state-of-the-art diffusion models maystill fail in generating images that fully convey the semantics in the giventext prompt. We analyze the publicly available Stable Diffusion model andassess the existence of catastrophic neglect, where the model fails to generateone or more of the subjects from the input prompt. Moreover, we find that insome cases the model also fails to correctly bind attributes (e.g., colors) totheir corresponding subjects. To help mitigate these failure cases, weintroduce the concept of Generative Semantic Nursing (GSN), where we seek tointervene in the generative process on the fly during inference time to improvethe faithfulness of the generated images. Using an attention-based formulationof GSN, dubbed Attend-and-Excite, we guide the model to refine thecross-attention units to attend to all subject tokens in the text prompt andstrengthen - or excite - their activations, encouraging the model to generateall subjects described in the text prompt. We compare our approach toalternative approaches and demonstrate that it conveys the desired conceptsmore faithfully across a range of text prompts.</description><author>Hila Chefer, Yuval Alaluf, Yael Vinker, Lior Wolf, Daniel Cohen-Or</author><pubDate>Wed, 31 May 2023 16:42:00 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2301.13826v2</guid></item><item><title>What Can Be Learnt With Wide Convolutional Neural Networks?</title><link>http://arxiv.org/abs/2208.01003v5</link><description>Understanding how convolutional neural networks (CNNs) can efficiently learnhigh-dimensional functions remains a fundamental challenge. A popular belief isthat these models harness the local and hierarchical structure of natural datasuch as images. Yet, we lack a quantitative understanding of how such structureaffects performance, e.g., the rate of decay of the generalisation error withthe number of training samples. In this paper, we study infinitely-wide deepCNNs in the kernel regime. First, we show that the spectrum of thecorresponding kernel inherits the hierarchical structure of the network, and wecharacterise its asymptotics. Then, we use this result together withgeneralisation bounds to prove that deep CNNs adapt to the spatial scale of thetarget function. In particular, we find that if the target function depends onlow-dimensional subsets of adjacent input variables, then the decay of theerror is controlled by the effective dimensionality of these subsets.Conversely, if the target function depends on the full set of input variables,then the error decay is controlled by the input dimension. We conclude bycomputing the generalisation error of a deep CNN trained on the output ofanother deep CNN with randomly-initialised parameters. Interestingly, we findthat, despite their hierarchical structure, the functions generated byinfinitely-wide deep CNNs are too rich to be efficiently learnable in highdimension.</description><author>Francesco Cagnetta, Alessandro Favero, Matthieu Wyart</author><pubDate>Wed, 31 May 2023 16:39:31 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2208.01003v5</guid></item><item><title>Explaining the effects of non-convergent sampling in the training of Energy-Based Models</title><link>http://arxiv.org/abs/2301.09428v2</link><description>In this paper, we quantify the impact of using non-convergent Markov chainsto train Energy-Based models (EBMs). In particular, we show analytically thatEBMs trained with non-persistent short runs to estimate the gradient canperfectly reproduce a set of empirical statistics of the data, not at the levelof the equilibrium measure, but through a precise dynamical process. Ourresults provide a first-principles explanation for the observations of recentworks proposing the strategy of using short runs starting from random initialconditions as an efficient way to generate high-quality samples in EBMs, andlay the groundwork for using EBMs as diffusion models. After explaining thiseffect in generic EBMs, we analyze two solvable models in which the effect ofthe non-convergent sampling in the trained parameters can be described indetail. Finally, we test these predictions numerically on a ConvNet EBM and aBoltzmann machine.</description><author>Elisabeth Agoritsas, Giovanni Catania, Aurélien Decelle, Beatriz Seoane</author><pubDate>Wed, 31 May 2023 16:38:32 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2301.09428v2</guid></item><item><title>Multi-Dataset Co-Training with Sharpness-Aware Optimization for Audio Anti-spoofing</title><link>http://arxiv.org/abs/2305.19953v1</link><description>Audio anti-spoofing for automatic speaker verification aims to safeguardusers' identities from spoofing attacks. Although state-of-the-art spoofingcountermeasure(CM) models perform well on specific datasets, they lackgeneralization when evaluated with different datasets. To address thislimitation, previous studies have explored large pre-trained models, whichrequire significant resources and time. We aim to develop a compact butwell-generalizing CM model that can compete with large pre-trained models. Ourapproach involves multi-dataset co-training and sharpness-aware minimization,which has not been investigated in this domain. Extensive experiments revealthat proposed method yield competitive results across various datasets whileutilizing 4,000 times less parameters than the large pre-trained models.</description><author>Hye-jin Shim, Jee-weon Jung, Tomi Kinnunen</author><pubDate>Wed, 31 May 2023 16:37:48 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.19953v1</guid></item><item><title>Generalizable Memory-driven Transformer for Multivariate Long Sequence Time-series Forecasting</title><link>http://arxiv.org/abs/2207.07827v3</link><description>Multivariate long sequence time-series forecasting (M-LSTF) is a practicalbut challenging problem. Unlike traditional timer-series forecasting tasks,M-LSTF tasks are more challenging from two aspects: 1) M-LSTF models need tolearn time-series patterns both within and between multiple time features; 2)Under the rolling forecasting setting, the similarity between two consecutivetraining samples increases with the increasing prediction length, which makesmodels more prone to overfitting. In this paper, we propose a generalizablememory-driven Transformer to target M-LSTF problems. Specifically, we firstpropose a global-level memory component to drive the forecasting procedure byintegrating multiple time-series features. In addition, we adopt a progressivefashion to train our model to increase its generalizability, in which wegradually introduce Bernoulli noises to training samples. Extensive experimentshave been performed on five different datasets across multiple fields.Experimental results demonstrate that our approach can be seamlessly pluggedinto varying Transformer-based models to improve their performances up toroughly 30%. Particularly, this is the first work to specifically focus on theM-LSTF tasks to the best of our knowledge.</description><author>Xiaoyun Zhao, Rui Liu, Mingjie Li, Guangsi Shi, Mingfei Han, Changlin Li, Ling Chen, Xiaojun Chang</author><pubDate>Wed, 31 May 2023 16:37:31 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2207.07827v3</guid></item><item><title>Not All Neuro-Symbolic Concepts Are Created Equal: Analysis and Mitigation of Reasoning Shortcuts</title><link>http://arxiv.org/abs/2305.19951v1</link><description>Neuro-Symbolic (NeSy) predictive models hold the promise of improvedcompliance with given constraints, systematic generalization, andinterpretability, as they allow to infer labels that are consistent with someprior knowledge by reasoning over high-level concepts extracted fromsub-symbolic inputs. It was recently shown that NeSy predictors are affected byreasoning shortcuts: they can attain high accuracy but by leveraging conceptswith unintended semantics, thus coming short of their promised advantages. Yet,a systematic characterization of reasoning shortcuts and of potentialmitigation strategies is missing. This work fills this gap by characterizingthem as unintended optima of the learning objective and identifying four keyconditions behind their occurrence. Based on this, we derive several naturalmitigation strategies, and analyze their efficacy both theoretically andempirically. Our analysis shows reasoning shortcuts are difficult to deal with,casting doubts on the trustworthiness and interpretability of existing NeSysolutions.</description><author>Emanuele Marconato, Stefano Teso, Antonio Vergari, Andrea Passerini</author><pubDate>Wed, 31 May 2023 16:35:48 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.19951v1</guid></item></channel></rss>