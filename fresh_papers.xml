<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/"><channel><title>Arxivfresh papers</title><link></link><description>Arxiv paper</description><language>en-US</language><lastBuildDate>Wed, 30 Aug 2023 14:00:04 GMT</lastBuildDate><generator>rfeed v1.0.0</generator><docs>https://github.com/svpino/rfeed/blob/master/README.md</docs><item><title>3D Adversarial Augmentations for Robust Out-of-Domain Predictions</title><link>http://arxiv.org/abs/2308.15479v1</link><description>Since real-world training datasets cannot properly sample the long tail ofthe underlying data distribution, corner cases and rare out-of-domain samplescan severely hinder the performance of state-of-the-art models. This problembecomes even more severe for dense tasks, such as 3D semantic segmentation,where points of non-standard objects can be confidently associated to the wrongclass. In this work, we focus on improving the generalization to out-of-domaindata. We achieve this by augmenting the training set with adversarial examples.First, we learn a set of vectors that deform the objects in an adversarialfashion. To prevent the adversarial examples from being too far from theexisting data distribution, we preserve their plausibility through a series ofconstraints, ensuring sensor-awareness and shapes smoothness. Then, we performadversarial augmentation by applying the learned sample-independent vectors tothe available objects when training a model. We conduct extensive experimentsacross a variety of scenarios on data from KITTI, Waymo, and CrashD for 3Dobject detection, and on data from SemanticKITTI, Waymo, and nuScenes for 3Dsemantic segmentation. Despite training on a standard single dataset, ourapproach substantially improves the robustness and generalization of both 3Dobject detection and 3D semantic segmentation methods to out-of-domain data.</description><author>Alexander Lehner, Stefano Gasperini, Alvaro Marcos-Ramiro, Michael Schmidt, Nassir Navab, Benjamin Busam, Federico Tombari</author><pubDate>Tue, 29 Aug 2023 18:58:55 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2308.15479v1</guid></item><item><title>An Adaptive Tangent Feature Perspective of Neural Networks</title><link>http://arxiv.org/abs/2308.15478v1</link><description>In order to better understand feature learning in neural networks, we proposea framework for understanding linear models in tangent feature space where thefeatures are allowed to be transformed during training. We consider lineartransformations of features, resulting in a joint optimization over parametersand transformations with a bilinear interpolation constraint. We show that thisoptimization problem has an equivalent linearly constrained optimization withstructured regularization that encourages approximately low rank solutions.Specializing to neural network structure, we gain insights into how thefeatures and thus the kernel function change, providing additional nuance tothe phenomenon of kernel alignment when the target function is poorlyrepresented using tangent features. In addition to verifying our theoreticalobservations in real neural networks on a simple regression problem, weempirically show that an adaptive feature implementation of tangent featureclassification has an order of magnitude lower sample complexity than the fixedtangent feature model on MNIST and CIFAR-10.</description><author>Daniel LeJeune, Sina Alemohammad</author><pubDate>Tue, 29 Aug 2023 18:57:20 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2308.15478v1</guid></item><item><title>A Deep Convolutional Neural Networks Based Multi-Task Ensemble Model for Aspect and Polarity Classification in Persian Reviews</title><link>http://arxiv.org/abs/2201.06313v4</link><description>Aspect-based sentiment analysis is of great importance and applicationbecause of its ability to identify all aspects discussed in the text. However,aspect-based sentiment analysis will be most effective when, in addition toidentifying all the aspects discussed in the text, it can also identify theirpolarity. Most previous methods use the pipeline approach, that is, they firstidentify the aspects and then identify the polarities. Such methods areunsuitable for practical applications since they can lead to model errors.Therefore, in this study, we propose a multi-task learning model based onConvolutional Neural Networks (CNNs), which can simultaneously detect aspectcategory and detect aspect category polarity. creating a model alone may notprovide the best predictions and lead to errors such as bias and high variance.To reduce these errors and improve the efficiency of model predictions,combining several models known as ensemble learning may provide better results.Therefore, the main purpose of this article is to create a model based on anensemble of multi-task deep convolutional neural networks to enhance sentimentanalysis in Persian reviews. We evaluated the proposed method using a Persianlanguage dataset in the movie domain. Jacquard index and Hamming loss measureswere used to evaluate the performance of the developed models. The resultsindicate that this new approach increases the efficiency of the sentimentanalysis model in the Persian language.</description><author>Milad Vazan, Fatemeh Sadat Masoumi, Sepideh Saeedi Majd</author><pubDate>Tue, 29 Aug 2023 18:54:26 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2201.06313v4</guid></item><item><title>A General-Purpose Self-Supervised Model for Computational Pathology</title><link>http://arxiv.org/abs/2308.15474v1</link><description>Tissue phenotyping is a fundamental computational pathology (CPath) task inlearning objective characterizations of histopathologic biomarkers in anatomicpathology. However, whole-slide imaging (WSI) poses a complex computer visionproblem in which the large-scale image resolutions of WSIs and the enormousdiversity of morphological phenotypes preclude large-scale data annotation.Current efforts have proposed using pretrained image encoders with eithertransfer learning from natural image datasets or self-supervised pretraining onpublicly-available histopathology datasets, but have not been extensivelydeveloped and evaluated across diverse tissue types at scale. We introduce UNI,a general-purpose self-supervised model for pathology, pretrained using over100 million tissue patches from over 100,000 diagnostic haematoxylin andeosin-stained WSIs across 20 major tissue types, and evaluated on 33representative CPath clinical tasks in CPath of varying diagnosticdifficulties. In addition to outperforming previous state-of-the-art models, wedemonstrate new modeling capabilities in CPath such as resolution-agnostictissue classification, slide classification using few-shot class prototypes,and disease subtyping generalization in classifying up to 108 cancer types inthe OncoTree code classification system. UNI advances unsupervisedrepresentation learning at scale in CPath in terms of both pretraining data anddownstream evaluation, enabling data-efficient AI models that can generalizeand transfer to a gamut of diagnostically-challenging tasks and clinicalworkflows in anatomic pathology.</description><author>Richard J. Chen, Tong Ding, Ming Y. Lu, Drew F. K. Williamson, Guillaume Jaume, Bowen Chen, Andrew Zhang, Daniel Shao, Andrew H. Song, Muhammad Shaban, Mane Williams, Anurag Vaidya, Sharifa Sahai, Lukas Oldenburg, Luca L. Weishaupt, Judy J. Wang, Walt Williams, Long Phi Le, Georg Gerber, Faisal Mahmood</author><pubDate>Tue, 29 Aug 2023 18:52:10 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2308.15474v1</guid></item><item><title>Empowering Clinicians and Democratizing Data Science: Large Language Models Automate Machine Learning for Clinical Studies</title><link>http://arxiv.org/abs/2308.14120v2</link><description>A knowledge gap persists between Machine Learning (ML) developers (e.g., datascientists) and practitioners (e.g., clinicians), hampering the fullutilization of ML for clinical data analysis. We investigated the potential ofthe chatGPT Advanced Data Analysis (ADA), an extension of GPT-4, to bridge thisgap and perform ML analyses efficiently. Real-world clinical datasets and studydetails from large trials across various medical specialties were presented tochatGPT ADA without specific guidance. ChatGPT ADA autonomously developedstate-of-the-art ML models based on the original study's training data topredict clinical outcomes such as cancer development, cancer progression,disease complications, or biomarkers such as pathogenic gene sequences.Strikingly, these ML models matched or outperformed their publishedcounterparts. We conclude that chatGPT ADA offers a promising avenue todemocratize ML in medicine, making advanced analytics accessible to non-MLexperts and promoting broader applications in medical research and practice.</description><author>Soroosh Tayebi Arasteh, Tianyu Han, Mahshad Lotfinia, Christiane Kuhl, Jakob Nikolas Kather, Daniel Truhn, Sven Nebelung</author><pubDate>Tue, 29 Aug 2023 18:52:02 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2308.14120v2</guid></item><item><title>Learning Modulated Transformation in GANs</title><link>http://arxiv.org/abs/2308.15472v1</link><description>The success of style-based generators largely benefits from style modulation,which helps take care of the cross-instance variation within data. However, theinstance-wise stochasticity is typically introduced via regular convolution,where kernels interact with features at some fixed locations, limiting itscapacity for modeling geometric variation. To alleviate this problem, we equipthe generator in generative adversarial networks (GANs) with a plug-and-playmodule, termed as modulated transformation module (MTM). This module predictsspatial offsets under the control of latent codes, based on which theconvolution operation can be applied at variable locations for differentinstances, and hence offers the model an additional degree of freedom to handlegeometry deformation. Extensive experiments suggest that our approach can befaithfully generalized to various generative tasks, including image generation,3D-aware image synthesis, and video generation, and get compatible withstate-of-the-art frameworks without any hyper-parameter tuning. It isnoteworthy that, towards human generation on the challenging TaiChi dataset, weimprove the FID of StyleGAN3 from 21.36 to 13.60, demonstrating the efficacy oflearning modulated geometry transformation.</description><author>Ceyuan Yang, Qihang Zhang, Yinghao Xu, Jiapeng Zhu, Yujun Shen, Bo Dai</author><pubDate>Tue, 29 Aug 2023 18:51:22 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2308.15472v1</guid></item><item><title>Policy composition in reinforcement learning via multi-objective policy optimization</title><link>http://arxiv.org/abs/2308.15470v1</link><description>We enable reinforcement learning agents to learn successful behavior policiesby utilizing relevant pre-existing teacher policies. The teacher policies areintroduced as objectives, in addition to the task objective, in amulti-objective policy optimization setting. Using the Multi-Objective Maximuma Posteriori Policy Optimization algorithm\citep{abdolmaleki2020distributional}, we show that teacher policies can helpspeed up learning, particularly in the absence of shaping rewards. In twodomains with continuous observation and action spaces, our agents successfullycompose teacher policies in sequence and in parallel, and are also able tofurther extend the policies of the teachers in order to solve the task. Depending on the specified combination of task and teacher(s), teacher(s) maynaturally act to limit the final performance of an agent. The extent to whichagents are required to adhere to teacher policies are determined byhyperparameters which determine both the effect of teachers on learning speedand the eventual performance of the agent on the task. In the {\tt humanoid}domain \citep{deepmindcontrolsuite2018}, we also equip agents with the abilityto control the selection of teachers. With this ability, agents are able tomeaningfully compose from the teacher policies to achieve a superior taskreward on the {\tt walk} task than in cases without access to the teacherpolicies. We show the resemblance of composed task policies with thecorresponding teacher policies through videos.</description><author>Shruti Mishra, Ankit Anand, Jordan Hoffmann, Nicolas Heess, Martin Riedmiller, Abbas Abdolmaleki, Doina Precup</author><pubDate>Tue, 29 Aug 2023 18:50:27 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2308.15470v1</guid></item><item><title>Multimodal Contrastive Learning and Tabular Attention for Automated Alzheimer's Disease Prediction</title><link>http://arxiv.org/abs/2308.15469v1</link><description>Alongside neuroimaging such as MRI scans and PET, Alzheimer's disease (AD)datasets contain valuable tabular data including AD biomarkers and clinicalassessments. Existing computer vision approaches struggle to utilize thisadditional information. To address these needs, we propose a generalizableframework for multimodal contrastive learning of image data and tabular data, anovel tabular attention module for amplifying and ranking salient features intables, and the application of these techniques onto Alzheimer's diseaseprediction. Experimental evaulations demonstrate the strength of our frameworkby detecting Alzheimer's disease (AD) from over 882 MR image slices from theADNI database. We take advantage of the high interpretability of tabular dataand our novel tabular attention approach and through attribution of theattention scores for each row of the table, we note and rank the mostpredominant features. Results show that the model is capable of an accuracy ofover 83.8%, almost a 10% increase from previous state of the art.</description><author>Weichen Huang</author><pubDate>Tue, 29 Aug 2023 18:48:33 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2308.15469v1</guid></item><item><title>Input margins can predict generalization too</title><link>http://arxiv.org/abs/2308.15466v1</link><description>Understanding generalization in deep neural networks is an active area ofresearch. A promising avenue of exploration has been that of marginmeasurements: the shortest distance to the decision boundary for a given sampleor its representation internal to the network. While margins have been shown tobe correlated with the generalization ability of a model when measured at itshidden representations (hidden margins), no such link between large margins andgeneralization has been established for input margins. We show that while inputmargins are not generally predictive of generalization, they can be if thesearch space is appropriately constrained. We develop such a measure based oninput margins, which we refer to as `constrained margins'. The predictive powerof this new measure is demonstrated on the 'Predicting Generalization in DeepLearning' (PGDL) dataset and contrasted with hidden representation margins. Wefind that constrained margins achieve highly competitive scores and outperformother margin measurements in general. This provides a novel insight on therelationship between generalization and classification margins, and highlightsthe importance of considering the data manifold for investigations ofgeneralization in DNNs.</description><author>Coenraad Mouton, Marthinus W. Theunissen, Marelie H. Davel</author><pubDate>Tue, 29 Aug 2023 18:47:42 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2308.15466v1</guid></item><item><title>A Comparative Study of Loss Functions: Traffic Predictions in Regular and Congestion Scenarios</title><link>http://arxiv.org/abs/2308.15464v1</link><description>Spatiotemporal graph neural networks have achieved state-of-the-artperformance in traffic forecasting. However, they often struggle to forecastcongestion accurately due to the limitations of traditional loss functions.While accurate forecasting of regular traffic conditions is crucial, a reliableAI system must also accurately forecast congestion scenarios to maintain safeand efficient transportation. In this paper, we explore various loss functionsinspired by heavy tail analysis and imbalanced classification problems toaddress this issue. We evaluate the efficacy of these loss functions inforecasting traffic speed, with an emphasis on congestion scenarios. Throughextensive experiments on real-world traffic datasets, we discovered that whenoptimizing for Mean Absolute Error (MAE), the MAE-Focal Loss function standsout as the most effective. When optimizing Mean Squared Error (MSE), GumbelLoss proves to be the superior choice. These choices effectively forecasttraffic congestion events without compromising the accuracy of regular trafficspeed forecasts. This research enhances deep learning models' capabilities inforecasting sudden speed changes due to congestion and underscores the need formore research in this direction. By elevating the accuracy of congestionforecasting, we advocate for AI systems that are reliable, secure, andresilient in practical traffic management scenarios.</description><author>Yangxinyu Xie, Tanwi Mallick</author><pubDate>Tue, 29 Aug 2023 18:44:02 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2308.15464v1</guid></item><item><title>Online Overexposed Pixels Hallucination in Videos with Adaptive Reference Frame Selection</title><link>http://arxiv.org/abs/2308.15462v1</link><description>Low dynamic range (LDR) cameras cannot deal with wide dynamic range inputs,frequently leading to local overexposure issues. We present a learning-basedsystem to reduce these artifacts without resorting to complex acquisitionmechanisms like alternating exposures or costly processing that are typical ofhigh dynamic range (HDR) imaging. We propose a transformer-based deep neuralnetwork (DNN) to infer the missing HDR details. In an ablation study, we showthe importance of using a multiscale DNN and train it with the proper costfunction to achieve state-of-the-art quality. To aid the reconstruction of theoverexposed areas, our DNN takes a reference frame from the past as anadditional input. This leverages the commonly occurring temporal instabilitiesof autoexposure to our advantage: since well-exposed details in the currentframe may be overexposed in the future, we use reinforcement learning to traina reference frame selection DNN that decides whether to adopt the current frameas a future reference. Without resorting to alternating exposures, we obtaintherefore a causal, HDR hallucination algorithm with potential application incommon video acquisition settings. Our demo video can be found athttps://drive.google.com/file/d/1-r12BKImLOYCLUoPzdebnMyNjJ4Rk360/view</description><author>Yazhou Xing, Amrita Mazumdar, Anjul Patney, Chao Liu, Hongxu Yin, Qifeng Chen, Jan Kautz, Iuri Frosio</author><pubDate>Tue, 29 Aug 2023 18:40:57 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2308.15462v1</guid></item><item><title>Fairness-aware Vision Transformer via Debiased Self-Attention</title><link>http://arxiv.org/abs/2301.13803v2</link><description>Vision Transformer (ViT) has recently gained significant interest in solvingcomputer vision (CV) problems due to its capability of extracting informativefeatures and modeling long-range dependencies through the self-attentionmechanism. To fully realize the advantages of ViT in real-world applications,recent works have explored the trustworthiness of ViT, including its robustnessand explainability. However, another desiderata, fairness has not yet beenadequately addressed in the literature. We establish that the existingfairness-aware algorithms (primarily designed for CNNs) do not perform well onViT. This necessitates the need for developing our novel framework via DebiasedSelf-Attention (DSA). DSA is a fairness-through-blindness approach thatenforces ViT to eliminate spurious features correlated with the sensitiveattributes for bias mitigation. Notably, adversarial examples are leveraged tolocate and mask the spurious features in the input image patches. In addition,DSA utilizes an attention weights alignment regularizer in the trainingobjective to encourage learning informative features for target prediction.Importantly, our DSA framework leads to improved fairness guarantees over priorworks on multiple prediction tasks without compromising target predictionperformance.</description><author>Yao Qiang, Chengyin Li, Prashant Khanduri, Dongxiao Zhu</author><pubDate>Tue, 29 Aug 2023 18:38:45 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2301.13803v2</guid></item><item><title>Canonical Factors for Hybrid Neural Fields</title><link>http://arxiv.org/abs/2308.15461v1</link><description>Factored feature volumes offer a simple way to build more compact, efficient,and intepretable neural fields, but also introduce biases that are notnecessarily beneficial for real-world data. In this work, we (1) characterizethe undesirable biases that these architectures have for axis-aligned signals-- they can lead to radiance field reconstruction differences of as high as 2PSNR -- and (2) explore how learning a set of canonicalizing transformationscan improve representations by removing these biases. We prove in atwo-dimensional model problem that simultaneously learning thesetransformations together with scene appearance succeeds with drasticallyimproved efficiency. We validate the resulting architectures, which we callTILTED, using image, signed distance, and radiance field reconstruction tasks,where we observe improvements across quality, robustness, compactness, andruntime. Results demonstrate that TILTED can enable capabilities comparable tobaselines that are 2x larger, while highlighting weaknesses of neural fieldevaluation procedures.</description><author>Brent Yi, Weijia Zeng, Sam Buchanan, Yi Ma</author><pubDate>Tue, 29 Aug 2023 18:38:33 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2308.15461v1</guid></item><item><title>ParaGuide: Guided Diffusion Paraphrasers for Plug-and-Play Textual Style Transfer</title><link>http://arxiv.org/abs/2308.15459v1</link><description>Textual style transfer is the task of transforming stylistic properties oftext while preserving meaning. Target "styles" can be defined in numerous ways,ranging from single attributes (e.g, formality) to authorship (e.g,Shakespeare). Previous unsupervised style-transfer approaches generally rely onsignificant amounts of labeled data for only a fixed set of styles or requirelarge language models. In contrast, we introduce a novel diffusion-basedframework for general-purpose style transfer that can be flexibly adapted toarbitrary target styles at inference time. Our parameter-efficient approach,ParaGuide, leverages paraphrase-conditioned diffusion models alongsidegradient-based guidance from both off-the-shelf classifiers and strong existingstyle embedders to transform the style of text while preserving semanticinformation. We validate the method on the Enron Email Corpus, with both humanand automatic evaluations, and find that it outperforms strong baselines onformality, sentiment, and even authorship style transfer.</description><author>Zachary Horvitz, Ajay Patel, Chris Callison-Burch, Zhou Yu, Kathleen McKeown</author><pubDate>Tue, 29 Aug 2023 18:36:02 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2308.15459v1</guid></item><item><title>From SMOTE to Mixup for Deep Imbalanced Classification</title><link>http://arxiv.org/abs/2308.15457v1</link><description>Given imbalanced data, it is hard to train a good classifier using deeplearning because of the poor generalization of minority classes. Traditionally,the well-known synthetic minority oversampling technique (SMOTE) for dataaugmentation, a data mining approach for imbalanced learning, has been used toimprove this generalization. However, it is unclear whether SMOTE also benefitsdeep learning. In this work, we study why the original SMOTE is insufficientfor deep learning, and enhance SMOTE using soft labels. Connecting theresulting soft SMOTE with Mixup, a modern data augmentation technique, leads toa unified framework that puts traditional and modern data augmentationtechniques under the same umbrella. A careful study within this framework showsthat Mixup improves generalization by implicitly achieving uneven marginsbetween majority and minority classes. We then propose a novel margin-awareMixup technique that more explicitly achieves uneven margins. Extensiveexperimental results demonstrate that our proposed technique yieldsstate-of-the-art performance on deep imbalanced classification while achievingsuperior performance on extremely imbalanced data. The code is open-sourced inour developed package https://github.com/ntucllab/imbalanced-DL to fosterfuture research in this direction.</description><author>Wei-Chao Cheng, Tan-Ha Mai, Hsuan-Tien Lin</author><pubDate>Tue, 29 Aug 2023 18:31:26 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2308.15457v1</guid></item><item><title>Pseudo-Boolean Polynomials Approach To Edge Detection And Image Segmentation</title><link>http://arxiv.org/abs/2308.15453v1</link><description>We introduce a deterministic approach to edge detection and imagesegmentation by formulating pseudo-Boolean polynomials on image patches. Theapproach works by applying a binary classification of blob and edge regions inan image based on the degrees of pseudo-Boolean polynomials calculated onpatches extracted from the provided image. We test our method on simple imagescontaining primitive shapes of constant and contrasting colour and establishthe feasibility before applying it to complex instances like aerial landscapeimages. The proposed method is based on the exploitation of the reduction,polynomial degree, and equivalence properties of penalty-based pseudo-Booleanpolynomials.</description><author>Tendai Mapungwana Chikake, Boris Goldengorin, Alexey Samosyuk</author><pubDate>Tue, 29 Aug 2023 18:23:33 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2308.15453v1</guid></item><item><title>When Do Program-of-Thoughts Work for Reasoning?</title><link>http://arxiv.org/abs/2308.15452v1</link><description>The reasoning capabilities of Large Language Models (LLMs) play a pivotalrole in the realm of embodied artificial intelligence. Although there areeffective methods like program-of-thought prompting for LLMs which usesprogramming language to tackle complex reasoning tasks, the specific impact ofcode data on the improvement of reasoning capabilities remains under-explored.To address this gap, we propose complexity-impacted reasoning score (CIRS),which combines structural and logical attributes, to measure the correlationbetween code and reasoning abilities. Specifically, we use the abstract syntaxtree to encode the structural information and calculate logical complexity byconsidering the difficulty and the cyclomatic complexity. Through an empiricalanalysis, we find not all code data of complexity can be learned or understoodby LLMs. Optimal level of complexity is critical to the improvement ofreasoning abilities by program-aided prompting. Then we design anauto-synthesizing and stratifying algorithm, and apply it to instructiongeneration for mathematical reasoning and code data filtering for codegeneration tasks. Extensive results demonstrates the effectiveness of ourproposed approach. Code will be integrated into the EasyInstruct framework athttps://github.com/zjunlp/EasyInstruct.</description><author>Zhen Bi, Ningyu Zhang, Yinuo Jiang, Shumin Deng, Guozhou Zheng, Huajun Chen</author><pubDate>Tue, 29 Aug 2023 18:22:39 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2308.15452v1</guid></item><item><title>Vulgar Remarks Detection in Chittagonian Dialect of Bangla</title><link>http://arxiv.org/abs/2308.15448v1</link><description>The negative effects of online bullying and harassment are increasing withInternet popularity, especially in social media. One solution is using naturallanguage processing (NLP) and machine learning (ML) methods for the automaticdetection of harmful remarks, but these methods are limited in low-resourcelanguages like the Chittagonian dialect of Bangla.This study focuses ondetecting vulgar remarks in social media using supervised ML and deep learningalgorithms.Logistic Regression achieved promising accuracy (0.91) while simpleRNN with Word2vec and fastTex had lower accuracy (0.84-0.90), highlighting theissue that NN algorithms require more data.</description><author>Tanjim Mahmud, Michal Ptaszynski, Fumito Masui</author><pubDate>Tue, 29 Aug 2023 18:19:32 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2308.15448v1</guid></item><item><title>Mol-Instructions: A Large-Scale Biomolecular Instruction Dataset for Large Language Models</title><link>http://arxiv.org/abs/2306.08018v2</link><description>Large Language Models (LLMs), with their remarkable task-handlingcapabilities and innovative outputs, have catalyzed significant advancementsacross a spectrum of fields. However, their proficiency within specializeddomains such as biomolecular studies remains limited. To address thischallenge, we introduce Mol-Instructions, a meticulously curated, comprehensiveinstruction dataset expressly designed for the biomolecular realm.Mol-Instructions is composed of three pivotal components: molecule-orientedinstructions, protein-oriented instructions, and biomolecular textinstructions, each curated to enhance the understanding and predictioncapabilities of LLMs concerning biomolecular features and behaviors. Throughextensive instruction tuning experiments on the representative LLM, weunderscore the potency of Mol-Instructions to enhance the adaptability andcognitive acuity of large models within the complex sphere of biomolecularstudies, thereby promoting advancements in the biomolecular research community.Mol-Instructions is made publicly accessible for future research endeavors andwill be subjected to continual updates for enhanced applicability.</description><author>Yin Fang, Xiaozhuan Liang, Ningyu Zhang, Kangwei Liu, Rui Huang, Zhuo Chen, Xiaohui Fan, Huajun Chen</author><pubDate>Tue, 29 Aug 2023 18:13:05 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.08018v2</guid></item><item><title>Combining predictive distributions of electricity prices: Does minimizing the CRPS lead to optimal decisions in day-ahead bidding?</title><link>http://arxiv.org/abs/2308.15443v1</link><description>Probabilistic price forecasting has recently gained attention in powertrading because decisions based on such predictions can yield significantlyhigher profits than those made with point forecasts alone. At the same time,methods are being developed to combine predictive distributions, since no modelis perfect and averaging generally improves forecasting performance. In thisarticle we address the question of whether using CRPS learning, a novelweighting technique minimizing the continuous ranked probability score (CRPS),leads to optimal decisions in day-ahead bidding. To this end, we conduct anempirical study using hourly day-ahead electricity prices from the German EPEXmarket. We find that increasing the diversity of an ensemble can have apositive impact on accuracy. At the same time, the higher computational cost ofusing CRPS learning compared to an equal-weighted aggregation of distributionsis not offset by higher profits, despite significantly more accuratepredictions.</description><author>Weronika Nitka, Rafał Weron</author><pubDate>Tue, 29 Aug 2023 18:10:38 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2308.15443v1</guid></item><item><title>An Empirical Investigation of the Role of Pre-training in Lifelong Learning</title><link>http://arxiv.org/abs/2112.09153v2</link><description>The lifelong learning paradigm in machine learning is an attractivealternative to the more prominent isolated learning scheme not only due to itsresemblance to biological learning but also its potential to reduce energywaste by obviating excessive model re-training. A key challenge to thisparadigm is the phenomenon of catastrophic forgetting. With the increasingpopularity and success of pre-trained models in machine learning, we pose thequestion: What role does pre-training play in lifelong learning, specificallywith respect to catastrophic forgetting? We investigate existing methods in thecontext of large, pre-trained models and evaluate their performance on avariety of text and image classification tasks, including a large-scale studyusing a novel data set of 15 diverse NLP tasks. Across all settings, we observethat generic pre-training implicitly alleviates the effects of catastrophicforgetting when learning multiple tasks sequentially compared to randomlyinitialized models. We then further investigate why pre-training alleviatesforgetting in this setting. We study this phenomenon by analyzing the losslandscape, finding that pre-trained weights appear to ease forgetting byleading to wider minima. Based on this insight, we propose jointly optimizingfor current task loss and loss basin sharpness to explicitly encourage widerbasins during sequential fine-tuning. We show that this optimization approachoutperforms several state-of-the-art task-sequential continual learningalgorithms across multiple settings, occasionally even without retaining amemory that scales in size with the number of tasks.</description><author>Sanket Vaibhav Mehta, Darshan Patil, Sarath Chandar, Emma Strubell</author><pubDate>Tue, 29 Aug 2023 18:04:19 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2112.09153v2</guid></item><item><title>Random feature approximation for general spectral methods</title><link>http://arxiv.org/abs/2308.15434v1</link><description>Random feature approximation is arguably one of the most popular techniquesto speed up kernel methods in large scale algorithms and provides a theoreticalapproach to the analysis of deep neural networks. We analyze generalizationproperties for a large class of spectral regularization methods combined withrandom features, containing kernel methods with implicit regularization such asgradient descent or explicit methods like Tikhonov regularization. For ourestimators we obtain optimal learning rates over regularity classes (even forclasses that are not included in the reproducing kernel Hilbert space), whichare defined through appropriate source conditions. This improves or completesprevious results obtained in related settings for specific kernel algorithms.</description><author>Mike Nguyen, Nicole Mücke</author><pubDate>Tue, 29 Aug 2023 17:56:03 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2308.15434v1</guid></item><item><title>Political Sentiment Analysis of Persian Tweets Using CNN-LSTM Model</title><link>http://arxiv.org/abs/2307.07740v2</link><description>Sentiment analysis is the process of identifying and categorizing people'semotions or opinions regarding various topics. The analysis of Twittersentiment has become an increasingly popular topic in recent years. In thispaper, we present several machine learning and a deep learning model toanalysis sentiment of Persian political tweets. Our analysis was conductedusing Bag of Words and ParsBERT for word representation. We applied GaussianNaive Bayes, Gradient Boosting, Logistic Regression, Decision Trees, RandomForests, as well as a combination of CNN and LSTM to classify the polarities oftweets. The results of this study indicate that deep learning with ParsBERTembedding performs better than machine learning. The CNN-LSTM model had thehighest classification accuracy with 89 percent on the first dataset and 71percent on the second dataset. Due to the complexity of Persian, it was adifficult task to achieve this level of efficiency. The main objective of ourresearch was to reduce the training time while maintaining the model'sperformance. As a result, several adjustments were made to the modelarchitecture and parameters. In addition to achieving the objective, theperformance was slightly improved as well.</description><author>Mohammad Dehghani, Zahra Yazdanparast</author><pubDate>Tue, 29 Aug 2023 17:55:11 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.07740v2</guid></item><item><title>Complementing Onboard Sensors with Satellite Map: A New Perspective for HD Map Construction</title><link>http://arxiv.org/abs/2308.15427v1</link><description>High-Definition (HD) maps play a crucial role in autonomous driving systems.Recent methods have attempted to construct HD maps in real-time based oninformation obtained from vehicle onboard sensors. However, the performance ofthese methods is significantly susceptible to the environment surrounding thevehicle due to the inherent limitation of onboard sensors, such as weakcapacity for long-range detection. In this study, we demonstrate thatsupplementing onboard sensors with satellite maps can enhance the performanceof HD map construction methods, leveraging the broad coverage capability ofsatellite maps. For the purpose of further research, we release the satellitemap tiles as a complementary dataset of nuScenes dataset. Meanwhile, we proposea hierarchical fusion module that enables better fusion of satellite mapsinformation with existing methods. Specifically, we design an attention maskbased on segmentation and distance, applying the cross-attention mechanism tofuse onboard Bird's Eye View (BEV) features and satellite features infeature-level fusion. An alignment module is introduced before concatenation inBEV-level fusion to mitigate the impact of misalignment between the twofeatures. The experimental results on the augmented nuScenes dataset showcasethe seamless integration of our module into three existing HD map constructionmethods. It notably enhances their performance in both HD map semanticsegmentation and instance detection tasks.</description><author>Wenjie Gao, Jiawei Fu, Haodong Jing, Nanning Zheng</author><pubDate>Tue, 29 Aug 2023 17:33:16 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2308.15427v1</guid></item><item><title>Characterizing Learning Curves During Language Model Pre-Training: Learning, Forgetting, and Stability</title><link>http://arxiv.org/abs/2308.15419v1</link><description>How do language models learn to make predictions during pre-training? Tostudy this question, we extract learning curves from five autoregressiveEnglish language model pre-training runs, for 1M tokens in context. We observethat the language models generate short repetitive phrases before learning togenerate longer and more coherent text. We quantify the final surprisal,within-run variability, age of acquisition, forgettability, and cross-runvariability of learning curves for individual tokens in context. More frequenttokens reach lower final surprisals, exhibit less variability within and acrosspre-training runs, are learned earlier, and are less likely to be "forgotten"during pre-training. Higher n-gram probabilities further accentuate theseeffects. Independent of the target token, shorter and more frequent contextscorrelate with marginally more stable and quickly acquired predictions. Effectsof part-of-speech are also small, although nouns tend to be acquired later andless stably than verbs, adverbs, and adjectives. Our work contributes to abetter understanding of language model pre-training dynamics and informs thedeployment of stable language models in practice.</description><author>Tyler A. Chang, Zhuowen Tu, Benjamin K. Bergen</author><pubDate>Tue, 29 Aug 2023 17:24:09 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2308.15419v1</guid></item><item><title>WrappingNet: Mesh Autoencoder via Deep Sphere Deformation</title><link>http://arxiv.org/abs/2308.15413v1</link><description>There have been recent efforts to learn more meaningful representations viafixed length codewords from mesh data, since a mesh serves as a complete modelof underlying 3D shape compared to a point cloud. However, the meshconnectivity presents new difficulties when constructing a deep learningpipeline for meshes. Previous mesh unsupervised learning approaches typicallyassume category-specific templates, e.g., human face/body templates. Itrestricts the learned latent codes to only be meaningful for objects in aspecific category, so the learned latent spaces are unable to be used acrossdifferent types of objects. In this work, we present WrappingNet, the firstmesh autoencoder enabling general mesh unsupervised learning over heterogeneousobjects. It introduces a novel base graph in the bottleneck dedicated torepresenting mesh connectivity, which is shown to facilitate learning a sharedlatent space representing object shape. The superiority of WrappingNet meshlearning is further demonstrated via improved reconstruction quality andcompetitive classification compared to point cloud learning, as well as latentinterpolation between meshes of different categories.</description><author>Eric Lei, Muhammad Asad Lodhi, Jiahao Pang, Junghyun Ahn, Dong Tian</author><pubDate>Tue, 29 Aug 2023 17:13:04 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2308.15413v1</guid></item><item><title>Probabilistic solar flare forecasting using historical magnetogram data</title><link>http://arxiv.org/abs/2308.15410v1</link><description>Solar flare forecasting research using machine learning (ML) has focused onhigh resolution magnetogram data from the SDO/HMI era covering Solar Cycle 24and the start of Solar Cycle 25, with some efforts looking back to SOHO/MDI fordata from Solar Cycle 23. In this paper, we consider over 4 solar cycles ofdaily historical magnetogram data from multiple instruments. This is the firstattempt to take advantage of this historical data for ML-based flareforecasting. We apply a convolutional neural network (CNN) to extract featuresfrom full-disk magnetograms together with a logistic regression model toincorporate scalar features based on magnetograms and flaring history. We usean ensemble approach to generate calibrated probabilistic forecasts of M-classor larger flares in the next 24 hours. Overall, we find that includinghistorical data improves forecasting skill and reliability. We show that singleframe magnetograms do not contain significantly more relevant information thancan be summarized in a small number of scalar features, and that flaringhistory has greater predictive power than our CNN-extracted features. Thisindicates the importance of including temporal information in flare forecastingmodels.</description><author>Kiera van der Sande, Andrés Muñoz-Jaramillo, Subhamoy Chatterjee</author><pubDate>Tue, 29 Aug 2023 17:10:20 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2308.15410v1</guid></item><item><title>Robust Long-Tailed Learning via Label-Aware Bounded CVaR</title><link>http://arxiv.org/abs/2308.15405v1</link><description>Data in the real-world classification problems are always imbalanced orlong-tailed, wherein the majority classes have the most of the samples thatdominate the model training. In such setting, the naive model tends to havepoor performance on the minority classes. Previously, a variety of lossmodifications have been proposed to address the long-tailed leaning problem,while these methods either treat the samples in the same classindiscriminatingly or lack a theoretical guarantee. In this paper, we proposetwo novel approaches based on CVaR (Conditional Value at Risk) to improve theperformance of long-tailed learning with a solid theoretical ground.Specifically, we firstly introduce a Label-Aware Bounded CVaR (LAB-CVaR) lossto overcome the pessimistic result of the original CVaR, and further design theoptimal weight bounds for LAB-CVaR theoretically. Based on LAB-CVaR, weadditionally propose a LAB-CVaR with logit adjustment (LAB-CVaR-logit) loss tostabilize the optimization process, where we also offer the theoreticalsupport. Extensive experiments on real-world datasets with long-tailed labeldistributions verify the superiority of our proposed methods.</description><author>Hong Zhu, Runpeng Yu, Xing Tang, Yifei Wang, Yuan Fang, Yisen Wang</author><pubDate>Tue, 29 Aug 2023 17:07:18 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2308.15405v1</guid></item><item><title>Rethinking Machine Ethics -- Can LLMs Perform Moral Reasoning through the Lens of Moral Theories?</title><link>http://arxiv.org/abs/2308.15399v1</link><description>Making moral judgments is an essential step toward developing ethical AIsystems. Prevalent approaches are mostly implemented in a bottom-up manner,which uses a large set of annotated data to train models based on crowd-sourcedopinions about morality. These approaches have been criticized for potentiallyovergeneralizing a limited group of annotators' moral stances and lackingexplainability. In contrast, top-down approaches make moral judgments groundedin a set of principles. However, it remains conceptual due to the incapabilityof previous language models and the unsolved debate among moral principles. Inthis study, we propose a flexible framework to steer Large Language Models(LLMs) to perform moral reasoning with well-established moral theories frominterdisciplinary research. The theory-guided top-down framework canincorporate various moral theories. Our experiments demonstrate theeffectiveness of the proposed framework on datasets derived from moraltheories. Furthermore, we show the alignment between different moral theoriesand existing morality datasets. Our analysis exhibits the potentials and flawsin existing resources (models and datasets) in developing explainable moraljudgment-making systems.</description><author>Jingyan Zhou, Minda Hu, Junan Li, Xiaoying Zhang, Xixin Wu, Irwin King, Helen Meng</author><pubDate>Tue, 29 Aug 2023 16:57:32 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2308.15399v1</guid></item><item><title>Beyond Document Page Classification: Design, Datasets, and Challenges</title><link>http://arxiv.org/abs/2308.12896v2</link><description>This paper highlights the need to bring document classification benchmarkingcloser to real-world applications, both in the nature of data tested ($X$:multi-channel, multi-paged, multi-industry; $Y$: class distributions and labelset variety) and in classification tasks considered ($f$: multi-page document,page stream, and document bundle classification, ...). We identify the lack ofpublic multi-page document classification datasets, formalize differentclassification tasks arising in application scenarios, and motivate the valueof targeting efficient multi-page document representations. An experimentalstudy on proposed multi-page document classification datasets demonstrates thatcurrent benchmarks have become irrelevant and need to be updated to evaluatecomplete documents, as they naturally occur in practice. This reality checkalso calls for more mature evaluation methodologies, covering calibrationevaluation, inference complexity (time-memory), and a range of realisticdistribution shifts (e.g., born-digital vs. scanning noise, shifting pageorder). Our study ends on a hopeful note by recommending concrete avenues forfuture improvements.}</description><author>Jordy Van Landeghem, Sanket Biswas, Matthew B. Blaschko, Marie-Francine Moens</author><pubDate>Tue, 29 Aug 2023 16:57:02 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2308.12896v2</guid></item><item><title>Color Aesthetics: Fuzzy based User-driven Method for Harmony and Preference Prediction</title><link>http://arxiv.org/abs/2308.15397v1</link><description>Color is the most important intrinsic sensory feature that has a powerfulimpact on product sales. Color is even responsible for raising the aestheticsenses in our brains. Account for individual differences is crucial in coloraesthetics. It requires user-driven mechanisms for various e-commerceapplications. We propose a method for quantitative evaluation of all types ofperceptual responses to color(s): distinct color preference, color harmony, andcolor combination preference. Preference for color schemes can be predicted bycombining preferences for the basic colors and ratings of color harmony.Harmonious pallets are extracted from big data set using comparison algorithmsbased on fuzzy similarity and grouping. The proposed model results in usefulpredictions of harmony and preference of multicolored images. For example, inthe context of apparel coordination, it allows predicting a preference for alook based on clothing colors. Our approach differs from standard aestheticmodels, since in accounts for a personal variation. In addition, it can processnot only lower-order color pairs, but also groups of several colors.</description><author>Pakizar Shamoi, Atsushi Inoue, Hiroharu Kawanaka</author><pubDate>Tue, 29 Aug 2023 16:56:38 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2308.15397v1</guid></item><item><title>The CausalBench challenge: A machine learning contest for gene network inference from single-cell perturbation data</title><link>http://arxiv.org/abs/2308.15395v1</link><description>In drug discovery, mapping interactions between genes within cellular systemsis a crucial early step. This helps formulate hypotheses regarding molecularmechanisms that could potentially be targeted by future medicines. TheCausalBench Challenge was an initiative to invite the machine learningcommunity to advance the state of the art in constructing gene-gene interactionnetworks. These networks, derived from large-scale, real-world datasets ofsingle cells under various perturbations, are crucial for understanding thecausal mechanisms underlying disease biology. Using the framework provided bythe CausalBench benchmark, participants were tasked with enhancing the capacityof the state of the art methods to leverage large-scale genetic perturbationdata. This report provides an analysis and summary of the methods submittedduring the challenge to give a partial image of the state of the art at thetime of the challenge. The winning solutions significantly improved performancecompared to previous baselines, establishing a new state of the art for thiscritical task in biology and medicine.</description><author>Mathieu Chevalley, Jacob Sackett-Sanders, Yusuf Roohani, Pascal Notin, Artemy Bakulin, Dariusz Brzezinski, Kaiwen Deng, Yuanfang Guan, Justin Hong, Michael Ibrahim, Wojciech Kotlowski, Marcin Kowiel, Panagiotis Misiakos, Achille Nazaret, Markus Püschel, Chris Wendler, Arash Mehrjou, Patrick Schwab</author><pubDate>Tue, 29 Aug 2023 16:54:15 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2308.15395v1</guid></item><item><title>inTformer: A Time-Embedded Attention-Based Transformer for Crash Likelihood Prediction at Intersections Using Connected Vehicle Data</title><link>http://arxiv.org/abs/2307.03854v4</link><description>The real-time crash likelihood prediction model is an essential component ofthe proactive traffic safety management system. Over the years, numerousstudies have attempted to construct a crash likelihood prediction model inorder to enhance traffic safety, but mostly on freeways. In the majority of theexisting studies, researchers have primarily employed a deep learning-basedframework to identify crash potential. Lately, Transformer has emerged as apotential deep neural network that fundamentally operates throughattention-based mechanisms. Transformer has several functional benefits overextant deep learning models such as LSTM, CNN, etc. Firstly, Transformer canreadily handle long-term dependencies in a data sequence. Secondly,Transformers can parallelly process all elements in a data sequence duringtraining. Finally, a Transformer does not have the vanishing gradient issue.Realizing the immense possibility of Transformers, this paper proposesinTersection-Transformer (inTformer), a time-embedded attention-basedTransformer model that can effectively predict intersection crash likelihood inreal-time. The proposed model was evaluated using connected vehicle dataextracted from Signal Analytics Platform. Acknowledging the complex trafficoperation mechanism at intersection, this study developed zone-specific modelsby dividing the intersection region into two distinct zones:within-intersection and approach zone. The best inTformer models in'within-intersection,' and 'approach' zone achieved a sensitivity of 73%, and70%, respectively. The zone-level models were also compared to earlier studieson crash likelihood prediction at intersections and with several establisheddeep learning models trained on the same connected vehicle dataset.</description><author>B M Tazbiul Hassan Anik, Zubayer Islam, Mohamed Abdel-Aty</author><pubDate>Tue, 29 Aug 2023 16:51:05 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.03854v4</guid></item><item><title>Decentralized Multi-agent Reinforcement Learning based State-of-Charge Balancing Strategy for Distributed Energy Storage System</title><link>http://arxiv.org/abs/2308.15394v1</link><description>This paper develops a Decentralized Multi-Agent Reinforcement Learning(Dec-MARL) method to solve the SoC balancing problem in the distributed energystorage system (DESS). First, the SoC balancing problem is formulated into afinite Markov decision process with action constraints derived from demandbalance, which can be solved by Dec-MARL. Specifically, the first-order averageconsensus algorithm is utilized to expand the observations of the DESS state ina fully-decentralized way, and the initial actions (i.e., output power) aredecided by the agents (i.e., energy storage units) according to theseobservations. In order to get the final actions in the allowable range, acounterfactual demand balance algorithm is proposed to balance the total demandand the initial actions. Next, the agents execute the final actions and getlocal rewards from the environment, and the DESS steps into the next state.Finally, through the first-order average consensus algorithm, the agents getthe average reward and the expended observation of the next state for latertraining. By the above procedure, Dec-MARL reveals outstanding performance in afully-decentralized system without any expert experience or constructing anycomplicated model. Besides, it is flexible and can be extended to otherdecentralized multi-agent systems straightforwardly. Extensive simulations havevalidated the effectiveness and efficiency of Dec-MARL.</description><author>Zheng Xiong, Biao Luo, Bing-Chuan Wang, Xiaodong Xu, Xiaodong Liu, Tingwen Huang</author><pubDate>Tue, 29 Aug 2023 16:48:49 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2308.15394v1</guid></item><item><title>Challenges of GPT-3-based Conversational Agents for Healthcare</title><link>http://arxiv.org/abs/2308.14641v2</link><description>The potential to provide patients with faster information access whileallowing medical specialists to concentrate on critical tasks makes medicaldomain dialog agents appealing. However, the integration of large-languagemodels (LLMs) into these agents presents certain limitations that may result inserious consequences. This paper investigates the challenges and risks of usingGPT-3-based models for medical question-answering (MedQA). We perform severalevaluations contextualized in terms of standard medical principles. We providea procedure for manually designing patient queries to stress-test high-risklimitations of LLMs in MedQA systems. Our analysis reveals that LLMs fail torespond adequately to these queries, generating erroneous medical information,unsafe recommendations, and content that may be considered offensive.</description><author>Fabian Lechner, Allison Lahnala, Charles Welch, Lucie Flek</author><pubDate>Tue, 29 Aug 2023 16:48:23 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2308.14641v2</guid></item><item><title>A Bayesian Framework for Digital Twin-Based Control, Monitoring, and Data Collection in Wireless Systems</title><link>http://arxiv.org/abs/2212.01351v3</link><description>Commonly adopted in the manufacturing and aerospace sectors, digital twin(DT) platforms are increasingly seen as a promising paradigm to control,monitor, and analyze software-based, "open", communication systems. Notably, DTplatforms provide a sandbox in which to test artificial intelligence (AI)solutions for communication systems, potentially reducing the need to collectdata and test algorithms in the field, i.e., on the physical twin (PT). A keychallenge in the deployment of DT systems is to ensure that virtual controloptimization, monitoring, and analysis at the DT are safe and reliable,avoiding incorrect decisions caused by "model exploitation". To address thischallenge, this paper presents a general Bayesian framework with the aim ofquantifying and accounting for model uncertainty at the DT that is caused bylimitations in the amount and quality of data available at the DT from the PT.In the proposed framework, the DT builds a Bayesian model of the communicationsystem, which is leveraged to enable core DT functionalities such as controlvia multi-agent reinforcement learning (MARL), monitoring of the PT for anomalydetection, prediction, data-collection optimization, and counterfactualanalysis. To exemplify the application of the proposed framework, wespecifically investigate a case-study system encompassing multiple sensingdevices that report to a common receiver. Experimental results validate theeffectiveness of the proposed Bayesian framework as compared to standardfrequentist model-based solutions.</description><author>Clement Ruah, Osvaldo Simeone, Bashir Al-Hashimi</author><pubDate>Tue, 29 Aug 2023 16:42:35 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2212.01351v3</guid></item><item><title>Investigating Reproducibility at Interspeech Conferences: A Longitudinal and Comparative Perspective</title><link>http://arxiv.org/abs/2306.10033v2</link><description>Reproducibility is a key aspect for scientific advancement acrossdisciplines, and reducing barriers for open science is a focus area for thetheme of Interspeech 2023. Availability of source code is one of the indicatorsthat facilitates reproducibility. However, less is known about the rates ofreproducibility at Interspeech conferences in comparison to other conferencesin the field. In order to fill this gap, we have surveyed 27,717 papers atseven conferences across speech and language processing disciplines. We findthat despite having a close number of accepted papers to the other conferences,Interspeech has up to 40% less source code availability. In addition toreporting the difficulties we have encountered during our research, we alsoprovide recommendations and possible directions to increase reproducibility forfurther studies.</description><author>Mohammad Arvan, A. Seza Doğruöz, Natalie Parde</author><pubDate>Tue, 29 Aug 2023 16:39:32 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.10033v2</guid></item><item><title>Bayesian Integration of Information Using Top-Down Modulated WTA Networks</title><link>http://arxiv.org/abs/2308.15390v1</link><description>Winner Take All (WTA) circuits a type of Spiking Neural Networks (SNN) havebeen suggested as facilitating the brain's ability to process information in aBayesian manner. Research has shown that WTA circuits are capable ofapproximating hierarchical Bayesian models via Expectation Maximization (EM).So far, research in this direction has focused on bottom up processes. This iscontrary to neuroscientific evidence that shows that, besides bottom upprocesses, top down processes too play a key role in information processing bythe human brain. Several functions ascribed to top down processes includedirection of attention, adjusting for expectations, facilitation of encodingand recall of learned information, and imagery. This paper explores whether WTAcircuits are suitable for further integrating information represented inseparate WTA networks. Furthermore, it explores whether, and under whatcircumstances, top down processes can improve WTA network performance withrespect to inference and learning. The results show that WTA circuits arecapable of integrating the probabilistic information represented by other WTAnetworks, and that top down processes can improve a WTA network's inference andlearning performance. Notably, it is able to do this according to keyneuromorphic principles, making it ideal for low-latency and energy efficientimplementation on neuromorphic hardware.</description><author>Otto van der Himst, Leila Bagheriye, Johan Kwisthout</author><pubDate>Tue, 29 Aug 2023 16:33:51 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2308.15390v1</guid></item><item><title>Shape-Margin Knowledge Augmented Network for Thyroid Nodule Segmentation and Diagnosis</title><link>http://arxiv.org/abs/2308.15386v1</link><description>Thyroid nodule segmentation is a crucial step in the diagnostic procedure ofphysicians and computer-aided diagnosis systems. Mostly, current studies treatsegmentation and diagnosis as independent tasks without considering thecorrelation between these tasks. The sequence steps of these independent tasksin computer-aided diagnosis systems may lead to the accumulation of errors.Therefore, it is worth combining them as a whole through exploring therelationship between thyroid nodule segmentation and diagnosis. According tothe thyroid imaging reporting and data system (TI-RADS), the assessment ofshape and margin characteristics is the prerequisite for the discrimination ofbenign and malignant thyroid nodules. These characteristics can be observed inthe thyroid nodule segmentation masks. Inspired by the diagnostic procedure ofTI-RADS, this paper proposes a shape-margin knowledge augmented network(SkaNet) for simultaneously thyroid nodule segmentation and diagnosis. Due tothe similarity in visual features between segmentation and diagnosis, SkaNetshares visual features in the feature extraction stage and then utilizes adual-branch architecture to perform thyroid nodule segmentation and diagnosistasks simultaneously. To enhance effective discriminative features, anexponential mixture module is devised, which incorporates convolutional featuremaps and self-attention maps by exponential weighting. Then, SkaNet is jointlyoptimized by a knowledge augmented multi-task loss function with a constraintpenalty term. It embeds shape and margin characteristics through numericalcomputation and models the relationship between the thyroid nodule diagnosisresults and segmentation masks.</description><author>Weihua Liu, Chaochao Lin</author><pubDate>Tue, 29 Aug 2023 16:29:06 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2308.15386v1</guid></item><item><title>Learning Content-enhanced Mask Transformer for Domain Generalized Urban-Scene Segmentation</title><link>http://arxiv.org/abs/2307.00371v2</link><description>Domain-generalized urban-scene semantic segmentation (USSS) aims to learngeneralized semantic predictions across diverse urban-scene styles. Unlikedomain gap challenges, USSS is unique in that the semantic categories are oftensimilar in different urban scenes, while the styles can vary significantly dueto changes in urban landscapes, weather conditions, lighting, and otherfactors. Existing approaches typically rely on convolutional neural networks(CNNs) to learn the content of urban scenes. In this paper, we propose a Content-enhanced Mask TransFormer (CMFormer) fordomain-generalized USSS. The main idea is to enhance the focus of thefundamental component, the mask attention mechanism, in Transformersegmentation models on content information. To achieve this, we introduce anovel content-enhanced mask attention mechanism. It learns mask queries fromboth the image feature and its down-sampled counterpart, as lower-resolutionimage features usually contain more robust content information and are lesssensitive to style variations. These features are fused into a Transformerdecoder and integrated into a multi-resolution content-enhanced mask attentionlearning scheme. Extensive experiments conducted on various domain-generalized urban-scenesegmentation datasets demonstrate that the proposed CMFormer significantlyoutperforms existing CNN-based methods for domain-generalized semanticsegmentation, achieving improvements of up to 14.00\% in terms of mIoU (meanintersection over union). The source code for CMFormer will be made availableat this\href{https://github.com/BiQiWHU/domain-generalized-urban-scene-segmentation}{repository}.</description><author>Qi Bi, Shaodi You, Theo Gevers</author><pubDate>Tue, 29 Aug 2023 16:25:30 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.00371v2</guid></item><item><title>On the Robustness of Object Detection Models in Aerial Images</title><link>http://arxiv.org/abs/2308.15378v1</link><description>The robustness of object detection models is a major concern when applied toreal-world scenarios. However, the performance of most object detection modelsdegrades when applied to images subjected to corruptions, since they areusually trained and evaluated on clean datasets. Enhancing the robustness ofobject detection models is of utmost importance, especially for those designedfor aerial images, which feature complex backgrounds, substantial variations inscales and orientations of objects. This paper addresses the challenge ofassessing the robustness of object detection models in aerial images, with aspecific emphasis on scenarios where images are affected by clouds. In thisstudy, we introduce two novel benchmarks based on DOTA-v1.0. The firstbenchmark encompasses 19 prevalent corruptions, while the second focuses oncloud-corrupted images-a phenomenon uncommon in natural pictures yet frequentin aerial photography. We systematically evaluate the robustness of mainstreamobject detection models and perform numerous ablation experiments. Through ourinvestigations, we find that enhanced model architectures, larger networks,well-crafted modules, and judicious data augmentation strategies collectivelyenhance the robustness of aerial object detection models. The benchmarks wepropose and our comprehensive experimental analyses can facilitate research onrobust object detection in aerial images. Codes and datasets are available at:(https://github.com/hehaodong530/DOTA-C)</description><author>Haodong He, Jian Ding, Gui-Song Xia</author><pubDate>Tue, 29 Aug 2023 16:16:51 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2308.15378v1</guid></item><item><title>Multi-Response Heteroscedastic Gaussian Process Models and Their Inference</title><link>http://arxiv.org/abs/2308.15370v1</link><description>Despite the widespread utilization of Gaussian process models for versatilenonparametric modeling, they exhibit limitations in effectively capturingabrupt changes in function smoothness and accommodating relationships withheteroscedastic errors. Addressing these shortcomings, the heteroscedasticGaussian process (HeGP) regression seeks to introduce flexibility byacknowledging the variability of residual variances across covariates in theregression model. In this work, we extend the HeGP concept, expanding its scopebeyond regression tasks to encompass classification and state-space models. Toachieve this, we propose a novel framework where the Gaussian process iscoupled with a covariate-induced precision matrix process, adopting a mixtureformulation. This approach enables the modeling of heteroscedastic covariancefunctions across covariates. To mitigate the computational challenges posed bysampling, we employ variational inference to approximate the posterior andfacilitate posterior predictive modeling. Additionally, our training processleverages an EM algorithm featuring closed-form M-step updates to efficientlyevaluate the heteroscedastic covariance function. A notable feature of ourmodel is its consistent performance on multivariate responses, accommodatingvarious types (continuous or categorical) seamlessly. Through a combination ofsimulations and real-world applications in climatology, we illustrate themodel's prowess and advantages. By overcoming the limitations of traditionalGaussian process models, our proposed framework offers a robust and versatiletool for a wide array of applications.</description><author>Taehee Lee, Jun S. Liu</author><pubDate>Tue, 29 Aug 2023 16:06:47 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2308.15370v1</guid></item><item><title>RED: A Systematic Real-Time Scheduling Approach for Robotic Environmental Dynamics</title><link>http://arxiv.org/abs/2308.15368v1</link><description>Intelligent robots are designed to effectively navigate dynamic andunpredictable environments laden with moving mechanical elements and objects.Such environment-induced dynamics, including moving obstacles, can readilyalter the computational demand (e.g., the creation of new tasks) and thestructure of workloads (e.g., precedence constraints among tasks) duringruntime, thereby adversely affecting overall system performance. This challengeis amplified when multi-task inference is expected on robots operating understringent resource and real-time constraints. To address such a challenge, weintroduce RED, a systematic real-time scheduling approach designed to supportmulti-task deep neural network workloads in resource-limited robotic systems.It is designed to adaptively manage the Robotic Environmental Dynamics (RED)while adhering to real-time constraints. At the core of RED lies adeadline-based scheduler that employs an intermediate deadline assignmentpolicy, effectively managing to change workloads and asynchronous inferenceprompted by complex, unpredictable environments. This scheduling framework alsofacilitates the flexible deployment of MIMONet (multi-input multi-output neuralnetworks), which are commonly utilized in multi-tasking robotic systems tocircumvent memory bottlenecks. Building on this scheduling framework, REDrecognizes and leverages a unique characteristic of MIMONet: its weight-sharedarchitecture. To further accommodate and exploit this feature, RED devises anovel and effective workload refinement and reconstruction process. Thisprocess ensures the scheduling framework's compatibility with MIMONet andmaximizes efficiency.</description><author>Zexin Li, Tao Ren, Xiaoxi He, Cong Liu</author><pubDate>Tue, 29 Aug 2023 16:04:08 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2308.15368v1</guid></item><item><title>Efficient Model Personalization in Federated Learning via Client-Specific Prompt Generation</title><link>http://arxiv.org/abs/2308.15367v1</link><description>Federated learning (FL) emerges as a decentralized learning framework whichtrains models from multiple distributed clients without sharing their data topreserve privacy. Recently, large-scale pre-trained models (e.g., VisionTransformer) have shown a strong capability of deriving robust representations.However, the data heterogeneity among clients, the limited computationresources, and the communication bandwidth restrict the deployment oflarge-scale models in FL frameworks. To leverage robust representations fromlarge-scale models while enabling efficient model personalization forheterogeneous clients, we propose a novel personalized FL framework ofclient-specific Prompt Generation (pFedPG), which learns to deploy apersonalized prompt generator at the server for producing client-specificvisual prompts that efficiently adapts frozen backbones to local datadistributions. Our proposed framework jointly optimizes the stages ofpersonalized prompt adaptation locally and personalized prompt generationglobally. The former aims to train visual prompts that adapt foundation modelsto each client, while the latter observes local optimization directions togenerate personalized prompts for all clients. Through extensive experiments onbenchmark datasets, we show that our pFedPG is favorable againststate-of-the-art personalized FL methods under various types of dataheterogeneity, allowing computation and communication efficient modelpersonalization.</description><author>Fu-En Yang, Chien-Yi Wang, Yu-Chiang Frank Wang</author><pubDate>Tue, 29 Aug 2023 16:03:05 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2308.15367v1</guid></item><item><title>AnomalyGPT: Detecting Industrial Anomalies using Large Vision-Language Models</title><link>http://arxiv.org/abs/2308.15366v1</link><description>Large Vision-Language Models (LVLMs) such as MiniGPT-4 and LLaVA havedemonstrated the capability of understanding images and achieved remarkableperformance in various visual tasks. Despite their strong abilities inrecognizing common objects due to extensive training datasets, they lackspecific domain knowledge and have a weaker understanding of localized detailswithin objects, which hinders their effectiveness in the Industrial AnomalyDetection (IAD) task. On the other hand, most existing IAD methods only provideanomaly scores and necessitate the manual setting of thresholds to distinguishbetween normal and abnormal samples, which restricts their practicalimplementation. In this paper, we explore the utilization of LVLM to addressthe IAD problem and propose AnomalyGPT, a novel IAD approach based on LVLM. Wegenerate training data by simulating anomalous images and producingcorresponding textual descriptions for each image. We also employ an imagedecoder to provide fine-grained semantic and design a prompt learner tofine-tune the LVLM using prompt embeddings. Our AnomalyGPT eliminates the needfor manual threshold adjustments, thus directly assesses the presence andlocations of anomalies. Additionally, AnomalyGPT supports multi-turn dialoguesand exhibits impressive few-shot in-context learning capabilities. With onlyone normal shot, AnomalyGPT achieves the state-of-the-art performance with anaccuracy of 86.1%, an image-level AUC of 94.1%, and a pixel-level AUC of 95.3%on the MVTec-AD dataset. Code is available athttps://github.com/CASIA-IVA-Lab/AnomalyGPT.</description><author>Zhaopeng Gu, Bingke Zhu, Guibo Zhu, Yingying Chen, Ming Tang, Jinqiao Wang</author><pubDate>Tue, 29 Aug 2023 16:02:53 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2308.15366v1</guid></item><item><title>OLISIA: a Cascade System for Spoken Dialogue State Tracking</title><link>http://arxiv.org/abs/2304.11073v2</link><description>Though Dialogue State Tracking (DST) is a core component of spoken dialoguesystems, recent work on this task mostly deals with chat corpora, disregardingthe discrepancies between spoken and written language.In this paper, we proposeOLISIA, a cascade system which integrates an Automatic Speech Recognition (ASR)model and a DST model. We introduce several adaptations in the ASR and DSTmodules to improve integration and robustness to spoken conversations.Withthese adaptations, our system ranked first in DSTC11 Track 3, a benchmark toevaluate spoken DST. We conduct an in-depth analysis of the results and findthat normalizing the ASR outputs and adapting the DST inputs through dataaugmentation, along with increasing the pre-trained models size all play animportant role in reducing the performance discrepancy between written andspoken conversations.</description><author>Léo Jacqmin, Lucas Druart, Yannick Estève, Benoît Favre, Lina Maria Rojas-Barahona, Valentin Vielzeuf</author><pubDate>Tue, 29 Aug 2023 16:02:08 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2304.11073v2</guid></item><item><title>Heterogeneous Multi-Task Gaussian Cox Processes</title><link>http://arxiv.org/abs/2308.15364v1</link><description>This paper presents a novel extension of multi-task Gaussian Cox processesfor modeling multiple heterogeneous correlated tasks jointly, e.g.,classification and regression, via multi-output Gaussian processes (MOGP). AMOGP prior over the parameters of the dedicated likelihoods for classification,regression and point process tasks can facilitate sharing of informationbetween heterogeneous tasks, while allowing for nonparametric parameterestimation. To circumvent the non-conjugate Bayesian inference in the MOGPmodulated heterogeneous multi-task framework, we employ the data augmentationtechnique and derive a mean-field approximation to realize closed-formiterative updates for estimating model parameters. We demonstrate theperformance and inference on both 1D synthetic data as well as 2D urban data ofVancouver.</description><author>Feng Zhou, Quyu Kong, Zhijie Deng, Fengxiang He, Peng Cui, Jun Zhu</author><pubDate>Tue, 29 Aug 2023 16:01:01 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2308.15364v1</guid></item><item><title>Text-to-SQL Empowered by Large Language Models: A Benchmark Evaluation</title><link>http://arxiv.org/abs/2308.15363v1</link><description>Large language models (LLMs) have emerged as a new paradigm for Text-to-SQLtask. However, the absence of a systematical benchmark inhibits the developmentof designing effective, efficient and economic LLM-based Text-to-SQL solutions.To address this challenge, in this paper, we first conduct a systematical andextensive comparison over existing prompt engineering methods, includingquestion representation, example selection and example organization, and withthese experimental results, we elaborates their pros and cons. Based on thesefindings, we propose a new integrated solution, named DAIL-SQL, which refreshesthe Spider leaderboard with 86.6% execution accuracy and sets a new bar.Towards an efficient and economic LLM-based Text-to-SQL solution, we emphasizethe token efficiency in prompt engineering and compare the prior studies underthis metric. Additionally, we investigate open-source LLMs in in-contextlearning, and further enhance their performance with task-specific supervisedfine-tuning. Our explorations highlight open-source LLMs' potential inText-to-SQL, as well as the advantages and disadvantages of the task-specificsupervised fine-tuning. We hope that our work provides a deeper understandingof Text-to-SQL with LLMs, and inspire further investigations and broadapplications.</description><author>Dawei Gao, Haibin Wang, Yaliang Li, Xiuyu Sun, Yichen Qian, Bolin Ding, Jingren Zhou</author><pubDate>Tue, 29 Aug 2023 15:59:54 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2308.15363v1</guid></item><item><title>Exploring the Relationship between Samples and Masks for Robust Defect Localization</title><link>http://arxiv.org/abs/2306.10720v2</link><description>Defect detection aims to detect and localize regions out of the normaldistribution.Previous approaches model normality and compare it with the inputto identify defective regions, potentially limiting their generalizability.Thispaper proposes a one-stage framework that detects defective patterns directlywithout the modeling process.This ability is adopted through the joint effortsof three parties: a generative adversarial network (GAN), a newly proposedscaled pattern loss, and a dynamic masked cycle-consistent auxiliary network.Explicit information that could indicate the position of defects isintentionally excluded to avoid learning any direct mapping.Experimentalresults on the texture class of the challenging MVTec AD dataset show that theproposed method is 2.9\% higher than the SOTA methods in F1-Score, whilesubstantially outperforming SOTA methods in generalizability.</description><author>Jiang Lin, Yaping yan</author><pubDate>Tue, 29 Aug 2023 15:59:28 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.10720v2</guid></item><item><title>Theory of Mind Might Have Spontaneously Emerged in Large Language Models</title><link>http://arxiv.org/abs/2302.02083v4</link><description>We explore the intriguing possibility that theory of mind (ToM), or theuniquely human ability to impute unobservable mental states to others, mighthave spontaneously emerged in large language models (LLMs). We designed 40false-belief tasks, considered a gold standard in testing ToM in humans, andadministered them to several LLMs. Each task included a false-belief scenario,three closely matched true-belief controls, and the reversed versions of allfour. Smaller and older models solved no tasks; GPT-3-davinci-001 (from May2020) and GPT-3-davinci-002 (from January 2022) solved 10%; andGPT-3-davinci-003 (from November 2022) and ChatGPT-3.5-turbo (from March 2023)solved 35% of the tasks, mirroring the performance of three-year-old children.ChatGPT-4 (from June 2023) solved 90% of the tasks, matching the performance ofseven-year-old children. These findings suggest the intriguing possibility thatToM, previously considered exclusive to humans, may have spontaneously emergedas a byproduct of LLMs' improving language skills.</description><author>Michal Kosinski</author><pubDate>Tue, 29 Aug 2023 15:55:37 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2302.02083v4</guid></item><item><title>Ego-Motion Estimation and Dynamic Motion Separation from 3D Point Clouds for Accumulating Data and Improving 3D Object Detection</title><link>http://arxiv.org/abs/2308.15357v1</link><description>New 3+1D high-resolution radar sensors are gaining importance for 3D objectdetection in the automotive domain due to their relative affordability andimproved detection compared to classic low-resolution radar sensors. Onelimitation of high-resolution radar sensors, compared to lidar sensors, is thesparsity of the generated point cloud. This sparsity could be partiallyovercome by accumulating radar point clouds of subsequent time steps. Thiscontribution analyzes limitations of accumulating radar point clouds on theView-of-Delft dataset. By employing different ego-motion estimation approaches,the dataset's inherent constraints, and possible solutions are analyzed.Additionally, a learning-based instance motion estimation approach is deployedto investigate the influence of dynamic motion on the accumulated point cloudfor object detection. Experiments document an improved object detectionperformance by applying an ego-motion estimation and dynamic motion correctionapproach.</description><author>Patrick Palmer, Martin Krueger, Richard Altendorfer, Torsten Bertram</author><pubDate>Tue, 29 Aug 2023 15:53:16 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2308.15357v1</guid></item><item><title>torchgfn: A PyTorch GFlowNet library</title><link>http://arxiv.org/abs/2305.14594v2</link><description>The growing popularity of generative flow networks (GFlowNets or GFNs) from arange of researchers with diverse backgrounds and areas of expertisenecessitates a library which facilitates the testing of new features such astraining losses that can be easily compared to standard benchmarkimplementations, or on a set of common environments. torchgfn is a PyTorchlibrary that aims to address this need. It provides users with a simple API forenvironments and useful abstractions for samplers and losses. Multiple examplesare provided, replicating and unifying published results. The code is availablein https://github.com/saleml/torchgfn.</description><author>Salem Lahlou, Joseph D. Viviano, Victor Schmidt, Yoshua Bengio</author><pubDate>Tue, 29 Aug 2023 15:51:08 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.14594v2</guid></item><item><title>Few-shot $\mathbf{1/a}$ Anomalies Feedback : Damage Vision Mining Opportunity and Embedding Feature Imbalance</title><link>http://arxiv.org/abs/2307.12676v5</link><description>Over the past decade, previous balanced datasets have been used to advancedeep learning algorithms for industrial applications. In urban infrastructuresand living environments, damage data mining cannot avoid imbalanced data issuesbecause of rare unseen events and the high-quality status of improvedoperations. For visual inspection, the deteriorated class acquired from thesurface of concrete and steel components are occasionally imbalanced. Fromnumerous related surveys, we conclude that imbalanced data problems can becategorised into four types: 1) missing range of target and label valuables, 2)majority-minority class imbalance, 3) foreground background of spatialimbalance, and 4) long-tailed class of pixel-wise imbalance. Since 2015, manyimbalanced studies have been conducted using deep-learning approaches,including regression, image classification, object detection, and semanticsegmentation. However, anomaly detection for imbalanced data is not well known.In this study, we highlight a one-class anomaly detection application, whetheranomalous class or not, and demonstrate clear examples of imbalanced visiondatasets: medical disease, hazardous behaviour, material deterioration, plantdisease, river sludge, and disaster damage. We provide key results on theadvantage of damage-vision mining, hypothesising that the more effective therange of the positive ratio, the higher the accuracy gain of the anomaliesfeedback. In our imbalanced studies, compared with the balanced case with apositive ratio of $1/1$, we find that there is an applicable positive ratio$1/a$ where the accuracy is consistently high. However, the extremelyimbalanced range is from one shot to $1/2a$, the accuracy of which is inferiorto that of the applicable ratio. In contrast, with a positive ratio rangingover $2/a$, it shifts in the over-mining phase without an effective gain inaccuracy.</description><author>Takato Yasuno</author><pubDate>Tue, 29 Aug 2023 15:48:37 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.12676v5</guid></item><item><title>Detect, Augment, Compose, and Adapt: Four Steps for Unsupervised Domain Adaptation in Object Detection</title><link>http://arxiv.org/abs/2308.15353v1</link><description>Unsupervised domain adaptation (UDA) plays a crucial role in object detectionwhen adapting a source-trained detector to a target domain without annotateddata. In this paper, we propose a novel and effective four-step UDA approachthat leverages self-supervision and trains source and target data concurrently.We harness self-supervised learning to mitigate the lack of ground truth in thetarget domain. Our method consists of the following steps: (1) identify theregion with the highest-confidence set of detections in each target image,which serve as our pseudo-labels; (2) crop the identified region and generate acollection of its augmented versions; (3) combine these latter into a compositeimage; (4) adapt the network to the target domain using the composed image.Through extensive experiments under cross-camera, cross-weather, andsynthetic-to-real scenarios, our approach achieves state-of-the-artperformance, improving upon the nearest competitor by more than 2% in terms ofmean Average Precision (mAP). The code is available athttps://github.com/MohamedTEV/DACA.</description><author>Mohamed L. Mekhalfi, Davide Boscaini, Fabio Poiesi</author><pubDate>Tue, 29 Aug 2023 15:48:29 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2308.15353v1</guid></item><item><title>Historical patterns of rice farming explain modern-day language use in China and Japan more than modernization and urbanization</title><link>http://arxiv.org/abs/2308.15352v1</link><description>We used natural language processing to analyze a billion words to studycultural differences on Weibo, one of China's largest social media platforms.We compared predictions from two common explanations about cultural differencesin China (economic development and urban-rural differences) against theless-obvious legacy of rice versus wheat farming. Rice farmers had tocoordinate shared irrigation networks and exchange labor to cope with higherlabor requirements. In contrast, wheat relied on rainfall and required half asmuch labor. We test whether this legacy made southern China moreinterdependent. Across all word categories, rice explained twice as muchvariance as economic development and urbanization. Rice areas used more wordsreflecting tight social ties, holistic thought, and a cautious, preventionorientation. We then used Twitter data comparing prefectures in Japan, whichlargely replicated the results from China. This provides crucial evidence ofthe rice theory in a different nation, language, and platform.</description><author>Sharath Chandra Guntuku, Thomas Talhelm, Garrick Sherman, Angel Fan, Salvatore Giorgi, Liuqing Wei, Lyle H. Ungar</author><pubDate>Tue, 29 Aug 2023 15:47:08 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2308.15352v1</guid></item><item><title>Lie-Poisson Neural Networks (LPNets): Data-Based Computing of Hamiltonian Systems with Symmetries</title><link>http://arxiv.org/abs/2308.15349v1</link><description>An accurate data-based prediction of the long-term evolution of Hamiltoniansystems requires a network that preserves the appropriate structure under eachtime step. Every Hamiltonian system contains two essential ingredients: thePoisson bracket and the Hamiltonian. Hamiltonian systems with symmetries, whoseparadigm examples are the Lie-Poisson systems, have been shown to describe abroad category of physical phenomena, from satellite motion to underwatervehicles, fluids, geophysical applications, complex fluids, and plasma physics.The Poisson bracket in these systems comes from the symmetries, while theHamiltonian comes from the underlying physics. We view the symmetry of thesystem as primary, hence the Lie-Poisson bracket is known exactly, whereas theHamiltonian is regarded as coming from physics and is considered not known, orknown approximately. Using this approach, we develop a network based ontransformations that exactly preserve the Poisson bracket and the specialfunctions of the Lie-Poisson systems (Casimirs) to machine precision. Wepresent two flavors of such systems: one, where the parameters oftransformations are computed from data using a dense neural network (LPNets),and another, where the composition of transformations is used as buildingblocks (G-LPNets). We also show how to adapt these methods to a larger class ofPoisson brackets. We apply the resulting methods to several examples, such asrigid body (satellite) motion, underwater vehicles, a particle in a magneticfield, and others. The methods developed in this paper are important for theconstruction of accurate data-based methods for simulating the long-termdynamics of physical systems.</description><author>Christopher Eldred, François Gay-Balmaz, Sofiia Huraka, Vakhtang Putkaradze</author><pubDate>Tue, 29 Aug 2023 15:45:23 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2308.15349v1</guid></item><item><title>Enhancing Mobile Face Anti-Spoofing: A Robust Framework for Diverse Attack Types under Screen Flash</title><link>http://arxiv.org/abs/2308.15346v1</link><description>Face anti-spoofing (FAS) is crucial for securing face recognition systems.However, existing FAS methods with handcrafted binary or pixel-wise labels havelimitations due to diverse presentation attacks (PAs). In this paper, wepropose an attack type robust face anti-spoofing framework under light flash,called ATR-FAS. Due to imaging differences caused by various attack types,traditional FAS methods based on single binary classification network mayresult in excessive intra-class distance of spoof faces, leading to a challengeof decision boundary learning. Therefore, we employed multiple networks toreconstruct multi-frame depth maps as auxiliary supervision, and each networkexperts in one type of attack. A dual gate module (DGM) consisting of a typegate and a frame-attention gate is introduced, which perform attack typerecognition and multi-frame attention generation, respectively. The outputs ofDGM are utilized as weight to mix the result of multiple expert networks. Themulti-experts mixture enables ATR-FAS to generate spoof-differentiated depthmaps, and stably detects spoof faces without being affected by different typesof PAs. Moreover, we design a differential normalization procedure to convertoriginal flash frames into differential frames. This simple but effectiveprocessing enhances the details in flash frames, aiding in the generation ofdepth maps. To verify the effectiveness of our framework, we collected alarge-scale dataset containing 12,660 live and spoof videos with diverse PAsunder dynamic flash from the smartphone screen. Extensive experimentsillustrate that the proposed ATR-FAS significantly outperforms existingstate-of-the-art methods. The code and dataset will be available athttps://github.com/Chaochao-Lin/ATR-FAS.</description><author>Weihua Liu, Chaochao Lin, Yu Yan</author><pubDate>Tue, 29 Aug 2023 15:41:40 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2308.15346v1</guid></item><item><title>IndGIC: Supervised Action Recognition under Low Illumination</title><link>http://arxiv.org/abs/2308.15345v1</link><description>Technologies of human action recognition in the dark are gaining more andmore attention as huge demand in surveillance, motion control andhuman-computer interaction. However, because of limitation in image enhancementmethod and low-lighting video datasets, e.g. labeling cost, existing methodsmeet some problems. Some video-based approached are effect and efficient inspecific datasets but cannot generalize to most cases while others methodsusing multiple sensors rely heavily to prior knowledge to deal with noisynature from video stream. In this paper, we proposes action recognition methodusing deep multi-input network. Furthermore, we proposed a Independent GammaIntensity Corretion (Ind-GIC) to enhance poor-illumination video, generatingone gamma for one frame to increase enhancement performance. To prove ourmethod is effective, there is some evaluation and comparison between our methodand existing methods. Experimental results show that our model achieves highaccuracy in on ARID dataset.</description><author>Jingbo Zeng</author><pubDate>Tue, 29 Aug 2023 15:41:10 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2308.15345v1</guid></item><item><title>Imperceptible Adversarial Attack on Deep Neural Networks from Image Boundary</title><link>http://arxiv.org/abs/2308.15344v1</link><description>Although Deep Neural Networks (DNNs), such as the convolutional neuralnetworks (CNN) and Vision Transformers (ViTs), have been successfully appliedin the field of computer vision, they are demonstrated to be vulnerable towell-sought Adversarial Examples (AEs) that can easily fool the DNNs. Theresearch in AEs has been active, and many adversarial attacks and explanationshave been proposed since they were discovered in 2014. The mystery of the AE'sexistence is still an open question, and many studies suggest that DNN trainingalgorithms have blind spots. The salient objects usually do not overlap withboundaries; hence, the boundaries are not the DNN model's attention.Nevertheless, recent studies show that the boundaries can dominate the behaviorof the DNN models. Hence, this study aims to look at the AEs from a differentperspective and proposes an imperceptible adversarial attack that systemicallyattacks the input image boundary for finding the AEs. The experimental resultshave shown that the proposed boundary attacking method effectively attacks sixCNN models and the ViT using only 32% of the input image content (from theboundaries) with an average success rate (SR) of 95.2% and an average peaksignal-to-noise ratio of 41.37 dB. Correlation analyses are conducted,including the relation between the adversarial boundary's width and the SR andhow the adversarial boundary changes the DNN model's attention. This paper'sdiscoveries can potentially advance the understanding of AEs and provide adifferent perspective on how AEs can be constructed.</description><author>Fahad Alrasheedi, Xin Zhong</author><pubDate>Tue, 29 Aug 2023 15:41:05 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2308.15344v1</guid></item><item><title>Application Performance Modeling via Tensor Completion</title><link>http://arxiv.org/abs/2210.10184v3</link><description>Performance tuning, software/hardware co-design, and job scheduling are amongthe many tasks that rely on models to predict application performance. Wepropose and evaluate low-rank tensor decomposition for modeling applicationperformance. We discretize the input and configuration domains of anapplication using regular grids. Application execution times mapped withingrid-cells are averaged and represented by tensor elements. We show thatlow-rank canonical-polyadic (CP) tensor decomposition is effective inapproximating these tensors. We further show that this decomposition enablesaccurate extrapolation of unobserved regions of an application's parameterspace. We then employ tensor completion to optimize a CP decomposition given asparse set of observed execution times. We consider alternativepiecewise/grid-based models and supervised learning models for six applicationsand demonstrate that CP decomposition optimized using tensor completion offershigher prediction accuracy and memory-efficiency for high-dimensionalperformance modeling.</description><author>Edward Hutter, Edgar Solomonik</author><pubDate>Tue, 29 Aug 2023 15:36:29 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2210.10184v3</guid></item><item><title>AI Framework for Early Diagnosis of Coronary Artery Disease: An Integration of Borderline SMOTE, Autoencoders and Convolutional Neural Networks Approach</title><link>http://arxiv.org/abs/2308.15339v1</link><description>The accuracy of coronary artery disease (CAD) diagnosis is dependent on avariety of factors, including demographic, symptom, and medical examination,ECG, and echocardiography data, among others. In this context, artificialintelligence (AI) can help clinicians identify high-risk patients early in thediagnostic process, by synthesizing information from multiple factors. To thisaim, Machine Learning algorithms are used to classify patients based on theirCAD disease risk. In this study, we contribute to this research filed bydeveloping a methodology for balancing and augmenting data for more accurateprediction when the data is imbalanced and the sample size is small. Themethodology can be used in a variety of other situations, particularly whendata collection is expensive and the sample size is small. The experimentalresults revealed that the average accuracy of our proposed method for CADprediction was 95.36, and was higher than random forest (RF), decision tree(DT), support vector machine (SVM), logistic regression (LR), and artificialneural network (ANN).</description><author>Elham Nasarian, Danial Sharifrazi, Saman Mohsenirad, Kwok Tsui, Roohallah Alizadehsani</author><pubDate>Tue, 29 Aug 2023 15:33:38 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2308.15339v1</guid></item><item><title>A Framework for Responsible Development of Automated Student Feedback with Generative AI</title><link>http://arxiv.org/abs/2308.15334v1</link><description>Providing rich feedback to students is essential for supporting studentlearning. Recent advances in generative AI, particularly within large languagemodelling (LLM), provide the opportunity to deliver repeatable, scalable andinstant automatically generated feedback to students, making abundant apreviously scarce and expensive learning resource. Such an approach is feasiblefrom a technical perspective due to these recent advances in ArtificialIntelligence (AI) and Natural Language Processing (NLP); while the potentialupside is a strong motivator, doing so introduces a range of potential ethicalissues that must be considered as we apply these technologies. Theattractiveness of AI systems is that they can effectively automate the mostmundane tasks; but this risks introducing a "tyranny of the majority", wherethe needs of minorities in the long tail are overlooked because they aredifficult to automate. Developing machine learning models that can generate valuable and authenticfeedback requires the input of human domain experts. The choices we make incapturing this expertise -- whose, which, when, and how -- will havesignificant consequences for the nature of the resulting feedback. How wemaintain our models will affect how that feedback remains relevant giventemporal changes in context, theory, and prior learning profiles of studentcohorts. These questions are important from an ethical perspective; but theyare also important from an operational perspective. Unless they can beanswered, our AI generated systems will lack the trust necessary for them to beuseful features in the contemporary learning environment. This article will outline the frontiers of automated feedback, identify theethical issues involved in the provision of automated feedback and present aframework to assist academics to develop such systems responsibly.</description><author>Euan D Lindsay, Aditya Johri, Johannes Bjerva</author><pubDate>Tue, 29 Aug 2023 15:29:57 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2308.15334v1</guid></item><item><title>Learning Bayesian Networks with Heterogeneous Agronomic Data Sets via Mixed-Effect Models and Hierarchical Clustering</title><link>http://arxiv.org/abs/2308.06399v2</link><description>Research involving diverse but related data sets, where associations betweencovariates and outcomes may vary, is prevalent in various fields includingagronomic studies. In these scenarios, hierarchical models, also known asmultilevel models, are frequently employed to assimilate information fromdifferent data sets while accommodating their distinct characteristics.However, their structure extend beyond simple heterogeneity, as variables oftenform complex networks of causal relationships. Bayesian networks (BNs) provide a powerful framework for modelling suchrelationships using directed acyclic graphs to illustrate the connectionsbetween variables. This study introduces a novel approach that integratesrandom effects into BN learning. Rooted in linear mixed-effects models, thisapproach is particularly well-suited for handling hierarchical data. Resultsfrom a real-world agronomic trial suggest that employing this approach enhancesstructural learning, leading to the discovery of new connections and theimprovement of improved model specification. Furthermore, we observe areduction in prediction errors from 28% to 17%. By extending the applicabilityof BNs to complex data set structures, this approach contributes to theeffective utilisation of BNs for hierarchical agronomic data. This, in turn,enhances their value as decision-support tools in the field.</description><author>Lorenzo Valleggi, Marco Scutari, Federico Mattia Stefanini</author><pubDate>Tue, 29 Aug 2023 15:27:58 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2308.06399v2</guid></item><item><title>Enhancing Robot Learning through Learned Human-Attention Feature Maps</title><link>http://arxiv.org/abs/2308.15327v1</link><description>Robust and efficient learning remains a challenging problem in robotics, inparticular with complex visual inputs. Inspired by human attention mechanism,with which we quickly process complex visual scenes and react to changes in theenvironment, we think that embedding auxiliary information about focus pointinto robot learning would enhance efficiency and robustness of the learningprocess. In this paper, we propose a novel approach to model and emulate thehuman attention with an approximate prediction model. We then leverage thisoutput and feed it as a structured auxiliary feature map into downstreamlearning tasks. We validate this idea by learning a prediction model fromhuman-gaze recordings of manual driving in the real world. We test our approachon two learning tasks - object detection and imitation learning. Ourexperiments demonstrate that the inclusion of predicted human attention leadsto improved robustness of the trained models to out-of-distribution samples andfaster learning in low-data regime settings. Our work highlights the potentialof incorporating structured auxiliary information in representation learningfor robotics and opens up new avenues for research in this direction. All codeand data are available online.</description><author>Daniel Scheuchenstuhl, Stefan Ulmer, Felix Resch, Luigi Berducci, Radu Grosu</author><pubDate>Tue, 29 Aug 2023 15:23:44 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2308.15327v1</guid></item><item><title>FedLogic: Interpretable Federated Multi-Domain Chain-of-Thought Prompt Selection for Large Language Models</title><link>http://arxiv.org/abs/2308.15324v1</link><description>Leveraging ``chain-of-thought (CoT)'' reasoning to elicit rapid and preciseresponses from large language models (LLMs) is rapidly attracting researchinterest. A notable challenge here is how to design or select optimal prompts.The process of prompt selection relies on trial and error, involving continuousadjustments and combinations of input prompts by users based on thecorresponding new responses generated from LLMs. Furthermore, minimal researchhas been conducted to explore how LLMs employ the mathematical problem-solvingcapabilities learned from user interactions to address issues in narrativewriting. To improve interpretability and explore the balance principle betweengenerality and personalization under a multi-domain CoT prompt selectionscenario, we propose the Federated Logic rule learning approach (FedLogic). Weintroduce a theoretical formalization and interactive emulation of themulti-domain CoT prompt selection dilemma in the context of federated LLMs. Wecast the problem of joint probability modeling as a bilevel program, where theCoT prompt selection intricacy can be likened to a fuzzy score-based ruleselection with the LLMs function as rule generators. FedLogic solves thisproblem through variational expectation maximization (V-EM). In addition, weincorporate two KL-divergence constraints within this probabilistic modelingframework to surmount the intricacies of managing extensive search spaces andaccomplishing cross-domain personalization of CoTs. To the best of ourknowledge, FedLogic is the first interpretable and principled federatedmulti-domain CoT prompt selection approach for LLMs.</description><author>Pengwei Xing, Songtao Lu, Han Yu</author><pubDate>Tue, 29 Aug 2023 15:20:17 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2308.15324v1</guid></item><item><title>Occlusion-Aware Deep Convolutional Neural Network via Homogeneous Tanh-transforms for Face Parsing</title><link>http://arxiv.org/abs/2308.15323v1</link><description>Face parsing infers a pixel-wise label map for each semantic facialcomponent. Previous methods generally work well for uncovered faces, howeveroverlook the facial occlusion and ignore some contextual area outside a singleface, especially when facial occlusion has become a common situation during theCOVID-19 epidemic. Inspired by the illumination theory of image, we propose anovel homogeneous tanh-transforms for image preprocessing, which made up offour tanh-transforms, that fuse the central vision and the peripheral visiontogether. Our proposed method addresses the dilemma of face parsing underocclusion and compresses more information of surrounding context. Based onhomogeneous tanh-transforms, we propose an occlusion-aware convolutional neuralnetwork for occluded face parsing. It combines the information both inTanh-polar space and Tanh-Cartesian space, capable of enhancing receptivefields. Furthermore, we introduce an occlusion-aware loss to focus on theboundaries of occluded regions. The network is simple and flexible, and can betrained end-to-end. To facilitate future research of occluded face parsing, wealso contribute a new cleaned face parsing dataset, which is manually purifiedfrom several academic or industrial datasets, including CelebAMask-HQ,Short-video Face Parsing as well as Helen dataset and will make it public.Experiments demonstrate that our method surpasses state-of-art methods of faceparsing under occlusion.</description><author>Weihua Liu, Chaochao Lin, Haoping Yu, Said Boumaraf, Zhaoqiong Pi</author><pubDate>Tue, 29 Aug 2023 15:20:13 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2308.15323v1</guid></item><item><title>Elucidating the Exposure Bias in Diffusion Models</title><link>http://arxiv.org/abs/2308.15321v1</link><description>Diffusion models have demonstrated impressive generative capabilities, buttheir 'exposure bias' problem, described as the input mismatch between trainingand sampling, lacks in-depth exploration. In this paper, we systematicallyinvestigate the exposure bias problem in diffusion models by first analyticallymodelling the sampling distribution, based on which we then attribute theprediction error at each sampling step as the root cause of the exposure biasissue. Furthermore, we discuss potential solutions to this issue and propose anintuitive metric for it. Along with the elucidation of exposure bias, wepropose a simple, yet effective, training-free method called Epsilon Scaling toalleviate the exposure bias. We show that Epsilon Scaling explicitly moves thesampling trajectory closer to the vector field learned in the training phase byscaling down the network output (Epsilon), mitigating the input mismatchbetween training and sampling. Experiments on various diffusion frameworks(ADM, DDPM/DDIM, LDM), unconditional and conditional settings, anddeterministic vs. stochastic sampling verify the effectiveness of our method.</description><author>Mang Ning, Mingxiao Li, Jianlin Su, Albert Ali Salah, Itir Onal Ertugrul</author><pubDate>Tue, 29 Aug 2023 15:16:09 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2308.15321v1</guid></item><item><title>Reliable Multimodality Eye Disease Screening via Mixture of Student's t Distributions</title><link>http://arxiv.org/abs/2303.09790v4</link><description>Multimodality eye disease screening is crucial in ophthalmology as itintegrates information from diverse sources to complement their respectiveperformances. However, the existing methods are weak in assessing thereliability of each unimodality, and directly fusing an unreliable modality maycause screening errors. To address this issue, we introduce a novelmultimodality evidential fusion pipeline for eye disease screening, EyeMoSt,which provides a measure of confidence for unimodality and elegantly integratesthe multimodality information from a multi-distribution fusion perspective.Specifically, our model estimates both local uncertainty for unimodality andglobal uncertainty for the fusion modality to produce reliable classificationresults. More importantly, the proposed mixture of Student's $t$ distributionsadaptively integrates different modalities to endow the model with heavy-tailedproperties, increasing robustness and reliability. Our experimental findings onboth public and in-house datasets show that our model is more reliable thancurrent methods. Additionally, EyeMost has the potential ability to serve as adata quality discriminator, enabling reliable decision-making for multimodalityeye disease screening.</description><author>Ke Zou, Tian Lin, Xuedong Yuan, Haoyu Chen, Xiaojing Shen, Meng Wang, Huazhu Fu</author><pubDate>Tue, 29 Aug 2023 15:16:04 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2303.09790v4</guid></item><item><title>Unreliable Partial Label Learning with Recursive Separation</title><link>http://arxiv.org/abs/2302.09891v2</link><description>Partial label learning (PLL) is a typical weakly supervised learning problemin which each instance is associated with a candidate label set, and amongwhich only one is true. However, the assumption that the ground-truth label isalways among the candidate label set would be unrealistic, as the reliabilityof the candidate label sets in real-world applications cannot be guaranteed byannotators. Therefore, a generalized PLL named Unreliable Partial LabelLearning (UPLL) is proposed, in which the true label may not be in thecandidate label set. Due to the challenges posed by unreliable labeling,previous PLL methods will experience a marked decline in performance whenapplied to UPLL. To address the issue, we propose a two-stage framework namedUnreliable Partial Label Learning with Recursive Separation (UPLLRS). In thefirst stage, the self-adaptive recursive separation strategy is proposed toseparate the training set into a reliable subset and an unreliable subset. Inthe second stage, a disambiguation strategy is employed to progressivelyidentify the ground-truth labels in the reliable subset. Simultaneously,semi-supervised learning methods are adopted to extract valuable informationfrom the unreliable subset. Our method demonstrates state-of-the-artperformance as evidenced by experimental results, particularly in situations ofhigh unreliability. Code and supplementary materials are available athttps://github.com/dhiyu/UPLLRS.</description><author>Yu Shi, Ning Xu, Hua Yuan, Xin Geng</author><pubDate>Tue, 29 Aug 2023 15:10:46 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2302.09891v2</guid></item><item><title>Cross-Lingual Constituency Parsing for Middle High German: A Delexicalized Approach</title><link>http://arxiv.org/abs/2308.04645v2</link><description>Constituency parsing plays a fundamental role in advancing natural languageprocessing (NLP) tasks. However, training an automatic syntactic analysissystem for ancient languages solely relying on annotated parse data is aformidable task due to the inherent challenges in building treebanks for suchlanguages. It demands extensive linguistic expertise, leading to a scarcity ofavailable resources. To overcome this hurdle, cross-lingual transfer techniqueswhich require minimal or even no annotated data for low-resource targetlanguages offer a promising solution. In this study, we focus on building aconstituency parser for $\mathbf{M}$iddle $\mathbf{H}$igh $\mathbf{G}$erman($\mathbf{MHG}$) under realistic conditions, where no annotated MHG treebank isavailable for training. In our approach, we leverage the linguistic continuityand structural similarity between MHG and $\mathbf{M}$odern $\mathbf{G}$erman($\mathbf{MG}$), along with the abundance of MG treebank resources.Specifically, by employing the $\mathit{delexicalization}$ method, we train aconstituency parser on MG parse datasets and perform cross-lingual transfer toMHG parsing. Our delexicalized constituency parser demonstrates remarkableperformance on the MHG test set, achieving an F1-score of 67.3%. It outperformsthe best zero-shot cross-lingual baseline by a margin of 28.6% points. Theseencouraging results underscore the practicality and potential for automaticsyntactic analysis in other ancient languages that face similar challenges asMHG.</description><author>Ercong Nie, Helmut Schmid, Hinrich Schütze</author><pubDate>Tue, 29 Aug 2023 15:09:49 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2308.04645v2</guid></item><item><title>Quantifying Causes of Arctic Amplification via Deep Learning based Time-series Causal Inference</title><link>http://arxiv.org/abs/2303.07122v4</link><description>The warming of the Arctic, also known as Arctic amplification, is led byseveral atmospheric and oceanic drivers. However, the details of its underlyingthermodynamic causes are still unknown. Inferring the causal effects ofatmospheric processes on sea ice melt using fixed treatment effect strategiesleads to unrealistic counterfactual estimations. Such models are also prone tobias due to time-varying confoundedness. Further, the complex non-linearity inEarth science data makes it infeasible to perform causal inference usingexisting marginal structural techniques. In order to tackle these challenges,we propose TCINet - time-series causal inference model to infer causation undercontinuous treatment using recurrent neural networks and a novel probabilisticbalancing technique. Through experiments on synthetic and observational data,we show how our research can substantially improve the ability to quantifyleading causes of Arctic sea ice melt, further paving paths for causalinference in observational Earth science.</description><author>Sahara Ali, Omar Faruque, Yiyi Huang, Md. Osman Gani, Aneesh Subramanian, Nicole-Jienne Shchlegel, Jianwu Wang</author><pubDate>Tue, 29 Aug 2023 15:07:12 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2303.07122v4</guid></item><item><title>3D-MuPPET: 3D Multi-Pigeon Pose Estimation and Tracking</title><link>http://arxiv.org/abs/2308.15316v1</link><description>Markerless methods for animal posture tracking have been developing recently,but frameworks and benchmarks for tracking large animal groups in 3D are stilllacking. To overcome this gap in the literature, we present 3D-MuPPET, aframework to estimate and track 3D poses of up to 10 pigeons at interactivespeed using multiple-views. We train a pose estimator to infer 2D keypoints andbounding boxes of multiple pigeons, then triangulate the keypoints to 3D. Forcorrespondence matching, we first dynamically match 2D detections to globalidentities in the first frame, then use a 2D tracker to maintaincorrespondences accross views in subsequent frames. We achieve comparableaccuracy to a state of the art 3D pose estimator for Root Mean Square Error(RMSE) and Percentage of Correct Keypoints (PCK). We also showcase a novel usecase where our model trained with data of single pigeons provides comparableresults on data containing multiple pigeons. This can simplify the domain shiftto new species because annotating single animal data is less labour intensivethan multi-animal data. Additionally, we benchmark the inference speed of3D-MuPPET, with up to 10 fps in 2D and 1.5 fps in 3D, and perform quantitativetracking evaluation, which yields encouraging results. Finally, we show that3D-MuPPET also works in natural environments without model fine-tuning onadditional annotations. To the best of our knowledge we are the first topresent a framework for 2D/3D posture and trajectory tracking that works inboth indoor and outdoor environments.</description><author>Urs Waldmann, Alex Hoi Hang Chan, Hemal Naik, Máté Nagy, Iain D. Couzin, Oliver Deussen, Bastian Goldluecke, Fumihiro Kano</author><pubDate>Tue, 29 Aug 2023 15:02:27 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2308.15316v1</guid></item><item><title>Spatio-temporal MLP-graph network for 3D human pose estimation</title><link>http://arxiv.org/abs/2308.15313v1</link><description>Graph convolutional networks and their variants have shown significantpromise in 3D human pose estimation. Despite their success, most of thesemethods only consider spatial correlations between body joints and do not takeinto account temporal correlations, thereby limiting their ability to capturerelationships in the presence of occlusions and inherent ambiguity. To addressthis potential weakness, we propose a spatio-temporal network architecturecomposed of a joint-mixing multi-layer perceptron block that facilitatescommunication among different joints and a graph weighted Jacobi network blockthat enables communication among various feature channels. The major novelty ofour approach lies in a new weighted Jacobi feature propagation rule obtainedthrough graph filtering with implicit fairing. We leverage temporal informationfrom the 2D pose sequences, and integrate weight modulation into the model toenable untangling of the feature transformations of distinct nodes. We alsoemploy adjacency modulation with the aim of learning meaningful correlationsbeyond defined linkages between body joints by altering the graph topologythrough a learnable modulation matrix. Extensive experiments on two benchmarkdatasets demonstrate the effectiveness of our model, outperforming recentstate-of-the-art methods for 3D human pose estimation.</description><author>Tanvir Hassan, A. Ben Hamza</author><pubDate>Tue, 29 Aug 2023 15:00:55 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2308.15313v1</guid></item><item><title>Bayesian Feature Selection in Joint Quantile Time Series Analysis</title><link>http://arxiv.org/abs/2010.01654v3</link><description>Quantile feature selection over correlated multivariate time series data hasalways been a methodological challenge and is an open problem. In this paper,we propose a general Bayesian dimension reduction methodology for featureselection in high-dimensional joint quantile time series analysis, under thename of the quantile feature selection time series (QFSTS) model. The QFSTSmodel is a general structural time series model, where each component yields anadditive contribution to the time series modeling with direct interpretations.Its flexibility is compound in the sense that users can add/deduct componentsfor each time series and each time series can have its own specific valuedcomponents of different sizes. Feature selection is conducted in the quantileregression component, where each time series has its own pool ofcontemporaneous external predictors allowing nowcasting. Bayesian methodologyin extending feature selection to the quantile time series research area isdeveloped using multivariate asymmetric Laplace distribution, spike-and-slabprior setup, the Metropolis-Hastings algorithm, and the Bayesian modelaveraging technique, all implemented consistently in the Bayesian paradigm. TheQFSTS model requires small datasets to train and converges fast. Extensiveexaminations confirmed that the QFSTS model has superior performance in featureselection, parameter estimation, and forecast.</description><author>Ning Ning</author><pubDate>Tue, 29 Aug 2023 14:58:43 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2010.01654v3</guid></item><item><title>A Trip Towards Fairness: Bias and De-Biasing in Large Language Models</title><link>http://arxiv.org/abs/2305.13862v2</link><description>Cheap-to-Build Very Large-Language Models (CtB-LLMs) with affordable trainingare emerging as the next big revolution in natural language processing andunderstanding. These CtB-LLMs are democratizing access to trainable VeryLarge-Language Models (VLLMs) and, thus, may represent the building blocks ofmany NLP systems solving downstream tasks. Hence, a little or a large bias inCtB-LLMs may cause huge harm. In this paper, we performed a large investigationof the bias of three families of CtB-LLMs, and we showed that debiasingtechniques are effective and usable. Indeed, according to current tests, theLLaMA and the OPT families have an important bias in gender, race, religion,and profession. In contrast to the analysis for other LLMs, we discovered thatbias depends not on the number of parameters but on the perplexity. Finally,the debiasing of OPT using LoRA reduces bias up to 4.12 points in thenormalized stereotype score.</description><author>Leonardo Ranaldi, Elena Sofia Ruzzetti, Davide Venditti, Dario Onorati, Fabio Massimo Zanzotto</author><pubDate>Tue, 29 Aug 2023 14:55:13 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.13862v2</guid></item><item><title>Uncertainty-inspired Open Set Learning for Retinal Anomaly Identification</title><link>http://arxiv.org/abs/2304.03981v3</link><description>Failure to recognize samples from the classes unseen during training is amajor limitation of artificial intelligence in the real-world implementationfor recognition and classification of retinal anomalies. We established anuncertainty-inspired open-set (UIOS) model, which was trained with fundusimages of 9 retinal conditions. Besides assessing the probability of eachcategory, UIOS also calculated an uncertainty score to express its confidence.Our UIOS model with thresholding strategy achieved an F1 score of 99.55%,97.01% and 91.91% for the internal testing set, external target categories(TC)-JSIEC dataset and TC-unseen testing set, respectively, compared to the F1score of 92.20%, 80.69% and 64.74% by the standard AI model. Furthermore, UIOScorrectly predicted high uncertainty scores, which would prompt the need for amanual check in the datasets of non-target categories retinal diseases,low-quality fundus images, and non-fundus images. UIOS provides a robust methodfor real-world screening of retinal anomalies.</description><author>Meng Wang, Tian Lin, Lianyu Wang, Aidi Lin, Ke Zou, Xinxing Xu, Yi Zhou, Yuanyuan Peng, Qingquan Meng, Yiming Qian, Guoyao Deng, Zhiqun Wu, Junhong Chen, Jianhong Lin, Mingzhi Zhang, Weifang Zhu, Changqing Zhang, Daoqiang Zhang, Rick Siow Mong Goh, Yong Liu, Chi Pui Pang, Xinjian Chen, Haoyu Chen, Huazhu Fu</author><pubDate>Tue, 29 Aug 2023 14:50:43 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2304.03981v3</guid></item><item><title>On-Device Learning with Binary Neural Networks</title><link>http://arxiv.org/abs/2308.15308v1</link><description>Existing Continual Learning (CL) solutions only partially address theconstraints on power, memory and computation of the deep learning models whendeployed on low-power embedded CPUs. In this paper, we propose a CL solutionthat embraces the recent advancements in CL field and the efficiency of theBinary Neural Networks (BNN), that use 1-bit for weights and activations toefficiently execute deep learning models. We propose a hybrid quantization ofCWR* (an effective CL approach) that considers differently forward and backwardpass in order to retain more precision during gradient update step and at thesame time minimizing the latency overhead. The choice of a binary network asbackbone is essential to meet the constraints of low power devices and, to thebest of authors' knowledge, this is the first attempt to prove on-devicelearning with BNN. The experimental validation carried out confirms thevalidity and the suitability of the proposed method.</description><author>Lorenzo Vorabbi, Davide Maltoni, Stefano Santi</author><pubDate>Tue, 29 Aug 2023 14:48:35 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2308.15308v1</guid></item><item><title>TALL: Thumbnail Layout for Deepfake Video Detection</title><link>http://arxiv.org/abs/2307.07494v2</link><description>The growing threats of deepfakes to society and cybersecurity have raisedenormous public concerns, and increasing efforts have been devoted to thiscritical topic of deepfake video detection. Existing video methods achieve goodperformance but are computationally intensive. This paper introduces a simpleyet effective strategy named Thumbnail Layout (TALL), which transforms a videoclip into a pre-defined layout to realize the preservation of spatial andtemporal dependencies. Specifically, consecutive frames are masked in a fixedposition in each frame to improve generalization, then resized to sub-imagesand rearranged into a pre-defined layout as the thumbnail. TALL ismodel-agnostic and extremely simple by only modifying a few lines of code.Inspired by the success of vision transformers, we incorporate TALL into SwinTransformer, forming an efficient and effective method TALL-Swin. Extensiveexperiments on intra-dataset and cross-dataset validate the validity andsuperiority of TALL and SOTA TALL-Swin. TALL-Swin achieves 90.79$\%$ AUC on thechallenging cross-dataset task, FaceForensics++ $\to$ Celeb-DF. The code isavailable at https://github.com/rainy-xu/TALL4Deepfake.</description><author>Yuting Xu, Jian Liang, Gengyun Jia, Ziming Yang, Yanhao Zhang, Ran He</author><pubDate>Tue, 29 Aug 2023 14:43:37 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.07494v2</guid></item><item><title>Weakly Supervised Intracranial Hemorrhage Segmentation using Head-Wise Gradient-Infused Self-Attention Maps from a Swin Transformer in Categorical Learning</title><link>http://arxiv.org/abs/2304.04902v2</link><description>Intracranial hemorrhage (ICH) is a life-threatening medical emergency thatrequires timely and accurate diagnosis for effective treatment and improvedpatient survival rates. While deep learning techniques have emerged as theleading approach for medical image analysis and processing, the most commonlyemployed supervised learning often requires large, high-quality annotateddatasets that can be costly to obtain, particularly for pixel/voxel-wise imagesegmentation. To address this challenge and facilitate ICH treatment decisions,we introduce a novel weakly supervised method for ICH segmentation, utilizing aSwin transformer trained on an ICH classification task with categorical labels.Our approach leverages a hierarchical combination of head-wise gradient-infusedself-attention maps to generate accurate image segmentation. Additionally, weconducted an exploratory study on different learning strategies and showed thatbinary ICH classification has a more positive impact on self-attention mapscompared to full ICH subtyping. With a mean Dice score of 0.44, our techniqueachieved similar ICH segmentation performance as the popular U-Net andSwin-UNETR models with full supervision and outperformed a similar weaklysupervised approach using GradCAM, demonstrating the excellent potential of theproposed framework in challenging medical image segmentation tasks. Our code isavailable at https://github.com/HealthX-Lab/HGI-SAM.</description><author>Amirhossein Rasoulian, Soorena Salari, Yiming Xiao</author><pubDate>Tue, 29 Aug 2023 14:42:27 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2304.04902v2</guid></item><item><title>MSFlow: Multi-Scale Flow-based Framework for Unsupervised Anomaly Detection</title><link>http://arxiv.org/abs/2308.15300v1</link><description>Unsupervised anomaly detection (UAD) attracts a lot of research interest anddrives widespread applications, where only anomaly-free samples are availablefor training. Some UAD applications intend to further locate the anomalousregions without any anomaly information. Although the absence of anomalous samples and annotations deteriorates theUAD performance, an inconspicuous yet powerful statistics model, thenormalizing flows, is appropriate for anomaly detection and localization in anunsupervised fashion. The flow-based probabilistic models, only trained onanomaly-free data, can efficiently distinguish unpredictable anomalies byassigning them much lower likelihoods than normal data. Nevertheless, the size variation of unpredictable anomalies introducesanother inconvenience to the flow-based methods for high-precision anomalydetection and localization. To generalize the anomaly size variation, wepropose a novel Multi-Scale Flow-based framework dubbed MSFlow composed ofasymmetrical parallel flows followed by a fusion flow to exchange multi-scaleperceptions. Moreover, different multi-scale aggregation strategies are adoptedfor image-wise anomaly detection and pixel-wise anomaly localization accordingto the discrepancy between them. The proposed MSFlow is evaluated on threeanomaly detection datasets, significantly outperforming existing methods.Notably, on the challenging MVTec AD benchmark, our MSFlow achieves a newstate-of-the-art with a detection AUORC score of up to 99.7%, localizationAUCROC score of 98.8%, and PRO score of 97.1%. The reproducible code isavailable at https://github.com/cool-xuan/msflow.</description><author>Yixuan Zhou, Xing Xu, Jingkuan Song, Fumin Shen, Heng Tao Shen</author><pubDate>Tue, 29 Aug 2023 14:38:35 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2308.15300v1</guid></item><item><title>TaskLAMA: Probing the Complex Task Understanding of Language Models</title><link>http://arxiv.org/abs/2308.15299v1</link><description>Structured Complex Task Decomposition (SCTD) is the problem of breaking downa complex real-world task (such as planning a wedding) into a directed acyclicgraph over individual steps that contribute to achieving the task, with edgesspecifying temporal dependencies between them. SCTD is an important componentof assistive planning tools, and a challenge for commonsense reasoning systems.We probe how accurately SCTD can be done with the knowledge extracted fromLarge Language Models (LLMs). We introduce a high-quality human-annotateddataset for this problem and novel metrics to fairly assess performance of LLMsagainst several baselines. Our experiments reveal that LLMs are able todecompose complex tasks into individual steps effectively, with a relativeimprovement of 15% to 280% over the best baseline. We also propose a number ofapproaches to further improve their performance, with a relative improvement of7% to 37% over the base model. However, we find that LLMs still struggle topredict pairwise temporal dependencies, which reveals a gap in theirunderstanding of complex tasks.</description><author>Quan Yuan, Mehran Kazemi, Xin Xu, Isaac Noble, Vaiva Imbrasaite, Deepak Ramachandran</author><pubDate>Tue, 29 Aug 2023 14:36:45 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2308.15299v1</guid></item><item><title>KGConv, a Conversational Corpus grounded in Wikidata</title><link>http://arxiv.org/abs/2308.15298v1</link><description>We present KGConv, a large, conversational corpus of 71k conversations whereeach question-answer pair is grounded in a Wikidata fact. Conversations containon average 8.6 questions and for each Wikidata fact, we provide multiplevariants (12 on average) of the corresponding question using templates, humanannotations, hand-crafted rules and a question rewriting neural model. Weprovide baselines for the task of Knowledge-Based, Conversational QuestionGeneration. KGConv can further be used for other generation and analysis taskssuch as single-turn question generation from Wikidata triples, questionrewriting, question answering from conversation or from knowledge graphs andquiz generation.</description><author>Quentin Brabant, Gwenole Lecorve, Lina M. Rojas-Barahona, Claire Gardent</author><pubDate>Tue, 29 Aug 2023 14:35:51 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2308.15298v1</guid></item><item><title>Combinatorial Pure Exploration with Full-bandit Feedback and Beyond: Solving Combinatorial Optimization under Uncertainty with Limited Observation</title><link>http://arxiv.org/abs/2012.15584v2</link><description>Combinatorial optimization is one of the fundamental research fields that hasbeen extensively studied in theoretical computer science and operationsresearch. When developing an algorithm for combinatorial optimization, it iscommonly assumed that parameters such as edge weights are exactly known asinputs. However, this assumption may not be fulfilled since input parametersare often uncertain or initially unknown in many applications such asrecommender systems, crowdsourcing, communication networks, and onlineadvertisement. To resolve such uncertainty, the problem of combinatorial pureexploration of multi-armed bandits (CPE) and its variants have recievedincreasing attention. Earlier work on CPE has studied the semi-bandit feedbackor assumed that the outcome from each individual edge is always accessible atall rounds. However, due to practical constraints such as a budget ceiling orprivacy concern, such strong feedback is not always available in recentapplications. In this article, we review recently proposed techniques forcombinatorial pure exploration problems with limited feedback.</description><author>Yuko Kuroki, Junya Honda, Masashi Sugiyama</author><pubDate>Tue, 29 Aug 2023 14:35:42 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2012.15584v2</guid></item><item><title>Large Language Models are Fixated by Red Herrings: Exploring Creative Problem Solving and Einstellung Effect using the Only Connect Wall Dataset</title><link>http://arxiv.org/abs/2306.11167v3</link><description>The quest for human imitative AI has been an enduring topic in AI researchsince its inception. The technical evolution and emerging capabilities of thelatest cohort of large language models (LLMs) have reinvigorated the subjectbeyond academia to the cultural zeitgeist. While recent NLP evaluationbenchmark tasks test some aspects of human-imitative behaviour (e.g.,BIG-bench's 'human-like behavior' tasks), few, if not none, examine creativeproblem solving abilities. Creative problem solving in humans is a well-studiedtopic in cognitive neuroscience with standardized tests that predominantly usethe ability to associate (heterogeneous) connections among clue words as ametric for creativity. Exposure to misleading stimuli - distractors dubbed redherrings - impede human performance in such tasks via the fixation effect andEinstellung paradigm. In cognitive neuroscience studies, such fixations areexperimentally induced by pre-exposing participants to orthographically similarincorrect words to subsequent word-fragments or clues. The popular British quizshow Only Connect's Connecting Wall segment essentially mimics Mednick's RemoteAssociates Test (RAT) formulation with built-in, deliberate red herrings, whichmakes it an ideal proxy dataset to explore and study fixation effect andEinstellung paradigm from cognitive neuroscience in LLMs. In this paper wepresent the novel Only Connect Wall (OCW) dataset and report results from ourevaluation of selected pre-trained language models and LLMs on creative problemsolving tasks like grouping clue words by heterogeneous connections, andidentifying correct open knowledge domain connections in respective groups. Wesynthetically generate two additional datasets: OCW-Randomized, OCW-WordNet tofurther analyze our red-herrings hypothesis in language models. The code andlink to the dataset are available at https://github.com/TaatiTeam/OCW.</description><author>Saeid Naeini, Raeid Saqur, Mozhgan Saeidi, John Giorgi, Babak Taati</author><pubDate>Tue, 29 Aug 2023 14:33:52 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.11167v3</guid></item><item><title>Deep Learning Based Residuals in Non-linear Factor Models: Precision Matrix Estimation of Returns with Low Signal-to-Noise Ratio</title><link>http://arxiv.org/abs/2209.04512v3</link><description>This paper introduces a consistent estimator and rate of convergence for theprecision matrix of asset returns in large portfolios using a non-linear factormodel within the deep learning framework. Our estimator remains valid even inlow signal-to-noise ratio environments typical for financial markets and iscompatible with weak factors. Our theoretical analysis establishes uniformbounds on expected estimation risk based on deep neural networks for anexpanding number of assets. Additionally, we provide a new consistentdata-dependent estimator of error covariance in deep neural networks. Ourmodels demonstrate superior accuracy in extensive simulations and the empirics.</description><author>Mehmet Caner, Maurizio Daniele</author><pubDate>Tue, 29 Aug 2023 14:33:49 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2209.04512v3</guid></item><item><title>Description Logics Go Second-Order -- Extending EL with Universally Quantified Concepts</title><link>http://arxiv.org/abs/2308.08252v2</link><description>The study of Description Logics have been historically mostly focused onfeatures that can be translated to decidable fragments of first-order logic. Inthis paper, we leave this restriction behind and look for useful and decidableextensions outside first-order logic. We introduce universally quantifiedconcepts, which take the form of variables that can be replaced with arbitraryconcepts, and define two semantics of this extension. A schema semantics allowsreplacements of concept variables only by concepts from a particular language,giving us axiom schemata similar to modal logics. A second-order semanticsallows replacement of concept variables with arbitrary subsets of the domain,which is similar to quantified predicates in second-order logic. To study the proposed semantics, we focus on the extension of the descriptionlogic $\mathcal{EL}$. We show that for a useful fragment of the extension, theconclusions entailed by the different semantics coincide, allowing us to useclassical $\mathcal{EL}$ reasoning algorithms even for the second-ordersemantics. For a slightly smaller, but still useful, fragment, we were alsoable to show polynomial decidability of the extension. This fragment, inparticular, can express a generalized form of role chain axioms, positive selfrestrictions, and some forms of (local) role-value-maps from KL-ONE, withoutrequiring any additional constructors.</description><author>Joshua Hirschbrunn, Yevgeny Kazakov</author><pubDate>Tue, 29 Aug 2023 14:32:40 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2308.08252v2</guid></item><item><title>A Hybrid Membership Latent Distance Model for Unsigned and Signed Integer Weighted Networks</title><link>http://arxiv.org/abs/2308.15293v1</link><description>Graph representation learning (GRL) has become a prominent tool forfurthering the understanding of complex networks providing tools for networkembedding, link prediction, and node classification. In this paper, we proposethe Hybrid Membership-Latent Distance Model (HM-LDM) by exploring how a LatentDistance Model (LDM) can be constrained to a latent simplex. By controlling theedge lengths of the corners of the simplex, the volume of the latent space canbe systematically controlled. Thereby communities are revealed as the spacebecomes more constrained, with hard memberships being recovered as the simplexvolume goes to zero. We further explore a recent likelihood formulation forsigned networks utilizing the Skellam distribution to account for signedweighted networks and extend the HM-LDM to the signed Hybrid Membership-LatentDistance Model (sHM-LDM). Importantly, the induced likelihood functionexplicitly attracts nodes with positive links and deters nodes from havingnegative interactions. We demonstrate the utility of HM-LDM and sHM-LDM onseveral real networks. We find that the procedures successfully identifyprominent distinct structures, as well as how nodes relate to the extractedaspects providing favorable performances in terms of link prediction whencompared to prominent baselines. Furthermore, the learned soft membershipsenable easily interpretable network visualizations highlighting distinctpatterns.</description><author>Nikolaos Nakis, Abdulkadir Çelikkanat, Morten Mørup</author><pubDate>Tue, 29 Aug 2023 14:30:48 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2308.15293v1</guid></item><item><title>What's meant by explainable model: A Scoping Review</title><link>http://arxiv.org/abs/2307.09673v3</link><description>We often see the term explainable in the titles of papers that describeapplications based on artificial intelligence (AI). However, the literature inexplainable artificial intelligence (XAI) indicates that explanations in XAIare application- and domain-specific, hence requiring evaluation whenever theyare employed to explain a model that makes decisions for a specific applicationproblem. Additionally, the literature reveals that the performance of post-hocmethods, particularly feature attribution methods, varies substantially hintingthat they do not represent a solution to AI explainability. Therefore, whenusing XAI methods, the quality and suitability of their information outputsshould be evaluated within the specific application. For these reasons, we useda scoping review methodology to investigate papers that apply AI models andadopt methods to generate post-hoc explanations while referring to said modelsas explainable. This paper investigates whether the term explainable model isadopted by authors under the assumption that incorporating a post-hoc XAImethod suffices to characterize a model as explainable. To inspect thisproblem, our review analyzes whether these papers conducted evaluations. Wefound that 81% of the application papers that refer to their approaches as anexplainable model do not conduct any form of evaluation on the XAI method theyused.</description><author>Mallika Mainali, Rosina O Weber</author><pubDate>Tue, 29 Aug 2023 14:30:12 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.09673v3</guid></item><item><title>Towards quantitative precision for ECG analysis: Leveraging state space models, self-supervision and patient metadata</title><link>http://arxiv.org/abs/2308.15291v1</link><description>Deep learning has emerged as the preferred modeling approach for automaticECG analysis. In this study, we investigate three elements aimed at improvingthe quantitative accuracy of such systems. These components consistentlyenhance performance beyond the existing state-of-the-art, which ispredominantly based on convolutional models. Firstly, we explore moreexpressive architectures by exploiting structured state space models (SSMs).These models have shown promise in capturing long-term dependencies in timeseries data. By incorporating SSMs into our approach, we not only achievebetter performance, but also gain insights into long-standing questions in thefield. Specifically, for standard diagnostic tasks, we find no advantage inusing higher sampling rates such as 500Hz compared to 100Hz. Similarly,extending the input size of the model beyond 3 seconds does not lead tosignificant improvements. Secondly, we demonstrate that self-supervisedlearning using contrastive predictive coding can further improve theperformance of SSMs. By leveraging self-supervision, we enable the model tolearn more robust and representative features, leading to improved analysisaccuracy. Lastly, we depart from synthetic benchmarking scenarios andincorporate basic demographic metadata alongside the ECG signal as input. Thisinclusion of patient metadata departs from the conventional practice of relyingsolely on the signal itself. Remarkably, this addition consistently yieldspositive effects on predictive performance. We firmly believe that all threecomponents should be considered when developing next-generation ECG analysisalgorithms.</description><author>Temesgen Mehari, Nils Strodthoff</author><pubDate>Tue, 29 Aug 2023 14:25:26 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2308.15291v1</guid></item><item><title>Unveiling Gender Bias in Terms of Profession Across LLMs: Analyzing and Addressing Sociological Implications</title><link>http://arxiv.org/abs/2307.09162v2</link><description>Gender bias in artificial intelligence (AI) and natural language processinghas garnered significant attention due to its potential impact on societalperceptions and biases. This research paper aims to analyze gender bias inLarge Language Models (LLMs) with a focus on multiple comparisons between GPT-2and GPT-3.5, some prominent language models, to better understand itsimplications. Through a comprehensive literature review, the study examinesexisting research on gender bias in AI language models and identifies gaps inthe current knowledge. The methodology involves collecting and preprocessingdata from GPT-2 and GPT-3.5, and employing in-depth quantitative analysistechniques to evaluate gender bias in the generated text. The findings shedlight on gendered word associations, language usage, and biased narrativespresent in the outputs of these Large Language Models. The discussion exploresthe ethical implications of gender bias and its potential consequences onsocial perceptions and marginalized communities. Additionally, the paperpresents strategies for reducing gender bias in LLMs, including algorithmicapproaches and data augmentation techniques. The research highlights theimportance of interdisciplinary collaborations and the role of sociologicalstudies in mitigating gender bias in AI models. By addressing these issues, wecan pave the way for more inclusive and unbiased AI systems that have apositive impact on society.</description><author>Vishesh Thakur</author><pubDate>Tue, 29 Aug 2023 14:15:24 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.09162v2</guid></item><item><title>ARTxAI: Explainable Artificial Intelligence Curates Deep Representation Learning for Artistic Images using Fuzzy Techniques</title><link>http://arxiv.org/abs/2308.15284v1</link><description>Automatic art analysis employs different image processing techniques toclassify and categorize works of art. When working with artistic images, weneed to take into account further considerations compared to classical imageprocessing. This is because such artistic paintings change drasticallydepending on the author, the scene depicted, and their artistic style. This canresult in features that perform very well in a given task but do not grasp thewhole of the visual and symbolic information contained in a painting. In thispaper, we show how the features obtained from different tasks in artistic imageclassification are suitable to solve other ones of similar nature. We presentdifferent methods to improve the generalization capabilities and performance ofartistic classification systems. Furthermore, we propose an explainableartificial intelligence method to map known visual traits of an image with thefeatures used by the deep learning model considering fuzzy rules. These rulesshow the patterns and variables that are relevant to solve each task and howeffective is each of the patterns found. Our results show that our proposedcontext-aware features can achieve up to $6\%$ and $26\%$ more accurate resultsthan other context- and non-context-aware solutions, respectively, depending onthe specific task. We also show that some of the features used by these modelscan be more clearly correlated to visual traits in the original image thanothers.</description><author>Javier Fumanal-Idocin, Javier Andreu-Perez, Oscar Cordón, Hani Hagras, Humberto Bustince</author><pubDate>Tue, 29 Aug 2023 14:15:13 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2308.15284v1</guid></item><item><title>Structural Node Embeddings with Homomorphism Counts</title><link>http://arxiv.org/abs/2308.15283v1</link><description>Graph homomorphism counts, first explored by Lov\'asz in 1967, have recentlygarnered interest as a powerful tool in graph-based machine learning. Grohe(PODS 2020) proposed the theoretical foundations for using homomorphism countsin machine learning on graph level as well as node level tasks. By their verynature, these capture local structural information, which enables the creationof robust structural embeddings. While a first approach for graph level taskshas been made by Nguyen and Maehara (ICML 2020), we experimentally show theeffectiveness of homomorphism count based node embeddings. Enriched with nodelabels, node weights, and edge weights, these offer an interpretablerepresentation of graph data, allowing for enhanced explainability of machinelearning models. We propose a theoretical framework for isomorphism-invariant homomorphismcount based embeddings which lend themselves to a wide variety of downstreamtasks. Our approach capitalises on the efficient computability of graphhomomorphism counts for bounded treewidth graph classes, rendering it apractical solution for real-world applications. We demonstrate theirexpressivity through experiments on benchmark datasets. Although our results donot match the accuracy of state-of-the-art neural architectures, they arecomparable to other advanced graph learning models. Remarkably, our approachdemarcates itself by ensuring explainability for each individual feature. Byintegrating interpretable machine learning algorithms like SVMs or RandomForests, we establish a seamless, end-to-end explainable pipeline. Our studycontributes to the advancement of graph-based techniques that offer bothperformance and interpretability.</description><author>Hinrikus Wolf, Luca Oeljeklaus, Pascal Kühner, Martin Grohe</author><pubDate>Tue, 29 Aug 2023 14:14:53 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2308.15283v1</guid></item><item><title>TeViS:Translating Text Synopses to Video Storyboards</title><link>http://arxiv.org/abs/2301.00135v4</link><description>A video storyboard is a roadmap for video creation which consists ofshot-by-shot images to visualize key plots in a text synopsis. Creating videostoryboards, however, remains challenging which not only requires cross-modalassociation between high-level texts and images but also demands long-termreasoning to make transitions smooth across shots. In this paper, we propose anew task called Text synopsis to Video Storyboard (TeViS) which aims toretrieve an ordered sequence of images as the video storyboard to visualize thetext synopsis. We construct a MovieNet-TeViS dataset based on the publicMovieNet dataset. It contains 10K text synopses each paired with keyframesmanually selected from corresponding movies by considering both relevance andcinematic coherence. To benchmark the task, we present strong CLIP-basedbaselines and a novel VQ-Trans. VQ-Trans first encodes text synopsis and imagesinto a joint embedding space and uses vector quantization (VQ) to improve thevisual representation. Then, it auto-regressively generates a sequence ofvisual features for retrieval and ordering. Experimental results demonstratethat VQ-Trans significantly outperforms prior methods and the CLIP-basedbaselines. Nevertheless, there is still a large gap compared to humanperformance suggesting room for promising future work. The code and data areavailable at: \url{https://ruc-aimind.github.io/projects/TeViS/}</description><author>Xu Gu, Yuchong Sun, Feiyue Ni, Shizhe Chen, Xihua Wang, Ruihua Song, Boyuan Li, Xiang Cao</author><pubDate>Tue, 29 Aug 2023 14:10:56 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2301.00135v4</guid></item><item><title>ADFA: Attention-augmented Differentiable top-k Feature Adaptation for Unsupervised Medical Anomaly Detection</title><link>http://arxiv.org/abs/2308.15280v1</link><description>The scarcity of annotated data, particularly for rare diseases, limits thevariability of training data and the range of detectable lesions, presenting asignificant challenge for supervised anomaly detection in medical imaging. Tosolve this problem, we propose a novel unsupervised method for medical imageanomaly detection: Attention-Augmented Differentiable top-k Feature Adaptation(ADFA). The method utilizes Wide-ResNet50-2 (WR50) network pre-trained onImageNet to extract initial feature representations. To reduce the channeldimensionality while preserving relevant channel information, we employ anattention-augmented patch descriptor on the extracted features. We then applydifferentiable top-k feature adaptation to train the patch descriptor, mappingthe extracted feature representations to a new vector space, enabling effectivedetection of anomalies. Experiments show that ADFA outperforms state-of-the-art(SOTA) methods on multiple challenging medical image datasets, confirming itseffectiveness in medical anomaly detection.</description><author>Yiming Huang, Guole Liu, Yaoru Luo, Ge Yang</author><pubDate>Tue, 29 Aug 2023 14:10:53 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2308.15280v1</guid></item><item><title>Cross-Modal Retrieval Meets Inference:Improving Zero-Shot Classification with Cross-Modal Retrieval</title><link>http://arxiv.org/abs/2308.15273v1</link><description>Contrastive language-image pre-training (CLIP) has demonstrated remarkablezero-shot classification ability, namely image classification using novel textlabels. Existing works have attempted to enhance CLIP by fine-tuning ondownstream tasks, but these have inadvertently led to performance degradationon unseen classes, thus harming zero-shot generalization. This paper aims toaddress this challenge by leveraging readily available image-text pairs from anexternal dataset for cross-modal guidance during inference. To this end, wepropose X-MoRe, a novel inference method comprising two key steps: (1)cross-modal retrieval and (2) modal-confidence-based ensemble. Given a queryimage, we harness the power of CLIP's cross-modal representations to retrieverelevant textual information from an external image-text pair dataset. Then, weassign higher weights to the more reliable modality between the original queryimage and retrieved text, contributing to the final prediction. X-MoRedemonstrates robust performance across a diverse set of tasks without the needfor additional training, showcasing the effectiveness of utilizing cross-modalfeatures to maximize CLIP's zero-shot ability.</description><author>Seongha Eom, Namgyu Ho, Jaehoon Oh, Se-Young Yun</author><pubDate>Tue, 29 Aug 2023 14:02:35 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2308.15273v1</guid></item><item><title>Empowering LLM to use Smartphone for Intelligent Task Automation</title><link>http://arxiv.org/abs/2308.15272v1</link><description>Mobile task automation is an attractive technique that aims to enablevoice-based hands-free user interaction with smartphones. However, existingapproaches suffer from poor scalability due to the limited languageunderstanding ability and the non-trivial manual efforts required fromdevelopers or end-users. The recent advance of large language models (LLMs) inlanguage understanding and reasoning inspires us to rethink the problem from amodel-centric perspective, where task preparation, comprehension, and executionare handled by a unified language model. In this work, we introduce AutoDroid,a mobile task automation system that can handle arbitrary tasks on any Androidapplication without manual efforts. The key insight is to combine thecommonsense knowledge of LLMs and domain-specific knowledge of apps throughautomated dynamic analysis. The main components include a functionality-awareUI representation method that bridges the UI with the LLM, exploration-basedmemory injection techniques that augment the app-specific domain knowledge ofLLM, and a multi-granularity query optimization module that reduces the cost ofmodel inference. We integrate AutoDroid with off-the-shelf LLMs includingonline GPT-4/GPT-3.5 and on-device Vicuna, and evaluate its performance on anew benchmark for memory-augmented Android task automation with 158 commontasks. The results demonstrated that AutoDroid is able to precisely generateactions with an accuracy of 90.9%, and complete tasks with a success rate of71.3%, outperforming the GPT-4-powered baselines by 36.4% and 39.7%. The demo,benchmark suites, and source code of AutoDroid will be released athttps://autodroid-sys.github.io/.</description><author>Hao Wen, Yuanchun Li, Guohong Liu, Shanhui Zhao, Tao Yu, Toby Jia-Jun Li, Shiqi Jiang, Yunhao Liu, Yaqin Zhang, Yunxin Liu</author><pubDate>Tue, 29 Aug 2023 14:02:30 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2308.15272v1</guid></item><item><title>Atlas-Based Interpretable Age Prediction In Whole-Body MR Images</title><link>http://arxiv.org/abs/2307.07439v2</link><description>Age prediction is an important part of medical assessments and research. Itcan aid in detecting diseases as well as abnormal ageing by highlighting thediscrepancy between chronological and biological age. To gain a comprehensiveunderstanding of age-related changes observed in various body parts, weinvestigate them on a larger scale by using whole-body images. We utilise theGrad-CAM interpretability method to determine the body areas most predictive ofa person's age. We expand our analysis beyond individual subjects by employingregistration techniques to generate population-wide interpretability maps.Furthermore, we set state-of-the-art whole-body age prediction with a modelthat achieves a mean absolute error of 2.76 years. Our findings reveal threeprimary areas of interest: the spine, the autochthonous back muscles, and thecardiac region, which exhibits the highest importance.</description><author>Sophie Starck, Yadunandan Vivekanand Kini, Jessica Johanna Maria Ritter, Rickmer Braren, Daniel Rueckert, Tamara Mueller</author><pubDate>Tue, 29 Aug 2023 13:57:17 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.07439v2</guid></item><item><title>NOVIS: A Case for End-to-End Near-Online Video Instance Segmentation</title><link>http://arxiv.org/abs/2308.15266v1</link><description>Until recently, the Video Instance Segmentation (VIS) community operatedunder the common belief that offline methods are generally superior to a frameby frame online processing. However, the recent success of online methodsquestions this belief, in particular, for challenging and long video sequences.We understand this work as a rebuttal of those recent observations and anappeal to the community to focus on dedicated near-online VIS approaches. Tosupport our argument, we present a detailed analysis on different processingparadigms and the new end-to-end trainable NOVIS (Near-Online Video InstanceSegmentation) method. Our transformer-based model directly predictsspatio-temporal mask volumes for clips of frames and performs instance trackingbetween clips via overlap embeddings. NOVIS represents the first near-onlineVIS approach which avoids any handcrafted tracking heuristics. We outperformall existing VIS methods by large margins and provide new state-of-the-artresults on both YouTube-VIS (2019/2021) and the OVIS benchmarks.</description><author>Tim Meinhardt, Matt Feiszli, Yuchen Fan, Laura Leal-Taixe, Rakesh Ranjan</author><pubDate>Tue, 29 Aug 2023 13:51:04 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2308.15266v1</guid></item><item><title>Generalized partitioned local depth</title><link>http://arxiv.org/abs/2303.10167v3</link><description>In this paper we provide a generalization of the concept of cohesion asintroduced recently by Berenhaut, Moore and Melvin [Proceedings of the NationalAcademy of Sciences, 119 (4) (2022)]. The formulation presented builds on thetechnique of partitioned local depth by distilling two key probabilisticconcepts: local relevance and support division. Earlier results are extendedwithin the new context, and examples of applications to revealing communitiesin data with uncertainty are included. The work sheds light on the foundationsof partitioned local depth, and extends the original ideas to enableprobabilistic consideration of uncertain, variable and potentially conflictinginformation.</description><author>Kenneth S. Berenhaut, John D. Foley, Liangdongsheng Lyu</author><pubDate>Tue, 29 Aug 2023 13:49:55 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2303.10167v3</guid></item><item><title>Unified and Dynamic Graph for Temporal Character Grouping in Long Videos</title><link>http://arxiv.org/abs/2308.14105v2</link><description>Video temporal character grouping locates appearing moments of majorcharacters within a video according to their identities. To this end, recentworks have evolved from unsupervised clustering to graph-based supervisedclustering. However, graph methods are built upon the premise of fixed affinitygraphs, bringing many inexact connections. Besides, they extract multi-modalfeatures with kinds of models, which are unfriendly to deployment. In thispaper, we present a unified and dynamic graph (UniDG) framework for temporalcharacter grouping. This is accomplished firstly by a unified representationnetwork that learns representations of multiple modalities within the samespace and still preserves the modality's uniqueness simultaneously. Secondly,we present a dynamic graph clustering where the neighbors of differentquantities are dynamically constructed for each node via a cyclic matchingstrategy, leading to a more reliable affinity graph. Thirdly, a progressiveassociation method is introduced to exploit spatial and temporal contexts amongdifferent modalities, allowing multi-modal clustering results to be well fused.As current datasets only provide pre-extracted features, we evaluate our UniDGmethod on a collected dataset named MTCG, which contains each character'sappearing clips of face and body and speaking voice tracks. We also evaluateour key components on existing clustering and retrieval datasets to verify thegeneralization ability. Experimental results manifest that our method canachieve promising results and outperform several state-of-the-art approaches.</description><author>Xiujun Shu, Wei Wen, Liangsheng Xu, Mingbao Lin, Ruizhi Qiao, Taian Guo, Hanjun Li, Bei Gan, Xiao Wang, Xing Sun</author><pubDate>Tue, 29 Aug 2023 13:43:53 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2308.14105v2</guid></item></channel></rss>