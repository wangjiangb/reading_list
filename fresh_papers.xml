<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/"><channel><title>Arxivfresh papers</title><link></link><description>Arxiv paper</description><language>en-US</language><lastBuildDate>Mon, 05 Feb 2024 14:00:05 GMT</lastBuildDate><generator>rfeed v1.0.0</generator><docs>https://github.com/svpino/rfeed/blob/master/README.md</docs><item><title>kNN Algorithm for Conditional Mean and Variance Estimation with Automated Uncertainty Quantification and Variable Selection</title><link>http://arxiv.org/abs/2402.01635v1</link><description>In this paper, we introduce a kNN-based regression method that synergizes thescalability and adaptability of traditional non-parametric kNN models with anovel variable selection technique. This method focuses on accuratelyestimating the conditional mean and variance of random response variables,thereby effectively characterizing conditional distributions across diversescenarios.Our approach incorporates a robust uncertainty quantificationmechanism, leveraging our prior estimation work on conditional mean andvariance. The employment of kNN ensures scalable computational efficiency inpredicting intervals and statistical accuracy in line with optimalnon-parametric rates. Additionally, we introduce a new kNN semi-parametricalgorithm for estimating ROC curves, accounting for covariates. For selectingthe smoothing parameter k, we propose an algorithm with theoreticalguarantees.Incorporation of variable selection enhances the performance of themethod significantly over conventional kNN techniques in various modelingtasks. We validate the approach through simulations in low, moderate, andhigh-dimensional covariate spaces. The algorithm's effectiveness isparticularly notable in biomedical applications as demonstrated in two casestudies. Concluding with a theoretical analysis, we highlight the consistencyand convergence rate of our method over traditional kNN models, particularlywhen the underlying regression model takes values in a low-dimensional space.</description><author>Marcos Matabuena, Juan C. Vidal, Oscar Hernan Madrid Padilla, Jukka-Pekka Onnela</author><pubDate>Fri, 02 Feb 2024 18:54:18 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.01635v1</guid></item><item><title>Inversion by Direct Iteration: An Alternative to Denoising Diffusion for Image Restoration</title><link>http://arxiv.org/abs/2303.11435v5</link><description>Inversion by Direct Iteration (InDI) is a new formulation for supervisedimage restoration that avoids the so-called "regression to the mean" effect andproduces more realistic and detailed images than existing regression-basedmethods. It does this by gradually improving image quality in small steps,similar to generative denoising diffusion models. Image restoration is anill-posed problem where multiple high-quality images are plausiblereconstructions of a given low-quality input. Therefore, the outcome of asingle step regression model is typically an aggregate of all possibleexplanations, therefore lacking details and realism. The main advantage of InDIis that it does not try to predict the clean target image in a single step butinstead gradually improves the image in small steps, resulting in betterperceptual quality. While generative denoising diffusion models also work insmall steps, our formulation is distinct in that it does not require knowledgeof any analytic form of the degradation process. Instead, we directly learn aniterative restoration process from low-quality and high-quality pairedexamples. InDI can be applied to virtually any image degradation, given pairedtraining data. In conditional denoising diffusion image restoration thedenoising network generates the restored image by repeatedly denoising aninitial image of pure noise, conditioned on the degraded input. Contrary toconditional denoising formulations, InDI directly proceeds by iterativelyrestoring the input low-quality image, producing high-quality results on avariety of image restoration tasks, including motion and out-of-focusdeblurring, super-resolution, compression artifact removal, and denoising.</description><author>Mauricio Delbracio, Peyman Milanfar</author><pubDate>Fri, 02 Feb 2024 18:52:51 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2303.11435v5</guid></item><item><title>Beyond Lengthscales: No-regret Bayesian Optimisation With Unknown Hyperparameters Of Any Type</title><link>http://arxiv.org/abs/2402.01632v1</link><description>Bayesian optimisation requires fitting a Gaussian process model, which inturn requires specifying hyperparameters - most of the theoretical literatureassumes those hyperparameters are known. The commonly used maximum likelihoodestimator for hyperparameters of the Gaussian process is consistent only if thedata fills the space uniformly, which does not have to be the case in Bayesianoptimisation. Since no guarantees exist regarding the correctness ofhyperparameter estimation, and those hyperparameters can significantly affectthe Gaussian process fit, theoretical analysis of Bayesian optimisation withunknown hyperparameters is very challenging. Previously proposed algorithmswith the no-regret property were only able to handle the special case ofunknown lengthscales, reproducing kernel Hilbert space norm and applied only tothe frequentist case. We propose a novel algorithm, HE-GP-UCB, which is thefirst algorithm enjoying the no-regret property in the case of unknownhyperparameters of arbitrary form, and which supports both Bayesian andfrequentist settings. Our proof idea is novel and can easily be extended toother variants of Bayesian optimisation. We show this by extending ouralgorithm to the adversarially robust optimisation setting under unknownhyperparameters. Finally, we empirically evaluate our algorithm on a set of toyproblems and show that it can outperform the maximum likelihood estimator.</description><author>Juliusz Ziomek, Masaki Adachi, Michael A. Osborne</author><pubDate>Fri, 02 Feb 2024 18:52:16 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.01632v1</guid></item><item><title>Position Paper: Generalized grammar rules and structure-based generalization beyond classical equivariance for lexical tasks and transduction</title><link>http://arxiv.org/abs/2402.01629v1</link><description>Compositional generalization is one of the main properties whichdifferentiates lexical learning in humans from state-of-art neural networks. Wepropose a general framework for building models that can generalizecompositionally using the concept of Generalized Grammar Rules (GGRs), a classof symmetry-based compositional constraints for transduction tasks, which weview as a transduction analogue of equivariance constraints in physics-inspiredtasks. Besides formalizing generalized notions of symmetry for languagetransduction, our framework is general enough to contain many existing works asspecial cases. We present ideas on how GGRs might be implemented, and in theprocess draw connections to reinforcement learning and other areas of research.</description><author>Mircea Petrache, Shubhendu Trivedi</author><pubDate>Fri, 02 Feb 2024 18:44:37 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.01629v1</guid></item><item><title>TravelPlanner: A Benchmark for Real-World Planning with Language Agents</title><link>http://arxiv.org/abs/2402.01622v1</link><description>Planning has been part of the core pursuit for artificial intelligence sinceits conception, but earlier AI agents mostly focused on constrained settingsbecause many of the cognitive substrates necessary for human-level planninghave been lacking. Recently, language agents powered by large language models(LLMs) have shown interesting capabilities such as tool use and reasoning. Arethese language agents capable of planning in more complex settings that are outof the reach of prior AI agents? To advance this investigation, we proposeTravelPlanner, a new planning benchmark that focuses on travel planning, acommon real-world planning scenario. It provides a rich sandbox environment,various tools for accessing nearly four million data records, and 1,225meticulously curated planning intents and reference plans. Comprehensiveevaluations show that the current language agents are not yet capable ofhandling such complex planning tasks-even GPT-4 only achieves a success rate of0.6%. Language agents struggle to stay on task, use the right tools to collectinformation, or keep track of multiple constraints. However, we note that themere possibility for language agents to tackle such a complex problem is initself non-trivial progress. TravelPlanner provides a challenging yetmeaningful testbed for future language agents.</description><author>Jian Xie, Kai Zhang, Jiangjie Chen, Tinghui Zhu, Renze Lou, Yuandong Tian, Yanghua Xiao, Yu Su</author><pubDate>Fri, 02 Feb 2024 18:39:51 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.01622v1</guid></item><item><title>Stochastic Two Points Method for Deep Model Zeroth-order Optimization</title><link>http://arxiv.org/abs/2402.01621v1</link><description>Large foundation models, such as large language models, have performedexceptionally well in various application scenarios. Building or fullyfine-tuning such large models is usually prohibitive due to either hardwarebudget or lack of access to backpropagation. The zeroth-order methods offer apromising direction for tackling this challenge, where only forward passes areneeded to update the model. This paper introduces an efficient StochasticTwo-Point (S2P) approach within the gradient-free regime. We present thetheoretical convergence properties of S2P under the general and relaxedsmoothness assumptions. The theoretical properties also shed light on a fasterand more stable S2P variant, Accelerated S2P (AS2P), through exploiting our newconvergence properties that better represent the dynamics of deep models intraining. Our comprehensive empirical results show that AS2P is highlyeffective in optimizing objectives for large deep models, including languagemodels, and outperforms standard methods across various model types and scales,with 2 $\times$ speed-up in training over most conducted tasks.</description><author>Yijiang Pang, Jiayu Zhou</author><pubDate>Fri, 02 Feb 2024 18:39:40 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.01621v1</guid></item><item><title>Two Failures of Self-Consistency in the Multi-Step Reasoning of LLMs</title><link>http://arxiv.org/abs/2305.14279v4</link><description>Large language models (LLMs) have achieved widespread success on a variety ofin-context few-shot tasks, but this success is typically evaluated viacorrectness rather than consistency. We argue that self-consistency is animportant criteria for valid multi-step reasoning in tasks where the solutionis composed of the answers to multiple sub-steps. We propose two types ofself-consistency that are particularly important for multi-step reasoning --hypothetical consistency (a model's ability to predict what its output would bein a hypothetical other context) and compositional consistency (consistency ofa model's final outputs when intermediate sub-steps are replaced with themodel's outputs for those steps). We demonstrate that multiple variants of theGPT-3/-4 models exhibit poor consistency rates across both types of consistencyon a variety of tasks.</description><author>Angelica Chen, Jason Phang, Alicia Parrish, Vishakh Padmakumar, Chen Zhao, Samuel R. Bowman, Kyunghyun Cho</author><pubDate>Fri, 02 Feb 2024 18:37:07 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.14279v4</guid></item><item><title>MAGDi: Structured Distillation of Multi-Agent Interaction Graphs Improves Reasoning in Smaller Language Models</title><link>http://arxiv.org/abs/2402.01620v1</link><description>Multi-agent interactions between Large Language Model (LLM) agents have shownmajor improvements on diverse reasoning tasks. However, these involve longgenerations from multiple models across several rounds, making them expensive.Moreover, these multi-agent approaches fail to provide a final, single modelfor efficient inference. To address this, we introduce MAGDi, a new method forstructured distillation of the reasoning interactions between multiple LLMsinto smaller LMs. MAGDi teaches smaller models by representing multi-agentinteractions as graphs, augmenting a base student model with a graph encoder,and distilling knowledge using three objective functions: next-tokenprediction, a contrastive loss between correct and incorrect reasoning, and agraph-based objective to model the interaction structure. Experiments on sevenwidely-used commonsense and math reasoning benchmarks show that MAGDi improvesthe reasoning capabilities of smaller models, outperforming several methodsthat distill from a single teacher and multiple teachers. Moreover, MAGDi alsodemonstrates an order of magnitude higher efficiency over its teachers. Weconduct extensive analyses to show that MAGDi (1) enhances the generalizabilityto out-of-domain tasks, (2) scales positively with the size and strength of thebase student model, and (3) obtains larger improvements (via our multi-teachertraining) when applying self-consistency - an inference technique that relieson model diversity.</description><author>Justin Chih-Yao Chen, Swarnadeep Saha, Elias Stengel-Eskin, Mohit Bansal</author><pubDate>Fri, 02 Feb 2024 18:35:14 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.01620v1</guid></item><item><title>Nonlinear Filtering with Brenier Optimal Transport Maps</title><link>http://arxiv.org/abs/2310.13886v2</link><description>This paper is concerned with the problem of nonlinear filtering, i.e.,computing the conditional distribution of the state of a stochastic dynamicalsystem given a history of noisy partial observations. Conventional sequentialimportance resampling (SIR) particle filters suffer from fundamentallimitations, in scenarios involving degenerate likelihoods or high-dimensionalstates, due to the weight degeneracy issue. In this paper, we explore analternative method, which is based on estimating the Brenier optimal transport(OT) map from the current prior distribution of the state to the posteriordistribution at the next time step. Unlike SIR particle filters, the OTformulation does not require the analytical form of the likelihood. Moreover,it allows us to harness the approximation power of neural networks to modelcomplex and multi-modal distributions and employ stochastic optimizationalgorithms to enhance scalability. Extensive numerical experiments arepresented that compare the OT method to the SIR particle filter and theensemble Kalman filter, evaluating the performance in terms of sampleefficiency, high-dimensional scalability, and the ability to capture complexand multi-modal distributions.</description><author>Mohammad Al-Jarrah, Niyizhen Jin, Bamdad Hosseini, Amirhossein Taghvaei</author><pubDate>Fri, 02 Feb 2024 18:35:11 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.13886v2</guid></item><item><title>New Online Communities: Graph Deep Learning on Anonymous Voting Networks to Identify Sybils in Polycentric Governance</title><link>http://arxiv.org/abs/2311.17929v5</link><description>This research examines the polycentric governance of digital assets inblockchain-based Decentralized Autonomous Organizations (DAOs). It offers atheoretical framework and addresses a critical challenge facing decentralizedgovernance by developing a method to identify sybils, or spurious identities.Sybils pose significant organizational sustainability threats to DAOs andother, commons-based online communities, and threat models are identified. Theexperimental method uses graph deep learning techniques to identify sybilactivity in a DAO governance dataset (snapshot.org). Specifically, a GraphConvolutional Neural Network (GCNN) learned voting behaviours and a fastk-means vector clustering algorithm (FAISS) used high-dimensional embeddings toidentify similar nodes in a graph. The results reveal that deep learning caneffectively identify sybils, reducing the voting graph by 2-5%. This researchunderscores the importance of sybil resistance in DAOs and offers a novelperspective on decentralized governance, informing future policy, regulation,and governance practices.</description><author>Quinn DuPont</author><pubDate>Fri, 02 Feb 2024 18:33:43 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.17929v5</guid></item><item><title>KB-Plugin: A Plug-and-play Framework for Large Language Models to Induce Programs over Low-resourced Knowledge Bases</title><link>http://arxiv.org/abs/2402.01619v1</link><description>Program induction (PI) has become a promising paradigm for using knowledgebases (KBs) to help large language models (LLMs) answer complexknowledge-intensive questions. Nonetheless, PI typically relies on a largenumber of parallel question-program pairs to make the LLM aware of the schemaof the given KB, and is thus challenging for many low-resourced KBs that lackannotated data. To this end, we propose KB-Plugin, a plug-and-play frameworkthat enables LLMs to induce programs over any low-resourced KB. Firstly,KB-Plugin adopts self-supervised learning to encode the detailed schemainformation of a given KB into a pluggable module, namely schema plugin.Secondly, KB-Plugin utilizes abundant annotated data from a rich-resourced KBto train another pluggable module, namely PI plugin, which can help the LLMextract question-relevant schema information from the schema plugin of any KBand utilize this information to induce programs over this KB. Experiments onfive heterogeneous KBQA datasets show that KB-Plugin achieves better orcomparable performance with 25$\times$ smaller backbone LLM compared to SoTA PImethods for low-resourced KBs, and even approaches the performance ofsupervised methods. Our code and data are available athttps://github.com/THU-KEG/KB-Plugin.</description><author>Jiajie Zhang, Shulin Cao, Linmei Hu, Ling Feng, Lei Hou, Juanzi Li</author><pubDate>Fri, 02 Feb 2024 18:32:24 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.01619v1</guid></item><item><title>STELLA: Continual Audio-Video Pre-training with Spatio-Temporal Localized Alignment</title><link>http://arxiv.org/abs/2310.08204v2</link><description>Continuously learning a variety of audio-video semantics over time is crucialfor audio-related reasoning tasks in our ever-evolving world. However, this isa nontrivial problem and poses two critical challenges: sparse spatio-temporalcorrelation between audio-video pairs and multimodal correlation overwritingthat forgets audio-video relations. To tackle this problem, we propose a newcontinual audio-video pre-training method with two novel ideas: (1) LocalizedPatch Importance Scoring: we introduce a multimodal encoder to determine theimportance score for each patch, emphasizing semantically intertwinedaudio-video patches. (2) Replay-guided Correlation Assessment: to reduce thecorruption of previously learned audiovisual knowledge due to drift, we proposeto assess the correlation of the current patches on the past steps to identifythe patches exhibiting high correlations with the past steps. Based on theresults from the two ideas, we perform probabilistic patch selection foreffective continual audio-video pre-training. Experimental validation onmultiple benchmarks shows that our method achieves a 3.69%p of relativeperformance gain in zero-shot retrieval tasks compared to strong continuallearning baselines, while reducing memory consumption by ~45%.</description><author>Jaewoo Lee, Jaehong Yoon, Wonjae Kim, Yunji Kim, Sung Ju Hwang</author><pubDate>Fri, 02 Feb 2024 18:31:52 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.08204v2</guid></item><item><title>Is Self-Repair a Silver Bullet for Code Generation?</title><link>http://arxiv.org/abs/2306.09896v5</link><description>Large language models have shown remarkable aptitude in code generation, butstill struggle to perform complex tasks. Self-repair -- in which the modeldebugs and repairs its own code -- has recently become a popular way to boostperformance in these settings. However, despite its increasing popularity,existing studies of self-repair have been limited in scope; in many settings,its efficacy thus remains poorly understood. In this paper, we analyze CodeLlama, GPT-3.5 and GPT-4's ability to perform self-repair on problems takenfrom HumanEval and APPS. We find that when the cost of carrying out repair istaken into account, performance gains are often modest, vary a lot betweensubsets of the data, and are sometimes not present at all. We hypothesize thatthis is because self-repair is bottlenecked by the model's ability to providefeedback on its own code; using a stronger model to artificially boost thequality of the feedback, we observe substantially larger performance gains.Similarly, a small-scale study in which we provide GPT-4 with feedback fromhuman participants suggests that even for the strongest models, self-repairstill lags far behind what can be achieved with human-level debugging.</description><author>Theo X. Olausson, Jeevana Priya Inala, Chenglong Wang, Jianfeng Gao, Armando Solar-Lezama</author><pubDate>Fri, 02 Feb 2024 18:31:34 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.09896v5</guid></item><item><title>The Benefits of Being Categorical Distributional: Uncertainty-aware Regularized Exploration in Reinforcement Learning</title><link>http://arxiv.org/abs/2110.03155v5</link><description>The theoretical advantages of distributional reinforcement learning~(RL) overclassical RL remain elusive despite its remarkable empirical performance.Starting from Categorical Distributional RL~(CDRL), we attribute the potentialsuperiority of distributional RL to a derived distribution-matchingregularization by applying a return density function decomposition technique.This unexplored regularization in the distributional RL context is aimed atcapturing additional return distribution information regardless of only itsexpectation, contributing to an augmented reward signal in the policyoptimization. Compared with the entropy regularization in MaxEnt RL thatexplicitly optimizes the policy to encourage the exploration, the resultingregularization in CDRL implicitly optimizes policies guided by the new rewardsignal to align with the uncertainty of target return distributions, leading toan uncertainty-aware exploration effect. Finally, extensive experimentssubstantiate the importance of this uncertainty-aware regularization indistributional RL on the empirical benefits over classical RL.</description><author>Ke Sun, Yingnan Zhao, Enze Shi, Yafei Wang, Xiaodong Yan, Bei Jiang, Linglong Kong</author><pubDate>Fri, 02 Feb 2024 18:31:23 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2110.03155v5</guid></item><item><title>Style Vectors for Steering Generative Large Language Model</title><link>http://arxiv.org/abs/2402.01618v1</link><description>This research explores strategies for steering the output of large languagemodels (LLMs) towards specific styles, such as sentiment, emotion, or writingstyle, by adding style vectors to the activations of hidden layers during textgeneration. We show that style vectors can be simply computed from recordedlayer activations for input texts in a specific style in contrast to morecomplex training-based approaches. Through a series of experiments, wedemonstrate the effectiveness of activation engineering using such stylevectors to influence the style of generated text in a nuanced andparameterisable way, distinguishing it from prompt engineering. The presentedresearch constitutes a significant step towards developing more adaptive andeffective AI-empowered interactive systems.</description><author>Kai Konen, Sophie Jentzsch, Diaoulé Diallo, Peer Schütt, Oliver Bensch, Roxanne El Baff, Dominik Opitz, Tobias Hecking</author><pubDate>Fri, 02 Feb 2024 18:31:15 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.01618v1</guid></item><item><title>A GP-based Robust Motion Planning Framework for Agile Autonomous Robot Navigation and Recovery in Unknown Environments</title><link>http://arxiv.org/abs/2402.01617v1</link><description>For autonomous mobile robots, uncertainties in the environment and systemmodel can lead to failure in the motion planning pipeline, resulting inpotential collisions. In order to achieve a high level of robust autonomy,these robots should be able to proactively predict and recover from suchfailures. To this end, we propose a Gaussian Process (GP) based model forproactively detecting the risk of future motion planning failure. When thisrisk exceeds a certain threshold, a recovery behavior is triggered thatleverages the same GP model to find a safe state from which the robot maycontinue towards the goal. The proposed approach is trained in simulation onlyand can generalize to real world environments on different robotic platforms.Simulations and physical experiments demonstrate that our framework is capableof both predicting planner failures and recovering the robot to states whereplanner success is likely, all while producing agile motion.</description><author>Nicholas Mohammad, Jacob Higgins, Nicola Bezzo</author><pubDate>Fri, 02 Feb 2024 18:27:21 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.01617v1</guid></item><item><title>L2G2G: a Scalable Local-to-Global Network Embedding with Graph Autoencoders</title><link>http://arxiv.org/abs/2402.01614v1</link><description>For analysing real-world networks, graph representation learning is a populartool. These methods, such as a graph autoencoder (GAE), typically rely onlow-dimensional representations, also called embeddings, which are obtainedthrough minimising a loss function; these embeddings are used with a decoderfor downstream tasks such as node classification and edge prediction. WhileGAEs tend to be fairly accurate, they suffer from scalability issues. Forimproved speed, a Local2Global approach, which combines graph patch embeddingsbased on eigenvector synchronisation, was shown to be fast and achieve goodaccuracy. Here we propose L2G2G, a Local2Global method which improves GAEaccuracy without sacrificing scalability. This improvement is achieved bydynamically synchronising the latent node representations, while training theGAEs. It also benefits from the decoder computing an only local patch loss.Hence, aligning the local embeddings in each epoch utilises more informationfrom the graph than a single post-training alignment does, while maintainingscalability. We illustrate on synthetic benchmarks, as well as real-worldexamples, that L2G2G achieves higher accuracy than the standard Local2Globalapproach and scales efficiently on the larger data sets. We find that for largeand dense networks, it even outperforms the slow, but assumed more accurate,GAEs.</description><author>Ruikang Ouyang, Andrew Elliott, Stratis Limnios, Mihai Cucuringu, Gesine Reinert</author><pubDate>Fri, 02 Feb 2024 18:24:37 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.01614v1</guid></item><item><title>Nomic Embed: Training a Reproducible Long Context Text Embedder</title><link>http://arxiv.org/abs/2402.01613v1</link><description>This technical report describes the training of nomic-embed-text-v1, thefirst fully reproducible, open-source, open-weights, open-data, 8192 contextlength English text embedding model that outperforms both OpenAI Ada-002 andOpenAI text-embedding-3-small on short and long-context tasks. We release thetraining code and model weights under an Apache 2 license. In contrast withother open-source models, we release a training data loader with 235 millioncurated text pairs that allows for the full replication of nomic-embed-text-v1.You can find code and data to replicate the model athttps://github.com/nomic-ai/contrastors</description><author>Zach Nussbaum, John X. Morris, Brandon Duderstadt, Andriy Mulyar</author><pubDate>Fri, 02 Feb 2024 18:23:18 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.01613v1</guid></item><item><title>DSPy Assertions: Computational Constraints for Self-Refining Language Model Pipelines</title><link>http://arxiv.org/abs/2312.13382v2</link><description>Chaining language model (LM) calls as composable modules is fueling a new wayof programming, but ensuring LMs adhere to important constraints requiresheuristic "prompt engineering". We introduce LM Assertions, a programmingconstruct for expressing computational constraints that LMs should satisfy. Weintegrate our constructs into the recent DSPy programming model for LMs, andpresent new strategies that allow DSPy to compile programs with LM Assertionsinto more reliable and accurate systems. We also propose strategies to useassertions at inference time for automatic self-refinement with LMs. We reporton four diverse case studies for text generation and find that LM Assertionsimprove not only compliance with imposed rules but also downstream taskperformance, passing constraints up to 164% more often and generating up to 37%more higher-quality responses. Our reference implementation of LM Assertions isintegrated into DSPy at https://github.com/stanfordnlp/dspy</description><author>Arnav Singhvi, Manish Shetty, Shangyin Tan, Christopher Potts, Koushik Sen, Matei Zaharia, Omar Khattab</author><pubDate>Fri, 02 Feb 2024 18:20:03 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.13382v2</guid></item><item><title>Runtime phylogenetic analysis enables extreme subsampling for test-based problems</title><link>http://arxiv.org/abs/2402.01610v1</link><description>A phylogeny describes the evolutionary history of an evolving population.Evolutionary search algorithms can perfectly track the ancestry of candidatesolutions, illuminating a population's trajectory through the search space.However, phylogenetic analyses are typically limited to post-hoc studies ofsearch performance. We introduce phylogeny-informed subsampling, a new class ofsubsampling methods that exploit runtime phylogenetic analyses for solvingtest-based problems. Specifically, we assess two phylogeny-informed subsamplingmethods -- individualized random subsampling and ancestor-based subsampling --on three diagnostic problems and ten genetic programming (GP) problems fromprogram synthesis benchmark suites. Overall, we found that phylogeny-informedsubsampling methods enable problem-solving success at extreme subsamplinglevels where other subsampling methods fail. For example, phylogeny-informedsubsampling methods more reliably solved program synthesis problems whenevaluating just one training case per-individual, per-generation. However, atmoderate subsampling levels, phylogeny-informed subsampling generally performedno better than random subsampling on GP problems. Our diagnostic experimentsshow that phylogeny-informed subsampling improves diversity maintenancerelative to random subsampling, but its effects on a selection scheme'scapacity to rapidly exploit fitness gradients varied by selection scheme.Continued refinements of phylogeny-informed subsampling techniques offer apromising new direction for scaling up evolutionary systems to handle problemswith many expensive-to-evaluate fitness criteria.</description><author>Alexander Lalejini, Marcos Sanson, Jack Garbus, Matthew Andres Moreno, Emily Dolson</author><pubDate>Fri, 02 Feb 2024 18:14:33 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.01610v1</guid></item><item><title>Contingency Analysis of a Grid of Connected EVs for Primary Frequency Control of an Industrial Microgrid Using Efficient Control Scheme</title><link>http://arxiv.org/abs/2402.01608v1</link><description>After over a century of internal combustion engines ruling the transportsector, electric vehicles appear to be on the verge of gaining traction due toa slew of advantages, including lower operating costs and lower CO2 emissions.By using the Vehicle-to-Grid (or Grid-to-Vehicle if Electric vehicles (EVs) areutilized as load) approach, EVs can operate as both a load and a source.Primary frequency regulation and congestion management are two essentialcharacteristics of this technology that are added to an industrial microgrid.Industrial Microgrids are made up of different energy sources such as windfarms and PV farms, storage systems, and loads. EVs have gained a lot ofinterest as a technique for frequency management because of their ability toregulate quickly. Grid reliability depends on this quick reaction. Differentcontingency, state of charge of the electric vehicles, and a varying number ofEVs in an EV fleet are considered in this work, and a proposed control schemefor frequency management is presented. This control scheme enablesbidirectional power flow, allowing for primary frequency regulation during thevarious scenarios that an industrial microgrid may encounter over the course ofa 24-h period. The presented controller will provide dependable frequencyregulation support to the industrial microgrid during contingencies, as will bedemonstrated by simulation results, achieving a more reliable system. However,simulation results will show that by increasing a number of the EVs in a fleetfor the Vehicle-to-Grid approach, an industrial microgrid\'s frequency can beenhanced even further.</description><author>J. N. Sabhahit, S. S. Solanke, V. K. Jadoun, H. Malik, F. P. García Márquez, J. M. Pinar-Pérez</author><pubDate>Fri, 02 Feb 2024 18:14:16 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.01608v1</guid></item><item><title>Natural Counterfactuals With Necessary Backtracking</title><link>http://arxiv.org/abs/2402.01607v1</link><description>Counterfactual reasoning is pivotal in human cognition and especiallyimportant for providing explanations and making decisions. While Judea Pearl'sinfluential approach is theoretically elegant, its generation of acounterfactual scenario often requires interventions that are too detached fromthe real scenarios to be feasible. In response, we propose a framework ofnatural counterfactuals and a method for generating counterfactuals that arenatural with respect to the actual world's data distribution. Our methodologyrefines counterfactual reasoning, allowing changes in causally precedingvariables to minimize deviations from realistic scenarios. To generate naturalcounterfactuals, we introduce an innovative optimization framework that permitsbut controls the extent of backtracking with a naturalness criterion. Empiricalexperiments indicate the effectiveness of our method.</description><author>Guang-Yuan Hao, Jiji Zhang, Biwei Huang, Hao Wang, Kun Zhang</author><pubDate>Fri, 02 Feb 2024 18:11:43 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.01607v1</guid></item><item><title>NoFunEval: Funny How Code LMs Falter on Requirements Beyond Functional Correctness</title><link>http://arxiv.org/abs/2401.15963v2</link><description>Existing evaluation benchmarks of language models of code (code LMs) focusalmost exclusively on whether the LMs can generate functionally-correct code.In real-world software engineering, developers think beyond functionalcorrectness. They have requirements on "how" a functionality should beimplemented to meet overall system design objectives like efficiency, security,and maintainability. They would also trust the code LMs more if the LMsdemonstrate robust understanding of requirements and code semantics. We propose a new benchmark NoFunEval to evaluate code LMs on non-functionalrequirements and simple classification instances for both functional andnon-functional requirements. We propose a prompting method, Coding Concepts(CoCo), as a way for a developer to communicate the domain knowledge to theLMs. We conduct an extensive evaluation of twenty-two code LMs. Our finding isthat they generally falter when tested on our benchmark, hinting at fundamentalblindspots in their training setups. Surprisingly, even the classificationaccuracy on functional-correctness instances derived from the popular HumanEvalbenchmark is low, calling in question the depth of their comprehension and thesource of their success in generating functionally-correct code in the firstplace. We will release our benchmark and evaluation scripts publicly athttps://aka.ms/NoFunEval.</description><author>Manav Singhal, Tushar Aggarwal, Abhijeet Awasthi, Nagarajan Natarajan, Aditya Kanade</author><pubDate>Fri, 02 Feb 2024 18:11:27 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.15963v2</guid></item><item><title>Foundation Model's Embedded Representations May Detect Distribution Shift</title><link>http://arxiv.org/abs/2310.13836v2</link><description>Sampling biases can cause distribution shifts between train and test datasetsfor supervised learning tasks, obscuring our ability to understand thegeneralization capacity of a model. This is especially important consideringthe wide adoption of pre-trained foundational neural networks -- whose behaviorremains poorly understood -- for transfer learning (TL) tasks. We present acase study for TL on the Sentiment140 dataset and show that many pre-trainedfoundation models encode different representations of Sentiment140's manuallycurated test set $M$ from the automatically labeled training set $P$,confirming that a distribution shift has occurred. We argue training on $P$ andmeasuring performance on $M$ is a biased measure of generalization. Experimentson pre-trained GPT-2 show that the features learnable from $P$ do not improve(and in fact hamper) performance on $M$. Linear probes on pre-trained GPT-2'srepresentations are robust and may even outperform overall fine-tuning,implying a fundamental importance for discerning distribution shift intrain/test splits for model interpretation.</description><author>Max Vargas, Adam Tsou, Andrew Engel, Tony Chiang</author><pubDate>Fri, 02 Feb 2024 18:07:37 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.13836v2</guid></item><item><title>How Powerful are Decoder-Only Transformer Neural Models?</title><link>http://arxiv.org/abs/2305.17026v3</link><description>In this article we prove that the general transformer neural modelundergirding modern large language models (LLMs) is Turing complete underreasonable assumptions. This is the first work to directly address the Turingcompleteness of the underlying technology employed in GPT-x as past work hasfocused on the more expressive, full auto-encoder transformer architecture.From this theoretical analysis, we show that the sparsity/compressibility ofthe word embedding is an important consideration for Turing completeness tohold. We also show that Transformers are are a variant of B machines studied byHao Wang.</description><author>Jesse Roberts</author><pubDate>Fri, 02 Feb 2024 18:04:58 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.17026v3</guid></item><item><title>Machine Learning with Requirements: a Manifesto</title><link>http://arxiv.org/abs/2304.03674v2</link><description>In the recent years, machine learning has made great advancements that havebeen at the root of many breakthroughs in different application domains.However, it is still an open issue how make them applicable to high-stakes orsafety-critical application domains, as they can often be brittle andunreliable. In this paper, we argue that requirements definition andsatisfaction can go a long way to make machine learning models even morefitting to the real world, especially in critical domains. To this end, wepresent two problems in which (i) requirements arise naturally, (ii) machinelearning models are or can be fruitfully deployed, and (iii) neglecting therequirements can have dramatic consequences. We show how the requirementsspecification can be fruitfully integrated into the standard machine learningdevelopment pipeline, proposing a novel pyramid development process in whichrequirements definition may impact all the subsequent phases in the pipeline,and viceversa.</description><author>Eleonora Giunchiglia, Fergus Imrie, Mihaela van der Schaar, Thomas Lukasiewicz</author><pubDate>Fri, 02 Feb 2024 18:04:02 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2304.03674v2</guid></item><item><title>Foundation Model Sherpas: Guiding Foundation Models through Knowledge and Reasoning</title><link>http://arxiv.org/abs/2402.01602v1</link><description>Foundation models (FMs) such as large language models have revolutionized thefield of AI by showing remarkable performance in various tasks. However, theyexhibit numerous limitations that prevent their broader adoption in manyreal-world systems, which often require a higher bar for trustworthiness andusability. Since FMs are trained using loss functions aimed at reconstructingthe training corpus in a self-supervised manner, there is no guarantee that themodel's output aligns with users' preferences for a specific task at hand. Inthis survey paper, we propose a conceptual framework that encapsulatesdifferent modes by which agents could interact with FMs and guide them suitablyfor a set of tasks, particularly through knowledge augmentation and reasoning.Our framework elucidates agent role categories such as updating the underlyingFM, assisting with prompting the FM, and evaluating the FM output. We alsocategorize several state-of-the-art approaches into agent interactionprotocols, highlighting the nature and extent of involvement of the variousagent roles. The proposed framework provides guidance for future directions tofurther realize the power of FMs in practical AI systems.</description><author>Debarun Bhattacharjya, Junkyu Lee, Don Joven Agravante, Balaji Ganesan, Radu Marinescu</author><pubDate>Fri, 02 Feb 2024 18:00:35 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.01602v1</guid></item><item><title>Distributional Reinforcement Learning by Sinkhorn Divergence</title><link>http://arxiv.org/abs/2202.00769v4</link><description>The empirical success of distributional reinforcement learning~(RL) highlydepends on the distribution representation and the choice of distributiondivergence. In this paper, we propose \textit{Sinkhorn distributionalRL~(SinkhornDRL)} that learns unrestricted statistics from return distributionsand leverages Sinkhorn divergence to minimize the difference between currentand target Bellman return distributions. Theoretically, we prove thecontraction properties of SinkhornDRL, consistent with the interpolation natureof Sinkhorn divergence between Wasserstein distance and Maximum MeanDiscrepancy~(MMD). We also establish the equivalence between Sinkhorndivergence and a regularized MMD with a regularized Moment Matching behavior,contributing to explaining the superiority of SinkhornDRL. Empirically, we showthat SinkhornDRL is consistently better or comparable to existing algorithms onthe Atari games suite.</description><author>Ke Sun, Yingnan Zhao, Wulong Liu, Bei Jiang, Linglong Kong</author><pubDate>Fri, 02 Feb 2024 17:59:50 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2202.00769v4</guid></item><item><title>Hyperparameter tuning via trajectory predictions: Stochastic prox-linear methods in matrix sensing</title><link>http://arxiv.org/abs/2402.01599v1</link><description>Motivated by the desire to understand stochastic algorithms for nonconvexoptimization that are robust to their hyperparameter choices, we analyze amini-batched prox-linear iterative algorithm for the problem of recovering anunknown rank-1 matrix from rank-1 Gaussian measurements corrupted by noise. Wederive a deterministic recursion that predicts the error of this method andshow, using a non-asymptotic framework, that this prediction is accurate forany batch-size and a large range of step-sizes. In particular, our analysisreveals that this method, though stochastic, converges linearly from a localinitialization with a fixed step-size to a statistical error floor. Ouranalysis also exposes how the batch-size, step-size, and noise level affect the(linear) convergence rate and the eventual statistical estimation error, and wedemonstrate how to use our deterministic predictions to perform hyperparametertuning (e.g. step-size and batch-size selection) without ever running themethod. On a technical level, our analysis is enabled in part by showing thatthe fluctuations of the empirical iterates around our deterministic predictionsscale with the error of the previous iterate.</description><author>Mengqi Lou, Kabir Aladin Verchand, Ashwin Pananjady</author><pubDate>Fri, 02 Feb 2024 17:55:12 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.01599v1</guid></item><item><title>Learning from Two Decades of Blood Pressure Data: Demography-Specific Patterns Across 75 Million Patient Encounters</title><link>http://arxiv.org/abs/2402.01598v1</link><description>Hypertension remains a global health concern with a rising prevalence,necessitating effective monitoring and understanding of blood pressure (BP)dynamics. This study delves into the wealth of information derived from BPmeasurement, a crucial approach in informing our understanding of hypertensivetrends. Numerous studies have reported on the relationship between BP variationand various factors. In this research, we leveraged an extensive datasetcomprising 75 million records spanning two decades, offering a uniqueopportunity to explore and analyze BP variations across demographic featuressuch as age, race, and gender. Our findings revealed that gender-based BPvariation was not statistically significant, challenging conventionalassumptions. Interestingly, systolic blood pressure (SBP) consistentlyincreased with age, while diastolic blood pressure (DBP) displayed adistinctive peak in the forties age group. Moreover, our analysis uncoveredintriguing similarities in the distribution of BP among some of the racialgroups. This comprehensive investigation contributes to the ongoing discourseon hypertension and underscores the importance of considering diversedemographic factors in understanding BP variations. Our results providevaluable insights that may inform personalized healthcare approaches tailoredto specific demographic profiles.</description><author>Seyedeh Somayyeh Mousavi, Yuting Guo, Abeed Sarker, Reza Sameni</author><pubDate>Fri, 02 Feb 2024 17:51:49 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.01598v1</guid></item><item><title>Immersive Video Compression using Implicit Neural Representations</title><link>http://arxiv.org/abs/2402.01596v1</link><description>Recent work on implicit neural representations (INRs) has evidenced theirpotential for efficiently representing and encoding conventional video content.In this paper we, for the first time, extend their application to immersive(multi-view) videos, by proposing MV-HiNeRV, a new INR-based immersive videocodec. MV-HiNeRV is an enhanced version of a state-of-the-art INR-based videocodec, HiNeRV, which was developed for single-view video compression. We havemodified the model to learn a different group of feature grids for each view,and share the learnt network parameters among all views. This enables the modelto effectively exploit the spatio-temporal and the inter-view redundancy thatexists within multi-view videos. The proposed codec was used to compressmulti-view texture and depth video sequences in the MPEG Immersive Video (MIV)Common Test Conditions, and tested against the MIV Test model (TMIV) that usesthe VVenC video codec. The results demonstrate the superior performance ofMV-HiNeRV, with significant coding gains (up to 72.33%) over TMIV. Theimplementation of MV-HiNeRV will be published for further development andevaluation.</description><author>Ho Man Kwan, Fan Zhang, Andrew Gower, David Bull</author><pubDate>Fri, 02 Feb 2024 17:49:31 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.01596v1</guid></item><item><title>CroissantLLM: A Truly Bilingual French-English Language Model</title><link>http://arxiv.org/abs/2402.00786v2</link><description>We introduce CroissantLLM, a 1.3B language model pretrained on a set of 3TEnglish and French tokens, to bring to the research and industrial community ahigh-performance, fully open-sourced bilingual model that runs swiftly onconsumer-grade local hardware. To that end, we pioneer the approach of trainingan intrinsically bilingual model with a 1:1 English-to-French pretraining dataratio, a custom tokenizer, and bilingual finetuning datasets. We release thetraining dataset, notably containing a French split with manually curated,high-quality, and varied data sources. To assess performance outside ofEnglish, we craft a novel benchmark, FrenchBench, consisting of an array ofclassification and generation tasks, covering various orthogonal aspects ofmodel performance in the French Language. Additionally, rooted in transparencyand to foster further Large Language Model research, we release codebases, anddozens of checkpoints across various model sizes, training data distributions,and training steps, as well as fine-tuned Chat models, and strong translationmodels. We evaluate our model through the FMTI framework, and validate 81 % ofthe transparency criteria, far beyond the scores of even most open initiatives.This work enriches the NLP landscape, breaking away from previousEnglish-centric work in order to strengthen our understanding ofmultilinguality in language models.</description><author>Manuel Faysse, Patrick Fernandes, Nuno M. Guerreiro, António Loison, Duarte M. Alves, Caio Corro, Nicolas Boizard, João Alves, Ricardo Rei, Pedro H. Martins, Antoni Bigata Casademunt, François Yvon, André F. T. Martins, Gautier Viaud, Céline Hudelot, Pierre Colombo</author><pubDate>Fri, 02 Feb 2024 17:43:41 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.00786v2</guid></item><item><title>Topic Bias in Emotion Classification</title><link>http://arxiv.org/abs/2312.09043v3</link><description>Emotion corpora are typically sampled based on keyword/hashtag search or byasking study participants to generate textual instances. In any case, thesecorpora are not uniform samples representing the entirety of a domain. Wehypothesize that this practice of data acquisition leads to unrealisticcorrelations between overrepresented topics in these corpora that harm thegeneralizability of models. Such topic bias could lead to wrong predictions forinstances like "I organized the service for my aunt's funeral." when funeralevents are over-represented for instances labeled with sadness, despite theemotion of pride being more appropriate here. In this paper, we study thistopic bias both from the data and the modeling perspective. We first label aset of emotion corpora automatically via topic modeling and show that emotionsin fact correlate with specific topics. Further, we see that emotionclassifiers are confounded by such topics. Finally, we show that theestablished debiasing method of adversarial correction via gradient reversalmitigates the issue. Our work points out issues with existing emotion corporaand that more representative resources are required for fair evaluation ofmodels predicting affective concepts from text.</description><author>Maximilian Wegge, Roman Klinger</author><pubDate>Fri, 02 Feb 2024 17:40:52 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.09043v3</guid></item><item><title>Deep graph kernel point processes</title><link>http://arxiv.org/abs/2306.11313v3</link><description>Point process models are widely used for continuous asynchronous event data,where each data point includes time and additional information called "marks",which can be locations, nodes, or event types. This paper presents a novelpoint process model for discrete event data over graphs, where the eventinteraction occurs within a latent graph structure. Our model builds uponHawkes's classic influence kernel-based formulation in the originalself-exciting point processes work to capture the influence of historicalevents on future events' occurrence. The key idea is to represent the influencekernel by Graph Neural Networks (GNN) to capture the underlying graph structurewhile harvesting the strong representation power of GNNs. Compared with priorworks focusing on directly modeling the conditional intensity function usingneural networks, our kernel presentation herds the repeated event influencepatterns more effectively by combining statistical and deep models, achievingbetter model estimation/learning efficiency and superior predictiveperformance. Our work significantly extends the existing deep spatio-temporalkernel for point process data, which is inapplicable to our setting due to thefundamental difference in the nature of the observation space being Euclideanrather than a graph. We present comprehensive experiments on synthetic andreal-world data to show the superior performance of the proposed approachagainst the state-of-the-art in predicting future events and uncovering therelational structure among data.</description><author>Zheng Dong, Matthew Repasky, Xiuyuan Cheng, Yao Xie</author><pubDate>Fri, 02 Feb 2024 17:36:32 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.11313v3</guid></item><item><title>Towards Sustainable Workplace Mental Health: A Novel Approach to Early Intervention and Support</title><link>http://arxiv.org/abs/2402.01592v1</link><description>Employee well-being is a critical concern in the contemporary workplace, ashighlighted by the American Psychological Association's 2021 report, indicatingthat 71% of employees experience stress or tension. This stress contributessignificantly to workplace attrition and absenteeism, with 61% of attrition and16% of sick days attributed to poor mental health. A major challenge foremployers is that employees often remain unaware of their mental health issuesuntil they reach a crisis point, resulting in limited utilization of corporatewell-being benefits. This research addresses this challenge by presenting agroundbreaking stress detection algorithm that provides real-time supportpreemptively. Leveraging automated chatbot technology, the algorithmobjectively measures mental health levels by analyzing chat conversations,offering personalized treatment suggestions in real-time based on linguisticbiomarkers. The study explores the feasibility of integrating these innovationsinto practical learning applications within real-world contexts and introducesa chatbot-style system integrated into the broader employee experienceplatform. This platform, encompassing various features, aims to enhance overallemployee well-being, detect stress in real time, and proactively engage withindividuals to improve support effectiveness, demonstrating a 22% increase whenassistance is provided early. Overall, the study emphasizes the importance offostering a supportive workplace environment for employees' mental health.</description><author>David W. Vinson, Mihael Arcan, David-Paul Niland, Fionn Delahunty</author><pubDate>Fri, 02 Feb 2024 17:35:49 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.01592v1</guid></item><item><title>BAT: Learning to Reason about Spatial Sounds with Large Language Models</title><link>http://arxiv.org/abs/2402.01591v1</link><description>Spatial sound reasoning is a fundamental human skill, enabling us to navigateand interpret our surroundings based on sound. In this paper we present BAT,which combines the spatial sound perception ability of a binaural acousticscene analysis model with the natural language reasoning capabilities of alarge language model (LLM) to replicate this innate ability. To address thelack of existing datasets of in-the-wild spatial sounds, we synthesized abinaural audio dataset using AudioSet and SoundSpaces 2.0. Next, we developedSpatialSoundQA, a spatial sound-based question-answering dataset, offering arange of QA tasks that train BAT in various aspects of spatial sound perceptionand reasoning. The acoustic front end encoder of BAT is a novel spatial audioencoder named Spatial Audio Spectrogram Transformer, or Spatial-AST, which byitself achieves strong performance across sound event detection, spatiallocalization, and distance estimation. By integrating Spatial-AST with LLaMA-27B model, BAT transcends standard Sound Event Localization and Detection (SELD)tasks, enabling the model to reason about the relationships between the soundsin its environment. Our experiments demonstrate BAT's superior performance onboth spatial sound perception and reasoning, showcasing the immense potentialof LLMs in navigating and interpreting complex spatial audio environments.</description><author>Zhisheng Zheng, Puyuan Peng, Ziyang Ma, Xie Chen, Eunsol Choi, David Harwath</author><pubDate>Fri, 02 Feb 2024 17:34:53 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.01591v1</guid></item><item><title>NeuroCine: Decoding Vivid Video Sequences from Human Brain Activties</title><link>http://arxiv.org/abs/2402.01590v1</link><description>In the pursuit to understand the intricacies of human brain's visualprocessing, reconstructing dynamic visual experiences from brain activitiesemerges as a challenging yet fascinating endeavor. While recent advancementshave achieved success in reconstructing static images from non-invasive brainrecordings, the domain of translating continuous brain activities into videoformat remains underexplored. In this work, we introduce NeuroCine, a noveldual-phase framework to targeting the inherent challenges of decoding fMRIdata, such as noises, spatial redundancy and temporal lags. This frameworkproposes spatial masking and temporal interpolation-based augmentation forcontrastive learning fMRI representations and a diffusion model enhanced bydependent prior noise for video generation. Tested on a publicly available fMRIdataset, our method shows promising results, outperforming the previousstate-of-the-art models by a notable margin of ${20.97\%}$, ${31.00\%}$ and${12.30\%}$ respectively on decoding the brain activities of three subjects inthe fMRI dataset, as measured by SSIM. Additionally, our attention analysissuggests that the model aligns with existing brain structures and functions,indicating its biological plausibility and interpretability.</description><author>Jingyuan Sun, Mingxiao Li, Zijiao Chen, Marie-Francine Moens</author><pubDate>Fri, 02 Feb 2024 17:34:25 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.01590v1</guid></item><item><title>CAST: Cluster-Aware Self-Training for Tabular Data</title><link>http://arxiv.org/abs/2310.06380v2</link><description>Self-training has gained attraction because of its simplicity andversatility, yet it is vulnerable to noisy pseudo-labels caused by erroneousconfidence. Several solutions have been proposed to handle the problem, butthey require significant modifications in self-training algorithms or modelarchitecture, and most have limited applicability in tabular domains. Toaddress this issue, we explore a novel direction of reliable confidence inself-training contexts and conclude that the confidence, which represents thevalue of the pseudo-label, should be aware of the cluster assumption. In thisregard, we propose Cluster-Aware Self-Training (CAST) for tabular data, whichenhances existing self-training algorithms at a negligible cost withoutsignificant modifications. Concretely, CAST regularizes the confidence of theclassifier by leveraging local density for each class in the labeled trainingdata, forcing the pseudo-labels in low-density regions to have lowerconfidence. Extensive empirical evaluations on up to 21 real-world datasetsconfirm not only the superior performance of CAST but also its robustness invarious setups in self-training contexts.</description><author>Minwook Kim, Juseong Kim, Ki Beom Kim, Giltae Song</author><pubDate>Fri, 02 Feb 2024 17:31:05 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.06380v2</guid></item><item><title>End-to-end Learnable Clustering for Intent Learning in Recommendation</title><link>http://arxiv.org/abs/2401.05975v3</link><description>Intent learning, which aims to learn users' intents for user understandingand item recommendation, has become a hot research spot in recent years.However, the existing methods suffer from complex and cumbersome alternatingoptimization, limiting the performance and scalability. To this end, we proposea novel intent learning method termed \underline{ELCRec}, by unifying behaviorrepresentation learning into an \underline{E}nd-to-end \underline{L}earnable\underline{C}lustering framework, for effective and efficient\underline{Rec}ommendation. Concretely, we encode users' behavior sequences andinitialize the cluster centers (latent intents) as learnable neurons. Then, wedesign a novel learnable clustering module to separate different clustercenters, thus decoupling users' complex intents. Meanwhile, it guides thenetwork to learn intents from behaviors by forcing behavior embeddings close tocluster centers. This allows simultaneous optimization of recommendation andclustering via mini-batch data. Moreover, we propose intent-assistedcontrastive learning by using cluster centers as self-supervision signals,further enhancing mutual promotion. Both experimental results and theoreticalanalyses demonstrate the superiority of ELCRec from six perspectives. Comparedto the runner-up, ELCRec improves NDCG@5 by 8.9\% and reduces computationalcosts by 22.5\% on Beauty dataset. Furthermore, due to the scalability anduniversal applicability, we deploy this method on the industrial recommendationsystem with 130 million page views and achieve promising results.</description><author>Yue Liu, Shihao Zhu, Jun Xia, Yingwei Ma, Jian Ma, Wenliang Zhong, Xinwang Liu, Guannan Zhang, Kejun Zhang</author><pubDate>Fri, 02 Feb 2024 17:30:51 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.05975v3</guid></item><item><title>An Accurate and Low-Parameter Machine Learning Architecture for Next Location Prediction</title><link>http://arxiv.org/abs/2402.00306v2</link><description>Next location prediction is a discipline that involves predicting a usersnext location. Its applications include resource allocation, quality ofservice, energy efficiency, and traffic management. This paper proposes anenergy-efficient, small, and low parameter machine learning (ML) architecturefor accurate next location prediction, deployable on modest base stations andedge devices. To accomplish this we ran a hundred hyperparameter experiments onthe full human mobility patterns of an entire city, to determine an exact MLarchitecture that reached a plateau of accuracy with the least amount of modelparameters. We successfully achieved a reduction in the number of modelparameters within published ML architectures from 202 million down to 2million. This reduced the total size of the model parameters from 791 MB downto 8 MB. Additionally, this decreased the training time by a factor of four,the amount of graphics processing unit (GPU) memory needed for training by afactor of twenty, and the overall accuracy was increased from 80.16% to 82.54%.This improvement allows for modest base stations and edge devices which do nothave a large amount of memory or storage, to deploy and utilize the proposed MLarchitecture for next location prediction.</description><author>Calvin Jary, Nafiseh Kahani</author><pubDate>Fri, 02 Feb 2024 17:29:21 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.00306v2</guid></item><item><title>Leveraging Professional Radiologists' Expertise to Enhance LLMs' Evaluation for Radiology Reports</title><link>http://arxiv.org/abs/2401.16578v2</link><description>In radiology, Artificial Intelligence (AI) has significantly advanced reportgeneration, but automatic evaluation of these AI-produced reports remainschallenging. Current metrics, such as Conventional Natural Language Generation(NLG) and Clinical Efficacy (CE), often fall short in capturing the semanticintricacies of clinical contexts or overemphasize clinical details, underminingreport clarity. To overcome these issues, our proposed method synergizes theexpertise of professional radiologists with Large Language Models (LLMs), likeGPT-3.5 and GPT-4 1. Utilizing In-Context Instruction Learning (ICIL) and Chainof Thought (CoT) reasoning, our approach aligns LLM evaluations withradiologist standards, enabling detailed comparisons between human and AIgenerated reports. This is further enhanced by a Regression model thataggregates sentence evaluation scores. Experimental results show that our"Detailed GPT-4 (5-shot)" model achieves a 0.48 score, outperforming the METEORmetric by 0.19, while our "Regressed GPT-4" model shows even greater alignmentwith expert evaluations, exceeding the best existing metric by a 0.35 margin.Moreover, the robustness of our explanations has been validated through athorough iterative strategy. We plan to publicly release annotations fromradiology experts, setting a new standard for accuracy in future assessments.This underscores the potential of our approach in enhancing the qualityassessment of AI-driven medical reports.</description><author>Qingqing Zhu, Xiuying Chen, Qiao Jin, Benjamin Hou, Tejas Sudharshan Mathai, Pritam Mukherjee, Xin Gao, Ronald M Summers, Zhiyong Lu</author><pubDate>Fri, 02 Feb 2024 17:28:22 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.16578v2</guid></item><item><title>TrustAgent: Towards Safe and Trustworthy LLM-based Agents through Agent Constitution</title><link>http://arxiv.org/abs/2402.01586v1</link><description>The emergence of LLM-based agents has garnered considerable attention, yettheir trustworthiness remains an under-explored area. As agents can directlyinteract with the physical environment, their reliability and safety iscritical. This paper presents an Agent-Constitution-based agent framework,TrustAgent, an initial investigation into improving the safety dimension oftrustworthiness in LLM-based agents. This framework consists of threefoldstrategies: pre-planning strategy which injects safety knowledge to the modelprior to plan generation, in-planning strategy which bolsters safety duringplan generation, and post-planning strategy which ensures safety bypost-planning inspection. Through experimental analysis, we demonstrate howthese approaches can effectively elevate an LLM agent's safety by identifyingand preventing potential dangers. Furthermore, we explore the intricaterelationships between safety and helpfulness, and between the model's reasoningability and its efficacy as a safe agent. This paper underscores the imperativeof integrating safety awareness and trustworthiness into the design anddeployment of LLM-based agents, not only to enhance their performance but alsoto ensure their responsible integration into human-centric environments. Dataand code are available at https://github.com/agiresearch/TrustAgent.</description><author>Wenyue Hua, Xianjun Yang, Zelong Li, Cheng Wei, Yongfeng Zhang</author><pubDate>Fri, 02 Feb 2024 17:26:23 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.01586v1</guid></item><item><title>Fix-Con: Automatic Fault Localization and Repair of Deep Learning Model Conversions</title><link>http://arxiv.org/abs/2312.15101v2</link><description>Converting deep learning models between frameworks is a common step tomaximize model compatibility across devices and leverage optimization featuresthat may be exclusively provided in one deep learning framework. However, thisconversion process may be riddled with bugs, making the converted models eitherundeployable or problematic, considerably degrading their predictioncorrectness. We propose an automated approach for fault localization and repair, Fix-Con,during model conversion between deep learning frameworks. Fix-Con is capable ofdetecting and fixing faults introduced in model input, parameters,hyperparameters, and the model graph during conversion. Fix-Con uses a set of fault types mined from surveying conversion issuesraised to localize potential conversion faults in the converted target model,and then repairs them appropriately, e.g. replacing the parameters of thetarget model with those from the source model. This is done iteratively forevery image in the dataset with output label differences between the sourcemodel and the converted target model until all differences are resolved. Weevaluate the effectiveness of Fix-Con in fixing model conversion bugs of threewidely used image recognition models converted across four different deeplearning frameworks. Overall, Fix-Con was able to either completely repair, orsignificantly improve the performance of 14 out of the 15 erroneous conversioncases.</description><author>Nikolaos Louloudakis, Perry Gibson, José Cano, Ajitha Rajan</author><pubDate>Fri, 02 Feb 2024 17:26:07 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.15101v2</guid></item><item><title>Automating Sound Change Prediction for Phylogenetic Inference: A Tukanoan Case Study</title><link>http://arxiv.org/abs/2402.01582v1</link><description>We describe a set of new methods to partially automate linguisticphylogenetic inference given (1) cognate sets with their respective protoformsand sound laws, (2) a mapping from phones to their articulatory features and(3) a typological database of sound changes. We train a neural network on thesesound change data to weight articulatory distances between phones and predictintermediate sound change steps between historical protoforms and their moderndescendants, replacing a linguistic expert in part of a parsimony-basedphylogenetic inference algorithm. In our best experiments on Tukanoanlanguages, this method produces trees with a Generalized Quartet Distance of0.12 from a tree that used expert annotations, a significant improvement overother semi-automated baselines. We discuss potential benefits and drawbacks toour neural approach and parsimony-based tree prediction. We also experimentwith a minimal generalization learner for automatic sound law induction,finding it comparably effective to sound laws from expert annotation. Our codeis publicly available at https://github.com/cmu-llab/aiscp.</description><author>Kalvin Chang, Nathaniel R. Robinson, Anna Cai, Ting Chen, Annie Zhang, David R. Mortensen</author><pubDate>Fri, 02 Feb 2024 17:20:16 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.01582v1</guid></item><item><title>Generative AI for Education (GAIED): Advances, Opportunities, and Challenges</title><link>http://arxiv.org/abs/2402.01580v1</link><description>This survey article has grown out of the GAIED (pronounced "guide") workshoporganized by the authors at the NeurIPS 2023 conference. We organized the GAIEDworkshop as part of a community-building effort to bring together researchers,educators, and practitioners to explore the potential of generative AI forenhancing education. This article aims to provide an overview of the workshopactivities and highlight several future research directions in the area ofGAIED.</description><author>Paul Denny, Sumit Gulwani, Neil T. Heffernan, Tanja Käser, Steven Moore, Anna N. Rafferty, Adish Singla</author><pubDate>Fri, 02 Feb 2024 17:19:20 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.01580v1</guid></item><item><title>How Paralingual are Paralinguistic Representations? A Case Study in Speech Emotion Recognition</title><link>http://arxiv.org/abs/2402.01579v1</link><description>Pre-trained Models (PTMs) have facilitated substantial progress in the fieldof Speech Emotion Recognition (SER). SER is an area with applications rangingfrom HumanComputer Interaction to Healthcare. Recent studies have leveragedvarious PTM representations as input features for downstream models for SER.PTM specifically pre-trained for paralinguistic tasks have obtainedstate-of-the-art (SOTA) performance for SER. However, such PTM haven't beenevaluated for SER in multilingual settings and experimented only with English.So, we fill this gap, by performing a comprehensive comparative study of fivePTMs (TRILLsson, wav2vec2, XLS-R, x-vector, Whisper) for assessing theeffectiveness of paralingual PTM (TRILLsson) for SER across multiple languages.Representations from TRILLsson achieved the best performance among all thePTMs. This demonstrates that TRILLsson is able to effectively capture thevarious paralinguistic features from speech data for better SER. We also showthat downstream models using TRILLsson representations achieve SOTA performancein terms of accuracy across various multi-lingual datasets.</description><author>Orchid Chetia Phukan, Gautam Siddharth Kashyap, Arun Balaji Buduru, Rajesh Sharma</author><pubDate>Fri, 02 Feb 2024 17:17:42 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.01579v1</guid></item><item><title>Deep Active Learning for Data Mining from Conflict Text Corpora</title><link>http://arxiv.org/abs/2402.01577v1</link><description>High-resolution event data on armed conflict and related processes haverevolutionized the study of political contention with datasets like UCDP GED,ACLED etc. However, most of these datasets limit themselves to collectingspatio-temporal (high-resolution) and intensity data. Information on dynamics,such as targets, tactics, purposes etc. are rarely collected owing to theextreme workload of collecting data. However, most datasets rely on a richcorpus of textual data allowing further mining of further information connectedto each event. This paper proposes one such approach that is inexpensive andhigh performance, leveraging active learning - an iterative process ofimproving a machine learning model based on sequential (guided) human input.Active learning is employed to then step-wise train (fine-tuning) of a large,encoder-only language model adapted for extracting sub-classes of eventsrelating to conflict dynamics. The approach shows performance similar to human(gold-standard) coding while reducing the amount of required human annotationby as much as 99%.</description><author>Mihai Croicu</author><pubDate>Fri, 02 Feb 2024 17:16:23 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.01577v1</guid></item><item><title>TadML: A fast temporal action detection with Mechanics-MLP</title><link>http://arxiv.org/abs/2206.02997v2</link><description>Temporal Action Detection(TAD) is a crucial but challenging task in videounderstanding.It is aimed at detecting both the type and start-end frame foreach action instance in a long, untrimmed video.Most current models adopt bothRGB and Optical-Flow streams for the TAD task. Thus, original RGB frames mustbe converted manually into Optical-Flow frames with additional computation andtime cost, which is an obstacle to achieve real-time processing. At present,many models adopt two-stage strategies, which would slow the inference speeddown and complicatedly tuning on proposals generating.By comparison, we proposea one-stage anchor-free temporal localization method with RGB stream only, inwhich a novel Newtonian Mechanics-MLP architecture is established. It hascomparable accuracy with all existing state-of-the-art models, while surpassesthe inference speed of these methods by a large margin. The typical inferencespeed in this paper is astounding 4.44 video per second on THUMOS14. Inapplications, because there is no need to convert optical flow, the inferencespeed will be faster.It also proves that MLP has great potential in downstreamtasks such as TAD. The source code is available athttps://github.com/BonedDeng/TadML</description><author>Bowen Deng, Dongchang Liu</author><pubDate>Fri, 02 Feb 2024 17:11:10 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2206.02997v2</guid></item><item><title>Analog-digital Scheduling for Federated Learning: A Communication-Efficient Approach</title><link>http://arxiv.org/abs/2402.00318v2</link><description>Over-the-air (OTA) computation has recently emerged as acommunication-efficient Federated Learning (FL) paradigm to train machinelearning models over wireless networks. However, its performance is limited bythe device with the worst SNR, resulting in fast yet noisy updates. On theother hand, allocating orthogonal resource blocks (RB) to individual devicesvia digital channels mitigates the noise problem, at the cost of increasedcommunication latency. In this paper, we address this discrepancy and presentADFL, a novel Analog-Digital FL scheme: in each round, the parameter server(PS) schedules each device to either upload its gradient via the analog OTAscheme or transmit its quantized gradient over an orthogonal RB using the``digital" scheme. Focusing on a single FL round, we cast the optimalscheduling problem as the minimization of the mean squared error (MSE) on theestimated global gradient at the PS, subject to a delay constraint, yieldingthe optimal device scheduling configuration and quantization bits for thedigital devices. Our simulation results show that ADFL, by scheduling most ofthe devices in the OTA scheme while also occasionally employing the digitalscheme for a few devices, consistently outperforms OTA-only and digital-onlyschemes, in both i.i.d. and non-i.i.d. settings.</description><author>Muhammad Faraz Ul Abrar, Nicolò Michelusi</author><pubDate>Fri, 02 Feb 2024 17:08:39 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.00318v2</guid></item><item><title>Spiking Music: Audio Compression with Event Based Auto-encoders</title><link>http://arxiv.org/abs/2402.01571v1</link><description>Neurons in the brain communicate information via punctual events calledspikes. The timing of spikes is thought to carry rich information, but it isnot clear how to leverage this in digital systems. We demonstrate thatevent-based encoding is efficient for audio compression. To build thisevent-based representation we use a deep binary auto-encoder, and under highsparsity pressure, the model enters a regime where the binary event matrix isstored more efficiently with sparse matrix storage algorithms. We test this onthe large MAESTRO dataset of piano recordings against vector quantizedauto-encoders. Not only does our "Spiking Music compression" algorithm achievea competitive compression/reconstruction trade-off, but selectivity andsynchrony between encoded events and piano key strikes emerge withoutsupervision in the sparse regime.</description><author>Martim Lisboa, Guillaume Bellec</author><pubDate>Fri, 02 Feb 2024 17:07:39 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.01571v1</guid></item><item><title>Understanding Adam Optimizer via Online Learning of Updates: Adam is FTRL in Disguise</title><link>http://arxiv.org/abs/2402.01567v1</link><description>Despite the success of the Adam optimizer in practice, the theoreticalunderstanding of its algorithmic components still remains limited. Inparticular, most existing analyses of Adam show the convergence rate that canbe simply achieved by non-adative algorithms like SGD. In this work, we providea different perspective based on online learning that underscores theimportance of Adam's algorithmic components. Inspired by Cutkosky et al.(2023), we consider the framework called online learning of updates, where wechoose the updates of an optimizer based on an online learner. With thisframework, the design of a good optimizer is reduced to the design of a goodonline learner. Our main observation is that Adam corresponds to a principledonline learning framework called Follow-the-Regularized-Leader (FTRL). Buildingon this observation, we study the benefits of its algorithmic components fromthe online learning perspective.</description><author>Kwangjun Ahn, Zhiyu Zhang, Yunbum Kook, Yan Dai</author><pubDate>Fri, 02 Feb 2024 17:00:17 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.01567v1</guid></item><item><title>Boximator: Generating Rich and Controllable Motions for Video Synthesis</title><link>http://arxiv.org/abs/2402.01566v1</link><description>Generating rich and controllable motion is a pivotal challenge in videosynthesis. We propose Boximator, a new approach for fine-grained motioncontrol. Boximator introduces two constraint types: hard box and soft box.Users select objects in the conditional frame using hard boxes and then useeither type of boxes to roughly or rigorously define the object's position,shape, or motion path in future frames. Boximator functions as a plug-in forexisting video diffusion models. Its training process preserves the basemodel's knowledge by freezing the original weights and training only thecontrol module. To address training challenges, we introduce a novelself-tracking technique that greatly simplifies the learning of box-objectcorrelations. Empirically, Boximator achieves state-of-the-art video quality(FVD) scores, improving on two base models, and further enhanced afterincorporating box constraints. Its robust motion controllability is validatedby drastic increases in the bounding box alignment metric. Human evaluationalso shows that users favor Boximator generation results over the base model.</description><author>Jiawei Wang, Yuchen Zhang, Jiaxin Zou, Yan Zeng, Guoqiang Wei, Liping Yuan, Hang Li</author><pubDate>Fri, 02 Feb 2024 16:59:48 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.01566v1</guid></item><item><title>Explanations, Fairness, and Appropriate Reliance in Human-AI Decision-Making</title><link>http://arxiv.org/abs/2209.11812v4</link><description>In this work, we study the effects of feature-based explanations ondistributive fairness of AI-assisted decisions, specifically focusing on thetask of predicting occupations from short textual bios. We also investigate howany effects are mediated by humans' fairness perceptions and their reliance onAI recommendations. Our findings show that explanations influence fairnessperceptions, which, in turn, relate to humans' tendency to adhere to AIrecommendations. However, we see that such explanations do not enable humans todiscern correct and incorrect AI recommendations. Instead, we show that theymay affect reliance irrespective of the correctness of AI recommendations.Depending on which features an explanation highlights, this can foster orhinder distributive fairness: when explanations highlight features that aretask-irrelevant and evidently associated with the sensitive attribute, thisprompts overrides that counter AI recommendations that align with genderstereotypes. Meanwhile, if explanations appear task-relevant, this inducesreliance behavior that reinforces stereotype-aligned errors. These resultsimply that feature-based explanations are not a reliable mechanism to improvedistributive fairness.</description><author>Jakob Schoeffer, Maria De-Arteaga, Niklas Kuehl</author><pubDate>Fri, 02 Feb 2024 16:55:56 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2209.11812v4</guid></item><item><title>MagiCapture: High-Resolution Multi-Concept Portrait Customization</title><link>http://arxiv.org/abs/2309.06895v2</link><description>Large-scale text-to-image models including Stable Diffusion are capable ofgenerating high-fidelity photorealistic portrait images. There is an activeresearch area dedicated to personalizing these models, aiming to synthesizespecific subjects or styles using provided sets of reference images. However,despite the plausible results from these personalization methods, they tend toproduce images that often fall short of realism and are not yet on acommercially viable level. This is particularly noticeable in portrait imagegeneration, where any unnatural artifact in human faces is easily discernibledue to our inherent human bias. To address this, we introduce MagiCapture, apersonalization method for integrating subject and style concepts to generatehigh-resolution portrait images using just a few subject and style references.For instance, given a handful of random selfies, our fine-tuned model cangenerate high-quality portrait images in specific styles, such as passport orprofile photos. The main challenge with this task is the absence of groundtruth for the composed concepts, leading to a reduction in the quality of thefinal output and an identity shift of the source subject. To address theseissues, we present a novel Attention Refocusing loss coupled with auxiliarypriors, both of which facilitate robust learning within this weakly supervisedlearning setting. Our pipeline also includes additional post-processing stepsto ensure the creation of highly realistic outputs. MagiCapture outperformsother baselines in both quantitative and qualitative evaluations and can alsobe generalized to other non-human objects.</description><author>Junha Hyung, Jaeyo Shin, Jaegul Choo</author><pubDate>Fri, 02 Feb 2024 16:55:00 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2309.06895v2</guid></item><item><title>Deep Continuous Networks</title><link>http://arxiv.org/abs/2402.01557v1</link><description>CNNs and computational models of biological vision share some fundamentalprinciples, which opened new avenues of research. However, fruitful cross-fieldresearch is hampered by conventional CNN architectures being based on spatiallyand depthwise discrete representations, which cannot accommodate certainaspects of biological complexity such as continuously varying receptive fieldsizes and dynamics of neuronal responses. Here we propose deep continuousnetworks (DCNs), which combine spatially continuous filters, with thecontinuous depth framework of neural ODEs. This allows us to learn the spatialsupport of the filters during training, as well as model the continuousevolution of feature maps, linking DCNs closely to biological models. We showthat DCNs are versatile and highly applicable to standard image classificationand reconstruction problems, where they improve parameter and data efficiency,and allow for meta-parametrization. We illustrate the biological plausibilityof the scale distributions learned by DCNs and explore their performance in aneuroscientifically inspired pattern completion task. Finally, we investigatean efficient implementation of DCNs by changing input contrast.</description><author>Nergis Tomen, Silvia L. Pintea, Jan C. van Gemert</author><pubDate>Fri, 02 Feb 2024 16:50:18 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.01557v1</guid></item><item><title>Neural Semantic Surface Maps</title><link>http://arxiv.org/abs/2309.04836v2</link><description>We present an automated technique for computing a map between two genus-zeroshapes, which matches semantically corresponding regions to one another. Lackof annotated data prohibits direct inference of 3D semantic priors; instead,current State-of-the-art methods predominantly optimize geometric properties orrequire varying amounts of manual annotation. To overcome the lack of annotatedtraining data, we distill semantic matches from pre-trained vision models: ourmethod renders the pair of 3D shapes from multiple viewpoints; the resultingrenders are then fed into an off-the-shelf image-matching method whichleverages a pretrained visual model to produce feature points. This yieldssemantic correspondences, which can be projected back to the 3D shapes,producing a raw matching that is inaccurate and inconsistent between differentviewpoints. These correspondences are refined and distilled into aninter-surface map by a dedicated optimization scheme, which promotesbijectivity and continuity of the output map. We illustrate that our approachcan generate semantic surface-to-surface maps, eliminating manual annotationsor any 3D training data requirement. Furthermore, it proves effective inscenarios with high semantic complexity, where objects are non-isometricallyrelated, as well as in situations where they are nearly isometric.</description><author>Luca Morreale, Noam Aigerman, Vladimir G. Kim, Niloy J. Mitra</author><pubDate>Fri, 02 Feb 2024 16:50:15 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2309.04836v2</guid></item><item><title>SLYKLatent, a Learning Framework for Facial Features Estimation</title><link>http://arxiv.org/abs/2402.01555v1</link><description>In this research, we present SLYKLatent, a novel approach for enhancing gazeestimation by addressing appearance instability challenges in datasets due toaleatoric uncertainties, covariant shifts, and test domain generalization.SLYKLatent utilizes Self-Supervised Learning for initial training with facialexpression datasets, followed by refinement with a patch-based tri-branchnetwork and an inverse explained variance-weighted training loss function. Ourevaluation on benchmark datasets achieves an 8.7% improvement on Gaze360,rivals top MPIIFaceGaze results, and leads on a subset of ETH-XGaze by 13%,surpassing existing methods by significant margins. Adaptability tests onRAF-DB and Affectnet show 86.4% and 60.9% accuracies, respectively. Ablationstudies confirm the effectiveness of SLYKLatent's novel components. Thisapproach has strong potential in human-robot interaction.</description><author>Samuel Adebayo, Joost C. Dessing, Seán McLoone</author><pubDate>Fri, 02 Feb 2024 16:47:18 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.01555v1</guid></item><item><title>A Linguistic Comparison between Human and ChatGPT-Generated Conversations</title><link>http://arxiv.org/abs/2401.16587v2</link><description>This study explores linguistic differences between human and LLM-generateddialogues, using 19.5K dialogues generated by ChatGPT-3.5 as a companion to theEmpathicDialogues dataset. The research employs Linguistic Inquiry and WordCount (LIWC) analysis, comparing ChatGPT-generated conversations with humanconversations across 118 linguistic categories. Results show greatervariability and authenticity in human dialogues, but ChatGPT excels incategories such as social processes, analytical style, cognition, attentionalfocus, and positive emotional tone, reinforcing recent findings of LLMs being"more human than human." However, no significant difference was found inpositive or negative affect between ChatGPT and human dialogues. Classifieranalysis of dialogue embeddings indicates implicit coding of the valence ofaffect despite no explicit mention of affect in the conversations. The researchalso contributes a novel, companion ChatGPT-generated dataset of conversationsbetween two independent chatbots, which were designed to replicate a corpus ofhuman conversations available for open access and used widely in AI research onlanguage modeling. Our findings increase understanding of ChatGPT's linguisticcapabilities and inform ongoing efforts to distinguish between human andLLM-generated text, which is critical in detecting AI-generated fakes,misinformation, and disinformation.</description><author>Morgan Sandler, Hyesun Choung, Arun Ross, Prabu David</author><pubDate>Fri, 02 Feb 2024 16:47:16 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.16587v2</guid></item><item><title>Almost Equivariance via Lie Algebra Convolutions</title><link>http://arxiv.org/abs/2310.13164v4</link><description>Recently, the equivariance of models with respect to a group action hasbecome an important topic of research in machine learning. Analysis of thebuilt-in equivariance of existing neural network architectures, as well as thestudy of building models that explicitly "bake in" equivariance, have becomesignificant research areas in their own right. However, imbuing an architecturewith a specific group equivariance imposes a strong prior on the types of datatransformations that the model expects to see. While strictly-equivariantmodels enforce symmetries, real-world data does not always conform to suchstrict equivariances. In such cases, the prior of strict equivariance canactually prove too strong and cause models to underperform. Therefore, in thiswork we study a closely related topic, that of almost equivariance. We providea definition of almost equivariance and give a practical method for encodingalmost equivariance in models by appealing to the Lie algebra of a Lie group.Specifically, we define Lie algebra convolutions and demonstrate that theyoffer several benefits over Lie group convolutions, including beingwell-defined for non-compact Lie groups having non-surjective exponential map.From there, we demonstrate connections between the notions of equivariance andisometry and those of almost equivariance and almost isometry. We prove twoexistence theorems, one showing the existence of almost isometries withinbounded distance of isometries of a manifold, and another showing the conversefor Hilbert spaces. We extend these theorems to prove the existence of almostequivariant manifold embeddings within bounded distance of fully equivariantembedding functions, subject to certain constraints on the group action and thefunction class. Finally, we demonstrate the validity of our approach bybenchmarking against datasets in fully equivariant and almost equivariantsettings.</description><author>Daniel McNeela</author><pubDate>Fri, 02 Feb 2024 16:43:57 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.13164v4</guid></item><item><title>Improving Monte Carlo Evaluation with Offline Data</title><link>http://arxiv.org/abs/2301.13734v3</link><description>Most reinforcement learning practitioners evaluate their policies with onlineMonte Carlo estimators for either hyperparameter tuning or testing differentalgorithmic design choices, where the policy is repeatedly executed in theenvironment to get the average outcome. Such massive interactions with theenvironment are prohibitive in many scenarios. In this paper, we propose novelmethods that improve the data efficiency of online Monte Carlo estimators whilemaintaining their unbiasedness. We first propose a tailored closed-formbehavior policy that provably reduces the variance of an online Monte Carloestimator. We then design efficient algorithms to learn this closed-formbehavior policy from previously collected offline data. Theoretical analysis isprovided to characterize how the behavior policy learning error affects theamount of reduced variance. Compared with previous works, our method achievesbetter empirical performance in a broader set of environments, with fewerrequirements for offline data.</description><author>Shuze Liu, Shangtong Zhang</author><pubDate>Fri, 02 Feb 2024 16:42:19 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2301.13734v3</guid></item><item><title>Privacy-Preserving Distributed Learning for Residential Short-Term Load Forecasting</title><link>http://arxiv.org/abs/2402.01546v1</link><description>In the realm of power systems, the increasing involvement of residentialusers in load forecasting applications has heightened concerns about dataprivacy. Specifically, the load data can inadvertently reveal the dailyroutines of residential users, thereby posing a risk to their propertysecurity. While federated learning (FL) has been employed to safeguard userprivacy by enabling model training without the exchange of raw data, these FLmodels have shown vulnerabilities to emerging attack techniques, such as DeepLeakage from Gradients and poisoning attacks. To counteract these, we initiallyemploy a Secure-Aggregation (SecAgg) algorithm that leverages multipartycomputation cryptographic techniques to mitigate the risk of gradient leakage.However, the introduction of SecAgg necessitates the deployment of additionalsub-center servers for executing the multiparty computation protocol, therebyescalating computational complexity and reducing system robustness, especiallyin scenarios where one or more sub-centers are unavailable. To address thesechallenges, we introduce a Markovian Switching-based distributed trainingframework, the convergence of which is substantiated through rigoroustheoretical analysis. The Distributed Markovian Switching (DMS) topology showsstrong robustness towards the poisoning attacks as well. Case studies employingreal-world power system load data validate the efficacy of our proposedalgorithm. It not only significantly minimizes communication complexity butalso maintains accuracy levels comparable to traditional FL methods, therebyenhancing the scalability of our load forecasting algorithm.</description><author>Yi Dong, Yingjie Wang, Mariana Gama, Mustafa A. Mustafa, Geert Deconinck, Xiaowei Huang</author><pubDate>Fri, 02 Feb 2024 16:39:08 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.01546v1</guid></item><item><title>How to escape sharp minima with random perturbations</title><link>http://arxiv.org/abs/2305.15659v2</link><description>Modern machine learning applications have witnessed the remarkable success ofoptimization algorithms that are designed to find flat minima. Motivated bythis design choice, we undertake a formal study that (i) formulates the notionof flat minima, and (ii) studies the complexity of finding them. Specifically,we adopt the trace of the Hessian of the cost function as a measure offlatness, and use it to formally define the notion of approximate flat minima.Under this notion, we then analyze algorithms that find approximate flat minimaefficiently. For general cost functions, we discuss a gradient-based algorithmthat finds an approximate flat local minimum efficiently. The main component ofthe algorithm is to use gradients computed from randomly perturbed iterates toestimate a direction that leads to flatter minima. For the setting where thecost function is an empirical risk over training data, we present a fasteralgorithm that is inspired by a recently proposed practical algorithm calledsharpness-aware minimization, supporting its success in practice.</description><author>Kwangjun Ahn, Ali Jadbabaie, Suvrit Sra</author><pubDate>Fri, 02 Feb 2024 16:38:35 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.15659v2</guid></item><item><title>On the Identification and Optimization of Nonsmooth Superposition Operators in Semilinear Elliptic PDEs</title><link>http://arxiv.org/abs/2306.05185v2</link><description>We study an infinite-dimensional optimization problem that aims to identifythe Nemytskii operator in the nonlinear part of a prototypical semilinearelliptic partial differential equation (PDE) which minimizes the distancebetween the PDE-solution and a given desired state. In contrast to previousworks, we consider this identification problem in a low-regularity regime inwhich the function inducing the Nemytskii operator is a-priori only known to bean element of $H^1_{loc}(\mathbb{R})$. This makes the studied problem class asuitable point of departure for the rigorous analysis of training problems forlearning-informed PDEs in which an unknown superposition operator isapproximated by means of a neural network with nonsmooth activation functions(ReLU, leaky-ReLU, etc.). We establish that, despite the low regularity of thecontrols, it is possible to derive a classical stationarity system for localminimizers and to solve the considered problem by means of a gradientprojection method. The convergence of the resulting algorithm is proven in thefunction space setting. It is also shown that the established first-ordernecessary optimality conditions imply that locally optimal superpositionoperators share various characteristic properties with commonly used activationfunctions: They are always sigmoidal, continuously differentiable away from theorigin, and typically possess a distinct kink at zero. The paper concludes withnumerical experiments which confirm the theoretical findings.</description><author>Constantin Christof, Julia Kowalczyk</author><pubDate>Fri, 02 Feb 2024 16:37:31 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.05185v2</guid></item><item><title>Adaptive Optimization for Prediction with Missing Data</title><link>http://arxiv.org/abs/2402.01543v1</link><description>When training predictive models on data with missing entries, the most widelyused and versatile approach is a pipeline technique where we first imputemissing entries and then compute predictions. In this paper, we view predictionwith missing data as a two-stage adaptive optimization problem and propose anew class of models, adaptive linear regression models, where the regressioncoefficients adapt to the set of observed features. We show that some adaptivelinear regression models are equivalent to learning an imputation rule and adownstream linear regression model simultaneously instead of sequentially. Weleverage this joint-impute-then-regress interpretation to generalize ourframework to non-linear models. In settings where data is strongly not missingat random, our methods achieve a 2-10% improvement in out-of-sample accuracy.</description><author>Dimitris Bertsimas, Arthur Delarue, Jean Pauphilet</author><pubDate>Fri, 02 Feb 2024 16:35:51 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.01543v1</guid></item><item><title>Learning Collective Variables for Protein Folding with Labeled Data Augmentation through Geodesic Interpolation</title><link>http://arxiv.org/abs/2402.01542v1</link><description>In molecular dynamics (MD) simulations, rare events, such as protein folding,are typically studied by means of enhanced sampling techniques, most of whichrely on the definition of a collective variable (CV) along which theacceleration occurs. Obtaining an expressive CV is crucial, but often hinderedby the lack of information about the particular event, e.g., the transitionfrom unfolded to folded conformation. We propose a simulation-free dataaugmentation strategy using physics-inspired metrics to generate geodesicinterpolations resembling protein folding transitions, thereby improvingsampling efficiency without true transition state samples. Leveraginginterpolation progress parameters, we introduce a regression-based learningscheme for CV models, which outperforms classifier-based methods whentransition state data is limited and noisy</description><author>Soojung Yang, Juno Nam, Johannes C. B. Dietschreit, Rafael Gómez-Bombarelli</author><pubDate>Fri, 02 Feb 2024 16:35:02 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.01542v1</guid></item><item><title>Closing the Gap in Human Behavior Analysis: A Pipeline for Synthesizing Trimodal Data</title><link>http://arxiv.org/abs/2402.01537v1</link><description>In pervasive machine learning, especially in Human Behavior Analysis (HBA),RGB has been the primary modality due to its accessibility and richness ofinformation. However, linked with its benefits are challenges, includingsensitivity to lighting conditions and privacy concerns. One possibility toovercome these vulnerabilities is to resort to different modalities. Forinstance, thermal is particularly adept at accentuating human forms, whiledepth adds crucial contextual layers. Despite their known benefits, only a fewHBA-specific datasets that integrate these modalities exist. To address thisshortage, our research introduces a novel generative technique for creatingtrimodal, i.e., RGB, thermal, and depth, human-focused datasets. This techniquecapitalizes on human segmentation masks derived from RGB images, combined withthermal and depth backgrounds that are sourced automatically. With these twoingredients, we synthesize depth and thermal counterparts from existing RGBdata utilizing conditional image-to-image translation. By employing thisapproach, we generate trimodal data that can be leveraged to train models forsettings with limited data, bad lightning conditions, or privacy-sensitiveareas.</description><author>Christian Stippel, Thomas Heitzinger, Rafael Sterzinger, Martin Kampel</author><pubDate>Fri, 02 Feb 2024 16:27:45 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.01537v1</guid></item><item><title>Homogenization Effects of Large Language Models on Human Creative Ideation</title><link>http://arxiv.org/abs/2402.01536v1</link><description>Large language models (LLMs) are now being used in a wide variety ofcontexts, including as creativity support tools (CSTs) intended to help theirusers come up with new ideas. But do LLMs actually support user creativity? Wehypothesized that the use of an LLM as a CST might make the LLM's users feelmore creative, and even broaden the range of ideas suggested by each individualuser, but also homogenize the ideas suggested by different users. We conducteda 36-participant comparative user study and found, in accordance with thehomogenization hypothesis, that different users tended to produce lesssemantically distinct ideas with ChatGPT than with an alternative CST.Additionally, ChatGPT users generated a greater number of more detailed ideas,but felt less responsible for the ideas they generated. We discuss potentialimplications of these findings for users, designers, and developers ofLLM-based CSTs.</description><author>Barrett R. Anderson, Jash Hemant Shah, Max Kreminski</author><pubDate>Fri, 02 Feb 2024 16:27:11 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.01536v1</guid></item><item><title>An Empirical Analysis of Diversity in Argument Summarization</title><link>http://arxiv.org/abs/2402.01535v1</link><description>Presenting high-level arguments is a crucial task for fostering participationin online societal discussions. Current argument summarization approaches missan important facet of this task -- capturing diversity -- which is importantfor accommodating multiple perspectives. We introduce three aspects ofdiversity: those of opinions, annotators, and sources. We evaluate approachesto a popular argument summarization task called Key Point Analysis, which showshow these approaches struggle to (1) represent arguments shared by few people,(2) deal with data from various sources, and (3) align with subjectivity inhuman-provided annotations. We find that both general-purpose LLMs anddedicated KPA models exhibit this behavior, but have complementary strengths.Further, we observe that diversification of training data may ameliorategeneralization. Addressing diversity in argument summarization requires a mixof strategies to deal with subjectivity.</description><author>Michiel van der Meer, Piek Vossen, Catholijn M. Jonker, Pradeep K. Murukannaiah</author><pubDate>Fri, 02 Feb 2024 16:26:52 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.01535v1</guid></item><item><title>Online Variational Sequential Monte Carlo</title><link>http://arxiv.org/abs/2312.12616v2</link><description>Being the most classical generative model for serial data, state-space models(SSM) are fundamental in AI and statistical machine learning. In SSM, any formof parameter learning or latent state inference typically involves thecomputation of complex latent-state posteriors. In this work, we build upon thevariational sequential Monte Carlo (VSMC) method, which providescomputationally efficient and accurate model parameter estimation and Bayesianlatent-state inference by combining particle methods and variational inference.While standard VSMC operates in the offline mode, by re-processing repeatedly agiven batch of data, we distribute the approximation of the gradient of theVSMC surrogate ELBO in time using stochastic approximation, allowing for onlinelearning in the presence of streams of data. This results in an algorithm,online VSMC, that is capable of performing efficiently, entirely on-the-fly,both parameter estimation and particle proposal adaptation. In addition, weprovide rigorous theoretical results describing the algorithm's convergenceproperties as the number of data tends to infinity as well as numericalillustrations of its excellent convergence properties and usefulness also inbatch-processing settings.</description><author>Alessandro Mastrototaro, Jimmy Olsson</author><pubDate>Fri, 02 Feb 2024 16:24:14 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.12616v2</guid></item><item><title>Efficient and Effective Time-Series Forecasting with Spiking Neural Networks</title><link>http://arxiv.org/abs/2402.01533v1</link><description>Spiking neural networks (SNNs), inspired by the spiking behavior ofbiological neurons, provide a unique pathway for capturing the intricacies oftemporal data. However, applying SNNs to time-series forecasting is challengingdue to difficulties in effective temporal alignment, complexities in encodingprocesses, and the absence of standardized guidelines for model selection. Inthis paper, we propose a framework for SNNs in time-series forecasting tasks,leveraging the efficiency of spiking neurons in processing temporalinformation. Through a series of experiments, we demonstrate that our proposedSNN-based approaches achieve comparable or superior results to traditionaltime-series forecasting methods on diverse benchmarks with much less energyconsumption. Furthermore, we conduct detailed analysis experiments to assessthe SNN's capacity to capture temporal dependencies within time-series data,offering valuable insights into its nuanced strengths and effectiveness inmodeling the intricate dynamics of temporal data. Our study contributes to theexpanding field of SNNs and offers a promising alternative for time-seriesforecasting tasks, presenting a pathway for the development of morebiologically inspired and temporally aware forecasting models.</description><author>Changze Lv, Yansen Wang, Dongqi Han, Xiaoqing Zheng, Xuanjing Huang, Dongsheng Li</author><pubDate>Fri, 02 Feb 2024 16:23:50 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.01533v1</guid></item><item><title>Task Aware Dreamer for Task Generalization in Reinforcement Learning</title><link>http://arxiv.org/abs/2303.05092v3</link><description>A long-standing goal of reinforcement learning is to acquire agents that canlearn on training tasks and generalize well on unseen tasks that may share asimilar dynamic but with different reward functions. The ability to generalizeacross tasks is important as it determines an agent's adaptability toreal-world scenarios where reward mechanisms might vary. In this work, we firstshow that training a general world model can utilize similar structures inthese tasks and help train more generalizable agents. Extending world modelsinto the task generalization setting, we introduce a novel method named TaskAware Dreamer (TAD), which integrates reward-informed features to identifyconsistent latent characteristics across tasks. Within TAD, we compute thevariational lower bound of sample data log-likelihood, which introduces a newterm designed to differentiate tasks using their states, as the optimizationobjective of our reward-informed world models. To demonstrate the advantages ofthe reward-informed policy in TAD, we introduce a new metric called TaskDistribution Relevance (TDR) which quantitatively measures the relevance ofdifferent tasks. For tasks exhibiting a high TDR, i.e., the tasks differsignificantly, we illustrate that Markovian policies struggle to distinguishthem, thus it is necessary to utilize reward-informed policies in TAD.Extensive experiments in both image-based and state-based tasks show that TADcan significantly improve the performance of handling different taskssimultaneously, especially for those with high TDR, and display a stronggeneralization ability to unseen tasks.</description><author>Chengyang Ying, Zhongkai Hao, Xinning Zhou, Hang Su, Songming Liu, Dong Yan, Jun Zhu</author><pubDate>Fri, 02 Feb 2024 16:18:10 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2303.05092v3</guid></item><item><title>Decoding Speculative Decoding</title><link>http://arxiv.org/abs/2402.01528v1</link><description>Speculative Decoding is a widely used technique to speed up inference forLarge Language Models (LLMs) without modifying its outcome. When performinginference on an LLM, speculative decoding uses a smaller draft model whichgenerates speculative tokens and then uses the target LLM to verify those drafttokens. The speedup provided by speculative decoding heavily depends on thechoice of the draft model. It has been widely suggested to select a draft modelthat provides a high probability of the generated token being accepted by theLLM to achieve the highest throughput. However, our experiments indicate thecontrary with throughput diminishing as the probability of generated tokens tobe accepted by the target model increases. To understand this phenomenon, weperform extensive experiments to characterize the different factors that affectspeculative decoding and how those factors interact and affect the speedups.Based on our experiments we describe an analytical model which can be used todecide the right draft model for a given workload. Further, using our insightswe design a new draft model for LLaMA-65B which can provide 30% higherthroughput than existing draft models.</description><author>Minghao Yan, Saurabh Agarwal, Shivaram Venkataraman</author><pubDate>Fri, 02 Feb 2024 16:15:24 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.01528v1</guid></item><item><title>InstantID: Zero-shot Identity-Preserving Generation in Seconds</title><link>http://arxiv.org/abs/2401.07519v2</link><description>There has been significant progress in personalized image synthesis withmethods such as Textual Inversion, DreamBooth, and LoRA. Yet, their real-worldapplicability is hindered by high storage demands, lengthy fine-tuningprocesses, and the need for multiple reference images. Conversely, existing IDembedding-based methods, while requiring only a single forward inference, facechallenges: they either necessitate extensive fine-tuning across numerous modelparameters, lack compatibility with community pre-trained models, or fail tomaintain high face fidelity. Addressing these limitations, we introduceInstantID, a powerful diffusion model-based solution. Our plug-and-play moduleadeptly handles image personalization in various styles using just a singlefacial image, while ensuring high fidelity. To achieve this, we design a novelIdentityNet by imposing strong semantic and weak spatial conditions,integrating facial and landmark images with textual prompts to steer the imagegeneration. InstantID demonstrates exceptional performance and efficiency,proving highly beneficial in real-world applications where identitypreservation is paramount. Moreover, our work seamlessly integrates withpopular pre-trained text-to-image diffusion models like SD1.5 and SDXL, servingas an adaptable plugin. Our codes and pre-trained checkpoints will be availableat https://github.com/InstantID/InstantID.</description><author>Qixun Wang, Xu Bai, Haofan Wang, Zekui Qin, Anthony Chen, Huaxia Li, Xu Tang, Yao Hu</author><pubDate>Fri, 02 Feb 2024 16:15:22 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.07519v2</guid></item><item><title>Conditional Generative Representation for Black-Box Optimization with Implicit Constraints</title><link>http://arxiv.org/abs/2310.18449v2</link><description>Black-box optimization (BBO) has become increasingly relevant for tacklingcomplex decision-making problems, especially in public policy domains such aspolice districting. However, its broader application in public policymaking ishindered by the complexity of defining feasible regions and thehigh-dimensionality of decisions. This paper introduces a novel BBO framework,termed as the Conditional And Generative Black-box Optimization (CageBO). Thisapproach leverages a conditional variational autoencoder to learn thedistribution of feasible decisions, enabling a two-way mapping between theoriginal decision space and a simplified, constraint-free latent space. TheCageBO efficiently handles the implicit constraints often found in publicpolicy applications, allowing for optimization in the latent space whileevaluating objectives in the original space. We validate our method through acase study on large-scale police districting problems in Atlanta, Georgia. Ourresults reveal that our CageBO offers notable improvements in performance andefficiency compared to the baselines.</description><author>Wenqian Xing, Jungho Lee, Chong Liu, Shixiang Zhu</author><pubDate>Fri, 02 Feb 2024 16:14:01 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.18449v2</guid></item><item><title>HyperPlanes: Hypernetwork Approach to Rapid NeRF Adaptation</title><link>http://arxiv.org/abs/2402.01524v1</link><description>Neural radiance fields (NeRFs) are a widely accepted standard forsynthesizing new 3D object views from a small number of base images. However,NeRFs have limited generalization properties, which means that we need to usesignificant computational resources to train individual architectures for eachitem we want to represent. To address this issue, we propose a few-shotlearning approach based on the hypernetwork paradigm that does not requiregradient optimization during inference. The hypernetwork gathers informationfrom the training data and generates an update for universal weights. As aresult, we have developed an efficient method for generating a high-quality 3Dobject representation from a small number of images in a single step. This hasbeen confirmed by direct comparison with the state-of-the-art solutions and acomprehensive ablation study.</description><author>Paweł Batorski, Dawid Malarz, Marcin Przewięźlikowski, Marcin Mazur, Sławomir Tadeja, Przemysław Spurek</author><pubDate>Fri, 02 Feb 2024 16:10:29 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.01524v1</guid></item><item><title>K-Level Reasoning with Large Language Models</title><link>http://arxiv.org/abs/2402.01521v1</link><description>While Large Language Models (LLMs) have demonstrated their proficiency incomplex reasoning tasks, their performance in dynamic, interactive, andcompetitive scenarios - such as business strategy and stock market analysis -remains underexplored. To bridge this gap, we formally explore the dynamicreasoning capabilities of LLMs for decision-making in rapidly evolvingenvironments. We introduce two game theory-based pilot challenges that mirrorthe complexities of real-world dynamic decision-making. These challenges arewell-defined, enabling clear, controllable, and precise evaluation of LLMs'dynamic reasoning abilities. Through extensive experiments, we find thatexisting reasoning methods tend to falter in dynamic settings that requirek-level thinking - a key concept not tackled by previous works. To addressthis, we propose a novel reasoning approach for LLMs, named "K-LevelReasoning". This approach adopts the perspective of rivals to recursivelyemploy k-level thinking based on available historical information, whichsignificantly improves the prediction accuracy of rivals' subsequent moves andinforms more strategic decision-making. This research not only sets a robustquantitative benchmark for the assessment of dynamic reasoning but alsomarkedly enhances the proficiency of LLMs in dynamic contexts.</description><author>Yadong Zhang, Shaoguang Mao, Tao Ge, Xun Wang, Yan Xia, Man Lan, Furu Wei</author><pubDate>Fri, 02 Feb 2024 16:07:05 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.01521v1</guid></item><item><title>Low-Resource Cross-Domain Singing Voice Synthesis via Reduced Self-Supervised Speech Representations</title><link>http://arxiv.org/abs/2402.01520v1</link><description>In this paper, we propose a singing voice synthesis model, Karaoker-SSL, thatis trained only on text and speech data as a typical multi-speaker acousticmodel. It is a low-resource pipeline that does not utilize any singing dataend-to-end, since its vocoder is also trained on speech data. Karaoker-SSL isconditioned by self-supervised speech representations in an unsupervisedmanner. We preprocess these representations by selecting only a subset of theirtask-correlated dimensions. The conditioning module is indirectly guided tocapture style information during training by multi-tasking. This is achievedwith a Conformer-based module, which predicts the pitch from the acousticmodel's output. Thus, Karaoker-SSL allows singing voice synthesis withoutreliance on hand-crafted and domain-specific features. There are also norequirements for text alignments or lyrics timestamps. To refine the voicequality, we employ a U-Net discriminator that is conditioned on the targetspeaker and follows a Diffusion GAN training scheme.</description><author>Panos Kakoulidis, Nikolaos Ellinas, Georgios Vamvoukakis, Myrsini Christidou, Alexandra Vioni, Georgia Maniati, Junkwang Oh, Gunu Jho, Inchul Hwang, Pirros Tsiakoulis, Aimilios Chalamandaris</author><pubDate>Fri, 02 Feb 2024 16:06:24 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.01520v1</guid></item><item><title>Cross-view Masked Diffusion Transformers for Person Image Synthesis</title><link>http://arxiv.org/abs/2402.01516v1</link><description>We present X-MDPT (Cross-view Masked Diffusion Prediction Transformers), anovel diffusion model designed for pose-guided human image generation. X-MDPTdistinguishes itself by employing masked diffusion transformers that operate onlatent patches, a departure from the commonly-used Unet structures in existingworks. The model comprises three key modules: 1) a denoising diffusionTransformer, 2) an aggregation network that consolidates conditions into asingle vector for the diffusion process, and 3) a mask cross-prediction modulethat enhances representation learning with semantic information from thereference image. X-MDPT demonstrates scalability, improving FID, SSIM, andLPIPS with larger models. Despite its simple design, our model outperformsstate-of-the-art approaches on the DeepFashion dataset while exhibitingefficiency in terms of training parameters, training time, and inference speed.Our compact 33MB model achieves an FID of 7.42, surpassing a prior Unet latentdiffusion approach (FID 8.07) using only $11\times$ fewer parameters. Our bestmodel surpasses the pixel-based diffusion with $\frac{2}{3}$ of the parametersand achieves $5.43 \times$ faster inference.</description><author>Trung X. Pham, Zhang Kang, Chang D. Yoo</author><pubDate>Fri, 02 Feb 2024 15:57:13 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.01516v1</guid></item><item><title>Enhancing Stochastic Gradient Descent: A Unified Framework and Novel Acceleration Methods for Faster Convergence</title><link>http://arxiv.org/abs/2402.01515v1</link><description>Based on SGD, previous works have proposed many algorithms that have improvedconvergence speed and generalization in stochastic optimization, such as SGDm,AdaGrad, Adam, etc. However, their convergence analysis under non-convexconditions is challenging. In this work, we propose a unified framework toaddress this issue. For any first-order methods, we interpret the updateddirection $g_t$ as the sum of the stochastic subgradient $\nabla f_t(x_t)$ andan additional acceleration term $\frac{2|\langle v_t, \nabla f_t(x_t)\rangle|}{\|v_t\|_2^2} v_t$, thus we can discuss the convergence by analyzing$\langle v_t, \nabla f_t(x_t) \rangle$. Through our framework, we havediscovered two plug-and-play acceleration methods: \textbf{Reject Accelerating}and \textbf{Random Vector Accelerating}, we theoretically demonstrate thatthese two methods can directly lead to an improvement in convergence rate.</description><author>Yichuan Deng, Zhao Song, Chiwun Yang</author><pubDate>Fri, 02 Feb 2024 15:55:25 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.01515v1</guid></item><item><title>Mapping the Multiverse of Latent Representations</title><link>http://arxiv.org/abs/2402.01514v1</link><description>Echoing recent calls to counter reliability and robustness concerns inmachine learning via multiverse analysis, we present PRESTO, a principledframework for mapping the multiverse of machine-learning models that rely onlatent representations. Although such models enjoy widespread adoption, thevariability in their embeddings remains poorly understood, resulting inunnecessary complexity and untrustworthy representations. Our framework usespersistent homology to characterize the latent spaces arising from differentcombinations of diverse machine-learning methods, (hyper)parameterconfigurations, and datasets, allowing us to measure their pairwise(dis)similarity and statistically reason about their distributions. As wedemonstrate both theoretically and empirically, our pipeline preservesdesirable properties of collections of latent representations, and it can beleveraged to perform sensitivity analysis, detect anomalous embeddings, orefficiently and effectively navigate hyperparameter search spaces.</description><author>Jeremy Wayland, Corinna Coupette, Bastian Rieck</author><pubDate>Fri, 02 Feb 2024 15:54:53 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.01514v1</guid></item><item><title>Multilingual Gradient Word-Order Typology from Universal Dependencies</title><link>http://arxiv.org/abs/2402.01513v1</link><description>While information from the field of linguistic typology has the potential toimprove performance on NLP tasks, reliable typological data is a prerequisite.Existing typological databases, including WALS and Grambank, suffer frominconsistencies primarily caused by their categorical format. Furthermore,typological categorisations by definition differ significantly from thecontinuous nature of phenomena, as found in natural language corpora. In thispaper, we introduce a new seed dataset made up of continuous-valued data,rather than categorical data, that can better reflect the variability oflanguage. While this initial dataset focuses on word-order typology, we alsopresent the methodology used to create the dataset, which can be easily adaptedto generate data for a broader set of features and languages.</description><author>Emi Baylor, Esther Ploeger, Johannes Bjerva</author><pubDate>Fri, 02 Feb 2024 15:54:19 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.01513v1</guid></item><item><title>Distractor Generation for Multiple-Choice Questions: A Survey of Methods, Datasets, and Evaluation</title><link>http://arxiv.org/abs/2402.01512v1</link><description>Distractors are important in learning evaluation. This paper surveysdistractor generation tasks using English multiple-choice question datasets fortextual and multimodal contexts. In particular, this paper presents a thoroughliterature review of the recent studies on distractor generation tasks,discusses multiple choice components and their characteristics, analyzes therelated datasets, and summarizes the evaluation metrics of distractorgeneration. Our investigation reveals that more than half of datasets arehuman-generated from educational sources in specific domains such as Scienceand English, which are largely text-based, with a lack of open domain andmultimodal datasets.</description><author>Elaf Alhazmi, Quan Z. Sheng, Wei Emma Zhang, Munazza Zaib, Ahoud Alhazmi</author><pubDate>Fri, 02 Feb 2024 15:53:31 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.01512v1</guid></item><item><title>Simulation-based optimization of a production system topology -- a neural network-assisted genetic algorithm</title><link>http://arxiv.org/abs/2402.01511v1</link><description>There is an abundance of prior research on the optimization of productionsystems, but there is a research gap when it comes to optimizing whichcomponents should be included in a design, and how they should be connected. Toovercome this gap, a novel approach is presented for topology optimization ofproduction systems using a genetic algorithm (GA). This GA employssimilarity-based mutation and recombination for the creation of offspring, anddiscrete-event simulation for fitness evaluation. To reduce computational cost,an extension to the GA is presented in which a neural network functions as asurrogate model for simulation. Three types of neural networks are compared,and the type most effective as a surrogate model is chosen based on itsoptimization performance and computational cost. Both the unassisted GA and neural network-assisted GA are applied to anindustrial case study and a scalability case study. These show that bothapproaches are effective at finding the optimal solution in industrialsettings, and both scale well as the number of potential solutions increases,with the neural network-assisted GA having the better scalability of the two.</description><author>N. Paape, J. A. W. M. van Eekelen, M. A. Reniers</author><pubDate>Fri, 02 Feb 2024 15:52:10 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.01511v1</guid></item><item><title>Towards Efficient and Exact Optimization of Language Model Alignment</title><link>http://arxiv.org/abs/2402.00856v2</link><description>The alignment of language models with human preferences is vital for theirapplication in real-world tasks. The problem is formulated as optimizing themodel's policy to maximize the expected reward that reflects human preferenceswith minimal deviation from the initial policy. While considered as astraightforward solution, reinforcement learning (RL) suffers from highvariance in policy updates, which impedes efficient policy improvement.Recently, direct preference optimization (DPO) was proposed to directlyoptimize the policy from preference data. Though simple to implement, DPO isderived based on the optimal policy that is not assured to be achieved inpractice, which undermines its convergence to the intended solution. In this paper, we propose efficient exact optimization (EXO) of the alignmentobjective. We prove that EXO is guaranteed to optimize in the same direction asthe RL algorithms asymptotically for arbitary parametrization of the policy,while enables efficient optimization by circumventing the complexitiesassociated with RL algorithms. We compare our method to DPO with boththeoretical and empirical analyses, and further demonstrate the advantages ofour method over existing approaches on realistic human preference data.</description><author>Haozhe Ji, Cheng Lu, Yilin Niu, Pei Ke, Hongning Wang, Jun Zhu, Jie Tang, Minlie Huang</author><pubDate>Fri, 02 Feb 2024 15:50:10 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.00856v2</guid></item><item><title>The Role of Data Curation in Image Captioning</title><link>http://arxiv.org/abs/2305.03610v2</link><description>Image captioning models are typically trained by treating all samplesequally, neglecting to account for mismatched or otherwise difficult datapoints. In contrast, recent work has shown the effectiveness of training modelsby scheduling the data using curriculum learning strategies. This papercontributes to this direction by actively curating difficult samples indatasets without increasing the total number of samples. We explore the effectof using three data curation methods within the training process: completeremoval of an sample, caption replacement, or image replacement via atext-to-image generation model. Experiments on the Flickr30K and COCO datasetswith the BLIP and BEiT-3 models demonstrate that these curation methods doindeed yield improved image captioning models, underscoring their efficacy.</description><author>Wenyan Li, Jonas F. Lotz, Chen Qiu, Desmond Elliott</author><pubDate>Fri, 02 Feb 2024 15:46:42 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.03610v2</guid></item><item><title>A Hybrid Strategy for Chat Transcript Summarization</title><link>http://arxiv.org/abs/2402.01510v1</link><description>Text summarization is the process of condensing a piece of text to fewersentences, while still preserving its content. Chat transcript, in thiscontext, is a textual copy of a digital or online conversation between acustomer (caller) and agent(s). This paper presents an indigenously (locally)developed hybrid method that first combines extractive and abstractivesummarization techniques in compressing ill-punctuated or un-punctuated chattranscripts to produce more readable punctuated summaries and then optimizesthe overall quality of summarization through reinforcement learning. Extensivetesting, evaluations, comparisons, and validation have demonstrated theefficacy of this approach for large-scale deployment of chat transcriptsummarization, in the absence of manually generated reference (annotated)summaries.</description><author>Pratik K. Biswas</author><pubDate>Fri, 02 Feb 2024 15:44:28 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.01510v1</guid></item><item><title>Advancing Brain Tumor Inpainting with Generative Models</title><link>http://arxiv.org/abs/2402.01509v1</link><description>Synthesizing healthy brain scans from diseased brain scans offers a potentialsolution to address the limitations of general-purpose algorithms, such astissue segmentation and brain extraction algorithms, which may not effectivelyhandle diseased images. We consider this a 3D inpainting task and investigatethe adaptation of 2D inpainting methods to meet the requirements of 3D magneticresonance imaging(MRI) data. Our contributions encompass potentialmodifications tailored to MRI-specific needs, and we conducted evaluations ofmultiple inpainting techniques using the BraTS2023 Inpainting datasets toassess their efficacy and limitations.</description><author>Ruizhi Zhu, Xinru Zhang, Haowen Pang, Chundan Xu, Chuyang Ye</author><pubDate>Fri, 02 Feb 2024 15:43:51 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.01509v1</guid></item><item><title>An Algorithm to Train Unrestricted Sequential Discrete Morphological Neural Networks</title><link>http://arxiv.org/abs/2310.04584v2</link><description>There have been attempts to insert mathematical morphology (MM) operatorsinto convolutional neural networks (CNN), and the most successful endeavor todate has been the morphological neural networks (MNN). Although MNN haveperformed better than CNN in solving some problems, they inherit theirblack-box nature. Furthermore, in the case of binary images, they areapproximations that loose the Boolean lattice structure of MM operators and,thus, it is not possible to represent a specific class of W-operators withdesired properties. In a recent work, we proposed the Discrete MorphologicalNeural Networks (DMNN) for binary image transformation to represent specificclasses of W-operators and estimate them via machine learning. We also proposeda stochastic lattice descent algorithm (SLDA) to learn the parameters ofCanonical Discrete Morphological Neural Networks (CDMNN), whose architecture iscomposed only of operators that can be decomposed as the supremum, infimum, andcomplement of erosions and dilations. In this paper, we propose an algorithm tolearn unrestricted sequential DMNN, whose architecture is given by thecomposition of general W-operators. We illustrate the algorithm in a practicalexample.</description><author>Diego Marcondes, Mariana Feldman, Junior Barrera</author><pubDate>Fri, 02 Feb 2024 15:40:51 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.04584v2</guid></item><item><title>Code-Switched Language Identification is Harder Than You Think</title><link>http://arxiv.org/abs/2402.01505v1</link><description>Code switching (CS) is a very common phenomenon in written and spokencommunication but one that is handled poorly by many natural languageprocessing applications. Looking to the application of building CS corpora, weexplore CS language identification (LID) for corpus building. We make the taskmore realistic by scaling it to more languages and considering models withsimpler architectures for faster inference. We also reformulate the task as asentence-level multi-label tagging problem to make it more tractable. Havingdefined the task, we investigate three reasonable models for this task anddefine metrics which better reflect desired performance. We present empiricalevidence that no current approach is adequate and finally providerecommendations for future work in this area.</description><author>Laurie Burchell, Alexandra Birch, Robert P. Thompson, Kenneth Heafield</author><pubDate>Fri, 02 Feb 2024 15:38:47 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.01505v1</guid></item><item><title>Why do Random Forests Work? Understanding Tree Ensembles as Self-Regularizing Adaptive Smoothers</title><link>http://arxiv.org/abs/2402.01502v1</link><description>Despite their remarkable effectiveness and broad application, the drivers ofsuccess underlying ensembles of trees are still not fully understood. In thispaper, we highlight how interpreting tree ensembles as adaptive andself-regularizing smoothers can provide new intuition and deeper insight tothis topic. We use this perspective to show that, when studied as smoothers,randomized tree ensembles not only make predictions that are quantifiably moresmooth than the predictions of the individual trees they consist of, but alsofurther regulate their smoothness at test-time based on the dissimilaritybetween testing and training inputs. First, we use this insight to revisit,refine and reconcile two recent explanations of forest success by providing anew way of quantifying the conjectured behaviors of tree ensembles objectivelyby measuring the effective degree of smoothing they imply. Then, we move beyondexisting explanations for the mechanisms by which tree ensembles improve uponindividual trees and challenge the popular wisdom that the superior performanceof forests should be understood as a consequence of variance reduction alone.We argue that the current high-level dichotomy into bias- andvariance-reduction prevalent in statistics is insufficient to understand treeensembles -- because the prevailing definition of bias does not capturedifferences in the expressivity of the hypothesis classes formed by trees andforests. Instead, we show that forests can improve upon trees by three distinctmechanisms that are usually implicitly entangled. In particular, we demonstratethat the smoothing effect of ensembling can reduce variance in predictions dueto noise in outcome generation, reduce variability in the quality of thelearned function given fixed input data and reduce potential bias in learnablefunctions by enriching the available hypothesis space.</description><author>Alicia Curth, Alan Jeffares, Mihaela van der Schaar</author><pubDate>Fri, 02 Feb 2024 15:36:43 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.01502v1</guid></item><item><title>Developing and Evaluating a Design Method for Positive Artificial Intelligence</title><link>http://arxiv.org/abs/2402.01499v1</link><description>As artificial intelligence (AI) continues advancing, ensuring positivesocietal impacts becomes critical, especially as AI systems become increasinglyubiquitous in various aspects of life. However, developing "AI for good" posessubstantial challenges around aligning systems with complex human values.Presently, we lack mature methods for addressing these challenges. This articlepresents and evaluates the Positive AI design method aimed at addressing thisgap. The method provides a human-centered process to translate wellbeingaspirations into concrete practices. First, we explain the method's four keysteps: contextualizing, operationalizing, optimizing, and implementingwellbeing supported by continuous measurement for feedback cycles. We thenpresent a multiple case study where novice designers applied the method,revealing strengths and weaknesses related to efficacy and usability. Next, anexpert evaluation study assessed the quality of the resulting concepts, ratingthem moderately high for feasibility, desirability, and plausibility ofachieving intended wellbeing benefits. Together, these studies providepreliminary validation of the method's ability to improve AI design, whilesurfacing areas needing refinement like developing support for complex steps.Proposed adaptations such as examples and evaluation heuristics could addressweaknesses. Further research should examine sustained application over multipleprojects. This human-centered approach shows promise for realizing the visionof 'AI for Wellbeing' that does not just avoid harm, but actively benefitshumanity.</description><author>Willem van der Maden, Derek Lomas, Paul Hekkert</author><pubDate>Fri, 02 Feb 2024 15:31:08 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.01499v1</guid></item><item><title>Random Exploration in Bayesian Optimization: Order-Optimal Regret and Computational Efficiency</title><link>http://arxiv.org/abs/2310.15351v2</link><description>We consider Bayesian optimization using Gaussian Process models, alsoreferred to as kernel-based bandit optimization. We study the methodology ofexploring the domain using random samples drawn from a distribution. We showthat this random exploration approach achieves the optimal error rates. Ouranalysis is based on novel concentration bounds in an infinite dimensionalHilbert space established in this work, which may be of independent interest.We further develop an algorithm based on random exploration with domainshrinking and establish its order-optimal regret guarantees under bothnoise-free and noisy settings. In the noise-free setting, our analysis closesthe existing gap in regret performance and thereby resolves a COLT openproblem. The proposed algorithm also enjoys a computational advantage overprevailing methods due to the random exploration that obviates the expensiveoptimization of a non-convex acquisition function for choosing the query pointsat each iteration.</description><author>Sudeep Salgia, Sattar Vakili, Qing Zhao</author><pubDate>Fri, 02 Feb 2024 15:28:17 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.15351v2</guid></item><item><title>A Comparative Analysis of Conversational Large Language Models in Knowledge-Based Text Generation</title><link>http://arxiv.org/abs/2402.01495v1</link><description>Generating natural language text from graph-structured data is essential forconversational information seeking. Semantic triples derived from knowledgegraphs can serve as a valuable source for grounding responses fromconversational agents by providing a factual basis for the information theycommunicate. This is especially relevant in the context of large languagemodels, which offer great potential for conversational interaction but areprone to hallucinating, omitting, or producing conflicting information. In thisstudy, we conduct an empirical analysis of conversational large language modelsin generating natural language text from semantic triples. We compare fourlarge language models of varying sizes with different prompting techniques.Through a series of benchmark experiments on the WebNLG dataset, we analyze themodels' performance and identify the most common issues in the generatedpredictions. Our findings show that the capabilities of large language modelsin triple verbalization can be significantly improved through few-shotprompting, post-processing, and efficient fine-tuning techniques, particularlyfor smaller models that exhibit lower zero-shot performance.</description><author>Phillip Schneider, Manuel Klettner, Elena Simperl, Florian Matthes</author><pubDate>Fri, 02 Feb 2024 15:26:39 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.01495v1</guid></item><item><title>Are Normalizing Flows the Key to Unlocking the Exponential Mechanism? A Path through the Accuracy-Privacy Ceiling Constraining Differentially Private ML</title><link>http://arxiv.org/abs/2311.09200v3</link><description>The state of the art and de facto standard for differentially private machinelearning (ML) is differentially private stochastic gradient descent (DPSGD).Yet, the method is inherently wasteful. By adding noise to every gradient, itdiminishes the overall privacy with every gradient step. Despite 15 years offruitful research advancing the composition theorems, sub-sampling methods, andimplementation techniques, adequate accuracy and privacy is often unattainablewith current private ML methods. Meanwhile, the Exponential Mechanism (ExpM),designed for private optimization, has been historically sidelined fromprivately training modern ML algorithms primarily because ExpM requiressampling from a historically intractable density. Despite the recent discoveryof Normalizing Flow models (NFs), expressive deep networks for approximatingintractable distributions, ExpM remains in the background. Our position is thatleveraging NFs to circumvent historic obstructions of ExpM is a potentiallytransformational solution for differentially private ML worth attention. Weintroduce a new training method, ExpM+NF, as a potential alternative to DPSGD,and we provide experiment with logistic regression and a modern deep learningmodel to test whether training via ExpM+NF is viable with "good" privacyparameters. Under the assumption that the NF output distribution is the ExpMdistribution, we are able to achieve $\varepsilon$ a low as $1\mathrm{e}{-3}$-- three orders of magnitude stronger privacy with similar accuracy. This workoutlines a new avenue for advancing differentially private ML, namelydiscovering NF approximation guarantees. Code to be provided after review.</description><author>Robert A. Bridges, Vandy J. Tombs, Christopher B. Stanley</author><pubDate>Fri, 02 Feb 2024 15:23:17 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.09200v3</guid></item><item><title>Sliced-Wasserstein Estimation with Spherical Harmonics as Control Variates</title><link>http://arxiv.org/abs/2402.01493v1</link><description>The Sliced-Wasserstein (SW) distance between probability measures is definedas the average of the Wasserstein distances resulting for the associatedone-dimensional projections. As a consequence, the SW distance can be writtenas an integral with respect to the uniform measure on the sphere and the MonteCarlo framework can be employed for calculating the SW distance. Sphericalharmonics are polynomials on the sphere that form an orthonormal basis of theset of square-integrable functions on the sphere. Putting these two factstogether, a new Monte Carlo method, hereby referred to as Spherical HarmonicsControl Variates (SHCV), is proposed for approximating the SW distance usingspherical harmonics as control variates. The resulting approach is shown tohave good theoretical properties, e.g., a no-error property for Gaussianmeasures under a certain form of linear dependency between the variables.Moreover, an improved rate of convergence, compared to Monte Carlo, isestablished for general measures. The convergence analysis relies on theLipschitz property associated to the SW integrand. Several numericalexperiments demonstrate the superior performance of SHCV againststate-of-the-art methods for SW distance computation.</description><author>Rémi Leluc, Aymeric Dieuleveut, François Portier, Johan Segers, Aigerim Zhuman</author><pubDate>Fri, 02 Feb 2024 15:22:06 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.01493v1</guid></item><item><title>Connecting the Dots: Is Mode-Connectedness the Key to Feasible Sample-Based Inference in Bayesian Neural Networks?</title><link>http://arxiv.org/abs/2402.01484v1</link><description>A major challenge in sample-based inference (SBI) for Bayesian neuralnetworks is the size and structure of the networks' parameter space. Our workshows that successful SBI is possible by embracing the characteristicrelationship between weight and function space, uncovering a systematic linkbetween overparameterization and the difficulty of the sampling problem.Through extensive experiments, we establish practical guidelines for samplingand convergence diagnosis. As a result, we present a Bayesian deep ensembleapproach as an effective solution with competitive performance and uncertaintyquantification.</description><author>Emanuel Sommer, Lisa Wimmer, Theodore Papamarkou, Ludwig Bothmann, Bernd Bischl, David Rügamer</author><pubDate>Fri, 02 Feb 2024 15:12:16 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.01484v1</guid></item><item><title>Multi-level protein pre-training with Vabs-Net</title><link>http://arxiv.org/abs/2402.01481v1</link><description>In recent years, there has been a surge in the development of 3Dstructure-based pre-trained protein models, representing a significantadvancement over pre-trained protein language models in various downstreamtasks. However, most existing structure-based pre-trained models primarilyfocus on the residue level, i.e., alpha carbon atoms, while ignoring otheratoms like side chain atoms. We argue that modeling proteins at both residueand atom levels is important since the side chain atoms can also be crucial fornumerous downstream tasks, for example, molecular docking. Nevertheless, wefind that naively combining residue and atom information during pre-trainingtypically fails. We identify a key reason is the information leakage caused bythe inclusion of atom structure in the input, which renders residue-levelpre-training tasks trivial and results in insufficiently expressive residuerepresentations. To address this issue, we introduce a span mask pre-trainingstrategy on 3D protein chains to learn meaningful representations of bothresidues and atoms. This leads to a simple yet effective approach to learningprotein representation suitable for diverse downstream tasks. Extensiveexperimental results on binding site prediction and function prediction tasksdemonstrate our proposed pre-training approach significantly outperforms othermethods. Our code will be made public.</description><author>Jiale Zhao, Wanru Zhuang, Jia Song, Yaqi Li, Shuqi Lu</author><pubDate>Fri, 02 Feb 2024 15:07:09 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.01481v1</guid></item><item><title>Self-Attention through Kernel-Eigen Pair Sparse Variational Gaussian Processes</title><link>http://arxiv.org/abs/2402.01476v1</link><description>While the great capability of Transformers significantly boosts predictionaccuracy, it could also yield overconfident predictions and require calibrateduncertainty estimation, which can be commonly tackled by Gaussian processes(GPs). Existing works apply GPs with symmetric kernels under variationalinference to the attention kernel; however, omitting the fact that attentionkernels are in essence asymmetric. Moreover, the complexity of deriving the GPposteriors remains high for large-scale data. In this work, we proposeKernel-Eigen Pair Sparse Variational Gaussian Processes (KEP-SVGP) for buildinguncertainty-aware self-attention where the asymmetry of attention kernels istackled by Kernel SVD (KSVD) and a reduced complexity is acquired. ThroughKEP-SVGP, i) the SVGP pair induced by the two sets of singular vectors fromKSVD w.r.t. the attention kernel fully characterizes the asymmetry; ii) usingonly a small set of adjoint eigenfunctions from KSVD, the derivation of SVGPposteriors can be based on the inversion of a diagonal matrix containingsingular values, contributing to a reduction in time complexity; iii) anevidence lower bound is derived so that variational parameters can be optimizedtowards this objective. Experiments verify our excellent performances andefficiency on in-distribution, distribution-shift and out-of-distributionbenchmarks.</description><author>Yingyi Chen, Qinghua Tao, Francesco Tonin, Johan A. K. Suykens</author><pubDate>Fri, 02 Feb 2024 15:05:13 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.01476v1</guid></item><item><title>On the Convergence of Federated Averaging under Partial Participation for Over-parameterized Neural Networks</title><link>http://arxiv.org/abs/2310.05495v2</link><description>Federated learning (FL) is a widely employed distributed paradigm forcollaboratively training machine learning models from multiple clients withoutsharing local data. In practice, FL encounters challenges in dealing withpartial client participation due to the limited bandwidth, intermittentconnection and strict synchronized delay. Simultaneously, there exist fewtheoretical convergence guarantees in this practical setting, especially whenassociated with the non-convex optimization of neural networks. To bridge thisgap, we focus on the training problem of federated averaging (FedAvg) methodfor two canonical models: a deep linear network and a two-layer ReLU network.Under the over-parameterized assumption, we provably show that FedAvg convergesto a global minimum at a linear rate $\mathcal{O}\left((1-\frac{min_{i \in[t]}|S_i|}{N^2})^t\right)$ after $t$ iterations, where $N$ is the number ofclients and $|S_i|$ is the number of the participated clients in the $i$-thiteration. Experimental evaluations confirm our theoretical results.</description><author>Xin Liu, Wei li, Dazhi Zhan, Yu Pan, Xin Ma, Yu Ding, Zhisong Pan</author><pubDate>Fri, 02 Feb 2024 15:04:51 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.05495v2</guid></item><item><title>Higher-order accurate two-sample network inference and network hashing</title><link>http://arxiv.org/abs/2208.07573v3</link><description>Two-sample hypothesis testing for network comparison presents manysignificant challenges, including: leveraging repeated network observations andknown node registration, but without requiring them to operate; relaxing strongstructural assumptions; achieving finite-sample higher-order accuracy; handlingdifferent network sizes and sparsity levels; fast computation and memoryparsimony; controlling false discovery rate (FDR) in multiple testing; andtheoretical understandings, particularly regarding finite-sample accuracy andminimax optimality. In this paper, we develop a comprehensive toolbox,featuring a novel main method and its variants, all accompanied by strongtheoretical guarantees, to address these challenges. Our method outperformsexisting tools in speed and accuracy, and it is proved power-optimal. Ouralgorithms are user-friendly and versatile in handling various data structures(single or repeated network observations; known or unknown node registration).We also develop an innovative framework for offline hashing and fast queryingas a very useful tool for large network databases. We showcase theeffectiveness of our method through comprehensive simulations and applicationsto two real-world datasets, which revealed intriguing new structures.</description><author>Meijia Shao, Dong Xia, Yuan Zhang, Qiong Wu, Shuo Chen</author><pubDate>Fri, 02 Feb 2024 15:04:36 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2208.07573v3</guid></item></channel></rss>