<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/"><channel><title>Arxivfresh papers</title><link></link><description>Arxiv paper</description><language>en-US</language><lastBuildDate>Wed, 09 Oct 2024 13:00:11 GMT</lastBuildDate><generator>rfeed v1.0.0</generator><docs>https://github.com/svpino/rfeed/blob/master/README.md</docs><item><title>Fine-Tuning CLIP's Last Visual Projector: A Few-Shot Cornucopia</title><link>http://arxiv.org/abs/2410.05270v1</link><description>We consider the problem of adapting a contrastively pretrainedvision-language model like CLIP (Radford et al., 2021) for few-shotclassification. The existing literature addresses this problem by learning alinear classifier of the frozen visual features, optimizing word embeddings, orlearning external feature adapters. This paper introduces an alternative wayfor CLIP adaptation without adding 'external' parameters to optimize. We findthat simply fine-tuning the last projection matrix of the vision encoder leadsto strong performance compared to the existing baselines. Furthermore, we showthat regularizing training with the distance between the fine-tuned andpretrained matrices adds reliability for adapting CLIP through this layer.Perhaps surprisingly, this approach, coined ProLIP, yields performances on paror better than state of the art on 11 few-shot classification benchmarks,few-shot domain generalization, cross-dataset transfer and test-timeadaptation. Code will be made available athttps://github.com/astra-vision/ProLIP .</description><author>Mohammad Fahes, Tuan-Hung Vu, Andrei Bursuc, Patrick PÃ©rez, Raoul de Charette</author><pubDate>Mon, 07 Oct 2024 17:59:59 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.05270v1</guid></item><item><title>Data Advisor: Dynamic Data Curation for Safety Alignment of Large Language Models</title><link>http://arxiv.org/abs/2410.05269v1</link><description>Data is a crucial element in large language model (LLM) alignment. Recentstudies have explored using LLMs for efficient data collection. However,LLM-generated data often suffers from quality issues, with underrepresented orabsent aspects and low-quality datapoints. To address these problems, wepropose Data Advisor, an enhanced LLM-based method for generating data thattakes into account the characteristics of the desired dataset. Starting from aset of pre-defined principles in hand, Data Advisor monitors the status of thegenerated data, identifies weaknesses in the current dataset, and advises thenext iteration of data generation accordingly. Data Advisor can be easilyintegrated into existing data generation methods to enhance data quality andcoverage. Experiments on safety alignment of three representative LLMs (i.e.,Mistral, Llama2, and Falcon) demonstrate the effectiveness of Data Advisor inenhancing model safety against various fine-grained safety issues withoutsacrificing model utility.</description><author>Fei Wang, Ninareh Mehrabi, Palash Goyal, Rahul Gupta, Kai-Wei Chang, Aram Galstyan</author><pubDate>Mon, 07 Oct 2024 17:59:58 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.05269v1</guid></item><item><title>Grounding Partially-Defined Events in Multimodal Data</title><link>http://arxiv.org/abs/2410.05267v1</link><description>How are we able to learn about complex current events just from shortsnippets of video? While natural language enables straightforward ways torepresent under-specified, partially observable events, visual data does notfacilitate analogous methods and, consequently, introduces unique challenges inevent understanding. With the growing prevalence of vision-capable AI agents,these systems must be able to model events from collections of unstructuredvideo data. To tackle robust event modeling in multimodal settings, weintroduce a multimodal formulation for partially-defined events and cast theextraction of these events as a three-stage span retrieval task. We propose acorresponding benchmark for this task, MultiVENT-G, that consists of 14.5 hoursof densely annotated current event videos and 1,168 text documents, containing22.8K labeled event-centric entities. We propose a collection of LLM-drivenapproaches to the task of multimodal event analysis, and evaluate them onMultiVENT-G. Results illustrate the challenges that abstract eventunderstanding poses and demonstrates promise in event-centric video-languagesystems.</description><author>Kate Sanders, Reno Kriz, David Etter, Hannah Recknor, Alexander Martin, Cameron Carpenter, Jingyang Lin, Benjamin Van Durme</author><pubDate>Mon, 07 Oct 2024 17:59:48 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.05267v1</guid></item><item><title>Brain Mapping with Dense Features: Grounding Cortical Semantic Selectivity in Natural Images With Vision Transformers</title><link>http://arxiv.org/abs/2410.05266v1</link><description>Advances in large-scale artificial neural networks have facilitated novelinsights into the functional topology of the brain. Here, we leverage thisapproach to study how semantic categories are organized in the human visualcortex. To overcome the challenge presented by the co-occurrence of multiplecategories in natural images, we introduce BrainSAIL (Semantic Attribution andImage Localization), a method for isolating specific neurally-activating visualconcepts in images. BrainSAIL exploits semantically consistent, dense spatialfeatures from pre-trained vision models, building upon their demonstratedability to robustly predict neural activity. This method derives clean,spatially dense embeddings without requiring any additional training, andemploys a novel denoising process that leverages the semantic consistency ofimages under random augmentations. By unifying the space of whole-imageembeddings and dense visual features and then applying voxel-wise encodingmodels to these features, we enable the identification of specific subregionsof each image which drive selectivity patterns in different areas of the highervisual cortex. We validate BrainSAIL on cortical regions with known categoryselectivity, demonstrating its ability to accurately localize and disentangleselectivity to diverse visual concepts. Next, we demonstrate BrainSAIL'sability to characterize high-level visual selectivity to scene properties andlow-level visual features such as depth, luminance, and saturation, providinginsights into the encoding of complex visual information. Finally, we useBrainSAIL to directly compare the feature selectivity of different brainencoding models across different regions of interest in visual cortex. Ourinnovative method paves the way for significant advances in mapping anddecomposing high-level visual representations in the human brain.</description><author>Andrew F. Luo, Jacob Yeung, Rushikesh Zawar, Shaurya Dewan, Margaret M. Henderson, Leila Wehbe, Michael J. Tarr</author><pubDate>Mon, 07 Oct 2024 17:59:45 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.05266v1</guid></item><item><title>mDPO: Conditional Preference Optimization for Multimodal Large Language Models</title><link>http://arxiv.org/abs/2406.11839v2</link><description>Direct preference optimization (DPO) has shown to be an effective method forlarge language model (LLM) alignment. Recent works have attempted to apply DPOto multimodal scenarios but have found it challenging to achieve consistentimprovement. Through a comparative experiment, we identify the unconditionalpreference problem in multimodal preference optimization, where the modeloverlooks the image condition. To address this problem, we propose mDPO, amultimodal DPO objective that prevents the over-prioritization of language-onlypreferences by also optimizing image preference. Moreover, we introduce areward anchor that forces the reward to be positive for chosen responses,thereby avoiding the decrease in their likelihood -- an intrinsic problem ofrelative preference optimization. Experiments on two multimodal LLMs ofdifferent sizes and three widely used benchmarks demonstrate that mDPOeffectively addresses the unconditional preference problem in multimodalpreference optimization and significantly improves model performance,particularly in reducing hallucination.</description><author>Fei Wang, Wenxuan Zhou, James Y. Huang, Nan Xu, Sheng Zhang, Hoifung Poon, Muhao Chen</author><pubDate>Mon, 07 Oct 2024 17:59:42 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.11839v2</guid></item><item><title>PrefixQuant: Static Quantization Beats Dynamic through Prefixed Outliers in LLMs</title><link>http://arxiv.org/abs/2410.05265v1</link><description>Quantization is essential for deploying Large Language Models (LLMs) byenhancing memory efficiency and inference speed. Existing methods foractivation quantization mainly address channel-wise outliers, often neglectingtoken-wise outliers, leading to reliance on costly per-token dynamicquantization. To address this, we introduce PrefixQuant, a novel technique thatisolates outlier tokens offline without re-training. Specifically, PrefixQuantidentifies high-frequency outlier tokens and prefixes them in the KV cache,preventing the generation of outlier tokens during inference and simplifyingquantization. To our knowledge, PrefixQuant is the first to enable efficientper-tensor static quantization to outperform expensive per-token dynamicquantization. For instance, in W4A4KV4 (4- bit weight, 4-bit activation, and4-bit KV cache) Llama-3-8B, PrefixQuant with per-tensor static quantizationachieves a 7.43 WikiText2 perplexity and 71.08% average accuracy on 5common-sense reasoning tasks, outperforming previous per-token dynamicquantization methods like QuaRot with 0.98 perplexity improvement and +5.98points accuracy. Additionally, the inference speed of W4A4 quantized modelsusing PrefixQuant is 1.60x to 2.81x faster than FP16 models and exceeds QuaRotmodels by 1.2x to 1.3x. Our code is available at\url{https://github.com/ChenMnZ/PrefixQuant}.</description><author>Mengzhao Chen, Yi Liu, Jiahao Wang, Yi Bin, Wenqi Shao, Ping Luo</author><pubDate>Mon, 07 Oct 2024 17:59:35 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.05265v1</guid></item><item><title>Regression Conformal Prediction under Bias</title><link>http://arxiv.org/abs/2410.05263v1</link><description>Uncertainty quantification is crucial to account for the imperfectpredictions of machine learning algorithms for high-impact applications.Conformal prediction (CP) is a powerful framework for uncertaintyquantification that generates calibrated prediction intervals with validcoverage. In this work, we study how CP intervals are affected by bias - thesystematic deviation of a prediction from ground truth values - a phenomenonprevalent in many real-world applications. We investigate the influence of biason interval lengths of two different types of adjustments -- symmetricadjustments, the conventional method where both sides of the interval areadjusted equally, and asymmetric adjustments, a more flexible method where theinterval can be adjusted unequally in positive or negative directions. Wepresent theoretical and empirical analyses characterizing how symmetric andasymmetric adjustments impact the "tightness" of CP intervals for regressiontasks. Specifically for absolute residual and quantile-based non-conformityscores, we prove: 1) the upper bound of symmetrically adjusted interval lengthsincreases by $2|b|$ where $b$ is a globally applied scalar value representingbias, 2) asymmetrically adjusted interval lengths are not affected by bias, and3) conditions when asymmetrically adjusted interval lengths are guaranteed tobe smaller than symmetric ones. Our analyses suggest that even if predictionsexhibit significant drift from ground truth values, asymmetrically adjustedintervals are still able to maintain the same tightness and validity ofintervals as if the drift had never happened, while symmetric onessignificantly inflate the lengths. We demonstrate our theoretical results withtwo real-world prediction tasks: sparse-view computed tomography (CT)reconstruction and time-series weather forecasting. Our work paves the way formore bias-robust machine learning systems.</description><author>Matt Y. Cheung, Tucker J. Netherton, Laurence E. Court, Ashok Veeraraghavan, Guha Balakrishnan</author><pubDate>Mon, 07 Oct 2024 17:59:09 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.05263v1</guid></item><item><title>TurtleBench: Evaluating Top Language Models via Real-World Yes/No Puzzles</title><link>http://arxiv.org/abs/2410.05262v1</link><description>As the application of Large Language Models (LLMs) expands, the demand forreliable evaluations increases. Existing LLM evaluation benchmarks primarilyrely on static datasets, making it challenging to assess model performance indynamic interactions with users. Moreover, these benchmarks often depend onspecific background knowledge, complicating the measurement of a model'slogical reasoning capabilities. Other dynamic evaluation methods based onstrong models or manual efforts may introduce biases and incur high costs andtime demands, hindering large-scale application. To address these issues, wepropose TurtleBench. TurtleBench collects real user guesses from our onlineTurtle Soup Puzzle platform that we developed. This approach allows for therelatively dynamic generation of evaluation datasets, mitigating the risk ofmodel cheating while aligning assessments more closely with genuine user needsfor reasoning capabilities, thus enhancing the reliability of evaluations.TurtleBench includes 1,532 user guesses along with the correctness of guessesafter annotation. Using this dataset, we thoroughly evaluated nine of the mostadvanced LLMs available today. Notably, the OpenAI o1 series models did notachieve leading results in these evaluations. We propose several hypotheses forfurther research, such as "the latent reasoning of o1 utilizes trivialChain-of-Thought (CoT) techniques" and "increasing CoT length not only providesreasoning benefits but also incurs noise costs."</description><author>Qingchen Yu, Shichao Song, Ke Fang, Yunfeng Shi, Zifan Zheng, Hanyu Wang, Simin Niu, Zhiyu Li</author><pubDate>Mon, 07 Oct 2024 17:58:47 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.05262v1</guid></item><item><title>TextHawk2: A Large Vision-Language Model Excels in Bilingual OCR and Grounding with 16x Fewer Tokens</title><link>http://arxiv.org/abs/2410.05261v1</link><description>Reading dense text and locating objects within images are fundamentalabilities for Large Vision-Language Models (LVLMs) tasked with advanced jobs.Previous LVLMs, including superior proprietary models like GPT-4o, havestruggled to excel in both tasks simultaneously. Moreover, previous LVLMs withfine-grained perception cost thousands of tokens per image, making themresource-intensive. We present TextHawk2, a bilingual LVLM featuring efficientfine-grained perception and demonstrating cutting-edge performance acrossgeneral-purpose, OCR, and grounding tasks with 16 times fewer image tokens.Critical improvements include: (1) Token Compression: Building on the efficientarchitecture of its predecessor, TextHawk2 significantly reduces the number oftokens per image by 16 times, facilitating training and deployment of theTextHawk series with minimal resources. (2) Visual Encoder Reinforcement: Weenhance the visual encoder through LVLM co-training, unlocking its potentialfor previously unseen tasks like Chinese OCR and grounding. (3) Data Diversity:We maintain a comparable scale of 100 million samples while diversifying thesources of pre-training data. We assess TextHawk2 across multiple benchmarks,where it consistently delivers superior performance and outperformsclosed-source models of similar scale, such as achieving 78.4% accuracy onOCRBench, 81.4% accuracy on ChartQA, 89.6% ANLS on DocVQA, and 88.1%accuracy@0.5 on RefCOCOg-test.</description><author>Ya-Qi Yu, Minghui Liao, Jiwen Zhang, Jihao Wu</author><pubDate>Mon, 07 Oct 2024 17:58:35 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.05261v1</guid></item><item><title>DART: A Diffusion-Based Autoregressive Motion Model for Real-Time Text-Driven Motion Control</title><link>http://arxiv.org/abs/2410.05260v1</link><description>Text-conditioned human motion generation, which allows for user interactionthrough natural language, has become increasingly popular. Existing methodstypically generate short, isolated motions based on a single input sentence.However, human motions are continuous and can extend over long periods,carrying rich semantics. Creating long, complex motions that precisely respondto streams of text descriptions, particularly in an online and real-timesetting, remains a significant challenge. Furthermore, incorporating spatialconstraints into text-conditioned motion generation presents additionalchallenges, as it requires aligning the motion semantics specified by textdescriptions with geometric information, such as goal locations and 3D scenegeometry. To address these limitations, we propose DART, a Diffusion-basedAutoregressive motion primitive model for Real-time Text-driven motion control.Our model, DART, effectively learns a compact motion primitive space jointlyconditioned on motion history and text inputs using latent diffusion models. Byautoregressively generating motion primitives based on the preceding historyand current text input, DART enables real-time, sequential motion generationdriven by natural language descriptions. Additionally, the learned motionprimitive space allows for precise spatial motion control, which we formulateeither as a latent noise optimization problem or as a Markov decision processaddressed through reinforcement learning. We present effective algorithms forboth approaches, demonstrating our model's versatility and superior performancein various motion synthesis tasks. Experiments show our method outperformsexisting baselines in motion realism, efficiency, and controllability. Videoresults are available on the project page: https://zkf1997.github.io/DART/.</description><author>Kaifeng Zhao, Gen Li, Siyu Tang</author><pubDate>Mon, 07 Oct 2024 17:58:22 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.05260v1</guid></item><item><title>GS-VTON: Controllable 3D Virtual Try-on with Gaussian Splatting</title><link>http://arxiv.org/abs/2410.05259v1</link><description>Diffusion-based 2D virtual try-on (VTON) techniques have recentlydemonstrated strong performance, while the development of 3D VTON has largelylagged behind. Despite recent advances in text-guided 3D scene editing,integrating 2D VTON into these pipelines to achieve vivid 3D VTON remainschallenging. The reasons are twofold. First, text prompts cannot providesufficient details in describing clothing. Second, 2D VTON results generatedfrom different viewpoints of the same 3D scene lack coherence and spatialrelationships, hence frequently leading to appearance inconsistencies andgeometric distortions. To resolve these problems, we introduce animage-prompted 3D VTON method (dubbed GS-VTON) which, by leveraging 3D GaussianSplatting (3DGS) as the 3D representation, enables the transfer of pre-trainedknowledge from 2D VTON models to 3D while improving cross-view consistency. (1)Specifically, we propose a personalized diffusion model that utilizes low-rankadaptation (LoRA) fine-tuning to incorporate personalized information intopre-trained 2D VTON models. To achieve effective LoRA training, we introduce areference-driven image editing approach that enables the simultaneous editingof multi-view images while ensuring consistency. (2) Furthermore, we propose apersona-aware 3DGS editing framework to facilitate effective editing whilemaintaining consistent cross-view appearance and high-quality 3D geometry. (3)Additionally, we have established a new 3D VTON benchmark, 3D-VTONBench, whichfacilitates comprehensive qualitative and quantitative 3D VTON evaluations.Through extensive experiments and comparative analyses with existing methods,the proposed \OM has demonstrated superior fidelity and advanced editingcapabilities, affirming its effectiveness for 3D VTON.</description><author>Yukang Cao, Masoud Hadi, Liang Pan, Ziwei Liu</author><pubDate>Mon, 07 Oct 2024 17:58:20 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.05259v1</guid></item><item><title>Differential Transformer</title><link>http://arxiv.org/abs/2410.05258v1</link><description>Transformer tends to overallocate attention to irrelevant context. In thiswork, we introduce Diff Transformer, which amplifies attention to the relevantcontext while canceling noise. Specifically, the differential attentionmechanism calculates attention scores as the difference between two separatesoftmax attention maps. The subtraction cancels noise, promoting the emergenceof sparse attention patterns. Experimental results on language modeling showthat Diff Transformer outperforms Transformer in various settings of scaling upmodel size and training tokens. More intriguingly, it offers notable advantagesin practical applications, such as long-context modeling, key informationretrieval, hallucination mitigation, in-context learning, and reduction ofactivation outliers. By being less distracted by irrelevant context, DiffTransformer can mitigate hallucination in question answering and textsummarization. For in-context learning, Diff Transformer not only enhancesaccuracy but is also more robust to order permutation, which was considered asa chronic robustness issue. The results position Diff Transformer as a highlyeffective and promising architecture to advance large language models.</description><author>Tianzhu Ye, Li Dong, Yuqing Xia, Yutao Sun, Yi Zhu, Gao Huang, Furu Wei</author><pubDate>Mon, 07 Oct 2024 17:57:38 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.05258v1</guid></item><item><title>SePPO: Semi-Policy Preference Optimization for Diffusion Alignment</title><link>http://arxiv.org/abs/2410.05255v1</link><description>Reinforcement learning from human feedback (RLHF) methods are emerging as away to fine-tune diffusion models (DMs) for visual generation. However,commonly used on-policy strategies are limited by the generalization capabilityof the reward model, while off-policy approaches require large amounts ofdifficult-to-obtain paired human-annotated data, particularly in visualgeneration tasks. To address the limitations of both on- and off-policy RLHF,we propose a preference optimization method that aligns DMs with preferenceswithout relying on reward models or paired human-annotated data. Specifically,we introduce a Semi-Policy Preference Optimization (SePPO) method. SePPOleverages previous checkpoints as reference models while using them to generateon-policy reference samples, which replace "losing images" in preference pairs.This approach allows us to optimize using only off-policy "winning images."Furthermore, we design a strategy for reference model selection that expandsthe exploration in the policy space. Notably, we do not simply treat referencesamples as negative examples for learning. Instead, we design an anchor-basedcriterion to assess whether the reference samples are likely to be winning orlosing images, allowing the model to selectively learn from the generatedreference samples. This approach mitigates performance degradation caused bythe uncertainty in reference sample quality. We validate SePPO across bothtext-to-image and text-to-video benchmarks. SePPO surpasses all previousapproaches on the text-to-image benchmarks and also demonstrates outstandingperformance on the text-to-video benchmarks. Code will be released inhttps://github.com/DwanZhang-AI/SePPO.</description><author>Daoan Zhang, Guangchen Lan, Dong-Jun Han, Wenlin Yao, Xiaoman Pan, Hongming Zhang, Mingxiao Li, Pengcheng Chen, Yu Dong, Christopher Brinton, Jiebo Luo</author><pubDate>Mon, 07 Oct 2024 17:56:53 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.05255v1</guid></item><item><title>GLEE: A Unified Framework and Benchmark for Language-based Economic Environments</title><link>http://arxiv.org/abs/2410.05254v1</link><description>Large Language Models (LLMs) show significant potential in economic andstrategic interactions, where communication via natural language is oftenprevalent. This raises key questions: Do LLMs behave rationally? Can they mimichuman behavior? Do they tend to reach an efficient and fair outcome? What isthe role of natural language in the strategic interaction? How docharacteristics of the economic environment influence these dynamics? Thesequestions become crucial concerning the economic and societal implications ofintegrating LLM-based agents into real-world data-driven systems, such asonline retail platforms and recommender systems. While the ML community hasbeen exploring the potential of LLMs in such multi-agent setups, varyingassumptions, design choices and evaluation criteria across studies make itdifficult to draw robust and meaningful conclusions. To address this, weintroduce a benchmark for standardizing research on two-player, sequential,language-based games. Inspired by the economic literature, we define three basefamilies of games with consistent parameterization, degrees of freedom andeconomic measures to evaluate agents' performance (self-gain), as well as thegame outcome (efficiency and fairness). We develop an open-source framework forinteraction simulation and analysis, and utilize it to collect a dataset of LLMvs. LLM interactions across numerous game configurations and an additionaldataset of human vs. LLM interactions. Through extensive experimentation, wedemonstrate how our framework and dataset can be used to: (i) compare thebehavior of LLM-based agents to human players in various economic contexts;(ii) evaluate agents in both individual and collective performance measures;and (iii) quantify the effect of the economic characteristics of theenvironments on the behavior of agents.</description><author>Eilam Shapira, Omer Madmon, Itamar Reinman, Samuel Joseph Amouyal, Roi Reichart, Moshe Tennenholtz</author><pubDate>Mon, 07 Oct 2024 17:55:35 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.05254v1</guid></item><item><title>Causal Micro-Narratives</title><link>http://arxiv.org/abs/2410.05252v1</link><description>We present a novel approach to classify causal micro-narratives from text.These narratives are sentence-level explanations of the cause(s) and/oreffect(s) of a target subject. The approach requires only a subject-specificontology of causes and effects, and we demonstrate it with an application toinflation narratives. Using a human-annotated dataset spanning historical andcontemporary US news articles for training, we evaluate several large languagemodels (LLMs) on this multi-label classification task. The best-performingmodel--a fine-tuned Llama 3.1 8B--achieves F1 scores of 0.87 on narrativedetection and 0.71 on narrative classification. Comprehensive error analysisreveals challenges arising from linguistic ambiguity and highlights how modelerrors often mirror human annotator disagreements. This research establishes aframework for extracting causal micro-narratives from real-world data, withwide-ranging applications to social science research.</description><author>Mourad Heddaya, Qingcheng Zeng, Chenhao Tan, Rob Voigt, Alexander Zentefis</author><pubDate>Mon, 07 Oct 2024 17:55:10 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.05252v1</guid></item><item><title>LoTLIP: Improving Language-Image Pre-training for Long Text Understanding</title><link>http://arxiv.org/abs/2410.05249v1</link><description>Understanding long text is of great demands in practice but beyond the reachof most language-image pre-training (LIP) models. In this work, we empiricallyconfirm that the key reason causing such an issue is that the training imagesare usually paired with short captions, leaving certain tokens easilyovershadowed by salient tokens. Towards this problem, our initial attempt is torelabel the data with long captions, however, directly learning with which maylead to performance degradation in understanding short text (e.g., in the imageclassification task). Then, after incorporating corner tokens to aggregatediverse textual information, we manage to help the model catch up to itsoriginal level of short text understanding yet greatly enhance its capabilityof long text understanding. We further look into whether the model cancontinuously benefit from longer captions and notice a clear trade-off betweenthe performance and the efficiency. Finally, we validate the effectiveness ofour approach using a self-constructed large-scale dataset, which consists of100M long caption oriented text-image pairs. It is noteworthy that, on the taskof long-text image retrieval, we beat the competitor using long captions with11.1% improvement (i.e., from 72.62% to 83.72%). We will release the code, themodel, and the new dataset to facilitate the reproducibility and furtherresearch. The project page is available at https://wuw2019.github.io/lotlip.</description><author>Wei Wu, Kecheng Zheng, Shuailei Ma, Fan Lu, Yuxin Guo, Yifei Zhang, Wei Chen, Qingpei Guo, Yujun Shen, Zheng-Jun Zha</author><pubDate>Mon, 07 Oct 2024 17:52:56 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.05249v1</guid></item><item><title>SFTMix: Elevating Language Model Instruction Tuning with Mixup Recipe</title><link>http://arxiv.org/abs/2410.05248v1</link><description>To induce desired behaviors in large language models (LLMs) forinteraction-driven tasks, the instruction-tuning stage typically trains LLMs oninstruction-response pairs using the next-token prediction (NTP) loss. Previouswork aiming to improve instruction-tuning performance often emphasizes the needfor higher-quality supervised fine-tuning (SFT) datasets, which typicallyinvolves expensive data filtering with proprietary LLMs or labor-intensive datageneration by human annotators. However, these approaches do not fully leveragethe datasets' intrinsic properties, resulting in high computational and laborcosts, thereby limiting scalability and performance gains. In this paper, wepropose SFTMix, a novel recipe that elevates instruction-tuning performancebeyond the conventional NTP paradigm, without the need for well-curateddatasets. Observing that LLMs exhibit uneven confidence across the semanticrepresentation space, we argue that examples with different confidence levelsshould play distinct roles during the instruction-tuning process. Based on thisinsight, SFTMix leverages training dynamics to identify examples with varyingconfidence levels, then applies a Mixup-based regularization to mitigateoverfitting on confident examples while propagating supervision signals toimprove learning on relatively unconfident ones. This approach enables SFTMixto significantly outperform NTP across a wide range of instruction-followingand healthcare domain-specific SFT tasks, demonstrating its adaptability todiverse LLM families and scalability to datasets of any size. Comprehensiveablation studies further verify the robustness of SFTMix's design choices,underscoring its versatility in consistently enhancing performance acrossdifferent LLMs and datasets in broader natural language processingapplications.</description><author>Yuxin Xiao, Shujian Zhang, Wenxuan Zhou, Marzyeh Ghassemi, Sanqiang Zhao</author><pubDate>Mon, 07 Oct 2024 17:52:21 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.05248v1</guid></item><item><title>SoK: Membership Inference Attacks on LLMs are Rushing Nowhere (and How to Fix It)</title><link>http://arxiv.org/abs/2406.17975v2</link><description>Whether LLMs memorize their training data and what this means, from privacyleakage to detecting copyright violations -- has become a rapidly growing areaof research over the last two years. In recent months, more than 10 new methodshave been proposed to perform Membership Inference Attacks (MIAs) against LLMs.Contrary to traditional MIAs which rely on fixed -- but randomized -- recordsor models, these methods are mostly evaluated on datasets collected post-hoc.Sets of members and non-members, used to evaluate the MIA, are constructedusing informed guesses after the release of a model. This lack of randomizationraises concerns of a distribution shift between members and non-members. In thefirst part, we review the literature on MIAs against LLMs. While most workfocuses on sequence-level MIAs evaluated in post-hoc setups, we show that arange of target models, motivations and units of interest have been consideredin the literature. We then quantify distribution shifts present in the 6datasets used in the literature, ranging from books to papers, using a bag ofword classifier. Our analysis reveals that all of them suffer from severedistribution shifts. This challenges the validity of using such setups tomeasure LLM memorization and may undermine the benchmarking of recentlyproposed methods. Yet, all hope might not be lost. In the second part, weintroduce important considerations to properly evaluate MIAs against LLMs anddiscuss potential ways forward: randomized test splits, injections ofrandomized (unique) sequences, randomized finetuning, and post-hoc controlmethods. While each option comes with its advantages and limitations, webelieve they collectively provide solid grounds to guide the development of MIAmethods and study LLM memorization. We conclude by proposing comprehensive,easy-to-use benchmarks for sequence- and document-level MIAs against LLMs.</description><author>Matthieu Meeus, Igor Shilov, Shubham Jain, Manuel Faysse, Marek Rei, Yves-Alexandre de Montjoye</author><pubDate>Mon, 07 Oct 2024 17:49:13 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.17975v2</guid></item><item><title>Navigating the Digital World as Humans Do: Universal Visual Grounding for GUI Agents</title><link>http://arxiv.org/abs/2410.05243v1</link><description>Multimodal large language models (MLLMs) are transforming the capabilities ofgraphical user interface (GUI) agents, facilitating their transition fromcontrolled simulations to complex, real-world applications across variousplatforms. However, the effectiveness of these agents hinges on the robustnessof their grounding capability. Current GUI agents predominantly utilizetext-based representations such as HTML or accessibility trees, which, despitetheir utility, often introduce noise, incompleteness, and increasedcomputational overhead. In this paper, we advocate a human-like embodiment forGUI agents that perceive the environment entirely visually and directly takepixel-level operations on the GUI. The key is visual grounding models that canaccurately map diverse referring expressions of GUI elements to theircoordinates on the GUI across different platforms. We show that a simplerecipe, which includes web-based synthetic data and slight adaptation of theLLaVA architecture, is surprisingly effective for training such visualgrounding models. We collect the largest dataset for GUI visual grounding sofar, containing 10M GUI elements and their referring expressions over 1.3Mscreenshots, and use it to train UGround, a strong universal visual groundingmodel for GUI agents. Empirical results on six benchmarks spanning threecategories (grounding, offline agent, and online agent) show that 1) UGroundsubstantially outperforms existing visual grounding models for GUI agents, byup to 20% absolute, and 2) agents with UGround outperform state-of-the-artagents, despite the fact that existing agents use additional text-based inputwhile ours only uses visual perception. These results provide strong supportfor the feasibility and promises of GUI agents that navigate the digital worldas humans do.</description><author>Boyu Gou, Ruohan Wang, Boyuan Zheng, Yanan Xie, Cheng Chang, Yiheng Shu, Huan Sun, Yu Su</author><pubDate>Mon, 07 Oct 2024 17:47:50 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.05243v1</guid></item><item><title>MMLU-Pro: A More Robust and Challenging Multi-Task Language Understanding Benchmark (Published at NeurIPS 2024 Track Datasets and Benchmarks)</title><link>http://arxiv.org/abs/2406.01574v5</link><description>In the age of large-scale language models, benchmarks like the MassiveMultitask Language Understanding (MMLU) have been pivotal in pushing theboundaries of what AI can achieve in language comprehension and reasoningacross diverse domains. However, as models continue to improve, theirperformance on these benchmarks has begun to plateau, making it increasinglydifficult to discern differences in model capabilities. This paper introducesMMLU-Pro, an enhanced dataset designed to extend the mostly knowledge-drivenMMLU benchmark by integrating more challenging, reasoning-focused questions andexpanding the choice set from four to ten options. Additionally, MMLU-Proeliminates the trivial and noisy questions in MMLU. Our experimental resultsshow that MMLU-Pro not only raises the challenge, causing a significant drop inaccuracy by 16% to 33% compared to MMLU but also demonstrates greater stabilityunder varying prompts. With 24 different prompt styles tested, the sensitivityof model scores to prompt variations decreased from 4-5% in MMLU to just 2% inMMLU-Pro. Additionally, we found that models utilizing Chain of Thought (CoT)reasoning achieved better performance on MMLU-Pro compared to direct answering,which is in stark contrast to the findings on the original MMLU, indicatingthat MMLU-Pro includes more complex reasoning questions. Our assessmentsconfirm that MMLU-Pro is a more discriminative benchmark to better trackprogress in the field.</description><author>Yubo Wang, Xueguang Ma, Ge Zhang, Yuansheng Ni, Abhranil Chandra, Shiguang Guo, Weiming Ren, Aaran Arulraj, Xuan He, Ziyan Jiang, Tianle Li, Max Ku, Kai Wang, Alex Zhuang, Rongqi Fan, Xiang Yue, Wenhu Chen</author><pubDate>Mon, 07 Oct 2024 17:46:08 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.01574v5</guid></item><item><title>TuneVLSeg: Prompt Tuning Benchmark for Vision-Language Segmentation Models</title><link>http://arxiv.org/abs/2410.05239v1</link><description>Vision-Language Models (VLMs) have shown impressive performance in visiontasks, but adapting them to new domains often requires expensive fine-tuning.Prompt tuning techniques, including textual, visual, and multimodal prompting,offer efficient alternatives by leveraging learnable prompts. However, theirapplication to Vision-Language Segmentation Models (VLSMs) and evaluation undersignificant domain shifts remain unexplored. This work presents an open-sourcebenchmarking framework, TuneVLSeg, to integrate various unimodal and multimodalprompt tuning techniques into VLSMs, making prompt tuning usable for downstreamsegmentation datasets with any number of classes. TuneVLSeg includes $6$ prompttuning strategies on various prompt depths used in $2$ VLSMs totaling of $8$different combinations. We test various prompt tuning on $8$ diverse medicaldatasets, including $3$ radiology datasets (breast tumor, echocardiograph,chest X-ray pathologies) and $5$ non-radiology datasets (polyp, ulcer, skincancer), and two natural domain segmentation datasets. Our study found thattextual prompt tuning struggles under significant domain shifts, fromnatural-domain images to medical data. Furthermore, visual prompt tuning, withfewer hyperparameters than multimodal prompt tuning, often achieves performancecompetitive to multimodal approaches, making it a valuable first attempt. Ourwork advances the understanding and applicability of different prompt-tuningtechniques for robust domain-specific segmentation. The source code isavailable at https://github.com/naamiinepal/tunevlseg.</description><author>Rabin Adhikari, Safal Thapaliya, Manish Dhakal, Bishesh Khanal</author><pubDate>Mon, 07 Oct 2024 17:42:53 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.05239v1</guid></item><item><title>CasiMedicos-Arg: A Medical Question Answering Dataset Annotated with Explanatory Argumentative Structures</title><link>http://arxiv.org/abs/2410.05235v1</link><description>Explaining Artificial Intelligence (AI) decisions is a major challengenowadays in AI, in particular when applied to sensitive scenarios like medicineand law. However, the need to explain the rationale behind decisions is a mainissue also for human-based deliberation as it is important to justify\textit{why} a certain decision has been taken. Resident medical doctors forinstance are required not only to provide a (possibly correct) diagnosis, butalso to explain how they reached a certain conclusion. Developing new tools toaid residents to train their explanation skills is therefore a centralobjective of AI in education. In this paper, we follow this direction, and wepresent, to the best of our knowledge, the first multilingual dataset forMedical Question Answering where correct and incorrect diagnoses for a clinicalcase are enriched with a natural language explanation written by doctors. Theseexplanations have been manually annotated with argument components (i.e.,premise, claim) and argument relations (i.e., attack, support), resulting inthe Multilingual CasiMedicos-Arg dataset which consists of 558 clinical casesin four languages (English, Spanish, French, Italian) with explanations, wherewe annotated 5021 claims, 2313 premises, 2431 support relations, and 1106attack relations. We conclude by showing how competitive baselines perform overthis challenging dataset for the argument mining task.</description><author>katerina Sviridova, Anar Yeginbergen, Ainara Estarrona, Elena Cabrio, Serena Villata, Rodrigo Agerri</author><pubDate>Mon, 07 Oct 2024 17:41:45 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.05235v1</guid></item><item><title>DiffuseReg: Denoising Diffusion Model for Obtaining Deformation Fields in Unsupervised Deformable Image Registration</title><link>http://arxiv.org/abs/2410.05234v1</link><description>Deformable image registration aims to precisely align medical images fromdifferent modalities or times. Traditional deep learning methods, whileeffective, often lack interpretability, real-time observability and adjustmentcapacity during registration inference. Denoising diffusion models present analternative by reformulating registration as iterative image denoising.However, existing diffusion registration approaches do not fully harnesscapabilities, neglecting the critical sampling phase that enables continuousobservability during the inference. Hence, we introduce DiffuseReg, aninnovative diffusion-based method that denoises deformation fields instead ofimages for improved transparency. We also propose a novel denoising networkupon Swin Transformer, which better integrates moving and fixed images withdiffusion time step throughout the denoising process. Furthermore, we enhancecontrol over the denoising registration process with a novel similarityconsistency regularization. Experiments on ACDC datasets demonstrate DiffuseRegoutperforms existing diffusion registration methods by 1.32 in Dice score. Thesampling process in DiffuseReg enables real-time output observability andadjustment unmatched by previous deep models.</description><author>Yongtai Zhuo, Yiqing Shen</author><pubDate>Mon, 07 Oct 2024 17:41:35 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.05234v1</guid></item><item><title>SimO Loss: Anchor-Free Contrastive Loss for Fine-Grained Supervised Contrastive Learning</title><link>http://arxiv.org/abs/2410.05233v1</link><description>We introduce a novel anchor-free contrastive learning (AFCL) methodleveraging our proposed Similarity-Orthogonality (SimO) loss. Our approachminimizes a semi-metric discriminative loss function that simultaneouslyoptimizes two key objectives: reducing the distance and orthogonality betweenembeddings of similar inputs while maximizing these metrics for dissimilarinputs, facilitating more fine-grained contrastive learning. The AFCL method,powered by SimO loss, creates a fiber bundle topological structure in theembedding space, forming class-specific, internally cohesive yet orthogonalneighborhoods. We validate the efficacy of our method on the CIFAR-10 dataset,providing visualizations that demonstrate the impact of SimO loss on theembedding space. Our results illustrate the formation of distinct, orthogonalclass neighborhoods, showcasing the method's ability to create well-structuredembeddings that balance class separation with intra-class variability. Thiswork opens new avenues for understanding and leveraging the geometricproperties of learned representations in various machine learning tasks.</description><author>Taha Bouhsine, Imad El Aaroussi, Atik Faysal, Wang Huaxia</author><pubDate>Mon, 07 Oct 2024 17:41:10 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.05233v1</guid></item><item><title>SymmetryLens: A new candidate paradigm for unsupervised symmetry learning via locality and equivariance</title><link>http://arxiv.org/abs/2410.05232v1</link><description>We develop a new, unsupervised symmetry learning method that starts with rawdata, and gives the minimal (discrete) generator of an underlying Lie group ofsymmetries, together with a symmetry equivariant representation of the data.The method is able to learn the pixel translation operator from a dataset withonly an approximate translation symmetry, and can learn quite different typesof symmetries which are not apparent to the naked eye, equally well. The methodis based on the formulation of an information-theoretic loss function thatmeasures both the degree to which the dataset is symmetric under a givencandidate symmetry, and also, the degree of locality of the samples in thedataset with respect to this symmetry. We demonstrate that this couplingbetween symmetry and locality, together with a special optimization techniquedeveloped for entropy estimation, results in a highly stable system that givesreproducible results. The symmetry actions we consider are grouprepresentations, however, we believe the approach has the potential to begeneralized to more general, nonlinear actions of non-commutative Lie groups.</description><author>Onur Efe, Arkadas Ozakin</author><pubDate>Mon, 07 Oct 2024 17:40:51 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.05232v1</guid></item><item><title>Generative Parameter-Efficient Fine-Tuning</title><link>http://arxiv.org/abs/2312.00700v4</link><description>We present Generative Parameter-Efficient Fine-Tuning (GIFT) for adaptingpretrained Transformer backbones on downstream tasks. GIFT learns to generatethe fine-tuned weights for a layer directly from its pretrained weights. TheGIFT network is parameterized in a minimally-simple way by two linear layers(without bias terms), and is shared by different pretrained layers selected forfine-tuning (e.g., the Query layers), which result in significantly fewertrainable parameters compared to the layer-specific methods like Low-RankAdapter (LoRA). We also show this formulation bridges parameter-efficientfine-tuning and representation fine-tuning. We perform comprehensiveexperiments on natural language tasks (commonsense and arithmetic reasoning,instruction tuning, and sequence classification) and computer vision tasks(fine-grained classification). We obtain the best performance and parameterefficiency among baselines on commonsense and arithmetic reasoning, andinstruction following using the Llama family of models and on visualrecognition benchmarks using Vision Transformers. Notably, compared to LoRA, weobtain 5.7% absolute increase in average accuracy with 14 times reduction ofparameters on Commonsense170k using Llama-3 (8B), and 5.4% absolute increase inthe win rate with 4 times reduction of parameters using Llama-2 (7B) duringinstruction tuning. Our GIFT also obtains a slightly higher win rate oninstruction tuning than GPT 3.5 (Turbo 1106).</description><author>Chinmay Savadikar, Xi Song, Tianfu Wu</author><pubDate>Mon, 07 Oct 2024 17:40:32 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.00700v4</guid></item><item><title>3D-free meets 3D priors: Novel View Synthesis from a Single Image with Pretrained Diffusion Guidance</title><link>http://arxiv.org/abs/2408.06157v2</link><description>Recent 3D novel view synthesis (NVS) methods are limited tosingle-object-centric scenes and struggle with complex environments. They oftenrequire extensive 3D data for training, lacking generalization beyond thetraining distribution. Conversely, 3D-free methods can generate text-controlledviews of complex, in-the-wild scenes using a pretrained stable diffusion modelwithout the need for a large amount of 3D-based training data, but lack cameracontrol. In this paper, we introduce a method capable of generatingcamera-controlled viewpoints from a single input image, by combining thebenefits of 3D-free and 3D-based approaches. Our method excels in handlingcomplex and diverse scenes without extensive training or additional 3D andmultiview data. It leverages widely available pretrained NVS models for weakguidance, integrating this knowledge into a 3D-free view synthesis approach toachieve the desired results. Experimental results demonstrate that our methodoutperforms existing models in both qualitative and quantitative evaluations,providing high-fidelity and consistent novel view synthesis at desired cameraangles across a wide variety of scenes.</description><author>Taewon Kang, Divya Kothandaraman, Dinesh Manocha, Ming C. Lin</author><pubDate>Mon, 07 Oct 2024 17:39:52 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.06157v2</guid></item><item><title>GSM-Symbolic: Understanding the Limitations of Mathematical Reasoning in Large Language Models</title><link>http://arxiv.org/abs/2410.05229v1</link><description>Recent advancements in Large Language Models (LLMs) have sparked interest intheir formal reasoning capabilities, particularly in mathematics. The GSM8Kbenchmark is widely used to assess the mathematical reasoning of models ongrade-school-level questions. While the performance of LLMs on GSM8K hassignificantly improved in recent years, it remains unclear whether theirmathematical reasoning capabilities have genuinely advanced, raising questionsabout the reliability of the reported metrics. To address these concerns, weconduct a large-scale study on several SOTA open and closed models. To overcomethe limitations of existing evaluations, we introduce GSM-Symbolic, an improvedbenchmark created from symbolic templates that allow for the generation of adiverse set of questions. GSM-Symbolic enables more controllable evaluations,providing key insights and more reliable metrics for measuring the reasoningcapabilities of models.Our findings reveal that LLMs exhibit noticeablevariance when responding to different instantiations of the same question.Specifically, the performance of all models declines when only the numericalvalues in the question are altered in the GSM-Symbolic benchmark. Furthermore,we investigate the fragility of mathematical reasoning in these models and showthat their performance significantly deteriorates as the number of clauses in aquestion increases. We hypothesize that this decline is because current LLMscannot perform genuine logical reasoning; they replicate reasoning steps fromtheir training data. Adding a single clause that seems relevant to the questioncauses significant performance drops (up to 65%) across all state-of-the-artmodels, even though the clause doesn't contribute to the reasoning chain neededfor the final answer. Overall, our work offers a more nuanced understanding ofLLMs' capabilities and limitations in mathematical reasoning.</description><author>Iman Mirzadeh, Keivan Alizadeh, Hooman Shahrokhi, Oncel Tuzel, Samy Bengio, Mehrdad Farajtabar</author><pubDate>Mon, 07 Oct 2024 17:36:37 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.05229v1</guid></item><item><title>The Dawn of Video Generation: Preliminary Explorations with SORA-like Models</title><link>http://arxiv.org/abs/2410.05227v1</link><description>High-quality video generation, encompassing text-to-video (T2V),image-to-video (I2V), and video-to-video (V2V) generation, holds considerablesignificance in content creation to benefit anyone express their inherentcreativity in new ways and world simulation to modeling and understanding theworld. Models like SORA have advanced generating videos with higher resolution,more natural motion, better vision-language alignment, and increasedcontrollability, particularly for long video sequences. These improvements havebeen driven by the evolution of model architectures, shifting from UNet to morescalable and parameter-rich DiT models, along with large-scale data expansionand refined training strategies. However, despite the emergence of DiT-basedclosed-source and open-source models, a comprehensive investigation into theircapabilities and limitations remains lacking. Furthermore, the rapiddevelopment has made it challenging for recent benchmarks to fully coverSORA-like models and recognize their significant advancements. Additionally,evaluation metrics often fail to align with human preferences.</description><author>Ailing Zeng, Yuhang Yang, Weidong Chen, Wei Liu</author><pubDate>Mon, 07 Oct 2024 17:35:10 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.05227v1</guid></item><item><title>ETGL-DDPG: A Deep Deterministic Policy Gradient Algorithm for Sparse Reward Continuous Control</title><link>http://arxiv.org/abs/2410.05225v1</link><description>We consider deep deterministic policy gradient (DDPG) in the context ofreinforcement learning with sparse rewards. To enhance exploration, weintroduce a search procedure, \emph{${\epsilon}{t}$-greedy}, which generatesexploratory options for exploring less-visited states. We prove that searchusing $\epsilon t$-greedy has polynomial sample complexity under mild MDPassumptions. To more efficiently use the information provided by rewardedtransitions, we develop a new dual experience replay buffer framework,\emph{GDRB}, and implement \emph{longest n-step returns}. The resultingalgorithm, \emph{ETGL-DDPG}, integrates all three techniques: \bm{$\epsilont$}-greedy, \textbf{G}DRB, and \textbf{L}ongest $n$-step, into DDPG. Weevaluate ETGL-DDPG on standard benchmarks and demonstrate that it outperformsDDPG, as well as other state-of-the-art methods, across all testedsparse-reward continuous environments. Ablation studies further highlight howeach strategy individually enhances the performance of DDPG in this setting.</description><author>Ehsan Futuhi, Shayan Karimi, Chao Gao, Martin MÃ¼ller</author><pubDate>Mon, 07 Oct 2024 17:31:52 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.05225v1</guid></item><item><title>Cookbook: A framework for improving LLM generative abilities via programmatic data generating templates</title><link>http://arxiv.org/abs/2410.05224v1</link><description>Fine-tuning large language models (LLMs) on instruction datasets is a commonway to improve their generative capabilities. However, instruction datasets canbe expensive and time-consuming to manually curate, and while LLM-generateddata is less labor-intensive, it may violate user privacy agreements or termsof service of LLM providers. Therefore, we seek a way of constructinginstruction datasets with samples that are not generated by humans or LLMs butstill improve LLM generative capabilities. In this work, we introduce Cookbook,a framework that programmatically generates training data consisting of simplepatterns over random tokens, resulting in a scalable, cost-effective approachthat avoids legal and privacy issues. First, Cookbook uses a template -- a datagenerating Python function -- to produce training data that encourages themodel to learn an explicit pattern-based rule that corresponds to a desiredtask. We find that fine-tuning on Cookbook-generated data is able to improveperformance on its corresponding task by up to 52.7 accuracy points. Second,since instruction datasets improve performance on multiple downstream taskssimultaneously, Cookbook algorithmically learns how to mix data from varioustemplates to optimize performance on multiple tasks. On the standard multi-taskGPT4ALL evaluation suite, Mistral-7B fine-tuned using a Cookbook-generateddataset attains the best accuracy on average compared to other 7B parameterinstruction-tuned models and is the best performing model on 3 out of 8 tasks.Finally, we analyze when and why Cookbook improves performance and present ametric that allows us to verify that the improvement is largely explained bythe model's generations adhering better to template rules.</description><author>Avanika Narayan, Mayee F. Chen, Kush Bhatia, Christopher RÃ©</author><pubDate>Mon, 07 Oct 2024 17:29:40 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.05224v1</guid></item><item><title>Jogging the Memory of Unlearned LLMs Through Targeted Relearning Attack</title><link>http://arxiv.org/abs/2406.13356v2</link><description>Machine unlearning is a promising approach to mitigate undesirablememorization of training data in LLMs. However, in this work we show thatexisting approaches for unlearning in LLMs are surprisingly susceptible to asimple set of targeted relearning attacks. With access to only a small andpotentially loosely related set of data, we find that we can "jog" the memoryof unlearned models to reverse the effects of unlearning. For example, we showthat relearning on public medical articles can lead an unlearned LLM to outputharmful knowledge about bioweapons, and relearning general wiki informationabout the book series Harry Potter can force the model to output verbatimmemorized text. We formalize this unlearning-relearning pipeline, explore theattack across three popular unlearning benchmarks, and discuss futuredirections and guidelines that result from our study.</description><author>Shengyuan Hu, Yiwei Fu, Zhiwei Steven Wu, Virginia Smith</author><pubDate>Mon, 07 Oct 2024 17:27:30 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.13356v2</guid></item><item><title>Learning Successor Features with Distributed Hebbian Temporal Memory</title><link>http://arxiv.org/abs/2310.13391v3</link><description>This paper presents a novel approach to address the challenge of onlinetemporal memory learning for decision-making under uncertainty innon-stationary, partially observable environments. The proposed algorithm,Distributed Hebbian Temporal Memory (DHTM), is based on factor graph formalismand a multicomponent neuron model. DHTM aims to capture sequential datarelationships and make cumulative predictions about future observations,forming Successor Features (SF). Inspired by neurophysiological models of theneocortex, the algorithm utilizes distributed representations, sparsetransition matrices, and local Hebbian-like learning rules to overcome theinstability and slow learning process of traditional temporal memory algorithmslike RNN and HMM. Experimental results demonstrate that DHTM outperforms LSTMand a biologically inspired HMM-like algorithm, CSCG, in the case ofnon-stationary datasets. Our findings suggest that DHTM is a promising approachfor addressing the challenges of online sequence learning and planning indynamic environments.</description><author>Evgenii Dzhivelikian, Petr Kuderov, Aleksandr I. Panov</author><pubDate>Mon, 07 Oct 2024 17:27:21 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.13391v3</guid></item><item><title>Precise Model Benchmarking with Only a Few Observations</title><link>http://arxiv.org/abs/2410.05222v1</link><description>How can we precisely estimate a large language model's (LLM) accuracy onquestions belonging to a specific topic within a larger question-answeringdataset? The standard direct estimator, which averages the model's accuracy onthe questions in each subgroup, may exhibit high variance for subgroups(topics) with small sample sizes. Synthetic regression modeling, whichleverages the model's accuracy on questions about other topics, may yieldbiased estimates that are too unreliable for large subgroups. We prescribe asimple yet effective solution: an empirical Bayes (EB) estimator that balancesdirect and regression estimates for each subgroup separately, improving theprecision of subgroup-level estimates of model performance. Our experiments onmultiple datasets show that this approach consistently provides more preciseestimates of the LLM performance compared to the direct and regressionapproaches, achieving substantial reductions in the mean squared error.Confidence intervals for EB estimates also have near-nominal coverage and arenarrower compared to those for the direct estimator. Additional experiments ontabular and vision data validate the benefits of this EB approach.</description><author>Riccardo Fogliato, Pratik Patil, Nil-Jana Akpinar, Mathew Monfort</author><pubDate>Mon, 07 Oct 2024 17:26:31 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.05222v1</guid></item><item><title>BigCodeBench: Benchmarking Code Generation with Diverse Function Calls and Complex Instructions</title><link>http://arxiv.org/abs/2406.15877v3</link><description>Task automation has been greatly empowered by the recent advances in LargeLanguage Models (LLMs) via Python code, where the tasks ranging from softwareengineering development to general-purpose reasoning. While current benchmarkshave shown that LLMs can solve tasks using programs like human developers, themajority of their evaluations are limited to short and self-containedalgorithmic tasks or standalone function calls. Solving challenging andpractical requires the capability of utilizing diverse function calls as toolsto efficiently implement functionalities like data analysis and webdevelopment. In addition, using multiple tools to solve a task needscompositional reasoning by accurately understanding complex instructions.Fulfilling both of these characteristics can pose a great challenge for LLMs.Toassess how well LLMs can solve challenging and practical tasks via programs, weintroduce BigCodeBench, a benchmark that challenges LLMs to invoke multiplefunction calls as tools from 139 libraries and 7 domains for 1,140 fine-grainedtasks. To evaluate LLMs rigorously, each task encompasses 5.6 test cases withan average branch coverage of 99%. In addition, we propose anatural-language-oriented variant of BigCodeBench, BigCodeBench-Instruct, thatautomatically transforms the original docstrings into short instructions onlywith essential information. Our extensive evaluation of 60 LLMs shows that LLMsare not yet capable of following complex instructions to use function callsprecisely, with scores up to 60%, significantly lower than the humanperformance of 97%. The results underscore the need for further advancements inthis area.</description><author>Terry Yue Zhuo, Minh Chien Vu, Jenny Chim, Han Hu, Wenhao Yu, Ratnadira Widyasari, Imam Nur Bani Yusuf, Haolan Zhan, Junda He, Indraneil Paul, Simon Brunner, Chen Gong, Thong Hoang, Armel Randy Zebaze, Xiaoheng Hong, Wen-Ding Li, Jean Kaddour, Ming Xu, Zhihan Zhang, Prateek Yadav, Naman Jain, Alex Gu, Zhoujun Cheng, Jiawei Liu, Qian Liu, Zijian Wang, David Lo, Binyuan Hui, Niklas Muennighoff, Daniel Fried, Xiaoning Du, Harm de Vries, Leandro Von Werra</author><pubDate>Mon, 07 Oct 2024 17:23:30 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.15877v3</guid></item><item><title>Full Line Code Completion: Bringing AI to Desktop</title><link>http://arxiv.org/abs/2405.08704v2</link><description>In recent years, several industrial solutions for the problem of multi-tokencode completion appeared, each making a great advance in the area but mostlyfocusing on cloud-based runtime and avoiding working on the end user's device. In this work, we describe our approach for building a multi-token codecompletion feature for the JetBrains' IntelliJ Platform, which we call FullLine Code Completion. The feature suggests only syntactically correct code andworks fully locally, i.e., data querying and the generation of suggestionshappens on the end user's machine. We share important time andmemory-consumption restrictions, as well as design principles that a codecompletion engine should satisfy. Working entirely on the end user's device,our code completion engine enriches user experience while being not only fastand compact but also secure. We share a number of useful techniques to meet thestated development constraints and also describe offline and online evaluationpipelines that allowed us to make better decisions. Our online evaluation shows that the usage of the tool leads to 1.3 timesmore Python code in the IDE being produced by code completion. The describedsolution was initially started with a help of researchers and was then bundledinto all JetBrains IDEs where it is now used by millions of users. Thus, webelieve that this work is useful for bridging academia and industry, providingresearchers with the knowledge of what happens when complex research-basedsolutions are integrated into real products.</description><author>Anton Semenkin, Vitaliy Bibaev, Yaroslav Sokolov, Kirill Krylov, Alexey Kalina, Anna Khannanova, Danila Savenkov, Darya Rovdo, Igor Davidenko, Kirill Karnaukhov, Maxim Vakhrushev, Mikhail Kostyukov, Mikhail Podvitskii, Petr Surkov, Yaroslav Golubev, Nikita Povarov, Timofey Bryksin</author><pubDate>Mon, 07 Oct 2024 17:23:25 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.08704v2</guid></item><item><title>Density estimation with LLMs: a geometric investigation of in-context learning trajectories</title><link>http://arxiv.org/abs/2410.05218v1</link><description>Large language models (LLMs) demonstrate remarkable emergent abilities toperform in-context learning across various tasks, including time seriesforecasting. This work investigates LLMs' ability to estimate probabilitydensity functions (PDFs) from data observed in-context; such density estimation(DE) is a fundamental task underlying many probabilistic modeling problems. Weleverage the Intensive Principal Component Analysis (InPCA) to visualize andanalyze the in-context learning dynamics of LLaMA-2 models. Our main finding isthat these LLMs all follow similar learning trajectories in a low-dimensionalInPCA space, which are distinct from those of traditional density estimationmethods like histograms and Gaussian kernel density estimation (KDE). Weinterpret the LLaMA in-context DE process as a KDE with an adaptive kernelwidth and shape. This custom kernel model captures a significant portion ofLLaMA's behavior despite having only two parameters. We further speculate onwhy LLaMA's kernel width and shape differs from classical algorithms, providinginsights into the mechanism of in-context probabilistic reasoning in LLMs.</description><author>Toni J. B. Liu, Nicolas BoullÃ©, RaphaÃ«l Sarfati, Christopher J. Earls</author><pubDate>Mon, 07 Oct 2024 17:22:56 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.05218v1</guid></item><item><title>Stateful Large Language Model Serving with Pensieve</title><link>http://arxiv.org/abs/2312.05516v3</link><description>Large Language Models (LLMs) are wildly popular today and it is important toserve them efficiently. Existing LLM serving systems are stateless acrossrequests. Consequently, when LLMs are used in the common setting of multi-turnconversations, a growing log of the conversation history must be processedalongside any request by the serving system at each turn, resulting in repeatedprocessing. In this paper, we design $Pensieve$, a system optimized for multi-turnconversation LLM serving. $Pensieve$ maintains the conversation state acrossrequests by caching previously processed history to avoid duplicate processing.$Pensieve$'s multi-tier caching strategy can utilize both GPU and CPU memory toefficiently store and retrieve cached data. $Pensieve$ also generalizes therecent PagedAttention kernel to support attention between multiple input tokenswith a GPU cache spread over non-contiguous memory. Our evaluation shows that$Pensieve$ can achieve $1.14$-$3.0\times$ the throughput of vLLM andTensorRT-LLM and significantly reduce latency.</description><author>Lingfan Yu, Jinkun Lin, Jinyang Li</author><pubDate>Mon, 07 Oct 2024 17:21:57 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.05516v3</guid></item><item><title>Organizing Unstructured Image Collections using Natural Language</title><link>http://arxiv.org/abs/2410.05217v1</link><description>Organizing unstructured visual data into semantic clusters is a key challengein computer vision. Traditional deep clustering (DC) approaches focus on asingle partition of data, while multiple clustering (MC) methods address thislimitation by uncovering distinct clustering solutions. The rise of largelanguage models (LLMs) and multimodal LLMs (MLLMs) has enhanced MC by allowingusers to define clustering criteria in natural language. However, manuallyspecifying criteria for large datasets is impractical. In this work, weintroduce the task Semantic Multiple Clustering (SMC) that aims toautomatically discover clustering criteria from large image collections,uncovering interpretable substructures without requiring human input. Ourframework, Text Driven Semantic Multiple Clustering (TeDeSC), uses text as aproxy to concurrently reason over large image collections, discoverpartitioning criteria, expressed in natural language, and reveal semanticsubstructures. To evaluate TeDeSC, we introduce the COCO-4c and Food-4cbenchmarks, each containing four grouping criteria and ground-truthannotations. We apply TeDeSC to various applications, such as discoveringbiases and analyzing social media image popularity, demonstrating its utilityas a tool for automatically organizing image collections and revealing novelinsights.</description><author>Mingxuan Liu, Zhun Zhong, Jun Li, Gianni Franchi, Subhankar Roy, Elisa Ricci</author><pubDate>Mon, 07 Oct 2024 17:21:46 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.05217v1</guid></item><item><title>Augmenting Black-box LLMs with Medical Textbooks for Biomedical Question Answering (Published in Findings of EMNLP 2024)</title><link>http://arxiv.org/abs/2309.02233v3</link><description>Large-scale language models (LLMs) like ChatGPT have demonstrated impressiveabilities in generating responses based on human instructions. However, theiruse in the medical field can be challenging due to their lack of specific,in-depth knowledge. In this study, we present a system called LLMs Augmentedwith Medical Textbooks (LLM-AMT) designed to enhance the proficiency of LLMs inspecialized domains. LLM-AMT integrates authoritative medical textbooks intothe LLMs' framework using plug-and-play modules. These modules include a QueryAugmenter, a Hybrid Textbook Retriever, and a Knowledge Self-Refiner. Together,they incorporate authoritative medical knowledge. Additionally, an LLM Readeraids in contextual understanding. Our experimental results on three medical QAtasks demonstrate that LLMAMT significantly improves response quality, withaccuracy gains ranging from 11.6% to 16.6%. Notably, with GPT-4-Turbo as thebase model, LLM-AMT outperforms the specialized Med-PaLM 2 model pre-trained ona massive amount of medical corpus by 2-3%. We found that despite being 100xsmaller in size, medical textbooks as a retrieval corpus is proven to be a moreeffective knowledge database than Wikipedia in the medical domain, boostingperformance by 7.8%-13.7%.</description><author>Yubo Wang, Xueguang Ma, Wenhu Chen</author><pubDate>Mon, 07 Oct 2024 17:21:45 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2309.02233v3</guid></item><item><title>The Informed Elastic Net for Fast Grouped Variable Selection and FDR Control in Genomics Research</title><link>http://arxiv.org/abs/2410.05211v1</link><description>Modern genomics research relies on genome-wide association studies (GWAS) toidentify the few genetic variants among potentially millions that areassociated with diseases of interest. Only reproducible discoveries of groupsof associations improve our understanding of complex polygenic diseases andenable the development of new drugs and personalized medicine. Thus, fastmultivariate variable selection methods that have a high true positive rate(TPR) while controlling the false discovery rate (FDR) are crucial. Recently,the T-Rex+GVS selector, a version of the T-Rex selector that uses the elasticnet (EN) as a base selector to perform grouped variable election, was proposed.Although it significantly increased the TPR in simulated GWAS compared to theoriginal T-Rex, its comparably high computational cost limits scalability.Therefore, we propose the informed elastic net (IEN), a new base selector thatsignificantly reduces computation time while retaining the grouped variableselection property. We quantify its grouping effect and derive its formulationas a Lasso-type optimization problem, which is solved efficiently within theT-Rex framework by the terminated LARS algorithm. Numerical simulations and aGWAS study demonstrate that the proposed T-Rex+GVS (IEN) exhibits the desiredgrouping effect, reduces computation time, and achieves the same TPR asT-Rex+GVS (EN) but with lower FDR, which makes it a promising method forlarge-scale GWAS.</description><author>Jasin Machkour, Michael Muma, Daniel P. Palomar</author><pubDate>Mon, 07 Oct 2024 17:18:25 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.05211v1</guid></item><item><title>Preserving Multi-Modal Capabilities of Pre-trained VLMs for Improving Vision-Linguistic Compositionality</title><link>http://arxiv.org/abs/2410.05210v1</link><description>In this paper, we propose a new method to enhance compositional understandingin pre-trained vision and language models (VLMs) without sacrificingperformance in zero-shot multi-modal tasks. Traditional fine-tuning approachesoften improve compositional reasoning at the cost of degrading multi-modalcapabilities, primarily due to the use of global hard negative (HN) loss, whichcontrasts global representations of images and texts. This global HN losspushes HN texts that are highly similar to the original ones, damaging themodel's multi-modal representations. To overcome this limitation, we proposeFine-grained Selective Calibrated CLIP (FSC-CLIP), which integrates local hardnegative loss and selective calibrated regularization. These innovationsprovide fine-grained negative supervision while preserving the model'srepresentational integrity. Our extensive evaluations across diverse benchmarksfor both compositionality and multi-modal tasks show that FSC-CLIP not onlyachieves compositionality on par with state-of-the-art models but also retainsstrong multi-modal capabilities. Code is available at:https://github.com/ytaek-oh/fsc-clip.</description><author>Youngtaek Oh, Jae Won Cho, Dong-Jin Kim, In So Kweon, Junmo Kim</author><pubDate>Mon, 07 Oct 2024 17:16:20 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.05210v1</guid></item><item><title>Online Convex Optimization with a Separation Oracle</title><link>http://arxiv.org/abs/2410.02476v2</link><description>In this paper, we introduce a new projection-free algorithm for Online ConvexOptimization (OCO) with a state-of-the-art regret guarantee amongseparation-based algorithms. Existing projection-free methods based on theclassical Frank-Wolfe algorithm achieve a suboptimal regret bound of$O(T^{3/4})$, while more recent separation-based approaches guarantee a regretbound of $O(\kappa \sqrt{T})$, where $\kappa$ denotes the asphericity of thefeasible set, defined as the ratio of the radii of the containing and containedballs. However, for ill-conditioned sets, $\kappa$ can be arbitrarily large,potentially leading to poor performance. Our algorithm achieves a regret boundof $\widetilde{O}(\sqrt{dT} + \kappa d)$, while requiring only$\widetilde{O}(1)$ calls to a separation oracle per round. Crucially, the mainterm in the bound, $\widetilde{O}(\sqrt{d T})$, is independent of $\kappa$,addressing the limitations of previous methods. Additionally, as a by-productof our analysis, we recover the $O(\kappa \sqrt{T})$ regret bound of existingOCO algorithms with a more straightforward analysis and improve the regretbound for projection-free online exp-concave optimization. Finally, forconstrained stochastic convex optimization, we achieve a state-of-the-artconvergence rate of $\widetilde{O}(\sigma/\sqrt{T} + \kappa d/T)$, where$\sigma$ represents the noise in the stochastic gradients, while requiring only$\widetilde{O}(1)$ calls to a separation oracle per iteration.</description><author>Zakaria Mhammedi</author><pubDate>Mon, 07 Oct 2024 17:15:37 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.02476v2</guid></item><item><title>Annotation alignment: Comparing LLM and human annotations of conversational safety</title><link>http://arxiv.org/abs/2406.06369v4</link><description>Do LLMs align with human perceptions of safety? We study this question viaannotation alignment, the extent to which LLMs and humans agree when annotatingthe safety of user-chatbot conversations. We leverage the recent DICES dataset(Aroyo et al., 2023), in which 350 conversations are each rated for safety by112 annotators spanning 10 race-gender groups. GPT-4 achieves a Pearsoncorrelation of $r = 0.59$ with the average annotator rating, \textit{higher}than the median annotator's correlation with the average ($r=0.51$). We showthat larger datasets are needed to resolve whether LLMs exhibit disparities inhow well they correlate with different demographic groups. Also, there issubstantial idiosyncratic variation in correlation within groups, suggestingthat race &amp; gender do not fully capture differences in alignment. Finally, wefind that GPT-4 cannot predict when one demographic group finds a conversationmore unsafe than another.</description><author>Rajiv Movva, Pang Wei Koh, Emma Pierson</author><pubDate>Mon, 07 Oct 2024 17:13:45 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.06369v4</guid></item><item><title>CAnDOIT: Causal Discovery with Observational and Interventional Data from Time-Series</title><link>http://arxiv.org/abs/2410.02844v2</link><description>The study of cause-and-effect is of the utmost importance in many branches ofscience, but also for many practical applications of intelligent systems. Inparticular, identifying causal relationships in situations that include hiddenfactors is a major challenge for methods that rely solely on observational datafor building causal models. This paper proposes CAnDOIT, a causal discoverymethod to reconstruct causal models using both observational and interventionaltime-series data. The use of interventional data in the causal analysis iscrucial for real-world applications, such as robotics, where the scenario ishighly complex and observational data alone are often insufficient to uncoverthe correct causal structure. Validation of the method is performed initiallyon randomly generated synthetic models and subsequently on a well-knownbenchmark for causal structure learning in a robotic manipulation environment.The experiments demonstrate that the approach can effectively handle data frominterventions and exploit them to enhance the accuracy of the causal analysis.A Python implementation of CAnDOIT has also been developed and is publiclyavailable on GitHub: https://github.com/lcastri/causalflow.</description><author>Luca Castri, Sariah Mghames, Marc Hanheide, Nicola Bellotto</author><pubDate>Mon, 07 Oct 2024 17:12:15 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.02844v2</guid></item><item><title>Finding Visual Task Vectors</title><link>http://arxiv.org/abs/2404.05729v2</link><description>Visual Prompting is a technique for teaching models to perform a visual taskvia in-context examples, without any additional training. In this work, weanalyze the activations of MAE-VQGAN, a recent Visual Prompting model, and findtask vectors, activations that encode task-specific information. Equipped withthis insight, we demonstrate that it is possible to identify the task vectorsand use them to guide the network towards performing different tasks withoutproviding any input-output examples. To find task vectors, we compute theaverage intermediate activations per task and use the REINFORCE algorithm tosearch for the subset of task vectors. The resulting task vectors guide themodel towards performing a task better than the original model without the needfor input-output examples.</description><author>Alberto Hojel, Yutong Bai, Trevor Darrell, Amir Globerson, Amir Bar</author><pubDate>Mon, 07 Oct 2024 17:10:52 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.05729v2</guid></item><item><title>Studying and Mitigating Biases in Sign Language Understanding Models</title><link>http://arxiv.org/abs/2410.05206v1</link><description>Ensuring that the benefits of sign language technologies are distributedequitably among all community members is crucial. Thus, it is important toaddress potential biases and inequities that may arise from the design or useof these resources. Crowd-sourced sign language datasets, such as the ASLCitizen dataset, are great resources for improving accessibility and preservinglinguistic diversity, but they must be used thoughtfully to avoid reinforcingexisting biases. In this work, we utilize the rich information about participant demographicsand lexical features present in the ASL Citizen dataset to study and documentthe biases that may result from models trained on crowd-sourced sign datasets.Further, we apply several bias mitigation techniques during model training, andfind that these techniques reduce performance disparities without decreasingaccuracy. With the publication of this work, we release the demographicinformation about the participants in the ASL Citizen dataset to encouragefuture bias mitigation work in this space.</description><author>Katherine Atwell, Danielle Bragg, Malihe Alikhani</author><pubDate>Mon, 07 Oct 2024 17:09:03 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.05206v1</guid></item><item><title>Beyond FVD: Enhanced Evaluation Metrics for Video Generation Quality</title><link>http://arxiv.org/abs/2410.05203v1</link><description>The Fr\'echet Video Distance (FVD) is a widely adopted metric for evaluatingvideo generation distribution quality. However, its effectiveness relies oncritical assumptions. Our analysis reveals three significant limitations: (1)the non-Gaussianity of the Inflated 3D Convnet (I3D) feature space; (2) theinsensitivity of I3D features to temporal distortions; (3) the impracticalsample sizes required for reliable estimation. These findings undermine FVD'sreliability and show that FVD falls short as a standalone metric for videogeneration evaluation. After extensive analysis of a wide range of metrics andbackbone architectures, we propose JEDi, the JEPA Embedding Distance, based onfeatures derived from a Joint Embedding Predictive Architecture, measured usingMaximum Mean Discrepancy with polynomial kernel. Our experiments on multipleopen-source datasets show clear evidence that it is a superior alternative tothe widely used FVD metric, requiring only 16% of the samples to reach itssteady value, while increasing alignment with human evaluation by 34%, onaverage.</description><author>Ge Ya, Luo, Gian Favero, Zhi Hao Luo, Alexia Jolicoeur-Martineau, Christopher Pal</author><pubDate>Mon, 07 Oct 2024 17:07:21 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.05203v1</guid></item><item><title>Optimal Aggregation of Prediction Intervals under Unsupervised Domain Shift</title><link>http://arxiv.org/abs/2405.10302v2</link><description>As machine learning models are increasingly deployed in dynamic environments,it becomes paramount to assess and quantify uncertainties associated withdistribution shifts. A distribution shift occurs when the underlyingdata-generating process changes, leading to a deviation in the model'sperformance. The prediction interval, which captures the range of likelyoutcomes for a given prediction, serves as a crucial tool for characterizinguncertainties induced by their underlying distribution. In this paper, wepropose methodologies for aggregating prediction intervals to obtain one withminimal width and adequate coverage on the target domain under unsuperviseddomain shift, under which we have labeled samples from a related source domainand unlabeled covariates from the target domain. Our analysis encompassesscenarios where the source and the target domain are related via i) a boundeddensity ratio, and ii) a measure-preserving transformation. Our proposedmethodologies are computationally efficient and easy to implement. Beyondillustrating the performance of our method through real-world datasets, we alsodelve into the theoretical details. This includes establishing rigoroustheoretical guarantees, coupled with finite sample bounds, regarding thecoverage and width of our prediction intervals. Our approach excels inpractical applications and is underpinned by a solid theoretical framework,ensuring its reliability and effectiveness across diverse contexts.</description><author>Jiawei Ge, Debarghya Mukherjee, Jianqing Fan</author><pubDate>Mon, 07 Oct 2024 17:07:09 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.10302v2</guid></item><item><title>RevisEval: Improving LLM-as-a-Judge via Response-Adapted References</title><link>http://arxiv.org/abs/2410.05193v1</link><description>With significant efforts in recent studies, LLM-as-a-Judge has become acost-effective alternative to human evaluation for assessing the textgeneration quality in a wide range of tasks. However, there still remains areliability gap between LLM-as-a-Judge and human evaluation. One importantreason is the lack of guided oracles in the evaluation process. Motivated bythe role of reference pervasively used in classic text evaluation, we introduceRevisEval, a novel text generation evaluation paradigm via the response-adaptedreferences. RevisEval is driven by the key observation that an ideal referenceshould maintain the necessary relevance to the response to be evaluated.Specifically, RevisEval leverages the text revision capabilities of largelanguage models (LLMs) to adaptively revise the response, then treat therevised text as the reference (response-adapted reference) for the subsequentevaluation. Extensive experiments demonstrate that RevisEval outperformstraditional reference-free and reference-based evaluation paradigms that useLLM-as-a-Judge across NLG tasks and open-ended instruction-following tasks.More importantly, our response-adapted references can further boost theclassical text metrics, e.g., BLEU and BERTScore, compared to traditionalreferences and even rival the LLM-as-a-Judge. A detailed analysis is alsoconducted to confirm RevisEval's effectiveness in bias reduction, the impact ofinference cost, and reference relevance.</description><author>Qiyuan Zhang, Yufei Wang, Tiezheng YU, Yuxin Jiang, Chuhan Wu, Liangyou Li, Yasheng Wang, Xin Jiang, Lifeng Shang, Ruiming Tang, Fuyuan Lyu, Chen Ma</author><pubDate>Mon, 07 Oct 2024 16:50:47 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.05193v1</guid></item><item><title>Understanding Warmup-Stable-Decay Learning Rates: A River Valley Loss Landscape Perspective</title><link>http://arxiv.org/abs/2410.05192v1</link><description>Training language models currently requires pre-determining a fixed computebudget because the typical cosine learning rate schedule depends on the totalnumber of steps. In contrast, the Warmup-Stable-Decay (WSD) schedule uses aconstant learning rate to produce a main branch of iterates that can inprinciple continue indefinitely without a pre-specified compute budget. Then,given any compute budget, one can branch out from the main branch at a properat any time with a rapidly decaying learning rate to produce a strong model.Empirically, WSD generates a non-traditional loss curve: the loss remainselevated during the stable phase but sharply declines during the decay phase.Towards explaining this phenomenon, we conjecture that pretraining lossexhibits a river valley landscape, which resembles a deep valley with a riverat its bottom. Under this assumption, we show that during the stable phase, theiterate undergoes large oscillations due to the high learning rate, yet itprogresses swiftly along the river. During the decay phase, the rapidlydropping learning rate minimizes the iterate's oscillations, moving it closerto the river and revealing true optimization progress. Therefore, the sustainedhigh learning rate phase and fast decaying phase are responsible for progressin the river and the mountain directions respectively, and are both critical.Our analysis predicts phenomenons consistent with empirical observations andshows that this landscape can emerge from pretraining on a simple bi-gramdataset. Inspired by the theory, we introduce WSD-S, a variant of WSD thatreuses previous checkpoints' decay phases and keeps only one main branch, wherewe resume from a decayed checkpoint. WSD-S empirically outperforms WSD andCyclic-Cosine in obtaining multiple language model checkpoints across variouscompute budgets in a single run for parameters scaling from 0.1B to 1.2B.</description><author>Kaiyue Wen, Zhiyuan Li, Jason Wang, David Hall, Percy Liang, Tengyu Ma</author><pubDate>Mon, 07 Oct 2024 16:49:39 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.05192v1</guid></item><item><title>LADEV: A Language-Driven Testing and Evaluation Platform for Vision-Language-Action Models in Robotic Manipulation</title><link>http://arxiv.org/abs/2410.05191v1</link><description>Building on the advancements of Large Language Models (LLMs) and VisionLanguage Models (VLMs), recent research has introduced Vision-Language-Action(VLA) models as an integrated solution for robotic manipulation tasks. Thesemodels take camera images and natural language task instructions as input anddirectly generate control actions for robots to perform specified tasks,greatly improving both decision-making capabilities and interaction with humanusers. However, the data-driven nature of VLA models, combined with their lackof interpretability, makes the assurance of their effectiveness and robustnessa challenging task. This highlights the need for a reliable testing andevaluation platform. For this purpose, in this work, we propose LADEV, acomprehensive and efficient platform specifically designed for evaluating VLAmodels. We first present a language-driven approach that automaticallygenerates simulation environments from natural language inputs, mitigating theneed for manual adjustments and significantly improving testing efficiency.Then, to further assess the influence of language input on the VLA models, weimplement a paraphrase mechanism that produces diverse natural language taskinstructions for testing. Finally, to expedite the evaluation process, weintroduce a batch-style method for conducting large-scale testing of VLAmodels. Using LADEV, we conducted experiments on several state-of-the-art VLAmodels, demonstrating its effectiveness as a tool for evaluating these models.Our results showed that LADEV not only enhances testing efficiency but alsoestablishes a solid baseline for evaluating VLA models, paving the way for thedevelopment of more intelligent and advanced robotic systems.</description><author>Zhijie Wang, Zhehua Zhou, Jiayang Song, Yuheng Huang, Zhan Shu, Lei Ma</author><pubDate>Mon, 07 Oct 2024 16:49:16 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.05191v1</guid></item><item><title>Matrix-weighted networks for modeling multidimensional dynamics</title><link>http://arxiv.org/abs/2410.05188v1</link><description>Networks are powerful tools for modeling interactions in complex systems.While traditional networks use scalar edge weights, many real-world systemsinvolve multidimensional interactions. For example, in social networks,individuals often have multiple interconnected opinions that can affectdifferent opinions of other individuals, which can be better characterized bymatrices. We propose a novel, general framework for modeling suchmultidimensional interacting dynamics: matrix-weighted networks (MWNs). Wepresent the mathematical foundations of MWNs and examine consensus dynamics andrandom walks within this context. Our results reveal that the coherence of MWNsgives rise to non-trivial steady states that generalize the notions ofcommunities and structural balance in traditional networks.</description><author>Yu Tian, Sadamori Kojaku, Hiroki Sayama, Renaud Lambiotte</author><pubDate>Mon, 07 Oct 2024 16:47:30 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.05188v1</guid></item><item><title>Principal-Agent Reinforcement Learning: Orchestrating AI Agents with Contracts</title><link>http://arxiv.org/abs/2407.18074v2</link><description>The increasing deployment of AI is shaping the future landscape of theinternet, which is set to become an integrated ecosystem of AI agents.Orchestrating the interaction among AI agents necessitates decentralized,self-sustaining mechanisms that harmonize the tension between individualinterests and social welfare. In this paper we tackle this challenge bysynergizing reinforcement learning with principal-agent theory from economics.Taken separately, the former allows unrealistic freedom of intervention, whilethe latter struggles to scale in sequential settings. Combining them achievesthe best of both worlds. We propose a framework where a principal guides anagent in a Markov Decision Process (MDP) using a series of contracts, whichspecify payments by the principal based on observable outcomes of the agent'sactions. We present and analyze a meta-algorithm that iteratively optimizes thepolicies of the principal and agent, showing its equivalence to a contractionoperator on the principal's Q-function, and its convergence to subgame-perfectequilibrium. We then scale our algorithm with deep Q-learning and analyze itsconvergence in the presence of approximation error, both theoretically andthrough experiments with randomly generated binary game-trees. Extending ourframework to multiple agents, we apply our methodology to the combinatorialCoin Game. Addressing this multi-agent sequential social dilemma is a promisingfirst step toward scaling our approach to more complex, real-world instances.</description><author>Dima Ivanov, Paul DÃ¼tting, Inbal Talgam-Cohen, Tonghan Wang, David C. Parkes</author><pubDate>Mon, 07 Oct 2024 16:46:42 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.18074v2</guid></item><item><title>Contextual Document Embeddings</title><link>http://arxiv.org/abs/2410.02525v2</link><description>Dense document embeddings are central to neural retrieval. The dominantparadigm is to train and construct embeddings by running encoders directly onindividual documents. In this work, we argue that these embeddings, whileeffective, are implicitly out-of-context for targeted use cases of retrieval,and that a contextualized document embedding should take into account both thedocument and neighboring documents in context - analogous to contextualizedword embeddings. We propose two complementary methods for contextualizeddocument embeddings: first, an alternative contrastive learning objective thatexplicitly incorporates the document neighbors into the intra-batch contextualloss; second, a new contextual architecture that explicitly encodes neighbordocument information into the encoded representation. Results show that bothmethods achieve better performance than biencoders in several settings, withdifferences especially pronounced out-of-domain. We achieve state-of-the-artresults on the MTEB benchmark with no hard negative mining, score distillation,dataset-specific instructions, intra-GPU example-sharing, or extremely largebatch sizes. Our method can be applied to improve performance on anycontrastive learning dataset and any biencoder.</description><author>John X. Morris, Alexander M. Rush</author><pubDate>Mon, 07 Oct 2024 16:46:05 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.02525v2</guid></item><item><title>A Narrative Review of Image Processing Techniques Related to Prostate Ultrasound</title><link>http://arxiv.org/abs/2407.00678v2</link><description>Prostate cancer (PCa) poses a significant threat to men's health, with earlydiagnosis being crucial for improving prognosis and reducing mortality rates.Transrectal ultrasound (TRUS) plays a vital role in the diagnosis andimage-guided intervention of PCa.To facilitate physicians with more accurateand efficient computer-assisted diagnosis and interventions, many imageprocessing algorithms in TRUS have been proposed and achieved state-of-the-artperformance in several tasks, including prostate gland segmentation, prostateimage registration, PCa classification and detection, and interventional needledetection. The rapid development of these algorithms over the past two decadesnecessitates a comprehensive summary. In consequence, this survey provides a\textcolor{blue}{narrative } analysis of this field, outlining the evolution ofimage processing methods in the context of TRUS image analysis and meanwhilehighlighting their relevant contributions. Furthermore, this survey discussescurrent challenges and suggests future research directions to possibly advancethis field further.</description><author>Haiqiao Wang, Hong Wu, Zhuoyuan Wang, Peiyan Yue, Dong Ni, Pheng-Ann Heng, Yi Wang</author><pubDate>Mon, 07 Oct 2024 16:45:55 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.00678v2</guid></item><item><title>Creative Beam Search: LLM-as-a-Judge For Improving Response Generation</title><link>http://arxiv.org/abs/2405.00099v4</link><description>Large language models are revolutionizing several areas, including artificialcreativity. However, the process of generation in machines profoundly divergesfrom that observed in humans. In particular, machine generation ischaracterized by a lack of intentionality and an underlying creative process.We propose a method called Creative Beam Search that uses Diverse Beam Searchand LLM-as-a-Judge to perform response generation and response validation. Theresults of a qualitative experiment show how our approach can provide betteroutput than standard sampling techniques. We also show that the responsevalidation step is a necessary complement to the response generation step.</description><author>Giorgio Franceschelli, Mirco Musolesi</author><pubDate>Mon, 07 Oct 2024 16:45:42 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.00099v4</guid></item><item><title>Beyond Correlation: Interpretable Evaluation of Machine Translation Metrics</title><link>http://arxiv.org/abs/2410.05183v1</link><description>Machine Translation (MT) evaluation metrics assess translation qualityautomatically. Recently, researchers have employed MT metrics for various newuse cases, such as data filtering and translation re-ranking. However, most MTmetrics return assessments as scalar scores that are difficult to interpret,posing a challenge to making informed design choices. Moreover, MT metrics'capabilities have historically been evaluated using correlation with humanjudgment, which, despite its efficacy, falls short of providing intuitiveinsights into metric performance, especially in terms of new metric use cases.To address these issues, we introduce an interpretable evaluation framework forMT metrics. Within this framework, we evaluate metrics in two scenarios thatserve as proxies for the data filtering and translation re-ranking use cases.Furthermore, by measuring the performance of MT metrics using Precision,Recall, and F-score, we offer clearer insights into their capabilities thancorrelation with human judgments. Finally, we raise concerns regarding thereliability of manually curated data following the Direct Assessments+ScalarQuality Metrics (DA+SQM) guidelines, reporting a notably low agreement withMultidimensional Quality Metrics (MQM) annotations.</description><author>Stefano Perrella, Lorenzo Proietti, Pere-LluÃ­s Huguet Cabot, Edoardo Barba, Roberto Navigli</author><pubDate>Mon, 07 Oct 2024 16:42:10 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.05183v1</guid></item><item><title>Forest Proximities for Time Series</title><link>http://arxiv.org/abs/2410.03098v2</link><description>RF-GAP has recently been introduced as an improved random forest proximitymeasure. In this paper, we present PF-GAP, an extension of RF-GAP proximitiesto proximity forests, an accurate and efficient time series classificationmodel. We use the forest proximities in connection with Multi-DimensionalScaling to obtain vector embeddings of univariate time series, comparing theembeddings to those obtained using various time series distance measures. Wealso use the forest proximities alongside Local Outlier Factors to investigatethe connection between misclassified points and outliers, comparing withnearest neighbor classifiers which use time series distance measures. We showthat the forest proximities may exhibit a stronger connection betweenmisclassified points and outliers than nearest neighbor classifiers.</description><author>Ben Shaw, Jake Rhodes, Soukaina Filali Boubrahimi, Kevin R. Moon</author><pubDate>Mon, 07 Oct 2024 16:41:49 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.03098v2</guid></item><item><title>MARs: Multi-view Attention Regularizations for Patch-based Feature Recognition of Space Terrain</title><link>http://arxiv.org/abs/2410.05182v1</link><description>The visual detection and tracking of surface terrain is required forspacecraft to safely land on or navigate within close proximity to celestialobjects. Current approaches rely on template matching with pre-gatheredpatch-based features, which are expensive to obtain and a limiting factor inperceptual capability. While recent literature has focused on in-situ detectionmethods to enhance navigation and operational autonomy, robust description isstill needed. In this work, we explore metric learning as the lightweightfeature description mechanism and find that current solutions fail to addressinter-class similarity and multi-view observational geometry. We attribute thisto the view-unaware attention mechanism and introduce Multi-view AttentionRegularizations (MARs) to constrain the channel and spatial attention acrossmultiple feature views, regularizing the what and where of attention focus. Wethoroughly analyze many modern metric learning losses with and without MARs anddemonstrate improved terrain-feature recognition performance by upwards of 85%.We additionally introduce the Luna-1 dataset, consisting of Moon craterlandmarks and reference navigation frames from NASA mission data to supportfuture research in this difficult task. Luna-1 and source code are publiclyavailable at https://droneslab.github.io/mars/.</description><author>Timothy Chase Jr, Karthik Dantu</author><pubDate>Mon, 07 Oct 2024 16:41:45 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.05182v1</guid></item><item><title>Training Foundation Models as Data Compression: On Information, Model Weights and Copyright Law</title><link>http://arxiv.org/abs/2407.13493v3</link><description>The training process of foundation models as for other classes of deeplearning systems is based on minimizing the reconstruction error over atraining set. For this reason, they are susceptible to the memorization andsubsequent reproduction of training samples. In this paper, we introduce atraining-as-compressing perspective, wherein the model's weights embody acompressed representation of the training data. From a copyright standpoint,this point of view implies that the weights could be considered a reproductionor a derivative work of a potentially protected set of works. We investigatethe technical and legal challenges that emerge from this framing of thecopyright of outputs generated by foundation models, including theirimplications for practitioners and researchers. We demonstrate that adopting aninformation-centric approach to the problem presents a promising pathway fortackling these emerging complex legal issues.</description><author>Giorgio Franceschelli, Claudia Cevenini, Mirco Musolesi</author><pubDate>Mon, 07 Oct 2024 16:40:25 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.13493v3</guid></item><item><title>Enhancing Equity in Large Language Models for Medical Applications</title><link>http://arxiv.org/abs/2410.05180v1</link><description>Recent advancements have highlighted the potential of large language models(LLMs) in medical applications, notably in automating Clinical Trial Matchingfor translational research and providing medical question-answering forclinical decision support. However, our study reveals significant inequities inthe use of LLMs, particularly for individuals from specific racial, gender, andunderrepresented groups influenced by social determinants of health. Thesedisparities could worsen existing health inequities if LLMs are broadly adoptedin healthcare. To address this, we propose and evaluate a novel framework,EquityGuard, designed to detect and mitigate biases in LLM-based medicalapplications. EquityGuard incorporates a Bias Detection Mechanism capable ofidentifying and correcting unfair predictions, thus enhancing outcomes andpromoting equity across diverse population groups.</description><author>Yuelyu Ji, Wenhe Ma, Sonish Sivarajkumar, Hang Zhang, Eugene Mathew Sadhu, Zhuochun Li, Xizhi Wu, Shyam Visweswaran, Yanshan Wang</author><pubDate>Mon, 07 Oct 2024 16:40:21 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.05180v1</guid></item><item><title>MetaMetrics: Calibrating Metrics For Generation Tasks Using Human Preferences</title><link>http://arxiv.org/abs/2410.02381v2</link><description>Understanding the quality of a performance evaluation metric is crucial forensuring that model outputs align with human preferences. However, it remainsunclear how well each metric captures the diverse aspects of these preferences,as metrics often excel in one particular area but not across all dimensions. Toaddress this, it is essential to systematically calibrate metrics to specificaspects of human preference, catering to the unique characteristics of eachaspect. We introduce MetaMetrics, a calibrated meta-metric designed to evaluategeneration tasks across different modalities in a supervised manner.MetaMetrics optimizes the combination of existing metrics to enhance theiralignment with human preferences. Our metric demonstrates flexibility andeffectiveness in both language and vision downstream tasks, showing significantbenefits across various multilingual and multi-domain scenarios. MetaMetricsaligns closely with human preferences and is highly extendable and easilyintegrable into any application. This makes MetaMetrics a powerful tool forimproving the evaluation of generation tasks, ensuring that metrics are morerepresentative of human judgment across diverse contexts.</description><author>Genta Indra Winata, David Anugraha, Lucky Susanto, Garry Kuwanto, Derry Tanti Wijaya</author><pubDate>Mon, 07 Oct 2024 16:39:24 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.02381v2</guid></item><item><title>A Usage-centric Take on Intent Understanding in E-Commerce</title><link>http://arxiv.org/abs/2402.14901v2</link><description>Identifying and understanding user intents is a pivotal task for E-Commerce.Despite its essential role in product recommendation and business userprofiling analysis, intent understanding has not been consistently defined oraccurately benchmarked. In this paper, we focus on predicative user intents as"how a customer uses a product", and pose intent understanding as a naturallanguage reasoning task, independent of product ontologies. We identify twoweaknesses of FolkScope, the SOTA E-Commerce Intent Knowledge Graph:category-rigidity and property-ambiguity. They limit its ability to stronglyalign user intents with products having the most desirable property, and torecommend useful products across diverse categories. Following theseobservations, we introduce a Product Recovery Benchmark featuring a novelevaluation framework and an example dataset. We further validate the aboveFolkScope weaknesses on this benchmark. Our code and dataset are available athttps://github.com/stayones/Usgae-Centric-Intent-Understanding.</description><author>Wendi Zhou, Tianyi Li, Pavlos Vougiouklis, Mark Steedman, Jeff Z. Pan</author><pubDate>Mon, 07 Oct 2024 16:38:35 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.14901v2</guid></item><item><title>Machine Learning Based Optimal Design of Fibrillar Adhesives</title><link>http://arxiv.org/abs/2409.05928v3</link><description>Fibrillar adhesion, observed in animals like beetles, spiders, and geckos,relies on nanoscopic or microscopic fibrils to enhance surface adhesion via'contact splitting.' This concept has inspired engineering applications acrossrobotics, transportation, and medicine. Recent studies suggest that functionalgrading of fibril properties can improve adhesion, but this is a complex designchallenge that has only been explored in simplified geometries. While machinelearning (ML) has gained traction in adhesive design, no previous attempts havetargeted fibril-array scale optimization. In this study, we propose an ML-basedtool that optimizes the distribution of fibril compliance to maximize adhesivestrength. Our tool, featuring two deep neural networks (DNNs), recoversprevious design results for simple geometries and introduces novel solutionsfor complex configurations. The Predictor DNN estimates adhesive strength basedon random compliance distributions, while the Designer DNN optimizes compliancefor maximum strength using gradient-based optimization. Our methodsignificantly reduces test error and accelerates the optimization process,offering a high-performance solution for designing fibrillar adhesives andmicro-architected materials aimed at fracture resistance by achieving equalload sharing (ELS).</description><author>Mohammad Shojaeifard, Matteo Ferraresso, Alessandro Lucantonio, Mattia Bacca</author><pubDate>Mon, 07 Oct 2024 16:37:56 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2409.05928v3</guid></item><item><title>Are causal effect estimations enough for optimal recommendations under multitreatment scenarios?</title><link>http://arxiv.org/abs/2410.05177v1</link><description>When making treatment selection decisions, it is essential to include acausal effect estimation analysis to compare potential outcomes under differenttreatments or controls, assisting in optimal selection. However, merelyestimating individual treatment effects may not suffice for truly optimaldecisions. Our study addressed this issue by incorporating additional criteria,such as the estimations' uncertainty, measured by the conditionalvalue-at-risk, commonly used in portfolio and insurance management. Forcontinuous outcomes observable before and after treatment, we incorporated aspecific prediction condition. We prioritized treatments that could yieldoptimal treatment effect results and lead to post-treatment outcomes moredesirable than pretreatment levels, with the latter condition being called theprediction criterion. With these considerations, we propose a comprehensivemethodology for multitreatment selection. Our approach ensures satisfaction ofthe overlap assumption, crucial for comparing outcomes for treated and controlgroups, by training propensity score models as a preliminary step beforeemploying traditional causal models. To illustrate a practical application ofour methodology, we applied it to the credit card limit adjustment problem.Analyzing a fintech company's historical data, we found that relying solely oncounterfactual predictions was inadequate for appropriate credit linemodifications. Incorporating our proposed additional criteria significantlyenhanced policy performance.</description><author>Sherly Alfonso-SÃ¡nchez, Kristina P. Sendova, CristiÃ¡n Bravo</author><pubDate>Mon, 07 Oct 2024 16:37:35 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.05177v1</guid></item><item><title>Jailbreaking Leading Safety-Aligned LLMs with Simple Adaptive Attacks</title><link>http://arxiv.org/abs/2404.02151v3</link><description>We show that even the most recent safety-aligned LLMs are not robust tosimple adaptive jailbreaking attacks. First, we demonstrate how to successfullyleverage access to logprobs for jailbreaking: we initially design anadversarial prompt template (sometimes adapted to the target LLM), and then weapply random search on a suffix to maximize a target logprob (e.g., of thetoken "Sure"), potentially with multiple restarts. In this way, we achieve 100%attack success rate -- according to GPT-4 as a judge -- on Vicuna-13B,Mistral-7B, Phi-3-Mini, Nemotron-4-340B, Llama-2-Chat-7B/13B/70B,Llama-3-Instruct-8B, Gemma-7B, GPT-3.5, GPT-4o, and R2D2 from HarmBench thatwas adversarially trained against the GCG attack. We also show how to jailbreakall Claude models -- that do not expose logprobs -- via either a transfer orprefilling attack with a 100% success rate. In addition, we show how to userandom search on a restricted set of tokens for finding trojan strings inpoisoned models -- a task that shares many similarities with jailbreaking --which is the algorithm that brought us the first place in the SaTML'24 TrojanDetection Competition. The common theme behind these attacks is that adaptivityis crucial: different models are vulnerable to different prompting templates(e.g., R2D2 is very sensitive to in-context learning prompts), some models haveunique vulnerabilities based on their APIs (e.g., prefilling for Claude), andin some settings, it is crucial to restrict the token search space based onprior knowledge (e.g., for trojan detection). For reproducibility purposes, weprovide the code, logs, and jailbreak artifacts in the JailbreakBench format athttps://github.com/tml-epfl/llm-adaptive-attacks.</description><author>Maksym Andriushchenko, Francesco Croce, Nicolas Flammarion</author><pubDate>Mon, 07 Oct 2024 16:35:15 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.02151v3</guid></item><item><title>Efficient Model-Agnostic Multi-Group Equivariant Networks</title><link>http://arxiv.org/abs/2310.09675v2</link><description>Constructing model-agnostic group equivariant networks, such as equitune(Basu et al., 2023b) and its generalizations (Kim et al., 2023), can becomputationally expensive for large product groups. We address this problem byproviding efficient model-agnostic equivariant designs for two relatedproblems: one where the network has multiple inputs each with potentiallydifferent groups acting on them, and another where there is a single input butthe group acting on it is a large product group. For the first design, weinitially consider a linear model and characterize the entire equivariant spacethat satisfies this constraint. This characterization gives rise to a novelfusion layer between different channels that satisfies an invariance-symmetry(IS) constraint, which we call an IS layer. We then extend this design beyondlinear models, similar to equitune, consisting of equivariant and IS layers. Wealso show that the IS layer is a universal approximator of invariant-symmetricfunctions. Inspired by the first design, we use the notion of the IS propertyto design a second efficient model-agnostic equivariant design for largeproduct groups acting on a single input. For the first design, we provideexperiments on multi-image classification where each view is transformedindependently with transformations such as rotations. We find equivariantmodels are robust to such transformations and perform competitively otherwise.For the second design, we consider three applications: languagecompositionality on the SCAN dataset to product groups; fairness in naturallanguage generation from GPT-2 to address intersectionality; and robustzero-shot image classification with CLIP. Overall, our methods are simple andgeneral, competitive with equitune and its variants, while also beingcomputationally more efficient.</description><author>Razan Baltaji, Sourya Basu, Lav R. Varshney</author><pubDate>Mon, 07 Oct 2024 16:28:52 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.09675v2</guid></item><item><title>When "A Helpful Assistant" Is Not Really Helpful: Personas in System Prompts Do Not Improve Performances of Large Language Models</title><link>http://arxiv.org/abs/2311.10054v2</link><description>Prompting serves as the major way humans interact with Large Language Models(LLM). Commercial AI systems commonly define the role of the LLM in systemprompts. For example, ChatGPT uses "You are a helpful assistant" as part of itsdefault system prompt. Despite current practices of adding personas to systemprompts, it remains unclear how different personas affect a model's performanceon objective tasks. In this study, we present a systematic evaluation ofpersonas in system prompts. We curate a list of 162 roles covering 6 types ofinterpersonal relationships and 8 domains of expertise. Through extensiveanalysis of 4 popular families of LLMs and 2,410 factual questions, wedemonstrate that adding personas in system prompts does not improve modelperformance across a range of questions compared to the control setting whereno persona is added. Nevertheless, further analysis suggests that the gender,type, and domain of the persona can all influence the resulting predictionaccuracies. We further experimented with a list of persona search strategiesand found that, while aggregating results from the best persona for eachquestion significantly improves prediction accuracy, automatically identifyingthe best persona is challenging, with predictions often performing no betterthan random selection. Overall, our findings suggest that while adding apersona may lead to performance gains in certain settings, the effect of eachpersona can be largely random. Code and data are available athttps://github.com/Jiaxin-Pei/Prompting-with-Social-Roles.</description><author>Mingqian Zheng, Jiaxin Pei, Lajanugen Logeswaran, Moontae Lee, David Jurgens</author><pubDate>Mon, 07 Oct 2024 16:26:00 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.10054v2</guid></item><item><title>ReasoningRank: Teaching Student Models to Rank through Reasoning-Based Knowledge Distillation</title><link>http://arxiv.org/abs/2410.05168v1</link><description>Reranking documents based on their relevance to a given query is critical ininformation retrieval. Traditional reranking methods often focus on improvingthe initial rankings but lack transparency, failing to explain why one documentis ranked higher. In this paper, we introduce ReasoningRank, a novel rerankingapproach that enhances clarity by generating two types of reasoning: explicitreasoning, which explains how a document addresses the query, and comparisonreasoning, which justifies the relevance of one document over another. Weleverage large language models (LLMs) as teacher models to generate theseexplanations and distill this knowledge into smaller, more resource-efficientstudent models. While the student models may not outperform LLMs in speed, theysignificantly reduce the computational burden by requiring fewer resources,making them more suitable for large-scale or resource-constrained settings.These student models are trained to both generate meaningful reasoning andrerank documents, achieving competitive performance across multiple datasets,including MSMARCO and BRIGHT. Experiments demonstrate that ReasoningRankimproves reranking accuracy and provides valuable insights into thedecision-making process, offering a structured and interpretable solution forreranking tasks.</description><author>Yuelyu Ji, Zhuochun Li, Rui Meng, Daqing He</author><pubDate>Mon, 07 Oct 2024 16:25:39 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.05168v1</guid></item><item><title>Learning to Steer Markovian Agents under Model Uncertainty</title><link>http://arxiv.org/abs/2407.10207v2</link><description>Designing incentives for an adapting population is a ubiquitous problem in awide array of economic applications and beyond. In this work, we study how todesign additional rewards to steer multi-agent systems towards desired policies\emph{without} prior knowledge of the agents' underlying learning dynamics.Motivated by the limitation of existing works, we consider a new and generalcategory of learning dynamics called \emph{Markovian agents}. We introduce amodel-based non-episodic Reinforcement Learning (RL) formulation for oursteering problem. Importantly, we focus on learning a \emph{history-dependent}steering strategy to handle the inherent model uncertainty about the agents'learning dynamics. We introduce a novel objective function to encode thedesiderata of achieving a good steering outcome with reasonable cost.Theoretically, we identify conditions for the existence of steering strategiesto guide agents to the desired policies. Complementing our theoreticalcontributions, we provide empirical algorithms to approximately solve ourobjective, which effectively tackles the challenge in learninghistory-dependent strategies. We demonstrate the efficacy of our algorithmsthrough empirical evaluations.</description><author>Jiawei Huang, Vinzenz Thoma, Zebang Shen, Heinrich H. Nax, Niao He</author><pubDate>Mon, 07 Oct 2024 16:25:34 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.10207v2</guid></item><item><title>Better Instruction-Following Through Minimum Bayes Risk</title><link>http://arxiv.org/abs/2410.02902v2</link><description>General-purpose LLM judges capable of human-level evaluation provide not onlya scalable and accurate way of evaluating instruction-following LLMs but alsonew avenues for supervising and improving their performance. One promising wayof leveraging LLM judges for supervision is through Minimum Bayes Risk (MBR)decoding, which uses a reference-based evaluator to select a high-qualityoutput from amongst a set of candidate outputs. In the first part of this work,we explore using MBR decoding as a method for improving the test-timeperformance of instruction-following LLMs. We find that MBR decoding withreference-based LLM judges substantially improves over greedy decoding,best-of-N decoding with reference-free judges and MBR decoding with lexical andembedding-based metrics on AlpacaEval and MT-Bench. These gains are consistentacross LLMs with up to 70B parameters, demonstrating that smaller LLM judgescan be used to supervise much larger LLMs. Then, seeking to retain theimprovements from MBR decoding while mitigating additional test-time costs, weexplore iterative self-training on MBR-decoded outputs. We find thatself-training using Direct Preference Optimisation leads to significantperformance gains, such that the self-trained models with greedy decodinggenerally match and sometimes exceed the performance of their base models withMBR decoding.</description><author>Ian Wu, Patrick Fernandes, Amanda Bertsch, Seungone Kim, Sina Pakazad, Graham Neubig</author><pubDate>Mon, 07 Oct 2024 16:25:04 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.02902v2</guid></item><item><title>Deep Fusion: Capturing Dependencies in Contrastive Learning via Transformer Projection Heads</title><link>http://arxiv.org/abs/2403.18681v2</link><description>Contrastive Learning (CL) has emerged as a powerful method for trainingfeature extraction models using unlabeled data. Recent studies suggest thatincorporating a linear projection head post-backbone significantly enhancesmodel performance. In this work, we investigate the use of a transformer modelas a projection head within the CL framework, aiming to exploit thetransformer's capacity for capturing long-range dependencies across embeddingsto further improve performance. Our key contributions are fourfold: First, weintroduce a novel application of transformers in the projection head role forcontrastive learning, marking the first endeavor of its kind. Second, ourexperiments reveal a compelling "Deep Fusion" phenomenon where the attentionmechanism progressively captures the correct relational dependencies amongsamples from the same class in deeper layers. Third, we provide a theoreticalframework that explains and supports this "Deep Fusion" behavior. Finally, wedemonstrate through experimental results that our model achieves superiorperformance compared to the existing approach of using a feed-forward layer.</description><author>Huanran Li, Daniel Pimentel-AlarcÃ³n</author><pubDate>Mon, 07 Oct 2024 16:25:02 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.18681v2</guid></item><item><title>Presto! Distilling Steps and Layers for Accelerating Music Generation</title><link>http://arxiv.org/abs/2410.05167v1</link><description>Despite advances in diffusion-based text-to-music (TTM) methods, efficient,high-quality generation remains a challenge. We introduce Presto!, an approachto inference acceleration for score-based diffusion transformers via reducingboth sampling steps and cost per step. To reduce steps, we develop a newscore-based distribution matching distillation (DMD) method for the EDM-familyof diffusion models, the first GAN-based distillation method for TTM. To reducethe cost per step, we develop a simple, but powerful improvement to a recentlayer distillation method that improves learning via better preserving hiddenstate variance. Finally, we combine our step and layer distillation methodstogether for a dual-faceted approach. We evaluate our step and layerdistillation methods independently and show each yield best-in-classperformance. Our combined distillation method can generate high-quality outputswith improved diversity, accelerating our base model by 10-18x (230/435mslatency for 32 second mono/stereo 44.1kHz, 15x faster than comparable SOTA) --the fastest high-quality TTM to our knowledge. Sound examples can be found athttps://presto-music.github.io/web/.</description><author>Zachary Novack, Ge Zhu, Jonah Casebeer, Julian McAuley, Taylor Berg-Kirkpatrick, Nicholas J. Bryan</author><pubDate>Mon, 07 Oct 2024 16:24:18 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.05167v1</guid></item><item><title>Efficient Inference for Large Language Model-based Generative Recommendation</title><link>http://arxiv.org/abs/2410.05165v1</link><description>Large Language Model (LLM)-based generative recommendation has achievednotable success, yet its practical deployment is costly particularly due toexcessive inference latency caused by autoregressive decoding. For lossless LLMdecoding acceleration, Speculative Decoding (SD) has emerged as a promisingsolution. However, applying SD to generative recommendation presents uniquechallenges due to the requirement of generating top-K items (i.e., K distincttoken sequences) as a recommendation list by beam search. This leads to morestringent verification in SD, where all the top-K sequences from the target LLMmust be successfully drafted by the draft model at each decoding step. Toalleviate this, we consider 1) boosting top-K sequence alignment between thedraft model and the target LLM, and 2) relaxing the verification strategy toreduce trivial LLM calls. To this end, we propose an alignment framework namedAtSpeed, which presents the AtSpeed-S optimization objective for top-Kalignment under the strict top-K verification. Moreover, we introduce a relaxedsampling verification strategy that allows high-probability non-top-K draftedsequences to be accepted, significantly reducing LLM calls. Correspondingly, wepropose AtSpeed-R for top-K alignment under this relaxed sampling verification.Empirical results on two real-world datasets demonstrate that AtSpeedsignificantly accelerates LLM-based generative recommendation, e.g., near 2xspeedup under strict top-K verification and up to 2.5 speedup under relaxedsampling verification. The codes and datasets will be released in the nearfuture.</description><author>Xinyu Lin, Chaoqun Yang, Wenjie Wang, Yongqi Li, Cunxiao Du, Fuli Feng, See-Kiong Ng, Tat-Seng Chua</author><pubDate>Mon, 07 Oct 2024 16:23:36 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.05165v1</guid></item><item><title>Hydra: Sequentially-Dependent Draft Heads for Medusa Decoding</title><link>http://arxiv.org/abs/2402.05109v2</link><description>To combat the memory bandwidth-bound nature of autoregressive LLM inference,previous research has proposed the speculative decoding frame-work. To performspeculative decoding, a small draft model proposes candidate continuations ofthe input sequence that are then verified in parallel by the base model. Oneway to specify the draft model, as used in the recent Medusa decodingframework, is as a collection of lightweight heads, called draft heads, thatoperate on the base model's hidden states. To date, all existing draft headshave been sequentially independent, meaning that they speculate tokens in thecandidate continuation independently of any preceding tokens in the candidatecontinuation. In this work, we propose Hydra heads: a sequentially-dependentdrop-in replacement for standard draft heads that significantly improves theaccuracy of draft head speculation. We further explore the design space ofHydra head training objectives and architectures, and propose a carefully tunedHydra head recipe, which we call Hydra++, that improves decoding throughput byup to 1.31x and 2.70x compared to Medusa decoding and autoregressive de-codingrespectively. Overall, Hydra heads are a simple and well-motivated interventionon standard draft heads that significantly improve the end-to-end speed ofdraft head-based speculative decoding. We make our code publicly available athttps://github.com/zankner/Hydra.</description><author>Zachary Ankner, Rishab Parthasarathy, Aniruddha Nrusimha, Christopher Rinard, Jonathan Ragan-Kelley, William Brandon</author><pubDate>Mon, 07 Oct 2024 16:21:29 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.05109v2</guid></item><item><title>CYCLO: Cyclic Graph Transformer Approach to Multi-Object Relationship Modeling in Aerial Videos</title><link>http://arxiv.org/abs/2406.01029v2</link><description>Video scene graph generation (VidSGG) has emerged as a transformativeapproach to capturing and interpreting the intricate relationships amongobjects and their temporal dynamics in video sequences. In this paper, weintroduce the new AeroEye dataset that focuses on multi-object relationshipmodeling in aerial videos. Our AeroEye dataset features various drone scenesand includes a visually comprehensive and precise collection of predicates thatcapture the intricate relationships and spatial arrangements among objects. Tothis end, we propose the novel Cyclic Graph Transformer (CYCLO) approach thatallows the model to capture both direct and long-range temporal dependencies bycontinuously updating the history of interactions in a circular manner. Theproposed approach also allows one to handle sequences with inherent cyclicalpatterns and process object relationships in the correct sequential order.Therefore, it can effectively capture periodic and overlapping relationshipswhile minimizing information loss. The extensive experiments on the AeroEyedataset demonstrate the effectiveness of the proposed CYCLO model,demonstrating its potential to perform scene understanding on drone videos.Finally, the CYCLO method consistently achieves State-of-the-Art (SOTA) resultson two in-the-wild scene graph generation benchmarks, i.e., PVSG and ASPIRe.</description><author>Trong-Thuan Nguyen, Pha Nguyen, Xin Li, Jackson Cothren, Alper Yilmaz, Khoa Luu</author><pubDate>Mon, 07 Oct 2024 16:20:39 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.01029v2</guid></item><item><title>The SkipSponge Attack: Sponge Weight Poisoning of Deep Neural Networks</title><link>http://arxiv.org/abs/2402.06357v4</link><description>Sponge attacks aim to increase the energy consumption and computation time ofneural networks. In this work, we present a novel sponge attack calledSkipSponge. SkipSponge is the first sponge attack that is performed directly onthe parameters of a pre-trained model using only a few data samples. Ourexperiments show that SkipSponge can successfully increase the energyconsumption of image classification models, GANs, and autoencoders requiringfewer samples than the state-of-the-art (Sponge Poisoning). We show thatpoisoning defenses are ineffective if not adjusted specifically for the defenseagainst SkipSponge (i.e., they decrease target layer bias values). Our workshows that SkipSponge is more effective on the GANs and the autoencoders thanSponge Poisoning. Additionally, SkipSponge is stealthier than Sponge Poisoningas it does not require significant changes in the victim model's weights. Ourexperiments indicate that SkipSponge can be performed even when an attacker hasaccess to only 1% of the entire dataset and reaches up to 13% energy increase.</description><author>Jona te Lintelo, Stefanos Koffas, Stjepan Picek</author><pubDate>Mon, 07 Oct 2024 16:19:17 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.06357v4</guid></item><item><title>GMAI-MMBench: A Comprehensive Multimodal Evaluation Benchmark Towards General Medical AI</title><link>http://arxiv.org/abs/2408.03361v6</link><description>Large Vision-Language Models (LVLMs) are capable of handling diverse datatypes such as imaging, text, and physiological signals, and can be applied invarious fields. In the medical field, LVLMs have a high potential to offersubstantial assistance for diagnosis and treatment. Before that, it is crucialto develop benchmarks to evaluate LVLMs' effectiveness in various medicalapplications. Current benchmarks are often built upon specific academicliterature, mainly focusing on a single domain, and lacking varying perceptualgranularities. Thus, they face specific challenges, including limited clinicalrelevance, incomplete evaluations, and insufficient guidance for interactiveLVLMs. To address these limitations, we developed the GMAI-MMBench, the mostcomprehensive general medical AI benchmark with well-categorized data structureand multi-perceptual granularity to date. It is constructed from 284 datasetsacross 38 medical image modalities, 18 clinical-related tasks, 18 departments,and 4 perceptual granularities in a Visual Question Answering (VQA) format.Additionally, we implemented a lexical tree structure that allows users tocustomize evaluation tasks, accommodating various assessment needs andsubstantially supporting medical AI research and applications. We evaluated 50LVLMs, and the results show that even the advanced GPT-4o only achieves anaccuracy of 53.96%, indicating significant room for improvement. Moreover, weidentified five key insufficiencies in current cutting-edge LVLMs that need tobe addressed to advance the development of better medical applications. Webelieve that GMAI-MMBench will stimulate the community to build the nextgeneration of LVLMs toward GMAI.</description><author>Pengcheng Chen, Jin Ye, Guoan Wang, Yanjun Li, Zhongying Deng, Wei Li, Tianbin Li, Haodong Duan, Ziyan Huang, Yanzhou Su, Benyou Wang, Shaoting Zhang, Bin Fu, Jianfei Cai, Bohan Zhuang, Eric J Seibel, Junjun He, Yu Qiao</author><pubDate>Mon, 07 Oct 2024 16:18:21 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.03361v6</guid></item><item><title>A Simulation-Free Deep Learning Approach to Stochastic Optimal Control</title><link>http://arxiv.org/abs/2410.05163v1</link><description>We propose a simulation-free algorithm for the solution of generic problemsin stochastic optimal control (SOC). Unlike existing methods, our approach doesnot require the solution of an adjoint problem, but rather leverages Girsanovtheorem to directly calculate the gradient of the SOC objective on-policy. Thisallows us to speed up the optimization of control policies parameterized byneural networks since it completely avoids the expensive back-propagation stepthrough stochastic differential equations (SDEs) used in the Neural SDEframework. In particular, it enables us to solve SOC problems in high dimensionand on long time horizons. We demonstrate the efficiency of our approach invarious domains of applications, including standard stochastic optimal controlproblems, sampling from unnormalized distributions via construction of aSchr\"odinger-F\"ollmer process, and fine-tuning of pre-trained diffusionmodels. In all cases our method is shown to outperform the existing methods inboth the computing time and memory efficiency.</description><author>Mengjian Hua, Matthieu LauriÃ¨re, Eric Vanden-Eijnden</author><pubDate>Mon, 07 Oct 2024 16:16:53 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.05163v1</guid></item><item><title>Robust Multimodal Learning with Missing Modalities via Parameter-Efficient Adaptation</title><link>http://arxiv.org/abs/2310.03986v6</link><description>Multimodal learning seeks to utilize data from multiple sources to improvethe overall performance of downstream tasks. It is desirable for redundanciesin the data to make multimodal systems robust to missing or corruptedobservations in some correlated modalities. However, we observe that theperformance of several existing multimodal networks significantly deterioratesif one or multiple modalities are absent at test time. To enable robustness tomissing modalities, we propose a simple and parameter-efficient adaptationprocedure for pretrained multimodal networks. In particular, we exploitmodulation of intermediate features to compensate for the missing modalities.We demonstrate that such adaptation can partially bridge performance drop dueto missing modalities and outperform independent, dedicated networks trainedfor the available modality combinations in some cases. The proposed adaptationrequires extremely small number of parameters (e.g., fewer than 1% of the totalparameters) and applicable to a wide range of modality combinations and tasks.We conduct a series of experiments to highlight the missing modality robustnessof our proposed method on five different multimodal tasks across sevendatasets. Our proposed method demonstrates versatility across various tasks anddatasets, and outperforms existing methods for robust multimodal learning withmissing modalities.</description><author>Md Kaykobad Reza, Ashley Prater-Bennette, M. Salman Asif</author><pubDate>Mon, 07 Oct 2024 16:15:36 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.03986v6</guid></item><item><title>Deciphering the Interplay of Parametric and Non-parametric Memory in Retrieval-augmented Language Models</title><link>http://arxiv.org/abs/2410.05162v1</link><description>Generative language models often struggle with specialized or less-discussedknowledge. A potential solution is found in Retrieval-Augmented Generation(RAG) models which act like retrieving information before generating responses.In this study, we explore how the \textsc{Atlas} approach, a RAG model, decidesbetween what it already knows (parametric) and what it retrieves(non-parametric). We use causal mediation analysis and controlled experimentsto examine how internal representations influence information processing. Ourfindings disentangle the effects of parametric knowledge and the retrievedcontext. They indicate that in cases where the model can choose between bothtypes of information (parametric and non-parametric), it relies more on thecontext than the parametric knowledge. Furthermore, the analysis investigatesthe computations involved in \emph{how} the model uses the information from thecontext. We find that multiple mechanisms are active within the model and canbe detected with mediation analysis: first, the decision of \emph{whether thecontext is relevant}, and second, how the encoder computes outputrepresentations to support copying when relevant.</description><author>Mehrdad Farahani, Richard Johansson</author><pubDate>Mon, 07 Oct 2024 16:14:47 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.05162v1</guid></item><item><title>VLM2Vec: Training Vision-Language Models for Massive Multimodal Embedding Tasks</title><link>http://arxiv.org/abs/2410.05160v1</link><description>Embedding models have been crucial in enabling various downstream tasks suchas semantic similarity, information retrieval, and clustering. Recently, therehas been a surge of interest in developing universal text embedding models thatcan generalize across tasks (e.g., MTEB). However, progress in learninguniversal multimodal embedding models has been relatively slow despite theirimportance. In this work, we aim to explore the potential for buildinguniversal embeddings capable of handling a wide range of downstream tasks. Ourcontributions are twofold: (1) MMEB (Massive Multimodal Embedding Benchmark),which covers 4 meta-tasks (i.e. classification, visual question answering,multimodal retrieval, and visual grounding) and 36 datasets, including 20training and 16 evaluation datasets, and (2) VLM2Vec (Vision-Language Model -&gt;Vector), a contrastive training framework that converts any state-of-the-artvision-language model into an embedding model via training on MMEB. Unlikeprevious models such as CLIP and BLIP, VLM2Vec can process any combination ofimages and text to generate a fixed-dimensional vector based on taskinstructions. We build a series of VLM2Vec models on Phi-3.5-V and evaluatethem on MMEB's evaluation split. Our results show that \model achieves anabsolute average improvement of 10% to 20% over existing multimodal embeddingmodels on both in-distribution and out-of-distribution datasets in MMEB.</description><author>Ziyan Jiang, Rui Meng, Xinyi Yang, Semih Yavuz, Yingbo Zhou, Wenhu Chen</author><pubDate>Mon, 07 Oct 2024 16:14:05 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.05160v1</guid></item><item><title>MIBench: A Comprehensive Benchmark for Model Inversion Attack and Defense</title><link>http://arxiv.org/abs/2410.05159v1</link><description>Model Inversion (MI) attacks aim at leveraging the output information oftarget models to reconstruct privacy-sensitive training data, raisingwidespread concerns on privacy threats of Deep Neural Networks (DNNs).Unfortunately, in tandem with the rapid evolution of MI attacks, the lack of acomprehensive, aligned, and reliable benchmark has emerged as a formidablechallenge. This deficiency leads to inadequate comparisons between differentattack methods and inconsistent experimental setups. In this paper, weintroduce the first practical benchmark for model inversion attacks anddefenses to address this critical gap, which is named \textit{MIBench}. Thisbenchmark serves as an extensible and reproducible modular-based toolbox andcurrently integrates a total of 16 state-of-the-art attack and defense methods.Moreover, we furnish a suite of assessment tools encompassing 9 commonly usedevaluation protocols to facilitate standardized and fair evaluation andanalysis. Capitalizing on this foundation, we conduct extensive experimentsfrom multiple perspectives to holistically compare and analyze the performanceof various methods across different scenarios, which overcomes the misalignmentissues and discrepancy prevalent in previous works. Based on the collectedattack methods and defense strategies, we analyze the impact of targetresolution, defense robustness, model predictive power, model architectures,transferability and loss function. Our hope is that this \textit{MIBench} couldprovide a unified, practical and extensible toolbox and is widely utilized byresearchers in the field to rigorously test and compare their novel methods,ensuring equitable evaluations and thereby propelling further advancements inthe future development.</description><author>Yixiang Qiu, Hongyao Yu, Hao Fang, Wenbo Yu, Bin Chen, Xuan Wang, Shu-Tao Xia, Ke Xu</author><pubDate>Mon, 07 Oct 2024 16:13:49 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.05159v1</guid></item><item><title>Preventing Collapse in Contrastive Learning with Orthonormal Prototypes (CLOP)</title><link>http://arxiv.org/abs/2403.18699v2</link><description>Contrastive learning has emerged as a powerful method in deep learning,excelling at learning effective representations through contrasting samplesfrom different distributions. However, neural collapse, where embeddingsconverge into a lower-dimensional space, poses a significant challenge,especially in semi-supervised and self-supervised setups. In this paper, wefirst theoretically analyze the effect of large learning rates on contrastivelosses that solely rely on the cosine similarity metric, and derive atheoretical bound to mitigate this collapse. {Building on these insights, wepropose CLOP, a novel semi-supervised loss function designed to prevent neuralcollapse by promoting the formation of orthogonal linear subspaces among classembeddings.} Unlike prior approaches that enforce a simplex ETF structure, CLOPfocuses on subspace separation, leading to more distinguishable embeddings.Through extensive experiments on real and synthetic datasets, we demonstratethat CLOP enhances performance, providing greater stability across differentlearning rates and batch sizes.</description><author>Huanran Li, Manh Nguyen, Daniel Pimentel-AlarcÃ³n</author><pubDate>Mon, 07 Oct 2024 16:07:23 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.18699v2</guid></item><item><title>NoSENSE: Learned unrolled cardiac MRI reconstruction without explicit sensitivity maps</title><link>http://arxiv.org/abs/2309.15608v2</link><description>We present a novel learned image reconstruction method for acceleratedcardiac MRI with multiple receiver coils based on deep convolutional neuralnetworks (CNNs) and algorithm unrolling. In contrast to many existing learnedMR image reconstruction techniques that necessitate coil-sensitivity map (CSM)estimation as a distinct network component, our proposed approach avoidsexplicit CSM estimation. Instead, it implicitly captures and learns to exploitthe inter-coil relationships of the images. Our method consists of a series ofnovel learned image and k-space blocks with shared latent information andadaptation to the acquisition parameters by feature-wise modulation (FiLM), aswell as coil-wise data-consistency (DC) blocks. Our method achieved PSNR values of 34.89 and 35.56 and SSIM values of 0.920and 0.942 in the cine track and mapping track validation leaderboard of theMICCAI STACOM CMRxRecon Challenge, respectively, ranking 4th among differentteams at the time of writing. Code will be made available at https://github.com/fzimmermann89/CMRxRecon</description><author>Felix Frederik Zimmermann, Andreas Kofler</author><pubDate>Mon, 07 Oct 2024 16:05:53 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2309.15608v2</guid></item><item><title>Representation noising effectively prevents harmful fine-tuning on LLMs</title><link>http://arxiv.org/abs/2405.14577v2</link><description>Releasing open-source large language models (LLMs) presents a dual-use risksince bad actors can easily fine-tune these models for harmful purposes. Evenwithout the open release of weights, weight stealing and fine-tuning APIs makeclosed models vulnerable to harmful fine-tuning attacks (HFAs). While safetymeasures like preventing jailbreaks and improving safety guardrails areimportant, such measures can easily be reversed through fine-tuning. In thiswork, we propose Representation Noising (RepNoise), a defence mechanism that iseffective even when attackers have access to the weights. RepNoise works byremoving information about harmful representations such that it is difficult torecover them during fine-tuning. Importantly, our defence is also able togeneralize across different subsets of harm that have not been seen during thedefence process as long as they are drawn from the same distribution of theattack set. Our method does not degrade the general capability of LLMs andretains the ability to train the model on harmless tasks. We provide empiricalevidence that the effectiveness of our defence lies in its "depth": the degreeto which information about harmful representations is removed across all layersof the LLM.</description><author>Domenic Rosati, Jan Wehner, Kai Williams, Åukasz Bartoszcze, David Atanasov, Robie Gonzales, Subhabrata Majumdar, Carsten Maple, Hassan Sajjad, Frank Rudzicz</author><pubDate>Mon, 07 Oct 2024 16:01:49 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.14577v2</guid></item><item><title>Social Bias Probing: Fairness Benchmarking for Language Models</title><link>http://arxiv.org/abs/2311.09090v4</link><description>While the impact of social biases in language models has been recognized,prior methods for bias evaluation have been limited to binary association testson small datasets, limiting our understanding of bias complexities. This paperproposes a novel framework for probing language models for social biases byassessing disparate treatment, which involves treating individuals differentlyaccording to their affiliation with a sensitive demographic group. We curateSoFa, a large-scale benchmark designed to address the limitations of existingfairness collections. SoFa expands the analysis beyond the binary comparison ofstereotypical versus anti-stereotypical identities to include a diverse rangeof identities and stereotypes. Comparing our methodology with existingbenchmarks, we reveal that biases within language models are more nuanced thanacknowledged, indicating a broader scope of encoded biases than previouslyrecognized. Benchmarking LMs on SoFa, we expose how identities expressingdifferent religions lead to the most pronounced disparate treatments across allmodels. Finally, our findings indicate that real-life adversities faced byvarious groups such as women and people with disabilities are mirrored in thebehavior of these models.</description><author>Marta Marchiori Manerba, Karolina StaÅczak, Riccardo Guidotti, Isabelle Augenstein</author><pubDate>Mon, 07 Oct 2024 16:01:06 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.09090v4</guid></item><item><title>PAMLR: A Passive-Active Multi-Armed Bandit-Based Solution for LoRa Channel Allocation</title><link>http://arxiv.org/abs/2410.05147v1</link><description>Achieving low duty cycle operation in low-power wireless networks in urbanenvironments is complicated by the complex and variable dynamics of externalinterference and fading. We explore the use of reinforcement learning forachieving low power consumption for the task of optimal selection of channels.The learning relies on a hybrid of passive channel sampling for dealing withexternal interference and active channel sampling for dealing with fading. Oursolution, Passive-Active Multi-armed bandit for LoRa (PAMLR, pronounced"Pamela"), balances the two types of samples to achieve energy-efficientchannel selection: active channel measurements are tuned to an appropriatelylow level to update noise thresholds, and to compensate passive channelmeasurements are tuned to an appropriately high level for selecting thetop-most channels from channel exploration using the noise thresholds. Therates of both types of samples are adapted in response to channel dynamics.Based on extensive testing in multiple environments in different cities, wevalidate that PAMLR can maintain excellent communication quality, asdemonstrated by a low SNR regret compared to the optimal channel allocationpolicy, while substantially minimizing the energy cost associated with channelmeasurements.</description><author>Jihoon Yun, Chengzhang Li, Anish Arora</author><pubDate>Mon, 07 Oct 2024 16:00:27 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.05147v1</guid></item><item><title>Differentiable and Learnable Wireless Simulation with Geometric Transformers</title><link>http://arxiv.org/abs/2406.14995v2</link><description>Modelling the propagation of electromagnetic wireless signals is critical fordesigning modern communication systems. Wireless ray tracing simulators modelsignal propagation based on the 3D geometry and other scene parameters, buttheir accuracy is fundamentally limited by underlying modelling assumptions andcorrectness of parameters. In this work, we introduce Wi-GATr, afully-learnable neural simulation surrogate designed to predict the channelobservations based on scene primitives (e.g., surface mesh, antenna positionand orientation). Recognizing the inherently geometric nature of theseprimitives, Wi-GATr leverages an equivariant Geometric Algebra Transformer thatoperates on a tokenizer specifically tailored for wireless simulation. Weevaluate our approach on a range of tasks (i.e., signal strength and delayspread prediction, receiver localization, and geometry reconstruction) and findthat Wi-GATr is accurate, fast, sample-efficient, and robust tosymmetry-induced transformations. Remarkably, we find our results alsotranslate well to the real world: Wi-GATr demonstrates more than 35% lowererror than hybrid techniques, and 70% lower error than a calibrated wirelesstracer.</description><author>Thomas Hehn, Markus Peschl, Tribhuvanesh Orekondy, Arash Behboodi, Johann Brehmer</author><pubDate>Mon, 07 Oct 2024 15:59:03 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.14995v2</guid></item><item><title>CTC-GMM: CTC guided modality matching for fast and accurate streaming speech translation</title><link>http://arxiv.org/abs/2410.05146v1</link><description>Models for streaming speech translation (ST) can achieve high accuracy andlow latency if they're developed with vast amounts of paired audio in thesource language and written text in the target language. Yet, these text labelsfor the target language are often pseudo labels due to the prohibitive cost ofmanual ST data labeling. In this paper, we introduce a methodology namedConnectionist Temporal Classification guided modality matching (CTC-GMM) thatenhances the streaming ST model by leveraging extensive machine translation(MT) text data. This technique employs CTC to compress the speech sequence intoa compact embedding sequence that matches the corresponding text sequence,allowing us to utilize matched {source-target} language text pairs from the MTcorpora to refine the streaming ST model further. Our evaluations with FLEURSand CoVoST2 show that the CTC-GMM approach can increase translation accuracyrelatively by 13.9% and 6.4% respectively, while also boosting decoding speedby 59.7% on GPU.</description><author>Rui Zhao, Jinyu Li, Ruchao Fan, Matt Post</author><pubDate>Mon, 07 Oct 2024 15:58:03 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.05146v1</guid></item><item><title>Efficient Gradient Estimation of Variational Quantum Circuits with Lie Algebraic Symmetries</title><link>http://arxiv.org/abs/2404.05108v2</link><description>Hybrid quantum-classical optimization and learning strategies are among themost promising approaches to harnessing quantum information or gaining aquantum advantage over classical methods. However, efficient estimation of thegradient of the objective function in such models remains a challenge due toseveral factors including the exponential dimensionality of the Hilbert spaces,and information loss of quantum measurements. In this work, we developed anefficient framework that makes the Hadamard test efficiently applicable togradient estimation for a broad range of quantum systems, an advance that hadbeen wanting from the outset. Under certain mild structural assumptions, thegradient is estimated with the measurement shots that scale logarithmicallywith the number of parameters and with polynomial classical and quantum time.This is an exponential reduction in the measurement cost and polynomial speedup in time compared to existing works. The structural assumptions are (1) thedimension of the dynamical Lie algebra is polynomial in the number of qubits,and (2) the observable has a bounded Hilbert-Schmidt norm.</description><author>Mohsen Heidari, Masih Mozakka, Wojciech Szpankowski</author><pubDate>Mon, 07 Oct 2024 15:57:38 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.05108v2</guid></item><item><title>Leveraging Multimodal Diffusion Models to Accelerate Imaging with Side Information</title><link>http://arxiv.org/abs/2410.05143v1</link><description>Diffusion models have found phenomenal success as expressive priors forsolving inverse problems, but their extension beyond natural images to morestructured scientific domains remains limited. Motivated by applications inmaterials science, we aim to reduce the number of measurements required from anexpensive imaging modality of interest, by leveraging side information from anauxiliary modality that is much cheaper to obtain. To deal with thenon-differentiable and black-box nature of the forward model, we propose aframework to train a multimodal diffusion model over the joint modalities,turning inverse problems with black-box forward models into simple linearinpainting problems. Numerically, we demonstrate the feasibility of trainingdiffusion models over materials imagery data, and show that our approachachieves superior image reconstruction by leveraging the available sideinformation, requiring significantly less amount of data from the expensivemicroscopy modality.</description><author>Timofey Efimov, Harry Dong, Megna Shah, Jeff Simmons, Sean Donegan, Yuejie Chi</author><pubDate>Mon, 07 Oct 2024 15:55:02 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.05143v1</guid></item><item><title>Navigating the Maze of Explainable AI: A Systematic Approach to Evaluating Methods and Metrics</title><link>http://arxiv.org/abs/2409.16756v2</link><description>Explainable AI (XAI) is a rapidly growing domain with a myriad of proposedmethods as well as metrics aiming to evaluate their efficacy. However, currentstudies are often of limited scope, examining only a handful of XAI methods andignoring underlying design parameters for performance, such as the modelarchitecture or the nature of input data. Moreover, they often rely on one or afew metrics and neglect thorough validation, increasing the risk of selectionbias and ignoring discrepancies among metrics. These shortcomings leavepractitioners confused about which method to choose for their problem. Inresponse, we introduce LATEC, a large-scale benchmark that critically evaluates17 prominent XAI methods using 20 distinct metrics. We systematicallyincorporate vital design parameters like varied architectures and diverse inputmodalities, resulting in 7,560 examined combinations. Through LATEC, weshowcase the high risk of conflicting metrics leading to unreliable rankingsand consequently propose a more robust evaluation scheme. Further, wecomprehensively evaluate various XAI methods to assist practitioners inselecting appropriate methods aligning with their needs. Curiously, theemerging top-performing method, Expected Gradients, is not examined in anyrelevant related study. LATEC reinforces its role in future XAI research bypublicly releasing all 326k saliency maps and 378k metric scores as a(meta-)evaluation dataset. The benchmark is hosted at:https://github.com/IML-DKFZ/latec.</description><author>Lukas Klein, Carsten T. LÃ¼th, Udo Schlegel, Till J. Bungert, Mennatallah El-Assady, Paul F. JÃ¤ger</author><pubDate>Mon, 07 Oct 2024 15:53:26 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2409.16756v2</guid></item><item><title>Fine-Tuning and Prompt Optimization: Two Great Steps that Work Better Together</title><link>http://arxiv.org/abs/2407.10930v2</link><description>Natural Language Processing (NLP) systems are increasingly taking the form ofsophisticated modular pipelines, e.g., Retrieval Augmented Generation (RAG),where each module may involve a distinct Language Model (LM) and an associatedprompt template. These compound systems often lack intermediate labels orgradient flow to optimize each module, making their end-to-end optimizationchallenging. Here we seek strategies to optimize both the module-level LMweights and the associated prompt templates of such systems to maximize adownstream task metric. We propose for the first time combining the weight andprompt optimization strategies to optimize a modular LM pipeline by alternatingbetween the two to get the same LM to teach itself. In experiments withmulti-hop QA, mathematical reasoning, and feature-based classification usingmistral-7b, llama-2-7b, and llama-3-8b, these BetterTogether strategiesoptimizing the weights and prompts of a pipeline together outperform directlyoptimizing weights alone and prompts alone by up to 60% and 6%, respectively,on average across LMs and tasks. BetterTogether optimizer is released in DSPyat http://dspy.ai</description><author>Dilara Soylu, Christopher Potts, Omar Khattab</author><pubDate>Mon, 07 Oct 2024 15:52:48 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.10930v2</guid></item><item><title>Tuning-Free Bilevel Optimization: New Algorithms and Convergence Analysis</title><link>http://arxiv.org/abs/2410.05140v1</link><description>Bilevel optimization has recently attracted considerable attention due to itsabundant applications in machine learning problems. However, existing methodsrely on prior knowledge of problem parameters to determine stepsizes, resultingin significant effort in tuning stepsizes when these parameters are unknown. Inthis paper, we propose two novel tuning-free algorithms, D-TFBO and S-TFBO.D-TFBO employs a double-loop structure with stepsizes adaptively adjusted bythe "inverse of cumulative gradient norms" strategy. S-TFBO features a simplerfully single-loop structure that updates three variables simultaneously with atheory-motivated joint design of adaptive stepsizes for all variables. Weprovide a comprehensive convergence analysis for both algorithms and show thatD-TFBO and S-TFBO respectively require $O(\frac{1}{\epsilon})$ and$O(\frac{1}{\epsilon}\log^4(\frac{1}{\epsilon}))$ iterations to find an$\epsilon$-accurate stationary point, (nearly) matching their well-tunedcounterparts using the information of problem parameters. Experiments onvarious problems show that our methods achieve performance comparable toexisting well-tuned approaches, while being more robust to the selection ofinitial stepsizes. To the best of our knowledge, our methods are the first tocompletely eliminate the need for stepsize tuning, while achieving theoreticalguarantees.</description><author>Yifan Yang, Hao Ban, Minhui Huang, Shiqian Ma, Kaiyi Ji</author><pubDate>Mon, 07 Oct 2024 15:50:30 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.05140v1</guid></item><item><title>Dr. Jekyll and Mr. Hyde: Two Faces of LLMs</title><link>http://arxiv.org/abs/2312.03853v5</link><description>Recently, we have witnessed a rise in the use of Large Language Models(LLMs), especially in applications like chatbots. Safety mechanisms areimplemented to prevent improper responses from these chatbots. In this work, webypass these measures for ChatGPT and Gemini by making them impersonate complexpersonas with personality characteristics that are not aligned with a truthfulassistant. First, we create elaborate biographies of these personas, which wethen use in a new session with the same chatbots. Our conversations then followa role-play style to elicit prohibited responses. Using personas, we show thatprohibited responses are provided, making it possible to obtain unauthorized,illegal, or harmful information in both ChatGPT and Gemini. We also introduceseveral ways of activating such adversarial personas, showing that bothchatbots are vulnerable to this attack. With the same principle, we introducetwo defenses that push the model to interpret trustworthy personalities andmake it more robust against such attacks.</description><author>Matteo Gioele Collu, Tom Janssen-Groesbeek, Stefanos Koffas, Mauro Conti, Stjepan Picek</author><pubDate>Mon, 07 Oct 2024 15:46:59 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.03853v5</guid></item><item><title>A Neural-Evolutionary Algorithm for Autonomous Transit Network Design</title><link>http://arxiv.org/abs/2403.07917v3</link><description>Planning a public transit network is a challenging optimization problem, butessential in order to realize the benefits of autonomous buses. We propose anovel algorithm for planning networks of routes for autonomous buses. We firsttrain a graph neural net model as a policy for constructing route networks, andthen use the policy as one of several mutation operators in a evolutionaryalgorithm. We evaluate this algorithm on a standard set of benchmarks fortransit network design, and find that it outperforms the learned policy aloneby up to 20% and a plain evolutionary algorithm approach by up to 53% onrealistic benchmark instances.</description><author>Andrew Holliday, Gregory Dudek</author><pubDate>Mon, 07 Oct 2024 15:45:38 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.07917v3</guid></item><item><title>FAC$^2$E: Better Understanding Large Language Model Capabilities by Dissociating Language and Cognition</title><link>http://arxiv.org/abs/2403.00126v2</link><description>Large language models (LLMs) are primarily evaluated by overall performanceon various text understanding and generation tasks. However, such a paradigmfails to comprehensively differentiate the fine-grained language and cognitiveskills, rendering the lack of sufficient interpretation to LLMs' capabilities.In this paper, we present FAC$^2$E, a framework for Fine-grAined andCognition-grounded LLMs' Capability Evaluation. Specifically, we formulateLLMs' evaluation in a multi-dimensional and explainable manner by dissociatingthe language-related capabilities and the cognition-related ones. Besides,through extracting the intermediate reasoning from LLMs, we further break downthe process of applying a specific capability into three sub-steps: recallingrelevant knowledge, utilizing knowledge, and solving problems. Finally,FAC$^2$E evaluates each sub-step of each fine-grained capability, providing atwo-faceted diagnosis for LLMs. Utilizing FAC$^2$E, we identify a commonshortfall in knowledge utilization among models and propose a straightforward,knowledge-enhanced method to mitigate this issue. Our results not only showcasepromising performance enhancements but also highlight a direction for futureLLM advancements.</description><author>Xiaoqiang Wang, Lingfei Wu, Tengfei Ma, Bang Liu</author><pubDate>Mon, 07 Oct 2024 15:44:45 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.00126v2</guid></item><item><title>LOTOS: Layer-wise Orthogonalization for Training Robust Ensembles</title><link>http://arxiv.org/abs/2410.05136v1</link><description>Transferability of adversarial examples is a well-known property thatendangers all classification models, even those that are only accessiblethrough black-box queries. Prior work has shown that an ensemble of models ismore resilient to transferability: the probability that an adversarial exampleis effective against most models of the ensemble is low. Thus, most ongoingresearch focuses on improving ensemble diversity. Another line of prior workhas shown that Lipschitz continuity of the models can make models more robustsince it limits how a model's output changes with small input perturbations. Inthis paper, we study the effect of Lipschitz continuity on transferabilityrates. We show that although a lower Lipschitz constant increases therobustness of a single model, it is not as beneficial in training robustensembles as it increases the transferability rate of adversarial examplesacross models in the ensemble. Therefore, we introduce LOTOS, a new trainingparadigm for ensembles, which counteracts this adverse effect. It does so bypromoting orthogonality among the top-$k$ sub-spaces of the transformations ofthe corresponding affine layers of any pair of models in the ensemble. Wetheoretically show that $k$ does not need to be large for convolutional layers,which makes the computational overhead negligible. Through various experiments,we show LOTOS increases the robust accuracy of ensembles of ResNet-18 models by$6$ percentage points (p.p) against black-box attacks on CIFAR-10. It is alsocapable of combining with the robustness of prior state-of-the-art methods fortraining robust ensembles to enhance their robust accuracy by $10.7$ p.p.</description><author>Ali Ebrahimpour-Boroojeny, Hari Sundaram, Varun Chandrasekaran</author><pubDate>Mon, 07 Oct 2024 15:43:28 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.05136v1</guid></item></channel></rss>