<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/"><channel><title>Arxivfresh papers</title><link></link><description>Arxiv paper</description><language>en-US</language><lastBuildDate>Tue, 27 Jun 2023 14:00:05 GMT</lastBuildDate><generator>rfeed v1.0.0</generator><docs>https://github.com/svpino/rfeed/blob/master/README.md</docs><item><title>FunQA: Towards Surprising Video Comprehension</title><link>http://arxiv.org/abs/2306.14899v1</link><description>Surprising videos, e.g., funny clips, creative performances, or visualillusions, attract significant attention. Enjoyment of these videos is notsimply a response to visual stimuli; rather, it hinges on the human capacity tounderstand (and appreciate) commonsense violations depicted in these videos. Weintroduce FunQA, a challenging video question answering (QA) datasetspecifically designed to evaluate and enhance the depth of video reasoningbased on counter-intuitive and fun videos. Unlike most video QA benchmarkswhich focus on less surprising contexts, e.g., cooking or instructional videos,FunQA covers three previously unexplored types of surprising videos: 1)HumorQA, 2) CreativeQA, and 3) MagicQA. For each subset, we establish rigorousQA tasks designed to assess the model's capability in counter-intuitivetimestamp localization, detailed video description, and reasoning aroundcounter-intuitiveness. We also pose higher-level tasks, such as attributing afitting and vivid title to the video, and scoring the video creativity. Intotal, the FunQA benchmark consists of 312K free-text QA pairs derived from4.3K video clips, spanning a total of 24 video hours. Extensive experimentswith existing VideoQA models reveal significant performance gaps for the FunQAvideos across spatial-temporal reasoning, visual-centered reasoning, andfree-text generation.</description><author>Binzhu Xie, Sicheng Zhang, Zitang Zhou, Bo Li, Yuanhan Zhang, Jack Hessel, Jingkang Yang, Ziwei Liu</author><pubDate>Mon, 26 Jun 2023 18:59:55 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.14899v1</guid></item><item><title>InterCode: Standardizing and Benchmarking Interactive Coding with Execution Feedback</title><link>http://arxiv.org/abs/2306.14898v1</link><description>Humans write code in a fundamentally interactive manner and rely on constantexecution feedback to correct errors, resolve ambiguities, and decompose tasks.While LLMs have recently exhibited promising coding capabilities, currentcoding benchmarks mostly consider a static instruction-to-code sequencetransduction process, which has the potential for error propagation and adisconnect between the generated code and its final execution environment. Toaddress this gap, we introduce InterCode, a lightweight, flexible, andeasy-to-use framework of interactive coding as a standard reinforcementlearning (RL) environment, with code as actions and execution feedback asobservations. Our framework is language and platform agnostic, usesself-contained Docker environments to provide safe and reproducible execution,and is compatible out-of-the-box with traditional seq2seq coding methods, whileenabling the development of new methods for interactive code generation. We useInterCode to create two interactive code environments with Bash and SQL asaction spaces, leveraging data from the static Spider and NL2Bash datasets. Wedemonstrate InterCode's viability as a testbed by evaluating multiplestate-of-the-art LLMs configured with different prompting strategies such asReAct and Plan &amp; Solve. Our results showcase the benefits of interactive codegeneration and demonstrate that InterCode can serve as a challenging benchmarkfor advancing code understanding and generation capabilities. InterCode isdesigned to be easily extensible and can even be used to incorporate new taskssuch as Capture the Flag, a popular coding puzzle that is inherently multi-stepand involves multiple programming languages. Project site with code and data:https://intercode-benchmark.github.io</description><author>John Yang, Akshara Prabhakar, Karthik Narasimhan, Shunyu Yao</author><pubDate>Mon, 26 Jun 2023 18:59:50 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.14898v1</guid></item><item><title>RVT: Robotic View Transformer for 3D Object Manipulation</title><link>http://arxiv.org/abs/2306.14896v1</link><description>For 3D object manipulation, methods that build an explicit 3D representationperform better than those relying only on camera images. But using explicit 3Drepresentations like voxels comes at large computing cost, adversely affectingscalability. In this work, we propose RVT, a multi-view transformer for 3Dmanipulation that is both scalable and accurate. Some key features of RVT arean attention mechanism to aggregate information across views and re-renderingof the camera input from virtual views around the robot workspace. Insimulations, we find that a single RVT model works well across 18 RLBench taskswith 249 task variations, achieving 26% higher relative success than theexisting state-of-the-art method (PerAct). It also trains 36X faster thanPerAct for achieving the same performance and achieves 2.3X the inference speedof PerAct. Further, RVT can perform a variety of manipulation tasks in the realworld with just a few ($\sim$10) demonstrations per task. Visual results, code,and trained model are provided at https://robotic-view-transformer.github.io/.</description><author>Ankit Goyal, Jie Xu, Yijie Guo, Valts Blukis, Yu-Wei Chao, Dieter Fox</author><pubDate>Mon, 26 Jun 2023 18:59:31 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.14896v1</guid></item><item><title>Large Multimodal Models: Notes on CVPR 2023 Tutorial</title><link>http://arxiv.org/abs/2306.14895v1</link><description>This tutorial note summarizes the presentation on ``Large Multimodal Models:Towards Building and Surpassing Multimodal GPT-4'', a part of CVPR 2023tutorial on ``Recent Advances in Vision Foundation Models''. The tutorialconsists of three parts. We first introduce the background on recent GPT-likelarge models for vision-and-language modeling to motivate the research ininstruction-tuned large multimodal models (LMMs). As a pre-requisite, wedescribe the basics of instruction-tuning in large language models, which isfurther extended to the multimodal space. Lastly, we illustrate how to buildthe minimum prototype of multimodal GPT-4 like models with the open-sourceresource, and review the recently emerged topics.</description><author>Chunyuan Li</author><pubDate>Mon, 26 Jun 2023 18:59:31 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.14895v1</guid></item><item><title>LongCoder: A Long-Range Pre-trained Language Model for Code Completion</title><link>http://arxiv.org/abs/2306.14893v1</link><description>In this paper, we introduce a new task for code completion that focuses onhandling long code input and propose a sparse Transformer model, calledLongCoder, to address this task. LongCoder employs a sliding window mechanismfor self-attention and introduces two types of globally accessible tokens -bridge tokens and memory tokens - to improve performance and efficiency. Bridgetokens are inserted throughout the input sequence to aggregate localinformation and facilitate global interaction, while memory tokens are includedto highlight important statements that may be invoked later and need to bememorized, such as package imports and definitions of classes, functions, orstructures. We conduct experiments on a newly constructed dataset that containslonger code context and the publicly available CodeXGLUE benchmark.Experimental results demonstrate that LongCoder achieves superior performanceon code completion tasks compared to previous models while maintainingcomparable efficiency in terms of computational resources during inference. Allthe codes and data are available at https://github.com/microsoft/CodeBERT.</description><author>Daya Guo, Canwen Xu, Nan Duan, Jian Yin, Julian McAuley</author><pubDate>Mon, 26 Jun 2023 18:59:24 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.14893v1</guid></item><item><title>Supervised Pretraining Can Learn In-Context Reinforcement Learning</title><link>http://arxiv.org/abs/2306.14892v1</link><description>Large transformer models trained on diverse datasets have shown a remarkableability to learn in-context, achieving high few-shot performance on tasks theywere not explicitly trained to solve. In this paper, we study the in-contextlearning capabilities of transformers in decision-making problems, i.e.,reinforcement learning (RL) for bandits and Markov decision processes. To doso, we introduce and study Decision-Pretrained Transformer (DPT), a supervisedpretraining method where the transformer predicts an optimal action given aquery state and an in-context dataset of interactions, across a diverse set oftasks. This procedure, while simple, produces a model with several surprisingcapabilities. We find that the pretrained transformer can be used to solve arange of RL problems in-context, exhibiting both exploration online andconservatism offline, despite not being explicitly trained to do so. The modelalso generalizes beyond the pretraining distribution to new tasks andautomatically adapts its decision-making strategies to unknown structure.Theoretically, we show DPT can be viewed as an efficient implementation ofBayesian posterior sampling, a provably sample-efficient RL algorithm. Wefurther leverage this connection to provide guarantees on the regret of thein-context algorithm yielded by DPT, and prove that it can learn faster thanalgorithms used to generate the pretraining data. These results suggest apromising yet simple path towards instilling strong in-context decision-makingabilities in transformers.</description><author>Jonathan N. Lee, Annie Xie, Aldo Pacchiano, Yash Chandak, Chelsea Finn, Ofir Nachum, Emma Brunskill</author><pubDate>Mon, 26 Jun 2023 18:58:50 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.14892v1</guid></item><item><title>Fuzzy-Conditioned Diffusion and Diffusion Projection Attention Applied to Facial Image Correction</title><link>http://arxiv.org/abs/2306.14891v1</link><description>Image diffusion has recently shown remarkable performance in image synthesisand implicitly as an image prior. Such a prior has been used with conditioningto solve the inpainting problem, but only supporting binary user-basedconditioning. We derive a fuzzy-conditioned diffusion, where implicit diffusionpriors can be exploited with controllable strength. Our fuzzy conditioning canbe applied pixel-wise, enabling the modification of different image componentsto varying degrees. Additionally, we propose an application to facial imagecorrection, where we combine our fuzzy-conditioned diffusion withdiffusion-derived attention maps. Our map estimates the degree of anomaly, andwe obtain it by projecting on the diffusion space. We show how our approachalso leads to interpretable and autonomous facial image correction.</description><author>Majed El Helou</author><pubDate>Mon, 26 Jun 2023 18:58:00 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.14891v1</guid></item><item><title>DreamSim: Learning New Dimensions of Human Visual Similarity using Synthetic Data</title><link>http://arxiv.org/abs/2306.09344v2</link><description>Current perceptual similarity metrics operate at the level of pixels andpatches. These metrics compare images in terms of their low-level colors andtextures, but fail to capture mid-level similarities and differences in imagelayout, object pose, and semantic content. In this paper, we develop aperceptual metric that assesses images holistically. Our first step is tocollect a new dataset of human similarity judgments over image pairs that arealike in diverse ways. Critical to this dataset is that judgments are nearlyautomatic and shared by all observers. To achieve this we use recenttext-to-image models to create synthetic pairs that are perturbed along variousdimensions. We observe that popular perceptual metrics fall short of explainingour new data, and we introduce a new metric, DreamSim, tuned to better alignwith human perception. We analyze how our metric is affected by differentvisual attributes, and find that it focuses heavily on foreground objects andsemantic content while also being sensitive to color and layout. Notably,despite being trained on synthetic data, our metric generalizes to real images,giving strong results on retrieval and reconstruction tasks. Furthermore, ourmetric outperforms both prior learned metrics and recent large vision models onthese tasks.</description><author>Stephanie Fu, Netanel Tamir, Shobhita Sundaram, Lucy Chai, Richard Zhang, Tali Dekel, Phillip Isola</author><pubDate>Mon, 26 Jun 2023 18:57:37 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.09344v2</guid></item><item><title>Explainable Parallel RCNN with Novel Feature Representation for Time Series Forecasting</title><link>http://arxiv.org/abs/2305.04876v2</link><description>Accurate time series forecasting is a fundamental challenge in data science.It is often affected by external covariates such as weather or humanintervention, which in many applications, may be predicted with reasonableaccuracy. We refer to them as predicted future covariates. However, existingmethods that attempt to predict time series in an iterative manner withautoregressive models end up with exponential error accumulations. Otherstrategies hat consider the past and future in the encoder and decoderrespectively limit themselves by dealing with the historical and future dataseparately. To address these limitations, a novel feature representationstrategy -- shifting -- is proposed to fuse the past data and future covariatessuch that their interactions can be considered. To extract complex dynamics intime series, we develop a parallel deep learning framework composed of RNN andCNN, both of which are used hierarchically. We also utilize the skip connectiontechnique to improve the model's performance. Extensive experiments on threedatasets reveal the effectiveness of our method. Finally, we demonstrate themodel interpretability using the Grad-CAM algorithm.</description><author>Jimeng Shi, Rukmangadh Myana, Vitalii Stebliankin, Azam Shirali, Giri Narasimhan</author><pubDate>Mon, 26 Jun 2023 18:57:32 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.04876v2</guid></item><item><title>Learning to Modulate pre-trained Models in RL</title><link>http://arxiv.org/abs/2306.14884v1</link><description>Reinforcement Learning (RL) has been successful in various domains likerobotics, game playing, and simulation. While RL agents have shown impressivecapabilities in their specific tasks, they insufficiently adapt to new tasks.In supervised learning, this adaptation problem is addressed by large-scalepre-training followed by fine-tuning to new down-stream tasks. Recently,pre-training on multiple tasks has been gaining traction in RL. However,fine-tuning a pre-trained model often suffers from catastrophic forgetting,that is, the performance on the pre-training tasks deteriorates whenfine-tuning on new tasks. To investigate the catastrophic forgettingphenomenon, we first jointly pre-train a model on datasets from two benchmarksuites, namely Meta-World and DMControl. Then, we evaluate and compare avariety of fine-tuning methods prevalent in natural language processing, bothin terms of performance on new tasks, and how well performance on pre-trainingtasks is retained. Our study shows that with most fine-tuning approaches, theperformance on pre-training tasks deteriorates significantly. Therefore, wepropose a novel method, Learning-to-Modulate (L2M), that avoids the degradationof learned skills by modulating the information flow of the frozen pre-trainedmodel via a learnable modulation pool. Our method achieves state-of-the-artperformance on the Continual-World benchmark, while retaining performance onthe pre-training tasks. Finally, to aid future research in this area, werelease a dataset encompassing 50 Meta-World and 16 DMControl tasks.</description><author>Thomas Schmied, Markus Hofmarcher, Fabian Paischer, Razvan Pascanu, Sepp Hochreiter</author><pubDate>Mon, 26 Jun 2023 18:53:05 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.14884v1</guid></item><item><title>Domain-Scalable Unpaired Image Translation via Latent Space Anchoring</title><link>http://arxiv.org/abs/2306.14879v1</link><description>Unpaired image-to-image translation (UNIT) aims to map images between twovisual domains without paired training data. However, given a UNIT modeltrained on certain domains, it is difficult for current methods to incorporatenew domains because they often need to train the full model on both existingand new domains. To address this problem, we propose a new domain-scalable UNITmethod, termed as latent space anchoring, which can be efficiently extended tonew visual domains and does not need to fine-tune encoders and decoders ofexisting domains. Our method anchors images of different domains to the samelatent space of frozen GANs by learning lightweight encoder and regressormodels to reconstruct single-domain images. In the inference phase, the learnedencoders and decoders of different domains can be arbitrarily combined totranslate images between any two domains without fine-tuning. Experiments onvarious datasets show that the proposed method achieves superior performance onboth standard and domain-scalable UNIT tasks in comparison with thestate-of-the-art methods.</description><author>Siyu Huang, Jie An, Donglai Wei, Zudi Lin, Jiebo Luo, Hanspeter Pfister</author><pubDate>Mon, 26 Jun 2023 18:50:02 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.14879v1</guid></item><item><title>Restart Sampling for Improving Generative Processes</title><link>http://arxiv.org/abs/2306.14878v1</link><description>Generative processes that involve solving differential equations, such asdiffusion models, frequently necessitate balancing speed and quality. ODE-basedsamplers are fast but plateau in performance while SDE-based samplers deliverhigher sample quality at the cost of increased sampling time. We attribute thisdifference to sampling errors: ODE-samplers involve smaller discretizationerrors while stochasticity in SDE contracts accumulated errors. Based on thesefindings, we propose a novel sampling algorithm called Restart in order tobetter balance discretization errors and contraction. The sampling methodalternates between adding substantial noise in additional forward steps andstrictly following a backward ODE. Empirically, Restart sampler surpassesprevious SDE and ODE samplers in both speed and accuracy. Restart not onlyoutperforms the previous best SDE results, but also accelerates the samplingspeed by 10-fold / 2-fold on CIFAR-10 / ImageNet $64 \times 64$. In addition,it attains significantly better sample quality than ODE samplers withincomparable sampling times. Moreover, Restart better balances text-imagealignment/visual quality versus diversity than previous samplers in thelarge-scale text-to-image Stable Diffusion model pre-trained on LAION $512\times 512$. Code is available athttps://github.com/Newbeeer/diffusion_restart_sampling</description><author>Yilun Xu, Mingyang Deng, Xiang Cheng, Yonglong Tian, Ziming Liu, Tommi Jaakkola</author><pubDate>Mon, 26 Jun 2023 18:48:25 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.14878v1</guid></item><item><title>A Fully Unsupervised Instance Segmentation Technique for White Blood Cell Images</title><link>http://arxiv.org/abs/2306.14875v1</link><description>White blood cells, also known as leukocytes are group of heterogeneouslynucleated cells which act as salient immune system cells. These are originatedin the bone marrow and are found in blood, plasma, and lymph tissues.Leukocytes kill the bacteria, virus and other kind of pathogens which invadehuman body through phagocytosis that in turn results immunity. Detection of awhite blood cell count can reveal camouflaged infections and warn doctors aboutchronic medical conditions such as autoimmune diseases, immune deficiencies,and blood disorders. Segmentation plays an important role in identification ofwhite blood cells (WBC) from microscopic image analysis. The goal ofsegmentation in a microscopic image is to divide the image into differentdistinct regions. In our paper, we tried to propose a novel instancesegmentation method for segmenting the WBCs containing both the nucleus and thecytoplasm, from bone marrow images.</description><author>Shrijeet Biswas, Amartya Bhattacharya</author><pubDate>Mon, 26 Jun 2023 18:44:36 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.14875v1</guid></item><item><title>Multiface: A Dataset for Neural Face Rendering</title><link>http://arxiv.org/abs/2207.11243v2</link><description>Photorealistic avatars of human faces have come a long way in recent years,yet research along this area is limited by a lack of publicly available,high-quality datasets covering both, dense multi-view camera captures, and richfacial expressions of the captured subjects. In this work, we presentMultiface, a new multi-view, high-resolution human face dataset collected from13 identities at Reality Labs Research for neural face rendering. We introduceMugsy, a large scale multi-camera apparatus to capture high-resolutionsynchronized videos of a facial performance. The goal of Multiface is to closethe gap in accessibility to high quality data in the academic community and toenable research in VR telepresence. Along with the release of the dataset, weconduct ablation studies on the influence of different model architecturestoward the model's interpolation capacity of novel viewpoint and expressions.With a conditional VAE model serving as our baseline, we found that addingspatial bias, texture warp field, and residual connections improves performanceon novel view synthesis. Our code and data is available at:https://github.com/facebookresearch/multiface</description><author>Cheng-hsin Wuu, Ningyuan Zheng, Scott Ardisson, Rohan Bali, Danielle Belko, Eric Brockmeyer, Lucas Evans, Timothy Godisart, Hyowon Ha, Xuhua Huang, Alexander Hypes, Taylor Koska, Steven Krenn, Stephen Lombardi, Xiaomin Luo, Kevyn McPhail, Laura Millerschoen, Michal Perdoch, Mark Pitts, Alexander Richard, Jason Saragih, Junko Saragih, Takaaki Shiratori, Tomas Simon, Matt Stewart, Autumn Trimble, Xinshuo Weng, David Whitewolf, Chenglei Wu, Shoou-I Yu, Yaser Sheikh</author><pubDate>Mon, 26 Jun 2023 18:43:18 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2207.11243v2</guid></item><item><title>Geometry-Aware Approaches for Balancing Performance and Theoretical Guarantees in Linear Bandits</title><link>http://arxiv.org/abs/2306.14872v1</link><description>This paper is motivated by recent developments in the linear banditliterature, which have revealed a discrepancy between the promising empiricalperformance of algorithms such as Thompson sampling and Greedy, when comparedto their pessimistic theoretical regret bounds. The challenge arises from thefact that while these algorithms may perform poorly in certain probleminstances, they generally excel in typical instances. To address this, wepropose a new data-driven technique that tracks the geometry of the uncertaintyellipsoid, enabling us to establish an instance-dependent frequentist regretbound for a broad class of algorithms, including Greedy, OFUL, and Thompsonsampling. This result empowers us to identify and ``course-correct" instancesin which the base algorithms perform poorly. The course-corrected algorithmsachieve the minimax optimal regret of order $\tilde{\mathcal{O}}(d\sqrt{T})$,while retaining most of the desirable properties of the base algorithms. Wepresent simulation results to validate our findings and compare the performanceof our algorithms with the baselines.</description><author>Yuwei Luo, Mohsen Bayati</author><pubDate>Mon, 26 Jun 2023 18:38:45 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.14872v1</guid></item><item><title>Composing Parameter-Efficient Modules with Arithmetic Operations</title><link>http://arxiv.org/abs/2306.14870v1</link><description>As an efficient alternative to conventional full finetuning,parameter-efficient finetuning (PEFT) is becoming the prevailing method toadapt pretrained language models. In PEFT, a lightweight module is learned oneach dataset while the underlying pretrained language model remains unchanged,resulting in multiple compact modules representing diverse skills when appliedto various domains and tasks. In this paper, we propose to compose theseparameter-efficient modules through linear arithmetic operations in the weightspace, thereby integrating different module capabilities. Specifically, wefirst define addition and negation operators for the module, and then furthercompose these two basic operators to perform flexible arithmetic. Our approachrequires \emph{no additional training} and enables highly flexible modulecomposition. We apply different arithmetic operations to compose theparameter-efficient modules for (1) distribution generalization, (2)multi-tasking, (3) unlearning, and (4) domain transfer. Additionally, we extendour approach to detoxify Alpaca-LoRA, the latest instruction-tuned largelanguage model based on LLaMA. Empirical results demonstrate that our approachproduces new and effective parameter-efficient modules that significantlyoutperform existing ones across all settings.</description><author>Jinghan Zhang, Shiqi Chen, Junteng Liu, Junxian He</author><pubDate>Mon, 26 Jun 2023 18:33:21 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.14870v1</guid></item><item><title>Sound Demixing Challenge 2023 Music Demixing Track Technical Report: TFC-TDF-UNet v3</title><link>http://arxiv.org/abs/2306.09382v2</link><description>In this report, we present our award-winning solutions for the Music DemixingTrack of Sound Demixing Challenge 2023. First, we propose TFC-TDF-UNet v3, atime-efficient music source separation model that achieves state-of-the-artresults on the MUSDB benchmark. We then give full details regarding oursolutions for each Leaderboard, including a loss masking approach fornoise-robust training. Code for reproducing model training and finalsubmissions is available at github.com/kuielab/sdx23.</description><author>Minseok Kim, Jun Hyung Lee, Soonyoung Jung</author><pubDate>Mon, 26 Jun 2023 18:31:30 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.09382v2</guid></item><item><title>Enriching the NArabizi Treebank: A Multifaceted Approach to Supporting an Under-Resourced Language</title><link>http://arxiv.org/abs/2306.14866v1</link><description>In this paper we address the scarcity of annotated data for NArabizi, aRomanized form of North African Arabic used mostly on social media, which poseschallenges for Natural Language Processing (NLP). We introduce an enrichedversion of NArabizi Treebank (Seddah et al., 2020) with three maincontributions: the addition of two novel annotation layers (named entityrecognition and offensive language detection) and a re-annotation of thetokenization, morpho-syntactic and syntactic layers that ensure annotationconsistency. Our experimental results, using different tokenization schemes,showcase the value of our contributions and highlight the impact of workingwith non-gold tokenization for NER and dependency parsing. To facilitate futureresearch, we make these annotations publicly available. Our enhanced NArabiziTreebank paves the way for creating sophisticated language models and NLP toolsfor this under-represented language.</description><author>Riabi Arij, Mahamdi Menel, Seddah Djamé</author><pubDate>Mon, 26 Jun 2023 18:27:31 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.14866v1</guid></item><item><title>An Overview of Catastrophic AI Risks</title><link>http://arxiv.org/abs/2306.12001v2</link><description>Rapid advancements in artificial intelligence (AI) have sparked growingconcerns among experts, policymakers, and world leaders regarding the potentialfor increasingly advanced AI systems to pose catastrophic risks. Althoughnumerous risks have been detailed separately, there is a pressing need for asystematic discussion and illustration of the potential dangers to betterinform efforts to mitigate them. This paper provides an overview of the mainsources of catastrophic AI risks, which we organize into four categories:malicious use, in which individuals or groups intentionally use AIs to causeharm; AI race, in which competitive environments compel actors to deploy unsafeAIs or cede control to AIs; organizational risks, highlighting how humanfactors and complex systems can increase the chances of catastrophic accidents;and rogue AIs, describing the inherent difficulty in controlling agents farmore intelligent than humans. For each category of risk, we describe specifichazards, present illustrative stories, envision ideal scenarios, and proposepractical suggestions for mitigating these dangers. Our goal is to foster acomprehensive understanding of these risks and inspire collective and proactiveefforts to ensure that AIs are developed and deployed in a safe manner.Ultimately, we hope this will allow us to realize the benefits of this powerfultechnology while minimizing the potential for catastrophic outcomes.</description><author>Dan Hendrycks, Mantas Mazeika, Thomas Woodside</author><pubDate>Mon, 26 Jun 2023 18:26:07 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.12001v2</guid></item><item><title>Infinite Photorealistic Worlds using Procedural Generation</title><link>http://arxiv.org/abs/2306.09310v2</link><description>We introduce Infinigen, a procedural generator of photorealistic 3D scenes ofthe natural world. Infinigen is entirely procedural: every asset, from shape totexture, is generated from scratch via randomized mathematical rules, using noexternal source and allowing infinite variation and composition. Infinigenoffers broad coverage of objects and scenes in the natural world includingplants, animals, terrains, and natural phenomena such as fire, cloud, rain, andsnow. Infinigen can be used to generate unlimited, diverse training data for awide range of computer vision tasks including object detection, semanticsegmentation, optical flow, and 3D reconstruction. We expect Infinigen to be auseful resource for computer vision research and beyond. Please visithttps://infinigen.org for videos, code and pre-generated data.</description><author>Alexander Raistrick, Lahav Lipson, Zeyu Ma, Lingjie Mei, Mingzhe Wang, Yiming Zuo, Karhan Kayan, Hongyu Wen, Beining Han, Yihan Wang, Alejandro Newell, Hei Law, Ankit Goyal, Kaiyu Yang, Jia Deng</author><pubDate>Mon, 26 Jun 2023 18:20:37 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.09310v2</guid></item><item><title>Autoencoders for Real-Time SUEP Detection</title><link>http://arxiv.org/abs/2306.13595v2</link><description>Confining dark sectors with pseudo-conformal dynamics can produce SoftUnclustered Energy Patterns, or SUEPs, at the Large Hadron Collider: theproduction of dark quarks in proton-proton collisions leading to a dark showerand the high-multiplicity production of dark hadrons. The final experimentalsignature is spherically-symmetric energy deposits by an anomalously largenumber of soft Standard Model particles with a transverse energy of a fewhundred MeV. The dominant background for the SUEP search, if it gets producedvia gluon-gluon fusion, is multi-jet QCD events. We have developed a deeplearning-based Anomaly Detection technique to reject QCD jets and identify anyanomalous signature, including SUEP, in real-time in the High-Level Triggersystem of the Compact Muon Solenoid experiment at the Large Hadron Collider. Adeep convolutional neural autoencoder network has been trained using QCD eventsby taking transverse energy deposits in the inner tracker, electromagneticcalorimeter, and hadron calorimeter sub-detectors as 3-channel image data. Totackle the biggest challenge of the task, due to the sparse nature of the data:only ~0.5% of the total ~300 k image pixels have non-zero values, anon-standard loss function, the inverse of the so-called Dice Loss, has beenexploited. The trained autoencoder with learned spatial features of QCD jetscan detect 40% of the SUEP events, with a QCD event mistagging rate as low as2%. The model inference time has been measured using the Intel CoreTM i5-9600KFprocessor and found to be ~20 ms, which perfectly satisfies the High-LevelTrigger system's latency of O(100) ms. Given the virtue of the unsupervisedlearning of the autoencoders, the trained model can be applied to any newphysics model that predicts an experimental signature anomalous to QCD jets.</description><author>Simranjit Singh Chhibra, Nadezda Chernyavskaya, Benedikt Maier, Maurzio Pierini, Syed Hasan</author><pubDate>Mon, 26 Jun 2023 18:18:16 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.13595v2</guid></item><item><title>Leveraging Task Structures for Improved Identifiability in Neural Network Representations</title><link>http://arxiv.org/abs/2306.14861v1</link><description>This work extends the theory of identifiability in supervised learning byconsidering the consequences of having access to a distribution of tasks. Insuch cases, we show that identifiability is achievable even in the case ofregression, extending prior work restricted to the single-task classificationcase. Furthermore, we show that the existence of a task distribution whichdefines a conditional prior over latent variables reduces the equivalence classfor identifiability to permutations and scaling, a much stronger and moreuseful result. When we further assume a causal structure over these tasks, ourapproach enables simple maximum marginal likelihood optimization together withdownstream applicability to causal representation learning. Empirically, wevalidate that our model outperforms more general unsupervised models inrecovering canonical representations for synthetic and real-world data.</description><author>Wenlin Chen, Julien Horwood, Juyeon Heo, José Miguel Hernández-Lobato</author><pubDate>Mon, 26 Jun 2023 18:16:50 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.14861v1</guid></item><item><title>Effective Minkowski Dimension of Deep Nonparametric Regression: Function Approximation and Statistical Theories</title><link>http://arxiv.org/abs/2306.14859v1</link><description>Existing theories on deep nonparametric regression have shown that when theinput data lie on a low-dimensional manifold, deep neural networks can adapt tothe intrinsic data structures. In real world applications, such an assumptionof data lying exactly on a low dimensional manifold is stringent. This paperintroduces a relaxed assumption that the input data are concentrated around asubset of $\mathbb{R}^d$ denoted by $\mathcal{S}$, and the intrinsic dimensionof $\mathcal{S}$ can be characterized by a new complexity notation -- effectiveMinkowski dimension. We prove that, the sample complexity of deep nonparametricregression only depends on the effective Minkowski dimension of $\mathcal{S}$denoted by $p$. We further illustrate our theoretical findings by consideringnonparametric regression with an anisotropic Gaussian random design$N(0,\Sigma)$, where $\Sigma$ is full rank. When the eigenvalues of $\Sigma$have an exponential or polynomial decay, the effective Minkowski dimension ofsuch an Gaussian random design is $p=\mathcal{O}(\sqrt{\log n})$ or$p=\mathcal{O}(n^\gamma)$, respectively, where $n$ is the sample size and$\gamma\in(0,1)$ is a small constant depending on the polynomial decay rate.Our theory shows that, when the manifold assumption does not hold, deep neuralnetworks can still adapt to the effective Minkowski dimension of the data, andcircumvent the curse of the ambient dimensionality for moderate sample sizes.</description><author>Zixuan Zhang, Minshuo Chen, Mengdi Wang, Wenjing Liao, Tuo Zhao</author><pubDate>Mon, 26 Jun 2023 18:13:31 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.14859v1</guid></item><item><title>Single-Stage Diffusion NeRF: A Unified Approach to 3D Generation and Reconstruction</title><link>http://arxiv.org/abs/2304.06714v3</link><description>3D-aware image synthesis encompasses a variety of tasks, such as scenegeneration and novel view synthesis from images. Despite numerous task-specificmethods, developing a comprehensive model remains challenging. In this paper,we present SSDNeRF, a unified approach that employs an expressive diffusionmodel to learn a generalizable prior of neural radiance fields (NeRF) frommulti-view images of diverse objects. Previous studies have used two-stageapproaches that rely on pretrained NeRFs as real data to train diffusionmodels. In contrast, we propose a new single-stage training paradigm with anend-to-end objective that jointly optimizes a NeRF auto-decoder and a latentdiffusion model, enabling simultaneous 3D reconstruction and prior learning,even from sparsely available views. At test time, we can directly sample thediffusion prior for unconditional generation, or combine it with arbitraryobservations of unseen objects for NeRF reconstruction. SSDNeRF demonstratesrobust results comparable to or better than leading task-specific methods inunconditional generation and single/sparse-view 3D reconstruction.</description><author>Hansheng Chen, Jiatao Gu, Anpei Chen, Wei Tian, Zhuowen Tu, Lingjie Liu, Hao Su</author><pubDate>Mon, 26 Jun 2023 18:12:09 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2304.06714v3</guid></item><item><title>Proportional Aggregation of Preferences for Sequential Decision Making</title><link>http://arxiv.org/abs/2306.14858v1</link><description>We study the problem of fair sequential decision making given voterpreferences. In each round, a decision rule must choose a decision from a setof alternatives where each voter reports which of these alternatives theyapprove. Instead of going with the most popular choice in each round, we aimfor proportional representation. We formalize this aim using axioms based onProportional Justified Representation (PJR), which were proposed in theliterature on multi-winner voting and were recently adapted to multi-issuedecision making. The axioms require that every group of $\alpha\%$ of thevoters, if it agrees in every round (i.e., approves a common alternative), thenthose voters must approve at least $\alpha\%$ of the decisions. A strongerversion of the axioms requires that every group of $\alpha\%$ of the votersthat agrees in a $\beta$ fraction of rounds must approve $\beta\cdot\alpha\%$of the decisions. We show that three attractive voting rules satisfy axioms ofthis style. One of them (Sequential Phragm\'en) makes its decisions online, andthe other two satisfy strengthened versions of the axioms but make decisionssemi-online (Method of Equal Shares) or fully offline (Proportional ApprovalVoting). The first two are polynomial-time computable, and the latter is basedon an NP-hard optimization, but it admits a polynomial-time local searchalgorithm that satisfies the same axiomatic properties. We present empiricalresults about the performance of these rules based on synthetic data and U.S.political elections. We also run experiments where votes are cast by preferencemodels trained on user responses from the moral machine dataset about ethicaldilemmas.</description><author>Nikhil Chandak, Shashwat Goel, Dominik Peters</author><pubDate>Mon, 26 Jun 2023 18:10:10 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.14858v1</guid></item><item><title>Near-Optimal Fully First-Order Algorithms for Finding Stationary Points in Bilevel Optimization</title><link>http://arxiv.org/abs/2306.14853v1</link><description>Bilevel optimization has various applications such as hyper-parameteroptimization and meta-learning. Designing theoretically efficient algorithmsfor bilevel optimization is more challenging than standard optimization becausethe lower-level problem defines the feasibility set implicitly via anotheroptimization problem. One tractable case is when the lower-level problempermits strong convexity. Recent works show that second-order methods canprovably converge to an $\epsilon$-first-order stationary point of the problemat a rate of $\tilde{\mathcal{O}}(\epsilon^{-2})$, yet these algorithms requirea Hessian-vector product oracle. Kwon et al. (2023) resolved the problem byproposing a first-order method that can achieve the same goal at a slower rateof $\tilde{\mathcal{O}}(\epsilon^{-3})$. In this work, we provide an improvedanalysis demonstrating that the first-order method can also find an$\epsilon$-first-order stationary point within $\tilde{\mathcal{O}}(\epsilon^{-2})$ oracle complexity, which matches the upper boundsfor second-order methods in the dependency on $\epsilon$. Our analysis furtherleads to simple first-order algorithms that can achieve similar near-optimalrates in finding second-order stationary points and in distributed bilevelproblems.</description><author>Lesi Chen, Yaohua Ma, Jingzhao Zhang</author><pubDate>Mon, 26 Jun 2023 18:07:54 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.14853v1</guid></item><item><title>On the Validity of Conformal Prediction for Network Data Under Non-Uniform Sampling</title><link>http://arxiv.org/abs/2306.07252v2</link><description>We study the properties of conformal prediction for network data undervarious sampling mechanisms that commonly arise in practice but often result ina non-representative sample of nodes. We interpret these sampling mechanisms asselection rules applied to a superpopulation and study the validity ofconformal prediction conditional on an appropriate selection event. We showthat the sampled subarray is exchangeable conditional on the selection event ifthe selection rule satisfies a permutation invariance property and a jointexchangeability condition holds for the superpopulation. Our result implies thefinite-sample validity of conformal prediction for certain selection eventsrelated to ego networks and snowball sampling. We also show that when data aresampled via a random walk on a graph, a variant of weighted conformalprediction yields asymptotically valid prediction sets for an independentlyselected node from the population.</description><author>Robert Lunde</author><pubDate>Mon, 26 Jun 2023 18:06:50 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.07252v2</guid></item><item><title>CoarsenConf: Equivariant Coarsening with Aggregated Attention for Molecular Conformer Generation</title><link>http://arxiv.org/abs/2306.14852v1</link><description>Molecular conformer generation (MCG) is an important task in cheminformaticsand drug discovery. The ability to efficiently generate low-energy 3Dstructures can avoid expensive quantum mechanical simulations, leading toaccelerated screenings and enhanced structural exploration. Several generativemodels have been developed for MCG, but many struggle to consistently producehigh-quality conformers. To address these issues, we introduce CoarsenConf,which coarse-grains molecular graphs based on torsional angles and integratesthem into an SE(3)-equivariant hierarchical variational autoencoder. Throughequivariant coarse-graining, we aggregate the fine-grained atomic coordinatesof subgraphs connected via rotatable bonds, creating a variable-lengthcoarse-grained latent representation. Our model uses a novel aggregatedattention mechanism to restore fine-grained coordinates from the coarse-grainedlatent representation, enabling efficient autoregressive generation of largemolecules. Furthermore, our work expands current conformer generationbenchmarks and introduces new metrics to better evaluate the quality andviability of generated conformers. We demonstrate that CoarsenConf generatesmore accurate conformer ensembles compared to prior generative models andtraditional cheminformatics methods.</description><author>Danny Reidenbach, Aditi S. Krishnapriyan</author><pubDate>Mon, 26 Jun 2023 18:02:54 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.14852v1</guid></item><item><title>Gain Confidence, Reduce Disappointment: A New Approach to Cross-Validation for Sparse Regression</title><link>http://arxiv.org/abs/2306.14851v1</link><description>Ridge regularized sparse regression involves selecting a subset of featuresthat explains the relationship between a design matrix and an output vector inan interpretable manner. To select the sparsity and robustness of linearregressors, techniques like leave-one-out cross-validation are commonly usedfor hyperparameter tuning. However, cross-validation typically increases thecost of sparse regression by several orders of magnitude. Additionally,validation metrics are noisy estimators of the test-set error, with differenthyperparameter combinations giving models with different amounts of noise.Therefore, optimizing over these metrics is vulnerable to out-of-sampledisappointment, especially in underdetermined settings. To address this, wemake two contributions. First, we leverage the generalization theory literatureto propose confidence-adjusted variants of leave-one-out that display lesspropensity to out-of-sample disappointment. Second, we leverage ideas from themixed-integer literature to obtain computationally tractable relaxations ofconfidence-adjusted leave-one-out, thereby minimizing it without solving asmany MIOs. Our relaxations give rise to an efficient coordinate descent schemewhich allows us to obtain significantly lower leave-one-out errors than viaother methods in the literature. We validate our theory by demonstrating weobtain significantly sparser and comparably accurate solutions than via popularmethods like GLMNet and suffer from less out-of-sample disappointment. Onsynthetic datasets, our confidence adjustment procedure generates significantlyfewer false discoveries, and improves out-of-sample performance by 2-5%compared to cross-validating without confidence adjustment. Across a suite of13 real datasets, a calibrated version of our procedure improves the test seterror by an average of 4% compared to cross-validating without confidenceadjustment.</description><author>Ryan Cory-Wright, Andrés Gómez</author><pubDate>Mon, 26 Jun 2023 18:02:45 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.14851v1</guid></item><item><title>ViNT: A Foundation Model for Visual Navigation</title><link>http://arxiv.org/abs/2306.14846v1</link><description>General-purpose pre-trained models ("foundation models") have enabledpractitioners to produce generalizable solutions for individual machinelearning problems with datasets that are significantly smaller than thoserequired for learning from scratch. Such models are typically trained on largeand diverse datasets with weak supervision, consuming much more training datathan is available for any individual downstream application. In this paper, wedescribe the Visual Navigation Transformer (ViNT), a foundation model that aimsto bring the success of general-purpose pre-trained models to vision-basedrobotic navigation. ViNT is trained with a general goal-reaching objective thatcan be used with any navigation dataset, and employs a flexibleTransformer-based architecture to learn navigational affordances and enableefficient adaptation to a variety of downstream navigational tasks. ViNT istrained on a number of existing navigation datasets, comprising hundreds ofhours of robotic navigation from a variety of different robotic platforms, andexhibits positive transfer, outperforming specialist models trained on singulardatasets. ViNT can be augmented with diffusion-based subgoal proposals toexplore novel environments, and can solve kilometer-scale navigation problemswhen equipped with long-range heuristics. ViNT can also be adapted to noveltask specifications with a technique inspired by prompt-tuning, where the goalencoder is replaced by an encoding of another task modality (e.g., GPSwaypoints or routing commands) embedded into the same space of goal tokens.This flexibility and ability to accommodate a variety of downstream problemdomains establishes ViNT as an effective foundation model for mobile robotics.For videos, code, and model checkpoints, see our project page athttps://visualnav-transformer.github.io.</description><author>Dhruv Shah, Ajay Sridhar, Nitish Dashora, Kyle Stachowicz, Kevin Black, Noriaki Hirose, Sergey Levine</author><pubDate>Mon, 26 Jun 2023 17:57:03 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.14846v1</guid></item><item><title>A Flyweight CNN with Adaptive Decoder for Schistosoma mansoni Egg Detection</title><link>http://arxiv.org/abs/2306.14840v1</link><description>Schistosomiasis mansoni is an endemic parasitic disease in more than seventycountries, whose diagnosis is commonly performed by visually counting theparasite eggs in microscopy images of fecal samples. State-of-the-art (SOTA)object detection algorithms are based on heavyweight neural networks,unsuitable for automating the diagnosis in the laboratory routine. Wecircumvent the problem by presenting a flyweight Convolutional Neural Network(CNN) that weighs thousands of times less than SOTA object detectors. Thekernels in our approach are learned layer-by-layer from attention regionsindicated by user-drawn scribbles on very few training images. Representativekernels are visually identified and selected to improve performance withreduced computational cost. Another innovation is a single-layer adaptivedecoder whose convolutional weights are automatically defined for each imageon-the-fly. The experiments show that our CNN can outperform three SOTAbaselines according to five measures, being also suitable for CPU execution inthe laboratory routine, processing approximately four images a second for eachavailable thread.</description><author>Leonardo de Melo Joao, Azael de Melo e Sousa, Bianca Martins dos Santos, Silvio Jamil Ferzoli Guimaraes, Jancarlo Ferreira Gomes, Ewa Kijak, Alexandre Xavier Falcao</author><pubDate>Mon, 26 Jun 2023 17:48:20 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.14840v1</guid></item><item><title>Finite-Sample Analysis of Learning High-Dimensional Single ReLU Neuron</title><link>http://arxiv.org/abs/2303.02255v2</link><description>This paper considers the problem of learning a single ReLU neuron withsquared loss (a.k.a., ReLU regression) in the overparameterized regime, wherethe input dimension can exceed the number of samples. We analyze aPerceptron-type algorithm called GLM-tron (Kakade et al., 2011) and provide itsdimension-free risk upper bounds for high-dimensional ReLU regression in bothwell-specified and misspecified settings. Our risk bounds recover severalexisting results as special cases. Moreover, in the well-specified setting, weprovide an instance-wise matching risk lower bound for GLM-tron. Our upper andlower risk bounds provide a sharp characterization of the high-dimensional ReLUregression problems that can be learned via GLM-tron. On the other hand, weprovide some negative results for stochastic gradient descent (SGD) for ReLUregression with symmetric Bernoulli data: if the model is well-specified, theexcess risk of SGD is provably no better than that of GLM-tron ignoringconstant factors, for each problem instance; and in the noiseless case,GLM-tron can achieve a small risk while SGD unavoidably suffers from a constantrisk in expectation. These results together suggest that GLM-tron might bepreferable to SGD for high-dimensional ReLU regression.</description><author>Jingfeng Wu, Difan Zou, Zixiang Chen, Vladimir Braverman, Quanquan Gu, Sham M. Kakade</author><pubDate>Mon, 26 Jun 2023 17:39:41 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2303.02255v2</guid></item><item><title>Scalable Neural Contextual Bandit for Recommender Systems</title><link>http://arxiv.org/abs/2306.14834v1</link><description>High-quality recommender systems ought to deliver both innovative andrelevant content through effective and exploratory interactions with users.Yet, supervised learning-based neural networks, which form the backbone of manyexisting recommender systems, only leverage recognized user interests, fallingshort when it comes to efficiently uncovering unknown user preferences. Whilethere has been some progress with neural contextual bandit algorithms towardsenabling online exploration through neural networks, their onerouscomputational demands hinder widespread adoption in real-world recommendersystems. In this work, we propose a scalable sample-efficient neural contextualbandit algorithm for recommender systems. To do this, we design an epistemicneural network architecture, Epistemic Neural Recommendation (ENR), thatenables Thompson sampling at a large scale. In two distinct large-scaleexperiments with real-world tasks, ENR significantly boosts click-through ratesand user ratings by at least 9% and 6% respectively compared tostate-of-the-art neural contextual bandit algorithms. Furthermore, it achievesequivalent performance with at least 29% fewer user interactions compared tothe best-performing baseline algorithm. Remarkably, while accomplishing theseimprovements, ENR demands orders of magnitude fewer computational resourcesthan neural contextual bandit baseline algorithms.</description><author>Zheqing Zhu, Benjamin Van Roy</author><pubDate>Mon, 26 Jun 2023 17:39:39 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.14834v1</guid></item><item><title>HonestBait: Forward References for Attractive but Faithful Headline Generation</title><link>http://arxiv.org/abs/2306.14828v1</link><description>Current methods for generating attractive headlines often learn directly fromdata, which bases attractiveness on the number of user clicks and views.Although clicks or views do reflect user interest, they can fail to reveal howmuch interest is raised by the writing style and how much is due to the eventor topic itself. Also, such approaches can lead to harmful inventions byover-exaggerating the content, aggravating the spread of false information. Inthis work, we propose HonestBait, a novel framework for solving these issuesfrom another aspect: generating headlines using forward references (FRs), awriting technique often used for clickbait. A self-verification process isincluded during training to avoid spurious inventions. We begin with apreliminary user study to understand how FRs affect user interest, after whichwe present PANCO1, an innovative dataset containing pairs of fake news withverified news for attractive but faithful news headline generation. Automaticmetrics and human evaluations show that our framework yields more attractiveresults (+11.25% compared to human-written verified news headlines) whilemaintaining high veracity, which helps promote real information to fightagainst fake news.</description><author>Chih-Yao Chen, Dennis Wu, Lun-Wei Ku</author><pubDate>Mon, 26 Jun 2023 17:34:37 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.14828v1</guid></item><item><title>Vietnamese multi-document summary using subgraph selection approach -- VLSP 2022 AbMuSu Shared Task</title><link>http://arxiv.org/abs/2306.14827v1</link><description>Document summarization is a task to generate afluent, condensed summary for adocument, andkeep important information. A cluster of documents serves as theinput for multi-document summarizing (MDS), while the cluster summary serves asthe output. In this paper, we focus on transforming the extractive MDS probleminto subgraph selection. Approaching the problem in the form of graphs helps tocapture simultaneously the relationship between sentences in the same documentand between sentences in the same cluster based on exploiting the overall graphstructure and selected subgraphs. Experiments have been implemented on theVietnamese dataset published in VLSP Evaluation Campaign 2022. This modelcurrently results in the top 10 participating teams reported on the ROUGH-2$F\_1$ measure on the public test set.</description><author>Huu-Thin Nguyen, Tam Doan Thanh, Cam-Van Thi Nguyen</author><pubDate>Mon, 26 Jun 2023 17:34:02 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.14827v1</guid></item><item><title>Kosmos-2: Grounding Multimodal Large Language Models to the World</title><link>http://arxiv.org/abs/2306.14824v1</link><description>We introduce Kosmos-2, a Multimodal Large Language Model (MLLM), enabling newcapabilities of perceiving object descriptions (e.g., bounding boxes) andgrounding text to the visual world. Specifically, we represent referexpressions as links in Markdown, i.e., ``[text span](bounding boxes)'', whereobject descriptions are sequences of location tokens. Together with multimodalcorpora, we construct large-scale data of grounded image-text pairs (calledGrIT) to train the model. In addition to the existing capabilities of MLLMs(e.g., perceiving general modalities, following instructions, and performingin-context learning), Kosmos-2 integrates the grounding capability intodownstream applications. We evaluate Kosmos-2 on a wide range of tasks,including (i) multimodal grounding, such as referring expression comprehension,and phrase grounding, (ii) multimodal referring, such as referring expressiongeneration, (iii) perception-language tasks, and (iv) language understandingand generation. This work lays out the foundation for the development ofEmbodiment AI and sheds light on the big convergence of language, multimodalperception, action, and world modeling, which is a key step toward artificialgeneral intelligence. Data, demo, and pretrained models are available athttps://aka.ms/kosmos-2.</description><author>Zhiliang Peng, Wenhui Wang, Li Dong, Yaru Hao, Shaohan Huang, Shuming Ma, Furu Wei</author><pubDate>Mon, 26 Jun 2023 17:32:47 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.14824v1</guid></item><item><title>Label-Aware Hyperbolic Embeddings for Fine-grained Emotion Classification</title><link>http://arxiv.org/abs/2306.14822v1</link><description>Fine-grained emotion classification (FEC) is a challenging task.Specifically, FEC needs to handle subtle nuance between labels, which can becomplex and confusing. Most existing models only address text classificationproblem in the euclidean space, which we believe may not be the optimalsolution as labels of close semantic (e.g., afraid and terrified) may not bedifferentiated in such space, which harms the performance. In this paper, wepropose HypEmo, a novel framework that can integrate hyperbolic embeddings toimprove the FEC task. First, we learn label embeddings in the hyperbolic spaceto better capture their hierarchical structure, and then our model projectscontextualized representations to the hyperbolic space to compute the distancebetween samples and labels. Experimental results show that incorporating suchdistance to weight cross entropy loss substantially improves the performancewith significantly higher efficiency. We evaluate our proposed model on twobenchmark datasets and found 4.8% relative improvement compared to the previousstate of the art with 43.2% fewer parameters and 76.9% less training time. Codeis available at https: //github.com/dinobby/HypEmo.</description><author>Chih-Yao Chen, Tun-Min Hung, Yi-Li Hsu, Lun-Wei Ku</author><pubDate>Mon, 26 Jun 2023 17:28:33 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.14822v1</guid></item><item><title>Accelerating Molecular Graph Neural Networks via Knowledge Distillation</title><link>http://arxiv.org/abs/2306.14818v1</link><description>Recent advances in graph neural networks (GNNs) have allowed molecularsimulations with accuracy on par with conventional gold-standard methods at afraction of the computational cost. Nonetheless, as the field has beenprogressing to bigger and more complex architectures, state-of-the-art GNNshave become largely prohibitive for many large-scale applications. In thispaper, we, for the first time, explore the utility of knowledge distillation(KD) for accelerating molecular GNNs. To this end, we devise KD strategies thatfacilitate the distillation of hidden representations in directional andequivariant GNNs and evaluate their performance on the regression task ofenergy and force prediction. We validate our protocols across differentteacher-student configurations and demonstrate that they can boost thepredictive accuracy of student models without altering their architecture. Wealso conduct comprehensive optimization of various components of our framework,and investigate the potential of data augmentation to further enhanceperformance. All in all, we manage to close as much as 59% of the gap inpredictive accuracy between models like GemNet-OC and PaiNN with zeroadditional cost at inference.</description><author>Filip Ekström Kelvinius, Dimitar Georgiev, Artur Petrov Toshev, Johannes Gasteiger</author><pubDate>Mon, 26 Jun 2023 17:24:31 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.14818v1</guid></item><item><title>Can Differentiable Decision Trees Learn Interpretable Reward Functions?</title><link>http://arxiv.org/abs/2306.13004v2</link><description>There is an increasing interest in learning reward functions that model humanintent and human preferences. However, many frameworks use blackbox learningmethods that, while expressive, are difficult to interpret. We propose andevaluate a novel approach for learning expressive and interpretable rewardfunctions from preferences using Differentiable Decision Trees (DDTs). Ourexperiments across several domains, including Cartpole, Visual Gridworldenvironments and Atari games, provide evidence that that the tree structure ofour learned reward function is useful in determining the extent to which thereward function is aligned with human preferences. We experimentallydemonstrate that using reward DDTs results in competitive performance whencompared with larger capacity deep neural network reward functions. We alsoobserve that the choice between soft and hard (argmax) output of reward DDTreveals a tension between wanting highly shaped rewards to ensure good RLperformance, while also wanting simple, non-shaped rewards to affordinterpretability.</description><author>Akansha Kalra, Daniel S. Brown</author><pubDate>Mon, 26 Jun 2023 17:22:34 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.13004v2</guid></item><item><title>Black holes and the loss landscape in machine learning</title><link>http://arxiv.org/abs/2306.14817v1</link><description>Understanding the loss landscape is an important problem in machine learning.One key feature of the loss function, common to many neural networkarchitectures, is the presence of exponentially many low lying local minima.Physical systems with similar energy landscapes may provide useful insights. Inthis work, we point out that black holes naturally give rise to suchlandscapes, owing to the existence of black hole entropy. For definiteness, weconsider 1/8 BPS black holes in $\mathcal{N} = 8$ string theory. These providean infinite family of potential landscapes arising in the microscopicdescriptions of corresponding black holes. The counting of minima amounts toblack hole microstate counting. Moreover, the exact numbers of the minima forthese landscapes are a priori known from dualities in string theory. Some ofthe minima are connected by paths of low loss values, resembling modeconnectivity. We estimate the number of runs needed to find all the solutions.Initial explorations suggest that Stochastic Gradient Descent can find asignificant fraction of the minima.</description><author>Pranav Kumar, Taniya Mandal, Swapnamay Mondal</author><pubDate>Mon, 26 Jun 2023 17:22:33 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.14817v1</guid></item><item><title>Experiments with Detecting and Mitigating AI Deception</title><link>http://arxiv.org/abs/2306.14816v1</link><description>How to detect and mitigate deceptive AI systems is an open problem for thefield of safe and trustworthy AI. We analyse two algorithms for mitigatingdeception: The first is based on the path-specific objectives framework wherepaths in the game that incentivise deception are removed. The second is basedon shielding, i.e., monitoring for unsafe policies and replacing them with asafe reference policy. We construct two simple games and evaluate ouralgorithms empirically. We find that both methods ensure that our agent is notdeceptive, however, shielding tends to achieve higher reward.</description><author>Ismail Sahbane, Francis Rhys Ward, C Henrik Åslund</author><pubDate>Mon, 26 Jun 2023 17:22:13 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.14816v1</guid></item><item><title>Probabilistic Risk Assessment of an Obstacle Detection System for GoA 4 Freight Trains</title><link>http://arxiv.org/abs/2306.14814v1</link><description>In this paper, a quantitative risk assessment approach is discussed for thedesign of an obstacle detection function for low-speed freight trains withgrade of automation (GoA)~4. In this 5-step approach, starting with singledetection channels and ending with a three-out-of-three (3oo3) modelconstructed of three independent dual-channel modules and a voter, aprobabilistic assessment is exemplified, using a combination of statisticalmethods and parametric stochastic model checking. It is illustrated that, undercertain not unreasonable assumptions, the resulting hazard rate becomesacceptable for specific application settings. The statistical approach forassessing the residual risk of misclassifications in convolutional neuralnetworks and conventional image processing software suggests that highconfidence can be placed into the safety-critical obstacle detection function,even though its implementation involves realistic machine learninguncertainties.</description><author>Mario Gleirscher, Anne E. Haxthausen, Jan Peleska</author><pubDate>Mon, 26 Jun 2023 17:18:20 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.14814v1</guid></item><item><title>MOVESe: MOVablE and Moving LiDAR Scene Segmentation with Improved Navigation in Seg-label free settings</title><link>http://arxiv.org/abs/2306.14812v1</link><description>Accurate detection of movable and moving objects in LiDAR is of vitalimportance for navigation. Most existing works focus on extracting and removingmoving objects during navigation. Movable objects like pedestrians, parkedvehicles, etc. although static may move in the future. This leads to erroneousnavigation and accidents. In such cases, it becomes necessary to detectpotentially movable objects. To this end, we present a learning-based approachthat segments movable and moving objects by generating static parts of scenesthat are otherwise occluded. Our model performs superior to existing baselineson static LiDAR reconstructions using 3 datasets including a challenging sparseindustrial dataset. We achieve this without the assistance of any segmentationlabels because such labels might not always be available for less popular yetimportant settings like industrial environments. The non-movable static partsof the scene generated by our model are of vital importance for downstreamnavigation for SLAM. The movable objects detected by our model can be fed to adownstream 3D detector for aiding navigation. Though we do not usesegmentation, we evaluate our method against navigation baselines that use itto remove dynamic objects for SLAM. Through extensive experiments on severaldatasets, we showcase that our model surpasses these baselines on navigation.</description><author>Prashant Kumar, Onkar Susladkar, Dhruv Makwana, Anurag Mittal, Prem Kumar Kalra</author><pubDate>Mon, 26 Jun 2023 17:16:46 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.14812v1</guid></item><item><title>MemeGraphs: Linking Memes to Knowledge Graphs</title><link>http://arxiv.org/abs/2305.18391v2</link><description>Memes are a popular form of communicating trends and ideas in social mediaand on the internet in general, combining the modalities of images and text.They can express humor and sarcasm but can also have offensive content.Analyzing and classifying memes automatically is challenging since theirinterpretation relies on the understanding of visual elements, language, andbackground knowledge. Thus, it is important to meaningfully represent thesesources and the interaction between them in order to classify a meme as awhole. In this work, we propose to use scene graphs, that express images interms of objects and their visual relations, and knowledge graphs as structuredrepresentations for meme classification with a Transformer-based architecture.We compare our approach with ImgBERT, a multimodal model that uses only learned(instead of structured) representations of the meme, and observe consistentimprovements. We further provide a dataset with human graph annotations that wecompare to automatically generated graphs and entity linking. Analysis showsthat automatic methods link more entities than human annotators and thatautomatically generated graphs are better suited for hatefulness classificationin memes.</description><author>Vasiliki Kougia, Simon Fetzel, Thomas Kirchmair, Erion Çano, Sina Moayed Baharlou, Sahand Sharifzadeh, Benjamin Roth</author><pubDate>Mon, 26 Jun 2023 17:15:48 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.18391v2</guid></item><item><title>Robust Wind Turbine Blade Segmentation from RGB Images in the Wild</title><link>http://arxiv.org/abs/2306.14810v1</link><description>With the relentless growth of the wind industry, there is an imperious needto design automatic data-driven solutions for wind turbine maintenance. Asstructural health monitoring mainly relies on visual inspections, the firststage in any automatic solution is to identify the blade region on the image.Thus, we propose a novel segmentation algorithm that strengthens the U-Netresults by a tailored loss, which pools the focal loss with a contiguityregularization term. To attain top performing results, a set of additionalsteps are proposed to ensure a reliable, generic, robust and efficientalgorithm. First, we leverage our prior knowledge on the images by filling theholes enclosed by temporarily-classified blade pixels and by the imageboundaries. Subsequently, the mislead classified pixels are successfullyamended by training an on-the-fly random forest. Our algorithm demonstrates itseffectiveness reaching a non-trivial 97.39% of accuracy.</description><author>Raül Pérez-Gonzalo, Andreas Espersen, Antonio Agudo</author><pubDate>Mon, 26 Jun 2023 17:12:35 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.14810v1</guid></item><item><title>Tanimoto Random Features for Scalable Molecular Machine Learning</title><link>http://arxiv.org/abs/2306.14809v1</link><description>The Tanimoto coefficient is commonly used to measure the similarity betweenmolecules represented as discrete fingerprints, either as a distance metric ora positive definite kernel. While many kernel methods can be accelerated usingrandom feature approximations, at present there is a lack of suchapproximations for the Tanimoto kernel. In this paper we propose two kinds ofnovel random features to allow this kernel to scale to large datasets, and inthe process discover a novel extension of the kernel to real vectors. Wetheoretically characterize these random features, and provide error bounds onthe spectral norm of the Gram matrix. Experimentally, we show that the randomfeatures proposed in this work are effective at approximating the Tanimotocoefficient in real-world datasets and that the kernels explored in this workare useful for molecular property prediction and optimization tasks.</description><author>Austin Tripp, Sergio Bacallado, Sukriti Singh, José Miguel Hernández-Lobato</author><pubDate>Mon, 26 Jun 2023 17:11:11 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.14809v1</guid></item><item><title>Brain Anatomy Prior Modeling to Forecast Clinical Progression of Cognitive Impairment with Structural MRI</title><link>http://arxiv.org/abs/2306.11837v2</link><description>Brain structural MRI has been widely used to assess the future progression ofcognitive impairment (CI). Previous learning-based studies usually suffer fromthe issue of small-sized labeled training data, while there exist a huge amountof structural MRIs in large-scale public databases. Intuitively, brainanatomical structures derived from these public MRIs (even withouttask-specific label information) can be used to boost CI progression trajectoryprediction. However, previous studies seldom take advantage of such brainanatomy prior. To this end, this paper proposes a brain anatomy prior modeling(BAPM) framework to forecast the clinical progression of cognitive impairmentwith small-sized target MRIs by exploring anatomical brain structures.Specifically, the BAPM consists of a pretext model and a downstream model, witha shared brain anatomy-guided encoder to model brain anatomy prior explicitly.Besides the encoder, the pretext model also contains two decoders for twoauxiliary tasks (i.e., MRI reconstruction and brain tissue segmentation), whilethe downstream model relies on a predictor for classification. The brainanatomy-guided encoder is pre-trained with the pretext model on 9,344 auxiliaryMRIs without diagnostic labels for anatomy prior modeling. With this encoderfrozen, the downstream model is then fine-tuned on limited target MRIs forprediction. We validate the BAPM on two CI-related studies with T1-weightedMRIs from 448 subjects. Experimental results suggest the effectiveness of BAPMin (1) four CI progression prediction tasks, (2) MR image reconstruction, and(3) brain tissue segmentation, compared with several state-of-the-art methods.</description><author>Lintao Zhang, Jinjian Wu, Lihong Wang, Li Wang, David C. Steffens, Shijun Qiu, Guy G. Potter, Mingxia Liu</author><pubDate>Mon, 26 Jun 2023 17:11:04 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.11837v2</guid></item><item><title>Maximum State Entropy Exploration using Predecessor and Successor Representations</title><link>http://arxiv.org/abs/2306.14808v1</link><description>Animals have a developed ability to explore that aids them in important taskssuch as locating food, exploring for shelter, and finding misplaced items.These exploration skills necessarily track where they have been so that theycan plan for finding items with relative efficiency. Contemporary explorationalgorithms often learn a less efficient exploration strategy because theyeither condition only on the current state or simply rely on making randomopen-loop exploratory moves. In this work, we propose $\eta\psi$-Learning, amethod to learn efficient exploratory policies by conditioning on past episodicexperience to make the next exploratory move. Specifically, $\eta\psi$-Learninglearns an exploration policy that maximizes the entropy of the state visitationdistribution of a single trajectory. Furthermore, we demonstrate how variantsof the predecessor representation and successor representations can be combinedto predict the state visitation entropy. Our experiments demonstrate theefficacy of $\eta\psi$-Learning to strategically explore the environment andmaximize the state coverage with limited samples.</description><author>Arnav Kumar Jain, Lucas Lehnert, Irina Rish, Glen Berseth</author><pubDate>Mon, 26 Jun 2023 17:08:26 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.14808v1</guid></item><item><title>Optimal Learning</title><link>http://arxiv.org/abs/2203.15994v2</link><description>This paper studies the problem of learning an unknown function $f$ from givendata about $f$. The learning problem is to give an approximation $\hat f$ to$f$ that predicts the values of $f$ away from the data. There are numeroussettings for this learning problem depending on (i) what additional informationwe have about $f$ (known as a model class assumption), (ii) how we measure theaccuracy of how well $\hat f$ predicts $f$, (iii) what is known about the dataand data sites, (iv) whether the data observations are polluted by noise. Amathematical description of the optimal performance possible (the smallestpossible error of recovery) is known in the presence of a model classassumption. Under standard model class assumptions, it is shown in this paperthat a near optimal $\hat f$ can be found by solving a certain discreteover-parameterized optimization problem with a penalty term. Here, near optimalmeans that the error is bounded by a fixed constant times the optimal error.This explains the advantage of over-parameterization which is commonly used inmodern machine learning. The main results of this paper prove thatover-parameterized learning with an appropriate loss function gives a nearoptimal approximation $\hat f$ of the function $f$ from which the data iscollected. Quantitative bounds are given for how much over-parameterizationneeds to be employed and how the penalization needs to be scaled in order toguarantee a near optimal recovery of $f$. An extension of these results to thecase where the data is polluted by additive deterministic noise is also given.</description><author>Peter Binev, Andrea Bonito, Ronald DeVore, Guergana Petrova</author><pubDate>Mon, 26 Jun 2023 17:07:33 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2203.15994v2</guid></item><item><title>A Positive-Unlabeled Metric Learning Framework for Document-Level Relation Extraction with Incomplete Labeling</title><link>http://arxiv.org/abs/2306.14806v1</link><description>The goal of document-level relation extraction (RE) is to identify relationsbetween entities that span multiple sentences. Recently, incomplete labeling indocument-level RE has received increasing attention, and some studies have usedmethods such as positive-unlabeled learning to tackle this issue, but there isstill a lot of room for improvement. Motivated by this, we propose apositive-augmentation and positive-mixup positive-unlabeled metric learningframework (P3M). Specifically, we formulate document-level RE as a metriclearning problem. We aim to pull the distance closer between entity pairembedding and their corresponding relation embedding, while pushing it fartheraway from the none-class relation embedding. Additionally, we adapt thepositive-unlabeled learning to this loss objective. In order to improve thegeneralizability of the model, we use dropout to augment positive samples andpropose a positive-none-class mixup method. Extensive experiments show that P3Mimproves the F1 score by approximately 4-10 points in document-level RE withincomplete labeling, and achieves state-of-the-art results in fully labeledscenarios. Furthermore, P3M has also demonstrated robustness to priorestimation bias in incomplete labeled scenarios.</description><author>Ye Wang, Huazheng Pan, Tao Zhang, Wen Wu, Wenxin Hu</author><pubDate>Mon, 26 Jun 2023 17:05:59 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.14806v1</guid></item><item><title>A Gradient Smoothed Functional Algorithm with Truncated Cauchy Random Perturbations for Stochastic Optimization</title><link>http://arxiv.org/abs/2208.00290v3</link><description>In this paper, we present a stochastic gradient algorithm for minimizing asmooth objective function that is an expectation over noisy cost samples, andonly the latter are observed for any given parameter. Our algorithm employs agradient estimation scheme with random perturbations, which are formed usingthe truncated Cauchy distribution from the delta sphere. We analyze the biasand variance of the proposed gradient estimator. Our algorithm is found to beparticularly useful in the case when the objective function is non-convex, andthe parameter dimension is high. From an asymptotic convergence analysis, weestablish that our algorithm converges almost surely to the set of stationarypoints of the objective function and obtains the asymptotic convergence rate.We also show that our algorithm avoids unstable equilibria, implyingconvergence to local minima. Further, we perform a non-asymptotic convergenceanalysis of our algorithm. In particular, we establish here a non-asymptoticbound for finding an epsilon-stationary point of the non-convex objectivefunction. Finally, we demonstrate numerically through simulations that theperformance of our algorithm outperforms GSF, SPSA, and RDSA by a significantmargin over a few non-convex settings and further validate its performance overconvex (noisy) objectives.</description><author>Akash Mondal, Prashanth L. A., Shalabh Bhatnagar</author><pubDate>Mon, 26 Jun 2023 17:04:47 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2208.00290v3</guid></item><item><title>On Imitation in Mean-field Games</title><link>http://arxiv.org/abs/2306.14799v1</link><description>We explore the problem of imitation learning (IL) in the context ofmean-field games (MFGs), where the goal is to imitate the behavior of apopulation of agents following a Nash equilibrium policy according to someunknown payoff function. IL in MFGs presents new challenges compared tosingle-agent IL, particularly when both the reward function and the transitionkernel depend on the population distribution. In this paper, departing from theexisting literature on IL for MFGs, we introduce a new solution concept calledthe Nash imitation gap. Then we show that when only the reward depends on thepopulation distribution, IL in MFGs can be reduced to single-agent IL withsimilar guarantees. However, when the dynamics is population-dependent, weprovide a novel upper-bound that suggests IL is harder in this setting. Toaddress this issue, we propose a new adversarial formulation where thereinforcement learning problem is replaced by a mean-field control (MFC)problem, suggesting progress in IL within MFGs may have to build upon MFC.</description><author>Giorgia Ramponi, Pavel Kolev, Olivier Pietquin, Niao He, Mathieu Laurière, Matthieu Geist</author><pubDate>Mon, 26 Jun 2023 16:58:13 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.14799v1</guid></item><item><title>MotionGPT: Human Motion as a Foreign Language</title><link>http://arxiv.org/abs/2306.14795v1</link><description>Though the advancement of pre-trained large language models unfolds, theexploration of building a unified model for language and other multi-modaldata, such as motion, remains challenging and untouched so far. Fortunately,human motion displays a semantic coupling akin to human language, oftenperceived as a form of body language. By fusing language data with large-scalemotion models, motion-language pre-training that can enhance the performance ofmotion-related tasks becomes feasible. Driven by this insight, we proposeMotionGPT, a unified, versatile, and user-friendly motion-language model tohandle multiple motion-relevant tasks. Specifically, we employ the discretevector quantization for human motion and transfer 3D motion into motion tokens,similar to the generation process of word tokens. Building upon this "motionvocabulary", we perform language modeling on both motion and text in a unifiedmanner, treating human motion as a specific language. Moreover, inspired byprompt learning, we pre-train MotionGPT with a mixture of motion-language dataand fine-tune it on prompt-based question-and-answer tasks. Extensiveexperiments demonstrate that MotionGPT achieves state-of-the-art performanceson multiple motion tasks including text-driven motion generation, motioncaptioning, motion prediction, and motion in-between.</description><author>Biao Jiang, Xin Chen, Wen Liu, Jingyi Yu, Gang Yu, Tao Chen</author><pubDate>Mon, 26 Jun 2023 16:53:02 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.14795v1</guid></item><item><title>Balanced Training of Energy-Based Models with Adaptive Flow Sampling</title><link>http://arxiv.org/abs/2306.00684v3</link><description>Energy-based models (EBMs) are versatile density estimation models thatdirectly parameterize an unnormalized log density. Although very flexible, EBMslack a specified normalization constant of the model, making the likelihood ofthe model computationally intractable. Several approximate samplers andvariational inference techniques have been proposed to estimate the likelihoodgradients for training. These techniques have shown promising results ingenerating samples, but little attention has been paid to the statisticalaccuracy of the estimated density, such as determining the relative importanceof different classes in a dataset. In this work, we propose a new maximumlikelihood training algorithm for EBMs that uses a different type of generativemodel, normalizing flows (NF), which have recently been proposed to facilitatesampling. Our method fits an NF to an EBM during training so that anNF-assisted sampling scheme provides an accurate gradient for the EBMs at alltimes, ultimately leading to a fast sampler for generating new data.</description><author>Louis Grenioux, Éric Moulines, Marylou Gabrié</author><pubDate>Mon, 26 Jun 2023 16:51:59 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.00684v3</guid></item><item><title>Automatic Assessment of Divergent Thinking in Chinese Language with TransDis: A Transformer-Based Language Model Approach</title><link>http://arxiv.org/abs/2306.14790v1</link><description>Language models have been increasingly popular for automatic creativityassessment, generating semantic distances to objectively measure the quality ofcreative ideas. However, there is currently a lack of an automatic assessmentsystem for evaluating creative ideas in the Chinese language. To address thisgap, we developed TransDis, a scoring system using transformer-based languagemodels, capable of providing valid originality (quality) and flexibility(variety) scores for Alternative Uses Task (AUT) responses in Chinese. Study 1demonstrated that the latent model-rated originality factor, comprised of threetransformer-based models, strongly predicted human originality ratings, and themodel-rated flexibility strongly correlated with human flexibility ratings aswell. Criterion validity analyses indicated that model-rated originality andflexibility positively correlated to other creativity measures, demonstratingsimilar validity to human ratings. Study 2 &amp; 3 showed that TransDis effectivelydistinguished participants instructed to provide creative vs. common uses(Study 2) and participants instructed to generate ideas in a flexible vs.persistent way (Study 3). Our findings suggest that TransDis can be a reliableand low-cost tool for measuring idea originality and flexibility in Chineselanguage, potentially paving the way for automatic creativity assessment inother languages. We offer an open platform to compute originality andflexibility for AUT responses in Chinese and over 50 other languages(https://osf.io/59jv2/).</description><author>Tianchen Yang, Qifan Zhang, Zhaoyang Sun, Yubo Hou</author><pubDate>Mon, 26 Jun 2023 16:48:05 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.14790v1</guid></item><item><title>BenchMD: A Benchmark for Unified Learning on Medical Images and Sensors</title><link>http://arxiv.org/abs/2304.08486v2</link><description>Medical data poses a daunting challenge for AI algorithms: it exists in manydifferent modalities, experiences frequent distribution shifts, and suffersfrom a scarcity of examples and labels. Recent advances, including transformersand self-supervised learning, promise a more universal approach that can beapplied flexibly across these diverse conditions. To measure and drive progressin this direction, we present BenchMD: a benchmark that tests how well unified,modality-agnostic methods, including architectures and training techniques(e.g. self-supervised learning, ImageNet pretraining),perform on a diversearray of clinically-relevant medical tasks. BenchMD combines 19 publiclyavailable datasets for 7 medical modalities, including 1D sensor data, 2Dimages, and 3D volumetric scans. Our benchmark reflects real-world dataconstraints by evaluating methods across a range of dataset sizes, includingchallenging few-shot settings that incentivize the use of pretraining. Finally,we evaluate performance on out-of-distribution data collected at differenthospitals than the training data, representing naturally-occurring distributionshifts that frequently degrade the performance of medical AI models. Ourbaseline results demonstrate that no unified learning technique achieves strongperformance across all modalities, leaving ample room for improvement on thebenchmark. Code is released at https://github.com/rajpurkarlab/BenchMD.</description><author>Kathryn Wantlin, Chenwei Wu, Shih-Cheng Huang, Oishi Banerjee, Farah Dadabhoy, Veeral Vipin Mehta, Ryan Wonhee Han, Fang Cao, Raja R. Narayan, Errol Colak, Adewole Adamson, Laura Heacock, Geoffrey H. Tison, Alex Tamkin, Pranav Rajpurkar</author><pubDate>Mon, 26 Jun 2023 16:47:27 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2304.08486v2</guid></item><item><title>Segmentation of Industrial Burner Flames: A Comparative Study from Traditional Image Processing to Machine and Deep Learning</title><link>http://arxiv.org/abs/2306.14789v1</link><description>In many industrial processes, such as power generation, chemical production,and waste management, accurately monitoring industrial burner flamecharacteristics is crucial for safe and efficient operation. A key stepinvolves separating the flames from the background through binary segmentation.Decades of machine vision research have produced a wide range of possiblesolutions, from traditional image processing to traditional machine learningand modern deep learning methods. In this work, we present a comparative studyof multiple segmentation approaches, namely Global Thresholding, RegionGrowing, Support Vector Machines, Random Forest, Multilayer Perceptron, U-Net,and DeepLabV3+, that are evaluated on a public benchmark dataset of industrialburner flames. We provide helpful insights and guidance for researchers andpractitioners aiming to select an appropriate approach for the binarysegmentation of industrial burner flames and beyond. For the highest accuracy,deep learning is the leading approach, while for fast and simple solutions,traditional image processing techniques remain a viable option.</description><author>Steven Landgraf, Markus Hillemann, Moritz Aberle, Valentin Jung, Markus Ulrich</author><pubDate>Mon, 26 Jun 2023 16:46:49 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.14789v1</guid></item><item><title>Distributive Pre-Training of Generative Modeling Using Matrix-Product States</title><link>http://arxiv.org/abs/2306.14787v1</link><description>Tensor networks have recently found applications in machine learning for bothsupervised learning and unsupervised learning. The most common approaches fortraining these models are gradient descent methods. In this work, we consideran alternative training scheme utilizing basic tensor network operations, e.g.,summation and compression. The training algorithm is based on compressing thesuperposition state constructed from all the training data in product staterepresentation. The algorithm could be parallelized easily and only iteratesthrough the dataset once. Hence, it serves as a pre-training algorithm. Webenchmark the algorithm on the MNIST dataset and show reasonable results forgenerating new images and classification tasks. Furthermore, we provide aninterpretation of the algorithm as a compressed quantum kernel densityestimation for the probability amplitude of input data.</description><author>Sheng-Hsuan Lin, Olivier Kuijpers, Sebastian Peterhansl, Frank Pollmann</author><pubDate>Mon, 26 Jun 2023 16:46:08 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.14787v1</guid></item><item><title>INDEXITY: a web-based collaborative tool for medical video annotation</title><link>http://arxiv.org/abs/2306.14780v1</link><description>This technical report presents Indexity 1.4.0, a web-based tool designed formedical video annotation in surgical data science projects. We describe themain features available for the management of videos, annotations, ontology andusers, as well as the global software architecture.</description><author>Jean-Paul Mazellier, Méline Bour-Lang, Sabrina Bourouis, Johan Moreau, Aimable Muzuri, Olivier Schweitzer, Aslan Vatsaev, Julien Waechter, Emilie Wernert, Frederic Woelffel, Alexandre Hostettler, Nicolas Padoy, Flavien Bridault</author><pubDate>Mon, 26 Jun 2023 16:40:15 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.14780v1</guid></item><item><title>A Differential Testing Framework to Evaluate Image Recognition Model Robustness</title><link>http://arxiv.org/abs/2306.06208v2</link><description>Image recognition tasks typically use deep learning and require enormousprocessing power, thus relying on hardware accelerators like GPUs and TPUs forfast, timely processing. Failure in real-time image recognition tasks can occurdue to sub-optimal mapping on hardware accelerators during model deployment,which may lead to timing uncertainty and erroneous behavior. Mapping onhardware accelerators is done through multiple software components like deeplearning frameworks, compilers, device libraries, that we refer to as thecomputational environment. Owing to the increased use of image recognitiontasks in safety-critical applications like autonomous driving and medicalimaging, it is imperative to assess their robustness to changes in thecomputational environment, as the impact of parameters like deep learningframeworks, compiler optimizations, and hardware devices on model performanceand correctness is not well understood. In this paper we present a differential testing framework, which allows deeplearning model variant generation, execution, differential analysis and testingfor a number of computational environment parameters. Using our framework, weconduct an empirical study of robustness analysis of three popular imagerecognition models using the ImageNet dataset, assessing the impact of changingdeep learning frameworks, compiler optimizations, and hardware devices. Wereport the impact in terms of misclassifications and inference time differencesacross different settings. In total, we observed up to 72% output labeldifferences across deep learning frameworks, and up to 82% unexpectedperformance degradation in terms of inference time, when applying compileroptimizations. Using the analysis tools in our framework, we also perform faultanalysis to understand the reasons for the observed differences.</description><author>Nikolaos Louloudakis, Perry Gibson, José Cano, Ajitha Rajan</author><pubDate>Mon, 26 Jun 2023 16:38:42 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.06208v2</guid></item><item><title>Language Models are Bounded Pragmatic Speakers</title><link>http://arxiv.org/abs/2305.17760v2</link><description>How do language models "think"? This paper formulates a probabilisticcognitive model called the bounded pragmatic speaker, which can characterizethe operation of different variations of language models. Specifically, wedemonstrate that large language models fine-tuned with reinforcement learningfrom human feedback (Ouyang et al., 2022) embody a model of thought thatconceptually resembles a fast-and-slow model (Kahneman, 2011), whichpsychologists have attributed to humans. We discuss the limitations ofreinforcement learning from human feedback as a fast-and-slow model of thoughtand propose avenues for expanding this framework. In essence, our researchhighlights the value of adopting a cognitive probabilistic modeling approach togain insights into the comprehension, evaluation, and advancement of languagemodels.</description><author>Khanh Nguyen</author><pubDate>Mon, 26 Jun 2023 16:37:55 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.17760v2</guid></item><item><title>Parameter-Level Soft-Masking for Continual Learning</title><link>http://arxiv.org/abs/2306.14775v1</link><description>Existing research on task incremental learning in continual learning hasprimarily focused on preventing catastrophic forgetting (CF). Although severaltechniques have achieved learning with no CF, they attain it by letting eachtask monopolize a sub-network in a shared network, which seriously limitsknowledge transfer (KT) and causes over-consumption of the network capacity,i.e., as more tasks are learned, the performance deteriorates. The goal of thispaper is threefold: (1) overcoming CF, (2) encouraging KT, and (3) tackling thecapacity problem. A novel technique (called SPG) is proposed that soft-masks(partially blocks) parameter updating in training based on the importance ofeach parameter to old tasks. Each task still uses the full network, i.e., nomonopoly of any part of the network by any task, which enables maximum KT andreduction in capacity usage. To our knowledge, this is the first work thatsoft-masks a model at the parameter-level for continual learning. Extensiveexperiments demonstrate the effectiveness of SPG in achieving all threeobjectives. More notably, it attains significant transfer of knowledge not onlyamong similar tasks (with shared knowledge) but also among dissimilar tasks(with little shared knowledge) while mitigating CF.</description><author>Tatsuya Konishi, Mori Kurokawa, Chihiro Ono, Zixuan Ke, Gyuhak Kim, Bing Liu</author><pubDate>Mon, 26 Jun 2023 16:35:27 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.14775v1</guid></item><item><title>LoSparse: Structured Compression of Large Language Models based on Low-Rank and Sparse Approximation</title><link>http://arxiv.org/abs/2306.11222v2</link><description>Transformer models have achieved remarkable results in various naturallanguage tasks, but they are often prohibitively large, requiring massivememories and computational resources. To reduce the size and complexity ofthese models, we propose LoSparse (Low-Rank and Sparse approximation), a novelmodel compression technique that approximates a weight matrix by the sum of alow-rank matrix and a sparse matrix. Our method combines the advantages of bothlow-rank approximations and pruning, while avoiding their limitations. Low-rankapproximation compresses the coherent and expressive parts in neurons, whilepruning removes the incoherent and non-expressive parts in neurons. Pruningenhances the diversity of low-rank approximations, and low-rank approximationprevents pruning from losing too many expressive neurons. We evaluate ourmethod on natural language understanding, question answering, and naturallanguage generation tasks. We show that it significantly outperforms existingcompression methods.</description><author>Yixiao Li, Yifan Yu, Qingru Zhang, Chen Liang, Pengcheng He, Weizhu Chen, Tuo Zhao</author><pubDate>Mon, 26 Jun 2023 16:34:57 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.11222v2</guid></item><item><title>Practical Sharpness-Aware Minimization Cannot Converge All the Way to Optima</title><link>http://arxiv.org/abs/2306.09850v2</link><description>Sharpness-Aware Minimization (SAM) is an optimizer that takes a descent stepbased on the gradient at a perturbation $y_t = x_t + \rho \frac{\nablaf(x_t)}{\lVert \nabla f(x_t) \rVert}$ of the current point $x_t$. Existingstudies prove convergence of SAM for smooth functions, but they do so byassuming decaying perturbation size $\rho$ and/or no gradient normalization in$y_t$, which is detached from practice. To address this gap, we studydeterministic/stochastic versions of SAM with practical configurations (i.e.,constant $\rho$ and gradient normalization in $y_t$) and explore theirconvergence properties on smooth functions with (non)convexity assumptions.Perhaps surprisingly, in many scenarios, we find out that SAM has limitedcapability to converge to global minima or stationary points. For smoothstrongly convex functions, we show that while deterministic SAM enjoys tightglobal convergence rates of $\tilde \Theta(\frac{1}{T^2})$, the convergencebound of stochastic SAM suffers an inevitable additive term $O(\rho^2)$,indicating convergence only up to neighborhoods of optima. In fact, such$O(\rho^2)$ factors arise for stochastic SAM in all the settings we consider,and also for deterministic SAM in nonconvex cases; importantly, we prove byexamples that such terms are unavoidable. Our results highlight vastlydifferent characteristics of SAM with vs. without decaying perturbation size orgradient normalization, and suggest that the intuitions gained from one versionmay not apply to the other.</description><author>Dongkuk Si, Chulhee Yun</author><pubDate>Mon, 26 Jun 2023 16:27:47 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.09850v2</guid></item><item><title>An Overview about Emerging Technologies of Autonomous Driving</title><link>http://arxiv.org/abs/2306.13302v2</link><description>Since DARPA started Grand Challenges in 2004 and Urban Challenges in 2007,autonomous driving has been the most active field of AI applications. Thispaper gives an overview about technical aspects of autonomous drivingtechnologies and open problems. We investigate the major fields of self-drivingsystems, such as perception, mapping and localization, prediction, planning andcontrol, simulation, V2X and safety etc. Especially we elaborate on all theseissues in a framework of data closed loop, a popular platform to solve the longtailed autonomous driving problems.</description><author>Yu Huang, Yue Chen, Zijiang Yang</author><pubDate>Mon, 26 Jun 2023 16:27:29 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.13302v2</guid></item><item><title>ProtoDiff: Learning to Learn Prototypical Networks by Task-Guided Diffusion</title><link>http://arxiv.org/abs/2306.14770v1</link><description>Prototype-based meta-learning has emerged as a powerful technique foraddressing few-shot learning challenges. However, estimating a deterministicprototype using a simple average function from a limited number of examplesremains a fragile process. To overcome this limitation, we introduce ProtoDiff,a novel framework that leverages a task-guided diffusion model during themeta-training phase to gradually generate prototypes, thereby providingefficient class representations. Specifically, a set of prototypes is optimizedto achieve per-task prototype overfitting, enabling accurately obtaining theoverfitted prototypes for individual tasks. Furthermore, we introduce atask-guided diffusion process within the prototype space, enabling themeta-learning of a generative process that transitions from a vanilla prototypeto an overfitted prototype. ProtoDiff gradually generates task-specificprototypes from random noise during the meta-test stage, conditioned on thelimited samples available for the new task. Furthermore, to expedite trainingand enhance ProtoDiff's performance, we propose the utilization of residualprototype learning, which leverages the sparsity of the residual prototype. Weconduct thorough ablation studies to demonstrate its ability to accuratelycapture the underlying prototype distribution and enhance generalization. Thenew state-of-the-art performance on within-domain, cross-domain, and few-taskfew-shot classification further substantiates the benefit of ProtoDiff.</description><author>Yingjun Du, Zehao Xiao, Shengcai Liao, Cees Snoek</author><pubDate>Mon, 26 Jun 2023 16:26:24 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.14770v1</guid></item><item><title>Uncovering Political Hate Speech During Indian Election Campaign: A New Low-Resource Dataset and Baselines</title><link>http://arxiv.org/abs/2306.14764v1</link><description>The detection of hate speech in political discourse is a critical issue, andthis becomes even more challenging in low-resource languages. To address thisissue, we introduce a new dataset named IEHate, which contains 11,457 manuallyannotated Hindi tweets related to the Indian Assembly Election Campaign fromNovember 1, 2021, to March 9, 2022. We performed a detailed analysis of thedataset, focusing on the prevalence of hate speech in political communicationand the different forms of hateful language used. Additionally, we benchmarkthe dataset using a range of machine learning, deep learning, andtransformer-based algorithms. Our experiments reveal that the performance ofthese models can be further improved, highlighting the need for more advancedtechniques for hate speech detection in low-resource languages. In particular,the relatively higher score of human evaluation over algorithms emphasizes theimportance of utilizing both human and automated approaches for effective hatespeech moderation. Our IEHate dataset can serve as a valuable resource forresearchers and practitioners working on developing and evaluating hate speechdetection techniques in low-resource languages. Overall, our work underscoresthe importance of addressing the challenges of identifying and mitigating hatespeech in political discourse, particularly in the context of low-resourcelanguages. The dataset and resources for this work are made available athttps://github.com/Farhan-jafri/Indian-Election.</description><author>Farhan Ahmad Jafri, Mohammad Aman Siddiqui, Surendrabikram Thapa, Kritesh Rauniyar, Usman Naseem, Imran Razzak</author><pubDate>Mon, 26 Jun 2023 16:17:54 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.14764v1</guid></item><item><title>Fault Detection via Occupation Kernel Principal Component Analysis</title><link>http://arxiv.org/abs/2303.11138v2</link><description>The reliable operation of automatic systems is heavily dependent on theability to detect faults in the underlying dynamical system. While traditionalmodel-based methods have been widely used for fault detection, data-drivenapproaches have garnered increasing attention due to their ease of deploymentand minimal need for expert knowledge. In this paper, we present a novelprincipal component analysis (PCA) method that uses occupation kernels.Occupation kernels result in feature maps that are tailored to the measureddata, have inherent noise-robustness due to the use of integration, and canutilize irregularly sampled system trajectories of variable lengths for PCA.The occupation kernel PCA method is used to develop a reconstruction errorapproach to fault detection and its efficacy is validated using numericalsimulations.</description><author>Zachary Morrison, Benjamin P. Russo, Yingzhao Lian, Rushikesh Kamalapurkar</author><pubDate>Mon, 26 Jun 2023 16:16:42 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2303.11138v2</guid></item><item><title>QR-CLIP: Introducing Explicit Open-World Knowledge for Location and Time Reasoning</title><link>http://arxiv.org/abs/2302.00952v2</link><description>Daily images may convey abstract meanings that require us to memorize andinfer profound information from them. To encourage such human-like reasoning,in this work, we teach machines to predict where and when it was taken ratherthan performing basic tasks like traditional segmentation or classification.Inspired by Horn's QR theory, we designed a novel QR-CLIP model consisting oftwo components: 1) the Quantity module first retrospects more open-worldknowledge as the candidate language inputs; 2) the Relevance module carefullyestimates vision and language cues and infers the location and time.Experiments show our QR-CLIP's effectiveness, and it outperforms the previousSOTA on each task by an average of about 10% and 130% relative lift in terms oflocation and time reasoning. This study lays a technical foundation forlocation and time reasoning and suggests that effectively introducingopen-world knowledge is one of the panaceas for the tasks.</description><author>Weimin Shi, Mingchen Zhuge, Zhong Zhou, Dehong Gao, Deng-Ping Fan</author><pubDate>Mon, 26 Jun 2023 16:14:45 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2302.00952v2</guid></item><item><title>PMaF: Deep Declarative Layers for Principal Matrix Features</title><link>http://arxiv.org/abs/2306.14759v1</link><description>We explore two differentiable deep declarative layers, namely least squareson sphere (LESS) and implicit eigen decomposition (IED), for learning theprincipal matrix features (PMaF). This can be used to represent data featureswith a low-dimension vector containing dominant information from ahigh-dimension matrix. We first solve the problems with iterative optimizationin the forward pass and then backpropagate the solution for implicit gradientsunder a bi-level optimization framework. Particularly, adaptive descent stepswith the backtracking line search method and descent decay in the tangent spaceare studied to improve the forward pass efficiency of LESS. Meanwhile,exploited data structures are used to greatly reduce the computationalcomplexity in the backward pass of LESS and IED. Empirically, we demonstratethe superiority of our layers over the off-the-shelf baselines by comparing thesolution optimality and computational requirements.</description><author>Zhiwei Xu, Hao Wang, Yanbin Liu, Stephen Gould</author><pubDate>Mon, 26 Jun 2023 16:13:36 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.14759v1</guid></item><item><title>The MI-Motion Dataset and Benchmark for 3D Multi-Person Motion Prediction</title><link>http://arxiv.org/abs/2306.13566v2</link><description>3D multi-person motion prediction is a challenging task that involvesmodeling individual behaviors and interactions between people. Despite theemergence of approaches for this task, comparing them is difficult due to thelack of standardized training settings and benchmark datasets. In this paper,we introduce the Multi-Person Interaction Motion (MI-Motion) Dataset, whichincludes skeleton sequences of multiple individuals collected by motion capturesystems and refined and synthesized using a game engine. The dataset contains167k frames of interacting people's skeleton poses and is categorized into 5different activity scenes. To facilitate research in multi-person motionprediction, we also provide benchmarks to evaluate the performance ofprediction methods in three settings: short-term, long-term, andultra-long-term prediction. Additionally, we introduce a novel baselineapproach that leverages graph and temporal convolutional networks, which hasdemonstrated competitive results in multi-person motion prediction. We believethat the proposed MI-Motion benchmark dataset and baseline will facilitatefuture research in this area, ultimately leading to better understanding andmodeling of multi-person interactions.</description><author>Xiaogang Peng, Xiao Zhou, Yikai Luo, Hao Wen, Yu Ding, Zizhao Wu</author><pubDate>Mon, 26 Jun 2023 16:13:31 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.13566v2</guid></item><item><title>Représentation graphique de la langue des signes française et édition logicielle</title><link>http://arxiv.org/abs/2306.14754v1</link><description>Cet article propose une m\'ethode pour d\'efinir une forme graphique\'editable standardis\'ee pour les langues des signes, ainsi qu'une proposition"AZVD" et un \'editeur logiciel associ\'e. Inspir\'ee d'une part par lesr\'egularit\'es observ\'ees dans les pratiques spontan\'ees de locuteurspratiquant la sch\'ematisation, la d\'emarche tente garantir un syst\`emequalifi\'e d'adoptable. Li\'ee d'autre part au mod\`ele formel derepr\'esentation AZee, elle vise \'egalement \`a sp\'ecifier un syst\`eme donttoutes les productions ont une lecture d\'etermin\'ee au point o\`u elles sontautomatiquement synth\'etisables par un avatar. -- This paper proposes a definition method for an editable standard graphicalform of Sign Language discourse representation. It also puts forward atentative system "AZVD", and presents an associated software editor. The systemis inspired by the regularities observed in spontaneous diagrams produced bysome language users, in order to make it as adoptable as possible. Moreover, itis built upon the formal representation model AZee, so that any graphicalinstance produced by the system determines its own read-out form, to the pointthat they can be automatically synthesised by an avatar.</description><author>Michael Filhol, Thomas von Ascheberg</author><pubDate>Mon, 26 Jun 2023 16:09:51 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.14754v1</guid></item><item><title>The Deep Arbitrary Polynomial Chaos Neural Network or how Deep Artificial Neural Networks could benefit from Data-Driven Homogeneous Chaos Theory</title><link>http://arxiv.org/abs/2306.14753v1</link><description>Artificial Intelligence and Machine learning have been widely used in variousfields of mathematical computing, physical modeling, computational science,communication science, and stochastic analysis. Approaches based on DeepArtificial Neural Networks (DANN) are very popular in our days. Depending onthe learning task, the exact form of DANNs is determined via their multi-layerarchitecture, activation functions and the so-called loss function. However,for a majority of deep learning approaches based on DANNs, the kernel structureof neural signal processing remains the same, where the node response isencoded as a linear superposition of neural activity, while the non-linearityis triggered by the activation functions. In the current paper, we suggest toanalyze the neural signal processing in DANNs from the point of view ofhomogeneous chaos theory as known from polynomial chaos expansion (PCE). Fromthe PCE perspective, the (linear) response on each node of a DANN could be seenas a $1^{st}$ degree multi-variate polynomial of single neurons from theprevious layer, i.e. linear weighted sum of monomials. From this point of view,the conventional DANN structure relies implicitly (but erroneously) on aGaussian distribution of neural signals. Additionally, this view revels that bydesign DANNs do not necessarily fulfill any orthogonality or orthonormalitycondition for a majority of data-driven applications. Therefore, the prevailinghandling of neural signals in DANNs could lead to redundant representation asany neural signal could contain some partial information from other neuralsignals. To tackle that challenge, we suggest to employ the data-drivengeneralization of PCE theory known as arbitrary polynomial chaos (aPC) toconstruct a corresponding multi-variate orthonormal representations on eachnode of a DANN to obtain Deep arbitrary polynomial chaos neural networks.</description><author>Sergey Oladyshkin, Timothy Praditia, Ilja Kröker, Farid Mohammadi, Wolfgang Nowak, Sebastian Otte</author><pubDate>Mon, 26 Jun 2023 16:09:14 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.14753v1</guid></item><item><title>MedLSAM: Localize and Segment Anything Model for 3D Medical Images</title><link>http://arxiv.org/abs/2306.14752v1</link><description>The Segment Anything Model (SAM) has recently emerged as a groundbreakingmodel in the field of image segmentation. Nevertheless, both the original SAMand its medical adaptations necessitate slice-by-slice annotations, whichdirectly increase the annotation workload with the size of the dataset. Wepropose MedLSAM to address this issue, ensuring a constant annotation workloadirrespective of dataset size and thereby simplifying the annotation process.Our model introduces a few-shot localization framework capable of localizingany target anatomical part within the body. To achieve this, we develop aLocalize Anything Model for 3D Medical Images (MedLAM), utilizing twoself-supervision tasks: relative distance regression (RDR) and multi-scalesimilarity (MSS) across a comprehensive dataset of 14,012 CT scans. We thenestablish a methodology for accurate segmentation by integrating MedLAM withSAM. By annotating only six extreme points across three directions on a fewtemplates, our model can autonomously identify the target anatomical region onall data scheduled for annotation. This allows our framework to generate a 2Dbounding box for every slice of the image, which are then leveraged by SAM tocarry out segmentations. We conducted experiments on two 3D datasets covering38 organs and found that MedLSAM matches the performance of SAM and its medicaladaptations while requiring only minimal extreme point annotations for theentire dataset. Furthermore, MedLAM has the potential to be seamlesslyintegrated with future 3D SAM models, paving the way for enhanced performance.Our code is public at\href{https://github.com/openmedlab/MedLSAM}{https://github.com/openmedlab/MedLSAM}.</description><author>Wenhui Lei, Xu Wei, Xiaofan Zhang, Kang Li, Shaoting Zhang</author><pubDate>Mon, 26 Jun 2023 16:09:02 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.14752v1</guid></item><item><title>A denoised Mean Teacher for domain adaptive point cloud registration</title><link>http://arxiv.org/abs/2306.14749v1</link><description>Point cloud-based medical registration promises increased computationalefficiency, robustness to intensity shifts, and anonymity preservation but islimited by the inefficacy of unsupervised learning with similarity metrics.Supervised training on synthetic deformations is an alternative but, in turn,suffers from the domain gap to the real domain. In this work, we aim to tacklethis gap through domain adaptation. Self-training with the Mean Teacher is anestablished approach to this problem but is impaired by the inherent noise ofthe pseudo labels from the teacher. As a remedy, we present a denoisedteacher-student paradigm for point cloud registration, comprising twocomplementary denoising strategies. First, we propose to filter pseudo labelsbased on the Chamfer distances of teacher and student registrations, thuspreventing detrimental supervision by the teacher. Second, we make the teacherdynamically synthesize novel training pairs with noise-free labels by warpingits moving inputs with the predicted deformations. Evaluation is performed forinhale-to-exhale registration of lung vessel trees on the public PVT datasetunder two domain shifts. Our method surpasses the baseline Mean Teacher by13.5/62.8%, consistently outperforms diverse competitors, and sets a newstate-of-the-art accuracy (TRE=2.31mm). Code is available athttps://github.com/multimodallearning/denoised_mt_pcd_reg.</description><author>Alexander Bigalke, Mattias P. Heinrich</author><pubDate>Mon, 26 Jun 2023 16:03:47 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.14749v1</guid></item><item><title>ChiPFormer: Transferable Chip Placement via Offline Decision Transformer</title><link>http://arxiv.org/abs/2306.14744v1</link><description>Placement is a critical step in modern chip design, aiming to determine thepositions of circuit modules on the chip canvas. Recent works have shown thatreinforcement learning (RL) can improve human performance in chip placement.However, such an RL-based approach suffers from long training time and lowtransfer ability in unseen chip circuits. To resolve these challenges, we castthe chip placement as an offline RL formulation and present ChiPFormer thatenables learning a transferable placement policy from fixed offline data.ChiPFormer has several advantages that prior arts do not have. First,ChiPFormer can exploit offline placement designs to learn transferable policiesmore efficiently in a multi-task setting. Second, ChiPFormer can promoteeffective finetuning for unseen chip circuits, reducing the placement runtimefrom hours to minutes. Third, extensive experiments on 32 chip circuitsdemonstrate that ChiPFormer achieves significantly better placement qualitywhile reducing the runtime by 10x compared to recent state-of-the-artapproaches in both public benchmarks and realistic industrial tasks. Thedeliverables are released at https://sites.google.com/view/chipformer/home.</description><author>Yao Lai, Jinxin Liu, Zhentao Tang, Bin Wang, Jianye Hao, Ping Luo</author><pubDate>Mon, 26 Jun 2023 15:59:56 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.14744v1</guid></item><item><title>Should I Stop or Should I Go: Early Stopping with Heterogeneous Populations</title><link>http://arxiv.org/abs/2306.11839v2</link><description>Randomized experiments often need to be stopped prematurely due to thetreatment having an unintended harmful effect. Existing methods that determinewhen to stop an experiment early are typically applied to the data in aggregateand do not account for treatment effect heterogeneity. In this paper, we studythe early stopping of experiments for harm on heterogeneous populations. Wefirst establish that current methods often fail to stop experiments when thetreatment harms a minority group of participants. We then use causal machinelearning to develop CLASH, the first broadly-applicable method forheterogeneous early stopping. We demonstrate CLASH's performance on simulatedand real data and show that it yields effective early stopping for bothclinical trials and A/B tests.</description><author>Hammaad Adam, Fan Yin, Mary Hu, Neil Tenenholtz, Lorin Crawford, Lester Mackey, Allison Koenecke</author><pubDate>Mon, 26 Jun 2023 15:45:42 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.11839v2</guid></item><item><title>Taking a Respite from Representation Learning for Molecular Property Prediction</title><link>http://arxiv.org/abs/2209.13492v3</link><description>Artificial intelligence (AI) has been widely applied in drug discovery with amajor task as molecular property prediction. Despite booming techniques inmolecular representation learning, fundamentals underlying molecular propertyprediction haven't been carefully examined yet. In this study, we conducted asystematic evaluation on a collection of representative models using variousmolecular representations. In addition to the commonly used MoleculeNetbenchmark datasets, we also assembled a suite of opioids-related datasets fromChEMBL and two additional activity datasets from literature. To interrogate thebasic predictive power, we also assembled a series of descriptors datasets withvarying sizes to evaluate the models' performance. In total, we trained 62,820models, including 50,220 models on fixed representations, 4,200 models onSMILES sequences and 8,400 models on molecular graphs. We first conducteddataset profiling and highlighted the activity-cliffs issue in theopioids-related datasets. We then conducted rigorous model evaluation andaddressed key questions therein. Furthermore, we examined inter-/intra-scaffoldchemical space generalization and found that activity cliffs significantly canimpact prediction performance. Based on extensive experimentation and rigorouscomparison, representation learning models still show limited performance inmolecular property prediction in most datasets. Finally, we explored intopotential causes why representation learning models fail and highlighted theimportance of dataset size. By taking this respite, we reflected on thefundamentals underlying molecular property prediction, the awareness of whichcan, hopefully, bring better AI techniques in this field.</description><author>Jianyuan Deng, Zhibo Yang, Hehe Wang, Iwao Ojima, Dimitris Samaras, Fusheng Wang</author><pubDate>Mon, 26 Jun 2023 15:44:19 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2209.13492v3</guid></item><item><title>Diffusion Models for Causal Discovery via Topological Ordering</title><link>http://arxiv.org/abs/2210.06201v2</link><description>Discovering causal relations from observational data becomes possible withadditional assumptions such as considering the functional relations to beconstrained as nonlinear with additive noise (ANM). Even with strongassumptions, causal discovery involves an expensive search problem over thespace of directed acyclic graphs (DAGs). \emph{Topological ordering} approachesreduce the optimisation space of causal discovery by searching over apermutation rather than graph space. For ANMs, the \emph{Hessian} of the datalog-likelihood can be used for finding leaf nodes in a causal graph, allowingits topological ordering. However, existing computational methods for obtainingthe Hessian still do not scale as the number of variables and the number ofsamples increase. Therefore, inspired by recent innovations in diffusionprobabilistic models (DPMs), we propose \emph{DiffAN}\footnote{Implementationis available at \url{https://github.com/vios-s/DiffAN} .}, a topologicalordering algorithm that leverages DPMs for learning a Hessian function. Weintroduce theory for updating the learned Hessian without re-training theneural network, and we show that computing with a subset of samples gives anaccurate approximation of the ordering, which allows scaling to datasets withmore samples and variables. We show empirically that our method scalesexceptionally well to datasets with up to $500$ nodes and up to $10^5$ sampleswhile still performing on par over small datasets with state-of-the-art causaldiscovery methods. Implementation is available athttps://github.com/vios-s/DiffAN .</description><author>Pedro Sanchez, Xiao Liu, Alison Q O'Neil, Sotirios A. Tsaftaris</author><pubDate>Mon, 26 Jun 2023 15:42:22 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2210.06201v2</guid></item><item><title>Leveraging Locality and Robustness to Achieve Massively Scalable Gaussian Process Regression</title><link>http://arxiv.org/abs/2306.14731v1</link><description>The accurate predictions and principled uncertainty measures provided by GPregression incur O(n^3) cost which is prohibitive for modern-day large-scaleapplications. This has motivated extensive work on computationally efficientapproximations. We introduce a new perspective by exploring robustnessproperties and limiting behaviour of GP nearest-neighbour (GPnn) prediction. Wedemonstrate through theory and simulation that as the data-size n increases,accuracy of estimated parameters and GP model assumptions become increasinglyirrelevant to GPnn predictive accuracy. Consequently, it is sufficient to spendsmall amounts of work on parameter estimation in order to achieve high MSEaccuracy, even in the presence of gross misspecification. In contrast, as ntends to infinity, uncertainty calibration and NLL are shown to remainsensitive to just one parameter, the additive noise-variance; but we show thatthis source of inaccuracy can be corrected for, thereby achieving bothwell-calibrated uncertainty measures and accurate predictions at remarkably lowcomputational cost. We exhibit a very simple GPnn regression algorithm withstand-out performance compared to other state-of-the-art GP approximations asmeasured on large UCI datasets. It operates at a small fraction of those othermethods' training costs, for example on a basic laptop taking about 30 secondsto train on a dataset of size n = 1.6 x 10^6.</description><author>Robert Allison, Anthony Stephenson, Samuel F, Edward Pyzer-Knapp</author><pubDate>Mon, 26 Jun 2023 15:32:46 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.14731v1</guid></item><item><title>Learn over Past, Evolve for Future: Forecasting Temporal Trends for Fake News Detection</title><link>http://arxiv.org/abs/2306.14728v1</link><description>Fake news detection has been a critical task for maintaining the health ofthe online news ecosystem. However, very few existing works consider thetemporal shift issue caused by the rapidly-evolving nature of news data inpractice, resulting in significant performance degradation when training onpast data and testing on future data. In this paper, we observe that theappearances of news events on the same topic may display discernible patternsover time, and posit that such patterns can assist in selecting traininginstances that could make the model adapt better to future data. Specifically,we design an effective framework FTT (Forecasting Temporal Trends), which couldforecast the temporal distribution patterns of news data and then guide thedetector to fast adapt to future distribution. Experiments on the real-worldtemporally split dataset demonstrate the superiority of our proposed framework.The code is available at https://github.com/ICTMCG/FTT-ACL23.</description><author>Beizhe Hu, Qiang Sheng, Juan Cao, Yongchun Zhu, Danding Wang, Zhengjia Wang, Zhiwei Jin</author><pubDate>Mon, 26 Jun 2023 15:29:05 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.14728v1</guid></item><item><title>Error correcting 2D-3D cascaded network for myocardial infarct scar segmentation on late gadolinium enhancement cardiac magnetic resonance images</title><link>http://arxiv.org/abs/2306.14725v1</link><description>Late gadolinium enhancement (LGE) cardiac magnetic resonance (CMR) imaging isconsidered the in vivo reference standard for assessing infarct size (IS) andmicrovascular obstruction (MVO) in ST-elevation myocardial infarction (STEMI)patients. However, the exact quantification of those markers of myocardialinfarct severity remains challenging and very time-consuming. As LGEdistribution patterns can be quite complex and hard to delineate from the bloodpool or epicardial fat, automatic segmentation of LGE CMR images ischallenging. In this work, we propose a cascaded framework of two-dimensionaland three-dimensional convolutional neural networks (CNNs) which enables tocalculate the extent of myocardial infarction in a fully automated way. Byartificially generating segmentation errors which are characteristic for 2DCNNs during training of the cascaded framework we are enforcing the detectionand correction of 2D segmentation errors and hence improve the segmentationaccuracy of the entire method. The proposed method was trained and evaluated ina five-fold cross validation using the training dataset from the EMIDECchallenge. We perform comparative experiments where our framework outperformsstate-of-the-art methods of the EMIDEC challenge, as well as 2D and 3D nnU-Net.Furthermore, in extensive ablation studies we show the advantages that comewith the proposed error correcting cascaded method.</description><author>Matthias Schwab, Mathias Pamminger, Christian Kremser, Daniel Obmann, Markus Haltmeier, Agnes Mayr</author><pubDate>Mon, 26 Jun 2023 15:21:18 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.14725v1</guid></item><item><title>FC-KBQA: A Fine-to-Coarse Composition Framework for Knowledge Base Question Answering</title><link>http://arxiv.org/abs/2306.14722v1</link><description>The generalization problem on KBQA has drawn considerable attention. Existingresearch suffers from the generalization issue brought by the entanglement inthe coarse-grained modeling of the logical expression, or inexecutabilityissues due to the fine-grained modeling of disconnected classes and relationsin real KBs. We propose a Fine-to-Coarse Composition framework for KBQA(FC-KBQA) to both ensure the generalization ability and executability of thelogical expression. The main idea of FC-KBQA is to extract relevantfine-grained knowledge components from KB and reformulate them intomiddle-grained knowledge pairs for generating the final logical expressions.FC-KBQA derives new state-of-the-art performance on GrailQA and WebQSP, andruns 4 times faster than the baseline.</description><author>Lingxi Zhang, Jing Zhang, Yanling Wang, Shulin Cao, Xinmei Huang, Cuiping Li, Hong Chen, Juanzi Li</author><pubDate>Mon, 26 Jun 2023 15:19:46 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.14722v1</guid></item><item><title>Self-supervised novel 2D view synthesis of large-scale scenes with efficient multi-scale voxel carving</title><link>http://arxiv.org/abs/2306.14709v1</link><description>The task of generating novel views of real scenes is increasingly importantnowadays when AI models become able to create realistic new worlds. In manypractical applications, it is important for novel view synthesis methods tostay grounded in the physical world as much as possible, while also being ableto imagine it from previously unseen views. While most current methods aredeveloped and tested in virtual environments with small scenes and no errors inpose and depth information, we push the boundaries to the real-world domain oflarge scales in the new context of UAVs. Our algorithmic contributions are twofolds. First, we manage to stay anchored in the real 3D world, by introducingan efficient multi-scale voxel carving method, which is able to accommodatesignificant noises in pose, depth, and illumination variations, while beingable to reconstruct the view of the world from drastically different poses attest time. Second, our final high-resolution output is efficiently self-trainedon data automatically generated by the voxel carving module, which gives it theflexibility to adapt efficiently to any scene. We demonstrated theeffectiveness of our method on highly complex and large-scale scenes in realenvironments while outperforming the current state-of-the-art. Our code ispublicly available: https://github.com/onorabil/MSVC.</description><author>Alexandra Budisteanu, Dragos Costea, Alina Marcu, Marius Leordeanu</author><pubDate>Mon, 26 Jun 2023 14:57:05 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.14709v1</guid></item><item><title>Unsupervised HDR Image and Video Tone Mapping via Contrastive Learning</title><link>http://arxiv.org/abs/2303.07327v2</link><description>Capturing high dynamic range (HDR) images (videos) is attractive because itcan reveal the details in both dark and bright regions. Since the mainstreamscreens only support low dynamic range (LDR) content, tone mapping algorithm isrequired to compress the dynamic range of HDR images (videos). Although imagetone mapping has been widely explored, video tone mapping is lagging behind,especially for the deep-learning-based methods, due to the lack of HDR-LDRvideo pairs. In this work, we propose a unified framework (IVTMNet) forunsupervised image and video tone mapping. To improve unsupervised training, wepropose domain and instance based contrastive learning loss. Instead of using auniversal feature extractor, such as VGG to extract the features for similaritymeasurement, we propose a novel latent code, which is an aggregation of thebrightness and contrast of extracted features, to measure the similarity ofdifferent pairs. We totally construct two negative pairs and three positivepairs to constrain the latent codes of tone mapped results. For the networkstructure, we propose a spatial-feature-enhanced (SFE) module to enableinformation exchange and transformation of nonlocal regions. For video tonemapping, we propose a temporal-feature-replaced (TFR) module to efficientlyutilize the temporal correlation and improve the temporal consistency of videotone-mapped results. We construct a large-scale unpaired HDR-LDR video datasetto facilitate the unsupervised training process for video tone mapping.Experimental results demonstrate that our method outperforms state-of-the-artimage and video tone mapping methods. Our code and dataset are available athttps://github.com/cao-cong/UnCLTMO.</description><author>Cong Cao, Huanjing Yue, Xin Liu, Jingyu Yang</author><pubDate>Mon, 26 Jun 2023 14:56:52 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2303.07327v2</guid></item><item><title>A Simple and Effective Baseline for Attentional Generative Adversarial Networks</title><link>http://arxiv.org/abs/2306.14708v1</link><description>Synthesising a text-to-image model of high-quality images by guiding thegenerative model through the Text description is an innovative and challengingtask. In recent years, AttnGAN based on the Attention mechanism to guide GANtraining has been proposed, SD-GAN, which adopts a self-distillation techniqueto improve the performance of the generator and the quality of imagegeneration, and Stack-GAN++, which gradually improves the details and qualityof the image by stacking multiple generators and discriminators. However, thisseries of improvements to GAN all have redundancy to a certain extent, whichaffects the generation performance and complexity to a certain extent. We usethe popular simple and effective idea (1) to remove redundancy structure andimprove the backbone network of AttnGAN. (2) to integrate and reconstructmultiple losses of DAMSM. Our improvements have significantly improved themodel size and training efficiency while ensuring that the model's performanceis unchanged and finally proposed our \textbf{SEAttnGAN}. Code is avalilable athttps://github.com/jmyissb/SEAttnGAN.</description><author>Mingyu Jin, Chong Zhang, Qinkai Yu, Haochen Xue, Xiaobo Jin, Xi Yang }</author><pubDate>Mon, 26 Jun 2023 14:55:57 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.14708v1</guid></item><item><title>Augmenting Control over Exploration Space in Molecular Dynamics Simulators to Streamline De Novo Analysis through Generative Control Policies</title><link>http://arxiv.org/abs/2306.14705v1</link><description>This study introduces the P5 model - a foundational method that utilizesreinforcement learning (RL) to augment control, effectiveness, and scalabilityin molecular dynamics simulations (MD). Our innovative strategy optimizes thesampling of target polymer chain conformations, marking an efficiencyimprovement of over 37.1%. The RL-induced control policies function as aninductive bias, modulating Brownian forces to steer the system towards thepreferred state, thereby expanding the exploration of the configuration spacebeyond what traditional MD allows. This broadened exploration generates a morevaried set of conformations and targets specific properties, a feature pivotalfor progress in polymer development, drug discovery, and material design. Ourtechnique offers significant advantages when investigating new systems withlimited prior knowledge, opening up new methodologies for tackling complexsimulation problems with generative techniques.</description><author>Paloma Gonzalez-Rojas, Andrew Emmel, Luis Martinez, Neil Malur, Gregory Rutledge</author><pubDate>Mon, 26 Jun 2023 14:54:52 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.14705v1</guid></item><item><title>Ontology Enrichment from Texts: A Biomedical Dataset for Concept Discovery and Placement</title><link>http://arxiv.org/abs/2306.14704v1</link><description>Mentions of new concepts appear regularly in texts and require automatedapproaches to harvest and place them into Knowledge Bases (KB), e.g.,ontologies and taxonomies. Existing datasets suffer from three issues, (i)mostly assuming that a new concept is pre-discovered and cannot supportout-of-KB mention discovery; (ii) only using the concept label as the inputalong with the KB and thus lacking the contexts of a concept label; and (iii)mostly focusing on concept placement w.r.t a taxonomy of atomic concepts,instead of complex concepts, i.e., with logical operators. To address theseissues, we propose a new benchmark, adapting MedMentions dataset (PubMedabstracts) with SNOMED CT versions in 2014 and 2017 under the Diseasessub-category and the broader categories of Clinical finding, Procedure, andPharmaceutical / biologic product. We provide usage on the evaluation with thedataset for out-of-KB mention discovery and concept placement, adapting recentLarge Language Model based methods.</description><author>Hang Dong, Jiaoyan Chen, Yuan He, Ian Horrocks</author><pubDate>Mon, 26 Jun 2023 14:54:47 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.14704v1</guid></item><item><title>Hard Sample Mining Enabled Contrastive Feature Learning for Wind Turbine Pitch System Fault Diagnosis</title><link>http://arxiv.org/abs/2306.14701v1</link><description>The efficient utilization of wind power by wind turbines relies on theability of their pitch systems to adjust blade pitch angles in response tovarying wind speeds. However, the presence of multiple fault types in the pitchsystem poses challenges in accurately classifying these faults. This paperproposes a novel method based on hard sample mining-enabled contrastive featurelearning (HSMCFL) to address this problem. The proposed method employs cosinesimilarity to identify hard samples and subsequently leverages contrastivefeature learning to enhance representation learning through the construction ofhard sample pairs. Furthermore, a multilayer perceptron is trained using thelearned discriminative representations to serve as an efficient classifier. To evaluate the effectiveness of the proposed method, two real datasetscomprising wind turbine pitch system cog belt fracture data are utilized. Thefault diagnosis performance of the proposed method is compared against existingmethods, and the results demonstrate its superior performance. The proposedapproach exhibits significant improvements in fault diagnosis accuracy,providing promising prospects for enhancing the reliability and efficiency ofwind turbine pitch system fault diagnosis.</description><author>Zixuan Wang, Bo Qin, Mengxuan Li, Mark D. Butala, Haibo Wang, Peng Peng, Hongwei Wang</author><pubDate>Mon, 26 Jun 2023 14:47:38 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.14701v1</guid></item><item><title>No Need to Know Physics: Resilience of Process-based Model-free Anomaly Detection for Industrial Control Systems</title><link>http://arxiv.org/abs/2012.03586v2</link><description>In recent years, a number of process-based anomaly detection schemes forIndustrial Control Systems were proposed. In this work, we provide the firstsystematic analysis of such schemes, and introduce a taxonomy of propertiesthat are verified by those detection systems. We then present a novel generalframework to generate adversarial spoofing signals that violate physicalproperties of the system, and use the framework to analyze four anomalydetectors published at top security conferences. We find that three of thosedetectors are susceptible to a number of adversarial manipulations (e.g.,spoofing with precomputed patterns), which we call Synthetic Sensor Spoofingand one is resilient against our attacks. We investigate the root of itsresilience and demonstrate that it comes from the properties that weintroduced. Our attacks reduce the Recall (True Positive Rate) of the attackedschemes making them not able to correctly detect anomalies. Thus, thevulnerabilities we discovered in the anomaly detectors show that (despite anoriginal good detection performance), those detectors are not able to reliablylearn physical properties of the system. Even attacks that prior work wasexpected to be resilient against (based on verified properties) were found tobe successful. We argue that our findings demonstrate the need for both morecomplete attacks in datasets, and more critical analysis of process-basedanomaly detectors. We plan to release our implementation as open-source,together with an extension of two public datasets with a set of SyntheticSensor Spoofing attacks as generated by our framework.</description><author>Alessandro Erba, Nils Ole Tippenhauer</author><pubDate>Mon, 26 Jun 2023 14:46:52 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2012.03586v2</guid></item><item><title>How About Kind of Generating Hedges using End-to-End Neural Models?</title><link>http://arxiv.org/abs/2306.14696v1</link><description>Hedging is a strategy for softening the impact of a statement inconversation. In reducing the strength of an expression, it may help to avoidembarrassment (more technically, ``face threat'') to one's listener. For thisreason, it is often found in contexts of instruction, such as tutoring. In thiswork, we develop a model of hedge generation based on i) fine-tuningstate-of-the-art language models trained on human-human tutoring data, followedby ii) reranking to select the candidate that best matches the expected hedgingstrategy within a candidate pool using a hedge classifier. We apply this methodto a natural peer-tutoring corpus containing a significant number ofdisfluencies, repetitions, and repairs. The results show that generation inthis noisy environment is feasible with reranking. By conducting an erroranalysis for both approaches, we reveal the challenges faced by systemsattempting to accomplish both social and task-oriented goals in conversation.</description><author>Alafate Abulimiti, Chloé Clavel, Justine Cassell</author><pubDate>Mon, 26 Jun 2023 14:43:06 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.14696v1</guid></item><item><title>DR-HAI: Argumentation-based Dialectical Reconciliation in Human-AI Interactions</title><link>http://arxiv.org/abs/2306.14694v1</link><description>We introduce DR-HAI -- a novel argumentation-based framework designed toextend model reconciliation approaches, commonly used in explainable AIplanning, for enhanced human-AI interaction. By adopting a multi-shotreconciliation paradigm and not assuming a-priori knowledge of the human user'smodel, DR-HAI enables interactive reconciliation to address knowledgediscrepancies between an explainer and an explainee. We formally describe theoperational semantics of DR-HAI, provide theoretical guarantees related totermination and success, and empirically evaluate its efficacy. Our findingssuggest that DR-HAI offers a promising direction for fostering effectivehuman-AI interactions.</description><author>Stylianos Loukas Vasileiou, Ashwin Kumar, William Yeoh, Tran Cao Son, Francesca Toni</author><pubDate>Mon, 26 Jun 2023 14:39:36 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.14694v1</guid></item><item><title>Conformal link prediction to control the error rate</title><link>http://arxiv.org/abs/2306.14693v1</link><description>Most link prediction methods return estimates of the connection probabilityof missing edges in a graph. Such output can be used to rank the missing edges,from most to least likely to be a true edge, but it does not directly provide aclassification into true and non-existent. In this work, we consider theproblem of identifying a set of true edges with a control of the falsediscovery rate (FDR). We propose a novel method based on high-level ideas fromthe literature on conformal inference. The graph structure induces intricatedependence in the data, which we carefully take into account, as this makes thesetup different from the usual setup in conformal inference, whereexchangeability is assumed. The FDR control is empirically demonstrated forboth simulated and real data.</description><author>Ariane Marandon</author><pubDate>Mon, 26 Jun 2023 14:38:49 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.14693v1</guid></item><item><title>Data-Driven Chance-Constrained Multiple-Choice Knapsack Problem: Model, Algorithms, and Applications</title><link>http://arxiv.org/abs/2306.14690v1</link><description>The multiple-choice knapsack problem (MCKP) is a classic NP-hardcombinatorial optimization problem. Motivated by several significant practicalapplications, this work investigates a novel variant of MCKP called data-drivenchance-constrained multiple-choice knapsack problem (DDCCMCKP), where the itemweight is a random variable with unknown probability distribution. We firstpresent the problem formulation of DDCCMCKP, and then establish two benchmarksets. The first set contains synthetic instances, and the second set is devisedto simulate a real-world application scenario of a certain telecommunicationcompany. To solve DDCCMCKP, we propose a data-driven adaptive local search(DDALS) algorithm. The main merit of DDALS lies in evaluating solutions withchance constraints by data-driven methods, under the condition of unknowndistributions and only historical sample data being available. The experimentalresults demonstrate the effectiveness of the proposed algorithm and show thatit is superior to other baselines. Additionally, ablation experiments confirmthe necessity of each component in the algorithm. Our proposed algorithm canserve as the baseline for future research, and the code and benchmark sets willbe open-sourced to further promote research on this challenging problem.</description><author>Xuanfeng Li, Shengcai Liu, Jin Wang, Xiao Chen, Yew-Soon Ong, Ke Tang</author><pubDate>Mon, 26 Jun 2023 14:35:05 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.14690v1</guid></item><item><title>An Evolution Kernel Method for Graph Classification through Heat Diffusion Dynamics</title><link>http://arxiv.org/abs/2306.14688v1</link><description>Autonomous individuals establish a structural complex system through pairwiseconnections and interactions. Notably, the evolution reflects the dynamicnature of each complex system since it recodes a series of temporal changesfrom the past, the present into the future. Different systems follow distinctevolutionary trajectories, which can serve as distinguishing traits for systemclassification. However, modeling a complex system's evolution is challengingfor the graph model because the graph is typically a snapshot of the staticstatus of a system, and thereby hard to manifest the long-term evolutionarytraits of a system entirely. To address this challenge, we suggest utilizing aheat-driven method to generate temporal graph augmentation. This approachincorporates the physics-based heat kernel and DropNode technique to transformeach static graph into a sequence of temporal ones. This approach effectivelydescribes the evolutional behaviours of the system, including the retention ordisappearance of elements at each time point based on the distributed heat oneach node. Additionally, we propose a dynamic time-wrapping distance GDTW toquantitatively measure the distance between pairwise evolutionary systemsthrough optimal matching. The resulting approach, called the Evolution Kernelmethod, has been successfully applied to classification problems in real-worldstructural graph datasets. The results yield significant improvements insupervised classification accuracy over a series of baseline methods.</description><author>Xue Liu, Dan Sun, Wei Wei, Zhiming Zheng</author><pubDate>Mon, 26 Jun 2023 14:32:11 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.14688v1</guid></item><item><title>GSMorph: Gradient Surgery for cine-MRI Cardiac Deformable Registration</title><link>http://arxiv.org/abs/2306.14687v1</link><description>Deep learning-based deformable registration methods have been widelyinvestigated in diverse medical applications. Learning-based deformableregistration relies on weighted objective functions trading off registrationaccuracy and smoothness of the deformation field. Therefore, they inevitablyrequire tuning the hyperparameter for optimal registration performance. Tuningthe hyperparameters is highly computationally expensive and introducesundesired dependencies on domain knowledge. In this study, we construct aregistration model based on the gradient surgery mechanism, named GSMorph, toachieve a hyperparameter-free balance on multiple losses. In GSMorph, wereformulate the optimization procedure by projecting the gradient of similarityloss orthogonally to the plane associated with the smoothness constraint,rather than additionally introducing a hyperparameter to balance these twocompeting terms. Furthermore, our method is model-agnostic and can be mergedinto any deep registration network without introducing extra parameters orslowing down inference. In this study, We compared our method withstate-of-the-art (SOTA) deformable registration approaches over two publiclyavailable cardiac MRI datasets. GSMorph proves superior to five SOTAlearning-based registration models and two conventional registrationtechniques, SyN and Demons, on both registration accuracy and smoothness.</description><author>Haoran Dou, Ning Bi, Luyi Han, Yuhao Huang, Ritse Mann, Xin Yang, Dong Ni, Nishant Ravikumar, Alejandro F. Frangi, Yunzhi Huang</author><pubDate>Mon, 26 Jun 2023 14:32:09 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.14687v1</guid></item><item><title>DiffSketcher: Text Guided Vector Sketch Synthesis through Latent Diffusion Models</title><link>http://arxiv.org/abs/2306.14685v1</link><description>Even though trained mainly on images, we discover that pretrained diffusionmodels show impressive power in guiding sketch synthesis. In this paper, wepresent DiffSketcher, an innovative algorithm that creates vectorized free-handsketches using natural language input. DiffSketcher is developed based on apre-trained text-to-image diffusion model. It performs the task by directlyoptimizing a set of Bezier curves with an extended version of the scoredistillation sampling (SDS) loss, which allows us to use a raster-leveldiffusion model as a prior for optimizing a parametric vectorized sketchgenerator. Furthermore, we explore attention maps embedded in the diffusionmodel for effective stroke initialization to speed up the generation process.The generated sketches demonstrate multiple levels of abstraction whilemaintaining recognizability, underlying structure, and essential visual detailsof the subject drawn. Our experiments show that DiffSketcher achieves greaterquality than prior work.</description><author>Ximing Xing, Chuang Wang, Haitao Zhou, Jing Zhang, Qian Yu, Dong Xu</author><pubDate>Mon, 26 Jun 2023 14:30:38 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.14685v1</guid></item><item><title>Multi-Agent Deep Reinforcement Learning for Dynamic Avatar Migration in AIoT-enabled Vehicular Metaverses with Trajectory Prediction</title><link>http://arxiv.org/abs/2306.14683v1</link><description>Avatars, as promising digital assistants in Vehicular Metaverses, can enabledrivers and passengers to immerse in 3D virtual spaces, serving as a practicalemerging example of Artificial Intelligence of Things (AIoT) in intelligentvehicular environments. The immersive experience is achieved through seamlesshuman-avatar interaction, e.g., augmented reality navigation, which requiresintensive resources that are inefficient and impractical to process onintelligent vehicles locally. Fortunately, offloading avatar tasks to RoadSideUnits (RSUs) or cloud servers for remote execution can effectively reduceresource consumption. However, the high mobility of vehicles, the dynamicworkload of RSUs, and the heterogeneity of RSUs pose novel challenges to makingavatar migration decisions. To address these challenges, in this paper, wepropose a dynamic migration framework for avatar tasks based on real-timetrajectory prediction and Multi-Agent Deep Reinforcement Learning (MADRL).Specifically, we propose a model to predict the future trajectories ofintelligent vehicles based on their historical data, indicating the futureworkloads of RSUs.Based on the expected workloads of RSUs, we formulate theavatar task migration problem as a long-term mixed integer programming problem.To tackle this problem efficiently, the problem is transformed into a PartiallyObservable Markov Decision Process (POMDP) and solved by multiple DRL agentswith hybrid continuous and discrete actions in decentralized. Numerical resultsdemonstrate that our proposed algorithm can effectively reduce the latency ofexecuting avatar tasks by around 25% without prediction and 30% with predictionand enhance user immersive experiences in the AIoT-enabled Vehicular Metaverse(AeVeM).</description><author>Junlong Chen, Jiawen Kang, Minrui Xu, Zehui Xiong, Dusit Niyato, Chuan Chen, Abbas Jamalipour, Shengli Xie</author><pubDate>Mon, 26 Jun 2023 14:27:11 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.14683v1</guid></item><item><title>A Conditional Flow Variational Autoencoder for Controllable Synthesis of Virtual Populations of Anatomy</title><link>http://arxiv.org/abs/2306.14680v1</link><description>Generating virtual populations (VPs) of anatomy is essential for conductingin-silico trials of medical devices. Typically, the generated VP should capturesufficient variability while remaining plausible, and should reflect specificcharacteristics and patient demographics observed in real populations. It isdesirable in several applications to synthesize VPs in a \textit{controlled}manner, where relevant covariates are used to conditionally synthesise virtualpopulations that fit specific target patient populations/characteristics. Wepropose to equip a conditional variational autoencoder (cVAE) with normalizingflows to boost the flexibility and complexity of the approximate posteriorlearned, leading to enhanced flexibility for controllable synthesis of VPs ofanatomical structures. We demonstrate the performance of our conditional-flowVAE using a dataset of cardiac left ventricles acquired from 2360 patients,with associated demographic information and clinical measurements (used ascovariates/conditioning information). The obtained results indicate thesuperiority of the proposed method for conditional synthesis of virtualpopulations of cardiac left ventricles relative to a cVAE. Conditionalsynthesis performance was assessed in terms of generalisation and specificityerrors, and in terms of the ability to preserve clinical relevant biomarkers inthe synthesised VPs, I.e. left ventricular blood pool and myocardial volume,relative to the observed real population.</description><author>Haoran Dou, Nishant Ravikumar, Alejandro F. Frangi</author><pubDate>Mon, 26 Jun 2023 14:23:52 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.14680v1</guid></item><item><title>Faithful Synthesis of Low-dose Contrast-enhanced Brain MRI Scans using Noise-preserving Conditional GANs</title><link>http://arxiv.org/abs/2306.14678v1</link><description>Today Gadolinium-based contrast agents (GBCA) are indispensable in MagneticResonance Imaging (MRI) for diagnosing various diseases. However, GBCAs areexpensive and may accumulate in patients with potential side effects, thusdose-reduction is recommended. Still, it is unclear to which extent the GBCAdose can be reduced while preserving the diagnostic value -- especially inpathological regions. To address this issue, we collected brain MRI scans atnumerous non-standard GBCA dosages and developed a conditional GAN model forsynthesizing corresponding images at fractional dose levels. Along with theadversarial loss, we advocate a novel content loss function based on theWasserstein distance of locally paired patch statistics for the faithfulpreservation of noise. Our numerical experiments show that conditional GANs aresuitable for generating images at different GBCA dose levels and can be used toaugment datasets for virtual contrast models. Moreover, our model can betransferred to openly available datasets such as BraTS, where non-standard GBCAdosage images do not exist.</description><author>Thomas Pinetz, Erich Kobler, Robert Haase, Katerina Deike-Hofmann, Alexander Radbruch, Alexander Effland</author><pubDate>Mon, 26 Jun 2023 14:19:37 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.14678v1</guid></item></channel></rss>