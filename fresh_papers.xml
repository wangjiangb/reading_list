<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/"><channel><title>Arxivfresh papers</title><link></link><description>Arxiv paper</description><language>en-US</language><lastBuildDate>Tue, 10 Dec 2024 01:00:05 GMT</lastBuildDate><generator>rfeed v1.0.0</generator><docs>https://github.com/svpino/rfeed/blob/master/README.md</docs><item><title>Stag-1: Towards Realistic 4D Driving Simulation with Video Generation Model</title><link>http://arxiv.org/abs/2412.05280v1</link><description>4D driving simulation is essential for developing realistic autonomousdriving simulators. Despite advancements in existing methods for generatingdriving scenes, significant challenges remain in view transformation andspatial-temporal dynamic modeling. To address these limitations, we propose aSpatial-Temporal simulAtion for drivinG (Stag-1) model to reconstructreal-world scenes and design a controllable generative network to achieve 4Dsimulation. Stag-1 constructs continuous 4D point cloud scenes usingsurround-view data from autonomous vehicles. It decouples spatial-temporalrelationships and produces coherent keyframe videos. Additionally, Stag-1leverages video generation models to obtain photo-realistic and controllable 4Ddriving simulation videos from any perspective. To expand the range of viewgeneration, we train vehicle motion videos based on decomposed camera poses,enhancing modeling capabilities for distant scenes. Furthermore, we reconstructvehicle camera trajectories to integrate 3D points across consecutive views,enabling comprehensive scene understanding along the temporal dimension.Following extensive multi-level scene training, Stag-1 can simulate from anydesired viewpoint and achieve a deep understanding of scene evolution understatic spatial-temporal conditions. Compared to existing methods, our approachshows promising performance in multi-view scene consistency, backgroundcoherence, and accuracy, and contributes to the ongoing advancements inrealistic autonomous driving simulation. Code: https://github.com/wzzheng/Stag.</description><author>Lening Wang, Wenzhao Zheng, Dalong Du, Yunpeng Zhang, Yilong Ren, Han Jiang, Zhiyong Cui, Haiyang Yu, Jie Zhou, Jiwen Lu, Shanghang Zhang</author><pubDate>Fri, 06 Dec 2024 18:59:56 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.05280v1</guid></item><item><title>Perturb-and-Revise: Flexible 3D Editing with Generative Trajectories</title><link>http://arxiv.org/abs/2412.05279v1</link><description>The fields of 3D reconstruction and text-based 3D editing have advancedsignificantly with the evolution of text-based diffusion models. While existing3D editing methods excel at modifying color, texture, and style, they strugglewith extensive geometric or appearance changes, thus limiting theirapplications. We propose Perturb-and-Revise, which makes possible a variety ofNeRF editing. First, we perturb the NeRF parameters with random initializationsto create a versatile initialization. We automatically determine theperturbation magnitude through analysis of the local loss landscape. Then, werevise the edited NeRF via generative trajectories. Combined with thegenerative process, we impose identity-preserving gradients to refine theedited NeRF. Extensive experiments demonstrate that Perturb-and-Revisefacilitates flexible, effective, and consistent editing of color, appearance,and geometry in 3D. For 360{\deg} results, please visit our project page:https://susunghong.github.io/Perturb-and-Revise.</description><author>Susung Hong, Johanna Karras, Ricardo Martin-Brualla, Ira Kemelmacher-Shlizerman</author><pubDate>Fri, 06 Dec 2024 18:59:53 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.05279v1</guid></item><item><title>Birth and Death of a Rose</title><link>http://arxiv.org/abs/2412.05278v1</link><description>We study the problem of generating temporal object intrinsics -- temporallyevolving sequences of object geometry, reflectance, and texture, such as ablooming rose -- from pre-trained 2D foundation models. Unlike conventional 3Dmodeling and animation techniques that require extensive manual effort andexpertise, we introduce a method that generates such assets with signalsdistilled from pre-trained 2D diffusion models. To ensure the temporalconsistency of object intrinsics, we propose Neural Templates fortemporal-state-guided distillation, derived automatically from image featuresfrom self-supervised learning. Our method can generate high-quality temporalobject intrinsics for several natural phenomena and enable the sampling andcontrollable rendering of these dynamic objects from any viewpoint, under anyenvironmental lighting conditions, at any time of their lifespan. Projectwebsite: https://chen-geng.com/rose4d</description><author>Chen Geng, Yunzhi Zhang, Shangzhe Wu, Jiajun Wu</author><pubDate>Fri, 06 Dec 2024 18:59:52 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.05278v1</guid></item><item><title>Text to Blind Motion</title><link>http://arxiv.org/abs/2412.05277v1</link><description>People who are blind perceive the world differently than those who aresighted, which can result in distinct motion characteristics. For instance,when crossing at an intersection, blind individuals may have different patternsof movement, such as veering more from a straight path or using touch-basedexploration around curbs and obstacles. These behaviors may appear lesspredictable to motion models embedded in technologies such as autonomousvehicles. Yet, the ability of 3D motion models to capture such behavior has notbeen previously studied, as existing datasets for 3D human motion currentlylack diversity and are biased toward people who are sighted. In this work, weintroduce BlindWays, the first multimodal motion benchmark for pedestrians whoare blind. We collect 3D motion data using wearable sensors with 11 blindparticipants navigating eight different routes in a real-world urban setting.Additionally, we provide rich textual descriptions that capture the distinctivemovement characteristics of blind pedestrians and their interactions with boththe navigation aid (e.g., a white cane or a guide dog) and the environment. Webenchmark state-of-the-art 3D human prediction models, finding poor performancewith off-the-shelf and pre-training-based methods for our novel task. Tocontribute toward safer and more reliable systems that can seamlessly reasonover diverse human movements in their environments, our text-and-motionbenchmark is available at https://blindways.github.io.</description><author>Hee Jae Kim, Kathakoli Sengupta, Masaki Kuribayashi, Hernisa Kacorri, Eshed Ohn-Bar</author><pubDate>Fri, 06 Dec 2024 18:59:51 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.05277v1</guid></item><item><title>Sparse autoencoders reveal selective remapping of visual concepts during adaptation</title><link>http://arxiv.org/abs/2412.05276v1</link><description>Adapting foundation models for specific purposes has become a standardapproach to build machine learning systems for downstream applications. Yet, itis an open question which mechanisms take place during adaptation. Here wedevelop a new Sparse Autoencoder (SAE) for the CLIP vision transformer, namedPatchSAE, to extract interpretable concepts at granular levels (e.g. shape,color, or semantics of an object) and their patch-wise spatial attributions. Weexplore how these concepts influence the model output in downstream imageclassification tasks and investigate how recent state-of-the-art prompt-basedadaptation techniques change the association of model inputs to these concepts.While activations of concepts slightly change between adapted and non-adaptedmodels, we find that the majority of gains on common adaptation tasks can beexplained with the existing concepts already present in the non-adaptedfoundation model. This work provides a concrete framework to train and use SAEsfor Vision Transformers and provides insights into explaining adaptationmechanisms.</description><author>Hyesu Lim, Jinho Choi, Jaegul Choo, Steffen Schneider</author><pubDate>Fri, 06 Dec 2024 18:59:51 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.05276v1</guid></item><item><title>MotionFlow: Attention-Driven Motion Transfer in Video Diffusion Models</title><link>http://arxiv.org/abs/2412.05275v1</link><description>Text-to-video models have demonstrated impressive capabilities in producingdiverse and captivating video content, showcasing a notable advancement ingenerative AI. However, these models generally lack fine-grained control overmotion patterns, limiting their practical applicability. We introduceMotionFlow, a novel framework designed for motion transfer in video diffusionmodels. Our method utilizes cross-attention maps to accurately capture andmanipulate spatial and temporal dynamics, enabling seamless motion transfersacross various contexts. Our approach does not require training and works ontest-time by leveraging the inherent capabilities of pre-trained videodiffusion models. In contrast to traditional approaches, which struggle withcomprehensive scene changes while maintaining consistent motion, MotionFlowsuccessfully handles such complex transformations through its attention-basedmechanism. Our qualitative and quantitative experiments demonstrate thatMotionFlow significantly outperforms existing models in both fidelity andversatility even during drastic scene alterations.</description><author>Tuna Han Salih Meral, Hidir Yesiltepe, Connor Dunlop, Pinar Yanardag</author><pubDate>Fri, 06 Dec 2024 18:59:12 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.05275v1</guid></item><item><title>SimC3D: A Simple Contrastive 3D Pretraining Framework Using RGB Images</title><link>http://arxiv.org/abs/2412.05274v1</link><description>The 3D contrastive learning paradigm has demonstrated remarkable performancein downstream tasks through pretraining on point cloud data. Recent advancesinvolve additional 2D image priors associated with 3D point clouds for furtherimprovement. Nonetheless, these existing frameworks are constrained by therestricted range of available point cloud datasets, primarily due to the highcosts of obtaining point cloud data. To this end, we propose SimC3D, a simplebut effective 3D contrastive learning framework, for the first time,pretraining 3D backbones from pure RGB image data. SimC3D performs contrastive3D pretraining with three appealing properties. (1) Pure image data: SimC3Dsimplifies the dependency of costly 3D point clouds and pretrains 3D backbonesusing solely RBG images. By employing depth estimation and suitable dataprocessing, the monocular synthesized point cloud shows great potential for 3Dpretraining. (2) Simple framework: Traditional multi-modal frameworksfacilitate 3D pretraining with 2D priors by utilizing an additional 2Dbackbone, thereby increasing computational expense. In this paper, weempirically demonstrate that the primary benefit of the 2D modality stems fromthe incorporation of locality information. Inspired by this insightfulobservation, SimC3D directly employs 2D positional embeddings as a strongercontrastive objective, eliminating the necessity for 2D backbones and leadingto considerable performance improvements. (3) Strong performance: SimC3Doutperforms previous approaches that leverage ground-truth point cloud data forpretraining in various downstream tasks. Furthermore, the performance of SimC3Dcan be further enhanced by combining multiple image datasets, showcasing itssignificant potential for scalability. The code will be available athttps://github.com/Dongjiahua/SimC3D.</description><author>Jiahua Dong, Tong Wu, Rui Qian, Jiaqi Wang</author><pubDate>Fri, 06 Dec 2024 18:59:04 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.05274v1</guid></item><item><title>Expanding Performance Boundaries of Open-Source Multimodal Models with Model, Data, and Test-Time Scaling</title><link>http://arxiv.org/abs/2412.05271v1</link><description>We introduce InternVL 2.5, an advanced multimodal large language model (MLLM)series that builds upon InternVL 2.0, maintaining its core model architecturewhile introducing significant enhancements in training and testing strategiesas well as data quality. In this work, we delve into the relationship betweenmodel scaling and performance, systematically exploring the performance trendsin vision encoders, language models, dataset sizes, and test-timeconfigurations. Through extensive evaluations on a wide range of benchmarks,including multi-discipline reasoning, document understanding, multi-image /video understanding, real-world comprehension, multimodal hallucinationdetection, visual grounding, multilingual capabilities, and pure languageprocessing, InternVL 2.5 exhibits competitive performance, rivaling leadingcommercial models such as GPT-4o and Claude-3.5-Sonnet. Notably, our model isthe first open-source MLLMs to surpass 70% on the MMMU benchmark, achieving a3.7-point improvement through Chain-of-Thought (CoT) reasoning and showcasingstrong potential for test-time scaling. We hope this model contributes to theopen-source community by setting new standards for developing and applyingmultimodal AI systems. HuggingFace demo seehttps://huggingface.co/spaces/OpenGVLab/InternVL</description><author>Zhe Chen, Weiyun Wang, Yue Cao, Yangzhou Liu, Zhangwei Gao, Erfei Cui, Jinguo Zhu, Shenglong Ye, Hao Tian, Zhaoyang Liu, Lixin Gu, Xuehui Wang, Qingyun Li, Yimin Ren, Zixuan Chen, Jiapeng Luo, Jiahao Wang, Tan Jiang, Bo Wang, Conghui He, Botian Shi, Xingcheng Zhang, Han Lv, Yi Wang, Wenqi Shao, Pei Chu, Zhongying Tu, Tong He, Zhiyong Wu, Huipeng Deng, Jiaye Ge, Kai Chen, Min Dou, Lewei Lu, Xizhou Zhu, Tong Lu, Dahua Lin, Yu Qiao, Jifeng Dai, Wenhai Wang</author><pubDate>Fri, 06 Dec 2024 18:57:08 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.05271v1</guid></item><item><title>Conformal Prediction for Class-wise Coverage via Augmented Label Rank Calibration</title><link>http://arxiv.org/abs/2406.06818v5</link><description>Conformal prediction (CP) is an emerging uncertainty quantification frameworkthat allows us to construct a prediction set to cover the true label with apre-specified marginal or conditional probability. Although the valid coverageguarantee has been extensively studied for classification problems, CP oftenproduces large prediction sets which may not be practically useful. This issueis exacerbated for the setting of class-conditional coverage on imbalancedclassification tasks with many and/or imbalanced classes. This paper proposesthe Rank Calibrated Class-conditional CP (RC3P) algorithm to reduce theprediction set sizes to achieve class-conditional coverage, where the validcoverage holds for each class. In contrast to the standard class-conditional CP(CCP) method that uniformly thresholds the class-wise conformity score for eachclass, the augmented label rank calibration step allows RC3P to selectivelyiterate this class-wise thresholding subroutine only for a subset of classeswhose class-wise top-k error is small. We prove that agnostic to the classifierand data distribution, RC3P achieves class-wise coverage. We also show thatRC3P reduces the size of prediction sets compared to the CCP method.Comprehensive experiments on multiple real-world datasets demonstrate that RC3Pachieves class-wise coverage and 26.25% reduction in prediction set sizes onaverage.</description><author>Yuanjie Shi, Subhankar Ghosh, Taha Belkhouja, Janardhan Rao Doppa, Yan Yan</author><pubDate>Fri, 06 Dec 2024 18:56:05 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.06818v5</guid></item><item><title>APOLLO: SGD-like Memory, AdamW-level Performance</title><link>http://arxiv.org/abs/2412.05270v1</link><description>Large language models (LLMs) are notoriously memory-intensive duringtraining, particularly with the popular AdamW optimizer. This memory burdennecessitates using more or higher-end GPUs or reducing batch sizes, limitingtraining scalability and throughput. To address this, various memory-efficientoptimizers have been proposed to reduce optimizer memory usage. However, theyface critical challenges: (i) reliance on costly SVD operations; (ii)significant performance trade-offs compared to AdamW; and (iii) stillsubstantial optimizer memory overhead to maintain competitive performance. In this work, we identify that AdamW's learning rate adaptation rule can beeffectively coarsened as a structured learning rate update. Based on thisinsight, we propose Approximated Gradient Scaling for Memory-Efficient LLMOptimization (APOLLO), which approximates learning rate scaling using anauxiliary low-rank optimizer state based on pure random projection. Thisstructured learning rate update rule makes APOLLO highly tolerant to furthermemory reductions while delivering comparable pre-training performance. Evenits rank-1 variant, APOLLO-Mini, achieves superior pre-training performancecompared to AdamW with SGD-level memory costs. Extensive experiments demonstrate that the APOLLO series performs on-par withor better than AdamW, while achieving greater memory savings by nearlyeliminating the optimization states of AdamW. These savings provide significantsystem-level benefits: (1) Enhanced Throughput: 3x throughput on an 8xA100-80GBsetup compared to AdamW by supporting 4x larger batch sizes. (2) Improved ModelScalability: Pre-training LLaMA-13B with naive DDP on A100-80GB GPUs withoutsystem-level optimizations. (3) Low-End GPU Friendly Pre-training: Pre-trainingLLaMA-7B on a single GPU using less than 12 GB of memory with weightquantization.</description><author>Hanqing Zhu, Zhenyu Zhang, Wenyan Cong, Xi Liu, Sem Park, Vikas Chandra, Bo Long, David Z. Pan, Zhangyang Wang, Jinwon Lee</author><pubDate>Fri, 06 Dec 2024 18:55:34 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.05270v1</guid></item><item><title>Chimera: Accurate retrosynthesis prediction by ensembling models with diverse inductive biases</title><link>http://arxiv.org/abs/2412.05269v1</link><description>Planning and conducting chemical syntheses remains a major bottleneck in thediscovery of functional small molecules, and prevents fully leveraginggenerative AI for molecular inverse design. While early work has shown thatML-based retrosynthesis models can predict reasonable routes, their lowaccuracy for less frequent, yet important reactions has been pointed out. Asmulti-step search algorithms are limited to reactions suggested by theunderlying model, the applicability of those tools is inherently constrained bythe accuracy of retrosynthesis prediction. Inspired by how chemists usedifferent strategies to ideate reactions, we propose Chimera: a framework forbuilding highly accurate reaction models that combine predictions from diversesources with complementary inductive biases using a learning-based ensemblingstrategy. We instantiate the framework with two newly developed models, whichalready by themselves achieve state of the art in their categories. Throughexperiments across several orders of magnitude in data scale and time-splits,we show Chimera outperforms all major models by a large margin, owing both tothe good individual performance of its constituents, but also to thescalability of our ensembling strategy. Moreover, we find that PhD-levelorganic chemists prefer predictions from Chimera over baselines in terms ofquality. Finally, we transfer the largest-scale checkpoint to an internaldataset from a major pharmaceutical company, showing robust generalizationunder distribution shift. With the new dimension that our framework unlocks, weanticipate further acceleration in the development of even more accuratemodels.</description><author>Krzysztof Maziarz, Guoqing Liu, Hubert Misztela, Aleksei Kornev, Piotr Gaiński, Holger Hoefling, Mike Fortunato, Rishi Gupta, Marwin Segler</author><pubDate>Fri, 06 Dec 2024 18:55:19 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.05269v1</guid></item><item><title>DenseMatcher: Learning 3D Semantic Correspondence for Category-Level Manipulation from a Single Demo</title><link>http://arxiv.org/abs/2412.05268v1</link><description>Dense 3D correspondence can enhance robotic manipulation by enabling thegeneralization of spatial, functional, and dynamic information from one objectto an unseen counterpart. Compared to shape correspondence, semanticcorrespondence is more effective in generalizing across different objectcategories. To this end, we present DenseMatcher, a method capable of computing3D correspondences between in-the-wild objects that share similar structures.DenseMatcher first computes vertex features by projecting multiview 2D featuresonto meshes and refining them with a 3D network, and subsequently finds densecorrespondences with the obtained features using functional map. In addition,we craft the first 3D matching dataset that contains colored object meshesacross diverse categories. In our experiments, we show that DenseMatchersignificantly outperforms prior 3D matching baselines by 43.5%. We demonstratethe downstream effectiveness of DenseMatcher in (i) robotic manipulation, whereit achieves cross-instance and cross-category generalization on long-horizoncomplex manipulation tasks from observing only one demo; (ii) zero-shot colormapping between digital assets, where appearance can be transferred betweendifferent objects with relatable geometry.</description><author>Junzhe Zhu, Yuanchen Ju, Junyi Zhang, Muhan Wang, Zhecheng Yuan, Kaizhe Hu, Huazhe Xu</author><pubDate>Fri, 06 Dec 2024 18:55:09 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.05268v1</guid></item><item><title>Reinforcement Learning: An Overview</title><link>http://arxiv.org/abs/2412.05265v1</link><description>This manuscript gives a big-picture, up-to-date overview of the field of(deep) reinforcement learning and sequential decision making, coveringvalue-based RL, policy-gradient methods, model-based methods, and various othertopics (including a very brief discussion of RL+LLMs).</description><author>Kevin Murphy</author><pubDate>Fri, 06 Dec 2024 18:53:49 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.05265v1</guid></item><item><title>Entity-based Reinforcement Learning for Autonomous Cyber Defence</title><link>http://arxiv.org/abs/2410.17647v2</link><description>A significant challenge for autonomous cyber defence is ensuring a defensiveagent's ability to generalise across diverse network topologies andconfigurations. This capability is necessary for agents to remain effectivewhen deployed in dynamically changing environments, such as an enterprisenetwork where devices may frequently join and leave. Standard approaches todeep reinforcement learning, where policies are parameterised using afixed-input multi-layer perceptron (MLP) expect fixed-size observation andaction spaces. In autonomous cyber defence, this makes it hard to developagents that generalise to environments with network topologies different fromthose trained on, as the number of nodes affects the natural size of theobservation and action spaces. To overcome this limitation, we reframe theproblem of autonomous network defence using entity-based reinforcementlearning, where the observation and action space of an agent are decomposedinto a collection of discrete entities. This framework enables the use ofpolicy parameterisations specialised in compositional generalisation. We traina Transformer-based policy on the Yawning Titan cyber-security simulationenvironment and test its generalisation capabilities across various networktopologies. We demonstrate that this approach significantly outperforms anMLP-based policy when training across fixed-size networks of varyingtopologies, and matches performance when training on a single network. We alsodemonstrate the potential for zero-shot generalisation to networks of adifferent size to those seen in training. These findings highlight thepotential for entity-based reinforcement learning to advance the field ofautonomous cyber defence by providing more generalisable policies capable ofhandling variations in real-world network environments.</description><author>Isaac Symes Thompson, Alberto Caron, Chris Hicks, Vasilios Mavroudis</author><pubDate>Fri, 06 Dec 2024 18:52:25 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.17647v2</guid></item><item><title>Mind the Time: Temporally-Controlled Multi-Event Video Generation</title><link>http://arxiv.org/abs/2412.05263v1</link><description>Real-world videos consist of sequences of events. Generating such sequenceswith precise temporal control is infeasible with existing video generators thatrely on a single paragraph of text as input. When tasked with generatingmultiple events described using a single prompt, such methods often ignore someof the events or fail to arrange them in the correct order. To address thislimitation, we present MinT, a multi-event video generator with temporalcontrol. Our key insight is to bind each event to a specific period in thegenerated video, which allows the model to focus on one event at a time. Toenable time-aware interactions between event captions and video tokens, wedesign a time-based positional encoding method, dubbed ReRoPE. This encodinghelps to guide the cross-attention operation. By fine-tuning a pre-trainedvideo diffusion transformer on temporally grounded data, our approach producescoherent videos with smoothly connected events. For the first time in theliterature, our model offers control over the timing of events in generatedvideos. Extensive experiments demonstrate that MinT outperforms existingopen-source models by a large margin.</description><author>Ziyi Wu, Aliaksandr Siarohin, Willi Menapace, Ivan Skorokhodov, Yuwei Fang, Varnith Chordia, Igor Gilitschenski, Sergey Tulyakov</author><pubDate>Fri, 06 Dec 2024 18:52:20 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.05263v1</guid></item><item><title>Fast Tree-Field Integrators: From Low Displacement Rank to Topological Transformers</title><link>http://arxiv.org/abs/2406.15881v2</link><description>We present a new class of fast polylog-linear algorithms based on the theoryof structured matrices (in particular low displacement rank) for integratingtensor fields defined on weighted trees. Several applications of the resultingfast tree-field integrators (FTFIs) are presented, including (a) approximationof graph metrics with tree metrics, (b) graph classification, (c) modeling onmeshes, and finally (d) Topological Transformers (TTs) (Choromanski et al.,2022) for images. For Topological Transformers, we propose new relativeposition encoding (RPE) masking mechanisms with as few as three extra learnableparameters per Transformer layer, leading to 1.0-1.5%+ accuracy gains.Importantly, most of FTFIs are exact methods, thus numerically equivalent totheir brute-force counterparts. When applied to graphs with thousands of nodes,those exact algorithms provide 5.7-13x speedups. We also provide an extensivetheoretical analysis of our methods.</description><author>Krzysztof Choromanski, Arijit Sehanobish, Somnath Basu Roy Chowdhury, Han Lin, Avinava Dubey, Tamas Sarlos, Snigdha Chaturvedi</author><pubDate>Fri, 06 Dec 2024 18:41:56 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.15881v2</guid></item><item><title>Extrapolated Urban View Synthesis Benchmark</title><link>http://arxiv.org/abs/2412.05256v1</link><description>Photorealistic simulators are essential for the training and evaluation ofvision-centric autonomous vehicles (AVs). At their core is Novel View Synthesis(NVS), a crucial capability that generates diverse unseen viewpoints toaccommodate the broad and continuous pose distribution of AVs. Recent advancesin radiance fields, such as 3D Gaussian Splatting, achieve photorealisticrendering at real-time speeds and have been widely used in modeling large-scaledriving scenes. However, their performance is commonly evaluated using aninterpolated setup with highly correlated training and test views. In contrast,extrapolation, where test views largely deviate from training views, remainsunderexplored, limiting progress in generalizable simulation technology. Toaddress this gap, we leverage publicly available AV datasets with multipletraversals, multiple vehicles, and multiple cameras to build the firstExtrapolated Urban View Synthesis (EUVS) benchmark. Meanwhile, we conductquantitative and qualitative evaluations of state-of-the-art Gaussian Splattingmethods across different difficulty levels. Our results show that GaussianSplatting is prone to overfitting to training views. Besides, incorporatingdiffusion priors and improving geometry cannot fundamentally improve NVS underlarge view changes, highlighting the need for more robust approaches andlarge-scale training. We have released our data to help advance self-drivingand urban robotics simulation technology.</description><author>Xiangyu Han, Zhen Jia, Boyi Li, Yan Wang, Boris Ivanovic, Yurong You, Lingjie Liu, Yue Wang, Marco Pavone, Chen Feng, Yiming Li</author><pubDate>Fri, 06 Dec 2024 18:41:39 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.05256v1</guid></item><item><title>TeamCraft: A Benchmark for Multi-Modal Multi-Agent Systems in Minecraft</title><link>http://arxiv.org/abs/2412.05255v1</link><description>Collaboration is a cornerstone of society. In the real world, human teammatesmake use of multi-sensory data to tackle challenging tasks in ever-changingenvironments. It is essential for embodied agents collaborating invisually-rich environments replete with dynamic interactions to understandmulti-modal observations and task specifications. To evaluate the performanceof generalizable multi-modal collaborative agents, we present TeamCraft, amulti-modal multi-agent benchmark built on top of the open-world video gameMinecraft. The benchmark features 55,000 task variants specified by multi-modalprompts, procedurally-generated expert demonstrations for imitation learning,and carefully designed protocols to evaluate model generalization capabilities.We also perform extensive analyses to better understand the limitations andstrengths of existing approaches. Our results indicate that existing modelscontinue to face significant challenges in generalizing to novel goals, scenes,and unseen numbers of agents. These findings underscore the need for furtherresearch in this area. The TeamCraft platform and dataset are publiclyavailable at https://github.com/teamcraft-bench/teamcraft.</description><author>Qian Long, Zhi Li, Ran Gong, Ying Nian Wu, Demetri Terzopoulos, Xiaofeng Gao</author><pubDate>Fri, 06 Dec 2024 18:41:16 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.05255v1</guid></item><item><title>From classical techniques to convolution-based models: A review of object detection algorithms</title><link>http://arxiv.org/abs/2412.05252v1</link><description>Object detection is a fundamental task in computer vision and imageunderstanding, with the goal of identifying and localizing objects of interestwithin an image while assigning them corresponding class labels. Traditionalmethods, which relied on handcrafted features and shallow models, struggledwith complex visual data and showed limited performance. These methods combinedlow-level features with contextual information and lacked the ability tocapture high-level semantics. Deep learning, especially Convolutional NeuralNetworks (CNNs), addressed these limitations by automatically learning rich,hierarchical features directly from data. These features include both semanticand high-level representations essential for accurate object detection. Thispaper reviews object detection frameworks, starting with classical computervision methods. We categorize object detection approaches into two groups: (1)classical computer vision techniques and (2) CNN-based detectors. We comparemajor CNN models, discussing their strengths and limitations. In conclusion,this review highlights the significant advancements in object detection throughdeep learning and identifies key areas for further research to improveperformance.</description><author>Fnu Neha, Deepshikha Bhati, Deepak Kumar Shukla, Md Amiruzzaman</author><pubDate>Fri, 06 Dec 2024 18:32:54 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.05252v1</guid></item><item><title>Uncertainty Quantification for Transformer Models for Dark-Pattern Detection</title><link>http://arxiv.org/abs/2412.05251v1</link><description>The opaque nature of transformer-based models, particularly in applicationssusceptible to unethical practices such as dark-patterns in user interfaces,requires models that integrate uncertainty quantification to enhance trust inpredictions. This study focuses on dark-pattern detection, deceptive designchoices that manipulate user decisions, undermining autonomy and consent. Wepropose a differential fine-tuning approach implemented at the finalclassification head via uncertainty quantification with transformer-basedpre-trained models. Employing a dense neural network (DNN) head architecture asa baseline, we examine two methods capable of quantifying uncertainty:Spectral-normalized Neural Gaussian Processes (SNGPs) and Bayesian NeuralNetworks (BNNs). These methods are evaluated on a set of open-sourcefoundational models across multiple dimensions: model performance, variance incertainty of predictions and environmental impact during training and inferencephases. Results demonstrate that integrating uncertainty quantificationmaintains performance while providing insights into challenging instanceswithin the models. Moreover, the study reveals that the environmental impactdoes not uniformly increase with the incorporation of uncertaintyquantification techniques. The study's findings demonstrate that uncertaintyquantification enhances transparency and provides measurable confidence inpredictions, improving the explainability and clarity of black-box models. Thisfacilitates informed decision-making and mitigates the influence ofdark-patterns on user interfaces. These results highlight the importance ofincorporating uncertainty quantification techniques in developing machinelearning models, particularly in domains where interpretability andtrustworthiness are critical.</description><author>Javier Muñoz, Álvaro Huertas-García, Carlos Martí-González, Enrique De Miguel Ambite</author><pubDate>Fri, 06 Dec 2024 18:31:51 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.05251v1</guid></item><item><title>On the Generalization of Preference Learning with DPO</title><link>http://arxiv.org/abs/2408.03459v3</link><description>Large language models (LLMs) have demonstrated remarkable capabilities butoften struggle to align with human preferences, leading to harmful orundesirable outputs. Preference learning, which trains models to distinguishbetween preferred and non-preferred responses based on human feedback, hasbecome a crucial component for ensuring that LLMs align with human values.Despite the widespread adoption in real-world systems, a thorough theoreticalunderstanding of the generalization guarantees for these models remain lacking.This paper bridges that gap by introducing a new theoretical framework toanalyze the generalization guarantees of models trained with direct preferenceoptimization (DPO). While existing generalization theory often focuses onoverparameterized models achieving near-optimal loss or models independent ofthe training process, our framework rigorously assesses how well modelsgeneralize after a finite number of gradient steps, reflecting real-world LLMtraining practices. By analyzing the reward margin associated with each sampleand its trajectory throughout training, we can effectively bound thegeneralization error. We derive learning guarantees showing that, underspecific conditions, models trained with DPO can correctly discern preferredresponses on unseen data with high probability. These insights are empiricallyvalidated on contemporary LLMs, underscoring the practical relevance of ourtheoretical findings.</description><author>Shawn Im, Yixuan Li</author><pubDate>Fri, 06 Dec 2024 18:31:30 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.03459v3</guid></item><item><title>TFT-multi: simultaneous forecasting of vital sign trajectories in the ICU</title><link>http://arxiv.org/abs/2409.15586v3</link><description>Trajectory forecasting in healthcare data has been an important area ofresearch in precision care and clinical integration for computational methods.In recent years, generative AI models have demonstrated promising results incapturing short and long range dependencies in time series data. While thesemodels have also been applied in healthcare, most of them only predict onevalue at a time, which is unrealistic in a clinical setting where multiplemeasures are taken at once. In this work, we extend the framework temporalfusion transformer (TFT), a multi-horizon time series prediction tool, andpropose TFT-multi, an end-to-end framework that can predict multiple vitaltrajectories simultaneously. We apply TFT-multi to forecast 5 vital signsrecorded in the intensive care unit: blood pressure, pulse, SpO2, temperatureand respiratory rate. We hypothesize that by jointly predicting these measures,which are often correlated with one another, we can make more accuratepredictions, especially in variables with large missingness. We validate ourmodel on the public MIMIC dataset and an independent institutional dataset, anddemonstrate that this approach outperforms state-of-the-art univariateprediction tools including the original TFT and Prophet, as well as vectorregression modeling for multivariate prediction. Furthermore, we perform astudy case analysis by applying our pipeline to forecast blood pressure changesin response to actual and hypothetical pressor administration.</description><author>Rosemary Y. He, Jeffrey N. Chiang</author><pubDate>Fri, 06 Dec 2024 18:28:58 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2409.15586v3</guid></item><item><title>Enhancing FKG.in: automating Indian food composition analysis</title><link>http://arxiv.org/abs/2412.05248v1</link><description>This paper presents a novel approach to compute food composition data forIndian recipes using a knowledge graph for Indian food (FKG.in) and LLMs. Theprimary focus is to provide a broad overview of an automated food compositionanalysis workflow and describe its core functionalities: nutrition dataaggregation, food composition analysis, and LLM-augmented informationresolution. This workflow aims to complement FKG.in and iteratively supplementfood composition data from verified knowledge bases. Additionally, this paperhighlights the challenges of representing Indian food and accessing foodcomposition data digitally. It also reviews three key sources of foodcomposition data: the Indian Food Composition Tables, the Indian NutrientDatabank, and the Nutritionix API. Furthermore, it briefly outlines how userscan interact with the workflow to obtain diet-based health recommendations anddetailed food composition information for numerous recipes. We then explore thecomplex challenges of analyzing Indian recipe information across dimensionssuch as structure, multilingualism, and uncertainty as well as present ourongoing work on LLM-based solutions to address these issues. The methodsproposed in this workshop paper for AI-driven knowledge curation andinformation resolution are application-agnostic, generalizable, and replicablefor any domain.</description><author>Saransh Kumar Gupta, Lipika Dey, Partha Pratim Das, Geeta Trilok-Kumar, Ramesh Jain</author><pubDate>Fri, 06 Dec 2024 18:27:15 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.05248v1</guid></item><item><title>The Intelligible and Effective Graph Neural Additive Networks</title><link>http://arxiv.org/abs/2406.01317v3</link><description>Graph Neural Networks (GNNs) have emerged as the predominant approach forlearning over graph-structured data. However, most GNNs operate as black-boxmodels and require post-hoc explanations, which may not suffice in high-stakesscenarios where transparency is crucial. In this paper, we present a GNN thatis interpretable by design. Our model, Graph Neural Additive Network (GNAN), isa novel extension of the interpretable class of Generalized Additive Models,and can be visualized and fully understood by humans. GNAN is designed to befully interpretable, offering both global and local explanations at the featureand graph levels through direct visualization of the model. Thesevisualizations describe exactly how the model uses the relationships betweenthe target variable, the features, and the graph. We demonstrate theintelligibility of GNANs in a series of examples on different tasks anddatasets. In addition, we show that the accuracy of GNAN is on par withblack-box GNNs, making it suitable for critical applications where transparencyis essential, alongside high accuracy.</description><author>Maya Bechler-Speicher, Amir Globerson, Ran Gilad-Bachrach</author><pubDate>Fri, 06 Dec 2024 18:25:17 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.01317v3</guid></item><item><title>Differentiable Weightless Neural Networks</title><link>http://arxiv.org/abs/2410.11112v4</link><description>We introduce the Differentiable Weightless Neural Network (DWN), a modelbased on interconnected lookup tables. Training of DWNs is enabled by a novelExtended Finite Difference technique for approximate differentiation of binaryvalues. We propose Learnable Mapping, Learnable Reduction, and SpectralRegularization to further improve the accuracy and efficiency of these models.We evaluate DWNs in three edge computing contexts: (1) an FPGA-based hardwareaccelerator, where they demonstrate superior latency, throughput, energyefficiency, and model area compared to state-of-the-art solutions, (2) alow-power microcontroller, where they achieve preferable accuracy to XGBoostwhile subject to stringent memory constraints, and (3) ultra-low-cost chips,where they consistently outperform small models in both accuracy and projectedhardware area. DWNs also compare favorably against leading approaches fortabular datasets, with higher average rank. Overall, our work positions DWNs asa pioneering solution for edge-compatible high-throughput neural networks.</description><author>Alan T. L. Bacellar, Zachary Susskind, Mauricio Breternitz Jr., Eugene John, Lizy K. John, Priscila M. V. Lima, Felipe M. G. França</author><pubDate>Fri, 06 Dec 2024 18:23:05 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.11112v4</guid></item><item><title>Enhancing Foundation Models for Time Series Forecasting via Wavelet-based Tokenization</title><link>http://arxiv.org/abs/2412.05244v1</link><description>How to best develop foundational models for time series forecasting remainsan important open question. Tokenization is a crucial consideration in thiseffort: what is an effective discrete vocabulary for a real-valued sequentialinput? To address this question, we develop WaveToken, a wavelet-basedtokenizer that allows models to learn complex representations directly in thespace of time-localized frequencies. Our method first scales and decomposes theinput time series, then thresholds and quantizes the wavelet coefficients, andfinally pre-trains an autoregressive model to forecast coefficients for theforecast horizon. By decomposing coarse and fine structures in the inputs,wavelets provide an eloquent and compact language for time series forecastingthat simplifies learning. Empirical results on a comprehensive benchmark,including 42 datasets for both in-domain and zero-shot settings, show thatWaveToken: i) provides better accuracy than recently proposed foundation modelsfor forecasting while using a much smaller vocabulary (1024 tokens), andperforms on par or better than modern deep learning models trained specificallyon each dataset; and ii) exhibits superior generalization capabilities,achieving the best average rank across all datasets for three complementarymetrics. In addition, we show that our method can easily capture complextemporal patterns of practical relevance that are challenging for other recentpre-trained models, including trends, sparse spikes, and non-stationary timeseries with varying frequencies evolving over time.</description><author>Luca Masserano, Abdul Fatir Ansari, Boran Han, Xiyuan Zhang, Christos Faloutsos, Michael W. Mahoney, Andrew Gordon Wilson, Youngsuk Park, Syama Rangapuram, Danielle C. Maddix, Yuyang Wang</author><pubDate>Fri, 06 Dec 2024 18:22:59 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.05244v1</guid></item><item><title>CompCap: Improving Multimodal Large Language Models with Composite Captions</title><link>http://arxiv.org/abs/2412.05243v1</link><description>How well can Multimodal Large Language Models (MLLMs) understand compositeimages? Composite images (CIs) are synthetic visuals created by mergingmultiple visual elements, such as charts, posters, or screenshots, rather thanbeing captured directly by a camera. While CIs are prevalent in real-worldapplications, recent MLLM developments have primarily focused on interpretingnatural images (NIs). Our research reveals that current MLLMs face significantchallenges in accurately understanding CIs, often struggling to extractinformation or perform complex reasoning based on these images. We find thatexisting training data for CIs are mostly formatted for question-answer tasks(e.g., in datasets like ChartQA and ScienceQA), while high-qualityimage-caption datasets, critical for robust vision-language alignment, are onlyavailable for NIs. To bridge this gap, we introduce Composite Captions(CompCap), a flexible framework that leverages Large Language Models (LLMs) andautomation tools to synthesize CIs with accurate and detailed captions. UsingCompCap, we curate CompCap-118K, a dataset containing 118K image-caption pairsacross six CI types. We validate the effectiveness of CompCap-118K bysupervised fine-tuning MLLMs of three sizes: xGen-MM-inst.-4B andLLaVA-NeXT-Vicuna-7B/13B. Empirical results show that CompCap-118Ksignificantly enhances MLLMs' understanding of CIs, yielding average gains of1.7%, 2.0%, and 2.9% across eleven benchmarks, respectively.</description><author>Xiaohui Chen, Satya Narayan Shukla, Mahmoud Azab, Aashu Singh, Qifan Wang, David Yang, ShengYun Peng, Hanchao Yu, Shen Yan, Xuewen Zhang, Baosheng He</author><pubDate>Fri, 06 Dec 2024 18:22:47 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.05243v1</guid></item><item><title>A Practitioner's Guide to Continual Multimodal Pretraining</title><link>http://arxiv.org/abs/2408.14471v2</link><description>Multimodal foundation models serve numerous applications at the intersectionof vision and language. Still, despite being pretrained on extensive data, theybecome outdated over time. To keep models updated, research into continualpretraining mainly explores scenarios with either (1) infrequent,indiscriminate updates on large-scale new data, or (2) frequent, sample-levelupdates. However, practical model deployment often operates in the gap betweenthese two limit cases, as real-world applications often demand adaptation tospecific subdomains, tasks or concepts -- spread over the entire, varying lifecycle of a model. In this work, we complement current perspectives on continualpretraining through a research test bed as well as provide comprehensiveguidance for effective continual model updates in such scenarios. We firstintroduce FoMo-in-Flux, a continual multimodal pretraining benchmark withrealistic compute constraints and practical deployment requirements,constructed over 63 datasets with diverse visual and semantic coverage. UsingFoMo-in-Flux, we explore the complex landscape of practical continualpretraining through multiple perspectives: (1) A data-centric investigation ofdata mixtures and stream orderings that emulate real-world deploymentsituations, (2) a method-centric investigation ranging from simple fine-tuningand traditional continual learning strategies to parameter-efficient updatesand model merging, (3) meta learning rate schedules and mechanistic designchoices, and (4) the influence of model and compute scaling. Together, ourinsights provide a practitioner's guide to continual multimodal pretraining forreal-world deployment. Our benchmark and code is here:https://github.com/ExplainableML/fomo_in_flux.</description><author>Karsten Roth, Vishaal Udandarao, Sebastian Dziadzio, Ameya Prabhu, Mehdi Cherti, Oriol Vinyals, Olivier Hénaff, Samuel Albanie, Matthias Bethge, Zeynep Akata</author><pubDate>Fri, 06 Dec 2024 18:22:32 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.14471v2</guid></item><item><title>FairMedFM: Fairness Benchmarking for Medical Imaging Foundation Models</title><link>http://arxiv.org/abs/2407.00983v3</link><description>The advent of foundation models (FMs) in healthcare offers unprecedentedopportunities to enhance medical diagnostics through automated classificationand segmentation tasks. However, these models also raise significant concernsabout their fairness, especially when applied to diverse and underrepresentedpopulations in healthcare applications. Currently, there is a lack ofcomprehensive benchmarks, standardized pipelines, and easily adaptablelibraries to evaluate and understand the fairness performance of FMs in medicalimaging, leading to considerable challenges in formulating and implementingsolutions that ensure equitable outcomes across diverse patient populations. Tofill this gap, we introduce FairMedFM, a fairness benchmark for FM research inmedical imaging.FairMedFM integrates with 17 popular medical imaging datasets,encompassing different modalities, dimensionalities, and sensitive attributes.It explores 20 widely used FMs, with various usages such as zero-shot learning,linear probing, parameter-efficient fine-tuning, and prompting in variousdownstream tasks -- classification and segmentation. Our exhaustive analysisevaluates the fairness performance over different evaluation metrics frommultiple perspectives, revealing the existence of bias, varied utility-fairnesstrade-offs on different FMs, consistent disparities on the same datasetsregardless FMs, and limited effectiveness of existing unfairness mitigationmethods. Checkout FairMedFM's project page and open-sourced codebase, whichsupports extendible functionalities and applications as well as inclusive forstudies on FMs in medical imaging over the long term.</description><author>Ruinan Jin, Zikang Xu, Yuan Zhong, Qiongsong Yao, Qi Dou, S. Kevin Zhou, Xiaoxiao Li</author><pubDate>Fri, 06 Dec 2024 18:16:02 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.00983v3</guid></item><item><title>MAmmoTH-VL: Eliciting Multimodal Reasoning with Instruction Tuning at Scale</title><link>http://arxiv.org/abs/2412.05237v1</link><description>Open-source multimodal large language models (MLLMs) have shown significantpotential in a broad range of multimodal tasks. However, their reasoningcapabilities remain constrained by existing instruction-tuning datasets, whichwere predominately repurposed from academic datasets such as VQA, AI2D, andChartQA. These datasets target simplistic tasks, and only provide phrase-levelanswers without any intermediate rationales. To address these challenges, weintroduce a scalable and cost-effective method to construct a large-scalemultimodal instruction-tuning dataset with rich intermediate rationalesdesigned to elicit CoT reasoning. Using only open models, we create a datasetcontaining 12M instruction-response pairs to cover diverse, reasoning-intensivetasks with detailed and faithful rationales. Experiments demonstrate thattraining MLLMs on this dataset significantly improves reasoning capabilities,achieving state-of-the-art performance on benchmarks such as MathVerse (+8.1%),MMMU-Pro (+7%), and MuirBench (+13.3%). Additionally, the model demonstratesnotable improvements of up to 4% on non-reasoning-based benchmarks. Ablationstudies further highlight the importance of key components, such as rewritingand self-filtering, in the dataset construction process.</description><author>Jarvis Guo, Tuney Zheng, Yuelin Bai, Bo Li, Yubo Wang, King Zhu, Yizhi Li, Graham Neubig, Wenhu Chen, Xiang Yue</author><pubDate>Fri, 06 Dec 2024 18:14:24 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.05237v1</guid></item><item><title>Physics-informed reduced order model with conditional neural fields</title><link>http://arxiv.org/abs/2412.05233v1</link><description>This study presents the conditional neural fields for reduced-order modeling(CNF-ROM) framework to approximate solutions of parametrized partialdifferential equations (PDEs). The approach combines a parametric neural ODE(PNODE) for modeling latent dynamics over time with a decoder that reconstructsPDE solutions from the corresponding latent states. We introduce aphysics-informed learning objective for CNF-ROM, which includes two keycomponents. First, the framework uses coordinate-based neural networks tocalculate and minimize PDE residuals by computing spatial derivatives viaautomatic differentiation and applying the chain rule for time derivatives.Second, exact initial and boundary conditions (IC/BC) are imposed usingapproximate distance functions (ADFs) [Sukumar and Srivastava, CMAME, 2022].However, ADFs introduce a trade-off as their second- or higher-orderderivatives become unstable at the joining points of boundaries. To addressthis, we introduce an auxiliary network inspired by [Gladstone et al., NeurIPSML4PS workshop, 2022]. Our method is validated through parameter extrapolationand interpolation, temporal extrapolation, and comparisons with analyticalsolutions.</description><author>Minji Kim, Tianshu Wen, Kookjin Lee, Youngsoo Choi</author><pubDate>Fri, 06 Dec 2024 18:04:33 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.05233v1</guid></item><item><title>LIAR: Leveraging Alignment (Best-of-N) to Jailbreak LLMs in Seconds</title><link>http://arxiv.org/abs/2412.05232v1</link><description>Many existing jailbreak techniques rely on solving discrete combinatorialoptimization, while more recent approaches involve training LLMs to generatemultiple adversarial prompts. However, both approaches require significantcomputational resources to produce even a single adversarial prompt. Wehypothesize that the inefficiency of current approaches stems from aninadequate characterization of the jailbreak problem. To address this gap, weformulate the jailbreak problem in terms of alignment. By starting from anavailable safety-aligned model, we leverage an unsafe reward to guide the safemodel towards generating unsafe outputs using alignment techniques (e.g.,reinforcement learning from human feedback), effectively performingjailbreaking via alignment. We propose a novel jailbreak method called LIAR(LeveragIng Alignment to jailbReak). To demonstrate the simplicity andeffectiveness of our approach, we employ a best-of-N method to solve thealignment problem. LIAR offers significant advantages: lower computationalrequirements without additional training, fully black-box operation,competitive attack success rates, and more human-readable prompts. We providetheoretical insights into the possibility of jailbreaking a safety-alignedmodel, revealing inherent vulnerabilities in current alignment strategies forLLMs. We also provide sub-optimality guarantees for the proposed \algo.Experimentally, we achieve ASR comparable to the SoTA with a 10x improvement toperplexity and a Time-to-Attack measured in seconds rather than tens of hours.</description><author>James Beetham, Souradip Chakraborty, Mengdi Wang, Furong Huang, Amrit Singh Bedi, Mubarak Shah</author><pubDate>Fri, 06 Dec 2024 18:02:59 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.05232v1</guid></item><item><title>Aesthetic Post-Training Diffusion Models from Generic Preferences with Step-by-step Preference Optimization</title><link>http://arxiv.org/abs/2406.04314v2</link><description>Generating visually appealing images is fundamental to modern text-to-imagegeneration models. A potential solution to better aesthetics is directpreference optimization (DPO), which has been applied to diffusion models toimprove general image quality including prompt alignment and aesthetics.Popular DPO methods propagate preference labels from clean image pairs to allthe intermediate steps along the two generation trajectories. However,preference labels provided in existing datasets are blended with layout andaesthetic opinions, which would disagree with aesthetic preference. Even ifaesthetic labels were provided (at substantial cost), it would be hard for thetwo-trajectory methods to capture nuanced visual differences at differentsteps. To improve aesthetics economically, this paper uses existing genericpreference data and introduces step-by-step preference optimization (SPO) thatdiscards the propagation strategy and allows fine-grained image details to beassessed. Specifically, at each denoising step, we 1) sample a pool ofcandidates by denoising from a shared noise latent, 2) use a step-awarepreference model to find a suitable win-lose pair to supervise the diffusionmodel, and 3) randomly select one from the pool to initialize the nextdenoising step. This strategy ensures that the diffusion models to focus on thesubtle, fine-grained visual differences instead of layout aspect. We find thataesthetic can be significantly enhanced by accumulating these improved minordifferences. When fine-tuning Stable Diffusion v1.5 and SDXL, SPO yieldssignificant improvements in aesthetics compared with existing DPO methods whilenot sacrificing image-text alignment compared with vanilla models. Moreover,SPO converges much faster than DPO methods due to the step-by-step alignment offine-grained visual details. Code and models are available athttps://github.com/RockeyCoss/SPO.</description><author>Zhanhao Liang, Yuhui Yuan, Shuyang Gu, Bohan Chen, Tiankai Hang, Mingxi Cheng, Ji Li, Liang Zheng</author><pubDate>Fri, 06 Dec 2024 17:59:18 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.04314v2</guid></item><item><title>BEExformer: A Fast Inferencing Transformer Architecture via Binarization with Multiple Early Exits</title><link>http://arxiv.org/abs/2412.05225v1</link><description>Large Language Models (LLMs) based on transformers achieve cutting-edgeresults on a variety of applications. However, their enormous size andprocessing requirements make deployment on devices with constrained resourcesextremely difficult. Among various efficiency considerations, modelbinarization and Early Exit (EE) are common effective solutions. However,binarization may lead to performance loss due to reduced precision affectinggradient estimation and parameter updates. Besides, the present early-exitmechanisms are still in the nascent stages of research. To ameliorate theseissues, we propose Binarized Early Exit Transformer (BEExformer), thefirst-ever selective learning transformer architecture to combine early exitwith binarization for textual inference. It improves the binarization processthrough a differentiable second-order approximation to the impulse function.This enables gradient computation concerning both the sign as well as themagnitude of the weights. In contrast to absolute threshold-based EE, theproposed EE mechanism hinges on fractional reduction in entropy amongintermediate transformer blocks with soft-routing loss estimation. Whilebinarization results in 18.44 times reduction in model size, early exit reducesthe FLOPs during inference by 54.85% and even improves accuracy by 5.98%through resolving the "overthinking" problem inherent in deep networks.Moreover, the proposed BEExformer simplifies training by not requiringknowledge distillation from a full-precision LLM. Extensive evaluation on theGLUE dataset and comparison with the SOTA works showcase its pareto-optimalperformance-efficiency trade-off.</description><author>Wazib Ansar, Saptarsi Goswami, Amlan Chakrabarti</author><pubDate>Fri, 06 Dec 2024 17:58:14 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.05225v1</guid></item><item><title>100% Hallucination Elimination Using Acurai</title><link>http://arxiv.org/abs/2412.05223v1</link><description>The issue of hallucinations in large language models (LLMs) remains acritical barrier to the adoption of AI in enterprise and other high-stakesapplications. Despite advancements in retrieval-augmented generation (RAG)systems, current state-of-the-art methods fail to achieve more than 80%accuracy in generating faithful and factually correct outputs, even whenprovided with relevant and accurate context. In this work, we introduce Acurai,a novel systematic approach that achieves 100% hallucination-free responses inLLMs by reformatting queries and context data prior to input. Leveraging a deepunderstanding of LLM internal representations, the importance of noun-phrasedominance, and the role of discrete functional units (DFUs), Acurai ensuresalignment between input context and generated output. We validate this methodusing the RAGTruth corpus, demonstrating its ability to eliminate 100%hallucinations for both GPT-4 and GPT-3.5 Turbo. Acurai sets a new standard forachieving consistent, accurate, and faithful AI responses, marking asignificant step forward in the development of trustworthy AI systems.</description><author>Michael C. Wood, Adam A. Forbes</author><pubDate>Fri, 06 Dec 2024 17:54:54 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.05223v1</guid></item><item><title>Transformers Meet Relational Databases</title><link>http://arxiv.org/abs/2412.05218v1</link><description>Transformer models have continuously expanded into all machine learningdomains convertible to the underlying sequence-to-sequence representation,including tabular data. However, while ubiquitous, this representationrestricts their extension to the more general case of relational databases. Inthis paper, we introduce a modular neural message-passing scheme that closelyadheres to the formal relational model, enabling direct end-to-end learning oftabular Transformers from database storage systems. We address the challengesof appropriate learning data representation and loading, which are critical inthe database setting, and compare our approach against a number ofrepresentative models from various related fields across a significantly widerange of datasets. Our results demonstrate a superior performance of this newlyproposed class of neural architectures.</description><author>Jakub Peleška, Gustav Šír</author><pubDate>Fri, 06 Dec 2024 17:48:43 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.05218v1</guid></item><item><title>ColonNet: A Hybrid Of DenseNet121 And U-NET Model For Detection And Segmentation Of GI Bleeding</title><link>http://arxiv.org/abs/2412.05216v1</link><description>This study presents an integrated deep learning model for automatic detectionand classification of Gastrointestinal bleeding in the frames extracted fromWireless Capsule Endoscopy (WCE) videos. The dataset has been released as partof Auto-WCBleedGen Challenge Version V2 hosted by the MISAHUB team. Our modelattained the highest performance among 75 teams that took part in thiscompetition. It aims to efficiently utilizes CNN based model i.e. DenseNet andUNet to detect and segment bleeding and non-bleeding areas in the real-worldcomplex dataset. The model achieves an impressive overall accuracy of 80% whichwould surely help a skilled doctor to carry out further diagnostics.</description><author>Ayushman Singh, Sharad Prakash, Aniket Das, Nidhi Kushwaha</author><pubDate>Fri, 06 Dec 2024 17:48:06 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.05216v1</guid></item><item><title>AI's assigned gender affects human-AI cooperation</title><link>http://arxiv.org/abs/2412.05214v1</link><description>Cooperation between humans and machines is increasingly vital as artificialintelligence (AI) becomes more integrated into daily life. Research indicatesthat people are often less willing to cooperate with AI agents than withhumans, more readily exploiting AI for personal gain. While prior studies haveshown that giving AI agents human-like features influences people's cooperationwith them, the impact of AI's assigned gender remains underexplored. This studyinvestigates how human cooperation varies based on gender labels assigned to AIagents with which they interact. In the Prisoner's Dilemma game, 402participants interacted with partners labelled as AI (bot) or humans. Thepartners were also labelled male, female, non-binary, or gender-neutral.Results revealed that participants tended to exploit female-labelled anddistrust male-labelled AI agents more than their human counterparts, reflectinggender biases similar to those in human-human interactions. These findingshighlight the significance of gender biases in human-AI interactions that mustbe considered in future policy, design of interactive AI systems, andregulation of their use.</description><author>Sepideh Bazazi, Jurgis Karpus, Taha Yasseri</author><pubDate>Fri, 06 Dec 2024 17:46:35 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.05214v1</guid></item><item><title>Evaluating and Aligning CodeLLMs on Human Preference</title><link>http://arxiv.org/abs/2412.05210v1</link><description>Code large language models (codeLLMs) have made significant strides in codegeneration. Most previous code-related benchmarks, which consist of variousprogramming exercises along with the corresponding test cases, are used as acommon measure to evaluate the performance and capabilities of code LLMs.However, the current code LLMs focus on synthesizing the correct code snippet,ignoring the alignment with human preferences, where the query should besampled from the practical application scenarios and the model-generatedresponses should satisfy the human preference. To bridge the gap between themodel-generated response and human preference, we present a rigoroushuman-curated benchmark CodeArena to emulate the complexity and diversity ofreal-world coding tasks, where 397 high-quality samples spanning 40 categoriesand 44 programming languages, carefully curated from user queries. Further, wepropose a diverse synthetic instruction corpus SynCode-Instruct (nearly 20Btokens) by scaling instructions from the website to verify the effectiveness ofthe large-scale synthetic instruction fine-tuning, where Qwen2.5-SynCodertotally trained on synthetic instruction data can achieve top-tier performanceof open-source code LLMs. The results find performance differences betweenexecution-based benchmarks and CodeArena. Our systematic experiments ofCodeArena on 40+ LLMs reveal a notable performance gap between open SOTA codeLLMs (e.g. Qwen2.5-Coder) and proprietary LLMs (e.g., OpenAI o1), underscoringthe importance of the human preferencealignment.\footnote{\url{https://codearenaeval.github.io/ }}</description><author>Jian Yang, Jiaxi Yang, Ke Jin, Yibo Miao, Lei Zhang, Liqun Yang, Zeyu Cui, Yichang Zhang, Binyuan Hui, Junyang Lin</author><pubDate>Fri, 06 Dec 2024 17:40:38 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.05210v1</guid></item><item><title>Voronoi Candidates for Bayesian Optimization</title><link>http://arxiv.org/abs/2402.04922v2</link><description>Bayesian optimization (BO) offers an elegant approach for efficientlyoptimizing black-box functions. However, acquisition criteria demand their ownchallenging inner-optimization, which can induce significant overhead. Manypractical BO methods, particularly in high dimension, eschew a formal,continuous optimization of the acquisition function and instead searchdiscretely over a finite set of space-filling candidates. Here, we propose touse candidates which lie on the boundary of the Voronoi tessellation of thecurrent design points, so they are equidistant to two or more of them. Wediscuss strategies for efficient implementation by directly sampling theVoronoi boundary without explicitly generating the tessellation, thusaccommodating large designs in high dimension. On a battery of test problemsoptimized via Gaussian processes with expected improvement, our proposedapproach significantly improves the execution time of a multi-start continuoussearch without a loss in accuracy.</description><author>Nathan Wycoff, John W. Smith, Annie S. Booth, Robert B. Gramacy</author><pubDate>Fri, 06 Dec 2024 17:38:56 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.04922v2</guid></item><item><title>A Survey of Large Language Model-Based Generative AI for Text-to-SQL: Benchmarks, Applications, Use Cases, and Challenges</title><link>http://arxiv.org/abs/2412.05208v1</link><description>Text-to-SQL systems facilitate smooth interaction with databases bytranslating natural language queries into Structured Query Language (SQL),bridging the gap between non-technical users and complex database managementsystems. This survey provides a comprehensive overview of the evolution ofAI-driven text-to-SQL systems, highlighting their foundational components,advancements in large language model (LLM) architectures, and the critical roleof datasets such as Spider, WikiSQL, and CoSQL in driving progress. We examinethe applications of text-to-SQL in domains like healthcare, education, andfinance, emphasizing their transformative potential for improving dataaccessibility. Additionally, we analyze persistent challenges, including domaingeneralization, query optimization, support for multi-turn conversationalinteractions, and the limited availability of datasets tailored for NoSQLdatabases and dynamic real-world scenarios. To address these challenges, weoutline future research directions, such as extending text-to-SQL capabilitiesto support NoSQL databases, designing datasets for dynamic multi-turninteractions, and optimizing systems for real-world scalability and robustness.By surveying current advancements and identifying key gaps, this paper aims toguide the next generation of research and applications in LLM-based text-to-SQLsystems.</description><author>Aditi Singh, Akash Shetty, Abul Ehtesham, Saket Kumar, Tala Talaei Khoei</author><pubDate>Fri, 06 Dec 2024 17:36:28 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.05208v1</guid></item><item><title>ConQRet: Benchmarking Fine-Grained Evaluation of Retrieval Augmented Argumentation with LLM Judges</title><link>http://arxiv.org/abs/2412.05206v1</link><description>Computational argumentation, which involves generating answers or summariesfor controversial topics like abortion bans and vaccination, has becomeincreasingly important in today's polarized environment. Sophisticated LLMcapabilities offer the potential to provide nuanced, evidence-based answers tosuch questions through Retrieval-Augmented Argumentation (RAArg), leveragingreal-world evidence for high-quality, grounded arguments. However, evaluatingRAArg remains challenging, as human evaluation is costly and difficult forcomplex, lengthy answers on complicated topics. At the same time, re-usingexisting argumentation datasets is no longer sufficient, as they lack long,complex arguments and realistic evidence from potentially misleading sources,limiting holistic evaluation of retrieval effectiveness and argument quality.To address these gaps, we investigate automated evaluation methods usingmultiple fine-grained LLM judges, providing better and more interpretableassessments than traditional single-score metrics and even previously reportedhuman crowdsourcing. To validate the proposed techniques, we introduce ConQRet,a new benchmark featuring long and complex human-authored arguments on debatedtopics, grounded in real-world websites, allowing an exhaustive evaluationacross retrieval effectiveness, argument quality, and groundedness. We validateour LLM Judges on a prior dataset and the new ConQRet benchmark. Our proposedLLM Judges and the ConQRet benchmark can enable rapid progress in computationalargumentation and can be naturally extended to other complexretrieval-augmented generation tasks.</description><author>Kaustubh D. Dhole, Kai Shu, Eugene Agichtein</author><pubDate>Fri, 06 Dec 2024 17:35:52 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.05206v1</guid></item><item><title>Global Optimization with A Power-Transformed Objective and Gaussian Smoothing</title><link>http://arxiv.org/abs/2412.05204v1</link><description>We propose a novel method that solves global optimization problems in twosteps: (1) perform a (exponential) power-$N$ transformation to thenot-necessarily differentiable objective function $f$ to obtain $f_N$, and (2)optimize the Gaussian-smoothed $f_N$ with stochastic approximations. Under mildconditions on $f$, for any $\delta&gt;0$, we prove that with a sufficiently largepower $N_\delta$, this method converges to a solution in the$\delta$-neighborhood of $f$'s global maximum point. The convergence rate is$O(d^2\sigma^4\varepsilon^{-2})$, which is faster than both the standard andsingle-loop homotopy methods. Extensive experiments show that our methodrequires significantly fewer iterations than other compared algorithms toproduce a high-quality solution.</description><author>Chen Xu</author><pubDate>Fri, 06 Dec 2024 17:33:43 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.05204v1</guid></item><item><title>Archaeoscape: Bringing Aerial Laser Scanning Archaeology to the Deep Learning Era</title><link>http://arxiv.org/abs/2412.05203v1</link><description>Airborne Laser Scanning (ALS) technology has transformed modern archaeologyby unveiling hidden landscapes beneath dense vegetation. However, the lack ofexpert-annotated, open-access resources has hindered the analysis of ALS datausing advanced deep learning techniques. We address this limitation withArchaeoscape (available at https://archaeoscape.ai), a novel large-scalearchaeological ALS dataset spanning 888 km$^2$ in Cambodia with 31,141annotated archaeological features from the Angkorian period. Archaeoscape isover four times larger than comparable datasets, and the first ALS archaeologyresource with open-access data, annotations, and models. We benchmark several recent segmentation models to demonstrate the benefitsof modern vision techniques for this problem and highlight the uniquechallenges of discovering subtle human-made structures under dense junglecanopies. By making Archaeoscape available in open access, we hope to bridgethe gap between traditional archaeology and modern computer vision methods.</description><author>Yohann Perron, Vladyslav Sydorov, Adam P. Wijker, Damian Evans, Christophe Pottier, Loic Landrieu</author><pubDate>Fri, 06 Dec 2024 17:32:53 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.05203v1</guid></item><item><title>The Vizier Gaussian Process Bandit Algorithm</title><link>http://arxiv.org/abs/2408.11527v3</link><description>Google Vizier has performed millions of optimizations and acceleratednumerous research and production systems at Google, demonstrating the successof Bayesian optimization as a large-scale service. Over multiple years, itsalgorithm has been improved considerably, through the collective experiences ofnumerous research efforts and user feedback. In this technical report, wediscuss the implementation details and design choices of the current defaultalgorithm provided by Open Source Vizier. Our experiments on standardizedbenchmarks reveal its robustness and versatility against well-establishedindustry baselines on multiple practical modes.</description><author>Xingyou Song, Qiuyi Zhang, Chansoo Lee, Emily Fertig, Tzu-Kuo Huang, Lior Belenki, Greg Kochanski, Setareh Ariafar, Srinivas Vasudevan, Sagi Perel, Daniel Golovin</author><pubDate>Fri, 06 Dec 2024 17:31:39 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.11527v3</guid></item><item><title>Artificial intelligence and the internal processes of creativity</title><link>http://arxiv.org/abs/2412.04366v2</link><description>Artificial intelligence (AI) systems capable of generating creative outputsare reshaping our understanding of creativity. This shift presents anopportunity for creativity researchers to reevaluate the key components of thecreative process. In particular, the advanced capabilities of AI underscore theimportance of studying the internal processes of creativity. This paperexplores the neurobiological machinery that underlies these internal processesand describes the experiential component of creativity. It is concluded thatalthough the products of artificial and human creativity can be similar, theinternal processes are different. The paper also discusses how AI maynegatively affect the internal processes of human creativity, such as thedevelopment of skills, the integration of knowledge, and the diversity ofideas.</description><author>Jaan Aru</author><pubDate>Fri, 06 Dec 2024 17:31:22 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.04366v2</guid></item><item><title>Are Frontier Large Language Models Suitable for Q&amp;A in Science Centres?</title><link>http://arxiv.org/abs/2412.05200v1</link><description>This paper investigates the suitability of frontier Large Language Models(LLMs) for Q&amp;A interactions in science centres, with the aim of boostingvisitor engagement while maintaining factual accuracy. Using a dataset ofquestions collected from the National Space Centre in Leicester (UK), weevaluated responses generated by three leading models: OpenAI's GPT-4, Claude3.5 Sonnet, and Google Gemini 1.5. Each model was prompted for both standardand creative responses tailored to an 8-year-old audience, and these responseswere assessed by space science experts based on accuracy, engagement, clarity,novelty, and deviation from expected answers. The results revealed a trade-offbetween creativity and accuracy, with Claude outperforming GPT and Gemini inboth maintaining clarity and engaging young audiences, even when asked togenerate more creative responses. Nonetheless, experts observed that highernovelty was generally associated with reduced factual reliability across allmodels. This study highlights the potential of LLMs in educational settings,emphasizing the need for careful prompt engineering to balance engagement withscientific rigor.</description><author>Jacob Watson, Fabrício Góes, Marco Volpe, Talles Medeiros</author><pubDate>Fri, 06 Dec 2024 17:28:43 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.05200v1</guid></item><item><title>Understanding Multi-Granularity for Open-Vocabulary Part Segmentation</title><link>http://arxiv.org/abs/2406.11384v3</link><description>Open-vocabulary part segmentation (OVPS) is an emerging research area focusedon segmenting fine-grained entities using diverse and previously unseenvocabularies. Our study highlights the inherent complexities of partsegmentation due to intricate boundaries and diverse granularity, reflectingthe knowledge-based nature of part identification. To address these challenges,we propose PartCLIPSeg, a novel framework utilizing generalized parts andobject-level contexts to mitigate the lack of generalization in fine-grainedparts. PartCLIPSeg integrates competitive part relationships and attentioncontrol, alleviating ambiguous boundaries and underrepresented parts.Experimental results demonstrate that PartCLIPSeg outperforms existingstate-of-the-art OVPS methods, offering refined segmentation and an advancedunderstanding of part relationships within images. Through extensiveexperiments, our model demonstrated a significant improvement over thestate-of-the-art models on the Pascal-Part-116, ADE20K-Part-234, andPartImageNet datasets.</description><author>Jiho Choi, Seonho Lee, Seungho Lee, Minhyun Lee, Hyunjung Shim</author><pubDate>Fri, 06 Dec 2024 17:26:27 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.11384v3</guid></item><item><title>Is Your Paper Being Reviewed by an LLM? Investigating AI Text Detectability in Peer Review</title><link>http://arxiv.org/abs/2410.03019v2</link><description>Peer review is a critical process for ensuring the integrity of publishedscientific research. Confidence in this process is predicated on the assumptionthat experts in the relevant domain give careful consideration to the merits ofmanuscripts which are submitted for publication. With the recent rapidadvancements in the linguistic capabilities of large language models (LLMs), anew potential risk to the peer review process is that negligent reviewers willrely on LLMs to perform the often time consuming process of reviewing a paper.In this study, we investigate the ability of existing AI text detectionalgorithms to distinguish between peer reviews written by humans and differentstate-of-the-art LLMs. Our analysis shows that existing approaches fail toidentify many GPT-4o written reviews without also producing a high number offalse positive classifications. To address this deficiency, we propose a newdetection approach which surpasses existing methods in the identification ofGPT-4o written peer reviews at low levels of false positive classifications.Our work reveals the difficulty of accurately identifying AI-generated text atthe individual review level, highlighting the urgent need for new tools andmethods to detect this type of unethical application of generative AI.</description><author>Sungduk Yu, Man Luo, Avinash Madasu, Vasudev Lal, Phillip Howard</author><pubDate>Fri, 06 Dec 2024 17:23:53 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.03019v2</guid></item><item><title>Exponential Speedups by Rerooting Levin Tree Search</title><link>http://arxiv.org/abs/2412.05196v1</link><description>Levin Tree Search (LTS) (Orseau et al., 2018) is a search algorithm fordeterministic environments that uses a user-specified policy to guide thesearch. It comes with a formal guarantee on the number of search steps forfinding a solution node that depends on the quality of the policy. In thispaper, we introduce a new algorithm, called $\sqrt{\text{LTS}}$ (pronounceroot-LTS), which implicitly starts an LTS search rooted at every node of thesearch tree. Each LTS search is assigned a rerooting weight by a (user-definedor learnt) rerooter, and the search effort is shared between all LTS searchesproportionally to their weights. The rerooting mechanism implicitly decomposesthe search space into subtasks, leading to significant speedups. We prove thatthe number of search steps that $\sqrt{\text{LTS}}$ takes is competitive withthe best decomposition into subtasks, at the price of a factor that relates tothe uncertainty of the rerooter. If LTS takes time $T$, in the best case with$q$ rerooting points, $\sqrt{\text{LTS}}$ only takes time $O(q\sqrt[q]{T})$.Like the policy, the rerooter can be learnt from data, and we expect$\sqrt{\text{LTS}}$ to be applicable to a wide range of domains.</description><author>Laurent Orseau, Marcus Hutter, Levi H. S. Lelis</author><pubDate>Fri, 06 Dec 2024 17:20:50 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.05196v1</guid></item><item><title>PAC Privacy Preserving Diffusion Models</title><link>http://arxiv.org/abs/2312.01201v5</link><description>Data privacy protection is garnering increased attention among researchers.Diffusion models (DMs), particularly with strict differential privacy, canpotentially produce images with both high privacy and visual quality. However,challenges arise such as in ensuring robust protection in privatizing specificdata attributes, areas where current models often fall short. To address thesechallenges, we introduce the PAC Privacy Preserving Diffusion Model, a modelleverages diffusion principles and ensure Probably Approximately Correct (PAC)privacy. We enhance privacy protection by integrating a private classifierguidance into the Langevin Sampling Process. Additionally, recognizing the gapin measuring the privacy of models, we have developed a novel metric to gaugeprivacy levels. Our model, assessed with this new metric and supported byGaussian matrix computations for the PAC bound, has shown superior performancein privacy protection over existing leading private generative models accordingto benchmark tests.</description><author>Qipan Xu, Youlong Ding, Xinxi Zhang, Jie Gao, Hao Wang</author><pubDate>Fri, 06 Dec 2024 17:16:54 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.01201v5</guid></item><item><title>Beyond Pixels: Text Enhances Generalization in Real-World Image Restoration</title><link>http://arxiv.org/abs/2412.00878v2</link><description>Generalization has long been a central challenge in real-world imagerestoration. While recent diffusion-based restoration methods, which leveragegenerative priors from text-to-image models, have made progress in recoveringmore realistic details, they still encounter "generative capabilitydeactivation" when applied to out-of-distribution real-world data. To addressthis, we propose using text as an auxiliary invariant representation toreactivate the generative capabilities of these models. We begin by identifyingtwo key properties of text input: richness and relevance, and examine theirrespective influence on model performance. Building on these insights, weintroduce Res-Captioner, a module that generates enhanced textual descriptionstailored to image content and degradation levels, effectively mitigatingresponse failures. Additionally, we present RealIR, a new benchmark designed tocapture diverse real-world scenarios. Extensive experiments demonstrate thatRes-Captioner significantly enhances the generalization abilities ofdiffusion-based restoration models, while remaining fully plug-and-play.</description><author>Haoze Sun, Wenbo Li, Jiayue Liu, Kaiwen Zhou, Yongqiang Chen, Yong Guo, Yanwei Li, Renjing Pei, Long Peng, Yujiu Yang</author><pubDate>Fri, 06 Dec 2024 17:14:05 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.00878v2</guid></item><item><title>SurgBox: Agent-Driven Operating Room Sandbox with Surgery Copilot</title><link>http://arxiv.org/abs/2412.05187v1</link><description>Surgical interventions, particularly in neurology, represent complex andhigh-stakes scenarios that impose substantial cognitive burdens on surgicalteams. Although deliberate education and practice can enhance cognitivecapabilities, surgical training opportunities remain limited due to patientsafety concerns. To address these cognitive challenges in surgical training andoperation, we propose SurgBox, an agent-driven sandbox framework tosystematically enhance the cognitive capabilities of surgeons in immersivesurgical simulations. Specifically, our SurgBox leverages large language models(LLMs) with tailored Retrieval-Augmented Generation (RAG) to authenticallyreplicate various surgical roles, enabling realistic training environments fordeliberate practice. In particular, we devise Surgery Copilot, an AI-drivenassistant to actively coordinate the surgical information stream and supportclinical decision-making, thereby diminishing the cognitive workload ofsurgical teams during surgery. By incorporating a novel Long-Short Memorymechanism, our Surgery Copilot can effectively balance immediate proceduralassistance with comprehensive surgical knowledge. Extensive experiments usingreal neurosurgical procedure records validate our SurgBox framework in bothenhancing surgical cognitive capabilities and supporting clinicaldecision-making. By providing an integrated solution for training andoperational support to address cognitive challenges, our SurgBox frameworkadvances surgical education and practice, potentially transforming surgicaloutcomes and healthcare quality. The code is available athttps://github.com/franciszchen/SurgBox.</description><author>Jinlin Wu, Xusheng Liang, Xuexue Bai, Zhen Chen</author><pubDate>Fri, 06 Dec 2024 17:07:27 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.05187v1</guid></item><item><title>One-shot Federated Learning via Synthetic Distiller-Distillate Communication</title><link>http://arxiv.org/abs/2412.05186v1</link><description>One-shot Federated learning (FL) is a powerful technology facilitatingcollaborative training of machine learning models in a single round ofcommunication. While its superiority lies in communication efficiency andprivacy preservation compared to iterative FL, one-shot FL often compromisesmodel performance. Prior research has primarily focused on employing data-freeknowledge distillation to optimize data generators and ensemble models forbetter aggregating local knowledge into the server model. However, thesemethods typically struggle with data heterogeneity, where inconsistent localdata distributions can cause teachers to provide misleading knowledge.Additionally, they may encounter scalability issues with complex datasets dueto inherent two-step information loss: first, during local training (from datato model), and second, when transferring knowledge to the server model (frommodel to inversed data). In this paper, we propose FedSD2C, a novel andpractical one-shot FL framework designed to address these challenges. FedSD2Cintroduces a distiller to synthesize informative distillates directly fromlocal data to reduce information loss and proposes sharing syntheticdistillates instead of inconsistent local models to tackle data heterogeneity.Our empirical results demonstrate that FedSD2C consistently outperforms otherone-shot FL methods with more complex and real datasets, achieving up to 2.6the performance of the best baseline. Code: https://github.com/Carkham/FedSD2C</description><author>Junyuan Zhang, Songhua Liu, Xinchao Wang</author><pubDate>Fri, 06 Dec 2024 17:05:34 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.05186v1</guid></item><item><title>LinVT: Empower Your Image-level Large Language Model to Understand Videos</title><link>http://arxiv.org/abs/2412.05185v1</link><description>Large Language Models (LLMs) have been widely used in various tasks,motivating us to develop an LLM-based assistant for videos. Instead of trainingfrom scratch, we propose a module to transform arbitrary well-trainedimage-based LLMs into video-LLMs (after being trained on video data). To betteradapt image-LLMs for processing videos, we introduce two design principles:linear transformation to preserve the original visual-language alignment andrepresentative information condensation from redundant video content. Guided bythese principles, we propose a plug-and-play Linear Video Tokenizer(LinVT),which enables existing image-LLMs to understand videos. We benchmark LinVT withsix recent visual LLMs: Aquila, Blip-3, InternVL2, Mipha, Molmo and Qwen2-VL,showcasing the high compatibility of LinVT. LinVT-based LLMs achievestate-of-the-art performance across various video benchmarks, illustrating theeffectiveness of LinVT in multi-modal video understanding.</description><author>Lishuai Gao, Yujie Zhong, Yingsen Zeng, Haoxian Tan, Dengjie Li, Zheng Zhao</author><pubDate>Fri, 06 Dec 2024 17:04:42 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.05185v1</guid></item><item><title>QueEn: A Large Language Model for Quechua-English Translation</title><link>http://arxiv.org/abs/2412.05184v1</link><description>Recent studies show that large language models (LLMs) are powerful tools forworking with natural language, bringing advances in many areas of computationallinguistics. However, these models face challenges when applied to low-resourcelanguages due to limited training data and difficulty in understanding culturalnuances. In this paper, we propose QueEn, a novel approach for Quechua-Englishtranslation that combines Retrieval-Augmented Generation (RAG) withparameter-efficient fine-tuning techniques. Our method leverages externallinguistic resources through RAG and uses Low-Rank Adaptation (LoRA) forefficient model adaptation. Experimental results show that our approachsubstantially exceeds baseline models, with a BLEU score of 17.6 compared to1.5 for standard GPT models. The integration of RAG with fine-tuning allows oursystem to address the challenges of low-resource language translation whilemaintaining computational efficiency. This work contributes to the broader goalof preserving endangered languages through advanced language technologies.</description><author>Junhao Chen, Peng Shu, Yiwei Li, Huaqin Zhao, Hanqi Jiang, Yi Pan, Yifan Zhou, Zhengliang Liu, Lewis C Howe, Tianming Liu</author><pubDate>Fri, 06 Dec 2024 17:04:21 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.05184v1</guid></item><item><title>Privacy Drift: Evolving Privacy Concerns in Incremental Learning</title><link>http://arxiv.org/abs/2412.05183v1</link><description>In the evolving landscape of machine learning (ML), Federated Learning (FL)presents a paradigm shift towards decentralized model training while preservinguser data privacy. This paper introduces the concept of ``privacy drift", aninnovative framework that parallels the well-known phenomenon of concept drift.While concept drift addresses the variability in model accuracy over time dueto changes in the data, privacy drift encapsulates the variation in the leakageof private information as models undergo incremental training. By defining andexamining privacy drift, this study aims to unveil the nuanced relationshipbetween the evolution of model performance and the integrity of data privacy.Through rigorous experimentation, we investigate the dynamics of privacy driftin FL systems, focusing on how model updates and data distribution shiftsinfluence the susceptibility of models to privacy attacks, such as membershipinference attacks (MIA). Our results highlight a complex interplay betweenmodel accuracy and privacy safeguards, revealing that enhancements in modelperformance can lead to increased privacy risks. We provide empirical evidencefrom experiments on customized datasets derived from CIFAR-100 (CanadianInstitute for Advanced Research, 100 classes), showcasing the impact of dataand concept drift on privacy. This work lays the groundwork for future researchon privacy-aware machine learning, aiming to achieve a delicate balance betweenmodel accuracy and data privacy in decentralized environments.</description><author>Sayyed Farid Ahamed, Soumya Banerjee, Sandip Roy, Aayush Kapoor, Marc Vucovich, Kevin Choi, Abdul Rahman, Edward Bowen, Sachin Shetty</author><pubDate>Fri, 06 Dec 2024 17:04:09 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.05183v1</guid></item><item><title>Modular Duality in Deep Learning</title><link>http://arxiv.org/abs/2410.21265v2</link><description>An old idea in optimization theory says that since the gradient is a dualvector it may not be subtracted from the weights without first being mapped tothe primal space where the weights reside. We take this idea seriously in thispaper and construct such a duality map for general neural networks. Our map,which we call modular dualization, forms a unifying theoretical basis fortraining algorithms that are a) fast and b) scalable. Modular dualizationinvolves first assigning operator norms to layers based on the semantics ofeach layer, and then using these layerwise norms to recursively induce aduality map on the weight space of the full neural architecture. We conclude byderiving GPU-friendly algorithms for dualizing Embed, Linear and Conv2D layers-- the latter two methods are based on a rectangular Newton-Schulz iteration(Kovarik, 1970; Bj\"orck &amp; Bowie, 1971). A variant of our methods was used toset speed records for training NanoGPT. Overall, we hope that our theory ofmodular duality will yield a next generation of fast and scalable optimizersfor general neural architectures.</description><author>Jeremy Bernstein, Laker Newhouse</author><pubDate>Fri, 06 Dec 2024 17:02:28 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.21265v2</guid></item><item><title>HunyuanVideo: A Systematic Framework For Large Video Generative Models</title><link>http://arxiv.org/abs/2412.03603v2</link><description>Recent advancements in video generation have significantly impacted dailylife for both individuals and industries. However, the leading video generationmodels remain closed-source, resulting in a notable performance gap betweenindustry capabilities and those available to the public. In this report, weintroduce HunyuanVideo, an innovative open-source video foundation model thatdemonstrates performance in video generation comparable to, or even surpassing,that of leading closed-source models. HunyuanVideo encompasses a comprehensiveframework that integrates several key elements, including data curation,advanced architectural design, progressive model scaling and training, and anefficient infrastructure tailored for large-scale model training and inference.As a result, we successfully trained a video generative model with over 13billion parameters, making it the largest among all open-source models. Weconducted extensive experiments and implemented a series of targeted designs toensure high visual quality, motion dynamics, text-video alignment, and advancedfilming techniques. According to evaluations by professionals, HunyuanVideooutperforms previous state-of-the-art models, including Runway Gen-3, Luma 1.6,and three top-performing Chinese video generative models. By releasing the codefor the foundation model and its applications, we aim to bridge the gap betweenclosed-source and open-source communities. This initiative will empowerindividuals within the community to experiment with their ideas, fostering amore dynamic and vibrant video generation ecosystem. The code is publiclyavailable at https://github.com/Tencent/HunyuanVideo.</description><author>Weijie Kong, Qi Tian, Zijian Zhang, Rox Min, Zuozhuo Dai, Jin Zhou, Jiangfeng Xiong, Xin Li, Bo Wu, Jianwei Zhang, Kathrina Wu, Qin Lin, Junkun Yuan, Yanxin Long, Aladdin Wang, Andong Wang, Changlin Li, Duojun Huang, Fang Yang, Hao Tan, Hongmei Wang, Jacob Song, Jiawang Bai, Jianbing Wu, Jinbao Xue, Joey Wang, Kai Wang, Mengyang Liu, Pengyu Li, Shuai Li, Weiyan Wang, Wenqing Yu, Xinchi Deng, Yang Li, Yi Chen, Yutao Cui, Yuanbo Peng, Zhentao Yu, Zhiyu He, Zhiyong Xu, Zixiang Zhou, Zunnan Xu, Yangyu Tao, Qinglin Lu, Songtao Liu, Daquan Zhou, Hongfa Wang, Yong Yang, Di Wang, Yuhong Liu, Jie Jiang, Caesar Zhong</author><pubDate>Fri, 06 Dec 2024 17:02:10 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.03603v2</guid></item><item><title>DreamColour: Controllable Video Colour Editing without Training</title><link>http://arxiv.org/abs/2412.05180v1</link><description>Video colour editing is a crucial task for content creation, yet existingsolutions either require painstaking frame-by-frame manipulation or produceunrealistic results with temporal artefacts. We present a practical,training-free framework that makes precise video colour editing accessiblethrough an intuitive interface while maintaining professional-quality output.Our key insight is that by decoupling spatial and temporal aspects of colourediting, we can better align with users' natural workflow -- allowing them tofocus on precise colour selection in key frames before automaticallypropagating changes across time. We achieve this through a novel technicalframework that combines: (i) a simple point-and-click interface merginggrid-based colour selection with automatic instance segmentation for precisespatial control, (ii) bidirectional colour propagation that leverages inherentvideo motion patterns, and (iii) motion-aware blending that ensures smoothtransitions even with complex object movements. Through extensive evaluation ondiverse scenarios, we demonstrate that our approach matches or exceedsstate-of-the-art methods while eliminating the need for training or specializedhardware, making professional-quality video colour editing accessible toeveryone.</description><author>Chaitat Utintu, Pinaki Nath Chowdhury, Aneeshan Sain, Subhadeep Koley, Ayan Kumar Bhunia, Yi-Zhe Song</author><pubDate>Fri, 06 Dec 2024 16:57:54 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.05180v1</guid></item><item><title>Leveraging Skills from Unlabeled Prior Data for Efficient Online Exploration</title><link>http://arxiv.org/abs/2410.18076v2</link><description>Unsupervised pretraining has been transformative in many supervised domains.However, applying such ideas to reinforcement learning (RL) presents a uniquechallenge in that fine-tuning does not involve mimicking task-specific data,but rather exploring and locating the solution through iterativeself-improvement. In this work, we study how unlabeled prior trajectory datacan be leveraged to learn efficient exploration strategies. While prior datacan be used to pretrain a set of low-level skills, or as additional off-policydata for online RL, it has been unclear how to combine these ideas effectivelyfor online exploration. Our method SUPE (Skills from Unlabeled Prior data forExploration) demonstrates that a careful combination of these ideas compoundstheir benefits. Our method first extracts low-level skills using a variationalautoencoder (VAE), and then pseudo-relabels unlabeled trajectories using anoptimistic reward model, transforming prior data into high-level, task-relevantexamples. Finally, SUPE uses these transformed examples as additionaloff-policy data for online RL to learn a high-level policy that composespretrained low-level skills to explore efficiently. We empirically show thatSUPE reliably outperforms prior strategies, successfully solving a suite oflong-horizon, sparse-reward tasks. Code: https://github.com/rail-berkeley/supe.</description><author>Max Wilcoxson, Qiyang Li, Kevin Frans, Sergey Levine</author><pubDate>Fri, 06 Dec 2024 16:57:15 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.18076v2</guid></item><item><title>Evaluation of post-hoc interpretability methods in time-series classification</title><link>http://arxiv.org/abs/2202.05656v2</link><description>Post-hoc interpretability methods are critical tools to explainneural-network results. Several post-hoc methods have emerged in recent years,but when applied to a given task, they produce different results, raising thequestion of which method is the most suitable to provide correct post-hocinterpretability. To understand the performance of each method, quantitativeevaluation of interpretability methods is essential. However, currentlyavailable frameworks have several drawbacks which hinders the adoption ofpost-hoc interpretability methods, especially in high-risk sectors. In thiswork, we propose a framework with quantitative metrics to assess theperformance of existing post-hoc interpretability methods in particular in timeseries classification. We show that several drawbacks identified in theliterature are addressed, namely dependence on human judgement, retraining, andshift in the data distribution when occluding samples. We additionally design asynthetic dataset with known discriminative features and tunable complexity.The proposed methodology and quantitative metrics can be used to understand thereliability of interpretability methods results obtained in practicalapplications. In turn, they can be embedded within operational workflows incritical fields that require accurate interpretability results for e.g.,regulatory policies.</description><author>Hugues Turbé, Mina Bjelogrlic, Christian Lovis, Gianmarco Mengaldo</author><pubDate>Fri, 06 Dec 2024 16:56:46 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2202.05656v2</guid></item><item><title>Spatially-Adaptive Hash Encodings For Neural Surface Reconstruction</title><link>http://arxiv.org/abs/2412.05179v1</link><description>Positional encodings are a common component of neural scene reconstructionmethods, and provide a way to bias the learning of neural fields towardscoarser or finer representations. Current neural surface reconstruction methodsuse a "one-size-fits-all" approach to encoding, choosing a fixed set ofencoding functions, and therefore bias, across all scenes. Currentstate-of-the-art surface reconstruction approaches leverage grid-basedmulti-resolution hash encoding in order to recover high-detail geometry. Wepropose a learned approach which allows the network to choose its encodingbasis as a function of space, by masking the contribution of features stored atseparate grid resolutions. The resulting spatially adaptive approach allows thenetwork to fit a wider range of frequencies without introducing noise. We testour approach on standard benchmark surface reconstruction datasets and achievestate-of-the-art performance on two benchmark datasets.</description><author>Thomas Walker, Octave Mariotti, Amir Vaxman, Hakan Bilen</author><pubDate>Fri, 06 Dec 2024 16:54:55 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.05179v1</guid></item><item><title>Variational Encoder-Decoders for Learning Latent Representations of Physical Systems</title><link>http://arxiv.org/abs/2412.05175v1</link><description>We present a deep-learning Variational Encoder-Decoder (VED) framework forlearning data-driven low-dimensional representations of the relationshipbetween high-dimensional parameters of a physical system and the system'shigh-dimensional observable response. The framework consists of two deeplearning-based probabilistic transformations: An encoder mapping parameters tolatent codes and a decoder mapping latent codes to the observable response. Thehyperparameters of these transformations are identified by maximizing avariational lower bound on the log-conditional distribution of the observableresponse given parameters. To promote the disentanglement of latent codes, weequip this variational loss with a penalty on the off-diagonal entries of theaggregate distribution covariance of codes. This regularization penaltyencourages the pushforward of a standard Gaussian distribution of latent codesto approximate the marginal distribution of the observable response. Using the proposed framework we successfully model the hydraulic pressureresponse at observation wells of a groundwater flow model as a function of itsdiscrete log-hydraulic transmissivity field. Compared to the canonicalcorrelation analysis encoding, the VED model achieves a lower-dimensionallatent representation, with as low as $r = 50$ latent dimensions without asignificant loss of reconstruction accuracy. We explore the impact ofregularization on model performance, finding that KL-divergence and covarianceregularization improve feature disentanglement in latent space whilemaintaining reconstruction accuracy. Furthermore, we evaluate the generativecapabilities of the regularized model by decoding random Gaussian noise,revealing that tuning both $\beta$ and $\lambda$ parameters enhances thequality of the generated observable response data.</description><author>Subashree Venkatasubramanian, David A. Barajas-Solano</author><pubDate>Fri, 06 Dec 2024 16:46:48 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.05175v1</guid></item><item><title>Connecting Large Language Models with Blockchain: Advancing the Evolution of Smart Contracts from Automation to Intelligence</title><link>http://arxiv.org/abs/2412.02263v2</link><description>Blockchain smart contracts have catalyzed the development of decentralizedapplications across various domains, including decentralized finance. However,due to constraints in computational resources and the prevalence of data silos,current smart contracts face significant challenges in fully leveraging thepowerful capabilities of Large Language Models (LLMs) for tasks such asintelligent analysis and reasoning. To address this gap, this paper proposesand implements a universal framework for integrating LLMs with blockchain data,{\sysname}, effectively overcoming the interoperability barriers betweenblockchain and LLMs. By combining semantic relatedness with truth discoverymethods, we introduce an innovative data aggregation approach, {\funcname},which significantly enhances the accuracy and trustworthiness of data generatedby LLMs. To validate the framework's effectiveness, we construct a datasetconsisting of three types of questions, capturing Q\&amp;A interactions between 10oracle nodes and 5 LLM models. Experimental results demonstrate that, even with40\% malicious nodes, the proposed solution improves data accuracy by anaverage of 17.74\% compared to the optimal baseline. This research not onlyprovides an innovative solution for the intelligent enhancement of smartcontracts but also highlights the potential for deep integration between LLMsand blockchain technology, paving the way for more intelligent and complexapplications of smart contracts in the future.</description><author>Youquan Xian, Xueying Zeng, Duancheng Xuan, Danping Yang, Chunpei Li, Peng Fan, Peng Liu</author><pubDate>Fri, 06 Dec 2024 16:43:58 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.02263v2</guid></item><item><title>Towards Understanding the Role of Sharpness-Aware Minimization Algorithms for Out-of-Distribution Generalization</title><link>http://arxiv.org/abs/2412.05169v1</link><description>Recently, sharpness-aware minimization (SAM) has emerged as a promisingmethod to improve generalization by minimizing sharpness, which is known tocorrelate well with generalization ability. Since the original proposal of SAM,many variants of SAM have been proposed to improve its accuracy and efficiency,but comparisons have mainly been restricted to the i.i.d. setting. In thispaper we study SAM for out-of-distribution (OOD) generalization. First, weperform a comprehensive comparison of eight SAM variants on zero-shot OODgeneralization, finding that the original SAM outperforms the Adam baseline by$4.76\%$ and the strongest SAM variants outperform the Adam baseline by$8.01\%$ on average. We then provide an OOD generalization bound in terms ofsharpness for this setting. Next, we extend our study of SAM to the relatedsetting of gradual domain adaptation (GDA), another form of OOD generalizationwhere intermediate domains are constructed between the source and targetdomains, and iterative self-training is done on intermediate domains, toimprove the overall target domain error. In this setting, our experimentalresults demonstrate that the original SAM outperforms the baseline of Adam oneach of the experimental datasets by $0.82\%$ on average and the strongest SAMvariants outperform Adam by $1.52\%$ on average. We then provide ageneralization bound for SAM in the GDA setting. Asymptotically, thisgeneralization bound is no better than the one for self-training in theliterature of GDA. This highlights a further disconnection between thetheoretical justification for SAM versus its empirical performance, with recentwork finding that low sharpness alone does not account for all of SAM'sgeneralization benefits. For future work, we provide several potential avenuesfor obtaining a tighter analysis for SAM in the OOD setting.</description><author>Samuel Schapiro, Han Zhao</author><pubDate>Fri, 06 Dec 2024 16:41:44 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.05169v1</guid></item><item><title>Benchmarking Open-ended Audio Dialogue Understanding for Large Audio-Language Models</title><link>http://arxiv.org/abs/2412.05167v1</link><description>Large Audio-Language Models (LALMs) have unclocked audio dialoguecapabilities, where audio dialogues are a direct exchange of spoken languagebetween LALMs and humans. Recent advances, such as GPT-4o, have enabled LALMsin back-and-forth audio dialogues with humans. This progression not onlyunderscores the potential of LALMs but also broadens their applicability acrossa wide range of practical scenarios supported by audio dialogues. However,given these advancements, a comprehensive benchmark to evaluate the performanceof LALMs in the open-ended audio dialogue understanding remains absentcurrently. To address this gap, we propose an Audio Dialogue UnderstandingBenchmark (ADU-Bench), which consists of 4 benchmark datasets. They assess theopen-ended audio dialogue ability for LALMs in 3 general scenarios, 12 skills,9 multilingual languages, and 4 categories of ambiguity handling. Notably, wefirstly propose the evaluation of ambiguity handling in audio dialogues thatexpresses different intentions beyond the same literal meaning of sentences,e.g., "Really!?" with different intonations. In summary, ADU-Bench includesover 20,000 open-ended audio dialogues for the assessment of LALMs. Throughextensive experiments conducted on 13 LALMs, our analysis reveals that there isstill considerable room for improvement in the audio dialogue understandingabilities of existing LALMs. In particular, they struggle with mathematicalsymbols and formulas, understanding human behavior such as roleplay,comprehending multiple languages, and handling audio dialogue ambiguities fromdifferent phonetic elements, such as intonations, pause positions, andhomophones.</description><author>Kuofeng Gao, Shu-Tao Xia, Ke Xu, Philip Torr, Jindong Gu</author><pubDate>Fri, 06 Dec 2024 16:34:15 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.05167v1</guid></item><item><title>A Differentially Private Kaplan-Meier Estimator for Privacy-Preserving Survival Analysis</title><link>http://arxiv.org/abs/2412.05164v1</link><description>This paper presents a differentially private approach to Kaplan-Meierestimation that achieves accurate survival probability estimates whilesafeguarding individual privacy. The Kaplan-Meier estimator is widely used insurvival analysis to estimate survival functions over time, yet applying it tosensitive datasets, such as clinical records, risks revealing privateinformation. To address this, we introduce a novel algorithm that appliestime-indexed Laplace noise, dynamic clipping, and smoothing to produce aprivacy-preserving survival curve while maintaining the cumulative structure ofthe Kaplan-Meier estimator. By scaling noise over time, the algorithm accountsfor decreasing sensitivity as fewer individuals remain at risk, while dynamicclipping and smoothing prevent extreme values and reduce fluctuations,preserving the natural shape of the survival curve. Our results, evaluated on the NCCTG lung cancer dataset, show that theproposed method effectively lowers root mean squared error (RMSE) and enhancesaccuracy across privacy budgets ($\epsilon$). At $\epsilon = 10$, the algorithmachieves an RMSE as low as 0.04, closely approximating non-private estimates.Additionally, membership inference attacks reveal that higher $\epsilon$ values(e.g., $\epsilon \geq 6$) significantly reduce influential points, particularlyat higher thresholds, lowering susceptibility to inference attacks. Thesefindings confirm that our approach balances privacy and utility, advancingprivacy-preserving survival analysis.</description><author>Narasimha Raghavan Veeraragavan, Sai Praneeth Karimireddy, Jan Franz Nygård</author><pubDate>Fri, 06 Dec 2024 16:29:53 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.05164v1</guid></item><item><title>DNF: Unconditional 4D Generation with Dictionary-based Neural Fields</title><link>http://arxiv.org/abs/2412.05161v1</link><description>While remarkable success has been achieved through diffusion-based 3Dgenerative models for shapes, 4D generative modeling remains challenging due tothe complexity of object deformations over time. We propose DNF, a new 4Drepresentation for unconditional generative modeling that efficiently modelsdeformable shapes with disentangled shape and motion while capturinghigh-fidelity details in the deforming objects. To achieve this, we propose adictionary learning approach to disentangle 4D motion from shape as neuralfields. Both shape and motion are represented as learned latent spaces, whereeach deformable shape is represented by its shape and motion global latentcodes, shape-specific coefficient vectors, and shared dictionary information.This captures both shape-specific detail and global shared information in thelearned dictionary. Our dictionary-based representation well balances fidelity,contiguity and compression -- combined with a transformer-based diffusionmodel, our method is able to generate effective, high-fidelity 4D animations.</description><author>Xinyi Zhang, Naiqi Li, Angela Dai</author><pubDate>Fri, 06 Dec 2024 16:25:57 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.05161v1</guid></item><item><title>Enhancing Cross-Language Code Translation via Task-Specific Embedding Alignment in Retrieval-Augmented Generation</title><link>http://arxiv.org/abs/2412.05159v1</link><description>We introduce a novel method to enhance cross-language code translation fromFortran to C++ by integrating task-specific embedding alignment into aRetrieval-Augmented Generation (RAG) framework. Unlike conventional retrievalapproaches that utilize generic embeddings agnostic to the downstream task, ourstrategy aligns the retrieval model directly with the objective of maximizingtranslation quality, as quantified by the CodeBLEU metric. This alignmentensures that the embeddings are semantically and syntactically meaningful forthe specific code translation task. Our methodology involves constructing adataset of 25,000 Fortran code snippets sourced from Stack-V2 dataset andgenerating their corresponding C++ translations using the LLaMA 3.1-8B languagemodel. We compute pairwise CodeBLEU scores between the generated translationsand ground truth examples to capture fine-grained similarities. These scoresserve as supervision signals in a contrastive learning framework, where weoptimize the embedding model to retrieve Fortran-C++ pairs that are mostbeneficial for improving the language model's translation performance. Byintegrating these CodeBLEU-optimized embeddings into the RAG framework, ourapproach significantly enhances both retrieval accuracy and code generationquality over methods employing generic embeddings. On the HPC Fortran2C++dataset, our method elevates the average CodeBLEU score from 0.64 to 0.73,achieving a 14% relative improvement. On the Numerical Recipes dataset, weobserve an increase from 0.52 to 0.60, marking a 15% relative improvement.Importantly, these gains are realized without any fine-tuning of the languagemodel, underscoring the efficiency and practicality of our approach.</description><author>Manish Bhattarai, Minh Vu, Javier E. Santos, Ismael Boureima, Daniel O' Malley</author><pubDate>Fri, 06 Dec 2024 16:22:32 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.05159v1</guid></item><item><title>Unlocking State-Tracking in Linear RNNs Through Negative Eigenvalues</title><link>http://arxiv.org/abs/2411.12537v2</link><description>Linear Recurrent Neural Networks (LRNNs) such as Mamba, RWKV, GLA, mLSTM, andDeltaNet have emerged as efficient alternatives to Transformers in largelanguage modeling, offering linear scaling with sequence length and improvedtraining efficiency. However, LRNNs struggle to perform state-tracking whichmay impair performance in tasks such as code evaluation or tracking a chessgame. Even parity, the simplest state-tracking task, which non-linear RNNs likeLSTM handle effectively, cannot be solved by current LRNNs. Recently, Sarrof etal. (2024) demonstrated that the failure of LRNNs like Mamba to solve paritystems from restricting the value range of their diagonal state-transitionmatrices to $[0, 1]$ and that incorporating negative values can resolve thisissue. We extend this result to non-diagonal LRNNs, which have recently shownpromise in models such as DeltaNet. We prove that finite precision LRNNs withstate-transition matrices having only positive eigenvalues cannot solve parity,while complex eigenvalues are needed to count modulo $3$. Notably, we alsoprove that LRNNs can learn any regular language when their state-transitionmatrices are products of identity minus vector outer product matrices, eachwith eigenvalues in the range $[-1, 1]$. Our empirical results confirm thatextending the eigenvalue range of models like Mamba and DeltaNet to includenegative values not only enables them to solve parity but consistently improvestheir performance on state-tracking tasks. Furthermore, pre-training LRNNs withan extended eigenvalue range for language modeling achieves comparableperformance and stability while showing promise on code and math data. Our workenhances the expressivity of modern LRNNs, broadening their applicabilitywithout changing the cost of training or inference.</description><author>Riccardo Grazzi, Julien Siems, Jörg K. H. Franke, Arber Zela, Frank Hutter, Massimiliano Pontil</author><pubDate>Fri, 06 Dec 2024 16:22:21 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2411.12537v2</guid></item><item><title>Gaining Explainability from a CNN for Stereotype Detection Based on Mice Stopping Behavior</title><link>http://arxiv.org/abs/2412.05158v1</link><description>Understanding the behavior of laboratory animals is a key to find answersabout diseases and neurodevelopmental disorders that also affects humans. Onebehavior of interest is the stopping, as it correlates with exploration,feeding and sleeping habits of individuals. To improve comprehension ofanimal's behavior, we focus on identifying trait revealing age/sex of micethrough the series of stopping spots of each individual. We track 4 mice usingLiveMouseTracker (LMT) system during 3 days. Then, we build a stack of 2Dhistograms of the stop positions. This stack of histograms passes through ashallow CNN architecture to classify mice in terms of age and sex. We observethat female mice show more recognizable behavioral patterns, reaching aclassification accuracy of more than 90%, while males, which do not present asmany distinguishable patterns, reach an accuracy of 62.5%. To gainexplainability from the model, we look at the activation function of theconvolutional layers and found that some regions of the cage are preferentiallyexplored by females. Males, especially juveniles, present behavior patternsthat oscillate between juvenile female and adult male.</description><author>Raul Alfredo de Sousa Silva, Yasmine Belaidouni, Rabah Iguernaissi, Djamal Merad, Séverine Dubuisson</author><pubDate>Fri, 06 Dec 2024 16:22:00 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.05158v1</guid></item><item><title>Comparing ImageNet Pre-training with Digital Pathology Foundation Models for Whole Slide Image-Based Survival Analysis</title><link>http://arxiv.org/abs/2405.17446v3</link><description>The abundance of information present in Whole Slide Images (WSIs) rendersthem an essential tool for survival analysis. Several Multiple InstanceLearning frameworks proposed for this task utilize a ResNet50 backbonepre-trained on natural images. By leveraging recenetly releasedhistopathological foundation models such as UNI and Hibou, the predictiveprowess of existing MIL networks can be enhanced. Furthermore, deploying anensemble of digital pathology foundation models yields higher baselineaccuracy, although the benefits appear to diminish with more complex MILarchitectures. Our code will be made publicly available upon acceptance.</description><author>Kleanthis Marios Papadopoulos, Tania Stathaki</author><pubDate>Fri, 06 Dec 2024 16:20:05 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.17446v3</guid></item><item><title>Multimodal Fact-Checking with Vision Language Models: A Probing Classifier based Solution with Embedding Strategies</title><link>http://arxiv.org/abs/2412.05155v1</link><description>This study evaluates the effectiveness of Vision Language Models (VLMs) inrepresenting and utilizing multimodal content for fact-checking. To be morespecific, we investigate whether incorporating multimodal content improvesperformance compared to text-only models and how well VLMs utilize text andimage information to enhance misinformation detection. Furthermore we propose aprobing classifier based solution using VLMs. Our approach extracts embeddingsfrom the last hidden layer of selected VLMs and inputs them into a neuralprobing classifier for multi-class veracity classification. Through a series ofexperiments on two fact-checking datasets, we demonstrate that whilemultimodality can enhance performance, fusing separate embeddings from text andimage encoders yielded superior results compared to using VLM embeddings.Furthermore, the proposed neural classifier significantly outperformed KNN andSVM baselines in leveraging extracted embeddings, highlighting itseffectiveness for multimodal fact-checking.</description><author>Recep Firat Cekinel, Pinar Karagoz, Cagri Coltekin</author><pubDate>Fri, 06 Dec 2024 16:13:19 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.05155v1</guid></item><item><title>Random Tree Model of Meaningful Memory</title><link>http://arxiv.org/abs/2412.01806v2</link><description>Traditional studies of memory for meaningful narratives focus on specificstories and their semantic structures but do not address common quantitativefeatures of recall across different narratives. We introduce a statisticalensemble of random trees to represent narratives as hierarchies of key points,where each node is a compressed representation of its descendant leaves, whichare the original narrative segments. Recall is modeled as constrained byworking memory capacity from this hierarchical structure. Our analyticalsolution aligns with observations from large-scale narrative recallexperiments. Specifically, our model explains that (1) average recall lengthincreases sublinearly with narrative length, and (2) individuals summarizeincreasingly longer narrative segments in each recall sentence. Additionally,the theory predicts that for sufficiently long narratives, a universal,scale-invariant limit emerges, where the fraction of a narrative summarized bya single recall sentence follows a distribution independent of narrativelength.</description><author>Weishun Zhong, Tankut Can, Antonis Georgiou, Ilya Shnayderman, Mikhail Katkov, Misha Tsodyks</author><pubDate>Fri, 06 Dec 2024 16:13:01 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.01806v2</guid></item><item><title>Towards Flexible 3D Perception: Object-Centric Occupancy Completion Augments 3D Object Detection</title><link>http://arxiv.org/abs/2412.05154v1</link><description>While 3D object bounding box (bbox) representation has been widely used inautonomous driving perception, it lacks the ability to capture the precisedetails of an object's intrinsic geometry. Recently, occupancy has emerged as apromising alternative for 3D scene perception. However, constructing ahigh-resolution occupancy map remains infeasible for large scenes due tocomputational constraints. Recognizing that foreground objects only occupy asmall portion of the scene, we introduce object-centric occupancy as asupplement to object bboxes. This representation not only provides intricatedetails for detected objects but also enables higher voxel resolution inpractical applications. We advance the development of object-centric occupancyperception from both data and algorithm perspectives. On the data side, weconstruct the first object-centric occupancy dataset from scratch using anautomated pipeline. From the algorithmic standpoint, we introduce a novelobject-centric occupancy completion network equipped with an implicit shapedecoder that manages dynamic-size occupancy generation. This network accuratelypredicts the complete object-centric occupancy volume for inaccurate objectproposals by leveraging temporal information from long sequences. Our methoddemonstrates robust performance in completing object shapes under noisydetection and tracking conditions. Additionally, we show that our occupancyfeatures significantly enhance the detection results of state-of-the-art 3Dobject detectors, especially for incomplete or distant objects in the WaymoOpen Dataset.</description><author>Chaoda Zheng, Feng Wang, Naiyan Wang, Shuguang Cui, Zhen Li</author><pubDate>Fri, 06 Dec 2024 16:12:38 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.05154v1</guid></item><item><title>A text-to-tabular approach to generate synthetic patient data using LLMs</title><link>http://arxiv.org/abs/2412.05153v1</link><description>Access to large-scale high-quality healthcare databases is key to acceleratemedical research and make insightful discoveries about diseases. However,access to such data is often limited by patient privacy concerns, data sharingrestrictions and high costs. To overcome these limitations, synthetic patientdata has emerged as an alternative. However, synthetic data generation (SDG)methods typically rely on machine learning (ML) models trained on originaldata, leading back to the data scarcity problem. We propose an approach togenerate synthetic tabular patient data that does not require access to theoriginal data, but only a description of the desired database. We leverageprior medical knowledge and in-context learning capabilities of large languagemodels (LLMs) to generate realistic patient data, even in a low-resourcesetting. We quantitatively evaluate our approach against state-of-the-art SDGmodels, using fidelity, privacy, and utility metrics. Our results show thatwhile LLMs may not match the performance of state-of-the-art models trained onthe original data, they effectively generate realistic patient data withwell-preserved clinical correlations. An ablation study highlights key elementsof our prompt contributing to high-quality synthetic patient data generation.This approach, which is easy to use and does not require original data oradvanced ML skills, is particularly valuable for quickly generatingcustom-designed patient data, supporting project implementation and providingeducational resources.</description><author>Margaux Tornqvist, Jean-Daniel Zucker, Tristan Fauvel, Nicolas Lambert, Mathilde Berthelot, Antoine Movschin</author><pubDate>Fri, 06 Dec 2024 16:10:40 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.05153v1</guid></item><item><title>Navigating Shortcuts, Spurious Correlations, and Confounders: From Origins via Detection to Mitigation</title><link>http://arxiv.org/abs/2412.05152v1</link><description>Shortcuts, also described as Clever Hans behavior, spurious correlations, orconfounders, present a significant challenge in machine learning and AI,critically affecting model generalization and robustness. Research in thisarea, however, remains fragmented across various terminologies, hindering theprogress of the field as a whole. Consequently, we introduce a unifyingtaxonomy of shortcut learning by providing a formal definition of shortcuts andbridging the diverse terms used in the literature. In doing so, we furtherestablish important connections between shortcuts and related fields, includingbias, causality, and security, where parallels exist but are rarely discussed.Our taxonomy organizes existing approaches for shortcut detection andmitigation, providing a comprehensive overview of the current state of thefield and revealing underexplored areas and open challenges. Moreover, wecompile and classify datasets tailored to study shortcut learning. Altogether,this work provides a holistic perspective to deepen understanding and drive thedevelopment of more effective strategies for addressing shortcuts in machinelearning.</description><author>David Steinmann, Felix Divo, Maurice Kraus, Antonia Wüst, Lukas Struppek, Felix Friedrich, Kristian Kersting</author><pubDate>Fri, 06 Dec 2024 16:10:13 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.05152v1</guid></item><item><title>BIAS: A Body-based Interpretable Active Speaker Approach</title><link>http://arxiv.org/abs/2412.05150v1</link><description>State-of-the-art Active Speaker Detection (ASD) approaches heavily rely onaudio and facial features to perform, which is not a sustainable approach inwild scenarios. Although these methods achieve good results in the standardAVA-ActiveSpeaker set, a recent wilder ASD dataset (WASD) showed thelimitations of such models and raised the need for new approaches. As such, wepropose BIAS, a model that, for the first time, combines audio, face, and bodyinformation, to accurately predict active speakers in varying/challengingconditions. Additionally, we design BIAS to provide interpretability byproposing a novel use for Squeeze-and-Excitation blocks, namely in attentionheatmaps creation and feature importance assessment. For a fullinterpretability setup, we annotate an ASD-related actions dataset (ASD-Text)to finetune a ViT-GPT2 for text scene description to complement BIASinterpretability. The results show that BIAS is state-of-the-art in challengingconditions where body-based features are of utmost importance (Columbia,open-settings, and WASD), and yields competitive results in AVA-ActiveSpeaker,where face is more influential than body for ASD. BIAS interpretability alsoshows the features/aspects more relevant towards ASD prediction in varyingsettings, making it a strong baseline for further developments in interpretableASD models, and is available at https://github.com/Tiago-Roxo/BIAS.</description><author>Tiago Roxo, Joana C. Costa, Pedro R. M. Inácio, Hugo Proença</author><pubDate>Fri, 06 Dec 2024 16:08:09 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.05150v1</guid></item><item><title>Fine-Tuning CLIP's Last Visual Projector: A Few-Shot Cornucopia</title><link>http://arxiv.org/abs/2410.05270v2</link><description>We consider the problem of adapting a contrastively pretrainedvision-language model like CLIP (Radford et al., 2021) for few-shotclassification. The literature addresses this problem by learning a linearclassifier of the frozen visual features, optimizing word embeddings, orlearning external feature adapters. This paper introduces an alternative wayfor CLIP adaptation without adding 'external' parameters to optimize. We findthat simply fine-tuning the last projection matrix of the vision encoder leadsto performance better than all baselines. Furthermore, we show thatregularizing training with the distance between the fine-tuned and pretrainedmatrices adds reliability for adapting CLIP. This simple approach, coinedProLIP, yields state-of-the-art performance on 11 few-shot classificationbenchmarks, few-shot domain generalization, cross-dataset transfer, base-to-newclass generalization, and test-time adaptation. Code will be made available at:https://github.com/astra-vision/ProLIP .</description><author>Mohammad Fahes, Tuan-Hung Vu, Andrei Bursuc, Patrick Pérez, Raoul de Charette</author><pubDate>Fri, 06 Dec 2024 16:07:47 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.05270v2</guid></item><item><title>Findings of the Second BabyLM Challenge: Sample-Efficient Pretraining on Developmentally Plausible Corpora</title><link>http://arxiv.org/abs/2412.05149v1</link><description>The BabyLM Challenge is a community effort to close the data-efficiency gapbetween human and computational language learners. Participants compete tooptimize language model training on a fixed language data budget of 100 millionwords or less. This year, we released improved text corpora, as well as avision-and-language corpus to facilitate research into cognitively plausiblevision language models. Submissions were compared on evaluation tasks targetinggrammatical ability, (visual) question answering, pragmatic abilities, andgrounding, among other abilities. Participants could submit to a 10M-wordtext-only track, a 100M-word text-only track, and/or a 100M-word and imagemultimodal track. From 31 submissions employing diverse methods, a hybridcausal-masked language model architecture outperformed other approaches. Nosubmissions outperformed the baselines in the multimodal track. In follow-upanalyses, we found a strong relationship between training FLOPs and averageperformance across tasks, and that the best-performing submissions proposedchanges to the training data, training objective, and model architecture. Thisyear's BabyLM Challenge shows that there is still significant room forinnovation in this setting, in particular for image-text modeling, butcommunity-driven research can yield actionable insights about effectivestrategies for small-scale language modeling.</description><author>Michael Y. Hu, Aaron Mueller, Candace Ross, Adina Williams, Tal Linzen, Chengxu Zhuang, Ryan Cotterell, Leshem Choshen, Alex Warstadt, Ethan Gotlieb Wilcox</author><pubDate>Fri, 06 Dec 2024 16:06:08 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.05149v1</guid></item><item><title>LoRA.rar: Learning to Merge LoRAs via Hypernetworks for Subject-Style Conditioned Image Generation</title><link>http://arxiv.org/abs/2412.05148v1</link><description>Recent advancements in image generation models have enabled personalizedimage creation with both user-defined subjects (content) and styles. Priorworks achieved personalization by merging corresponding low-rank adaptationparameters (LoRAs) through optimization-based methods, which arecomputationally demanding and unsuitable for real-time use onresource-constrained devices like smartphones. To address this, we introduceLoRA.rar, a method that not only improves image quality but also achieves aremarkable speedup of over $4000\times$ in the merging process. LoRA.rarpre-trains a hypernetwork on a diverse set of content-style LoRA pairs,learning an efficient merging strategy that generalizes to new, unseencontent-style pairs, enabling fast, high-quality personalization. Moreover, weidentify limitations in existing evaluation metrics for content-style qualityand propose a new protocol using multimodal large language models (MLLM) formore accurate assessment. Our method significantly outperforms the currentstate of the art in both content and style fidelity, as validated by MLLMassessments and human evaluations.</description><author>Donald Shenaj, Ondrej Bohdal, Mete Ozay, Pietro Zanuttigh, Umberto Michieli</author><pubDate>Fri, 06 Dec 2024 16:04:56 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.05148v1</guid></item><item><title>The Score-Difference Flow for Implicit Generative Modeling</title><link>http://arxiv.org/abs/2304.12906v3</link><description>Implicit generative modeling (IGM) aims to produce samples of synthetic datamatching the characteristics of a target data distribution. Recent work (e.g.score-matching networks, diffusion models) has approached the IGM problem fromthe perspective of pushing synthetic source data toward the target distributionvia dynamical perturbations or flows in the ambient space. In this direction,we present the score difference (SD) between arbitrary target and sourcedistributions as a flow that optimally reduces the Kullback-Leibler divergencebetween them. We apply the SD flow to convenient proxy distributions, which arealigned if and only if the original distributions are aligned. We demonstratethe formal equivalence of this formulation to denoising diffusion models undercertain conditions. We also show that the training of generative adversarialnetworks includes a hidden data-optimization sub-problem, which induces the SDflow under certain choices of loss function when the discriminator is optimal.As a result, the SD flow provides a theoretical link between model classes thatindividually address the three challenges of the "generative modeling trilemma"-- high sample quality, mode coverage, and fast sampling -- thereby setting thestage for a unified approach.</description><author>Romann M. Weber</author><pubDate>Fri, 06 Dec 2024 16:02:25 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2304.12906v3</guid></item><item><title>Explingo: Explaining AI Predictions using Large Language Models</title><link>http://arxiv.org/abs/2412.05145v1</link><description>Explanations of machine learning (ML) model predictions generated byExplainable AI (XAI) techniques such as SHAP are essential for people using MLoutputs for decision-making. We explore the potential of Large Language Models(LLMs) to transform these explanations into human-readable, narrative formatsthat align with natural communication. We address two key research questions:(1) Can LLMs reliably transform traditional explanations into high-qualitynarratives? and (2) How can we effectively evaluate the quality of narrativeexplanations? To answer these questions, we introduce Explingo, which consistsof two LLM-based subsystems, a Narrator and Grader. The Narrator takes in MLexplanations and transforms them into natural-language descriptions. The Graderscores these narratives on a set of metrics including accuracy, completeness,fluency, and conciseness. Our experiments demonstrate that LLMs can generate high-quality narrativesthat achieve high scores across all metrics, particularly when guided by asmall number of human-labeled and bootstrapped examples. We also identifiedareas that remain challenging, in particular for effectively scoring narrativesin complex domains. The findings from this work have been integrated into anopen-source tool that makes narrative explanations available for furtherapplications.</description><author>Alexandra Zytek, Sara Pido, Sarah Alnegheimish, Laure Berti-Equille, Kalyan Veeramachaneni</author><pubDate>Fri, 06 Dec 2024 16:01:30 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.05145v1</guid></item><item><title>Effective Rank and the Staircase Phenomenon: New Insights into Neural Network Training Dynamics</title><link>http://arxiv.org/abs/2412.05144v1</link><description>In recent years, deep learning, powered by neural networks, has achievedwidespread success in solving high-dimensional problems, particularly thosewith low-dimensional feature structures. This success stems from their abilityto identify and learn low dimensional features tailored to the problems.Understanding how neural networks extract such features during trainingdynamics remains a fundamental question in deep learning theory. In this work,we propose a novel perspective by interpreting the neurons in the last hiddenlayer of a neural network as basis functions that represent essential features.To explore the linear independence of these basis functions throughout the deeplearning dynamics, we introduce the concept of 'effective rank'. Our extensivenumerical experiments reveal a notable phenomenon: the effective rank increasesprogressively during the learning process, exhibiting a staircase-like pattern,while the loss function concurrently decreases as the effective rank rises. Werefer to this observation as the 'staircase phenomenon'. Specifically, for deepneural networks, we rigorously prove the negative correlation between the lossfunction and effective rank, demonstrating that the lower bound of the lossfunction decreases with increasing effective rank. Therefore, to achieve arapid descent of the loss function, it is critical to promote the swift growthof effective rank. Ultimately, we evaluate existing advanced learningmethodologies and find that these approaches can quickly achieve a highereffective rank, thereby avoiding redundant staircase processes and acceleratingthe rapid decline of the loss function.</description><author>Yang Jiang, Yuxiang Zhao, Quanhui Zhu</author><pubDate>Fri, 06 Dec 2024 16:00:50 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.05144v1</guid></item><item><title>A Practical Examination of AI-Generated Text Detectors for Large Language Models</title><link>http://arxiv.org/abs/2412.05139v1</link><description>The proliferation of large language models has raised growing concerns abouttheir misuse, particularly in cases where AI-generated text is falselyattributed to human authors. Machine-generated content detectors claim toeffectively identify such text under various conditions and from any languagemodel. This paper critically evaluates these claims by assessing severalpopular detectors (RADAR, Wild, T5Sentinel, Fast-DetectGPT, GPTID, LogRank,Binoculars) on a range of domains, datasets, and models that these detectorshave not previously encountered. We employ various prompting strategies tosimulate adversarial attacks, demonstrating that even moderate efforts cansignificantly evade detection. We emphasize the importance of the true positiverate at a specific false positive rate (TPR@FPR) metric and demonstrate thatthese detectors perform poorly in certain settings, with TPR@.01 as low as 0\%.Our findings suggest that both trained and zero-shot detectors struggle tomaintain high sensitivity while achieving a reasonable true positive rate.</description><author>Brian Tufts, Xuandong Zhao, Lei Li</author><pubDate>Fri, 06 Dec 2024 15:56:11 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.05139v1</guid></item><item><title>Can Large Language Models Serve as Effective Classifiers for Hierarchical Multi-Label Classification of Scientific Documents at Industrial Scale?</title><link>http://arxiv.org/abs/2412.05137v1</link><description>We address the task of hierarchical multi-label classification (HMC) ofscientific documents at an industrial scale, where hundreds of thousands ofdocuments must be classified across thousands of dynamic labels. The rapidgrowth of scientific publications necessitates scalable and efficient methodsfor classification, further complicated by the evolving nature oftaxonomies--where new categories are introduced, existing ones are merged, andoutdated ones are deprecated. Traditional machine learning approaches, whichrequire costly retraining with each taxonomy update, become impractical due tothe high overhead of labelled data collection and model adaptation. LargeLanguage Models (LLMs) have demonstrated great potential in complex tasks suchas multi-label classification. However, applying them to large and dynamictaxonomies presents unique challenges as the vast number of labels can exceedLLMs' input limits. In this paper, we present novel methods that combine thestrengths of LLMs with dense retrieval techniques to overcome these challenges.Our approach avoids retraining by leveraging zero-shot HMC for real-time labelassignment. We evaluate the effectiveness of our methods on SSRN, a largerepository of preprints spanning multiple disciplines, and demonstratesignificant improvements in both classification accuracy and cost-efficiency.By developing a tailored evaluation framework for dynamic taxonomies andpublicly releasing our code, this research provides critical insights intoapplying LLMs for document classification, where the number of classescorresponds to the number of nodes in a large taxonomy, at an industrial scale.</description><author>Seyed Amin Tabatabaei, Sarah Fancher, Michael Parsons, Arian Askari</author><pubDate>Fri, 06 Dec 2024 15:51:22 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.05137v1</guid></item><item><title>The Polynomial Stein Discrepancy for Assessing Moment Convergence</title><link>http://arxiv.org/abs/2412.05135v1</link><description>We propose a novel method for measuring the discrepancy between a set ofsamples and a desired posterior distribution for Bayesian inference. Classicalmethods for assessing sample quality like the effective sample size are notappropriate for scalable Bayesian sampling algorithms, such as stochasticgradient Langevin dynamics, that are asymptotically biased. Instead, the goldstandard is to use the kernel Stein Discrepancy (KSD), which is itself notscalable given its quadratic cost in the number of samples. The KSD and itsfaster extensions also typically suffer from the curse-of-dimensionality andcan require extensive tuning. To address these limitations, we develop thepolynomial Stein discrepancy (PSD) and an associated goodness-of-fit test.While the new test is not fully convergence-determining, we prove that itdetects differences in the first r moments in the Bernstein-von Mises limit. Weempirically show that the test has higher power than its competitors in severalexamples, and at a lower computational cost. Finally, we demonstrate that thePSD can assist practitioners to select hyper-parameters of Bayesian samplingalgorithms more efficiently than competitors.</description><author>Narayan Srinivasan, Matthew Sutton, Christopher Drovandi, Leah F South</author><pubDate>Fri, 06 Dec 2024 15:51:04 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.05135v1</guid></item><item><title>How to Squeeze An Explanation Out of Your Model</title><link>http://arxiv.org/abs/2412.05134v1</link><description>Deep learning models are widely used nowadays for their reliability inperforming various tasks. However, they do not typically provide the reasoningbehind their decision, which is a significant drawback, particularly for moresensitive areas such as biometrics, security and healthcare. The most commonlyused approaches to provide interpretability create visual attention heatmaps ofregions of interest on an image based on models gradient backpropagation.Although this is a viable approach, current methods are targeted toward imagesettings and default/standard deep learning models, meaning that they requiresignificant adaptations to work on video/multi-modal settings and customarchitectures. This paper proposes an approach for interpretability that ismodel-agnostic, based on a novel use of the Squeeze and Excitation (SE) blockthat creates visual attention heatmaps. By including an SE block prior to theclassification layer of any model, we are able to retrieve the most influentialfeatures via SE vector manipulation, one of the key components of the SE block.Our results show that this new SE-based interpretability can be applied tovarious models in image and video/multi-modal settings, namely biometrics offacial features with CelebA and behavioral biometrics using Active SpeakerDetection datasets. Furthermore, our proposal does not compromise modelperformance toward the original task, and has competitive results with currentinterpretability approaches in state-of-the-art object datasets, highlightingits robustness to perform in varying data aside from the biometric context.</description><author>Tiago Roxo, Joana C. Costa, Pedro R. M. Inácio, Hugo Proença</author><pubDate>Fri, 06 Dec 2024 15:47:53 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.05134v1</guid></item><item><title>Learning Hidden Physics and System Parameters with Deep Operator Networks</title><link>http://arxiv.org/abs/2412.05133v1</link><description>Big data is transforming scientific progress by enabling the discovery ofnovel models, enhancing existing frameworks, and facilitating preciseuncertainty quantification, while advancements in scientific machine learningcomplement this by providing powerful tools to solve inverse problems toidentify the complex systems where traditional methods falter due to sparse ornoisy data. We introduce two innovative neural operator frameworks tailored fordiscovering hidden physics and identifying unknown system parameters fromsparse measurements. The first framework integrates a popular neural operator,DeepONet, and a physics-informed neural network to capture the relationshipbetween sparse data and the underlying physics, enabling the accurate discoveryof a family of governing equations. The second framework focuses on systemparameter identification, leveraging a DeepONet pre-trained on sparse sensormeasurements to initialize a physics-constrained inverse model. Both frameworksexcel in handling limited data and preserving physical consistency.Benchmarking on the Burgers' equation and reaction-diffusion systemdemonstrates state-of-the-art performance, achieving average $L_2$ errors of$\mathcal{O}(10^{-2})$ for hidden physics discovery and absolute errors of$\mathcal{O}(10^{-3})$ for parameter identification. These results underscorethe frameworks' robustness, efficiency, and potential for solving complexscientific problems with minimal observational data.</description><author>Vijay Kag, Dibakar Roy Sarkar, Birupaksha Pal, Somdatta Goswami</author><pubDate>Fri, 06 Dec 2024 15:44:59 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.05133v1</guid></item><item><title>An end-to-end attention-based approach for learning on graphs</title><link>http://arxiv.org/abs/2402.10793v2</link><description>There has been a recent surge in transformer-based architectures for learningon graphs, mainly motivated by attention as an effective learning mechanism andthe desire to supersede handcrafted operators characteristic of message passingschemes. However, concerns over their empirical effectiveness, scalability, andcomplexity of the pre-processing steps have been raised, especially in relationto much simpler graph neural networks that typically perform on par with themacross a wide range of benchmarks. To tackle these shortcomings, we considergraphs as sets of edges and propose a purely attention-based approachconsisting of an encoder and an attention pooling mechanism. The encodervertically interleaves masked and vanilla self-attention modules to learn aneffective representations of edges, while allowing for tackling possiblemisspecifications in input graphs. Despite its simplicity, the approachoutperforms fine-tuned message passing baselines and recently proposedtransformer-based methods on more than 70 node and graph-level tasks, includingchallenging long-range benchmarks. Moreover, we demonstrate state-of-the-artperformance across different tasks, ranging from molecular to vision graphs,and heterophilous node classification. The approach also outperforms graphneural networks and transformers in transfer learning settings, and scales muchbetter than alternatives with a similar performance level or expressive power.</description><author>David Buterez, Jon Paul Janet, Dino Oglic, Pietro Lio</author><pubDate>Fri, 06 Dec 2024 15:44:46 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.10793v2</guid></item><item><title>GaussianFormer-2: Probabilistic Gaussian Superposition for Efficient 3D Occupancy Prediction</title><link>http://arxiv.org/abs/2412.04384v2</link><description>3D semantic occupancy prediction is an important task for robustvision-centric autonomous driving, which predicts fine-grained geometry andsemantics of the surrounding scene. Most existing methods leverage densegrid-based scene representations, overlooking the spatial sparsity of thedriving scenes. Although 3D semantic Gaussian serves as an object-centricsparse alternative, most of the Gaussians still describe the empty region withlow efficiency. To address this, we propose a probabilistic Gaussiansuperposition model which interprets each Gaussian as a probabilitydistribution of its neighborhood being occupied and conforms to probabilisticmultiplication to derive the overall geometry. Furthermore, we adopt the exactGaussian mixture model for semantics calculation to avoid unnecessaryoverlapping of Gaussians. To effectively initialize Gaussians in non-emptyregion, we design a distribution-based initialization module which learns thepixel-aligned occupancy distribution instead of the depth of surfaces. Weconduct extensive experiments on nuScenes and KITTI-360 datasets and ourGaussianFormer-2 achieves state-of-the-art performance with high efficiency.Code: https://github.com/huang-yh/GaussianFormer.</description><author>Yuanhui Huang, Amonnut Thammatadatrakoon, Wenzhao Zheng, Yunpeng Zhang, Dalong Du, Jiwen Lu</author><pubDate>Fri, 06 Dec 2024 15:43:40 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.04384v2</guid></item><item><title>EmbodiedOcc: Embodied 3D Occupancy Prediction for Vision-based Online Scene Understanding</title><link>http://arxiv.org/abs/2412.04380v2</link><description>3D occupancy prediction provides a comprehensive description of thesurrounding scenes and has become an essential task for 3D perception. Mostexisting methods focus on offline perception from one or a few views and cannotbe applied to embodied agents which demands to gradually perceive the scenethrough progressive embodied exploration. In this paper, we formulate anembodied 3D occupancy prediction task to target this practical scenario andpropose a Gaussian-based EmbodiedOcc framework to accomplish it. We initializethe global scene with uniform 3D semantic Gaussians and progressively updatelocal regions observed by the embodied agent. For each update, we extractsemantic and structural features from the observed image and efficientlyincorporate them via deformable cross-attention to refine the regionalGaussians. Finally, we employ Gaussian-to-voxel splatting to obtain the global3D occupancy from the updated 3D Gaussians. Our EmbodiedOcc assumes an unknown(i.e., uniformly distributed) environment and maintains an explicit globalmemory of it with 3D Gaussians. It gradually gains knowledge through the localrefinement of regional Gaussians, which is consistent with how humansunderstand new scenes through embodied exploration. We reorganize anEmbodiedOcc-ScanNet benchmark based on local annotations to facilitate theevaluation of the embodied 3D occupancy prediction task. Experimentsdemonstrate that our EmbodiedOcc outperforms existing local prediction methodsand accomplishes the embodied occupancy prediction with high accuracy andstrong expandability. Code: https://github.com/YkiWu/EmbodiedOcc.</description><author>Yuqi Wu, Wenzhao Zheng, Sicheng Zuo, Yuanhui Huang, Jie Zhou, Jiwen Lu</author><pubDate>Fri, 06 Dec 2024 15:43:38 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.04380v2</guid></item><item><title>xLSTM: Extended Long Short-Term Memory</title><link>http://arxiv.org/abs/2405.04517v2</link><description>In the 1990s, the constant error carousel and gating were introduced as thecentral ideas of the Long Short-Term Memory (LSTM). Since then, LSTMs havestood the test of time and contributed to numerous deep learning successstories, in particular they constituted the first Large Language Models (LLMs).However, the advent of the Transformer technology with parallelizableself-attention at its core marked the dawn of a new era, outpacing LSTMs atscale. We now raise a simple question: How far do we get in language modelingwhen scaling LSTMs to billions of parameters, leveraging the latest techniquesfrom modern LLMs, but mitigating known limitations of LSTMs? Firstly, weintroduce exponential gating with appropriate normalization and stabilizationtechniques. Secondly, we modify the LSTM memory structure, obtaining: (i) sLSTMwith a scalar memory, a scalar update, and new memory mixing, (ii) mLSTM thatis fully parallelizable with a matrix memory and a covariance update rule.Integrating these LSTM extensions into residual block backbones yields xLSTMblocks that are then residually stacked into xLSTM architectures. Exponentialgating and modified memory structures boost xLSTM capabilities to performfavorably when compared to state-of-the-art Transformers and State SpaceModels, both in performance and scaling.</description><author>Maximilian Beck, Korbinian Pöppel, Markus Spanring, Andreas Auer, Oleksandra Prudnikova, Michael Kopp, Günter Klambauer, Johannes Brandstetter, Sepp Hochreiter</author><pubDate>Fri, 06 Dec 2024 15:42:07 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.04517v2</guid></item><item><title>Stochastic Primal-Dual Three Operator Splitting Algorithm with Extension to Equivariant Regularization-by-Denoising</title><link>http://arxiv.org/abs/2208.01631v2</link><description>In this work we propose a stochastic primal-dual three-operator splittingalgorithm (TOS-SPDHG) for solving a class of convex three-compositeoptimization problems. Our proposed scheme is a direct three-operator splittingextension of the SPDHG algorithm [Chambolle et al. 2018]. We providetheoretical convergence analysis showing ergodic $O(1/K)$ convergence rate, anddemonstrate the effectiveness of our approach in imaging inverse problems.Moreover, we further propose TOS-SPDHG-RED and TOS-SPDHG-eRED which utilizesthe regularization-by-denoising (RED) framework to leverage pretrained deepdenoising networks as priors.</description><author>Junqi Tang, Matthias Ehrhardt, Carola-Bibiane Schönlieb</author><pubDate>Fri, 06 Dec 2024 15:41:07 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2208.01631v2</guid></item><item><title>LUDVIG: Learning-free Uplifting of 2D Visual features to Gaussian Splatting scenes</title><link>http://arxiv.org/abs/2410.14462v3</link><description>We address the problem of extending the capabilities of vision foundationmodels such as DINO, SAM, and CLIP, to 3D tasks. Specifically, we introduce anovel method to uplift 2D image features into 3D Gaussian Splatting scenes.Unlike traditional approaches that rely on minimizing a reconstruction loss,our method employs a simpler and more efficient feature aggregation technique,augmented by a graph diffusion mechanism. Graph diffusion enriches featuresfrom a given model, such as CLIP, by leveraging 3D geometry and pairwisesimilarities induced by another strong model such as DINOv2. Our approachachieves performance comparable to the state of the art on multiple downstreamtasks while delivering significant speed-ups. Notably, we obtain competitivesegmentation results using generic DINOv2 features, despite DINOv2 not beingtrained on millions of annotated segmentation masks like SAM. When applied toCLIP features, our method demonstrates strong performance in open-vocabularyobject detection tasks, highlighting the versatility of our approach.</description><author>Juliette Marrie, Romain Menegaux, Michael Arbel, Diane Larlus, Julien Mairal</author><pubDate>Fri, 06 Dec 2024 15:39:13 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.14462v3</guid></item><item><title>Dirac-Equation Signal Processing: Physics Boosts Topological Machine Learning</title><link>http://arxiv.org/abs/2412.05132v1</link><description>Topological signals are variables or features associated with both nodes andedges of a network. Recently, in the context of Topological Machine Learning,great attention has been devoted to signal processing of such topologicalsignals. Most of the previous topological signal processing algorithms treatnode and edge signals separately and work under the hypothesis that the truesignal is smooth and/or well approximated by a harmonic eigenvector of theHodge-Laplacian, which may be violated in practice. Here we proposeDirac-equation signal processing, a framework for efficiently reconstructingtrue signals on nodes and edges, also if they are not smooth or harmonic, byprocessing them jointly. The proposed physics-inspired algorithm is based onthe spectral properties of the topological Dirac operator. It leverages themathematical structure of the topological Dirac equation to boost theperformance of the signal processing algorithm. We discuss how the relativisticdispersion relation obeyed by the topological Dirac equation can be used toassess the quality of the signal reconstruction. Finally, we demonstrate theimproved performance of the algorithm with respect to previous algorithms.Specifically, we show that Dirac-equation signal processing can also be usedefficiently if the true signal is a non-trivial linear combination of more thanone eigenstate of the Dirac equation, as it generally occurs for real signals.</description><author>Runyue Wang, Yu Tian, Pietro Liò, Ginestra Bianconi</author><pubDate>Fri, 06 Dec 2024 15:38:58 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.05132v1</guid></item><item><title>Technology as uncharted territory: Contextual integrity and the notion of AI as new ethical ground</title><link>http://arxiv.org/abs/2412.05130v1</link><description>Recent research illustrates how AI can be developed and deployed in a mannerdetached from the concrete social context of application. By abstracting fromthe contexts of AI application, practitioners also disengage from the distinctnormative structures that govern them. Building upon Helen Nissenbaum'sframework of contextual integrity, I illustrate how disregard for contextualnorms can threaten the integrity of a context with often decisive ethicalimplications. I argue that efforts to promote responsible and ethical AI caninadvertently contribute to and seemingly legitimize this disregard forestablished contextual norms. Echoing a persistent undercurrent in technologyethics of understanding emerging technologies as uncharted moral territory,certain approaches to AI ethics can promote a notion of AI as a novel anddistinct realm for ethical deliberation, norm setting, and virtue cultivation.This narrative of AI as new ethical ground, however, can come at the expense ofpractitioners, policymakers and ethicists engaging with already establishednorms and virtues that were gradually cultivated to promote successful andresponsible practice within concrete social contexts. In response, I questionthe current narrow prioritization in AI ethics of moral innovation over moralpreservation. Engaging also with emerging foundation models, I advocate for amoderately conservative approach to the ethics of AI that prioritizes theresponsible and considered integration of AI within established social contextsand their respective normative structures.</description><author>Alexander Martin Mussgnug</author><pubDate>Fri, 06 Dec 2024 15:36:13 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.05130v1</guid></item><item><title>The Prompt Canvas: A Literature-Based Practitioner Guide for Creating Effective Prompts in Large Language Models</title><link>http://arxiv.org/abs/2412.05127v1</link><description>The rise of large language models (LLMs) has highlighted the importance ofprompt engineering as a crucial technique for optimizing model outputs. Whileexperimentation with various prompting methods, such as Few-shot,Chain-of-Thought, and role-based techniques, has yielded promising results,these advancements remain fragmented across academic papers, blog posts andanecdotal experimentation. The lack of a single, unified resource toconsolidate the field's knowledge impedes the progress of both research andpractical application. This paper argues for the creation of an overarchingframework that synthesizes existing methodologies into a cohesive overview forpractitioners. Using a design-based research approach, we present the PromptCanvas, a structured framework resulting from an extensive literature review onprompt engineering that captures current knowledge and expertise. By combiningthe conceptual foundations and practical strategies identified in promptengineering, the Prompt Canvas provides a practical approach for leveraging thepotential of Large Language Models. It is primarily designed as a learningresource for pupils, students and employees, offering a structured introductionto prompt engineering. This work aims to contribute to the growing discourse onprompt engineering by establishing a unified methodology for researchers andproviding guidance for practitioners.</description><author>Michael Hewing, Vincent Leinhos</author><pubDate>Fri, 06 Dec 2024 15:35:18 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.05127v1</guid></item><item><title>Robust Computation with Intrinsic Heterogeneity</title><link>http://arxiv.org/abs/2412.05126v1</link><description>Intrinsic within-type neuronal heterogeneity is a ubiquitous feature ofbiological systems, with well-documented computational advantages. Recent worksin machine learning have incorporated such diversities by optimizing neuronalparameters alongside synaptic connections and demonstrated state-of-the-artperformance across common benchmarks. However, this performance gain comes atthe cost of significantly higher computational costs, imposed by a largerparameter space. Furthermore, it is unclear how the neuronal parameters,constrained by the biophysics of their surroundings, are globally orchestratedto minimize top-down errors. To address these challenges, we postulate thatneurons are intrinsically diverse, and investigate the computationalcapabilities of such heterogeneous neuronal parameters. Our results show thatintrinsic heterogeneity, viewed as a fixed quenched disorder, oftensubstantially improves performance across hundreds of temporal tasks. Notably,smaller but heterogeneous networks outperform larger homogeneous networks,despite consuming less data. We elucidate the underlying mechanisms drivingthis performance boost and illustrate its applicability to both rate andspiking dynamics. Moreover, our findings demonstrate that heterogeneousnetworks are highly resilient to severe alterations in their recurrent synaptichyperparameters, and even recurrent connections removal does not compromiseperformance. The remarkable effectiveness of heterogeneous networks with smallsizes and relaxed connectivity is particularly relevant for the neuromorphiccommunity, which faces challenges due to device-to-device variability.Furthermore, understanding the mechanism of robust computation withheterogeneity also benefits neuroscientists and machine learners.</description><author>Arash Golmohammadi, Christian Tetzlaff</author><pubDate>Fri, 06 Dec 2024 15:34:58 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.05126v1</guid></item></channel></rss>