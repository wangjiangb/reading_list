<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/"><channel><title>Arxivfresh papers</title><link></link><description>Arxiv paper</description><language>en-US</language><lastBuildDate>Fri, 26 Jul 2024 13:00:19 GMT</lastBuildDate><generator>rfeed v1.0.0</generator><docs>https://github.com/svpino/rfeed/blob/master/README.md</docs><item><title>Sparse vs Contiguous Adversarial Pixel Perturbations in Multimodal Models: An Empirical Analysis</title><link>http://arxiv.org/abs/2407.18251v1</link><description>Assessing the robustness of multimodal models against adversarial examples isan important aspect for the safety of its users. We craft L0-norm perturbationattacks on the preprocessed input images. We launch them in a black-box setupagainst four multimodal models and two unimodal DNNs, considering both targetedand untargeted misclassification. Our attacks target less than 0.04% ofperturbed image area and integrate different spatial positioning of perturbedpixels: sparse positioning and pixels arranged in different contiguous shapes(row, column, diagonal, and patch). To the best of our knowledge, we are thefirst to assess the robustness of three state-of-the-art multimodal models(ALIGN, AltCLIP, GroupViT) against different sparse and contiguous pixeldistribution perturbations. The obtained results indicate that unimodal DNNsare more robust than multimodal models. Furthermore, models using CNN-basedImage Encoder are more vulnerable than models with ViT - for untargetedattacks, we obtain a 99% success rate by perturbing less than 0.02% of theimage area.</description><author>Cristian-Alexandru Botocan, Raphael Meier, Ljiljana Dolamic</author><pubDate>Thu, 25 Jul 2024 17:59:48 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.18251v1</guid></item><item><title>Trajectory-aligned Space-time Tokens for Few-shot Action Recognition</title><link>http://arxiv.org/abs/2407.18249v1</link><description>We propose a simple yet effective approach for few-shot action recognition,emphasizing the disentanglement of motion and appearance representations. Byharnessing recent progress in tracking, specifically point trajectories andself-supervised representation learning, we build trajectory-aligned tokens(TATs) that capture motion and appearance information. This approachsignificantly reduces the data requirements while retaining essentialinformation. To process these representations, we use a Masked Space-timeTransformer that effectively learns to aggregate information to facilitatefew-shot action recognition. We demonstrate state-of-the-art results onfew-shot action recognition across multiple datasets. Our project page isavailable at https://www.cs.umd.edu/~pulkit/tats</description><author>Pulkit Kumar, Namitha Padmanabhan, Luke Luo, Sai Saketh Rambhatla, Abhinav Shrivastava</author><pubDate>Thu, 25 Jul 2024 17:59:31 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.18249v1</guid></item><item><title>Self-Training with Direct Preference Optimization Improves Chain-of-Thought Reasoning</title><link>http://arxiv.org/abs/2407.18248v1</link><description>Effective training of language models (LMs) for mathematical reasoning tasksdemands high-quality supervised fine-tuning data. Besides obtaining annotationsfrom human experts, a common alternative is sampling from larger and morepowerful LMs. However, this knowledge distillation approach can be costly andunstable, particularly when relying on closed-source, proprietary LMs likeGPT-4, whose behaviors are often unpredictable. In this work, we demonstratethat the reasoning abilities of small-scale LMs can be enhanced throughself-training, a process where models learn from their own outputs. We alsoshow that the conventional self-training can be further augmented by apreference learning algorithm called Direct Preference Optimization (DPO). Byintegrating DPO into self-training, we leverage preference data to guide LMstowards more accurate and diverse chain-of-thought reasoning. We evaluate ourmethod across various mathematical reasoning tasks using different base models.Our experiments show that this approach not only improves LMs' reasoningperformance but also offers a more cost-effective and scalable solutioncompared to relying on large proprietary LMs.</description><author>Tianduo Wang, Shichen Li, Wei Lu</author><pubDate>Thu, 25 Jul 2024 17:59:16 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.18248v1</guid></item><item><title>RegionDrag: Fast Region-Based Image Editing with Diffusion Models</title><link>http://arxiv.org/abs/2407.18247v1</link><description>Point-drag-based image editing methods, like DragDiffusion, have attractedsignificant attention. However, point-drag-based approaches suffer fromcomputational overhead and misinterpretation of user intentions due to thesparsity of point-based editing instructions. In this paper, we propose aregion-based copy-and-paste dragging method, RegionDrag, to overcome theselimitations. RegionDrag allows users to express their editing instructions inthe form of handle and target regions, enabling more precise control andalleviating ambiguity. In addition, region-based operations complete editing inone iteration and are much faster than point-drag-based methods. We alsoincorporate the attention-swapping technique for enhanced stability duringediting. To validate our approach, we extend existing point-drag-based datasetswith region-based dragging instructions. Experimental results demonstrate thatRegionDrag outperforms existing point-drag-based approaches in terms of speed,accuracy, and alignment with user intentions. Remarkably, RegionDrag completesthe edit on an image with a resolution of 512x512 in less than 2 seconds, whichis more than 100x faster than DragDiffusion, while achieving betterperformance. Project page: https://visual-ai.github.io/regiondrag.</description><author>Jingyi Lu, Xinghui Li, Kai Han</author><pubDate>Thu, 25 Jul 2024 17:59:13 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.18247v1</guid></item><item><title>VGGHeads: A Large-Scale Synthetic Dataset for 3D Human Heads</title><link>http://arxiv.org/abs/2407.18245v1</link><description>Human head detection, keypoint estimation, and 3D head model fitting areimportant tasks with many applications. However, traditional real-worlddatasets often suffer from bias, privacy, and ethical concerns, and they havebeen recorded in laboratory environments, which makes it difficult for trainedmodels to generalize. Here, we introduce VGGHeads -- a large scale syntheticdataset generated with diffusion models for human head detection and 3D meshestimation. Our dataset comprises over 1 million high-resolution images, eachannotated with detailed 3D head meshes, facial landmarks, and bounding boxes.Using this dataset we introduce a new model architecture capable ofsimultaneous heads detection and head meshes reconstruction from a single imagein a single step. Through extensive experimental evaluations, we demonstratethat models trained on our synthetic data achieve strong performance on realimages. Furthermore, the versatility of our dataset makes it applicable acrossa broad spectrum of tasks, offering a general and comprehensive representationof human heads. Additionally, we provide detailed information about thesynthetic data generation pipeline, enabling it to be re-used for other tasksand domains.</description><author>Orest Kupyn, Eugene Khvedchenia, Christian Rupprecht</author><pubDate>Thu, 25 Jul 2024 17:58:17 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.18245v1</guid></item><item><title>RefMask3D: Language-Guided Transformer for 3D Referring Segmentation</title><link>http://arxiv.org/abs/2407.18244v1</link><description>3D referring segmentation is an emerging and challenging vision-language taskthat aims to segment the object described by a natural language expression in apoint cloud scene. The key challenge behind this task is vision-languagefeature fusion and alignment. In this work, we propose RefMask3D to explore thecomprehensive multi-modal feature interaction and understanding. First, wepropose a Geometry-Enhanced Group-Word Attention to integrate language withgeometrically coherent sub-clouds through cross-modal group-word attention,which effectively addresses the challenges posed by the sparse and irregularnature of point clouds. Then, we introduce a Linguistic Primitives Constructionto produce semantic primitives representing distinct semantic attributes, whichgreatly enhance the vision-language understanding at the decoding stage.Furthermore, we introduce an Object Cluster Module that analyzes theinterrelationships among linguistic primitives to consolidate their insightsand pinpoint common characteristics, helping to capture holistic informationand enhance the precision of target identification. The proposed RefMask3Dachieves new state-of-the-art performance on 3D referring segmentation, 3Dvisual grounding, and also 2D referring image segmentation. Especially,RefMask3D outperforms previous state-of-the-art method by a large margin of3.16% mIoU} on the challenging ScanRefer dataset. Code is available athttps://github.com/heshuting555/RefMask3D.</description><author>Shuting He, Henghui Ding</author><pubDate>Thu, 25 Jul 2024 17:58:03 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.18244v1</guid></item><item><title>BIV-Priv-Seg: Locating Private Content in Images Taken by People With Visual Impairments</title><link>http://arxiv.org/abs/2407.18243v1</link><description>Individuals who are blind or have low vision (BLV) are at a heightened riskof sharing private information if they share photographs they have taken. Tofacilitate developing technologies that can help preserve privacy, we introduceBIV-Priv-Seg, the first localization dataset originating from people withvisual impairments that shows private content. It contains 1,028 images withsegmentation annotations for 16 private object categories. We firstcharacterize BIV-Priv-Seg and then evaluate modern models' performance forlocating private content in the dataset. We find modern models struggle mostwith locating private objects that are not salient, small, and lack text aswell as recognizing when private content is absent from an image. We facilitatefuture extensions by sharing our new dataset with the evaluation server athttps://vizwiz.org/tasks-and-datasets/object-localization.</description><author>Yu-Yun Tseng, Tanusree Sharma, Lotus Zhang, Abigale Stangl, Leah Findlater, Yang Wang, Danna Gurari Yu-Yun Tseng, Tanusree Sharma, Lotus Zhang, Abigale Stangl, Leah Findlater, Yang Wang, Danna Gurari</author><pubDate>Thu, 25 Jul 2024 17:57:48 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.18243v1</guid></item><item><title>LoRA-Pro: Are Low-Rank Adapters Properly Optimized?</title><link>http://arxiv.org/abs/2407.18242v1</link><description>Low-Rank Adaptation, also known as LoRA, has emerged as a prominent methodfor parameter-efficient fine-tuning foundation models by re-parameterizing theoriginal matrix into the product of two low-rank matrices. Despite itsefficiency, LoRA often yields inferior performance compared to fullfine-tuning. In this paper, we propose LoRA-Pro to bridge this performance gap.Firstly, we delve into the optimization processes in LoRA and full fine-tuning.We reveal that while LoRA employs low-rank approximation, it neglects toapproximate the optimization process of full fine-tuning. To address this, weintroduce a novel concept called the "equivalent gradient." This virtualgradient makes the optimization process on the re-parameterized matrixequivalent to LoRA, which can be used to quantify the differences between LoRAand full fine-tuning. The equivalent gradient is derived from the gradients ofmatrices $A$ and $B$. To narrow the performance gap, our approach minimizes thedifferences between the equivalent gradient and the gradient obtained from fullfine-tuning during the optimization process. By solving this objective, wederive optimal closed-form solutions for updating matrices $A$ and $B$. Ourmethod constrains the optimization process, shrinking the performance gapbetween LoRA and full fine-tuning. Extensive experiments on natural languageprocessing tasks validate the effectiveness of our method.</description><author>Zhengbo Wang, Jian Liang</author><pubDate>Thu, 25 Jul 2024 17:57:12 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.18242v1</guid></item><item><title>Numerical Literals in Link Prediction: A Critical Examination of Models and Datasets</title><link>http://arxiv.org/abs/2407.18241v1</link><description>Link Prediction(LP) is an essential task over Knowledge Graphs(KGs),traditionally focussed on using and predicting the relations between entities.Textual entity descriptions have already been shown to be valuable, but modelsthat incorporate numerical literals have shown minor improvements on existingbenchmark datasets. It is unclear whether a model is actually better in usingnumerical literals, or better capable of utilizing the graph structure. Thisraises doubts about the effectiveness of these methods and about thesuitability of the existing benchmark datasets. We propose a methodology to evaluate LP models that incorporate numericalliterals. We propose i) a new synthetic dataset to better understand how wellthese models use numerical literals and ii) dataset ablations strategies toinvestigate potential difficulties with the existing datasets. We identify aprevalent trend: many models underutilize literal information and potentiallyrely on additional parameters for performance gains. Our investigationhighlights the need for more extensive evaluations when releasing new modelsand datasets.</description><author>Moritz Blum, Basil Ell, Hannes Ill, Philipp Cimiano</author><pubDate>Thu, 25 Jul 2024 17:55:33 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.18241v1</guid></item><item><title>CodedVO: Coded Visual Odometry</title><link>http://arxiv.org/abs/2407.18240v1</link><description>Autonomous robots often rely on monocular cameras for odometry estimation andnavigation. However, the scale ambiguity problem presents a critical barrier toeffective monocular visual odometry. In this paper, we present CodedVO, a novelmonocular visual odometry method that overcomes the scale ambiguity problem byemploying custom optics to physically encode metric depth information intoimagery. By incorporating this information into our odometry pipeline, weachieve state-of-the-art performance in monocular visual odometry with a knownscale. We evaluate our method in diverse indoor environments and demonstrateits robustness and adaptability. We achieve a 0.08m average trajectory error inodometry evaluation on the ICL-NUIM indoor odometry dataset.</description><author>Sachin Shah, Naitri Rajyaguru, Chahat Deep Singh, Christopher Metzler, Yiannis Aloimonos</author><pubDate>Thu, 25 Jul 2024 17:54:58 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.18240v1</guid></item><item><title>Dr. Jekyll and Mr. Hyde: Two Faces of LLMs</title><link>http://arxiv.org/abs/2312.03853v4</link><description>Recently, we have witnessed a rise in the use of Large Language Models(LLMs), especially in applications like chatbot assistants. Safety mechanismsand specialized training procedures are implemented to prevent improperresponses from these assistants. In this work, we bypass these measures forChatGPT and Gemini (and, to some extent, Bing chat) by making them impersonatecomplex personas with personality characteristics that are not aligned with atruthful assistant. We start by creating elaborate biographies of thesepersonas, which we then use in a new session with the same chatbots. Ourconversations then follow a role-play style to elicit prohibited responses.Using personas, we show that prohibited responses are actually provided, makingit possible to obtain unauthorized, illegal, or harmful information. This workshows that by using adversarial personas, one can overcome safety mechanismsset out by ChatGPT and Gemini. We also introduce several ways of activatingsuch adversarial personas, which show that both chatbots are vulnerable to thiskind of attack. With the same principle, we introduce two defenses that pushthe model to interpret trustworthy personalities and make it more robustagainst such attacks.</description><author>Matteo Gioele Collu, Tom Janssen-Groesbeek, Stefanos Koffas, Mauro Conti, Stjepan Picek</author><pubDate>Thu, 25 Jul 2024 17:54:12 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.03853v4</guid></item><item><title>Can time series forecasting be automated? A benchmark and analysis</title><link>http://arxiv.org/abs/2407.16445v2</link><description>In the field of machine learning and artificial intelligence, time seriesforecasting plays a pivotal role across various domains such as finance,healthcare, and weather. However, the task of selecting the most suitableforecasting method for a given dataset is a complex task due to the diversityof data patterns and characteristics. This research aims to address thischallenge by proposing a comprehensive benchmark for evaluating and rankingtime series forecasting methods across a wide range of datasets. This studyinvestigates the comparative performance of many methods from two prominenttime series forecasting frameworks, AutoGluon-Timeseries, and sktime to shedlight on their applicability in different real-world scenarios. This researchcontributes to the field of time series forecasting by providing a robustbenchmarking methodology and facilitating informed decision-making whenchoosing forecasting methods for achieving optimal prediction.</description><author>Anvitha Thirthapura Sreedhara, Joaquin Vanschoren</author><pubDate>Thu, 25 Jul 2024 17:53:38 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.16445v2</guid></item><item><title>Block Verification Accelerates Speculative Decoding</title><link>http://arxiv.org/abs/2403.10444v2</link><description>Speculative decoding is an effective method for lossless acceleration oflarge language models during inference. It uses a fast model to draft a blockof tokens which are then verified in parallel by the target model, and providesa guarantee that the output is distributed identically to a sample from thetarget model. In prior works, draft verification is performed independentlytoken-by-token. Surprisingly, we show that this approach is not optimal. Wepropose Block Verification, a simple draft verification algorithm that verifiesthe entire block jointly and provides additional wall-clock speedup. We provethat the proposed mechanism is optimal in the expected number of tokensproduced each iteration and specifically is never worse than the standardtoken-level verification. Empirically, block verification provides modest butconsistent wall-clock speedups over the standard token verification algorithmof 5%-8% in a range of tasks and datasets. Given that block verification doesnot increase code complexity, maintains the strong lossless guarantee of thestandard speculative decoding verification algorithm, cannot deteriorateperformance, and, in fact, consistently improves it, it can be used as a gooddefault in speculative decoding implementations.</description><author>Ziteng Sun, Uri Mendlovic, Yaniv Leviathan, Asaf Aharoni, Ahmad Beirami, Jae Hun Ro, Ananda Theertha Suresh</author><pubDate>Thu, 25 Jul 2024 17:51:50 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.10444v2</guid></item><item><title>LION: Linear Group RNN for 3D Object Detection in Point Clouds</title><link>http://arxiv.org/abs/2407.18232v1</link><description>The benefit of transformers in large-scale 3D point cloud perception tasks,such as 3D object detection, is limited by their quadratic computation costwhen modeling long-range relationships. In contrast, linear RNNs have lowcomputational complexity and are suitable for long-range modeling. Toward thisgoal, we propose a simple and effective window-based framework built on LIneargrOup RNN (i.e., perform linear RNN for grouped features) for accurate 3Dobject detection, called LION. The key property is to allow sufficient featureinteraction in a much larger group than transformer-based methods. However,effectively applying linear group RNN to 3D object detection in highly sparsepoint clouds is not trivial due to its limitation in handling spatial modeling.To tackle this problem, we simply introduce a 3D spatial feature descriptor andintegrate it into the linear group RNN operators to enhance their spatialfeatures rather than blindly increasing the number of scanning orders for voxelfeatures. To further address the challenge in highly sparse point clouds, wepropose a 3D voxel generation strategy to densify foreground features thanks tolinear group RNN as a natural property of auto-regressive models. Extensiveexperiments verify the effectiveness of the proposed components and thegeneralization of our LION on different linear group RNN operators includingMamba, RWKV, and RetNet. Furthermore, it is worth mentioning that ourLION-Mamba achieves state-of-the-art on Waymo, nuScenes, Argoverse V2, and ONCEdataset. Last but not least, our method supports kinds of advanced linear RNNoperators (e.g., RetNet, RWKV, Mamba, xLSTM and TTT) on small but popular KITTIdataset for a quick experience with our linear RNN-based framework.</description><author>Zhe Liu, Jinghua Hou, Xinyu Wang, Xiaoqing Ye, Jingdong Wang, Hengshuang Zhao, Xiang Bai</author><pubDate>Thu, 25 Jul 2024 17:50:32 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.18232v1</guid></item><item><title>Streetscapes: Large-scale Consistent Street View Generation Using Autoregressive Video Diffusion</title><link>http://arxiv.org/abs/2407.13759v2</link><description>We present a method for generating Streetscapes-long sequences of viewsthrough an on-the-fly synthesized city-scale scene. Our generation isconditioned by language input (e.g., city name, weather), as well as anunderlying map/layout hosting the desired trajectory. Compared to recent modelsfor video generation or 3D view synthesis, our method can scale to muchlonger-range camera trajectories, spanning several city blocks, whilemaintaining visual quality and consistency. To achieve this goal, we build onrecent work on video diffusion, used within an autoregressive framework thatcan easily scale to long sequences. In particular, we introduce a new temporalimputation method that prevents our autoregressive approach from drifting fromthe distribution of realistic city imagery. We train our Streetscapes system ona compelling source of data-posed imagery from Google Street View, along withcontextual map data-which allows users to generate city views conditioned onany desired city layout, with controllable camera poses. Please see moreresults at our project page at https://boyangdeng.com/streetscapes.</description><author>Boyang Deng, Richard Tucker, Zhengqi Li, Leonidas Guibas, Noah Snavely, Gordon Wetzstein</author><pubDate>Thu, 25 Jul 2024 17:47:20 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.13759v2</guid></item><item><title>Automated Ensemble Multimodal Machine Learning for Healthcare</title><link>http://arxiv.org/abs/2407.18227v1</link><description>The application of machine learning in medicine and healthcare has led to thecreation of numerous diagnostic and prognostic models. However, despite theirsuccess, current approaches generally issue predictions using data from asingle modality. This stands in stark contrast with clinician decision-makingwhich employs diverse information from multiple sources. While severalmultimodal machine learning approaches exist, significant challenges indeveloping multimodal systems remain that are hindering clinical adoption. Inthis paper, we introduce a multimodal framework, AutoPrognosis-M, that enablesthe integration of structured clinical (tabular) data and medical imaging usingautomated machine learning. AutoPrognosis-M incorporates 17 imaging models,including convolutional neural networks and vision transformers, and threedistinct multimodal fusion strategies. In an illustrative application using amultimodal skin lesion dataset, we highlight the importance of multimodalmachine learning and the power of combining multiple fusion strategies usingensemble learning. We have open-sourced our framework as a tool for thecommunity and hope it will accelerate the uptake of multimodal machine learningin healthcare and spur further innovation.</description><author>Fergus Imrie, Stefan Denner, Lucas S. Brunschwig, Klaus Maier-Hein, Mihaela van der Schaar</author><pubDate>Thu, 25 Jul 2024 17:46:38 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.18227v1</guid></item><item><title>Recursive Introspection: Teaching Language Model Agents How to Self-Improve</title><link>http://arxiv.org/abs/2407.18219v1</link><description>A central piece in enabling intelligent agentic behavior in foundation modelsis to make them capable of introspecting upon their behavior, reasoning, andcorrecting their mistakes as more computation or interaction is available. Eventhe strongest proprietary large language models (LLMs) do not quite exhibit theability of continually improving their responses sequentially, even inscenarios where they are explicitly told that they are making a mistake. Inthis paper, we develop RISE: Recursive IntroSpEction, an approach forfine-tuning LLMs to introduce this capability, despite prior work hypothesizingthat this capability may not be possible to attain. Our approach prescribes aniterative fine-tuning procedure, which attempts to teach the model how to alterits response after having executed previously unsuccessful attempts to solve ahard test-time problem, with optionally additional environment feedback. RISEposes fine-tuning for a single-turn prompt as solving a multi-turn Markovdecision process (MDP), where the initial state is the prompt. Inspired byprinciples in online imitation learning and reinforcement learning, we proposestrategies for multi-turn data collection and training so as to imbue an LLMwith the capability to recursively detect and correct its previous mistakes insubsequent iterations. Our experiments show that RISE enables Llama2, Llama3,and Mistral models to improve themselves with more turns on math reasoningtasks, outperforming several single-turn strategies given an equal amount ofinference-time computation. We also find that RISE scales well, often attaininglarger benefits with more capable models. Our analysis shows that RISE makesmeaningful improvements to responses to arrive at the correct solution forchallenging prompts, without disrupting one-turn abilities as a result ofexpressing more complex distributions.</description><author>Yuxiao Qu, Tianjun Zhang, Naman Garg, Aviral Kumar</author><pubDate>Thu, 25 Jul 2024 17:35:59 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.18219v1</guid></item><item><title>An NKCS Model of Bookchins Communalism</title><link>http://arxiv.org/abs/2407.18218v1</link><description>The NKCS model was introduced to explore coevolutionary systems, that is,systems in which multiple species are closely interconnected. The fitnesslandscapes of the species are coupled to a controllable amount, where theunderlying properties of the individual landscapes are also controllable. Noprevious work has explored the use of hierarchical control within the model.This paper explores the effects of using a confederation, based on Bookchinscommunalism, and a single point of global control. Significant changes inbehaviour from the traditional model are seen across the parameter space.</description><author>Larry Bull</author><pubDate>Thu, 25 Jul 2024 17:35:11 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.18218v1</guid></item><item><title>Castling-ViT: Compressing Self-Attention via Switching Towards Linear-Angular Attention at Vision Transformer Inference</title><link>http://arxiv.org/abs/2211.10526v5</link><description>Vision Transformers (ViTs) have shown impressive performance but stillrequire a high computation cost as compared to convolutional neural networks(CNNs), one reason is that ViTs' attention measures global similarities andthus has a quadratic complexity with the number of input tokens. Existingefficient ViTs adopt local attention (e.g., Swin) or linear attention (e.g.,Performer), which sacrifice ViTs' capabilities of capturing either global orlocal context. In this work, we ask an important research question: Can ViTslearn both global and local context while being more efficient duringinference? To this end, we propose a framework called Castling-ViT, whichtrains ViTs using both linear-angular attention and masked softmax-basedquadratic attention, but then switches to having only linear angular attentionduring ViT inference. Our Castling-ViT leverages angular kernels to measure thesimilarities between queries and keys via spectral angles. And we furthersimplify it with two techniques: (1) a novel linear-angular attentionmechanism: we decompose the angular kernels into linear terms and high-orderresiduals, and only keep the linear terms; and (2) we adopt two parameterizedmodules to approximate high-order residuals: a depthwise convolution and anauxiliary masked softmax attention to help learn both global and localinformation, where the masks for softmax attention are regularized to graduallybecome zeros and thus incur no overhead during ViT inference. Extensiveexperiments and ablation studies on three tasks consistently validate theeffectiveness of the proposed Castling-ViT, e.g., achieving up to a 1.8% higheraccuracy or 40% MACs reduction on ImageNet classification and 1.2 higher mAP onCOCO detection under comparable FLOPs, as compared to ViTs with vanillasoftmax-based attentions.</description><author>Haoran You, Yunyang Xiong, Xiaoliang Dai, Bichen Wu, Peizhao Zhang, Haoqi Fan, Peter Vajda, Yingyan Celine Lin</author><pubDate>Thu, 25 Jul 2024 17:29:22 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2211.10526v5</guid></item><item><title>Exploring Scaling Trends in LLM Robustness</title><link>http://arxiv.org/abs/2407.18213v1</link><description>Language model capabilities predictably improve from scaling a model's sizeand training data. Motivated by this, increasingly large language models havebeen trained, yielding an array of impressive capabilities. Yet these modelsare vulnerable to adversarial prompts, such as "jailbreaks" that hijack modelsto perform undesired behaviors, posing a significant risk of misuse. Prior workindicates that computer vision models become more robust with model and datascaling, raising the question: does language model robustness also improve withscale? We study this question empirically, finding that larger models respondsubstantially better to adversarial training, but there is little to no benefitfrom model scale in the absence of explicit defenses.</description><author>Nikolhaus Howe, Michał Zajac, Ian McKenzie, Oskar Hollinsworth, Tom Tseng, Pierre-Luc Bacon, Adam Gleave</author><pubDate>Thu, 25 Jul 2024 17:26:41 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.18213v1</guid></item><item><title>ShiftAddLLM: Accelerating Pretrained LLMs via Post-Training Multiplication-Less Reparameterization</title><link>http://arxiv.org/abs/2406.05981v3</link><description>Large language models (LLMs) have shown impressive performance on languagetasks but face challenges when deployed on resource-constrained devices due totheir extensive parameters and reliance on dense multiplications, resulting inhigh memory demands and latency bottlenecks. Shift-and-add reparameterizationoffers a promising solution by replacing costly multiplications withhardware-friendly primitives in both the attention and multi-layer perceptron(MLP) layers of an LLM. However, current reparameterization techniques requiretraining from scratch or full parameter fine-tuning to restore accuracy, whichis resource-intensive for LLMs. To address this, we propose acceleratingpretrained LLMs through post-training shift-and-add reparameterization,creating efficient multiplication-free models, dubbed ShiftAddLLM.Specifically, we quantize each weight matrix into binary matrices paired withgroup-wise scaling factors. The associated multiplications are reparameterizedinto (1) shifts between activations and scaling factors and (2) queries andadds according to the binary matrices. To reduce accuracy loss, we present amulti-objective optimization method to minimize both weight and outputactivation reparameterization errors. Additionally, based on varyingsensitivity across layers to reparameterization, we develop an automated bitallocation strategy to further reduce memory usage and latency. Experiments onfive LLM families and eight tasks consistently validate the effectiveness ofShiftAddLLM, achieving average perplexity improvements of 5.6 and 22.7 pointsat comparable or lower latency compared to the most competitive quantized LLMsat 3 and 2 bits, respectively, and more than 80% memory and energy reductionsover the original LLMs. Codes and models are available athttps://github.com/GATECH-EIC/ShiftAddLLM.</description><author>Haoran You, Yipin Guo, Yichao Fu, Wei Zhou, Huihong Shi, Xiaofan Zhang, Souvik Kundu, Amir Yazdanbakhsh, Yingyan Celine Lin</author><pubDate>Thu, 25 Jul 2024 17:20:48 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.05981v3</guid></item><item><title>ShiftAddViT: Mixture of Multiplication Primitives Towards Efficient Vision Transformer</title><link>http://arxiv.org/abs/2306.06446v6</link><description>Vision Transformers (ViTs) have shown impressive performance and have becomea unified backbone for multiple vision tasks. However, both the attentionmechanism and multi-layer perceptrons (MLPs) in ViTs are not sufficientlyefficient due to dense multiplications, leading to costly training andinference. To this end, we propose to reparameterize pre-trained ViTs with amixture of multiplication primitives, e.g., bitwise shifts and additions,towards a new type of multiplication-reduced model, dubbed$\textbf{ShiftAddViT}$, which aims to achieve end-to-end inference speedups onGPUs without requiring training from scratch. Specifically, all$\texttt{MatMuls}$ among queries, keys, and values are reparameterized usingadditive kernels, after mapping queries and keys to binary codes in Hammingspace. The remaining MLPs or linear layers are then reparameterized with shiftkernels. We utilize TVM to implement and optimize those customized kernels forpractical hardware deployment on GPUs. We find that such a reparameterizationon attention maintains model accuracy, while inevitably leading to accuracydrops when being applied to MLPs. To marry the best of both worlds, we furtherpropose a new mixture of experts (MoE) framework to reparameterize MLPs bytaking multiplication or its primitives as experts, e.g., multiplication andshift, and designing a new latency-aware load-balancing loss. Such a loss helpsto train a generic router for assigning a dynamic amount of input tokens todifferent experts according to their latency. Extensive experiments on various2D/3D Transformer-based vision tasks consistently validate the effectiveness ofour proposed ShiftAddViT, achieving up to $\textbf{5.18$\times$}$ latencyreductions on GPUs and $\textbf{42.9}$% energy savings, while maintaining acomparable accuracy as original or efficient ViTs.</description><author>Haoran You, Huihong Shi, Yipin Guo, Yingyan Celine Lin</author><pubDate>Thu, 25 Jul 2024 17:19:31 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.06446v6</guid></item><item><title>When Linear Attention Meets Autoregressive Decoding: Towards More Effective and Efficient Linearized Large Language Models</title><link>http://arxiv.org/abs/2406.07368v2</link><description>Autoregressive Large Language Models (LLMs) have achieved impressiveperformance in language tasks but face two significant bottlenecks: (1)quadratic complexity in the attention module as the number of tokens increases,and (2) limited efficiency due to the sequential processing nature ofautoregressive LLMs during generation. While linear attention and speculativedecoding offer potential solutions, their applicability and synergisticpotential for enhancing autoregressive LLMs remain uncertain. We conduct thefirst comprehensive study on the efficacy of existing linear attention methodsfor autoregressive LLMs, integrating them with speculative decoding. Weintroduce an augmentation technique for linear attention that ensurescompatibility with speculative decoding, enabling more efficient training andserving of LLMs. Extensive experiments and ablation studies involving sevenexisting linear attention models and five encoder/decoder-based LLMsconsistently validate the effectiveness of our augmented linearized LLMs.Notably, our approach achieves up to a 6.67 reduction in perplexity on theLLaMA model and up to a 2$\times$ speedup during generation compared to priorlinear attention methods. Codes and models are available athttps://github.com/GATECH-EIC/Linearized-LLM.</description><author>Haoran You, Yichao Fu, Zheng Wang, Amir Yazdanbakhsh, Yingyan Celine Lin</author><pubDate>Thu, 25 Jul 2024 17:18:01 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.07368v2</guid></item><item><title>Geometry Fidelity for Spherical Images</title><link>http://arxiv.org/abs/2407.18207v1</link><description>Spherical or omni-directional images offer an immersive visual formatappealing to a wide range of computer vision applications. However, geometricproperties of spherical images pose a major challenge for models and metricsdesigned for ordinary 2D images. Here, we show that direct application ofFr\'echet Inception Distance (FID) is insufficient for quantifying geometricfidelity in spherical images. We introduce two quantitative metrics accountingfor geometric constraints, namely Omnidirectional FID (OmniFID) andDiscontinuity Score (DS). OmniFID is an extension of FID tailored toadditionally capture field-of-view requirements of the spherical format byleveraging cubemap projections. DS is a kernel-based seam alignment score ofcontinuity across borders of 2D representations of spherical images. Inexperiments, OmniFID and DS quantify geometry fidelity issues that areundetected by FID.</description><author>Anders Christensen, Nooshin Mojab, Khushman Patel, Karan Ahuja, Zeynep Akata, Ole Winther, Mar Gonzalez-Franco, Andrea Colaco</author><pubDate>Thu, 25 Jul 2024 17:17:10 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.18207v1</guid></item><item><title>Per-Gaussian Embedding-Based Deformation for Deformable 3D Gaussian Splatting</title><link>http://arxiv.org/abs/2404.03613v4</link><description>As 3D Gaussian Splatting (3DGS) provides fast and high-quality novel viewsynthesis, it is a natural extension to deform a canonical 3DGS to multipleframes for representing a dynamic scene. However, previous works fail toaccurately reconstruct complex dynamic scenes. We attribute the failure to thedesign of the deformation field, which is built as a coordinate-based function.This approach is problematic because 3DGS is a mixture of multiple fieldscentered at the Gaussians, not just a single coordinate-based framework. Toresolve this problem, we define the deformation as a function of per-Gaussianembeddings and temporal embeddings. Moreover, we decompose deformations ascoarse and fine deformations to model slow and fast movements, respectively.Also, we introduce a local smoothness regularization for per-Gaussian embeddingto improve the details in dynamic regions. Project page:https://jeongminb.github.io/e-d3dgs/</description><author>Jeongmin Bae, Seoha Kim, Youngsik Yun, Hahyun Lee, Gun Bang, Youngjung Uh</author><pubDate>Thu, 25 Jul 2024 17:15:58 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.03613v4</guid></item><item><title>Differentiable Quantum Architecture Search in Asynchronous Quantum Reinforcement Learning</title><link>http://arxiv.org/abs/2407.18202v1</link><description>The emergence of quantum reinforcement learning (QRL) is propelled byadvancements in quantum computing (QC) and machine learning (ML), particularlythrough quantum neural networks (QNN) built on variational quantum circuits(VQC). These advancements have proven successful in addressing sequentialdecision-making tasks. However, constructing effective QRL models demandssignificant expertise due to challenges in designing quantum circuitarchitectures, including data encoding and parameterized circuits, whichprofoundly influence model performance. In this paper, we propose addressingthis challenge with differentiable quantum architecture search (DiffQAS),enabling trainable circuit parameters and structure weights usinggradient-based optimization. Furthermore, we enhance training efficiencythrough asynchronous reinforcement learning (RL) methods facilitating paralleltraining. Through numerical simulations, we demonstrate that our proposedDiffQAS-QRL approach achieves performance comparable to manually-craftedcircuit architectures across considered environments, showcasing stabilityacross diverse scenarios. This methodology offers a pathway for designing QRLmodels without extensive quantum knowledge, ensuring robust performance andfostering broader application of QRL.</description><author>Samuel Yen-Chi Chen</author><pubDate>Thu, 25 Jul 2024 17:11:00 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.18202v1</guid></item><item><title>Sparse Incremental Aggregation in Multi-Hop Federated Learning</title><link>http://arxiv.org/abs/2407.18200v1</link><description>This paper investigates federated learning (FL) in a multi-hop communicationsetup, such as in constellations with inter-satellite links. In this setup,part of the FL clients are responsible for forwarding other client's results tothe parameter server. Instead of using conventional routing, the communicationefficiency can be improved significantly by using in-network model aggregationat each intermediate hop, known as incremental aggregation (IA). Prior works[1] have indicated diminishing gains for IA under gradient sparsification. Herewe study this issue and propose several novel correlated sparsification methodsfor IA. Numerical results show that, for some of these algorithms, the fullpotential of IA is still available under sparsification without impairingconvergence. We demonstrate a 15x improvement in communication efficiency overconventional routing and a 11x improvement over state-of-the-art (SoA) sparseIA.</description><author>Sourav Mukherjee, Nasrin Razmi, Armin Dekorsy, Petar Popovski, Bho Matthiesen</author><pubDate>Thu, 25 Jul 2024 17:09:22 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.18200v1</guid></item><item><title>Wasserstein approximation schemes based on Voronoi partitions</title><link>http://arxiv.org/abs/2310.09149v2</link><description>We consider structured approximation of measures in Wasserstein space$\mathrm{W}_p(\mathbb{R}^d)$ for $p\in[1,\infty)$ using general measureapproximants compactly supported on Voronoi regions derived from a scaledVoronoi partition of $\mathbb{R}^d$. We show that if a full rank lattice$\Lambda$ is scaled by a factor of $h\in(0,1]$, then approximation of a measurebased on the Voronoi partition of $h\Lambda$ is $O(h)$ regardless of $d$ or$p$. We then use a covering argument to show that $N$-term approximations ofcompactly supported measures is $O(N^{-\frac1d})$ which matches known rates foroptimal quantizers and empirical measure approximation in most instances.Additionally, we generalize our construction to nonuniform Voronoi partitions,highlighting the flexibility and robustness of our approach for various measureapproximation scenarios. Finally, we extend these results to noncompactlysupported measures with sufficient decay. Our findings are pertinent toapplications in computer vision and machine learning where measures are used torepresent structured data such as images.</description><author>Keaton Hamm, Varun Khurana</author><pubDate>Thu, 25 Jul 2024 17:05:37 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.09149v2</guid></item><item><title>AutoCodeRover: Autonomous Program Improvement</title><link>http://arxiv.org/abs/2404.05427v3</link><description>Researchers have made significant progress in automating the softwaredevelopment process in the past decades. Recent progress in Large LanguageModels (LLMs) has significantly impacted the development process, wheredevelopers can use LLM-based programming assistants to achieve automatedcoding. Nevertheless, software engineering involves the process of programimprovement apart from coding, specifically to enable software maintenance(e.g. bug fixing) and software evolution (e.g. feature additions). In thispaper, we propose an automated approach for solving GitHub issues toautonomously achieve program improvement. In our approach called AutoCodeRover,LLMs are combined with sophisticated code search capabilities, ultimatelyleading to a program modification or patch. In contrast to recent LLM agentapproaches from AI researchers and practitioners, our outlook is more softwareengineering oriented. We work on a program representation (abstract syntaxtree) as opposed to viewing a software project as a mere collection of files.Our code search exploits the program structure in the form of classes/methodsto enhance LLM's understanding of the issue's root cause, and effectivelyretrieve a context via iterative search. The use of spectrum-based faultlocalization using tests, further sharpens the context, as long as a test-suiteis available. Experiments on SWE-bench-lite (300 real-life GitHub issues) showincreased efficacy in solving GitHub issues (19% on SWE-bench-lite), which ishigher than the efficacy of the recently reported SWE-agent. In addition,AutoCodeRover achieved this efficacy with significantly lower cost (on average,$0.43 USD), compared to other baselines. We posit that our workflow enablesautonomous software engineering, where, in future, auto-generated code fromLLMs can be autonomously improved.</description><author>Yuntong Zhang, Haifeng Ruan, Zhiyu Fan, Abhik Roychoudhury</author><pubDate>Thu, 25 Jul 2024 16:54:41 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.05427v3</guid></item><item><title>A Unified Framework for Model Editing</title><link>http://arxiv.org/abs/2403.14236v4</link><description>ROME and MEMIT are largely believed to be two different model editingalgorithms, with the major difference between them being the ability to performbatched edits. In this paper, we unify these two algorithms under a singleconceptual umbrella, optimizing for the same goal, which we call thepreservation-memorization objective. ROME uses an equality constraint tooptimize this objective to perform one edit at a time, whereas MEMIT employs amore flexible least-square constraint that allows for batched edits. Wegeneralize ROME and enable batched editing with equality constraint in the formof EMMET - an Equality-constrained Mass Model Editing algorithm forTransformers, a new batched memory-editing algorithm. EMMET can performbatched-edits up to a batch-size of 10,000, with very similar performance toMEMIT across multiple dimensions. With the introduction of EMMET, we trulyunify ROME and MEMIT and show that both algorithms are equivalent in terms oftheir optimization objective, their abilities (singular and batched editing),their model editing performance and their limitations.</description><author>Akshat Gupta, Dev Sajnani, Gopala Anumanchipalli</author><pubDate>Thu, 25 Jul 2024 16:52:15 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.14236v4</guid></item><item><title>Regurgitative Training: The Value of Real Data in Training Large Language Models</title><link>http://arxiv.org/abs/2407.12835v2</link><description>What happens if we train a new Large Language Model (LLM) using data that areat least partially generated by other LLMs? The explosive success of LLMs meansthat a substantial amount of content online will be generated by LLMs ratherthan humans, which will inevitably enter the training datasets ofnext-generation LLMs. We evaluate the implications of such "regurgitativetraining" on LLM performance. Through fine-tuning GPT-3.5 with data generatedeither by itself or by other LLMs in a machine translation task, we find strongevidence that regurgitative training clearly handicaps the performance of LLMs.The same performance loss of regurgitative training is observed on transformermodels that we train from scratch. We find suggestive evidence that theperformance disadvantage of regurgitative training can be attributed to atleast two mechanisms: (1) higher error rates and (2) lower lexical diversity inLLM-generated data as compared to real data. Based on these mechanisms, wepropose and evaluate three different strategies to mitigate the performanceloss of regurgitative training. First, we devise data-driven metrics to gaugethe quality of each LLM-generated data instance, and then carry out an orderedtraining process where high-quality data are added before low-quality ones.Second, we combine data generated by multiple different LLMs (as an attempt toincrease lexical diversity). Third, we train an AI detection classifier todifferentiate between LLM- and human-generated data, and include LLM-generateddata in the order of resemblance to human-generated data. All three strategiescan improve the performance of regurgitative training to some extent but arenot always able to fully close the gap from training with real data. Ourresults highlight the value of real, human-generated data in training LLMs,which cannot be easily substituted by synthetic, LLM-generated data.</description><author>Jinghui Zhang, Dandan Qiao, Mochen Yang, Qiang Wei</author><pubDate>Thu, 25 Jul 2024 16:50:58 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.12835v2</guid></item><item><title>AsEP: Benchmarking Deep Learning Methods for Antibody-specific Epitope Prediction</title><link>http://arxiv.org/abs/2407.18184v1</link><description>Epitope identification is vital for antibody design yet challenging due tothe inherent variability in antibodies. While many deep learning methods havebeen developed for general protein binding site prediction tasks, whether theywork for epitope prediction remains an understudied research question. Thechallenge is also heightened by the lack of a consistent evaluation pipelinewith sufficient dataset size and epitope diversity. We introduce a filteredantibody-antigen complex structure dataset, AsEP (Antibody-specific EpitopePrediction). AsEP is the largest of its kind and provides clustered epitopegroups, allowing the community to develop and test novel epitope predictionmethods. AsEP comes with an easy-to-use interface in Python and pre-built graphrepresentations of each antibody-antigen complex while also supportingcustomizable embedding methods. Based on this new dataset, we benchmarkedvarious representative general protein-binding site prediction methods and findthat their performances are not satisfactory as expected for epitopeprediction. We thus propose a new method, WALLE, that leverages both proteinlanguage models and graph neural networks. WALLE demonstrate about 5Xperformance gain over existing methods. Our empirical findings evidence thatepitope prediction benefits from combining sequential embeddings provided bylanguage models and geometrical information from graph representations,providing a guideline for future method design. In addition, we reformulate thetask as bipartite link prediction, allowing easy model performance attributionand interpretability. We open-source our data and code athttps://github.com/biochunan/AsEP-dataset.</description><author>Chunan Liu, Lilian Denzler, Yihong Chen, Andrew Martin, Brooks Paige</author><pubDate>Thu, 25 Jul 2024 16:43:56 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.18184v1</guid></item><item><title>Gene Regulatory Network Inference from Pre-trained Single-Cell Transcriptomics Transformer with Joint Graph Learning</title><link>http://arxiv.org/abs/2407.18181v1</link><description>Inferring gene regulatory networks (GRNs) from single-cell RNA sequencing(scRNA-seq) data is a complex challenge that requires capturing the intricaterelationships between genes and their regulatory interactions. In this study,we tackle this challenge by leveraging the single-cell BERT-based pre-trainedtransformer model (scBERT), trained on extensive unlabeled scRNA-seq data, toaugment structured biological knowledge from existing GRNs. We introduce anovel joint graph learning approach that combines the rich contextualrepresentations learned by pre-trained single-cell language models with thestructured knowledge encoded in GRNs using graph neural networks (GNNs). Byintegrating these two modalities, our approach effectively reasons over boththegene expression level constraints provided by the scRNA-seq data and thestructured biological knowledge inherent in GRNs. We evaluate our method onhuman cell benchmark datasets from the BEELINE study with cell type-specificground truth networks. The results demonstrate superior performance overcurrent state-of-the-art baselines, offering a deeper understanding of cellularregulatory mechanisms.</description><author>Sindhura Kommu, Yizhi Wang, Yue Wang, Xuan Wang</author><pubDate>Thu, 25 Jul 2024 16:42:08 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.18181v1</guid></item><item><title>PianoMime: Learning a Generalist, Dexterous Piano Player from Internet Demonstrations</title><link>http://arxiv.org/abs/2407.18178v1</link><description>In this work, we introduce PianoMime, a framework for training apiano-playing agent using internet demonstrations. The internet is a promisingsource of large-scale demonstrations for training our robot agents. Inparticular, for the case of piano-playing, Youtube is full of videos ofprofessional pianists playing a wide myriad of songs. In our work, we leveragethese demonstrations to learn a generalist piano-playing agent capable ofplaying any arbitrary song. Our framework is divided into three parts: a datapreparation phase to extract the informative features from the Youtube videos,a policy learning phase to train song-specific expert policies from thedemonstrations and a policy distillation phase to distil the policies into asingle generalist agent. We explore different policy designs to represent theagent and evaluate the influence of the amount of training data on thegeneralization capability of the agent to novel songs not available in thedataset. We show that we are able to learn a policy with up to 56\% F1 score onunseen songs.</description><author>Cheng Qian, Julen Urain, Kevin Zakka, Jan Peters</author><pubDate>Thu, 25 Jul 2024 16:37:07 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.18178v1</guid></item><item><title>Quasar-ViT: Hardware-Oriented Quantization-Aware Architecture Search for Vision Transformers</title><link>http://arxiv.org/abs/2407.18175v1</link><description>Vision transformers (ViTs) have demonstrated their superior accuracy forcomputer vision tasks compared to convolutional neural networks (CNNs).However, ViT models are often computation-intensive for efficient deployment onresource-limited edge devices. This work proposes Quasar-ViT, ahardware-oriented quantization-aware architecture search framework for ViTs, todesign efficient ViT models for hardware implementation while preserving theaccuracy. First, Quasar-ViT trains a supernet using our row-wise flexiblemixed-precision quantization scheme, mixed-precision weight entanglement, andsupernet layer scaling techniques. Then, it applies an efficienthardware-oriented search algorithm, integrated with hardware latency andresource modeling, to determine a series of optimal subnets from supernet underdifferent inference latency targets. Finally, we propose a series ofmodel-adaptive designs on the FPGA platform to support the architecture searchand mitigate the gap between the theoretical computation reduction and thepractical inference speedup. Our searched models achieve 101.5, 159.6, and251.6 frames-per-second (FPS) inference speed on the AMD/Xilinx ZCU102 FPGAwith 80.4%, 78.6%, and 74.9% top-1 accuracy, respectively, for the ImageNetdataset, consistently outperforming prior works.</description><author>Zhengang Li, Alec Lu, Yanyue Xie, Zhenglun Kong, Mengshu Sun, Hao Tang, Zhong Jia Xue, Peiyan Dong, Caiwen Ding, Yanzhi Wang, Xue Lin, Zhenman Fang</author><pubDate>Thu, 25 Jul 2024 16:35:46 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.18175v1</guid></item><item><title>RIDA: A Robust Attack Framework on Incomplete Graphs</title><link>http://arxiv.org/abs/2407.18170v1</link><description>Graph Neural Networks (GNNs) are vital in data science but are increasinglysusceptible to adversarial attacks. To help researchers develop more robust GNNmodels, it's essential to focus on designing strong attack models asfoundational benchmarks and guiding references. Among adversarial attacks,gray-box poisoning attacks are noteworthy due to their effectiveness and fewerconstraints. These attacks exploit GNNs' need for retraining on updated data,thereby impacting their performance by perturbing these datasets. However,current research overlooks the real-world scenario of incomplete graphs.Toaddress this gap, we introduce the Robust Incomplete Deep Attack Framework(RIDA). It is the first algorithm for robust gray-box poisoning attacks onincomplete graphs. The approach innovatively aggregates distant vertexinformation and ensures powerful data utilization.Extensive tests against 9SOTA baselines on 3 real-world datasets demonstrate RIDA's superiority inhandling incompleteness and high attack performance on the incomplete graph.</description><author>Jianke Yu, Hanchen Wang, Chen Chen, Xiaoyang Wang, Wenjie Zhang, Ying Zhang</author><pubDate>Thu, 25 Jul 2024 16:33:35 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.18170v1</guid></item><item><title>Machine Translation Hallucination Detection for Low and High Resource Languages using Large Language Models</title><link>http://arxiv.org/abs/2407.16470v2</link><description>Recent advancements in massively multilingual machine translation systemshave significantly enhanced translation accuracy; however, even the bestperforming systems still generate hallucinations, severely impacting usertrust. Detecting hallucinations in Machine Translation (MT) remains a criticalchallenge, particularly since existing methods excel with High-ResourceLanguages (HRLs) but exhibit substantial limitations when applied toLow-Resource Languages (LRLs). This paper evaluates hallucination detectionapproaches using Large Language Models (LLMs) and semantic similarity withinmassively multilingual embeddings. Our study spans 16 language directions,covering HRLs, LRLs, with diverse scripts. We find that the choice of model isessential for performance. On average, for HRLs, Llama3-70B outperforms theprevious state of the art by as much as 0.16 MCC (Matthews CorrelationCoefficient). However, for LRLs we observe that Claude Sonnet outperforms otherLLMs on average by 0.03 MCC. The key takeaway from our study is that LLMs canachieve performance comparable or even better than previously proposed models,despite not being explicitly trained for any machine translation task. However,their advantage is less significant for LRLs.</description><author>Kenza Benkirane, Laura Gongas, Shahar Pelles, Naomi Fuchs, Joshua Darmon, Pontus Stenetorp, David Ifeoluwa Adelani, Eduardo Sánchez</author><pubDate>Thu, 25 Jul 2024 16:31:39 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.16470v2</guid></item><item><title>Light Curve Classification with DistClassiPy: a new distance-based classifier</title><link>http://arxiv.org/abs/2403.12120v2</link><description>The rise of synoptic sky surveys has ushered in an era of big data intime-domain astronomy, making data science and machine learning essential toolsfor studying celestial objects. While tree-based models (e.g. Random Forests)and deep learning models dominate the field, we explore the use of differentdistance metrics to aid in the classification of astrophysical objects. Wedeveloped DistClassiPy, a new distance metric based classifier. The direct useof distance metrics is unexplored in time-domain astronomy, but distance-basedmethods can help make classification more interpretable and decreasecomputational costs. In particular, we applied DistClassiPy to classify lightcurves of variable stars, comparing the distances between objects of differentclasses. Using 18 distance metrics on a catalog of 6,000 variable stars across10 classes, we demonstrate classification and dimensionality reduction. Ourclassifier meets state-of-the-art performance but has lower computationalrequirements and improved interpretability. Additionally, DistClassiPy can betailored to specific objects by identifying the most effective distance metricfor that classification. To facilitate broader applications within and beyondastronomy, we have made DistClassiPy open-source and available athttps://pypi.org/project/distclassipy/.</description><author>Siddharth Chaini, Ashish Mahabal, Ajit Kembhavi, Federica B. Bianco</author><pubDate>Thu, 25 Jul 2024 16:27:49 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.12120v2</guid></item><item><title>Statistical optimal transport</title><link>http://arxiv.org/abs/2407.18163v1</link><description>We present an introduction to the field of statistical optimal transport,based on lectures given at \'Ecole d'\'Et\'e de Probabilit\'es de Saint-FlourXLIX.</description><author>Sinho Chewi, Jonathan Niles-Weed, Philippe Rigollet</author><pubDate>Thu, 25 Jul 2024 16:25:10 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.18163v1</guid></item><item><title>Longhorn: State Space Models are Amortized Online Learners</title><link>http://arxiv.org/abs/2407.14207v2</link><description>The most fundamental capability of modern AI methods such as Large LanguageModels (LLMs) is the ability to predict the next token in a long sequence oftokens, known as ``sequence modeling." Although the Transformers model is thecurrent dominant approach to sequence modeling, its quadratic computationalcost with respect to sequence length is a significant drawback. State-spacemodels (SSMs) offer a promising alternative due to their linear decodingefficiency and high parallelizability during training. However, existing SSMsoften rely on seemingly ad hoc linear recurrence designs. In this work, weexplore SSM design through the lens of online learning, conceptualizing SSMs asmeta-modules for specific online learning problems. This approach links SSMdesign to formulating precise online learning objectives, with state transitionrules derived from optimizing these objectives. Based on this insight, weintroduce a novel deep SSM architecture based on the implicit update foroptimizing an online regression objective. Our experimental results show thatour models outperform state-of-the-art SSMs, including the Mamba model, onstandard sequence modeling benchmarks and language modeling tasks.</description><author>Bo Liu, Rui Wang, Lemeng Wu, Yihao Feng, Peter Stone, Qiang Liu</author><pubDate>Thu, 25 Jul 2024 16:24:59 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.14207v2</guid></item><item><title>Harmonic LLMs are Trustworthy</title><link>http://arxiv.org/abs/2404.19708v2</link><description>We introduce an intuitive method to test the robustness (stability andexplainability) of any black-box LLM in real-time via its local deviation fromharmoniticity, denoted as $\gamma$. To the best of our knowledge this is thefirst completely model-agnostic and unsupervised method of measuring therobustness of any given response from an LLM, based upon the model itselfconforming to a purely mathematical standard. To show general application andimmediacy of results, we measure $\gamma$ in 10 popular LLMs (ChatGPT,Claude-2.1, Claude3.0, GPT-4, GPT-4o, Smaug-72B, Mixtral-8x7B, Llama2-7B,Mistral-7B and MPT-7B) across thousands of queries in three objective domains:WebQA, ProgrammingQA, and TruthfulQA. Across all models and domains tested,human annotation confirms that $\gamma \to 0$ indicates trustworthiness, andconversely searching higher values of $\gamma$ easily exposes examples ofhallucination, a fact that enables efficient adversarial prompt generationthrough stochastic gradient ascent in $\gamma$. The low-$\gamma$ leaders amongthe models in the respective domains are GPT-4o, GPT-4, and Smaug-72B,providing evidence that mid-size open-source models can win out against largecommercial models.</description><author>Nicholas S. Kersting, Mohammad Rahman, Suchismitha Vedala, Yang Wang</author><pubDate>Thu, 25 Jul 2024 16:16:46 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.19708v2</guid></item><item><title>Unlocking Tokens as Data Points for Generalization Bounds on Larger Language Models</title><link>http://arxiv.org/abs/2407.18158v1</link><description>Large language models (LLMs) with billions of parameters excel at predictingthe next token in a sequence. Recent work computes non-vacuouscompression-based generalization bounds for LLMs, but these bounds are vacuousfor large models at the billion-parameter scale. Moreover, these bounds areobtained through restrictive compression techniques, bounding compressed modelsthat generate low-quality text. Additionally, the tightness of these existingbounds depends on the number of IID documents in a training set rather than themuch larger number of non-IID constituent tokens, leaving untapped potentialfor tighter bounds. In this work, we instead use properties of martingales toderive generalization bounds that benefit from the vast number of tokens in LLMtraining sets. Since a dataset contains far more tokens than documents, ourgeneralization bounds not only tolerate but actually benefit from far lessrestrictive compression schemes. With Monarch matrices, Kroneckerfactorizations, and post-training quantization, we achieve non-vacuousgeneralization bounds for LLMs as large as LLaMA2-70B. Unlike previousapproaches, our work achieves the first non-vacuous bounds for models that aredeployed in practice and generate high-quality text.</description><author>Sanae Lotfi, Yilun Kuang, Brandon Amos, Micah Goldblum, Marc Finzi, Andrew Gordon Wilson</author><pubDate>Thu, 25 Jul 2024 16:13:58 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.18158v1</guid></item><item><title>No Representation, No Trust: Connecting Representation, Collapse, and Trust Issues in PPO</title><link>http://arxiv.org/abs/2405.00662v2</link><description>Reinforcement learning (RL) is inherently rife with non-stationarity sincethe states and rewards the agent observes during training depend on itschanging policy. Therefore, networks in deep RL must be capable of adapting tonew observations and fitting new targets. However, previous works have observedthat networks in off-policy deep value-based methods exhibit a decrease inrepresentation rank, often correlated with an inability to continue learning ora collapse in performance. Although this phenomenon has generally beenattributed to neural network learning under non-stationarity, it has beenoverlooked in on-policy policy optimization methods which are often thoughtcapable of training indefinitely. In this work, we empirically studyrepresentation dynamics in Proximal Policy Optimization (PPO) on the Atari andMuJoCo environments, revealing that PPO agents are also affected by featurerank deterioration and loss of plasticity. We show that this is aggravated withstronger non-stationarity, ultimately driving the actor's performance tocollapse, regardless of the performance of the critic. We ask why the trustregion, specific to methods like PPO, cannot alleviate or prevent the collapse.We find that there is a connection between representation collapse and thedegradation of the trust region, one exacerbating the other, and presentProximal Feature Optimization (PFO), a novel auxiliary loss that, along withother interventions, shows that regularizing the representation dynamicsimproves the performance of PPO agents.</description><author>Skander Moalla, Andrea Miele, Razvan Pascanu, Caglar Gulcehre</author><pubDate>Thu, 25 Jul 2024 16:04:49 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.00662v2</guid></item><item><title>Evaluating the design space of diffusion-based generative models</title><link>http://arxiv.org/abs/2406.12839v2</link><description>Most existing theoretical investigations of the accuracy of diffusion models,albeit significant, assume the score function has been approximated to acertain accuracy, and then use this a priori bound to control the error ofgeneration. This article instead provides a first quantitative understanding ofthe whole generation process, i.e., both training and sampling. More precisely,it conducts a non-asymptotic convergence analysis of denoising score matchingunder gradient descent. In addition, a refined sampling error analysis forvariance exploding models is also provided. The combination of these tworesults yields a full error analysis, which elucidates (again, but this timetheoretically) how to design the training and sampling processes for effectivegeneration. For instance, our theory implies a preference toward noisedistribution and loss weighting in training that qualitatively agree with theones used in [Karras et al. 2022]. It also provides perspectives on the choicesof time and variance schedules in sampling: when the score is well trained, thedesign in [Song et al. 2020] is more preferable, but when it is less trained,the design in [Karras et al. 2022] becomes more preferable.</description><author>Yuqing Wang, Ye He, Molei Tao</author><pubDate>Thu, 25 Jul 2024 16:01:04 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.12839v2</guid></item><item><title>StraightLine: An End-to-End Resource-Aware Scheduler for Machine Learning Application Requests</title><link>http://arxiv.org/abs/2407.18148v1</link><description>The life cycle of machine learning (ML) applications consists of two stages:model development and model deployment. However, traditional ML systems (e.g.,training-specific or inference-specific systems) focus on one particular stageor phase of the life cycle of ML applications. These systems often aim atoptimizing model training or accelerating model inference, and they frequentlyassume homogeneous infrastructure, which may not always reflect real-worldscenarios that include cloud data centers, local servers, containers, andserverless platforms. We present StraightLine, an end-to-end resource-awarescheduler that schedules the optimal resources (e.g., container, virtualmachine, or serverless) for different ML application requests in a hybridinfrastructure. The key innovation is an empirical dynamic placing algorithmthat intelligently places requests based on their unique characteristics (e.g.,request frequency, input data size, and data distribution). In contrast toexisting ML systems, StraightLine offers end-to-end resource-aware placement,thereby it can significantly reduce response time and failure rate for modeldeployment when facing different computing resources in the hybridinfrastructure.</description><author>Cheng-Wei Ching, Boyuan Guan, Hailu Xu, Liting Hu</author><pubDate>Thu, 25 Jul 2024 15:58:56 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.18148v1</guid></item><item><title>The FIGNEWS Shared Task on News Media Narratives</title><link>http://arxiv.org/abs/2407.18147v1</link><description>We present an overview of the FIGNEWS shared task, organized as part of theArabicNLP 2024 conference co-located with ACL 2024. The shared task addressesbias and propaganda annotation in multilingual news posts. We focus on theearly days of the Israel War on Gaza as a case study. The task aims to fostercollaboration in developing annotation guidelines for subjective tasks bycreating frameworks for analyzing diverse narratives highlighting potentialbias and propaganda. In a spirit of fostering and encouraging diversity, weaddress the problem from a multilingual perspective, namely within fivelanguages: English, French, Arabic, Hebrew, and Hindi. A total of 17 teamsparticipated in two annotation subtasks: bias (16 teams) and propaganda (6teams). The teams competed in four evaluation tracks: guidelines development,annotation quality, annotation quantity, and consistency. Collectively, theteams produced 129,800 data points. Key findings and implications for the fieldare discussed.</description><author>Wajdi Zaghouani, Mustafa Jarrar, Nizar Habash, Houda Bouamor, Imed Zitouni, Mona Diab, Samhaa R. El-Beltagy, Muhammed AbuOdeh</author><pubDate>Thu, 25 Jul 2024 15:58:19 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.18147v1</guid></item><item><title>Taxonomy-Aware Continual Semantic Segmentation in Hyperbolic Spaces for Open-World Perception</title><link>http://arxiv.org/abs/2407.18145v1</link><description>Semantic segmentation models are typically trained on a fixed set of classes,limiting their applicability in open-world scenarios. Class-incrementalsemantic segmentation aims to update models with emerging new classes whilepreventing catastrophic forgetting of previously learned ones. However,existing methods impose strict rigidity on old classes, reducing theireffectiveness in learning new incremental classes. In this work, we proposeTaxonomy-Oriented Poincar\'e-regularized Incremental-Class Segmentation(TOPICS) that learns feature embeddings in hyperbolic space following explicittaxonomy-tree structures. This supervision provides plasticity for old classes,updating ancestors based on new classes while integrating new classes atfitting positions. Additionally, we maintain implicit class relationalconstraints on the geometric basis of the Poincar\'e ball. This ensures thatthe latent space can continuously adapt to new constraints while maintaining arobust structure to combat catastrophic forgetting. We also establish eightrealistic incremental learning protocols for autonomous driving scenarios,where novel classes can originate from known classes or the background.Extensive evaluations of TOPICS on the Cityscapes and Mapillary Vistas 2.0benchmarks demonstrate that it achieves state-of-the-art performance. We makethe code and trained models publicly available athttp://topics.cs.uni-freiburg.de.</description><author>Julia Hindel, Daniele Cattaneo, Abhinav Valada</author><pubDate>Thu, 25 Jul 2024 15:49:26 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.18145v1</guid></item><item><title>Maximum Entropy On-Policy Actor-Critic via Entropy Advantage Estimation</title><link>http://arxiv.org/abs/2407.18143v1</link><description>Entropy Regularisation is a widely adopted technique that enhances policyoptimisation performance and stability. A notable form of entropyregularisation is augmenting the objective with an entropy term, therebysimultaneously optimising the expected return and the entropy. This framework,known as maximum entropy reinforcement learning (MaxEnt RL), has showntheoretical and empirical successes. However, its practical application instraightforward on-policy actor-critic settings remains surprisinglyunderexplored. We hypothesise that this is due to the difficulty of managingthe entropy reward in practice. This paper proposes a simple method ofseparating the entropy objective from the MaxEnt RL objective, whichfacilitates the implementation of MaxEnt RL in on-policy settings. Ourempirical evaluations demonstrate that extending Proximal Policy Optimisation(PPO) and Trust Region Policy Optimisation (TRPO) within the MaxEnt frameworkimproves policy optimisation performance in both MuJoCo and Procgen tasks.Additionally, our results highlight MaxEnt RL's capacity to enhancegeneralisation.</description><author>Jean Seong Bjorn Choe, Jong-Kook Kim</author><pubDate>Thu, 25 Jul 2024 15:48:24 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.18143v1</guid></item><item><title>HAIFIT: Human-Centered AI for Fashion Image Translation</title><link>http://arxiv.org/abs/2403.08651v3</link><description>In the realm of fashion design, sketches serve as the canvas for expressingan artist's distinctive drawing style and creative vision, capturing intricatedetails like stroke variations and texture nuances. The advent ofsketch-to-image cross-modal translation technology has notably aided designers.However, existing methods often compromise these sketch details during imagegeneration, resulting in images that deviate from the designer's intendedconcept. This limitation hampers the ability to offer designers a precisepreview of the final output. To overcome this challenge, we introduce HAIFIT, anovel approach that transforms sketches into high-fidelity, lifelike clothingimages by integrating multi-scale features and capturing extensive feature mapdependencies from diverse perspectives. Through extensive qualitative andquantitative evaluations conducted on our self-collected dataset, our methoddemonstrates superior performance compared to existing methods in generatingphotorealistic clothing images. Our method excels in preserving the distinctivestyle and intricate details essential for fashion design applications. Inaddition, our method also has obvious advantages in model training andinference speed, contributing to reducing designers' time costs and improvingdesign efficiency.</description><author>Jianan Jiang, Xinglin Li, Weiren Yu, Di Wu</author><pubDate>Thu, 25 Jul 2024 15:46:50 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.08651v3</guid></item><item><title>Reference-Based 3D-Aware Image Editing with Triplanes</title><link>http://arxiv.org/abs/2404.03632v2</link><description>Generative Adversarial Networks (GANs) have emerged as powerful tools forhigh-quality image generation and real image editing by manipulating theirlatent spaces. Recent advancements in GANs include 3D-aware models such asEG3D, which feature efficient triplane-based architectures capable ofreconstructing 3D geometry from single images. However, limited attention hasbeen given to providing an integrated framework for 3D-aware, high-quality,reference-based image editing. This study addresses this gap by exploring anddemonstrating the effectiveness of the triplane space for advancedreference-based edits. Our novel approach integrates encoding, automaticlocalization, spatial disentanglement of triplane features, and fusion learningto achieve the desired edits. Additionally, our framework demonstratesversatility and robustness across various domains, extending its effectivenessto animal face edits, partially stylized edits like cartoon faces, full-bodyclothing edits, and 360-degree head edits. Our method shows state-of-the-artperformance over relevant latent direction, text, and image-guided 2D and3D-aware diffusion and GAN methods, both qualitatively and quantitatively.</description><author>Bahri Batuhan Bilecen, Yigit Yalin, Ning Yu, Aysegul Dundar</author><pubDate>Thu, 25 Jul 2024 15:45:58 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.03632v2</guid></item><item><title>IRIS: Wireless Ring for Vision-based Smart Home Interaction</title><link>http://arxiv.org/abs/2407.18141v1</link><description>Integrating cameras into wireless smart rings has been challenging due tosize and power constraints. We introduce IRIS, the first wirelessvision-enabled smart ring system for smart home interactions. Equipped with acamera, Bluetooth radio, inertial measurement unit (IMU), and an onboardbattery, IRIS meets the small size, weight, and power (SWaP) requirements forring devices. IRIS is context-aware, adapting its gesture set to the detecteddevice, and can last for 16-24 hours on a single charge. IRIS leverages thescene semantics to achieve instance-level device recognition. In a studyinvolving 23 participants, IRIS consistently outpaced voice commands, with ahigher proportion of participants expressing a preference for IRIS over voicecommands regarding toggling a device's state, granular control, and socialacceptability. Our work pushes the boundary of what is possible with ringform-factor devices, addressing system challenges and opening up novelinteraction capabilities.</description><author>Maruchi Kim, Antonio Glenn, Bandhav Veluri, Yunseo Lee, Eyoel Gebre, Aditya Bagaria, Shwetak Patel, Shyamnath Gollakota</author><pubDate>Thu, 25 Jul 2024 15:45:17 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.18141v1</guid></item><item><title>XS-VID: An Extremely Small Video Object Detection Dataset</title><link>http://arxiv.org/abs/2407.18137v1</link><description>Small Video Object Detection (SVOD) is a crucial subfield in modern computervision, essential for early object discovery and detection. However, existingSVOD datasets are scarce and suffer from issues such as insufficiently smallobjects, limited object categories, and lack of scene diversity, leading tounitary application scenarios for corresponding methods. To address this gap,we develop the XS-VID dataset, which comprises aerial data from various periodsand scenes, and annotates eight major object categories. To further evaluateexisting methods for detecting extremely small objects, XS-VID extensivelycollects three types of objects with smaller pixel areas: extremely small(\textit{es}, $0\sim12^2$), relatively small (\textit{rs}, $12^2\sim20^2$), andgenerally small (\textit{gs}, $20^2\sim32^2$). XS-VID offers unprecedentedbreadth and depth in covering and quantifying minuscule objects, significantlyenriching the scene and object diversity in the dataset. Extensive validationson XS-VID and the publicly available VisDrone2019VID dataset show that existingmethods struggle with small object detection and significantly underperformcompared to general object detectors. Leveraging the strengths of previousmethods and addressing their weaknesses, we propose YOLOFT, which enhanceslocal feature associations and integrates temporal motion features,significantly improving the accuracy and stability of SVOD. Our datasets andbenchmarks are available at \url{https://gjhhust.github.io/XS-VID/}.</description><author>Jiahao Guo, Ziyang Xu, Lianjun Wu, Fei Gao, Wenyu Liu, Xinggang Wang</author><pubDate>Thu, 25 Jul 2024 15:42:46 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.18137v1</guid></item><item><title>$\mathbb{X}$-Sample Contrastive Loss: Improving Contrastive Learning with Sample Similarity Graphs</title><link>http://arxiv.org/abs/2407.18134v1</link><description>Learning good representations involves capturing the diverse ways in whichdata samples relate. Contrastive loss - an objective matching related samples -underlies methods from self-supervised to multimodal learning. Contrastivelosses, however, can be viewed more broadly as modifying a similarity graph toindicate how samples should relate in the embedding space. This view reveals ashortcoming in contrastive learning: the similarity graph is binary, as onlyone sample is the related positive sample. Crucially, similarities\textit{across} samples are ignored. Based on this observation, we revise thestandard contrastive loss to explicitly encode how a sample relates to others.We experiment with this new objective, called $\mathbb{X}$-Sample Contrastive,to train vision models based on similarities in class or text captiondescriptions. Our study spans three scales: ImageNet-1k with 1 million, CC3Mwith 3 million, and CC12M with 12 million samples. The representations learnedvia our objective outperform both contrastive self-supervised andvision-language models trained on the same data across a range of tasks. Whentraining on CC12M, we outperform CLIP by $0.6\%$ on both ImageNet and ImageNetReal. Our objective appears to work particularly well in lower-data regimes,with gains over CLIP of $16.8\%$ on ImageNet and $18.1\%$ on ImageNet Real whentraining with CC3M. Finally, our objective seems to encourage the model tolearn representations that separate objects from their attributes andbackgrounds, with gains of $3.3$-$5.6$\% over CLIP on ImageNet9. We hope theproposed solution takes a small step towards developing richer learningobjectives for understanding sample relations in foundation models.</description><author>Vlad Sobal, Mark Ibrahim, Randall Balestriero, Vivien Cabannes, Diane Bouchacourt, Pietro Astolfi, Kyunghyun Cho, Yann LeCun</author><pubDate>Thu, 25 Jul 2024 15:38:16 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.18134v1</guid></item><item><title>Dallah: A Dialect-Aware Multimodal Large Language Model for Arabic</title><link>http://arxiv.org/abs/2407.18129v1</link><description>Recent advancements have significantly enhanced the capabilities ofMultimodal Large Language Models (MLLMs) in generating and understandingimage-to-text content. Despite these successes, progress is predominantlylimited to English due to the scarcity of high quality multimodal resources inother languages. This limitation impedes the development of competitive modelsin languages such as Arabic. To alleviate this situation, we introduce anefficient Arabic multimodal assistant, dubbed Dallah, that utilizes an advancedlanguage model based on LLaMA-2 to facilitate multimodal interactions. Dallahdemonstrates state-of-the-art performance in Arabic MLLMs. Through fine-tuningsix Arabic dialects, Dallah showcases its capability to handle complexdialectal interactions incorporating both textual and visual elements. Themodel excels in two benchmark tests: one evaluating its performance on ModernStandard Arabic (MSA) and another specifically designed to assess dialectalresponses. Beyond its robust performance in multimodal interaction tasks,Dallah has the potential to pave the way for further development ofdialect-aware Arabic MLLMs.</description><author>Fakhraddin Alwajih, Gagan Bhatia, Muhammad Abdul-Mageed</author><pubDate>Thu, 25 Jul 2024 15:36:48 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.18129v1</guid></item><item><title>Estimating Earthquake Magnitude in Sentinel-1 Imagery via Ranking</title><link>http://arxiv.org/abs/2407.18128v1</link><description>Earthquakes are commonly estimated using physical seismic stations, however,due to the installation requirements and costs of these stations, globalcoverage quickly becomes impractical. An efficient and lower-cost alternativeis to develop machine learning models to globally monitor earth observationdata to pinpoint regions impacted by these natural disasters. However, due tothe small amount of historically recorded earthquakes, this becomes a low-dataregime problem requiring algorithmic improvements to achieve peak performancewhen learning to regress earthquake magnitude. In this paper, we propose topose the estimation of earthquake magnitudes as a metric-learning problem,training models to not only estimate earthquake magnitude from Sentinel-1satellite imagery but to additionally rank pairwise samples. Our experimentsshow at max a 30%+ improvement in MAE over prior regression-only based methods,particularly transformer-based architectures.</description><author>Daniele Rege Cambrin, Isaac Corley, Paolo Garza, Peyman Najafirad</author><pubDate>Thu, 25 Jul 2024 15:35:44 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.18128v1</guid></item><item><title>Looking at Model Debiasing through the Lens of Anomaly Detection</title><link>http://arxiv.org/abs/2407.17449v2</link><description>It is widely recognized that deep neural networks are sensitive to bias inthe data. This means that during training these models are likely to learnspurious correlations between data and labels, resulting in limitedgeneralization abilities and low performance. In this context, model debiasingapproaches can be devised aiming at reducing the model's dependency on suchunwanted correlations, either leveraging the knowledge of bias information ornot. In this work, we focus on the latter and more realistic scenario, showingthe importance of accurately predicting the bias-conflicting and bias-alignedsamples to obtain compelling performance in bias mitigation. On this ground, wepropose to conceive the problem of model bias from an out-of-distributionperspective, introducing a new bias identification method based on anomalydetection. We claim that when data is mostly biased, bias-conflicting samplescan be regarded as outliers with respect to the bias-aligned distribution inthe feature space of a biased model, thus allowing for precisely detecting themwith an anomaly detection method. Coupling the proposed bias identificationapproach with bias-conflicting data upsampling and augmentation in a two-stepstrategy, we reach state-of-the-art performance on synthetic and real benchmarkdatasets. Ultimately, our proposed approach shows that the data bias issue doesnot necessarily require complex debiasing methods, given that an accurate biasidentification procedure is defined.</description><author>Vito Paolo Pastore, Massimiliano Ciranni, Davide Marinelli, Francesca Odone, Vittorio Murino</author><pubDate>Thu, 25 Jul 2024 15:33:00 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.17449v2</guid></item><item><title>Self-supervised pre-training with diffusion model for few-shot landmark detection in x-ray images</title><link>http://arxiv.org/abs/2407.18125v1</link><description>In the last few years, deep neural networks have been extensively applied inthe medical domain for different tasks, ranging from image classification andsegmentation to landmark detection. However, the application of thesetechnologies in the medical domain is often hindered by data scarcity, both interms of available annotations and images. This study introduces a newself-supervised pre-training protocol based on diffusion models for landmarkdetection in x-ray images. Our results show that the proposed self-supervisedframework can provide accurate landmark detection with a minimal number ofavailable annotated training images (up to 50), outperforming ImageNetsupervised pre-training and state-of-the-art self-supervised pre-trainings forthree popular x-ray benchmark datasets. To our knowledge, this is the firstexploration of diffusion models for self-supervised learning in landmarkdetection, which may offer a valuable pre-training approach in few-shotregimes, for mitigating data scarcity.</description><author>Roberto Di Via, Francesca Odone, Vito Paolo Pastore</author><pubDate>Thu, 25 Jul 2024 15:32:59 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.18125v1</guid></item><item><title>Better Call SAL: Towards Learning to Segment Anything in Lidar</title><link>http://arxiv.org/abs/2403.13129v2</link><description>We propose the SAL (Segment Anything in Lidar) method consisting of atext-promptable zero-shot model for segmenting and classifying any object inLidar, and a pseudo-labeling engine that facilitates model training withoutmanual supervision. While the established paradigm for Lidar PanopticSegmentation (LPS) relies on manual supervision for a handful of object classesdefined a priori, we utilize 2D vision foundation models to generate 3Dsupervision ``for free''. Our pseudo-labels consist of instance masks andcorresponding CLIP tokens, which we lift to Lidar using calibrated multi-modaldata. By training our model on these labels, we distill the 2D foundationmodels into our Lidar SAL model. Even without manual labels, our model achieves$91\%$ in terms of class-agnostic segmentation and $54\%$ in terms of zero-shotLidar Panoptic Segmentation of the fully supervised state-of-the-art.Furthermore, we outperform several baselines that do not distill but only liftimage features to 3D. More importantly, we demonstrate that SAL supportsarbitrary class prompts, can be easily extended to new datasets, and showssignificant potential to improve with increasing amounts of self-labeled data.Code and models are available at this$\href{https://github.com/nv-dvl/segment-anything-lidar}{URL}$.</description><author>Aljoša Ošep, Tim Meinhardt, Francesco Ferroni, Neehar Peri, Deva Ramanan, Laura Leal-Taixé</author><pubDate>Thu, 25 Jul 2024 15:32:39 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.13129v2</guid></item><item><title>Efficient Inference of Vision Instruction-Following Models with Elastic Cache</title><link>http://arxiv.org/abs/2407.18121v1</link><description>In the field of instruction-following large vision-language models (LVLMs),the efficient deployment of these models faces challenges, notably due to thehigh memory demands of their key-value (KV) caches. Conventional cachemanagement strategies for LLMs focus on cache eviction, which often fails toaddress the specific needs of multimodal instruction-following models.Recognizing this gap, in this paper, we introduce Elastic Cache, a novelapproach that benefits from applying distinct acceleration methods forinstruction encoding and output generation stages. We investigate the metricsof importance in different stages and propose an importance-driven cachemerging strategy to prune redundancy caches. Instead of discarding lessimportant caches, our strategy identifies important key/value vectors as anchorpoints. Surrounding less important caches are then merged with these anchors,enhancing the preservation of contextual information in the KV caches whileyielding an arbitrary acceleration ratio. For instruction encoding, we utilizethe frequency to evaluate the importance of caches. Regarding outputgeneration, we prioritize tokens based on their distance with an offset, bywhich both the initial and most recent tokens are retained. Results on a rangeof LVLMs demonstrate that Elastic Cache not only boosts efficiency but alsonotably outperforms existing pruning methods in language generation acrossvarious tasks. Code is available at https://github.com/liuzuyan/ElasticCache</description><author>Zuyan Liu, Benlin Liu, Jiahui Wang, Yuhao Dong, Guangyi Chen, Yongming Rao, Ranjay Krishna, Jiwen Lu</author><pubDate>Thu, 25 Jul 2024 15:29:05 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.18121v1</guid></item><item><title>Tracking linguistic information in transformer-based sentence embeddings through targeted sparsification</title><link>http://arxiv.org/abs/2407.18119v1</link><description>Analyses of transformer-based models have shown that they encode a variety oflinguistic information from their textual input. While these analyses have sheda light on the relation between linguistic information on one side, andinternal architecture and parameters on the other, a question remainsunanswered: how is this linguistic information reflected in sentenceembeddings? Using datasets consisting of sentences with known structure, wetest to what degree information about chunks (in particular noun, verb orprepositional phrases), such as grammatical number, or semantic role, can belocalized in sentence embeddings. Our results show that such information is notdistributed over the entire sentence embedding, but rather it is encoded inspecific regions. Understanding how the information from an input text iscompressed into sentence embeddings helps understand current transformer modelsand help build future explainable neural models.</description><author>Vivi Nastase, Paola Merlo</author><pubDate>Thu, 25 Jul 2024 15:27:08 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.18119v1</guid></item><item><title>Generative Learning of Continuous Data by Tensor Networks</title><link>http://arxiv.org/abs/2310.20498v2</link><description>Beyond their origin in modeling many-body quantum systems, tensor networkshave emerged as a promising class of models for solving machine learningproblems, notably in unsupervised generative learning. While possessing manydesirable features arising from their quantum-inspired nature, tensor networkgenerative models have previously been largely restricted to binary orcategorical data, limiting their utility in real-world modeling problems. Weovercome this by introducing a new family of tensor network generative modelsfor continuous data, which are capable of learning from distributionscontaining continuous random variables. We develop our method in the setting ofmatrix product states, first deriving a universal expressivity theorem provingthe ability of this model family to approximate any reasonably smoothprobability density function with arbitrary precision. We then benchmark theperformance of this model on several synthetic and real-world datasets, findingthat the model learns and generalizes well on distributions of continuous anddiscrete variables. We develop methods for modeling different data domains, andintroduce a trainable compression layer which is found to increase modelperformance given limited memory or computational resources. Overall, ourmethods give important theoretical and empirical evidence of the efficacy ofquantum-inspired methods for the rapidly growing field of generative learning.</description><author>Alex Meiburg, Jing Chen, Jacob Miller, Raphaëlle Tihon, Guillaume Rabusseau, Alejandro Perdomo-Ortiz</author><pubDate>Thu, 25 Jul 2024 15:25:27 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.20498v2</guid></item><item><title>Unsupervised Training of Neural Cellular Automata on Edge Devices</title><link>http://arxiv.org/abs/2407.18114v1</link><description>The disparity in access to machine learning tools for medical imaging acrossdifferent regions significantly limits the potential for universal healthcareinnovation, particularly in remote areas. Our research addresses this issue byimplementing Neural Cellular Automata (NCA) training directly on smartphonesfor accessible X-ray lung segmentation. We confirm the practicality andfeasibility of deploying and training these advanced models on five Androiddevices, improving medical diagnostics accessibility and bridging the techdivide to extend machine learning benefits in medical imaging to low- andmiddle-income countries (LMICs). We further enhance this approach with anunsupervised adaptation method using the novel Variance-Weighted SegmentationLoss (VWSL), which efficiently learns from unlabeled data by minimizing thevariance from multiple NCA predictions. This strategy notably improves modeladaptability and performance across diverse medical imaging contexts withoutthe need for extensive computational resources or labeled datasets, effectivelylowering the participation threshold. Our methodology, tested on threemultisite X-ray datasets -- Padchest, ChestX-ray8, and MIMIC-III --demonstrates improvements in segmentation Dice accuracy by 0.7 to 2.8%,compared to the classic Med-NCA. Additionally, in extreme cases where nodigital copy is available and images must be captured by a phone from an X-raylightbox or monitor, VWSL enhances Dice accuracy by 5-20%, demonstrating themethod's robustness even with suboptimal image sources.</description><author>John Kalkhof, Amin Ranem, Anirban Mukhopadhyay</author><pubDate>Thu, 25 Jul 2024 15:21:54 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.18114v1</guid></item><item><title>A unified theory and statistical learning approach for traffic conflict detection</title><link>http://arxiv.org/abs/2407.10959v2</link><description>This study proposes a unified theory and statistical learning approach fortraffic conflict detection, addressing the long-existing call for a consistentand comprehensive methodology to evaluate the collision risk emerging in roaduser interactions. The proposed theory assumes context-dependent probabilisticcollision risk and frames conflict detection as assessing this risk bystatistical learning of extreme events in daily interactions. Experiments usingreal-world trajectory data are conducted in this study, where a unified metricof conflict is trained with lane-changing interactions on German highways andapplied to near-crash events from the 100-Car Naturalistic Driving Study in theU.S. Results of the experiments demonstrate that the trained metric provideseffective collision warnings, generalises across distinct datasets and trafficenvironments, covers a broad range of conflicts, and delivers a long-taileddistribution of conflict intensity. Reflecting on these results, the unifiedtheory ensures consistent evaluation by a generic formulation that encompassesvarying assumptions of traffic conflicts; the statistical learning approachthen enables a comprehensive consideration of influencing factors such asmotion states of road users, environment conditions, and participantcharacteristics. Therefore, the theory and learning approach jointly provide anexplainable and adaptable methodology for conflict detection among differentroad users and across various interaction scenarios. This promises to reduceaccidents and improve overall traffic safety, by enhanced safety assessment oftraffic infrastructures, more effective collision warning systems forautonomous driving, and a deeper understanding of road user behaviour indifferent traffic conditions.</description><author>Yiru Jiao, Simeon C. Calvert, Sander van Cranenburgh, Hans van Lint</author><pubDate>Thu, 25 Jul 2024 15:21:16 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.10959v2</guid></item><item><title>Keypoint Promptable Re-Identification</title><link>http://arxiv.org/abs/2407.18112v1</link><description>Occluded Person Re-Identification (ReID) is a metric learning task thatinvolves matching occluded individuals based on their appearance. While manystudies have tackled occlusions caused by objects, multi-person occlusionsremain less explored. In this work, we identify and address a criticalchallenge overlooked by previous occluded ReID methods: the Multi-PersonAmbiguity (MPA) arising when multiple individuals are visible in the samebounding box, making it impossible to determine the intended ReID target amongthe candidates. Inspired by recent work on prompting in vision, we introduceKeypoint Promptable ReID (KPR), a novel formulation of the ReID problem thatexplicitly complements the input bounding box with a set of semantic keypointsindicating the intended target. Since promptable re-identification is anunexplored paradigm, existing ReID datasets lack the pixel-level annotationsnecessary for prompting. To bridge this gap and foster further research on thistopic, we introduce Occluded-PoseTrack ReID, a novel ReID dataset withkeypoints labels, that features strong inter-person occlusions. Furthermore, werelease custom keypoint labels for four popular ReID benchmarks. Experiments onperson retrieval, but also on pose tracking, demonstrate that our methodsystematically surpasses previous state-of-the-art approaches on variousoccluded scenarios. Our code, dataset and annotations are available athttps://github.com/VlSomers/keypoint_promptable_reidentification.</description><author>Vladimir Somers, Christophe De Vleeschouwer, Alexandre Alahi</author><pubDate>Thu, 25 Jul 2024 15:20:58 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.18112v1</guid></item><item><title>Towards More Practical Group Activity Detection: A New Benchmark and Model</title><link>http://arxiv.org/abs/2312.02878v2</link><description>Group activity detection (GAD) is the task of identifying members of eachgroup and classifying the activity of the group at the same time in a video.While GAD has been studied recently, there is still much room for improvementin both dataset and methodology due to their limited capability to addresspractical GAD scenarios. To resolve these issues, we first present a newdataset, dubbed Caf\'e. Unlike existing datasets, Caf\'e is constructedprimarily for GAD and presents more practical scenarios and metrics, as well asbeing large-scale and providing rich annotations. Along with the dataset, wepropose a new GAD model that deals with an unknown number of groups and latentgroup members efficiently and effectively. We evaluated our model on threedatasets including Caf\'e, where it outperformed previous work in terms of bothaccuracy and inference speed.</description><author>Dongkeun Kim, Youngkil Song, Minsu Cho, Suha Kwak</author><pubDate>Thu, 25 Jul 2024 15:20:48 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.02878v2</guid></item><item><title>MapTune: Advancing ASIC Technology Mapping via Reinforcement Learning Guided Library Tuning</title><link>http://arxiv.org/abs/2407.18110v1</link><description>Technology mapping involves mapping logical circuits to a library of cells.Traditionally, the full technology library is used, leading to a large searchspace and potential overhead. Motivated by randomly sampled technology mappingcase studies, we propose MapTune framework that addresses this challenge byutilizing reinforcement learning to make design-specific choices during cellselection. By learning from the environment, MapTune refines the cell selectionprocess, resulting in a reduced search space and potentially improved mappingquality. The effectiveness of MapTune is evaluated on a wide range of benchmarks,different technology libraries and technology mappers. The experimental resultsdemonstrate that MapTune achieves higher mapping accuracy and reducingdelay/area across diverse circuit designs, technology libraries and mappers.The paper also discusses the Pareto-Optimal exploration and confirms theperpetual delay-area trade-off. Conducted on benchmark suites ISCAS 85/89,ITC/ISCAS 99, VTR8.0 and EPFL benchmarks, the post-technology mapping andpost-sizing quality-of-results (QoR) have been significantly improved, withaverage Area-Delay Product (ADP) improvement of 22.54\% among all differentexploration settings in MapTune. The improvements are consistently remained forfour different technologies (7nm, 45nm, 130nm, and 180 nm) and two differentmappers.</description><author>Mingju Liu, Daniel Robinson, Yingjie Li, Cunxi Yu</author><pubDate>Thu, 25 Jul 2024 15:18:47 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.18110v1</guid></item><item><title>Graph Neural Ordinary Differential Equations for Coarse-Grained Socioeconomic Dynamics</title><link>http://arxiv.org/abs/2407.18108v1</link><description>We present a data-driven machine-learning approach for modeling space-timesocioeconomic dynamics. Through coarse-graining fine-scale observations, ourmodeling framework simplifies these complex systems to a set of tractablemechanistic relationships -- in the form of ordinary differential equations --while preserving critical system behaviors. This approach allows for expedited'what if' studies and sensitivity analyses, essential for informedpolicy-making. Our findings, from a case study of Baltimore, MD, indicate thatthis machine learning-augmented coarse-grained model serves as a powerfulinstrument for deciphering the complex interactions between social factors,geography, and exogenous stressors, offering a valuable asset for systemforecasting and resilience planning.</description><author>James Koch, Pranab Roy Chowdhury, Heng Wan, Parin Bhaduri, Jim Yoon, Vivek Srikrishnan, W. Brent Daniel</author><pubDate>Thu, 25 Jul 2024 15:12:46 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.18108v1</guid></item><item><title>Multi-Resolution Histopathology Patch Graphs for Ovarian Cancer Subtyping</title><link>http://arxiv.org/abs/2407.18105v1</link><description>Computer vision models are increasingly capable of classifying ovarianepithelial cancer subtypes, but they differ from pathologists by processingsmall tissue patches at a single resolution. Multi-resolution graph modelsleverage the spatial relationships of patches at multiple magnifications,learning the context for each patch. In this study, we conduct the mostthorough validation of a graph model for ovarian cancer subtyping to date.Seven models were tuned and trained using five-fold cross-validation on a setof 1864 whole slide images (WSIs) from 434 patients treated at Leeds TeachingHospitals NHS Trust. The cross-validation models were ensembled and evaluatedusing a balanced hold-out test set of 100 WSIs from 30 patients, and anexternal validation set of 80 WSIs from 80 patients in the Transcanadian Study.The best-performing model, a graph model using 10x+20x magnification data, gavebalanced accuracies of 73%, 88%, and 99% in cross-validation, hold-out testing,and external validation, respectively. However, this only exceeded theperformance of attention-based multiple instance learning in externalvalidation, with a 93% balanced accuracy. Graph models benefitted greatly fromusing the UNI foundation model rather than an ImageNet-pretrained ResNet50 forfeature extraction, with this having a much greater effect on performance thanchanging the subsequent classification approach. The accuracy of the combinedfoundation model and multi-resolution graph network offers a step towards theclinical applicability of these models, with a new highest-reported performancefor this task, though further validations are still required to ensure therobustness and usability of the models.</description><author>Jack Breen, Katie Allen, Kieran Zucker, Nicolas M. Orsi, Nishant Ravikumar</author><pubDate>Thu, 25 Jul 2024 15:08:54 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.18105v1</guid></item><item><title>Fine-Tuning Large Language Models for Stock Return Prediction Using Newsflow</title><link>http://arxiv.org/abs/2407.18103v1</link><description>Large language models (LLMs) and their fine-tuning techniques havedemonstrated superior performance in various language understanding andgeneration tasks. This paper explores fine-tuning LLMs for stock returnforecasting with financial newsflow. In quantitative investing, returnforecasting is fundamental for subsequent tasks like stock picking, portfoliooptimization, etc. We formulate the model to include text representation andforecasting modules. We propose to compare the encoder-only and decoder-onlyLLMs, considering they generate text representations in distinct ways. Theimpact of these different representations on forecasting performance remains anopen question. Meanwhile, we compare two simple methods of integrating LLMs'token-level representations into the forecasting module. The experiments onreal news and investment universes reveal that: (1) aggregated representationsfrom LLMs' token-level embeddings generally produce return predictions thatenhance the performance of long-only and long-short portfolios; (2) in therelatively large investment universe, the decoder LLMs-based prediction modelleads to stronger portfolios, whereas in the small universes, there are noconsistent winners. Among the three LLMs studied (DeBERTa, Mistral, Llama),Mistral performs more robustly across different universes; (3) returnpredictions derived from LLMs' text representations are a strong signal forportfolio construction, outperforming conventional sentiment scores.</description><author>Tian Guo, Emmanuel Hauptmann</author><pubDate>Thu, 25 Jul 2024 15:07:35 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.18103v1</guid></item><item><title>Review of Machine Learning Methods for Additive Manufacturing of Functionally Graded Materials</title><link>http://arxiv.org/abs/2309.16571v2</link><description>Additive Manufacturing (AM) is a transformative manufacturing technologyenabling direct fabrication of complex parts layer-be-layer from 3D modelingdata. Among AM applications, the fabrication of Functionally Graded Materials(FGMs) has significant importance due to the potential to enhance componentperformance across several industries. FGMs are manufactured with a gradientcomposition transition between dissimilar materials, enabling the design of newmaterials with location-dependent mechanical and physical properties. Thisstudy presents a comprehensive review of published literature pertaining to theimplementation of Machine Learning (ML) techniques in AM, with an emphasis onML-based methods for optimizing FGMs fabrication processes. Through anextensive survey of the literature, this review article explores the role of MLin addressing the inherent challenges in FGMs fabrication and encompassesparameter optimization, defect detection, and real-time monitoring. The articlealso provides a discussion of future research directions and challenges inemploying ML-based methods in AM fabrication of FGMs.</description><author>Mohammad Karimzadeh, Deekshith Basvoju, Aleksandar Vakanski, Indrajit Charit, Fei Xu, Xinchang Zhang</author><pubDate>Thu, 25 Jul 2024 15:04:31 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2309.16571v2</guid></item><item><title>Action2Sound: Ambient-Aware Generation of Action Sounds from Egocentric Videos</title><link>http://arxiv.org/abs/2406.09272v3</link><description>Generating realistic audio for human actions is important for manyapplications, such as creating sound effects for films or virtual realitygames. Existing approaches implicitly assume total correspondence between thevideo and audio during training, yet many sounds happen off-screen and haveweak to no correspondence with the visuals -- resulting in uncontrolled ambientsounds or hallucinations at test time. We propose a novel ambient-aware audiogeneration model, AV-LDM. We devise a novel audio-conditioning mechanism tolearn to disentangle foreground action sounds from the ambient backgroundsounds in in-the-wild training videos. Given a novel silent video, our modeluses retrieval-augmented generation to create audio that matches the visualcontent both semantically and temporally. We train and evaluate our model ontwo in-the-wild egocentric video datasets, Ego4D and EPIC-KITCHENS, and weintroduce Ego4D-Sounds -- 1.2M curated clips with action-audio correspondence.Our model outperforms an array of existing methods, allows controllablegeneration of the ambient sound, and even shows promise for generalizing tocomputer graphics game clips. Overall, our approach is the first to focusvideo-to-audio generation faithfully on the observed visual content despitetraining from uncurated clips with natural background sounds.</description><author>Changan Chen, Puyuan Peng, Ami Baid, Zihui Xue, Wei-Ning Hsu, David Harwath, Kristen Grauman</author><pubDate>Thu, 25 Jul 2024 15:03:37 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.09272v3</guid></item><item><title>DINOv2 Rocks Geological Image Analysis: Classification, Segmentation, and Interpretability</title><link>http://arxiv.org/abs/2407.18100v1</link><description>This study investigates the interpretability, classification, andsegmentation of CT-scan images of rock samples, with a particular focus on theapplication of DINOv2 within Geosciences. We compared various segmentationtechniques to evaluate their efficacy, efficiency, and adaptability ingeological image analysis. The methods assessed include the Otsu thresholdingmethod, clustering techniques (K-means and fuzzy C-means), a supervised machinelearning approach (Random Forest), and deep learning methods (UNet and DINOv2).We tested these methods using ten binary sandstone datasets and threemulti-class calcite datasets. To begin, we provide a thorough interpretabilityanalysis of DINOv2's features in the geoscientific context, discussing itssuitability and inherent ability to process CT-scanned rock data. In terms ofclassification, the out-of-the-box DINOv2 demonstrates an impressive capabilityto perfectly classify rock images, even when the CT scans are out of itsoriginal training set. Regarding segmentation, thresholding and unsupervisedmethods, while fast, perform poorly despite image preprocessing, whereassupervised methods show better results. We underscore the computational demandsof deep learning but highlight its minimal intervention, superiorgeneralization, and performance without additional image preprocessing.Additionally, we observe a lack of correlation between a network's depth or thenumber of parameters and its performance. Our results show that a LoRAfine-tuned DINOv2 excels in out-of-distribution segmentation and significantlyoutperforms other methods in multi-class segmentation. By systematicallycomparing these methods, we identify the most efficient strategy for meticulousand laborious segmentation tasks. DINOv2 proves advantageous, achievingsegmentations that could be described as "better than ground-truth" againstrelatively small training sets.</description><author>Florent Brondolo, Samuel Beaussant</author><pubDate>Thu, 25 Jul 2024 15:03:36 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.18100v1</guid></item><item><title>SSTD: Stripe-Like Space Target Detection using Single-Point Supervision</title><link>http://arxiv.org/abs/2407.18097v1</link><description>Stripe-like space target detection (SSTD) plays a key role in enhancing spacesituational awareness and assessing spacecraft behaviour. This domain facesthree challenges: the lack of publicly available datasets, interference fromstray light and stars, and the variability of stripe-like targets, whichcomplicates pixel-level annotation. In response, we introduces`AstroStripeSet', a pioneering dataset designed for SSTD, aiming to bridge thegap in academic resources and advance research in SSTD. Furthermore, we proposea novel pseudo-label evolution teacher-student framework with single-pointsupervision. This framework starts with generating initial pseudo-labels usingthe zero-shot capabilities of the Segment Anything Model (SAM) in asingle-point setting, and refines these labels iteratively. In our framework,the fine-tuned StripeSAM serves as the teacher and the newly developedStripeNet as the student, consistently improving segmentation performance byimproving the quality of pseudo-labels. We also introduce `GeoDice', a new lossfunction customized for the linear characteristics of stripe-like targets.Extensive experiments show that the performance of our approach matches fullysupervised methods on all evaluation metrics, establishing a newstate-of-the-art (SOTA) benchmark. Our dataset and code will be made publiclyavailable.</description><author>Zijian Zhu, Ali Zia, Xuesong Li, Bingbing Dan, Yuebo Ma, Enhai Liu, Rujin Zhao</author><pubDate>Thu, 25 Jul 2024 15:02:24 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.18097v1</guid></item><item><title>Privacy Threats and Countermeasures in Federated Learning for Internet of Things: A Systematic Review</title><link>http://arxiv.org/abs/2407.18096v1</link><description>Federated Learning (FL) in the Internet of Things (IoT) environments canenhance machine learning by utilising decentralised data, but at the same time,it might introduce significant privacy and security concerns due to theconstrained nature of IoT devices. This represents a research challenge that weaim to address in this paper. We systematically analysed recent literature toidentify privacy threats in FL within IoT environments, and evaluate thedefensive measures that can be employed to mitigate these threats. Using aSystematic Literature Review (SLR) approach, we searched five publicationdatabases (Scopus, IEEE Xplore, Wiley, ACM, and Science Direct), collatingrelevant papers published between 2017 and April 2024, a period which spansfrom the introduction of FL until now. Guided by the PRISMA protocol, weselected 49 papers to focus our systematic review on. We analysed these papers,paying special attention to the privacy threats and defensive measures --specifically within the context of IoT -- using inclusion and exclusioncriteria tailored to highlight recent advances and critical insights. Weidentified various privacy threats, including inference attacks, poisoningattacks, and eavesdropping, along with defensive measures such as DifferentialPrivacy and Secure Multi-Party Computation. These defences were evaluated fortheir effectiveness in protecting privacy without compromising the functionalintegrity of FL in IoT settings. Our review underscores the necessity forrobust and efficient privacy-preserving strategies tailored for IoTenvironments. Notably, there is a need for strategies against replay, evasion,and model stealing attacks. Exploring lightweight defensive measures andemerging technologies such as blockchain may help improve the privacy of FL inIoT, leading to the creation of FL models that can operate under variablenetwork conditions.</description><author>Adel ElZemity, Budi Arief</author><pubDate>Thu, 25 Jul 2024 15:01:56 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.18096v1</guid></item><item><title>Self-supervised learning of video representations from a child's perspective</title><link>http://arxiv.org/abs/2402.00300v2</link><description>Children learn powerful internal models of the world around them from a fewyears of egocentric visual experience. Can such internal models be learned froma child's visual experience with highly generic learning algorithms or do theyrequire strong inductive biases? Recent advances in collecting large-scale,longitudinal, developmentally realistic video datasets and genericself-supervised learning (SSL) algorithms are allowing us to begin to tacklethis nature vs. nurture question. However, existing work typically focuses onimage-based SSL algorithms and visual capabilities that can be learned fromstatic images (e.g. object recognition), thus ignoring temporal aspects of theworld. To close this gap, here we train self-supervised video models onlongitudinal, egocentric headcam recordings collected from a child over a twoyear period in their early development (6-31 months). The resulting models arehighly effective at facilitating the learning of action concepts from a smallnumber of labeled examples; they have favorable data size scaling properties;and they display emergent video interpolation capabilities. Video models alsolearn more robust object representations than image-based models trained withthe exact same data. These results suggest that important temporal aspects of achild's internal model of the world may be learnable from their visualexperience using highly generic learning algorithms and without stronginductive biases.</description><author>A. Emin Orhan, Wentao Wang, Alex N. Wang, Mengye Ren, Brenden M. Lake</author><pubDate>Thu, 25 Jul 2024 14:48:34 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.00300v2</guid></item><item><title>nnU-Net Revisited: A Call for Rigorous Validation in 3D Medical Image Segmentation</title><link>http://arxiv.org/abs/2404.09556v2</link><description>The release of nnU-Net marked a paradigm shift in 3D medical imagesegmentation, demonstrating that a properly configured U-Net architecture couldstill achieve state-of-the-art results. Despite this, the pursuit of novelarchitectures, and the respective claims of superior performance over the U-Netbaseline, continued. In this study, we demonstrate that many of these recentclaims fail to hold up when scrutinized for common validation shortcomings,such as the use of inadequate baselines, insufficient datasets, and neglectedcomputational resources. By meticulously avoiding these pitfalls, we conduct athorough and comprehensive benchmarking of current segmentation methodsincluding CNN-based, Transformer-based, and Mamba-based approaches. In contrastto current beliefs, we find that the recipe for state-of-the-art performance is1) employing CNN-based U-Net models, including ResNet and ConvNeXt variants, 2)using the nnU-Net framework, and 3) scaling models to modern hardwareresources. These results indicate an ongoing innovation bias towards novelarchitectures in the field and underscore the need for more stringentvalidation standards in the quest for scientific progress.</description><author>Fabian Isensee, Tassilo Wald, Constantin Ulrich, Michael Baumgartner, Saikat Roy, Klaus Maier-Hein, Paul F. Jaeger</author><pubDate>Thu, 25 Jul 2024 14:42:11 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.09556v2</guid></item><item><title>PEFT-U: Parameter-Efficient Fine-Tuning for User Personalization</title><link>http://arxiv.org/abs/2407.18078v1</link><description>The recent emergence of Large Language Models (LLMs) has heralded a new eraof human-AI interaction. These sophisticated models, exemplified by Chat-GPTand its successors, have exhibited remarkable capabilities in languageunderstanding. However, as these LLMs have undergone exponential growth, acrucial dimension that remains understudied is the personalization of thesemodels. Large foundation models such as GPT-3 etc. focus on creating auniversal model that serves a broad range of tasks and users. This approachemphasizes the model's generalization capabilities, treating users as acollective rather than as distinct individuals. While practical for many commonapplications, this one-size-fits-all approach often fails to address the richtapestry of human diversity and individual needs. To explore this issue weintroduce the PEFT-U Benchmark: a new dataset for building and evaluating NLPmodels for user personalization. \datasetname{} consists of a series ofuser-centered tasks containing diverse and individualized expressions where thepreferences of users can potentially differ for the same input. Using PEFT-U,we explore the challenge of efficiently personalizing LLMs to accommodateuser-specific preferences in the context of diverse user-centered tasks.</description><author>Christopher Clarke, Yuzhao Heng, Lingjia Tang, Jason Mars</author><pubDate>Thu, 25 Jul 2024 14:36:18 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.18078v1</guid></item><item><title>Uncovering Latent Memories: Assessing Data Leakage and Memorization Patterns in Frontier AI Models</title><link>http://arxiv.org/abs/2406.14549v2</link><description>Frontier AI systems are making transformative impacts across society, butsuch benefits are not without costs: models trained on web-scale datasetscontaining personal and private data raise profound concerns about data privacyand security. Language models are trained on extensive corpora includingpotentially sensitive or proprietary information, and the risk of data leakage- where the model response reveals pieces of such information - remainsinadequately understood. Prior work has investigated what factors drivememorization and have identified that sequence complexity and the number ofrepetitions drive memorization. Here, we focus on the evolution of memorizationover training. We begin by reproducing findings that the probability ofmemorizing a sequence scales logarithmically with the number of times it ispresent in the data. We next show that sequences which are apparently notmemorized after the first encounter can be "uncovered" throughout the course oftraining even without subsequent encounters, a phenomenon we term "latentmemorization". The presence of latent memorization presents a challenge fordata privacy as memorized sequences may be hidden at the final checkpoint ofthe model but remain easily recoverable. To this end, we develop a diagnostictest relying on the cross entropy loss to uncover latent memorized sequenceswith high accuracy.</description><author>Sunny Duan, Mikail Khona, Abhiram Iyer, Rylan Schaeffer, Ila R Fiete</author><pubDate>Thu, 25 Jul 2024 14:33:33 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.14549v2</guid></item><item><title>Clustering with minimum spanning trees: How good can it be?</title><link>http://arxiv.org/abs/2303.05679v3</link><description>Minimum spanning trees (MSTs) provide a convenient representation of datasetsin numerous pattern recognition activities. Moreover, they are relatively fastto compute. In this paper, we quantify the extent to which they are meaningfulin low-dimensional partitional data clustering tasks. By identifying the upperbounds for the agreement between the best (oracle) algorithm and the expertlabels from a large battery of benchmark data, we discover that MST methods canbe very competitive. Next, we review, study, extend, and generalise a fewexisting, state-of-the-art MST-based partitioning schemes. This leads to somenew noteworthy approaches. Overall, the Genie and the information-theoreticmethods often outperform the non-MST algorithms such as K-means, Gaussianmixtures, spectral clustering, Birch, density-based, and classical hierarchicalagglomerative procedures. Nevertheless, we identify that there is still someroom for improvement, and thus the development of novel algorithms isencouraged.</description><author>Marek Gagolewski, Anna Cena, Maciej Bartoszuk, Łukasz Brzozowski</author><pubDate>Thu, 25 Jul 2024 14:32:51 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2303.05679v3</guid></item><item><title>Normalised clustering accuracy: An asymmetric external cluster validity measure</title><link>http://arxiv.org/abs/2209.02935v4</link><description>There is no, nor will there ever be, single best clustering algorithm.Nevertheless, we would still like to be able to distinguish between methodsthat work well on certain task types and those that systematicallyunderperform. Clustering algorithms are traditionally evaluated using eitherinternal or external validity measures. Internal measures quantify differentaspects of the obtained partitions, e.g., the average degree of clustercompactness or point separability. However, their validity is questionablebecause the clusterings they endorse can sometimes be meaningless. Externalmeasures, on the other hand, compare the algorithms' outputs to fixed groundtruth groupings provided by experts. In this paper, we argue that the commonlyused classical partition similarity scores, such as the normalised mutualinformation, Fowlkes-Mallows, or adjusted Rand index, miss some desirableproperties. In particular, they do not identify worst-case scenarios correctly,nor are they easily interpretable. As a consequence, the evaluation ofclustering algorithms on diverse benchmark datasets can be difficult. To remedythese issues, we propose and analyse a new measure: a version of the optimalset-matching accuracy, which is normalised, monotonic with respect to somesimilarity relation, scale-invariant, and corrected for the imbalancedness ofcluster sizes (but neither symmetric nor adjusted for chance).</description><author>Marek Gagolewski</author><pubDate>Thu, 25 Jul 2024 14:31:03 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2209.02935v4</guid></item><item><title>3D Diffuser Actor: Policy Diffusion with 3D Scene Representations</title><link>http://arxiv.org/abs/2402.10885v3</link><description>Diffusion policies are conditional diffusion models that learn robot actiondistributions conditioned on the robot and environment state. They haverecently shown to outperform both deterministic and alternative actiondistribution learning formulations. 3D robot policies use 3D scene featurerepresentations aggregated from a single or multiple camera views using senseddepth. They have shown to generalize better than their 2D counterparts acrosscamera viewpoints. We unify these two lines of work and present 3D DiffuserActor, a neural policy equipped with a novel 3D denoising transformer thatfuses information from the 3D visual scene, a language instruction andproprioception to predict the noise in noised 3D robot pose trajectories. 3DDiffuser Actor sets a new state-of-the-art on RLBench with an absoluteperformance gain of 18.1% over the current SOTA on a multi-view setup and anabsolute gain of 13.1% on a single-view setup. On the CALVIN benchmark, itimproves over the current SOTA by a 9% relative increase. It also learns tocontrol a robot manipulator in the real world from a handful of demonstrations.Through thorough comparisons with the current SOTA policies and ablations ofour model, we show 3D Diffuser Actor's design choices dramatically outperform2D representations, regression and classification objectives, absoluteattentions, and holistic non-tokenized 3D scene embeddings.</description><author>Tsung-Wei Ke, Nikolaos Gkanatsios, Katerina Fragkiadaki</author><pubDate>Thu, 25 Jul 2024 14:30:22 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.10885v3</guid></item><item><title>Principal-Agent Reinforcement Learning</title><link>http://arxiv.org/abs/2407.18074v1</link><description>Contracts are the economic framework which allows a principal to delegate atask to an agent -- despite misaligned interests, and even without directlyobserving the agent's actions. In many modern reinforcement learning settings,self-interested agents learn to perform a multi-stage task delegated to them bya principal. We explore the significant potential of utilizing contracts toincentivize the agents. We model the delegated task as an MDP, and study astochastic game between the principal and agent where the principal learns whatcontracts to use, and the agent learns an MDP policy in response. We present alearning-based algorithm for optimizing the principal's contracts, whichprovably converges to the subgame-perfect equilibrium of the principal-agentgame. A deep RL implementation allows us to apply our method to very large MDPswith unknown transition dynamics. We extend our approach to multiple agents,and demonstrate its relevance to resolving a canonical sequential socialdilemma with minimal intervention to agent rewards.</description><author>Dima Ivanov, Paul Dütting, Inbal Talgam-Cohen, Tonghan Wang, David C. Parkes</author><pubDate>Thu, 25 Jul 2024 14:28:58 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.18074v1</guid></item><item><title>CSWin-UNet: Transformer UNet with Cross-Shaped Windows for Medical Image Segmentation</title><link>http://arxiv.org/abs/2407.18070v1</link><description>Deep learning, especially convolutional neural networks (CNNs) andTransformer architectures, have become the focus of extensive research inmedical image segmentation, achieving impressive results. However, CNNs comewith inductive biases that limit their effectiveness in more complex, variedsegmentation scenarios. Conversely, while Transformer-based methods excel atcapturing global and long-range semantic details, they suffer from highcomputational demands. In this study, we propose CSWin-UNet, a novel U-shapedsegmentation method that incorporates the CSWin self-attention mechanism intothe UNet to facilitate horizontal and vertical stripes self-attention. Thismethod significantly enhances both computational efficiency and receptive fieldinteractions. Additionally, our innovative decoder utilizes a content-awarereassembly operator that strategically reassembles features, guided bypredicted kernels, for precise image resolution restoration. Our extensiveempirical evaluations on diverse datasets, including synapse multi-organ CT,cardiac MRI, and skin lesions, demonstrate that CSWin-UNet maintains low modelcomplexity while delivering high segmentation accuracy.</description><author>Xiao Liu, Peng Gao, Tao Yu, Fei Wang, Ru-Yue Yuan</author><pubDate>Thu, 25 Jul 2024 14:25:17 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.18070v1</guid></item><item><title>HVM-1: Large-scale video models pretrained with nearly 5000 hours of human-like video data</title><link>http://arxiv.org/abs/2407.18067v1</link><description>We introduce Human-like Video Models (HVM-1), large-scale video modelspretrained with nearly 5000 hours of curated human-like video data (mostlyegocentric, temporally extended, continuous video recordings), using thespatiotemporal masked autoencoder (ST-MAE) algorithm. We release two 633Mparameter models trained at spatial resolutions of 224x224 and 448x448 pixels.We evaluate the performance of these models in downstream few-shot video andimage recognition tasks and compare them against a model pretrained with 1330hours of short action-oriented video clips from YouTube (Kinetics-700). HVM-1models perform competitively against the Kinetics-700 pretrained model indownstream evaluations despite substantial qualitative differences between thespatiotemporal characteristics of the corresponding pretraining datasets. HVM-1models also learn more accurate and more robust object representations comparedto models pretrained with the image-based MAE algorithm on the same data,demonstrating the potential benefits of learning to predict temporalregularities in natural videos for learning better object representations.</description><author>A. Emin Orhan</author><pubDate>Thu, 25 Jul 2024 14:21:50 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.18067v1</guid></item><item><title>Multi-Agent Deep Reinforcement Learning for Resilience Optimization in 5G RAN</title><link>http://arxiv.org/abs/2407.18066v1</link><description>Resilience is defined as the ability of a network to resist, adapt, andquickly recover from disruptions, and to continue to maintain an acceptablelevel of services from users' perspective. With the advent of future radionetworks, including advanced 5G and upcoming 6G, critical services becomeintegral to future networks, requiring uninterrupted service delivery for endusers. Unfortunately, with the growing network complexity, user mobility anddiversity, it becomes challenging to scale current resilience managementtechniques that rely on local optimizations to large dense network deployments.This paper aims to address this problem by globally optimizing the resilienceof a dense multi-cell network based on multi-agent deep reinforcement learning.Specifically, our proposed solution can dynamically tilt cell antennas andreconfigure transmit power to mitigate outages and increase both coverage andservice availability. A multi-objective optimization problem is formulated tosimultaneously satisfy resiliency constraints while maximizing the servicequality in the network area in order to minimize the impact of outages onneighbouring cells. Extensive simulations then demonstrate that with ourproposed solution, the average service availability in terms of user throughputcan be increased by up to 50-60% on average, while reaching a coverageavailability of 99% in best cases.</description><author>Soumeya Kaada, Dinh-Hieu Tran, Nguyen Van Huynh, Marie-Line Alberi Morel, Sofiene Jelassi, Gerardo Rubino</author><pubDate>Thu, 25 Jul 2024 14:19:59 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.18066v1</guid></item><item><title>Diagnosing and fixing common problems in Bayesian optimization for molecule design</title><link>http://arxiv.org/abs/2406.07709v2</link><description>Bayesian optimization (BO) is a principled approach to molecular designtasks. In this paper we explain three pitfalls of BO which can cause poorempirical performance: an incorrect prior width, over-smoothing, and inadequateacquisition function maximization. We show that with these issues addressed,even a basic BO setup is able to achieve the highest overall performance on thePMO benchmark for molecule design (Gao et al 2022). These results suggest thatBO may benefit from more attention in the machine learning for moleculescommunity.</description><author>Austin Tripp, José Miguel Hernández-Lobato</author><pubDate>Thu, 25 Jul 2024 14:17:40 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.07709v2</guid></item><item><title>Difficulty Estimation and Simplification of French Text Using LLMs</title><link>http://arxiv.org/abs/2407.18061v1</link><description>We leverage generative large language models for language learningapplications, focusing on estimating the difficulty of foreign language textsand simplifying them to lower difficulty levels. We frame both tasks asprediction problems and develop a difficulty classification model using labeledexamples, transfer learning, and large language models, demonstrating superioraccuracy compared to previous approaches. For simplification, we evaluate thetrade-off between simplification quality and meaning preservation, comparingzero-shot and fine-tuned performances of large language models. We show thatmeaningful text simplifications can be obtained with limited fine-tuning. Ourexperiments are conducted on French texts, but our methods arelanguage-agnostic and directly applicable to other foreign languages.</description><author>Henri Jamet, Yash Raj Shrestha, Michalis Vlachos</author><pubDate>Thu, 25 Jul 2024 14:16:08 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.18061v1</guid></item><item><title>Cross-Vendor Reproducibility of Radiomics-based Machine Learning Models for Computer-aided Diagnosis</title><link>http://arxiv.org/abs/2407.18060v1</link><description>Background: The reproducibility of machine-learning models in prostate cancerdetection across different MRI vendors remains a significant challenge.Methods: This study investigates Support Vector Machines (SVM) and RandomForest (RF) models trained on radiomic features extracted from T2-weighted MRIimages using Pyradiomics and MRCradiomics libraries. Feature selection wasperformed using the maximum relevance minimum redundancy (MRMR) technique. Weaimed to enhance clinical decision support through multimodal learning andfeature fusion. Results: Our SVM model, utilizing combined features fromPyradiomics and MRCradiomics, achieved an AUC of 0.74 on the Multi-Improddataset (Siemens scanner) but decreased to 0.60 on the Philips test set. The RFmodel showed similar trends, with notable robustness for models usingPyradiomics features alone (AUC of 0.78 on Philips). Conclusions: Thesefindings demonstrate the potential of multimodal feature integration to improvethe robustness and generalizability of machine-learning models for clinicaldecision support in prostate cancer detection. This study marks a significantstep towards developing reliable AI-driven diagnostic tools that maintainefficacy across various imaging platforms.</description><author>Jatin Chaudhary, Ivan Jambor, Hannu Aronen, Otto Ettala, Jani Saunavaara, Peter Boström, Jukka Heikkonen, Rajeev Kanth, Harri Merisaari</author><pubDate>Thu, 25 Jul 2024 14:16:02 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.18060v1</guid></item><item><title>I can listen but cannot read: An evaluation of two-tower multimodal systems for instrument recognition</title><link>http://arxiv.org/abs/2407.18058v1</link><description>Music two-tower multimodal systems integrate audio and text modalities into ajoint audio-text space, enabling direct comparison between songs and theircorresponding labels. These systems enable new approaches for classificationand retrieval, leveraging both modalities. Despite the promising results theyhave shown for zero-shot classification and retrieval tasks, closer inspectionof the embeddings is needed. This paper evaluates the inherent zero-shotproperties of joint audio-text spaces for the case-study of instrumentrecognition. We present an evaluation and analysis of two-tower systems forzero-shot instrument recognition and a detailed analysis of the properties ofthe pre-joint and joint embeddings spaces. Our findings suggest that audioencoders alone demonstrate good quality, while challenges remain within thetext encoder or joint space projection. Specifically, two-tower systems exhibitsensitivity towards specific words, favoring generic prompts over musicallyinformed ones. Despite the large size of textual encoders, they do not yetleverage additional textual context or infer instruments accurately from theirdescriptions. Lastly, a novel approach for quantifying the semanticmeaningfulness of the textual space leveraging an instrument ontology isproposed. This method reveals deficiencies in the systems' understanding ofinstruments and provides evidence of the need for fine-tuning text encoders onmusical data.</description><author>Yannis Vasilakis, Rachel Bittner, Johan Pauwels</author><pubDate>Thu, 25 Jul 2024 14:15:05 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.18058v1</guid></item><item><title>Physics-informed nonlinear vector autoregressive models for the prediction of dynamical systems</title><link>http://arxiv.org/abs/2407.18057v1</link><description>Machine learning techniques have recently been of great interest for solvingdifferential equations. Training these models is classically a data-fittingtask, but knowledge of the expression of the differential equation can be usedto supplement the training objective, leading to the development ofphysics-informed scientific machine learning. In this article, we focus on oneclass of models called nonlinear vector autoregression (NVAR) to solve ordinarydifferential equations (ODEs). Motivated by connections to numericalintegration and physics-informed neural networks, we explicitly derive thephysics-informed NVAR (piNVAR) which enforces the right-hand side of theunderlying differential equation regardless of NVAR construction. Because NVARand piNVAR completely share their learned parameters, we propose an augmentedprocedure to jointly train the two models. Then, using both data-driven andODE-driven metrics, we evaluate the ability of the piNVAR model to predictsolutions to various ODE systems, such as the undamped spring, a Lotka-Volterrapredator-prey nonlinear model, and the chaotic Lorenz system.</description><author>James H. Adler, Samuel Hocking, Xiaozhe Hu, Shafiqul Islam</author><pubDate>Thu, 25 Jul 2024 14:10:42 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.18057v1</guid></item><item><title>LKCell: Efficient Cell Nuclei Instance Segmentation with Large Convolution Kernels</title><link>http://arxiv.org/abs/2407.18054v1</link><description>The segmentation of cell nuclei in tissue images stained with the blood dyehematoxylin and eosin (H$\&amp;$E) is essential for various clinical applicationsand analyses. Due to the complex characteristics of cellular morphology, alarge receptive field is considered crucial for generating high-qualitysegmentation. However, previous methods face challenges in achieving a balancebetween the receptive field and computational burden. To address this issue, wepropose LKCell, a high-accuracy and efficient cell segmentation method. Itscore insight lies in unleashing the potential of large convolution kernels toachieve computationally efficient large receptive fields. Specifically, (1) Wetransfer pre-trained large convolution kernel models to the medical domain forthe first time, demonstrating their effectiveness in cell segmentation. (2) Weanalyze the redundancy of previous methods and design a new segmentationdecoder based on large convolution kernels. It achieves higher performancewhile significantly reducing the number of parameters. We evaluate our methodon the most challenging benchmark and achieve state-of-the-art results (0.5080mPQ) in cell nuclei instance segmentation with only 21.6% FLOPs compared withthe previous leading method. Our source code and models are available athttps://github.com/hustvl/LKCell.</description><author>Ziwei Cui, Jingfeng Yao, Lunbin Zeng, Juan Yang, Wenyu Liu, Xinggang Wang</author><pubDate>Thu, 25 Jul 2024 14:07:49 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.18054v1</guid></item><item><title>GaussianSR: High Fidelity 2D Gaussian Splatting for Arbitrary-Scale Image Super-Resolution</title><link>http://arxiv.org/abs/2407.18046v1</link><description>Implicit neural representations (INRs) have significantly advanced the fieldof arbitrary-scale super-resolution (ASSR) of images. Most existing INR-basedASSR networks first extract features from the given low-resolution image usingan encoder, and then render the super-resolved result via a multi-layerperceptron decoder. Although these approaches have shown promising results,their performance is constrained by the limited representation ability ofdiscrete latent codes in the encoded features. In this paper, we propose anovel ASSR method named GaussianSR that overcomes this limitation through 2DGaussian Splatting (2DGS). Unlike traditional methods that treat pixels asdiscrete points, GaussianSR represents each pixel as a continuous Gaussianfield. The encoded features are simultaneously refined and upsampled byrendering the mutually stacked Gaussian fields. As a result, long-rangedependencies are established to enhance representation ability. In addition, aclassifier is developed to dynamically assign Gaussian kernels to all pixels tofurther improve flexibility. All components of GaussianSR (i.e., encoder,classifier, Gaussian kernels, and decoder) are jointly learned end-to-end.Experiments demonstrate that GaussianSR achieves superior ASSR performance withfewer parameters than existing methods while enjoying interpretable andcontent-aware feature aggregations.</description><author>Jintong Hu, Bin Xia, Bin Chen, Wenming Yang, Lei Zhang</author><pubDate>Thu, 25 Jul 2024 13:53:48 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.18046v1</guid></item><item><title>The Geometry of Queries: Query-Based Innovations in Retrieval-Augmented Generation</title><link>http://arxiv.org/abs/2407.18044v1</link><description>Digital health chatbots powered by Large Language Models (LLMs) have thepotential to significantly improve personal health management for chronicconditions by providing accessible and on-demand health coaching andquestion-answering. However, these chatbots risk providing unverified andinaccurate information because LLMs generate responses based on patternslearned from diverse internet data. Retrieval Augmented Generation (RAG) canhelp mitigate hallucinations and inaccuracies in LLM responses by grounding iton reliable content. However, efficiently and accurately retrieving mostrelevant set of content for real-time user questions remains a challenge. Inthis work, we introduce Query-Based Retrieval Augmented Generation (QB-RAG), anovel approach that pre-computes a database of potential queries from a contentbase using LLMs. For an incoming patient question, QB-RAG efficiently matchesit against this pre-generated query database using vector search, improvingalignment between user questions and the content. We establish a theoreticalfoundation for QB-RAG and provide a comparative analysis of existing retrievalenhancement techniques for RAG systems. Finally, our empirical evaluationdemonstrates that QB-RAG significantly improves the accuracy of healthcarequestion answering, paving the way for robust and trustworthy LLM applicationsin digital health.</description><author>Eric Yang, Jonathan Amar, Jong Ha Lee, Bhawesh Kumar, Yugang Jia</author><pubDate>Thu, 25 Jul 2024 13:47:01 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.18044v1</guid></item><item><title>YOCO: You Only Calibrate Once for Accurate Extrinsic Parameter in LiDAR-Camera Systems</title><link>http://arxiv.org/abs/2407.18043v1</link><description>In a multi-sensor fusion system composed of cameras and LiDAR, preciseextrinsic calibration contributes to the system's long-term stability andaccurate perception of the environment. However, methods based on extractingand registering corresponding points still face challenges in terms ofautomation and precision. This paper proposes a novel fully automatic extrinsiccalibration method for LiDAR-camera systems that circumvents the need forcorresponding point registration. In our approach, a novel algorithm to extractrequired LiDAR correspondence point is proposed. This method can effectivelyfilter out irrelevant points by computing the orientation of plane point cloudsand extracting points by applying distance- and density-based thresholds. Weavoid the need for corresponding point registration by introducing extrinsicparameters between the LiDAR and camera into the projection of extracted pointsand constructing co-planar constraints. These parameters are then optimized tosolve for the extrinsic. We validated our method across multiple sets ofLiDAR-camera systems. In synthetic experiments, our method demonstratessuperior performance compared to current calibration techniques. Real-worlddata experiments further confirm the precision and robustness of the proposedalgorithm, with average rotation and translation calibration errors betweenLiDAR and camera of less than 0.05 degree and 0.015m, respectively. This methodenables automatic and accurate extrinsic calibration in a single one step,emphasizing the potential of calibration algorithms beyond using correspondingpoint registration to enhance the automation and precision of LiDAR-camerasystem calibration.</description><author>Tianle Zeng, Dengke He, Feifan Yan, Meixi He</author><pubDate>Thu, 25 Jul 2024 13:44:49 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.18043v1</guid></item><item><title>Lifelong Graph Summarization with Neural Networks: 2012, 2022, and a Time Warp</title><link>http://arxiv.org/abs/2407.18042v1</link><description>Summarizing web graphs is challenging due to the heterogeneity of the modeledinformation and its changes over time. We investigate the use of neuralnetworks for lifelong graph summarization. Assuming we observe the web graph ata certain time, we train the networks to summarize graph vertices. We applythis trained network to summarize the vertices of the changed graph at the nextpoint in time. Subsequently, we continue training and evaluating the network toperform lifelong graph summarization. We use the GNNs Graph-MLP and GraphSAINT,as well as an MLP baseline, to summarize the temporal graphs. We compare$1$-hop and $2$-hop summaries. We investigate the impact of reusing parametersfrom a previous snapshot by measuring the backward and forward transfer and theforgetting rate of the neural networks. Our extensive experiments on ten weeklysnapshots of a web graph with over $100$M edges, sampled in 2012 and 2022, showthat all networks predominantly use $1$-hop information to determine thesummary, even when performing $2$-hop summarization. Due to the heterogeneityof web graphs, in some snapshots, the $2$-hop summary produces over ten timesmore vertex summaries than the $1$-hop summary. When using the network trainedon the last snapshot from 2012 and applying it to the first snapshot of 2022,we observe a strong drop in accuracy. We attribute this drop over the ten-yeartime warp to the strongly increased heterogeneity of the web graph in 2022.</description><author>Jonatan Frank, Marcel Hoffmann, Nicolas Lell, David Richerby, Ansgar Scherp</author><pubDate>Thu, 25 Jul 2024 13:44:42 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.18042v1</guid></item><item><title>InternVideo2: Scaling Foundation Models for Multimodal Video Understanding</title><link>http://arxiv.org/abs/2403.15377v2</link><description>We introduce InternVideo2, a new family of video foundation models (ViFM)that achieve the state-of-the-art results in video recognition, video-texttasks, and video-centric dialogue. Our core design is a progressive trainingapproach that unifies the masked video modeling, crossmodal contrastivelearning, and next token prediction, scaling up the video encoder size to 6Bparameters. At the data level, we prioritize spatiotemporal consistency bysemantically segmenting videos and generating video-audio-speech captions. Thisimproves the alignment between video and text. Through extensive experiments,we validate our designs and demonstrate superior performance on over 60 videoand audio tasks. Notably, our model outperforms others on various video-relateddialogue and long video understanding benchmarks, highlighting its ability toreason and comprehend longer contexts. Code and models are available athttps://github.com/OpenGVLab/InternVideo/tree/main/InternVideo2/.</description><author>Yi Wang, Kunchang Li, Xinhao Li, Jiashuo Yu, Yinan He, Chenting Wang, Guo Chen, Baoqi Pei, Ziang Yan, Rongkun Zheng, Jilan Xu, Zun Wang, Yansong Shi, Tianxiang Jiang, Songze Li, Hongjie Zhang, Yifei Huang, Yu Qiao, Yali Wang, Limin Wang</author><pubDate>Thu, 25 Jul 2024 13:42:44 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.15377v2</guid></item><item><title>How to Train the Teacher Model for Effective Knowledge Distillation</title><link>http://arxiv.org/abs/2407.18041v1</link><description>Recently, it was shown that the role of the teacher in knowledge distillation(KD) is to provide the student with an estimate of the true Bayes conditionalprobability density (BCPD). Notably, the new findings propose that thestudent's error rate can be upper-bounded by the mean squared error (MSE)between the teacher's output and BCPD. Consequently, to enhance KD efficacy,the teacher should be trained such that its output is close to BCPD in MSEsense. This paper elucidates that training the teacher model with MSE lossequates to minimizing the MSE between its output and BCPD, aligning with itscore responsibility of providing the student with a BCPD estimate closelyresembling it in MSE terms. In this respect, through a comprehensive set ofexperiments, we demonstrate that substituting the conventional teacher trainedwith cross-entropy loss with one trained using MSE loss in state-of-the-art KDmethods consistently boosts the student's accuracy, resulting in improvementsof up to 2.6\%.</description><author>Shayan Mohajer Hamidi, Xizhen Deng, Renhao Tan, Linfeng Ye, Ahmed Hussein Salamah</author><pubDate>Thu, 25 Jul 2024 13:39:11 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.18041v1</guid></item><item><title>Anatomizing Deep Learning Inference in Web Browsers</title><link>http://arxiv.org/abs/2402.05981v2</link><description>Web applications have increasingly adopted Deep Learning (DL) throughin-browser inference, wherein DL inference performs directly within Webbrowsers. The actual performance of in-browser inference and its impacts on thequality of experience (QoE) remain unexplored, and urgently require new QoEmeasurements beyond traditional ones, e.g., mainly focusing on page load time.To bridge this gap, we make the first comprehensive performance measurement ofin-browser inference to date. Our approach proposes new metrics to measurein-browser inference: responsiveness, smoothness, and inference accuracy. Ourextensive analysis involves 9 representative DL models across Web browsers of50 popular PC devices and 20 mobile devices. The results reveal that in-browserinference exhibits a substantial latency gap, averaging 16.9 times slower onCPU and 4.9 times slower on GPU compared to native inference on PC devices. Thegap on mobile CPU and mobile GPU is 15.8 times and 7.8 times, respectively.Furthermore, we identify contributing factors to such latency gap, includingunderutilized hardware instruction sets, inherent overhead in the runtimeenvironment, resource contention within the browser, and inefficiencies insoftware libraries and GPU abstractions. Additionally, in-browser inferenceimposes significant memory demands, at times exceeding 334.6 times the size ofthe DL models themselves, partly attributable to suboptimal memory management.We also observe that in-browser inference leads to a significant 67.2% increasein the time it takes for GUI components to render within Web browsers,significantly affecting the overall user QoE of Web applications reliant onthis technology</description><author>Qipeng Wang, Shiqi Jiang, Zhenpeng Chen, Xu Cao, Yuanchun Li, Aoyu Li, Yun Ma, Ting Cao, Xuanzhe Liu</author><pubDate>Thu, 25 Jul 2024 13:37:16 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.05981v2</guid></item><item><title>Peak-Controlled Logits Poisoning Attack in Federated Distillation</title><link>http://arxiv.org/abs/2407.18039v1</link><description>Federated Distillation (FD) offers an innovative approach to distributedmachine learning, leveraging knowledge distillation for efficient and flexiblecross-device knowledge transfer without necessitating the upload of extensivemodel parameters to a central server. While FD has gained popularity, itsvulnerability to poisoning attacks remains underexplored. To address this gap,we previously introduced FDLA (Federated Distillation Logits Attack), a methodthat manipulates logits communication to mislead and degrade the performance ofclient models. However, the impact of FDLA on participants with differentidentities and the effects of malicious modifications at various stages ofknowledge transfer remain unexplored. To this end, we present PCFDLA(Peak-Controlled Federated Distillation Logits Attack), an advanced and morestealthy logits poisoning attack method for FD. PCFDLA enhances theeffectiveness of FDLA by carefully controlling the peak values of logits tocreate highly misleading yet inconspicuous modifications. Furthermore, weintroduce a novel metric for better evaluating attack efficacy, demonstratingthat PCFDLA maintains stealth while being significantly more disruptive tovictim models compared to its predecessors. Experimental results across variousdatasets confirm the superior impact of PCFDLA on model accuracy, solidifyingits potential threat in federated distillation systems.</description><author>Yuhan Tang, Aoxu Zhang, Zhiyuan Wu, Bo Gao, Tian Wen, Yuwei Wang, Sheng Sun</author><pubDate>Thu, 25 Jul 2024 13:36:42 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.18039v1</guid></item><item><title>TiCoSS: Tightening the Coupling between Semantic Segmentation and Stereo Matching within A Joint Learning Framework</title><link>http://arxiv.org/abs/2407.18038v1</link><description>Semantic segmentation and stereo matching, respectively analogous to theventral and dorsal streams in our human brain, are two key components ofautonomous driving perception systems. Addressing these two tasks with separatenetworks is no longer the mainstream direction in developing computer visionalgorithms, particularly with the recent advances in large vision models andembodied artificial intelligence. The trend is shifting towards combining themwithin a joint learning framework, especially emphasizing feature sharingbetween the two tasks. The major contributions of this study lie incomprehensively tightening the coupling between semantic segmentation andstereo matching. Specifically, this study introduces three novelties: (1) atightly coupled, gated feature fusion strategy, (2) a hierarchical deepsupervision strategy, and (3) a coupling tightening loss function. The combineduse of these technical contributions results in TiCoSS, a state-of-the-artjoint learning framework that simultaneously tackles semantic segmentation andstereo matching. Through extensive experiments on the KITTI and vKITTI2datasets, along with qualitative and quantitative analyses, we validate theeffectiveness of our developed strategies and loss function, and demonstrateits superior performance compared to prior arts, with a notable increase inmIoU by over 9%. Our source code will be publicly available atmias.group/TiCoSS upon publication.</description><author>Guanfeng Tang, Zhiyuan Wu, Rui Fan</author><pubDate>Thu, 25 Jul 2024 13:31:55 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.18038v1</guid></item></channel></rss>