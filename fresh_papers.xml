<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/"><channel><title>Arxivfresh papers</title><link></link><description>Arxiv paper</description><language>en-US</language><lastBuildDate>Tue, 19 Nov 2024 01:00:04 GMT</lastBuildDate><generator>rfeed v1.0.0</generator><docs>https://github.com/svpino/rfeed/blob/master/README.md</docs><item><title>VeriGraph: Scene Graphs for Execution Verifiable Robot Planning</title><link>http://arxiv.org/abs/2411.10446v1</link><description>Recent advancements in vision-language models (VLMs) offer potential forrobot task planning, but challenges remain due to VLMs' tendency to generateincorrect action sequences. To address these limitations, we propose VeriGraph,a novel framework that integrates VLMs for robotic planning while verifyingaction feasibility. VeriGraph employs scene graphs as an intermediaterepresentation, capturing key objects and spatial relationships to improve planverification and refinement. The system generates a scene graph from inputimages and uses it to iteratively check and correct action sequences generatedby an LLM-based task planner, ensuring constraints are respected and actionsare executable. Our approach significantly enhances task completion ratesacross diverse manipulation scenarios, outperforming baseline methods by 58%for language-based tasks and 30% for image-based tasks.</description><author>Daniel Ekpo, Mara Levy, Saksham Suri, Chuong Huynh, Abhinav Shrivastava</author><pubDate>Fri, 15 Nov 2024 18:59:51 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2411.10446v1</guid></item><item><title>Enhancing the Reasoning Ability of Multimodal Large Language Models via Mixed Preference Optimization</title><link>http://arxiv.org/abs/2411.10442v1</link><description>Existing open-source multimodal large language models (MLLMs) generallyfollow a training process involving pre-training and supervised fine-tuning.However, these models suffer from distribution shifts, which limit theirmultimodal reasoning, particularly in the Chain-of-Thought (CoT) performance.To address this, we introduce a preference optimization (PO) process to enhancethe multimodal reasoning capabilities of MLLMs. Specifically, (1) on the dataside, we design an automated preference data construction pipeline to createMMPR, a high-quality, large-scale multimodal reasoning preference dataset. and(2) on the model side, we explore integrating PO with MLLMs, developing asimple yet effective method, termed Mixed Preference Optimization (MPO), whichboosts multimodal CoT performance. Our approach demonstrates improvedperformance across multiple benchmarks, particularly in multimodal reasoningtasks. Notably, our model, InternVL2-8B-MPO, achieves an accuracy of 67.0 onMathVista, outperforming InternVL2-8B by 8.7 points and achieving performancecomparable to the 10x larger InternVL2-76B. We hope this study could inspirefurther advancements in MLLMs. Code, data, and model shall be publiclyreleased.</description><author>Weiyun Wang, Zhe Chen, Wenhai Wang, Yue Cao, Yangzhou Liu, Zhangwei Gao, Jinguo Zhu, Xizhou Zhu, Lewei Lu, Yu Qiao, Jifeng Dai</author><pubDate>Fri, 15 Nov 2024 18:59:27 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2411.10442v1</guid></item><item><title>Temporal Patterns of Multiple Long-Term Conditions in Individuals with Intellectual Disability Living in Wales: An Unsupervised Clustering Approach to Disease Trajectories</title><link>http://arxiv.org/abs/2411.08894v2</link><description>Identifying and understanding the co-occurrence of multiple long-termconditions (MLTC) in individuals with intellectual disabilities (ID) is vitalfor effective healthcare management. These individuals often face earlier onsetand higher prevalence of MLTCs, yet specific co-occurrence patterns remainunexplored. This study applies an unsupervised approach to characterise MLTCclusters based on shared disease trajectories using electronic health records(EHRs) from 13069 individuals with ID in Wales (2000-2021). Diseaseassociations and temporal directionality were assessed, followed by spectralclustering to group shared trajectories. The population consisted of 52.3%males and 47.7% females, with an average of 4.5 conditions per patient. Malesunder 45 formed a single cluster dominated by neurological conditions (32.4%),while males above 45 had three clusters, the largest characterised circulatory(51.8%). Females under 45 formed one cluster with digestive conditions (24.6%)as most prevalent, while those aged 45 and older showed two clusters: onedominated by circulatory (34.1%), and the other by digestive (25.9%) andmusculoskeletal (21.9%) system conditions. Mental illness, epilepsy, and refluxwere common across groups. These clusters offer insights into diseaseprogression in individuals with ID, informing targeted interventions andpersonalised healthcare strategies.</description><author>Rania Kousovista, Georgina Cosma, Emeka Abakasanga, Ashley Akbari, Francesco Zaccardi, Gyuchan Thomas Jun, Reza Kiani, Satheesh Gangadharan</author><pubDate>Fri, 15 Nov 2024 18:58:47 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2411.08894v2</guid></item><item><title>LLaVA-o1: Let Vision Language Models Reason Step-by-Step</title><link>http://arxiv.org/abs/2411.10440v1</link><description>Large language models have demonstrated substantial advancements in reasoningcapabilities, particularly through inference-time scaling, as illustrated bymodels such as OpenAI's o1. However, current Vision-Language Models (VLMs)often struggle to perform systematic and structured reasoning, especially whenhandling complex visual question-answering tasks. In this work, we introduceLLaVA-o1, a novel VLM designed to conduct autonomous multistage reasoning.Unlike chain-of-thought prompting, LLaVA-o1 independently engages in sequentialstages of summarization, visual interpretation, logical reasoning, andconclusion generation. This structured approach enables LLaVA-o1 to achievemarked improvements in precision on reasoning-intensive tasks. To accomplishthis, we compile the LLaVA-o1-100k dataset, integrating samples from variousvisual question answering sources and providing structured reasoningannotations. Besides, we propose an inference-time stage-level beam searchmethod, which enables effective inference-time scaling. Remarkably, with only100k training samples and a simple yet effective inference time scaling method,LLaVA-o1 not only outperforms its base model by 8.9% on a wide range ofmultimodal reasoning benchmarks, but also surpasses the performance of largerand even closed-source models, such as Gemini-1.5-pro, GPT-4o-mini, andLlama-3.2-90B-Vision-Instruct.</description><author>Guowei Xu, Peng Jin, Li Hao, Yibing Song, Lichao Sun, Li Yuan</author><pubDate>Fri, 15 Nov 2024 18:58:31 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2411.10440v1</guid></item><item><title>MARS: Unleashing the Power of Variance Reduction for Training Large Models</title><link>http://arxiv.org/abs/2411.10438v1</link><description>Training deep neural networks--and more recently, large models--demandsefficient and scalable optimizers. Adaptive gradient algorithms like Adam,AdamW, and their variants have been central to this task. Despite thedevelopment of numerous variance reduction algorithms in the past decade aimedat accelerating stochastic optimization in both convex and nonconvex settings,variance reduction has not found widespread success in training deep neuralnetworks or large language models. Consequently, it has remained a less favoredapproach in modern AI. In this paper, to unleash the power of variancereduction for efficient training of large models, we propose a unifiedoptimization framework, MARS (Make vAriance Reduction Shine), which reconcilespreconditioned gradient methods with variance reduction via a scaled stochasticrecursive momentum technique. Within our framework, we introduce threeinstances of MARS that leverage preconditioned gradient updates based on AdamW,Lion, and Shampoo, respectively. We also draw a connection between ouralgorithms and existing optimizers. Experimental results on training GPT-2models indicate that MARS consistently outperforms AdamW by a large margin.</description><author>Huizhuo Yuan, Yifeng Liu, Shuang Wu, Xun Zhou, Quanquan Gu</author><pubDate>Fri, 15 Nov 2024 18:57:39 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2411.10438v1</guid></item><item><title>Learning Diffusion Priors from Observations by Expectation Maximization</title><link>http://arxiv.org/abs/2405.13712v4</link><description>Diffusion models recently proved to be remarkable priors for Bayesian inverseproblems. However, training these models typically requires access to largeamounts of clean data, which could prove difficult in some settings. In thiswork, we present a novel method based on the expectation-maximization algorithmfor training diffusion models from incomplete and noisy observations only.Unlike previous works, our method leads to proper diffusion models, which iscrucial for downstream tasks. As part of our method, we propose and motivate animproved posterior sampling scheme for unconditional diffusion models. Wepresent empirical evidence supporting the effectiveness of our method.</description><author>François Rozet, Gérôme Andry, François Lanusse, Gilles Louppe</author><pubDate>Fri, 15 Nov 2024 18:57:14 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.13712v4</guid></item><item><title>Mitigating Hallucination in Multimodal Large Language Model via Hallucination-targeted Direct Preference Optimization</title><link>http://arxiv.org/abs/2411.10436v1</link><description>Multimodal Large Language Models (MLLMs) are known to hallucinate, whichlimits their practical applications. Recent works have attempted to applyDirect Preference Optimization (DPO) to enhance the performance of MLLMs, buthave shown inconsistent improvements in mitigating hallucinations. To addressthis issue more effectively, we introduce Hallucination-targeted DirectPreference Optimization (HDPO) to reduce hallucinations in MLLMs. Unlikeprevious approaches, our method tackles hallucinations from their diverse formsand causes. Specifically, we develop three types of preference pair datatargeting the following causes of MLLM hallucinations: (1) insufficient visualcapabilities, (2) long context generation, and (3) multimodal conflicts.Experimental results demonstrate that our method achieves superior performanceacross multiple hallucination evaluation datasets, surpassing moststate-of-the-art (SOTA) methods and highlighting the potential of our approach.Ablation studies and in-depth analyses further confirm the effectiveness of ourmethod and suggest the potential for further improvements through scaling up.</description><author>Yuhan Fu, Ruobing Xie, Xingwu Sun, Zhanhui Kang, Xirong Li</author><pubDate>Fri, 15 Nov 2024 18:56:01 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2411.10436v1</guid></item><item><title>The Spatial Complexity of Optical Computing and How to Reduce It</title><link>http://arxiv.org/abs/2411.10435v1</link><description>Similar to algorithms, which consume time and memory to run, hardwarerequires resources to function. For devices processing physical waves,implementing operations needs sufficient "space," as dictated by wave physics.How much space is needed to perform a certain function is a fundamentalquestion in optics, with recent research addressing it for given mathematicaloperations, but not for more general computing tasks, e.g., classification.Inspired by computational complexity theory, we study the "spatial complexity"of optical computing systems in terms of scaling laws - specifically, how theirphysical dimensions must scale as the dimension of the mathematical operationincreases - and propose a new paradigm for designing optical computing systems:space-efficient neuromorphic optics, based on structural sparsity constraintsand neural pruning methods motivated by wave physics (notably, the concept of"overlapping nonlocality"). On two mainstream platforms, free-space optics andon-chip integrated photonics, our methods demonstrate substantial sizereductions (to 1%-10% the size of conventional designs) with minimal compromiseon performance. Our theoretical and computational results reveal a trend ofdiminishing returns on accuracy as structure dimensions increase, providing anew perspective for interpreting and approaching the ultimate limits of opticalcomputing - a balanced trade-off between device size and accuracy.</description><author>Yandong Li, Francesco Monticone</author><pubDate>Fri, 15 Nov 2024 18:56:00 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2411.10435v1</guid></item><item><title>M-VAR: Decoupled Scale-wise Autoregressive Modeling for High-Quality Image Generation</title><link>http://arxiv.org/abs/2411.10433v1</link><description>There exists recent work in computer vision, named VAR, that proposes a newautoregressive paradigm for image generation. Diverging from the vanillanext-token prediction, VAR structurally reformulates the image generation intoa coarse to fine next-scale prediction. In this paper, we show that thisscale-wise autoregressive framework can be effectively decoupled into\textit{intra-scale modeling}, which captures local spatial dependencies withineach scale, and \textit{inter-scale modeling}, which models cross-scalerelationships progressively from coarse-to-fine scales. This decouplingstructure allows to rebuild VAR in a more computationally efficient manner.Specifically, for intra-scale modeling -- crucial for generating high-fidelityimages -- we retain the original bidirectional self-attention design to ensurecomprehensive modeling; for inter-scale modeling, which semantically connectsdifferent scales but is computationally intensive, we apply linear-complexitymechanisms like Mamba to substantially reduce computational overhead. We termthis new framework M-VAR. Extensive experiments demonstrate that our methodoutperforms existing models in both image quality and generation speed. Forexample, our 1.5B model, with fewer parameters and faster inference speed,outperforms the largest VAR-d30-2B. Moreover, our largest model M-VAR-d32impressively registers 1.78 FID on ImageNet 256$\times$256 and outperforms theprior-art autoregressive models LlamaGen/VAR by 0.4/0.19 and popular diffusionmodels LDM/DiT by 1.82/0.49, respectively. Code is avaiable at\url{https://github.com/OliverRensu/MVAR}.</description><author>Sucheng Ren, Yaodong Yu, Nataniel Ruiz, Feng Wang, Alan Yuille, Cihang Xie</author><pubDate>Fri, 15 Nov 2024 18:54:42 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2411.10433v1</guid></item><item><title>Mitigating Parameter Degeneracy using Joint Conditional Diffusion Model for WECC Composite Load Model in Power Systems</title><link>http://arxiv.org/abs/2411.10431v1</link><description>Data-driven modeling for dynamic systems has gained widespread attention inrecent years. Its inverse formulation, parameter estimation, aims to infer theinherent model parameters from observations. However, parameter degeneracy,where different combinations of parameters yield the same observable output,poses a critical barrier to accurately and uniquely identifying modelparameters. In the context of WECC composite load model (CLM) in power systems,utility practitioners have observed that CLM parameters carefully selected forone fault event may not perform satisfactorily in another fault. Here, weinnovate a joint conditional diffusion model-based inverse problem solver(JCDI), that incorporates a joint conditioning architecture with simultaneousinputs of multi-event observations to improve parameter generalizability.Simulation studies on the WECC CLM show that the proposed JCDI effectivelyreduces uncertainties of degenerate parameters, thus the parameter estimationerror is decreased by 42.1% compared to a single-event learning scheme. Thisenables the model to achieve high accuracy in predicting power trajectoriesunder different fault events, including electronic load tripping and motorstalling, outperforming standard deep reinforcement learning and supervisedlearning approaches. We anticipate this work will contribute to mitigatingparameter degeneracy in system dynamics, providing a general parameterestimation framework across various scientific domains.</description><author>Feiqin Zhu, Dmitrii Torbunov, Yihui Ren, Zhongjing Jiang, Tianqiao Zhao, Amirthagunaraj Yogarathnam, Meng Yue</author><pubDate>Fri, 15 Nov 2024 18:53:08 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2411.10431v1</guid></item><item><title>Private Counterfactual Retrieval With Immutable Features</title><link>http://arxiv.org/abs/2411.10429v1</link><description>In a classification task, counterfactual explanations provide the minimumchange needed for an input to be classified into a favorable class. We considerthe problem of privately retrieving the exact closest counterfactual from adatabase of accepted samples while enforcing that certain features of the inputsample cannot be changed, i.e., they are \emph{immutable}. An applicant (user)whose feature vector is rejected by a machine learning model wants to retrievethe sample closest to them in the database without altering a private subset oftheir features, which constitutes the immutable set. While doing this, the usershould keep their feature vector, immutable set and the resultingcounterfactual index information-theoretically private from the institution. Werefer to this as immutable private counterfactual retrieval (I-PCR) problemwhich generalizes PCR to a more practical setting. In this paper, we proposetwo I-PCR schemes by leveraging techniques from private information retrieval(PIR) and characterize their communication costs. Further, we quantify theinformation that the user learns about the database and compare it for theproposed schemes.</description><author>Shreya Meel, Pasan Dissanayake, Mohamed Nomeir, Sanghamitra Dutta, Sennur Ulukus</author><pubDate>Fri, 15 Nov 2024 18:50:53 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2411.10429v1</guid></item><item><title>Back to Supervision: Boosting Word Boundary Detection through Frame Classification</title><link>http://arxiv.org/abs/2411.10423v1</link><description>Speech segmentation at both word and phoneme levels is crucial for variousspeech processing tasks. It significantly aids in extracting meaningful unitsfrom an utterance, thus enabling the generation of discrete elements. In thiswork we propose a model-agnostic framework to perform word boundary detectionin a supervised manner also employing a labels augmentation technique and anoutput-frame selection strategy. We trained and tested on the Buckeye datasetand only tested on TIMIT one, using state-of-the-art encoder models, includingpre-trained solutions (Wav2Vec 2.0 and HuBERT), as well as convolutional andconvolutional recurrent networks. Our method, with the HuBERT encoder,surpasses the performance of other state-of-the-art architectures, whethertrained in supervised or self-supervised settings on the same datasets.Specifically, we achieved F-values of 0.8427 on the Buckeye dataset and 0.7436on the TIMIT dataset, along with R-values of 0.8489 and 0.7807, respectively.These results establish a new state-of-the-art for both datasets. Beyond theimmediate task, our approach offers a robust and efficient preprocessing methodfor future research in audio tokenization.</description><author>Simone Carnemolla, Salvatore Calcagno, Simone Palazzo, Daniela Giordano</author><pubDate>Fri, 15 Nov 2024 18:43:29 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2411.10423v1</guid></item><item><title>Treat Visual Tokens as Text? But Your MLLM Only Needs Fewer Efforts to See</title><link>http://arxiv.org/abs/2410.06169v2</link><description>By treating visual tokens from visual encoders as text tokens, MultimodalLarge Language Models (MLLMs) have achieved remarkable progress across diversevisual understanding tasks, leveraging the robust architectures of LargeLanguage Models (LLMs). However, as token counts grow, the quadratic scaling ofcomputation in LLMs introduces a significant efficiency bottleneck, impedingfurther scalability. Although recent approaches have explored pruning visualtokens or employing lighter LLM architectures, the computational overhead froman increasing number of visual tokens remains a substantial challenge. In this study, we investigate the redundancy in visual computation at boththe parameter and computational pattern levels within LLaVA, a representativeMLLM, and introduce a suite of streamlined strategies to enhance efficiency.These include neighbor-aware visual token attention, pruning of inactive visualattention heads, and selective layer dropping for visual computations. Byimplementing these strategies in LLaVA, we achieve a reduction in computationaldemands of 88% while maintaining model performance across key benchmarks.Additionally, we validate the existence of visual computational redundancy inother MLLMs, such as Qwen2-VL-7B and InternVL-2.0-4B/8B/26B. These resultspresent a novel pathway for MLLMs to handle dense visual tokens with minimalcomputational costs. Code and model checkpoints will be released to supportfurther research.</description><author>Zeliang Zhang, Phu Pham, Wentian Zhao, Kun Wan, Yu-Jhe Li, Jianing Zhou, Daniel Miranda, Ajinkya Kale, Chenliang Xu</author><pubDate>Fri, 15 Nov 2024 18:43:23 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.06169v2</guid></item><item><title>Evaluating Creativity and Deception in Large Language Models: A Simulation Framework for Multi-Agent Balderdash</title><link>http://arxiv.org/abs/2411.10422v1</link><description>Large Language Models (LLMs) have shown impressive capabilities in complextasks and interactive environments, yet their creativity remains underexplored.This paper introduces a simulation framework utilizing the game Balderdash toevaluate both the creativity and logical reasoning of LLMs. In Balderdash,players generate fictitious definitions for obscure terms to deceive otherswhile identifying correct definitions. Our framework enables multiple LLMagents to participate in this game, assessing their ability to produceplausible definitions and strategize based on game rules and history. Weimplemented a centralized game engine featuring various LLMs as participantsand a judge LLM to evaluate semantic equivalence. Through a series ofexperiments, we analyzed the performance of different LLMs, examining metricssuch as True Definition Ratio, Deception Ratio, and Correct Guess Ratio. Theresults provide insights into the creative and deceptive capabilities of LLMs,highlighting their strengths and areas for improvement. Specifically, the studyreveals that infrequent vocabulary in LLMs' input leads to poor reasoning ongame rules and historical context(https://github.com/ParsaHejabi/Simulation-Framework-for-Multi-Agent-Balderdash).</description><author>Parsa Hejabi, Elnaz Rahmati, Alireza S. Ziabari, Preni Golazizian, Jesse Thomason, Morteza Dehghani</author><pubDate>Fri, 15 Nov 2024 18:42:48 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2411.10422v1</guid></item><item><title>Multiscale Dubuc: A New Similarity Measure for Time Series</title><link>http://arxiv.org/abs/2411.10418v1</link><description>Quantifying similarities between time series in a meaningful way remains achallenge in time series analysis, despite many advances in the field. Mostreal-world solutions still rely on a few popular measures, such as EuclideanDistance (EuD), Longest Common Subsequence (LCSS), and Dynamic Time Warping(DTW). The strengths and weaknesses of these measures have been studiedextensively, and incremental improvements have been proposed. In this study,however, we present a different similarity measure that fuses the notion ofDubuc's variation from fractal analysis with the Intersection-over-Union (IoU)measure which is widely used in object recognition (also known as the JaccardIndex). In this proof-of-concept paper, we introduce the Multiscale DubucDistance (MDD) measure and prove that it is a metric, possessing desirableproperties such as the triangle inequality. We use 95 datasets from the UCRTime Series Classification Archive to compare MDD's performance with EuD, LCSS,and DTW. Our experiments show that MDD's overall success, without anycase-specific customization, is comparable to DTW with optimized window sizesper dataset. We also highlight several datasets where MDD's performanceimproves significantly when its single parameter is customized. Thiscustomization serves as a powerful tool for gauging MDD's sensitivity to noise.Lastly, we show that MDD's running time is linear in the length of the timeseries, which is crucial for real-world applications involving very largedatasets.</description><author>Mahsa Khazaei, Azim Ahmadzadeh, Krishna Rukmini Puthucode</author><pubDate>Fri, 15 Nov 2024 18:38:18 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2411.10418v1</guid></item><item><title>Demo: Multi-Modal Seizure Prediction System</title><link>http://arxiv.org/abs/2411.05817v2</link><description>This demo presents SeizNet, an innovative system for predicting epilepticseizures benefiting from a multi-modal sensor network and utilizing DeepLearning (DL) techniques. Epilepsy affects approximately 65 million peopleworldwide, many of whom experience drug-resistant seizures. SeizNet aims atproviding highly accurate alerts, allowing individuals to take preventivemeasures without being disturbed by false alarms. SeizNet uses a combination ofdata collected through either invasive (intracranial electroencephalogram(iEEG)) or non-invasive (electroencephalogram (EEG) and electrocardiogram(ECG)) sensors, and processed by advanced DL algorithms that are optimized forreal-time inference at the edge, ensuring privacy and minimizing datatransmission. SeizNet achieves &gt; 97% accuracy in seizure prediction whilekeeping the size and energy restrictions of an implantable device.</description><author>Ali Saeizadeh, Pietro Brach del Prever, Douglas Schonholtz, Raffaele Guida, Emrecan Demirors, Jorge M. Jimenez, Pedram Johari, Tommaso Melodia</author><pubDate>Fri, 15 Nov 2024 18:36:30 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2411.05817v2</guid></item><item><title>Towards Automatic Evaluation of Task-Oriented Dialogue Flows</title><link>http://arxiv.org/abs/2411.10416v1</link><description>Task-oriented dialogue systems rely on predefined conversation schemes(dialogue flows) often represented as directed acyclic graphs. These flows canbe manually designed or automatically generated from previously recordedconversations. Due to variations in domain expertise or reliance on differentsets of prior conversations, these dialogue flows can manifest in significantlydifferent graph structures. Despite their importance, there is no standardmethod for evaluating the quality of dialogue flows. We introduce FuDGE (FuzzyDialogue-Graph Edit Distance), a novel metric that evaluates dialogue flows byassessing their structural complexity and representational coverage of theconversation data. FuDGE measures how well individual conversations align witha flow and, consequently, how well a set of conversations is represented by theflow overall. Through extensive experiments on manually configured flows andflows generated by automated techniques, we demonstrate the effectiveness ofFuDGE and its evaluation framework. By standardizing and optimizing dialogueflows, FuDGE enables conversational designers and automated techniques toachieve higher levels of efficiency and automation.</description><author>Mehrnoosh Mirtaheri, Nikhil Varghese, Chandra Khatri, Amol Kelkar</author><pubDate>Fri, 15 Nov 2024 18:35:00 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2411.10416v1</guid></item><item><title>Large Language Model-Based Interpretable Machine Learning Control in Building Energy Systems</title><link>http://arxiv.org/abs/2402.09584v2</link><description>The potential of Machine Learning Control (MLC) in HVAC systems is hinderedby its opaque nature and inference mechanisms, which is challenging for usersand modelers to fully comprehend, ultimately leading to a lack of trust inMLC-based decision-making. To address this challenge, this paper investigatesand explores Interpretable Machine Learning (IML), a branch of Machine Learning(ML) that enhances transparency and understanding of models and theirinferences, to improve the credibility of MLC and its industrial application inHVAC systems. Specifically, we developed an innovative framework that combinesthe principles of Shapley values and the in-context learning feature of LargeLanguage Models (LLMs). While the Shapley values are instrumental in dissectingthe contributions of various features in ML models, LLM provides an in-depthunderstanding of the non-data-driven or rule-based elements in MLC; combiningthem, LLM further packages these insights into a coherent, human-understandablenarrative. The paper presents a case study to demonstrate the feasibility ofthe developed IML framework for model predictive control-based precooling underdemand response events in a virtual testbed. The results indicate that thedeveloped framework generates and explains the control signals in accordancewith the rule-based rationale.</description><author>Liang Zhang, Zhelun Chen</author><pubDate>Fri, 15 Nov 2024 18:34:42 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.09584v2</guid></item><item><title>Llama Guard 3 Vision: Safeguarding Human-AI Image Understanding Conversations</title><link>http://arxiv.org/abs/2411.10414v1</link><description>We introduce Llama Guard 3 Vision, a multimodal LLM-based safeguard forhuman-AI conversations that involves image understanding: it can be used tosafeguard content for both multimodal LLM inputs (prompt classification) andoutputs (response classification). Unlike the previous text-only Llama Guardversions (Inan et al., 2023; Llama Team, 2024b,a), it is specifically designedto support image reasoning use cases and is optimized to detect harmfulmultimodal (text and image) prompts and text responses to these prompts. LlamaGuard 3 Vision is fine-tuned on Llama 3.2-Vision and demonstrates strongperformance on the internal benchmarks using the MLCommons taxonomy. We alsotest its robustness against adversarial attacks. We believe that Llama Guard 3Vision serves as a good starting point to build more capable and robust contentmoderation tools for human-AI conversation with multimodal capabilities.</description><author>Jianfeng Chi, Ujjwal Karn, Hongyuan Zhan, Eric Smith, Javier Rando, Yiming Zhang, Kate Plawiak, Zacharie Delpierre Coudert, Kartikeya Upasani, Mahesh Pasupuleti</author><pubDate>Fri, 15 Nov 2024 18:34:07 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2411.10414v1</guid></item><item><title>Swarm Characteristics Classification Using Neural Networks</title><link>http://arxiv.org/abs/2403.19572v2</link><description>Understanding the characteristics of swarming autonomous agents is criticalfor defense and security applications. This article presents a study on usingsupervised neural network time series classification (NN TSC) to predict keyattributes and tactics of swarming autonomous agents for military contexts.Specifically, NN TSC is applied to infer two binary attributes - communicationand proportional navigation - which combine to define four mutually exclusiveswarm tactics. We identify a gap in literature on using NNs for swarmclassification and demonstrate the effectiveness of NN TSC in rapidly deducingintelligence about attacking swarms to inform counter-maneuvers. Throughsimulated swarm-vs-swarm engagements, we evaluate NN TSC performance in termsof observation window requirements, noise robustness, and scalability to swarmsize. Key findings show NNs can predict swarm behaviors with 97% accuracy usingshort observation windows of 20 time steps, while also demonstrating gracefuldegradation down to 80% accuracy under 50% noise, as well as excellentscalability to swarm sizes from 10 to 100 agents. These capabilities arepromising for real-time decision-making support in defense scenarios by rapidlyinferring insights about swarm behavior.</description><author>Donald W. Peltier III, Isaac Kaminer, Abram Clark, Marko Orescanin</author><pubDate>Fri, 15 Nov 2024 18:31:46 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.19572v2</guid></item><item><title>Repurposing Stable Diffusion Attention for Training-Free Unsupervised Interactive Segmentation</title><link>http://arxiv.org/abs/2411.10411v1</link><description>Recent progress in interactive point prompt based Image Segmentation allowsto significantly reduce the manual effort to obtain high quality semanticlabels. State-of-the-art unsupervised methods use self-supervised pre-trainedmodels to obtain pseudo-labels which are used in training a prompt-basedsegmentation model. In this paper, we propose a novel unsupervised andtraining-free approach based solely on the self-attention of Stable Diffusion.We interpret the self-attention tensor as a Markov transition operator, whichenables us to iteratively construct a Markov chain. Pixel-wise counting of therequired number of iterations along the Markov-chain to reach a relativeprobability threshold yields a Markov-iteration-map, which we simply call aMarkov-map. Compared to the raw attention maps, we show that our proposedMarkov-map has less noise, sharper semantic boundaries and more uniform valueswithin semantically similar regions. We integrate the Markov-map in a simpleyet effective truncated nearest neighbor framework to obtain interactive pointprompt based segmentation. Despite being training-free, we experimentally showthat our approach yields excellent results in terms of Number of Clicks (NoC),even outperforming state-of-the-art training based unsupervised methods in mostof the datasets.</description><author>Markus Karmann, Onay Urfalioglu</author><pubDate>Fri, 15 Nov 2024 18:29:59 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2411.10411v1</guid></item><item><title>Advancing Building Energy Modeling with Large Language Models: Exploration and Case Studies</title><link>http://arxiv.org/abs/2402.09579v2</link><description>The rapid progression in artificial intelligence has facilitated theemergence of large language models like ChatGPT, offering potentialapplications extending into specialized engineering modeling, especiallyphysics-based building energy modeling. This paper investigates the innovativeintegration of large language models with building energy modeling software,focusing specifically on the fusion of ChatGPT with EnergyPlus. A literaturereview is first conducted to reveal a growing trend of incorporating largelanguage models in engineering modeling, albeit limited research on theirapplication in building energy modeling. We underscore the potential of largelanguage models in addressing building energy modeling challenges and outlinepotential applications including simulation input generation, simulation outputanalysis and visualization, conducting error analysis, co-simulation,simulation knowledge extraction and training, and simulation optimization.Three case studies reveal the transformative potential of large language modelsin automating and optimizing building energy modeling tasks, underscoring thepivotal role of artificial intelligence in advancing sustainable buildingpractices and energy efficiency. The case studies demonstrate that selectingthe right large language model techniques is essential to enhance performanceand reduce engineering efforts. The findings advocate a multidisciplinaryapproach in future artificial intelligence research, with implicationsextending beyond building energy modeling to other specialized engineeringmodeling.</description><author>Liang Zhang, Zhelun Chen, Vitaly Ford</author><pubDate>Fri, 15 Nov 2024 18:20:23 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.09579v2</guid></item><item><title>On the Foundation Model for Cardiac MRI Reconstruction</title><link>http://arxiv.org/abs/2411.10403v1</link><description>In recent years, machine learning (ML) based reconstruction has been widelyinvestigated and employed in cardiac magnetic resonance (CMR) imaging. ML-basedreconstructions can deliver clinically acceptable image quality undersubstantially accelerated scans. ML-based reconstruction, however, alsorequires substantial data and computational time to train the neural network,which is often optimized for a fixed acceleration rate or image contrast. Inpractice, imaging parameters are often tuned to best suit the diagnosis, whichmay differ from the training data. This can result in degraded image quality,and multiple trained networks are needed to fulfill the clinical demands. Inthis study, we propose a foundation model that uses adaptive unrolling,channel-shifting, and Pattern and Contrast-Prompt-UNet (PCP-UNet) to tackle theproblem. In particular, the undersampled data goes through a different numberof unrolled iterations according to its acceleration rate. Channel-shiftingimproves reconstructed data quality. The PCP-UNet is equipped with an imagecontrast and sampling pattern prompt. In vivo CMR experiments were performedusing mixed combinations of image contrasts, acceleration rates, and(under)sampling patterns. The proposed foundation model has significantlyimproved image quality for a wide range of CMR protocols and outperforms theconventional ML-based method.</description><author>Chi Zhang, Michael Loecher, Cagan Alkan, Mahmut Yurt, Shreyas S. Vasanawala, Daniel B. Ennis</author><pubDate>Fri, 15 Nov 2024 18:15:56 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2411.10403v1</guid></item><item><title>Features that Make a Difference: Leveraging Gradients for Improved Dictionary Learning</title><link>http://arxiv.org/abs/2411.10397v1</link><description>Sparse Autoencoders (SAEs) are a promising approach for extracting neuralnetwork representations by learning a sparse and overcomplete decomposition ofthe network's internal activations. However, SAEs are traditionally trainedconsidering only activation values and not the effect those activations have ondownstream computations. This limits the information available to learnfeatures, and biases the autoencoder towards neglecting features which arerepresented with small activation values but strongly influence model outputs.To address this, we introduce Gradient SAEs (g-SAEs), which modify the$k$-sparse autoencoder architecture by augmenting the TopK activation functionto rely on the gradients of the input activation when selecting the $k$elements. For a given sparsity level, g-SAEs produce reconstructions that aremore faithful to original network performance when propagated through thenetwork. Additionally, we find evidence that g-SAEs learn latents that are onaverage more effective at steering models in arbitrary contexts. By consideringthe downstream effects of activations, our approach leverages the dual natureof neural network features as both $\textit{representations}$, retrospectively,and $\textit{actions}$, prospectively. While previous methods have approachedthe problem of feature discovery primarily focused on the former aspect, g-SAEsrepresent a step towards accounting for the latter as well.</description><author>Jeffrey Olmo, Jared Wilson, Max Forsey, Bryce Hepner, Thomas Vin Howe, David Wingate</author><pubDate>Fri, 15 Nov 2024 18:03:52 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2411.10397v1</guid></item><item><title>Coniferest: a complete active anomaly detection framework</title><link>http://arxiv.org/abs/2410.17142v2</link><description>We present coniferest, an open source generic purpose active anomalydetection framework written in Python. The package design and implementedalgorithms are described. Currently, static outlier detection analysis issupported via the Isolation forest algorithm. Moreover, Active AnomalyDiscovery (AAD) and Pineforest algorithms are available to tackle activeanomaly detection problems. The algorithms and package performance areevaluated on a series of synthetic datasets. We also describe a few successcases which resulted from applying the package to real astronomical data inactive anomaly detection tasks within the SNAD project.</description><author>M. V. Kornilov, V. S. Korolev, K. L. Malanchev, A. D. Lavrukhina, E. Russeil, T. A. Semenikhin, E. Gangler, E. E. O. Ishida, M. V. Pruzhinskaya, A. A. Volnova, S. Sreejith</author><pubDate>Fri, 15 Nov 2024 18:02:00 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.17142v2</guid></item><item><title>KPC-cF: Aspect-Based Sentiment Analysis via Implicit-Feature Alignment with Corpus Filtering</title><link>http://arxiv.org/abs/2407.00342v4</link><description>Investigations into Aspect-Based Sentiment Analysis (ABSA) for Koreanindustrial reviews are notably lacking in the existing literature. Our researchproposes an intuitive and effective framework for ABSA in low-resourcelanguages such as Korean. It optimizes prediction labels by integratingtranslated benchmark and unlabeled Korean data. Using a model fine-tuned ontranslated data, we pseudo-labeled the actual Korean NLI set. Subsequently, weapplied LaBSE and \MSP{}-based filtering to this pseudo-NLI set as implicitfeature, enhancing Aspect Category Detection and Polarity determination throughadditional training. Incorporating dual filtering, this model bridged datasetgaps, achieving positive results in Korean ABSA with minimal resources. Throughadditional data injection pipelines, our approach aims to utilize high-resourcedata and construct effective models within communities, whether corporate orindividual, in low-resource language countries. Compared to English ABSA, ourframework showed an approximately 3\% difference in F1 scores and accuracy. Werelease the dataset and our code for Korean ABSA, at this link.</description><author>Kibeom Nam</author><pubDate>Fri, 15 Nov 2024 17:59:10 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.00342v4</guid></item><item><title>Recurrent Neural Goodness-of-Fit Test for Time Series</title><link>http://arxiv.org/abs/2410.13986v3</link><description>Time series data are crucial across diverse domains such as finance andhealthcare, where accurate forecasting and decision-making rely on advancedmodeling techniques. While generative models have shown great promise incapturing the intricate dynamics inherent in time series, evaluating theirperformance remains a major challenge. Traditional evaluation metrics fallshort due to the temporal dependencies and potential high dimensionality of thefeatures. In this paper, we propose the REcurrent NeurAL (RENAL)Goodness-of-Fit test, a novel and statistically rigorous framework forevaluating generative time series models. By leveraging recurrent neuralnetworks, we transform the time series into conditionally independent datapairs, enabling the application of a chi-square-based goodness-of-fit test tothe temporal dependencies within the data. This approach offers a robust,theoretically grounded solution for assessing the quality of generative models,particularly in settings with limited time sequences. We demonstrate theefficacy of our method across both synthetic and real-world datasets,outperforming existing methods in terms of reliability and accuracy. Our methodfills a critical gap in the evaluation of time series generative models,offering a tool that is both practical and adaptable to high-stakesapplications.</description><author>Aoran Zhang, Wenbin Zhou, Liyan Xie, Shixiang Zhu</author><pubDate>Fri, 15 Nov 2024 17:58:35 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.13986v3</guid></item><item><title>Exploring GPU-to-GPU Communication: Insights into Supercomputer Interconnects</title><link>http://arxiv.org/abs/2408.14090v2</link><description>Multi-GPU nodes are increasingly common in the rapidly evolving landscape ofexascale supercomputers. On these systems, GPUs on the same node are connectedthrough dedicated networks, with bandwidths up to a few terabits per second.However, gauging performance expectations and maximizing system efficiency ischallenging due to different technologies, design options, and software layers.This paper comprehensively characterizes three supercomputers - Alps, Leonardo,and LUMI - each with a unique architecture and design. We focus on performanceevaluation of intra-node and inter-node interconnects on up to 4096 GPUs, usinga mix of intra-node and inter-node benchmarks. By analyzing its limitations andopportunities, we aim to offer practical guidance to researchers, systemarchitects, and software developers dealing with multi-GPU supercomputing. Ourresults show that there is untapped bandwidth, and there are still manyopportunities for optimization, ranging from network to software optimization.</description><author>Daniele De Sensi, Lorenzo Pichetti, Flavio Vella, Tiziano De Matteis, Zebin Ren, Luigi Fusco, Matteo Turisini, Daniele Cesarini, Kurt Lust, Animesh Trivedi, Duncan Roweth, Filippo Spiga, Salvatore Di Girolamo, Torsten Hoefler</author><pubDate>Fri, 15 Nov 2024 17:55:40 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.14090v2</guid></item><item><title>Deep Learning for Micro-Scale Crack Detection on Imbalanced Datasets Using Key Point Localization</title><link>http://arxiv.org/abs/2411.10389v1</link><description>Internal crack detection has been a subject of focus in structural healthmonitoring. By focusing on crack detection in structural datasets, it isdemonstrated that deep learning (DL) methods can effectively analyze seismicwave fields interacting with micro-scale cracks, which are beyond theresolution of conventional visual inspection. This work explores a novelapplication of DL-based key point detection technique, where cracks arelocalized by predicting the coordinates of four key points that define abounding region of the crack. The study not only opens new research directionsfor non-visual applications but also effectively mitigates the impact ofimbalanced data which poses a challenge for previous DL models, as it can bebiased toward predicting the majority class (non-crack regions). Popular DLtechniques, such as the Inception blocks, are used and investigated. The modelshows an overall reduction in loss when applied to micro-scale crack detectionand is reflected in the lower average deviation between the location of actualand predicted cracks, with an average Intersection over Union (IoU) being 0.511for all micro cracks (greater than 0.00 micrometers) and 0.631 for larger microcracks (greater than 4 micrometers).</description><author>Fatahlla Moreh, Yusuf Hasan, Bilal Zahid Hussain, Mohammad Ammar, Sven Tomforde</author><pubDate>Fri, 15 Nov 2024 17:50:46 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2411.10389v1</guid></item><item><title>Image Matching Filtering and Refinement by Planes and Beyond</title><link>http://arxiv.org/abs/2411.09484v2</link><description>This paper introduces a modular, non-deep learning method for filtering andrefining sparse correspondences in image matching. Assuming that motion flowwithin the scene can be approximated by local homography transformations,matches are aggregated into overlapping clusters corresponding to virtualplanes using an iterative RANSAC-based approach, with non-conformingcorrespondences discarded. Moreover, the underlying planar structural designprovides an explicit map between local patches associated with the matches,enabling optional refinement of keypoint positions through cross-correlationtemplate matching after patch reprojection. Finally, to enhance robustness andfault-tolerance against violations of the piece-wise planar approximationassumption, a further strategy is designed for minimizing relative patchdistortion in the plane reprojection by introducing an intermediate homographythat projects both patches into a common plane. The proposed method isextensively evaluated on standard datasets and image matching pipelines, andcompared with state-of-the-art approaches. Unlike other current comparisons,the proposed benchmark also takes into account the more general, real, andpractical cases where camera intrinsics are unavailable. Experimental resultsdemonstrate that our proposed non-deep learning, geometry-based approachachieves performances that are either superior to or on par with recentstate-of-the-art deep learning methods. Finally, this study suggests that thereare still development potential in actual image matching solutions in theconsidered research direction, which could be in the future incorporated innovel deep image matching architectures.</description><author>Fabio Bellavia, Zhenjun Zhao, Luca Morelli, Fabio Remondino</author><pubDate>Fri, 15 Nov 2024 17:48:31 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2411.09484v2</guid></item><item><title>Low-Latency Task-Oriented Communications with Multi-Round, Multi-Task Deep Learning</title><link>http://arxiv.org/abs/2411.10385v1</link><description>In this paper, we address task-oriented (or goal-oriented) communicationswhere an encoder at the transmitter learns compressed latent representations ofdata, which are then transmitted over a wireless channel. At the receiver, adecoder performs a machine learning task, specifically for classifying thereceived signals. The deep neural networks corresponding to the encoder-decoderpair are jointly trained, taking both channel and data characteristics intoaccount. Our objective is to achieve high accuracy in completing the underlyingtask while minimizing the number of channel uses determined by the encoder'soutput size. To this end, we propose a multi-round, multi-task learning (MRMTL)approach for the dynamic update of channel uses in multi-round transmissions.The transmitter incrementally sends an increasing number of encoded samplesover the channel based on the feedback from the receiver, and the receiverutilizes the signals from a previous round to enhance the task performance,rather than only considering the latest transmission. This approach employsmulti-task learning to jointly optimize accuracy across varying number ofchannel uses, treating each configuration as a distinct task. By evaluating theconfidence of the receiver in task decisions, MRMTL decides on whether toallocate additional channel uses in multiple rounds. We characterize both theaccuracy and the delay (total number of channel uses) of MRMTL, demonstratingthat it achieves the accuracy close to that of conventional methods requiringlarge numbers of channel uses, but with reduced delay by incorporating signalsfrom a prior round. We consider the CIFAR-10 dataset, convolutional neuralnetwork architectures, and AWGN and Rayleigh channel models for performanceevaluation. We show that MRMTL significantly improves the efficiency oftask-oriented communications, balancing accuracy and latency effectively.</description><author>Yalin E. Sagduyu, Tugba Erpek, Aylin Yener, Sennur Ulukus</author><pubDate>Fri, 15 Nov 2024 17:48:06 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2411.10385v1</guid></item><item><title>Framework for Co-distillation Driven Federated Learning to Address Class Imbalance in Healthcare</title><link>http://arxiv.org/abs/2411.10383v1</link><description>Federated Learning (FL) is a pioneering approach in distributed machinelearning, enabling collaborative model training across multiple clients whileretaining data privacy. However, the inherent heterogeneity due to imbalancedresource representations across multiple clients poses significant challenges,often introducing bias towards the majority class. This issue is particularlyprevalent in healthcare settings, where hospitals acting as clients sharemedical images. To address class imbalance and reduce bias, we propose aco-distillation driven framework in a federated healthcare setting. Unliketraditional federated setups with a designated server client, our frameworkpromotes knowledge sharing among clients to collectively improve learningoutcomes. Our experiments demonstrate that in a federated healthcare setting,co-distillation outperforms other federated methods in handling classimbalance. Additionally, we demonstrate that our framework has the leaststandard deviation with increasing imbalance while outperforming otherbaselines, signifying the robustness of our framework for FL in healthcare.</description><author>Suraj Racha, Shubh Gupta, Humaira Firdowse, Aastik Solanki, Ganesh Ramakrishnan, Kshitij S. Jadhav</author><pubDate>Fri, 15 Nov 2024 17:46:42 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2411.10383v1</guid></item><item><title>Generation of synthetic gait data: application to multiple sclerosis patients' gait patterns</title><link>http://arxiv.org/abs/2411.10377v1</link><description>Multiple sclerosis (MS) is the leading cause of severe non-traumaticdisability in young adults and its incidence is increasing worldwide. Thevariability of gait impairment in MS necessitates the development of anon-invasive, sensitive, and cost-effective tool for quantitative gaitevaluation. The eGait movement sensor, designed to characterize human gaitthrough unit quaternion time series (QTS) representing hip rotations, is apromising approach. However, the small sample sizes typical of clinical studiespose challenges for the stability of gait data analysis tools. To address thesechallenges, this article presents two key scientific contributions. First, acomprehensive framework is proposed for transforming QTS data into a form thatpreserves the essential geometric properties of gait while enabling the use ofany tabular synthetic data generation method. Second, a synthetic datageneration method is introduced, based on nearest neighbors weighting, whichproduces high-fidelity synthetic QTS data suitable for small datasets andprivate data environments. The effectiveness of the proposed method, isdemonstrated through its application to MS gait data, showing very goodfidelity and respect of the initial geometry of the data. Thanks to this work,we are able to produce synthetic data sets and work on the stability ofclustering methods.</description><author>Klervi Le Gall, Lise Bellanger, David Laplaud</author><pubDate>Fri, 15 Nov 2024 17:32:01 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2411.10377v1</guid></item><item><title>A Survey of Event Causality Identification: Principles, Taxonomy, Challenges, and Assessment</title><link>http://arxiv.org/abs/2411.10371v1</link><description>Event Causality Identification (ECI) has become a crucial task in NaturalLanguage Processing (NLP), aimed at automatically extracting causalities fromtextual data. In this survey, we systematically address the foundationalprinciples, technical frameworks, and challenges of ECI, offering acomprehensive taxonomy to categorize and clarify current researchmethodologies, as well as a quantitative assessment of existing models. Wefirst establish a conceptual framework for ECI, outlining key definitions,problem formulations, and evaluation standards. Our taxonomy classifies ECImethods according to the two primary tasks of sentence-level (SECI) anddocument-level (DECI) event causality identification. For SECI, we examinefeature pattern-based matching, deep semantic encoding, causal knowledgepre-training and prompt-based fine-tuning, and external knowledge enhancementmethods. For DECI, we highlight approaches focused on event graph reasoning andprompt-based techniques to address the complexity of cross-sentence causalinference. Additionally, we analyze the strengths, limitations, and openchallenges of each approach. We further conduct an extensive quantitativeevaluation of various ECI methods on two benchmark datasets. Finally, weexplore future research directions, highlighting promising pathways to overcomecurrent limitations and broaden ECI applications.</description><author>Zefan Zeng, Qing Cheng, Xingchen Hu, Yuehang Si, Zhong Liu</author><pubDate>Fri, 15 Nov 2024 17:19:42 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2411.10371v1</guid></item><item><title>Towards High-Fidelity 3D Portrait Generation with Rich Details by Cross-View Prior-Aware Diffusion</title><link>http://arxiv.org/abs/2411.10369v1</link><description>Recent diffusion-based Single-image 3D portrait generation methods typicallyemploy 2D diffusion models to provide multi-view knowledge, which is thendistilled into 3D representations. However, these methods usually struggle toproduce high-fidelity 3D models, frequently yielding excessively blurredtextures. We attribute this issue to the insufficient consideration ofcross-view consistency during the diffusion process, resulting in significantdisparities between different views and ultimately leading to blurred 3Drepresentations. In this paper, we address this issue by comprehensivelyexploiting multi-view priors in both the conditioning and diffusion proceduresto produce consistent, detail-rich portraits. From the conditioning standpoint,we propose a Hybrid Priors Diffsion model, which explicitly and implicitlyincorporates multi-view priors as conditions to enhance the status consistencyof the generated multi-view portraits. From the diffusion perspective,considering the significant impact of the diffusion noise distribution ondetailed texture generation, we propose a Multi-View Noise Resamplig Strategyintegrated within the optimization process leveraging cross-view priors toenhance representation consistency. Extensive experiments demonstrate that ourmethod can produce 3D portraits with accurate geometry and rich details from asingle image. The project page is at\url{https://haoran-wei.github.io/Portrait-Diffusion}.</description><author>Haoran Wei, Wencheng Han, Xingping Dong, Jianbing Shen</author><pubDate>Fri, 15 Nov 2024 17:19:18 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2411.10369v1</guid></item><item><title>Risk Sources and Risk Management Measures in Support of Standards for General-Purpose AI Systems</title><link>http://arxiv.org/abs/2410.23472v2</link><description>There is an urgent need to identify both short and long-term risks from newlyemerging types of Artificial Intelligence (AI), as well as available riskmanagement measures. In response, and to support global efforts in regulatingAI and writing safety standards, we compile an extensive catalog of risksources and risk management measures for general-purpose AI (GPAI) systems,complete with descriptions and supporting examples where relevant. This workinvolves identifying technical, operational, and societal risks across modeldevelopment, training, and deployment stages, as well as surveying establishedand experimental methods for managing these risks. To the best of ourknowledge, this paper is the first of its kind to provide extensivedocumentation of both GPAI risk sources and risk management measures that aredescriptive, self-contained and neutral with respect to any existing regulatoryframework. This work intends to help AI providers, standards experts,researchers, policymakers, and regulators in identifying and mitigatingsystemic risks from GPAI systems. For this reason, the catalog is releasedunder a public domain license for ease of direct use by stakeholders in AIgovernance and standards.</description><author>Rokas Gipiškis, Ayrton San Joaquin, Ze Shen Chin, Adrian Regenfuß, Ariel Gil, Koen Holtman</author><pubDate>Fri, 15 Nov 2024 17:18:57 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.23472v2</guid></item><item><title>Mechanisms of Generative Image-to-Image Translation Networks</title><link>http://arxiv.org/abs/2411.10368v1</link><description>Generative Adversarial Networks (GANs) are a class of neural networks thathave been widely used in the field of image-to-image translation. In thispaper, we propose a streamlined image-to-image translation network with asimpler architecture compared to existing models. We investigate therelationship between GANs and autoencoders and provide an explanation for theefficacy of employing only the GAN component for tasks involving imagetranslation. We show that adversarial for GAN models yields results comparableto those of existing methods without additional complex loss penalties.Subsequently, we elucidate the rationale behind this phenomenon. We alsoincorporate experimental results to demonstrate the validity of our findings.</description><author>Guangzong Chen, Mingui Sun, Zhi-Hong Mao, Kangni Liu, Wenyan Jia</author><pubDate>Fri, 15 Nov 2024 17:17:46 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2411.10368v1</guid></item><item><title>Continual Adversarial Reinforcement Learning (CARL) of False Data Injection detection: forgetting and explainability</title><link>http://arxiv.org/abs/2411.10367v1</link><description>False data injection attacks (FDIAs) on smart inverters are a growing concernlinked to increased renewable energy production. While data-based FDIAdetection methods are also actively developed, we show that they remainvulnerable to impactful and stealthy adversarial examples that can be craftedusing Reinforcement Learning (RL). We propose to include such adversarialexamples in data-based detection training procedure via a continual adversarialRL (CARL) approach. This way, one can pinpoint the deficiencies of data-baseddetection, thereby offering explainability during their incrementalimprovement. We show that a continual learning implementation is subject tocatastrophic forgetting, and additionally show that forgetting can be addressedby employing a joint training strategy on all generated FDIA scenarios.</description><author>Pooja Aslami, Kejun Chen, Timothy M. Hansen, Malik Hassanaly</author><pubDate>Fri, 15 Nov 2024 17:17:06 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2411.10367v1</guid></item><item><title>Forming Auxiliary High-confident Instance-level Loss to Promote Learning from Label Proportions</title><link>http://arxiv.org/abs/2411.10364v1</link><description>Learning from label proportions (LLP), i.e., a challenging weakly-supervisedlearning task, aims to train a classifier by using bags of instances and theproportions of classes within bags, rather than annotated labels for eachinstance. Beyond the traditional bag-level loss, the mainstream methodology ofLLP is to incorporate an auxiliary instance-level loss with pseudo-labelsformed by predictions. Unfortunately, we empirically observed that thepseudo-labels are are often inaccurate due to over-smoothing, especially forthe scenarios with large bag sizes, hurting the classifier induction. Toalleviate this problem, we suggest a novel LLP method, namely Learning fromLabel Proportions with Auxiliary High-confident Instance-level Loss(L^2P-AHIL). Specifically, we propose a dual entropy-based weight (DEW) methodto adaptively measure the confidences of pseudo-labels. It simultaneouslyemphasizes accurate predictions at the bag level and avoids overly smoothedpredictions. We then form high-confident instance-level loss with DEW, andjointly optimize it with the bag-level loss in a self-training manner. Theexperimental results on benchmark datasets show that L^2P-AHIL can surpass theexisting baseline methods, and the performance gain can be more significant asthe bag size increases.</description><author>Tianhao Ma, Han Chen, Juncheng Hu, Yungang Zhu, Ximing Li</author><pubDate>Fri, 15 Nov 2024 17:14:18 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2411.10364v1</guid></item><item><title>Convergence of Dirichlet Forms for MCMC Optimal Scaling with Dependent Target Distributions on Large Graphs</title><link>http://arxiv.org/abs/2210.17042v3</link><description>Markov chain Monte Carlo (MCMC) algorithms have played a significant role instatistics, physics, machine learning and others, and they are the only knowngeneral and efficient approach for some high-dimensional problems. The randomwalk Metropolis (RWM) algorithm as the most classical MCMC algorithm, has had agreat influence on the development and practice of science and engineering. Thebehavior of the RWM algorithm in high-dimensional problems is typicallyinvestigated through a weak convergence result of diffusion processes. In thispaper, we utilize the Mosco convergence of Dirichlet forms in analyzing the RWMalgorithm on large graphs, whose target distribution is the Gibbs measure thatincludes any probability measure satisfying a Markov property. The abstract andpowerful theory of Dirichlet forms allows us to work directly and naturally onthe infinite-dimensional space, and our notion of Mosco convergence allowsDirichlet forms associated with the RWM chains to lie on changing Hilbertspaces. Through the optimal scaling problem, we demonstrate the impressivestrengths of the Dirichlet form approach over the standard diffusion approach.</description><author>Ning Ning</author><pubDate>Fri, 15 Nov 2024 17:13:04 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2210.17042v3</guid></item><item><title>Mitigating the Linguistic Gap with Phonemic Representations for Robust Cross-lingual Transfer</title><link>http://arxiv.org/abs/2402.14279v3</link><description>Approaches to improving multilingual language understanding often strugglewith significant performance gaps between high-resource and low-resourcelanguages. While there are efforts to align the languages in a single latentspace to mitigate such gaps, how different input-level representationsinfluence such gaps has not been investigated, particularly with phonemicinputs. We hypothesize that the performance gaps are affected by representationdiscrepancies between these languages, and revisit the use of phonemicrepresentations as a means to mitigate these discrepancies. To demonstrate theeffectiveness of phonemic representations, we present experiments on threerepresentative cross-lingual tasks on 12 languages in total. The results showthat phonemic representations exhibit higher similarities between languagescompared to orthographic representations, and it consistently outperformsgrapheme-based baseline model on languages that are relatively low-resourced.We present quantitative evidence from three cross-lingual tasks thatdemonstrate the effectiveness of phonemic representations, and it is furtherjustified by a theoretical analysis of the cross-lingual performance gap.</description><author>Haeji Jung, Changdae Oh, Jooeon Kang, Jimin Sohn, Kyungwoo Song, Jinkyu Kim, David R. Mortensen</author><pubDate>Fri, 15 Nov 2024 17:11:08 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.14279v3</guid></item><item><title>Provocation: Who benefits from "inclusion" in Generative AI?</title><link>http://arxiv.org/abs/2411.09102v2</link><description>The demands for accurate and representative generative AI systems means thereis an increased demand on participatory evaluation structures. While theseparticipatory structures are paramount to to ensure non-dominant values,knowledge and material culture are also reflected in AI models and the mediathey generate, we argue that dominant structures of community participation inAI development and evaluation are not explicit enough about the benefits andharms that members of socially marginalized groups may experience as a resultof their participation. Without explicit interrogation of these benefits by AIdevelopers, as a community we may remain blind to the immensity of systemicchange that is needed as well. To support this provocation, we present aspeculative case study, developed from our own collective experiences as AIresearchers. We use this speculative context to itemize the barriers that needto be overcome in order for the proposed benefits to marginalized communitiesto be realized, and harms mitigated.</description><author>Samantha Dalal, Siobhan Mackenzie Hall, Nari Johnson</author><pubDate>Fri, 15 Nov 2024 17:09:40 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2411.09102v2</guid></item><item><title>Interactive Image-Based Aphid Counting in Yellow Water Traps under Stirring Actions</title><link>http://arxiv.org/abs/2411.10357v1</link><description>The current vision-based aphid counting methods in water traps suffer fromundercounts caused by occlusions and low visibility arising from denseaggregation of insects and other objects. To address this problem, we propose anovel aphid counting method through interactive stirring actions. We useinteractive stirring to alter the distribution of aphids in the yellow watertrap and capture a sequence of images which are then used for aphid detectionand counting through an optimized small object detection network based onYolov5. We also propose a counting confidence evaluation system to evaluate theconfidence of count-ing results. The final counting result is a weighted sum ofthe counting results from all sequence images based on the counting confidence.Experimental results show that our proposed aphid detection networksignificantly outperforms the original Yolov5, with improvements of 33.9% inAP@0.5 and 26.9% in AP@[0.5:0.95] on the aphid test set. In addition, the aphidcounting test results using our proposed counting confidence evaluation systemshow significant improvements over the static counting method, closely aligningwith manual counting results.</description><author>Xumin Gao, Mark Stevens, Grzegorz Cielniak</author><pubDate>Fri, 15 Nov 2024 17:06:50 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2411.10357v1</guid></item><item><title>Weakly-Supervised Multimodal Learning on MIMIC-CXR</title><link>http://arxiv.org/abs/2411.10356v1</link><description>Multimodal data integration and label scarcity pose significant challengesfor machine learning in medical settings. To address these issues, we conductan in-depth evaluation of the newly proposed Multimodal VariationalMixture-of-Experts (MMVM) VAE on the challenging MIMIC-CXR dataset. Ouranalysis demonstrates that the MMVM VAE consistently outperforms othermultimodal VAEs and fully supervised approaches, highlighting its strongpotential for real-world medical applications.</description><author>Andrea Agostini, Daphné Chopard, Yang Meng, Norbert Fortin, Babak Shahbaba, Stephan Mandt, Thomas M. Sutter, Julia E. Vogt</author><pubDate>Fri, 15 Nov 2024 17:05:33 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2411.10356v1</guid></item><item><title>Training Deep 3D Convolutional Neural Networks to Extract BSM Physics Parameters Directly from HEP Data: a Proof-of-Concept Study Using Monte Carlo Simulations</title><link>http://arxiv.org/abs/2311.13060v3</link><description>We report on a novel application of computer vision techniques to extractbeyond the Standard Model parameters directly from high energy physics flavordata. We propose a simple but novel data representation that transforms theangular and kinematic distributions into "quasi-images", which are used totrain a convolutional neural network to perform regression tasks, similar tofitting. As a proof-of-concept, we train a 34-layer Residual Neural Network toregress on these images and determine information about the Wilson Coefficient$C_{9}$ in Monte Carlo simulations of $B^0 \rightarrow K^{*0}\mu^{+}\mu^{-}$decays. The method described here can be generalized and may find applicabilityacross a variety of experiments.</description><author>S. Dubey, T. E. Browder, S. Kohani, R. Mandal, A. Sibidanov, R. Sinha</author><pubDate>Fri, 15 Nov 2024 16:55:47 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.13060v3</guid></item><item><title>The Silicon Ceiling: Auditing GPT's Race and Gender Biases in Hiring</title><link>http://arxiv.org/abs/2405.04412v3</link><description>Large language models (LLMs) are increasingly being introduced in workplacesettings, with the goals of improving efficiency and fairness. However,concerns have arisen regarding these models' potential to reflect or exacerbatesocial biases and stereotypes. This study explores the potential impact of LLMson hiring practices. To do so, we conduct an AI audit of race and gender biasesin one commonly-used LLM, OpenAI's GPT-3.5, taking inspiration from the historyof traditional offline resume audits. We conduct two studies using names withvaried race and gender connotations: resume assessment (Study 1) and resumegeneration (Study 2). In Study 1, we ask GPT to score resumes with 32 differentnames (4 names for each combination of the 2 gender and 4 racial groups) andtwo anonymous options across 10 occupations and 3 evaluation tasks (overallrating, willingness to interview, and hireability). We find that the modelreflects some biases based on stereotypes. In Study 2, we prompt GPT to createresumes (10 for each name) for fictitious job candidates. When generatingresumes, GPT reveals underlying biases; women's resumes had occupations withless experience, while Asian and Hispanic resumes had immigrant markers, suchas non-native English and non-U.S. education and work experiences. Our findingscontribute to a growing body of literature on LLM biases, particularly inworkplace contexts.</description><author>Lena Armstrong, Abbey Liu, Stephen MacNeil, Danaë Metaxa</author><pubDate>Fri, 15 Nov 2024 16:53:18 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.04412v3</guid></item><item><title>BiDense: Binarization for Dense Prediction</title><link>http://arxiv.org/abs/2411.10346v1</link><description>Dense prediction is a critical task in computer vision. However, previousmethods often require extensive computational resources, which hinders theirreal-world application. In this paper, we propose BiDense, a generalized binaryneural network (BNN) designed for efficient and accurate dense predictiontasks. BiDense incorporates two key techniques: the Distribution-adaptiveBinarizer (DAB) and the Channel-adaptive Full-precision Bypass (CFB). The DABadaptively calculates thresholds and scaling factors for binarization,effectively retaining more information within BNNs. Meanwhile, the CFBfacilitates full-precision bypassing for binary convolutional layers undergoingvarious channel size transformations, which enhances the propagation ofreal-valued signals and minimizes information loss. By leveraging thesetechniques, BiDense preserves more real-valued information, enabling moreaccurate and detailed dense predictions in BNNs. Extensive experimentsdemonstrate that our framework achieves performance levels comparable tofull-precision models while significantly reducing memory usage andcomputational costs.</description><author>Rui Yin, Haotong Qin, Yulun Zhang, Wenbo Li, Yong Guo, Jianjun Zhu, Cheng Wang, Biao Jia</author><pubDate>Fri, 15 Nov 2024 16:46:04 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2411.10346v1</guid></item><item><title>Comparative Analysis of Machine Learning Approaches for Bone Age Assessment: A Comprehensive Study on Three Distinct Models</title><link>http://arxiv.org/abs/2411.10345v1</link><description>Radiologists and doctors make use of X-ray images of the non-dominant handsof children and infants to assess the possibility of genetic conditions andgrowth abnormalities. This is done by assessing the difference between theactual extent of growth found using the X-rays and the chronological age of thesubject. The assessment was done conventionally using The Greulich Pyle (GP) orTanner Whitehouse (TW) approach. These approaches require a high level ofexpertise and may often lead to observer bias. Hence, to automate the processof assessing the X-rays, and to increase its accuracy and efficiency, severalmachine learning models have been developed. These machine-learning models haveseveral differences in their accuracy and efficiencies, leading to an unclearchoice for the suitable model depending on their needs and available resources.Methods: In this study, we have analyzed the 3 most widely used models for theautomation of bone age prediction, which are the Xception model, VGG model andCNN model. These models were trained on the preprocessed dataset and theaccuracy was measured using the MAE in terms of months for each model. Usingthis, the comparison between the models was done. Results: The 3 models,Xception, VGG, and CNN models have been tested for accuracy and other relevantfactors.</description><author>Nandavardhan R., Somanathan R., Vikram Suresh, Savaridassan P</author><pubDate>Fri, 15 Nov 2024 16:45:08 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2411.10345v1</guid></item><item><title>Domain Adaptation-based Edge Computing for Cross-Conditions Fault Diagnosis</title><link>http://arxiv.org/abs/2411.10340v1</link><description>Fault diagnosis technology supports the healthy operation of mechanicalequipment. However, the variations conditions during the operation ofmechanical equipment lead to significant disparities in data distribution,posing challenges to fault diagnosis. Furthermore, when deploying applications,traditional methods often encounter issues such as latency and data security.Therefore, conducting fault diagnosis and deploying application methods undercross-operating conditions holds significant value. This paper proposes adomain adaptation-based lightweight fault diagnosis framework for edgecomputing scenarios. Incorporating the local maximum mean discrepancy intoknowledge transfer aligns the feature distributions of different domains in ahigh-dimensional feature space, to discover a common feature space acrossdomains. The acquired fault diagnosis expertise from the cloud-model istransferred to the lightweight edge-model using adaptation knowledge transfermethods. While ensuring real-time diagnostic capabilities, accurate faultdiagnosis is achieved across working conditions. We conducted validationexperiments on the NVIDIA Jetson Xavier NX kit. In terms of diagnosticperformance, the proposed method significantly improved diagnostic accuracy,with average increases of 34.44% and 17.33% compared to the comparison method,respectively. Regarding lightweight effectiveness, proposed method achieved anaverage inference speed increase of 80.47%. Additionally, compared to thecloud-model, the parameter count of the edge-model decreased by 96.37%, whilethe Flops decreased by 83.08%.</description><author>Yanzhi Wang, Chu Wang, Jinhong Wu, Ziyang Yu, Qi Zhou</author><pubDate>Fri, 15 Nov 2024 16:40:43 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2411.10340v1</guid></item><item><title>On the Cost of Model-Serving Frameworks: An Experimental Evaluation</title><link>http://arxiv.org/abs/2411.10337v1</link><description>In machine learning (ML), the inference phase is the process of applyingpre-trained models to new, unseen data with the objective of makingpredictions. During the inference phase, end-users interact with ML services togain insights, recommendations, or actions based on the input data. For thisreason, serving strategies are nowadays crucial for deploying and managingmodels in production environments effectively. These strategies ensure thatmodels are available, scalable, reliable, and performant for real-worldapplications, such as time series forecasting, image classification, naturallanguage processing, and so on. In this paper, we evaluate the performances offive widely-used model serving frameworks (TensorFlow Serving, TorchServe,MLServer, MLflow, and BentoML) under four different scenarios (malwaredetection, cryptocoin prices forecasting, image classification, and sentimentanalysis). We demonstrate that TensorFlow Serving is able to outperform all theother frameworks in serving deep learning (DL) models. Moreover, we show thatDL-specific frameworks (TensorFlow Serving and TorchServe) displaysignificantly lower latencies than the three general-purpose ML frameworks(BentoML, MLFlow, and MLServer).</description><author>Pasquale De Rosa, Yérom-David Bromberg, Pascal Felber, Djob Mvondo, Valerio Schiavoni</author><pubDate>Fri, 15 Nov 2024 16:36:21 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2411.10337v1</guid></item><item><title>Y-MAP-Net: Real-time depth, normals, segmentation, multi-label captioning and 2D human pose in RGB images</title><link>http://arxiv.org/abs/2411.10334v1</link><description>We present Y-MAP-Net, a Y-shaped neural network architecture designed forreal-time multi-task learning on RGB images. Y-MAP-Net, simultaneously predictsdepth, surface normals, human pose, semantic segmentation and generatesmulti-label captions, all from a single network evaluation. To achieve this, weadopt a multi-teacher, single-student training paradigm, where task-specificfoundation models supervise the network's learning, enabling it to distilltheir capabilities into a lightweight architecture suitable for real-timeapplications. Y-MAP-Net, exhibits strong generalization, simplicity andcomputational efficiency, making it ideal for robotics and other practicalscenarios. To support future research, we will release our code publicly.</description><author>Ammar Qammaz, Nikolaos Vasilikopoulos, Iason Oikonomidis, Antonis A. Argyros</author><pubDate>Fri, 15 Nov 2024 16:33:59 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2411.10334v1</guid></item><item><title>Number it: Temporal Grounding Videos like Flipping Manga</title><link>http://arxiv.org/abs/2411.10332v1</link><description>Video Large Language Models (Vid-LLMs) have made remarkable advancements incomprehending video content for QA dialogue. However, they struggle to extendthis visual understanding to tasks requiring precise temporal localization,known as Video Temporal Grounding (VTG). To address this gap, we introduceNumber-Prompt (NumPro), a novel method that empowers Vid-LLMs to bridge visualcomprehension with temporal grounding by adding unique numerical identifiers toeach video frame. Treating a video as a sequence of numbered frame images,NumPro transforms VTG into an intuitive process: flipping through manga panelsin sequence. This allows Vid-LLMs to "read" event timelines, accurately linkingvisual content with corresponding temporal information. Our experimentsdemonstrate that NumPro significantly boosts VTG performance of top-tierVid-LLMs without additional computational cost. Furthermore, fine-tuning on aNumPro-enhanced dataset defines a new state-of-the-art for VTG, surpassingprevious top-performing methods by up to 6.9\% in mIoU for moment retrieval and8.5\% in mAP for highlight detection. The code will be available athttps://github.com/yongliang-wu/NumPro.</description><author>Yongliang Wu, Xinting Hu, Yuyang Sun, Yizhou Zhou, Wenbo Zhu, Fengyun Rao, Bernt Schiele, Xu Yang</author><pubDate>Fri, 15 Nov 2024 16:32:34 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2411.10332v1</guid></item><item><title>CNN-Based Classification of Persian Miniature Paintings from Five Renowned Schools</title><link>http://arxiv.org/abs/2411.10330v1</link><description>This article addresses the gap in computational painting analysis focused onPersian miniature painting, a rich cultural and artistic heritage. Itintroduces a novel approach using Convolutional Neural Networks (CNN) toclassify Persian miniatures from five schools: Herat, Tabriz-e Avval, Shiraz-eAvval, Tabriz-e Dovvom, and Qajar. The method achieves an average accuracy ofover 91%. A meticulously curated dataset captures the distinct features of eachschool, with a patch-based CNN approach classifying image segmentsindependently before merging results for enhanced accuracy. This researchcontributes significantly to digital art analysis, providing detailed insightsinto the dataset, CNN architecture, training, and validation processes. Ithighlights the potential for future advancements in automated art analysis,bridging machine learning, art history, and digital humanities, thereby aidingthe preservation and understanding of Persian cultural heritage.</description><author>Mojtaba Shahi, Roozbeh Rajabi, Farnaz Masoumzadeh</author><pubDate>Fri, 15 Nov 2024 16:29:57 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2411.10330v1</guid></item><item><title>Safe Text-to-Image Generation: Simply Sanitize the Prompt Embedding</title><link>http://arxiv.org/abs/2411.10329v1</link><description>In recent years, text-to-image (T2I) generation models have made significantprogress in generating high-quality images that align with text descriptions.However, these models also face the risk of unsafe generation, potentiallyproducing harmful content that violates usage policies, such as explicitmaterial. Existing safe generation methods typically focus on suppressinginappropriate content by erasing undesired concepts from visualrepresentations, while neglecting to sanitize the textual representation.Although these methods help mitigate the risk of misuse to certain extent,their robustness remains insufficient when dealing with adversarial attacks. Given that semantic consistency between input text and output image is afundamental requirement for T2I models, we identify that textualrepresentations (i.e., prompt embeddings) are likely the primary source ofunsafe generation. To this end, we propose a vision-agnostic safe generationframework, Embedding Sanitizer (ES), which focuses on erasing inappropriateconcepts from prompt embeddings and uses the sanitized embeddings to guide themodel for safe generation. ES is applied to the output of the text encoder as aplug-and-play module, enabling seamless integration with different T2I modelsas well as other safeguards. In addition, ES's unique scoring mechanism assignsa score to each token in the prompt to indicate its potential harmfulness, anddynamically adjusts the sanitization intensity to balance defensive performanceand generation quality. Through extensive evaluation on five prompt benchmarks,our approach achieves state-of-the-art robustness by sanitizing the source(prompt embedding) of unsafe generation compared to nine baseline methods. Itsignificantly outperforms existing safeguards in terms of interpretability andcontrollability while maintaining generation quality.</description><author>Huming Qiu, Guanxu Chen, Mi Zhang, Min Yang</author><pubDate>Fri, 15 Nov 2024 16:29:02 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2411.10329v1</guid></item><item><title>Emotion Detection in Reddit: Comparative Study of Machine Learning and Deep Learning Techniques</title><link>http://arxiv.org/abs/2411.10328v1</link><description>Emotion detection is pivotal in human communication, as it significantlyinfluences behavior, relationships, and decision-making processes. This studyconcentrates on text-based emotion detection by leveraging the GoEmotionsdataset, which annotates Reddit comments with 27 distinct emotions. Theseemotions are subsequently mapped to Ekman's six basic categories: joy, anger,fear, sadness, disgust, and surprise. We employed a range of models for thistask, including six machine learning models, three ensemble models, and a LongShort-Term Memory (LSTM) model to determine the optimal model for emotiondetection. Results indicate that the Stacking classifier outperforms othermodels in accuracy and performance. We also benchmark our models againstEmoBERTa, a pre-trained emotion detection model, with our Stacking classifierproving more effective. Finally, the Stacking classifier is deployed via aStreamlit web application, underscoring its potential for real-worldapplications in text-based emotion analysis.</description><author>Maliheh Alaeddini</author><pubDate>Fri, 15 Nov 2024 16:28:25 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2411.10328v1</guid></item><item><title>Bitcoin Research with a Transaction Graph Dataset</title><link>http://arxiv.org/abs/2411.10325v1</link><description>Bitcoin, launched in 2008 by Satoshi Nakamoto, established a new digitaleconomy where value can be stored and transferred in a fully decentralizedmanner - alleviating the need for a central authority. This paper introduces alarge scale dataset in the form of a transactions graph representingtransactions between Bitcoin users along with a set of tasks and baselines. Thegraph includes 252 million nodes and 785 million edges, covering a time span ofnearly 13 years of and 670 million transactions. Each node and edge istimestamped. As for supervised tasks we provide two labeled sets i. a 33,000nodes based on entity type and ii. nearly 100,000 Bitcoin addresses labeledwith an entity name and an entity type. This is the largest publicly availabledata set of bitcoin transactions designed to facilitate advanced research andexploration in this domain, overcoming the limitations of existing datasets.Various graph neural network models are trained to predict node labels,establishing a baseline for future research. In addition, several use cases arepresented to demonstrate the dataset's applicability beyond Bitcoin analysis.Finally, all data and source code is made publicly available to enablereproducibility of the results.</description><author>Hugo Schnoering, Michalis Vazirgiannis</author><pubDate>Fri, 15 Nov 2024 16:28:03 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2411.10325v1</guid></item><item><title>The Dawn of GUI Agent: A Preliminary Case Study with Claude 3.5 Computer Use</title><link>http://arxiv.org/abs/2411.10323v1</link><description>The recently released model, Claude 3.5 Computer Use, stands out as the firstfrontier AI model to offer computer use in public beta as a graphical userinterface (GUI) agent. As an early beta, its capability in the real-worldcomplex environment remains unknown. In this case study to explore Claude 3.5Computer Use, we curate and organize a collection of carefully designed tasksspanning a variety of domains and software. Observations from these casesdemonstrate Claude 3.5 Computer Use's unprecedented ability in end-to-endlanguage to desktop actions. Along with this study, we provide anout-of-the-box agent framework for deploying API-based GUI automation modelswith easy implementation. Our case studies aim to showcase a groundwork ofcapabilities and limitations of Claude 3.5 Computer Use with detailed analysesand bring to the fore questions about planning, action, and critic, which mustbe considered for future improvement. We hope this preliminary exploration willinspire future research into the GUI agent community. All the test cases in thepaper can be tried through the project:https://github.com/showlab/computer_use_ootb.</description><author>Siyuan Hu, Mingyu Ouyang, Difei Gao, Mike Zheng Shou</author><pubDate>Fri, 15 Nov 2024 16:23:52 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2411.10323v1</guid></item><item><title>Open LLMs are Necessary for Current Private Adaptations and Outperform their Closed Alternatives</title><link>http://arxiv.org/abs/2411.05818v2</link><description>While open Large Language Models (LLMs) have made significant progress, theystill fall short of matching the performance of their closed, proprietarycounterparts, making the latter attractive even for the use on highly privatedata. Recently, various new methods have been proposed to adapt closed LLMs toprivate data without leaking private information to third parties and/or theLLM provider. In this work, we analyze the privacy protection and performanceof the four most recent methods for private adaptation of closed LLMs. Byexamining their threat models and thoroughly comparing their performance underdifferent privacy levels according to differential privacy (DP), various LLMarchitectures, and multiple datasets for classification and generation tasks,we find that: (1) all the methods leak query data, i.e., the (potentiallysensitive) user data that is queried at inference time, to the LLM provider,(2) three out of four methods also leak large fractions of private trainingdata to the LLM provider while the method that protects private data requires alocal open LLM, (3) all the methods exhibit lower performance compared to threeprivate gradient-based adaptation methods for local open LLMs, and (4) theprivate adaptation methods for closed LLMs incur higher monetary training andquery costs than running the alternative methods on local open LLMs. Thisyields the conclusion that, to achieve truly privacy-preserving LLM adaptationsthat yield high performance and more privacy at lower costs, taking intoaccount current methods and models, one should use open LLMs.</description><author>Vincent Hanke, Tom Blanchard, Franziska Boenisch, Iyiola Emmanuel Olatunji, Michael Backes, Adam Dziedzic</author><pubDate>Fri, 15 Nov 2024 16:23:17 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2411.05818v2</guid></item><item><title>CE-SSL: Computation-Efficient Semi-Supervised Learning for ECG-based Cardiovascular Diseases Detection</title><link>http://arxiv.org/abs/2406.14377v2</link><description>The label scarcity problem is the main challenge that hinders the wideapplication of deep learning systems in automatic cardiovascular diseases(CVDs) detection using electrocardiography (ECG). Tuning pre-trained modelsalleviates this problem by transferring knowledge learned from large datasetsto downstream small datasets. However, bottlenecks in computational efficiencyand detection performance limit its clinical applications. It is difficult toimprove the detection performance without significantly sacrificing thecomputational efficiency during model training. Here, we propose acomputation-efficient semi-supervised learning paradigm (CE-SSL) for robust andcomputation-efficient CVDs detection using ECG. It enables a robust adaptationof pre-trained models on downstream datasets with limited supervision and highcomputational efficiency. First, a random-deactivation technique is developedto achieve robust and fast low-rank adaptation of pre-trained weights.Subsequently, we propose a one-shot rank allocation module to determine theoptimal ranks for the update matrices of the pre-trained weights. Finally, alightweight semi-supervised learning pipeline is introduced to enhance modelperformance by leveraging labeled and unlabeled data with high computationalefficiency. Extensive experiments on four downstream datasets demonstrate thatCE-SSL not only outperforms the state-of-the-art methods in multi-label CVDsdetection but also consumes fewer GPU footprints, training time, and parameterstorage space. As such, this paradigm provides an effective solution forachieving high computational efficiency and robust detection performance in theclinical applications of pre-trained models under limited supervision. Code andSupplementary Materials are available at https://github.com/KAZABANA/CE-SSL</description><author>Rushuang Zhou, Lei Clifton, Zijun Liu, Kannie W. Y. Chan, David A. Clifton, Yuan-Ting Zhang, Yining Dong</author><pubDate>Fri, 15 Nov 2024 16:23:15 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.14377v2</guid></item><item><title>Melanoma Detection with Uncertainty Quantification</title><link>http://arxiv.org/abs/2411.10322v1</link><description>Early detection of melanoma is crucial for improving survival rates. Currentdetection tools often utilize data-driven machine learning methods but oftenoverlook the full integration of multiple datasets. We combine publiclyavailable datasets to enhance data diversity, allowing numerous experiments totrain and evaluate various classifiers. We then calibrate them to minimizemisdiagnoses by incorporating uncertainty quantification. Our experiments onbenchmark datasets show accuracies of up to 93.2% before and 97.8% afterapplying uncertainty-based rejection, leading to a reduction in misdiagnoses byover 40.5%. Our code and data are publicly available, and a web-based interfacefor quick melanoma detection of user-supplied images is also provided.</description><author>SangHyuk Kim, Edward Gaibor, Brian Matejek, Daniel Haehn</author><pubDate>Fri, 15 Nov 2024 16:22:32 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2411.10322v1</guid></item><item><title>Probabilistic Prior Driven Attention Mechanism Based on Diffusion Model for Imaging Through Atmospheric Turbulence</title><link>http://arxiv.org/abs/2411.10321v1</link><description>Atmospheric turbulence introduces severe spatial and geometric distortions,challenging traditional image restoration methods. We propose the ProbabilisticPrior Turbulence Removal Network (PPTRN), which combines probabilisticdiffusion-based prior modeling with Transformer-driven feature extraction toaddress this issue. PPTRN employs a two-stage approach: first, a latent encoderand Transformer are jointly trained on clear images to establish robust featurerepresentations. Then, a Denoising Diffusion Probabilistic Model (DDPM) modelsprior distributions over latent vectors, guiding the Transformer in capturingdiverse feature variations essential for restoration. A key innovation in PPTRNis the Probabilistic Prior Driven Cross Attention mechanism, which integratesthe DDPM-generated prior with feature embeddings to reduce artifacts andenhance spatial coherence. Extensive experiments validate that PPTRNsignificantly improves restoration quality on turbulence-degraded images,setting a new benchmark in clarity and structural fidelity.</description><author>Guodong Sun, Qixiang Ma, Liqiang Zhang, Hongwei Wang, Zixuan Gao, Haotian Zhang</author><pubDate>Fri, 15 Nov 2024 16:22:22 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2411.10321v1</guid></item><item><title>Label Cluster Chains for Multi-Label Classification</title><link>http://arxiv.org/abs/2411.00514v2</link><description>Multi-label classification is a type of supervised machine learning that cansimultaneously assign multiple labels to an instance. To solve this task, somemethods divide the original problem into several sub-problems (local approach),others learn all labels at once (global approach), and others combine severalclassifiers (ensemble approach). Regardless of the approach used, exploring andlearning label correlations is important to improve the classifier predictions.Ensemble of Classifier Chains (ECC) is a well-known multi-label method thatconsiders label correlations and can achieve good overall performance onseveral multi-label datasets and evaluation measures. However, one of thechallenges when working with ECC is the high dimensionality of the label space,which can impose limitations for fully-cascaded chains as the complexityincreases regarding feature space expansion. To improve classifier chains, wepropose a method to chain disjoint correlated label clusters obtained byapplying a partition method in the label space. During the training phase, theground truth labels of each cluster are used as new features for all of thefollowing clusters. During the test phase, the predicted labels of clusters areused as new features for all the following clusters. Our proposal, called LabelCluster Chains for Multi-Label Classification (LCC-ML), uses multi-label RandomForests as base classifiers in each cluster, combining their predictions toobtain a final multi-label classification. Our proposal obtained better resultscompared to the original ECC. This shows that learning and chaining disjointcorrelated label clusters can better explore and learn label correlations.</description><author>Elaine Cecília Gatto, Felipe Nakano Kenji, Jesse Read, Mauri Ferrandin, Ricardo Cerri, Celine Vens</author><pubDate>Fri, 15 Nov 2024 16:15:46 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2411.00514v2</guid></item><item><title>M3TR: Generalist HD Map Construction with Variable Map Priors</title><link>http://arxiv.org/abs/2411.10316v1</link><description>Autonomous vehicles require road information for their operation, usually inform of HD maps. Since offline maps eventually become outdated or may only bepartially available, online HD map construction methods have been proposed toinfer map information from live sensor data. A key issue remains how to exploitsuch partial or outdated map information as a prior. We introduce M3TR(Multi-Masking Map Transformer), a generalist approach for HD map constructionboth with and without map priors. We address shortcomings in ground truthgeneration for Argoverse 2 and nuScenes and propose the first realisticscenarios with semantically diverse map priors. Examining various querydesigns, we use an improved method for integrating prior map elements into a HDmap construction model, increasing performance by +4.3 mAP. Finally, we showthat training across all prior scenarios yields a single Generalist model,whose performance is on par with previous Expert models that can handle onlyone specific type of map prior. M3TR thus is the first model capable ofleveraging variable map priors, making it suitable for real-world deployment.Code is available at https://github.com/immel-f/m3tr</description><author>Fabian Immel, Richard Fehler, Frank Bieder, Jan-Hendrik Pauls, Christoph Stiller</author><pubDate>Fri, 15 Nov 2024 16:14:48 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2411.10316v1</guid></item><item><title>Improved Canonicalization for Model Agnostic Equivariance</title><link>http://arxiv.org/abs/2405.14089v2</link><description>This work introduces a novel approach to achieving architecture-agnosticequivariance in deep learning, particularly addressing the limitations oftraditional layerwise equivariant architectures and the inefficiencies of theexisting architecture-agnostic methods. Building equivariant models usingtraditional methods requires designing equivariant versions of existing modelsand training them from scratch, a process that is both impractical andresource-intensive. Canonicalization has emerged as a promising alternative forinducing equivariance without altering model architecture, but it suffers fromthe need for highly expressive and expensive equivariant networks to learncanonical orientations accurately. We propose a new optimization-based methodthat employs any non-equivariant network for canonicalization. Our method usescontrastive learning to efficiently learn a canonical orientation and offersmore flexibility for the choice of canonicalization network. We empiricallydemonstrate that this approach outperforms existing methods in achievingequivariance for large pretrained models and significantly speeds up thecanonicalization process, making it up to 2 times faster.</description><author>Siba Smarak Panigrahi, Arnab Kumar Mondal</author><pubDate>Fri, 15 Nov 2024 16:08:55 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.14089v2</guid></item><item><title>Inconsistencies In Consistency Models: Better ODE Solving Does Not Imply Better Samples</title><link>http://arxiv.org/abs/2411.08954v2</link><description>Although diffusion models can generate remarkably high-quality samples, theyare intrinsically bottlenecked by their expensive iterative sampling procedure.Consistency models (CMs) have recently emerged as a promising diffusion modeldistillation method, reducing the cost of sampling by generating high-fidelitysamples in just a few iterations. Consistency model distillation aims to solvethe probability flow ordinary differential equation (ODE) defined by anexisting diffusion model. CMs are not directly trained to minimize erroragainst an ODE solver, rather they use a more computationally tractableobjective. As a way to study how effectively CMs solve the probability flowODE, and the effect that any induced error has on the quality of generatedsamples, we introduce Direct CMs, which \textit{directly} minimize this error.Intriguingly, we find that Direct CMs reduce the ODE solving error compared toCMs but also result in significantly worse sample quality, calling intoquestion why exactly CMs work well in the first place. Full code is availableat: https://github.com/layer6ai-labs/direct-cms.</description><author>Noël Vouitsis, Rasa Hosseinzadeh, Brendan Leigh Ross, Valentin Villecroze, Satya Krishna Gorti, Jesse C. Cresswell, Gabriel Loaiza-Ganem</author><pubDate>Fri, 15 Nov 2024 16:06:23 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2411.08954v2</guid></item><item><title>Modification Takes Courage: Seamless Image Stitching via Reference-Driven Inpainting</title><link>http://arxiv.org/abs/2411.10309v1</link><description>Current image stitching methods often produce noticeable seams in challengingscenarios such as uneven hue and large parallax. To tackle this problem, wepropose the Reference-Driven Inpainting Stitcher (RDIStitcher), whichreformulates the image fusion and rectangling as a reference-based inpaintingmodel, incorporating a larger modification fusion area and strongermodification intensity than previous methods. Furthermore, we introduce aself-supervised model training method, which enables the implementation ofRDIStitcher without requiring labeled data by fine-tuning a Text-to-Image (T2I)diffusion model. Recognizing difficulties in assessing the quality of stitchedimages, we present the Multimodal Large Language Models (MLLMs)-based metrics,offering a new perspective on evaluating stitched image quality. Compared tothe state-of-the-art (SOTA) method, extensive experiments demonstrate that ourmethod significantly enhances content coherence and seamless transitions in thestitched images. Especially in the zero-shot experiments, our method exhibitsstrong generalization capabilities. Code:https://github.com/yayoyo66/RDIStitcher</description><author>Ziqi Xie, Xiao Lai, Weidong Zhao, Xianhui Liu, Wenlong Hou</author><pubDate>Fri, 15 Nov 2024 16:05:01 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2411.10309v1</guid></item><item><title>A Realistic Collimated X-Ray Image Simulation Pipeline</title><link>http://arxiv.org/abs/2411.10308v1</link><description>Collimator detection remains a challenging task in X-ray systems withunreliable or non-available information about the detectors position relativeto the source. This paper presents a physically motivated image processingpipeline for simulating the characteristics of collimator shadows in X-rayimages. By generating randomized labels for collimator shapes and locations,incorporating scattered radiation simulation, and including Poisson noise, thepipeline enables the expansion of limited datasets for training deep neuralnetworks. We validate the proposed pipeline by a qualitative and quantitativecomparison against real collimator shadows. Furthermore, it is demonstratedthat utilizing simulated data within our deep learning framework not onlyserves as a suitable substitute for actual collimators but also enhances thegeneralization performance when applied to real-world data.</description><author>Benjamin El-Zein, Dominik Eckert, Thomas Weber, Maximilian Rohleder, Ludwig Ritschl, Steffen Kappler, Andreas Maier</author><pubDate>Fri, 15 Nov 2024 16:04:01 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2411.10308v1</guid></item><item><title>ThermoHands: A Benchmark for 3D Hand Pose Estimation from Egocentric Thermal Images</title><link>http://arxiv.org/abs/2403.09871v4</link><description>Designing egocentric 3D hand pose estimation systems that can performreliably in complex, real-world scenarios is crucial for downstreamapplications. Previous approaches using RGB or NIR imagery struggle inchallenging conditions: RGB methods are susceptible to lighting variations andobstructions like handwear, while NIR techniques can be disrupted by sunlightor interference from other NIR-equipped devices. To address these limitations,we present ThermoHands, the first benchmark focused on thermal image-basedegocentric 3D hand pose estimation, demonstrating the potential of thermalimaging to achieve robust performance under these conditions. The benchmarkincludes a multi-view and multi-spectral dataset collected from 28 subjectsperforming hand-object and hand-virtual interactions under diverse scenarios,accurately annotated with 3D hand poses through an automated process. Weintroduce a new baseline method, TherFormer, utilizing dual transformer modulesfor effective egocentric 3D hand pose estimation in thermal imagery. Ourexperimental results highlight TherFormer's leading performance and affirmthermal imaging's effectiveness in enabling robust 3D hand pose estimation inadverse conditions.</description><author>Fangqiang Ding, Yunzhou Zhu, Xiangyu Wen, Gaowen Liu, Chris Xiaoxuan Lu</author><pubDate>Fri, 15 Nov 2024 16:01:39 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.09871v4</guid></item><item><title>Unveiling Topological Structures in Text: A Comprehensive Survey of Topological Data Analysis Applications in NLP</title><link>http://arxiv.org/abs/2411.10298v1</link><description>The surge of data available on the internet has led to the adoption ofvarious computational methods to analyze and extract valuable insights fromthis wealth of information. Among these, the field of Machine Learning (ML) hasthrived by leveraging data to extract meaningful insights. However, MLtechniques face notable challenges when dealing with real-world data, often dueto issues of imbalance, noise, insufficient labeling, and high dimensionality.To address these limitations, some researchers advocate for the adoption ofTopological Data Analysis (TDA), a statistical approach that discerninglycaptures the intrinsic shape of data despite noise. Despite its potential, TDAhas not gained as much traction within the Natural Language Processing (NLP)domain compared to structurally distinct areas like computer vision.Nevertheless, a dedicated community of researchers has been exploring theapplication of TDA in NLP, yielding 85 papers we comprehensively survey in thispaper. Our findings categorize these efforts into theoretical andnontheoretical approaches. Theoretical approaches aim to explain linguisticphenomena from a topological viewpoint, while non-theoretical approaches mergeTDA with ML features, utilizing diverse numerical representation techniques. Weconclude by exploring the challenges and unresolved questions that persist inthis niche field. Resources and a list of papers on this topic can be found at:https://github.com/AdaUchendu/AwesomeTDA4NLP.</description><author>Adaku Uchendu, Thai Le</author><pubDate>Fri, 15 Nov 2024 15:55:05 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2411.10298v1</guid></item><item><title>RETR: Multi-View Radar Detection Transformer for Indoor Perception</title><link>http://arxiv.org/abs/2411.10293v1</link><description>Indoor radar perception has seen rising interest due to affordable costsdriven by emerging automotive imaging radar developments and the benefits ofreduced privacy concerns and reliability under hazardous conditions (e.g., fireand smoke). However, existing radar perception pipelines fail to account fordistinctive characteristics of the multi-view radar setting. In this paper, wepropose Radar dEtection TRansformer (RETR), an extension of the popular DETRarchitecture, tailored for multi-view radar perception. RETR inherits theadvantages of DETR, eliminating the need for hand-crafted components for objectdetection and segmentation in the image plane. More importantly, RETRincorporates carefully designed modifications such as 1) depth-prioritizedfeature similarity via a tunable positional encoding (TPE); 2) a tri-plane lossfrom both radar and camera coordinates; and 3) a learnable radar-to-cameratransformation via reparameterization, to account for the unique multi-viewradar setting. Evaluated on two indoor radar perception datasets, our approachoutperforms existing state-of-the-art methods by a margin of 15.38+ AP forobject detection and 11.77+ IoU for instance segmentation, respectively.</description><author>Ryoma Yataka, Adriano Cardace, Pu Perry Wang, Petros Boufounos, Ryuhei Takahashi</author><pubDate>Fri, 15 Nov 2024 15:51:25 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2411.10293v1</guid></item><item><title>The ParClusterers Benchmark Suite (PCBS): A Fine-Grained Analysis of Scalable Graph Clustering</title><link>http://arxiv.org/abs/2411.10290v1</link><description>We introduce the ParClusterers Benchmark Suite (PCBS) -- a collection ofhighly scalable parallel graph clustering algorithms and benchmarking toolsthat streamline comparing different graph clustering algorithms andimplementations. The benchmark includes clustering algorithms that target a wide range ofmodern clustering use cases, including community detection, classification, anddense subgraph mining. The benchmark toolkit makes it easy to run and evaluate multiple instances ofdifferent clustering algorithms, which can be useful for fine-tuning theperformance of clustering on a given task, and for comparing differentclustering algorithms based on different metrics of interest, includingclustering quality and running time. Using PCBS, we evaluate a broad collection of real-world graph clusteringdatasets. Somewhat surprisingly, we find that the best quality results areobtained by algorithms that not included in many popular graph clusteringtoolkits. The PCBS provides a standardized way to evaluate and judge thequality-performance tradeoffs of the active research area of scalable graphclustering algorithms. We believe it will help enable fair, accurate, andnuanced evaluation of graph clustering algorithms in the future.</description><author>Shangdi Yu, Jessica Shi, Jamison Meindl, David Eisenstat, Xiaoen Ju, Sasan Tavakkol, Laxman Dhulipala, Jakub Łącki, Vahab Mirrokni, Julian Shun</author><pubDate>Fri, 15 Nov 2024 15:47:32 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2411.10290v1</guid></item><item><title>Unlocking Real-Time Fluorescence Lifetime Imaging: Multi-Pixel Parallelism for FPGA-Accelerated Processing</title><link>http://arxiv.org/abs/2410.07364v2</link><description>Fluorescence lifetime imaging (FLI) is a widely used technique in thebiomedical field for measuring the decay times of fluorescent molecules,providing insights into metabolic states, protein interactions, andligand-receptor bindings. However, its broader application in fast biologicalprocesses, such as dynamic activity monitoring, and clinical use, such as inguided surgery, is limited by long data acquisition times and computationallydemanding data processing. While deep learning has reduced post-processingtimes, time-resolved data acquisition remains a bottleneck for real-timeapplications. To address this, we propose a method to achieve real-time FLIusing an FPGA-based hardware accelerator. Specifically, we implemented aGRU-based sequence-to-sequence (Seq2Seq) model on an FPGA board compatible withtime-resolved cameras. The GRU model balances accurate processing with theresource constraints of FPGAs, which have limited DSP units and BRAM. Thelimited memory and computational resources on the FPGA require efficientscheduling of operations and memory allocation to deploy deep learning modelsfor low-latency applications. We address these challenges by using STOMP, aqueue-based discrete-event simulator that automates and optimizes taskscheduling and memory management on hardware. By integrating a GRU-basedSeq2Seq model and its compressed version, called Seq2SeqLite, generated throughknowledge distillation, we were able to process multiple pixels in parallel,reducing latency compared to sequential processing. We explore various levelsof parallelism to achieve an optimal balance between performance and resourceutilization. Our results indicate that the proposed techniques achieved a 17.7xand 52.0x speedup over manual scheduling for the Seq2Seq model and theSeq2SeqLite model, respectively.</description><author>Ismail Erbas, Aporva Amarnath, Vikas Pandey, Karthik Swaminathan, Naigang Wang, Xavier Intes</author><pubDate>Fri, 15 Nov 2024 15:46:00 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.07364v2</guid></item><item><title>Disclosure of AI-Generated News Increases Engagement but Does Not Reduce Aversion, Despite Positive Quality Ratings</title><link>http://arxiv.org/abs/2409.03500v2</link><description>The advancement of artificial intelligence (AI) has led to its application inmany areas, including news media. The integration of AI in journalism presentsboth opportunities and risks for democracy, making it crucial to understandpublic reception of and engagement with AI-generated news, as it may directlyinfluence political knowledge and trust. This preregistered study investigates(i) the perceived quality of AI-assisted and AI-generated versushuman-generated news articles, (ii) whether disclosure of AI's involvement ingenerating these news articles influences engagement with them, and (iii)whether such awareness affects the willingness to read AI-generated articles inthe future. We employed a between-subjects survey experiment with 599participants from the German-speaking part of Switzerland, who evaluated thecredibility, readability, and expertise of news articles. These articles wereeither written by journalists (control group), rewritten by AI (AI-assistedgroup), or entirely generated by AI (AI-generated group). Our results indicatethat all news articles, regardless of whether they were written by journalistsor AI, were perceived to be of equal quality. When participants in thetreatment groups were subsequently made aware of AI's involvement in generatingthe articles, they expressed a higher willingness to engage with (i.e.,continue reading) the articles than participants in the control group. However,they were not more willing to read AI-generated news in the future. Theseresults suggest that aversion to AI usage in news media is not primarily rootedin a perceived lack of quality, and that by disclosing using AI, journalistscould attract more immediate engagement with their content, at least in theshort term.</description><author>Fabrizio Gilardi, Sabrina Di Lorenzo, Juri Ezzaini, Beryl Santa, Benjamin Streiff, Eric Zurfluh, Emma Hoes</author><pubDate>Fri, 15 Nov 2024 15:42:46 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2409.03500v2</guid></item><item><title>Systolic Arrays and Structured Pruning Co-design for Efficient Transformers in Edge Systems</title><link>http://arxiv.org/abs/2411.10285v1</link><description>Efficient deployment of resource-intensive transformers on edge devicesnecessitates cross-stack optimization. We thus study the interrelation betweenstructured pruning and systolic acceleration, matching the size of prunedblocks with the systolic array dimensions. In this setting, computations ofpruned weight blocks can be skipped, reducing run-time and energy consumption,but potentially impacting quality of service (QoS). To evaluate the trade-offsbetween systolic array size and sparsity opportunities, we present a novelco-design framework that integrates algorithmic optimization, systemsimulation, and hardware design. Targeting speech recognition usingtransformers as a case study, we analyze how configuration choices across thestack affect performance metrics. Results demonstrate that structured pruningon systems featuring systolic array acceleration can effectively increaseperformance, while maintaining high QoS levels. Up to 26% system-wide speedupsdue to structured pruning were measured, with only 1.4% word error ratedegradation on the standard Librispeech dataset.</description><author>Pedro Palacios, Rafael Medina, Jean-Luc Rouas, Giovanni Ansaloni, David Atienza</author><pubDate>Fri, 15 Nov 2024 15:40:49 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2411.10285v1</guid></item><item><title>Harnessing Machine Learning for Single-Shot Measurement of Free Electron Laser Pulse Power</title><link>http://arxiv.org/abs/2411.09468v2</link><description>Electron beam accelerators are essential in many scientific and technologicalfields. Their operation relies heavily on the stability and precision of theelectron beam. Traditional diagnostic techniques encounter difficulties inaddressing the complex and dynamic nature of electron beams. Particularly inthe context of free-electron lasers (FELs), it is fundamentally impossible tomeasure the lasing-on and lasingoff electron power profiles for a singleelectron bunch. This is a crucial hurdle in the exact reconstruction of thephoton pulse profile. To overcome this hurdle, we developed a machine learningmodel that predicts the temporal power profile of the electron bunch in thelasing-off regime using machine parameters that can be obtained when lasing ison. The model was statistically validated and showed superior predictionscompared to the state-of-the-art batch calibrations. The work we present hereis a critical element for a virtual pulse reconstruction diagnostic (VPRD) tooldesigned to reconstruct the power profile of individual photon pulses withoutrequiring repeated measurements in the lasing-off regime. This promises tosignificantly enhance the diagnostic capabilities in FELs at large.</description><author>Till Korten, Vladimir Rybnikov, Mathias Vogt, Juliane Roensch-Schulenburg, Peter Steinbach, Najmeh Mirian</author><pubDate>Fri, 15 Nov 2024 15:38:17 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2411.09468v2</guid></item><item><title>Multidimensional Byte Pair Encoding: Shortened Sequences for Improved Visual Data Generation</title><link>http://arxiv.org/abs/2411.10281v1</link><description>In language processing, transformers benefit greatly from text beingcondensed. This is achieved through a larger vocabulary that captures wordfragments instead of plain characters. This is often done with Byte PairEncoding. In the context of images, tokenisation of visual data is usuallylimited to regular grids obtained from quantisation methods, without globalcontent awareness. Our work improves tokenisation of visual data by bringingByte Pair Encoding from 1D to multiple dimensions, as a complementary add-on toexisting compression. We achieve this through counting constellations of tokenpairs and replacing the most frequent token pair with a newly introduced token.The multidimensionality only increases the computation time by a factor of 2for images, making it applicable even to large datasets like ImageNet withinminutes on consumer hardware. This is a lossless preprocessing step. Ourevaluation shows improved training and inference performance of transformers onvisual data achieved by compressing frequent constellations of tokens: Theresulting sequences are shorter, with more uniformly distributed informationcontent, e.g. condensing empty regions in an image into single tokens. As ourexperiments show, these condensed sequences are easier to process. Weadditionally introduce a strategy to amplify this compression further byclustering the vocabulary.</description><author>Tim Elsner, Paula Usinger, Julius Nehring-Wirxel, Gregor Kobsik, Victor Czech, Yanjiang He, Isaak Lim, Leif Kobbelt</author><pubDate>Fri, 15 Nov 2024 15:36:48 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2411.10281v1</guid></item><item><title>Lateral Movement Detection via Time-aware Subgraph Classification on Authentication Logs</title><link>http://arxiv.org/abs/2411.10279v1</link><description>Lateral movement is a crucial component of advanced persistent threat (APT)attacks in networks. Attackers exploit security vulnerabilities in internalnetworks or IoT devices, expanding their control after initial infiltration tosteal sensitive data or carry out other malicious activities, posing a seriousthreat to system security. Existing research suggests that attackers generallyemploy seemingly unrelated operations to mask their malicious intentions,thereby evading existing lateral movement detection methods and hiding theirintrusion traces. In this regard, we analyze host authentication log data froma graph perspective and propose a multi-scale lateral movement detectionframework called LMDetect. The main workflow of this framework proceeds asfollows: 1) Construct a heterogeneous multigraph from host authentication logdata to strengthen the correlations among internal system entities; 2) Design atime-aware subgraph generator to extract subgraphs centered on authenticationevents from the heterogeneous authentication multigraph; 3) Design amulti-scale attention encoder that leverages both local and global attention tocapture hidden anomalous behavior patterns in the authentication subgraphs,thereby achieving lateral movement detection. Extensive experiments on tworeal-world authentication log datasets demonstrate the effectiveness andsuperiority of our framework in detecting lateral movement behaviors.</description><author>Jiajun Zhou, Jiacheng Yao, Xuanze Chen, Shanqing Yu, Qi Xuan, Xiaoniu Yang</author><pubDate>Fri, 15 Nov 2024 15:35:56 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2411.10279v1</guid></item><item><title>4DPV: 4D Pet from Videos by Coarse-to-Fine Non-Rigid Radiance Fields</title><link>http://arxiv.org/abs/2411.10275v1</link><description>We present a coarse-to-fine neural deformation model to simultaneouslyrecover the camera pose and the 4D reconstruction of an unknown object frommultiple RGB sequences in the wild. To that end, our approach does not considerany pre-built 3D template nor 3D training data as well as controlledillumination conditions, and can sort out the problem in a self-supervisedmanner. Our model exploits canonical and image-variant spaces where both coarseand fine components are considered. We introduce a neural local quadratic modelwith spatio-temporal consistency to encode fine details that is combined withcanonical embeddings in order to establish correspondences across sequences. Wethoroughly validate the method on challenging scenarios with complex andreal-world deformations, providing both quantitative and qualitativeevaluations, an ablation study and a comparison with respect to competingapproaches. Our project is available at https://github.com/smontode24/4DPV.</description><author>Sergio M. de Paco, Antonio Agudo</author><pubDate>Fri, 15 Nov 2024 15:31:58 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2411.10275v1</guid></item><item><title>Pretrained ViTs Yield Versatile Representations For Medical Images</title><link>http://arxiv.org/abs/2303.07034v3</link><description>Convolutional Neural Networks (CNNs) have reigned for a decade as the defacto approach to automated medical image diagnosis, pushing thestate-of-the-art in classification, detection and segmentation tasks. Over thelast years, vision transformers (ViTs) have appeared as a competitivealternative to CNNs, yielding impressive levels of performance in the naturalimage domain, while possessing several interesting properties that could provebeneficial for medical imaging tasks. In this work, we explore the benefits anddrawbacks of transformer-based models for medical image classification. Weconduct a series of experiments on several standard 2D medical image benchmarkdatasets and tasks. Our findings show that, while CNNs perform better iftrained from scratch, off-the-shelf vision transformers can perform on par withCNNs when pretrained on ImageNet, both in a supervised and self-supervisedsetting, rendering them as a viable alternative to CNNs.</description><author>Christos Matsoukas, Johan Fredin Haslum, Moein Sorkhei, Magnus Söderberg, Kevin Smith</author><pubDate>Fri, 15 Nov 2024 15:31:44 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2303.07034v3</guid></item><item><title>Fill in the blanks: Rethinking Interpretability in vision</title><link>http://arxiv.org/abs/2411.10273v1</link><description>Model interpretability is a key challenge that has yet to align with theadvancements observed in contemporary state-of-the-art deep learning models. Inparticular, deep learning aided vision tasks require interpretability, in orderfor their adoption in more specialized domains such as medical imaging.Although the field of explainable AI (XAI) developed methods for interpretingvision models along with early convolutional neural networks, recent XAIresearch has mainly focused on assigning attributes via saliency maps. As such,these methods are restricted to providing explanations at a sample level, andmany explainability methods suffer from low adaptability across a wide range ofvision models. In our work, we re-think vision-model explainability from anovel perspective, to probe the general input structure that a model has learntduring its training. To this end, we ask the question: "How would a visionmodel fill-in a masked-image". Experiments on standard vision datasets andpre-trained models reveal consistent patterns, and could be intergrated as anadditional model-agnostic explainability tool in modern machine-learningplatforms. The code will be available at\url{https://github.com/BoTZ-TND/FillingTheBlanks.git}</description><author>Pathirage N. Deelaka, Tharindu Wickremasinghe, Devin Y. De Silva, Lisara N. Gajaweera</author><pubDate>Fri, 15 Nov 2024 15:31:06 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2411.10273v1</guid></item><item><title>Scaling Law for Post-training after Model Pruning</title><link>http://arxiv.org/abs/2411.10272v1</link><description>Large language models (LLMs) based on the Transformer architecture are widelyemployed across various domains and tasks. However, their increasing sizeimposes significant hardware demands, limiting practical deployment. Tomitigate this, model pruning techniques have been developed to create moreefficient models while maintaining high performance. Despite this,post-training after pruning is crucial for performance recovery and can beresource-intensive. This paper investigates the post-training requirements ofpruned LLMs and introduces a scaling law to determine the optimal amount ofpost-training data. Post-training experiments with the Llama-3 and Qwen-2.5series models, pruned using depth pruning, width pruning, and 2:4semi-structured pruning, show that higher pruning ratios necessitate morepost-training data for performance recovery, whereas larger LLMs require less.The proposed scaling law predicts a model's loss based on its parameter countsbefore and after pruning, as well as the post-training token counts.Furthermore, we find that the scaling law established from smaller LLMs can bereliably extrapolated to larger LLMs. This work provides valuable insights intothe post-training of pruned LLMs and offers a practical scaling law foroptimizing post-training data usage.</description><author>Xiaodong Chen, Yuxuan Hu, Jing Zhang, Xiaokang Zhang, Cuiping Li, Hong Chen</author><pubDate>Fri, 15 Nov 2024 15:28:42 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2411.10272v1</guid></item><item><title>Towards Sample-Efficiency and Generalization of Transfer and Inverse Reinforcement Learning: A Comprehensive Literature Review</title><link>http://arxiv.org/abs/2411.10268v1</link><description>Reinforcement learning (RL) is a sub-domain of machine learning, mainlyconcerned with solving sequential decision-making problems by a learning agentthat interacts with the decision environment to improve its behavior throughthe reward it receives from the environment. This learning paradigm is,however, well-known for being time-consuming due to the necessity of collectinga large amount of data, making RL suffer from sample inefficiency and difficultgeneralization. Furthermore, the construction of an explicit reward functionthat accounts for the trade-off between multiple desiderata of a decisionproblem is often a laborious task. These challenges have been recentlyaddressed utilizing transfer and inverse reinforcement learning (T-IRL). Inthis regard, this paper is devoted to a comprehensive review of realizing thesample efficiency and generalization of RL algorithms through T-IRL. Followinga brief introduction to RL, the fundamental T-IRL methods are presented and themost recent advancements in each research field have been extensively reviewed.Our findings denote that a majority of recent research works have dealt withthe aforementioned challenges by utilizing human-in-the-loop and sim-to-realstrategies for the efficient transfer of knowledge from source domains to thetarget domain under the transfer learning scheme. Under the IRL structure,training schemes that require a low number of experience transitions andextension of such frameworks to multi-agent and multi-intention problems havebeen the priority of researchers in recent years.</description><author>Hossein Hassani, Roozbeh Razavi-Far, Mehrdad Saif, Liang Lin</author><pubDate>Fri, 15 Nov 2024 15:18:57 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2411.10268v1</guid></item><item><title>CLCE: An Approach to Refining Cross-Entropy and Contrastive Learning for Optimized Learning Fusion</title><link>http://arxiv.org/abs/2402.14551v2</link><description>State-of-the-art pre-trained image models predominantly adopt a two-stageapproach: initial unsupervised pre-training on large-scale datasets followed bytask-specific fine-tuning using Cross-Entropy loss~(CE). However, it has beendemonstrated that CE can compromise model generalization and stability. Whilerecent works employing contrastive learning address some of these limitationsby enhancing the quality of embeddings and producing better decisionboundaries, they often overlook the importance of hard negative mining and relyon resource intensive and slow training using large sample batches. To counterthese issues, we introduce a novel approach named CLCE, which integratesLabel-Aware Contrastive Learning with CE. Our approach not only maintains thestrengths of both loss functions but also leverages hard negative mining in asynergistic way to enhance performance. Experimental results demonstrate thatCLCE significantly outperforms CE in Top-1 accuracy across twelve benchmarks,achieving gains of up to 3.52% in few-shot learning scenarios and 3.41% intransfer learning settings with the BEiT-3 model. Importantly, our proposedCLCE approach effectively mitigates the dependency of contrastive learning onlarge batch sizes such as 4096 samples per batch, a limitation that haspreviously constrained the application of contrastive learning inbudget-limited hardware environments.</description><author>Zijun Long, George Killick, Lipeng Zhuang, Gerardo Aragon-Camarasa, Zaiqiao Meng, Richard Mccreadie</author><pubDate>Fri, 15 Nov 2024 15:16:56 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.14551v2</guid></item><item><title>Partial Scene Text Retrieval</title><link>http://arxiv.org/abs/2411.10261v1</link><description>The task of partial scene text retrieval involves localizing and searchingfor text instances that are the same or similar to a given query text from animage gallery. However, existing methods can only handle text-line instances,leaving the problem of searching for partial patches within these text-lineinstances unsolved due to a lack of patch annotations in the training data. Toaddress this issue, we propose a network that can simultaneously retrieve bothtext-line instances and their partial patches. Our method embeds the two typesof data (query text and scene text instances) into a shared feature space andmeasures their cross-modal similarities. To handle partial patches, ourproposed approach adopts a Multiple Instance Learning (MIL) approach to learntheir similarities with query text, without requiring extra annotations.However, constructing bags, which is a standard step of conventional MILapproaches, can introduce numerous noisy samples for training, and lowerinference speed. To address this issue, we propose a Ranking MIL (RankMIL)approach to adaptively filter those noisy samples. Additionally, we present aDynamic Partial Match Algorithm (DPMA) that can directly search for the targetpartial patch from a text-line instance during the inference stage, withoutrequiring bags. This greatly improves the search efficiency and the performanceof retrieving partial patches. The source code and dataset are available athttps://github.com/lanfeng4659/PSTR.</description><author>Hao Wang, Minghui Liao, Zhouyi Xie, Wenyu Liu, Xiang Bai</author><pubDate>Fri, 15 Nov 2024 15:08:04 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2411.10261v1</guid></item><item><title>MDHP-Net: Detecting Injection Attacks on In-vehicle Network using Multi-Dimensional Hawkes Process and Temporal Model</title><link>http://arxiv.org/abs/2411.10258v1</link><description>The integration of intelligent and connected technologies in modern vehicles,while offering enhanced functionalities through Electronic Control Unit andinterfaces like OBD-II and telematics, also exposes the vehicle's in-vehiclenetwork (IVN) to potential cyberattacks. In this paper, we consider a specifictype of cyberattack known as the injection attack. As demonstrated by empiricaldata from real-world cybersecurity adversarial competitions(available athttps://mimic2024.xctf.org.cn/race/qwmimic2024 ), these injection attacks haveexcitation effect over time, gradually manipulating network traffic anddisrupting the vehicle's normal functioning, ultimately compromising both itsstability and safety. To profile the abnormal behavior of attackers, we proposea novel injection attack detector to extract long-term features of attackbehavior. Specifically, we first provide a theoretical analysis of modeling thetime-excitation effects of the attack using Multi-Dimensional Hawkes Process(MDHP). A gradient descent solver specifically tailored for MDHP, MDHP-GDS, isdeveloped to accurately estimate optimal MDHP parameters. We then propose aninjection attack detector, MDHP-Net, which integrates optimal MDHP parameterswith MDHP-LSTM blocks to enhance temporal feature extraction. By introducingMDHP parameters, MDHP-Net captures complex temporal features that standard LongShort-Term Memory (LSTM) cannot, enriching temporal dependencies within ourcustomized structure. Extensive evaluations demonstrate the effectiveness ofour proposed detection approach.</description><author>Qi Liu, Yanchen Liu, Ruifeng Li, Chenhong Cao, Yufeng Li, Xingyu Li, Peng Wang, Runhan Feng</author><pubDate>Fri, 15 Nov 2024 15:05:01 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2411.10258v1</guid></item><item><title>The Unreasonable Effectiveness of Guidance for Diffusion Models</title><link>http://arxiv.org/abs/2411.10257v1</link><description>Guidance is an error-correcting technique used to improve the perceptualquality of images generated by diffusion models. Typically, the correction isachieved by linear extrapolation, using an auxiliary diffusion model that haslower performance than the primary model. Using a 2D toy example, we show thatit is highly beneficial when the auxiliary model exhibits similar errors as theprimary one but stronger. We verify this finding in higher dimensions, where weshow that competitive generative performance to state-of-the-art guidancemethods can be achieved when the auxiliary model differs from the primary oneonly by having stronger weight regularization. As an independent contribution,we investigate whether upweighting long-range spatial dependencies improvesvisual fidelity. The result is a novel guidance method, which we call slidingwindow guidance (SWG), that guides the primary model with itself byconstraining its receptive field. Intriguingly, SWG aligns better with humanpreferences than state-of-the-art guidance methods while requiring neithertraining, architectural modifications, nor class conditioning. The code will bereleased.</description><author>Tim Kaiser, Nikolas Adaloglou, Markus Kollmann</author><pubDate>Fri, 15 Nov 2024 15:04:04 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2411.10257v1</guid></item><item><title>Artificial Intelligence in Pediatric Echocardiography: Exploring Challenges, Opportunities, and Clinical Applications with Explainable AI and Federated Learning</title><link>http://arxiv.org/abs/2411.10255v1</link><description>Pediatric heart diseases present a broad spectrum of congenital and acquireddiseases. More complex congenital malformations require a differentiated andmultimodal decision-making process, usually including echocardiography as acentral imaging method. Artificial intelligence (AI) offers considerablepromise for clinicians by facilitating automated interpretation of pediatricechocardiography data. However, adapting AI technologies for pediatricechocardiography analysis has challenges such as limited public dataavailability, data privacy, and AI model transparency. Recently, researchershave focused on disruptive technologies, such as federated learning (FL) andexplainable AI (XAI), to improve automatic diagnostic and decision supportworkflows. This study offers a comprehensive overview of the limitations andopportunities of AI in pediatric echocardiography, emphasizing the synergisticworkflow and role of XAI and FL, identifying research gaps, and exploringpotential future developments. Additionally, three relevant clinical use casesdemonstrate the functionality of XAI and FL with a focus on (i) viewrecognition, (ii) disease classification, (iii) segmentation of cardiacstructures, and (iv) quantitative assessment of cardiac function.</description><author>Mohammed Yaseen Jabarulla, Theodor Uden, Thomas Jack, Philipp Beerbaum, Steffen Oeltze-Jafra</author><pubDate>Fri, 15 Nov 2024 15:03:34 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2411.10255v1</guid></item><item><title>Uncertainty in Supply Chain Digital Twins: A Quantum-Classical Hybrid Approach</title><link>http://arxiv.org/abs/2411.10254v1</link><description>This study investigates uncertainty quantification (UQ) usingquantum-classical hybrid machine learning (ML) models for applications incomplex and dynamic fields, such as attaining resiliency in supply chaindigital twins and financial risk assessment. Although quantum featuretransformations have been integrated into ML models for complex data tasks, agap exists in determining their impact on UQ within their hybrid architectures(quantum-classical approach). This work applies existing UQ techniques fordifferent models within a hybrid framework, examining how quantum featuretransformation affects uncertainty propagation. Increasing qubits from 4 to 16shows varied model responsiveness to outlier detection (OD) samples, which is acritical factor for resilient decision-making in dynamic environments. Thiswork shows how quantum computing techniques can transform data features for UQ,particularly when combined with traditional methods.</description><author>Abdullah Abdullah, Fannya Ratana Sandjaja, Ayesha Abdul Majeed, Gyan Wickremasinghe, Karen Rafferty, Vishal Sharma</author><pubDate>Fri, 15 Nov 2024 15:02:35 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2411.10254v1</guid></item><item><title>Visual-Linguistic Agent: Towards Collaborative Contextual Object Reasoning</title><link>http://arxiv.org/abs/2411.10252v1</link><description>Multimodal Large Language Models (MLLMs) excel at descriptive tasks withinimages but often struggle with precise object localization, a critical elementfor reliable visual interpretation. In contrast, traditional object detectionmodels provide high localization accuracy but frequently generate detectionslacking contextual coherence due to limited modeling of inter-objectrelationships. To address this fundamental limitation, we introduce the\textbf{Visual-Linguistic Agent (VLA), a collaborative framework that combinesthe relational reasoning strengths of MLLMs with the precise localizationcapabilities of traditional object detectors. In the VLA paradigm, the MLLMserves as a central Linguistic Agent, working collaboratively with specializedVision Agents for object detection and classification. The Linguistic Agentevaluates and refines detections by reasoning over spatial and contextualrelationships among objects, while the classification Vision Agent offerscorrective feedback to improve classification accuracy. This collaborativeapproach enables VLA to significantly enhance both spatial reasoning and objectlocalization, addressing key challenges in multimodal understanding. Extensiveevaluations on the COCO dataset demonstrate substantial performanceimprovements across multiple detection models, highlighting VLA's potential toset a new benchmark in accurate and contextually coherent object detection.</description><author>Jingru Yang, Huan Yu, Yang Jingxin, Chentianye Xu, Yin Biao, Yu Sun, Shengfeng He</author><pubDate>Fri, 15 Nov 2024 15:02:06 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2411.10252v1</guid></item><item><title>Morpho-Aware Global Attention for Image Matting</title><link>http://arxiv.org/abs/2411.10251v1</link><description>Vision Transformers (ViTs) and Convolutional Neural Networks (CNNs) faceinherent challenges in image matting, particularly in preserving finestructural details. ViTs, with their global receptive field enabled by theself-attention mechanism, often lose local details such as hair strands.Conversely, CNNs, constrained by their local receptive field, rely on deeperlayers to approximate global context but struggle to retain fine structures atgreater depths. To overcome these limitations, we propose a novel Morpho-Aware GlobalAttention (MAGA) mechanism, designed to effectively capture the morphology offine structures. MAGA employs Tetris-like convolutional patterns to align thelocal shapes of fine structures, ensuring optimal local correspondence whilemaintaining sensitivity to morphological details. The extracted localmorphology information is used as query embeddings, which are projected ontoglobal key embeddings to emphasize local details in a broader context.Subsequently, by projecting onto value embeddings, MAGA seamlessly integratesthese emphasized morphological details into a unified global structure. This approach enables MAGA to simultaneously focus on local morphology andunify these details into a coherent whole, effectively preserving finestructures. Extensive experiments show that our MAGA-based ViT achievessignificant performance gains, outperforming state-of-the-art methods acrosstwo benchmarks with average improvements of 4.3% in SAD and 39.5% in MSE.</description><author>Jingru Yang, Chengzhi Cao, Chentianye Xu, Zhongwei Xie, Kaixiang Huang, Yang Zhou, Shengfeng He</author><pubDate>Fri, 15 Nov 2024 15:01:00 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2411.10251v1</guid></item><item><title>Scaling up the Evaluation of Collaborative Problem Solving: Promises and Challenges of Coding Chat Data with ChatGPT</title><link>http://arxiv.org/abs/2411.10246v1</link><description>Collaborative problem solving (CPS) is widely recognized as a critical 21stcentury skill. Efficiently coding communication data is a big challenge inscaling up research on assessing CPS. This paper reports the findings on usingChatGPT to directly code CPS chat data by benchmarking performance acrossmultiple datasets and coding frameworks. We found that ChatGPT-based codingoutperformed human coding in tasks where the discussions were characterized bycolloquial languages but fell short in tasks where the discussions dealt withspecialized scientific terminology and contexts. The findings offer practicalguidelines for researchers to develop strategies for efficient and scalableanalysis of communication data from CPS tasks.</description><author>Jiangang Hao, Wenju Cui, Patrick Kyllonen, Emily Kerzabi, Lei Liu, Michael Flor</author><pubDate>Fri, 15 Nov 2024 14:57:39 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2411.10246v1</guid></item><item><title>Optimization-based Prompt Injection Attack to LLM-as-a-Judge</title><link>http://arxiv.org/abs/2403.17710v3</link><description>LLM-as-a-Judge uses a large language model (LLM) to select the best responsefrom a set of candidates for a given question. LLM-as-a-Judge has manyapplications such as LLM-powered search, reinforcement learning with AIfeedback (RLAIF), and tool selection. In this work, we propose JudgeDeceiver,an optimization-based prompt injection attack to LLM-as-a-Judge. JudgeDeceiverinjects a carefully crafted sequence into an attacker-controlled candidateresponse such that LLM-as-a-Judge selects the candidate response for anattacker-chosen question no matter what other candidate responses are.Specifically, we formulate finding such sequence as an optimization problem andpropose a gradient based method to approximately solve it. Our extensiveevaluation shows that JudgeDeceive is highly effective, and is much moreeffective than existing prompt injection attacks that manually craft theinjected sequences and jailbreak attacks when extended to our problem. We alsoshow the effectiveness of JudgeDeceiver in three case studies, i.e.,LLM-powered search, RLAIF, and tool selection. Moreover, we consider defensesincluding known-answer detection, perplexity detection, and perplexity windoweddetection. Our results show these defenses are insufficient, highlighting theurgent need for developing new defense strategies. Our implementation isavailable at this repository: https://github.com/ShiJiawenwen/JudgeDeceiver.</description><author>Jiawen Shi, Zenghui Yuan, Yinuo Liu, Yue Huang, Pan Zhou, Lichao Sun, Neil Zhenqiang Gong</author><pubDate>Fri, 15 Nov 2024 14:57:28 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.17710v3</guid></item><item><title>Measuring Non-Adversarial Reproduction of Training Data in Large Language Models</title><link>http://arxiv.org/abs/2411.10242v1</link><description>Large language models memorize parts of their training data. Memorizing shortsnippets and facts is required to answer questions about the world and to befluent in any language. But models have also been shown to reproduce longverbatim sequences of memorized text when prompted by a motivated adversary. Inthis work, we investigate an intermediate regime of memorization that we callnon-adversarial reproduction, where we quantify the overlap between modelresponses and pretraining data when responding to natural and benign prompts.For a variety of innocuous prompt categories (e.g., writing a letter or atutorial), we show that up to 15% of the text output by popular conversationallanguage models overlaps with snippets from the Internet. In worst cases, wefind generations where 100% of the content can be found exactly online. For thesame tasks, we find that human-written text has far less overlap with Internetdata. We further study whether prompting strategies can close this reproductiongap between models and humans. While appropriate prompting can reducenon-adversarial reproduction on average, we find that mitigating worst-casereproduction of training data requires stronger defenses -- even for benigninteractions.</description><author>Michael Aerni, Javier Rando, Edoardo Debenedetti, Nicholas Carlini, Daphne Ippolito, Florian Tramèr</author><pubDate>Fri, 15 Nov 2024 14:55:01 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2411.10242v1</guid></item><item><title>Learning rheological parameters of non-Newtonian fluids from velocimetry data</title><link>http://arxiv.org/abs/2408.02604v2</link><description>We solve a Bayesian inverse Navier-Stokes (N-S) problem that assimilatesvelocimetry data in order to jointly reconstruct the flow field and learn theunknown N-S parameters. By incorporating a Carreau shear-thinning viscositymodel into the N-S problem, we devise an algorithm that learns the most likelyCarreau parameters of a shear-thinning fluid, and estimates theiruncertainties, from velocimetry data alone. We then conduct a flow-MRIexperiment to obtain velocimetry data of an axisymmetric laminar jet through anidealised medical device (FDA nozzle) for a blood analogue fluid. We show thatthe algorithm can successfully reconstruct the flow field by learning the mostlikely Carreau parameters, and that the learned parameters are in very goodagreement with rheometry measurements. The algorithm accepts any algebraiceffective viscosity model, as long as the model is differentiable, and it canbe extended to more complicated non-Newtonian fluids (e.g. Oldroyd-B fluid) ifa viscoelastic model is incorporated into the N-S problem.</description><author>Alexandros Kontogiannis, Richard Hodgkinson, Emily L. Manchester</author><pubDate>Fri, 15 Nov 2024 14:55:00 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.02604v2</guid></item><item><title>DCD: Discriminative and Consistent Representation Distillation</title><link>http://arxiv.org/abs/2407.11802v3</link><description>Knowledge Distillation (KD) aims to transfer knowledge from a large teachermodel to a smaller student model. While contrastive learning has shown promisein self-supervised learning by creating discriminative representations, itsapplication in knowledge distillation remains limited and focuses primarily ondiscrimination, neglecting the structural relationships captured by the teachermodel. To address this limitation, we propose Discriminative and ConsistentDistillation (DCD), which employs a contrastive loss along with a consistencyregularization to minimize the discrepancy between the distributions of teacherand student representations. Our method introduces learnable temperature andbias parameters that adapt during training to balance these complementaryobjectives, replacing the fixed hyperparameters commonly used in contrastivelearning approaches. Through extensive experiments on CIFAR-100 and ImageNetILSVRC-2012, we demonstrate that DCD achieves state-of-the-art performance,with the student model sometimes surpassing the teacher's accuracy.Furthermore, we show that DCD's learned representations exhibit superiorcross-dataset generalization when transferred to Tiny ImageNet and STL-10. Codeis available at https://github.com/giakoumoglou/distillers.</description><author>Nikolaos Giakoumoglou, Tania Stathaki</author><pubDate>Fri, 15 Nov 2024 14:54:58 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.11802v3</guid></item><item><title>Efficient Neural Hybrid System Learning and Transition System Abstraction for Dynamical Systems</title><link>http://arxiv.org/abs/2411.10240v1</link><description>This paper proposes a neural network hybrid modeling framework for dynamicslearning to promote an interpretable, computationally efficient way of dynamicslearning and system identification. First, a low-level model will be trained tolearn the system dynamics, which utilizes multiple simple neural networks toapproximate the local dynamics generated from data-driven partitions. Then,based on the low-level model, a high-level model will be trained to abstractthe low-level neural hybrid system model into a transition system that allowsComputational Tree Logic Verification to promote the model's ability with humaninteraction and verification efficiency.</description><author>Yejiang Yang, Zihao Mo, Weiming Xiang</author><pubDate>Fri, 15 Nov 2024 14:53:34 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2411.10240v1</guid></item><item><title>ScribbleVS: Scribble-Supervised Medical Image Segmentation via Dynamic Competitive Pseudo Label Selection</title><link>http://arxiv.org/abs/2411.10237v1</link><description>In clinical medicine, precise image segmentation can provide substantialsupport to clinicians. However, achieving such precision often requires a largeamount of finely annotated data, which can be costly. Scribble annotationpresents a more efficient alternative, boosting labeling efficiency. However,utilizing such minimal supervision for medical image segmentation training,especially with scribble annotations, poses significant challenges. To addressthese challenges, we introduce ScribbleVS, a novel framework that leveragesscribble annotations. We introduce a Regional Pseudo Labels Diffusion Module toexpand the scope of supervision and reduce the impact of noise present inpseudo labels. Additionally, we propose a Dynamic Competitive Selection modulefor enhanced refinement in selecting pseudo labels. Experiments conducted onthe ACDC and MSCMRseg datasets have demonstrated promising results, achievingperformance levels that even exceed those of fully supervised methodologies.The codes of this study are available athttps://github.com/ortonwang/ScribbleVS.</description><author>Tao Wang, Xinlin Zhang, Yuanbin Chen, Yuanbo Zhou, Longxuan Zhao, Tao Tan, Tong Tong</author><pubDate>Fri, 15 Nov 2024 14:51:30 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2411.10237v1</guid></item><item><title>Generative AI in Multimodal User Interfaces: Trends, Challenges, and Cross-Platform Adaptability</title><link>http://arxiv.org/abs/2411.10234v1</link><description>As the boundaries of human computer interaction expand, Generative AI emergesas a key driver in reshaping user interfaces, introducing new possibilities forpersonalized, multimodal and cross-platform interactions. This integrationreflects a growing demand for more adaptive and intuitive user interfaces thatcan accommodate diverse input types such as text, voice and video, and deliverseamless experiences across devices. This paper explores the integration ofgenerative AI in modern user interfaces, examining historical developments andfocusing on multimodal interaction, cross-platform adaptability and dynamicpersonalization. A central theme is the interface dilemma, which addresses thechallenge of designing effective interactions for multimodal large languagemodels, assessing the trade-offs between graphical, voice-based and immersiveinterfaces. The paper further evaluates lightweight frameworks tailored formobile platforms, spotlighting the role of mobile hardware in enabling scalablemultimodal AI. Technical and ethical challenges, including context retention,privacy concerns and balancing cloud and on-device processing are thoroughlyexamined. Finally, the paper outlines future directions such as emotionallyadaptive interfaces, predictive AI driven user interfaces and real-timecollaborative systems, underscoring generative AI's potential to redefineadaptive user-centric interfaces across platforms.</description><author>J. Bieniek, M. Rahouti, D. C. Verma</author><pubDate>Fri, 15 Nov 2024 14:49:58 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2411.10234v1</guid></item><item><title>GenoCraft: A Comprehensive, User-Friendly Web-Based Platform for High-Throughput Omics Data Analysis and Visualization</title><link>http://arxiv.org/abs/2312.14249v3</link><description>The surge in high-throughput omics data has reshaped the landscape ofbiological research, underlining the need for powerful, user-friendly dataanalysis and interpretation tools. This paper presents GenoCraft, a web-basedcomprehensive software solution designed to handle the entire pipeline of omicsdata processing. GenoCraft offers a unified platform featuring advancedbioinformatics tools, covering all aspects of omics data analysis. Itencompasses a range of functionalities, such as normalization, quality control,differential analysis, network analysis, pathway analysis, and diversevisualization techniques. This software makes state-of-the-art omics dataanalysis more accessible to a wider range of users. With GenoCraft, researchersand data scientists have access to an array of cutting-edge bioinformaticstools under a user-friendly interface, making it a valuable resource formanaging and analyzing large-scale omics data. The API with an interactive webinterface is publicly available at https://genocraft.stanford. edu/. We alsorelease all the codes in https://github.com/futianfan/GenoCraft.</description><author>Yingzhou Lu, Minjie Shen, Ling Yue, Chenhao Li, Lulu Chen, Fan Meng, Xiao Wang, David Herrington, Yue Wang, Yue Zhao, Tianfan Fu, Capucine Van Rechem</author><pubDate>Fri, 15 Nov 2024 14:49:21 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.14249v3</guid></item><item><title>ColorEdit: Training-free Image-Guided Color editing with diffusion model</title><link>http://arxiv.org/abs/2411.10232v1</link><description>Text-to-image (T2I) diffusion models, with their impressive generativecapabilities, have been adopted for image editing tasks, demonstratingremarkable efficacy. However, due to attention leakage and collision betweenthe cross-attention map of the object and the new color attribute from the textprompt, text-guided image editing methods may fail to change the color of anobject, resulting in a misalignment between the resulting image and the textprompt. In this paper, we conduct an in-depth analysis on the process oftext-guided image synthesizing and what semantic information differentcross-attention blocks have learned. We observe that the visual representationof an object is determined in the up-block of the diffusion model in the earlystage of the denoising process, and color adjustment can be achieved throughvalue matrices alignment in the cross-attention layer. Based on our findings,we propose a straightforward, yet stable, and effective image-guided method tomodify the color of an object without requiring any additional fine-tuning ortraining. Lastly, we present a benchmark dataset called COLORBENCH, the firstbenchmark to evaluate the performance of color change methods. Extensiveexperiments validate the effectiveness of our method in object-level colorediting and surpass the performance of popular text-guided image editingapproaches in both synthesized and real images.</description><author>Xingxi Yin, Zhi Li, Jingfeng Zhang, Chenglin Li, Yin Zhang</author><pubDate>Fri, 15 Nov 2024 14:45:58 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2411.10232v1</guid></item></channel></rss>