<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/"><channel><title>Arxivhot papers</title><link></link><description>Arxiv paper</description><language>en-US</language><lastBuildDate>Tue, 09 Apr 2024 06:01:03 GMT</lastBuildDate><generator>rfeed v1.0.0</generator><docs>https://github.com/svpino/rfeed/blob/master/README.md</docs><item><title>Self-Play Fine-Tuning of Diffusion Models for Text-to-Image Generation</title><link>http://arxiv.org/abs/2402.10210v1</link><description>Fine-tuning Diffusion Models remains an underexplored frontier in generativeartificial intelligence (GenAI), especially when compared with the remarkableprogress made in fine-tuning Large Language Models (LLMs). While cutting-edgediffusion models such as Stable Diffusion (SD) and SDXL rely on supervisedfine-tuning, their performance inevitably plateaus after seeing a certainvolume of data. Recently, reinforcement learning (RL) has been employed tofine-tune diffusion models with human preference data, but it requires at leasttwo images ("winner" and "loser" images) for each text prompt. In this paper,we introduce an innovative technique called self-play fine-tuning for diffusionmodels (SPIN-Diffusion), where the diffusion model engages in competition withits earlier versions, facilitating an iterative self-improvement process. Ourapproach offers an alternative to conventional supervised fine-tuning and RLstrategies, significantly improving both model performance and alignment. Ourexperiments on the Pick-a-Pic dataset reveal that SPIN-Diffusion outperformsthe existing supervised fine-tuning method in aspects of human preferencealignment and visual appeal right from its first iteration. By the seconditeration, it exceeds the performance of RLHF-based methods across all metrics,achieving these results with less data.</description><author>Huizhuo Yuan, Zixiang Chen, Kaixuan Ji, Quanquan Gu</author><pubDate>Thu, 15 Feb 2024 18:59:18 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.10210v1</guid></item><item><title>Recovering the Pre-Fine-Tuning Weights of Generative Models</title><link>http://arxiv.org/abs/2402.10208v1</link><description>The dominant paradigm in generative modeling consists of two steps: i)pre-training on a large-scale but unsafe dataset, ii) aligning the pre-trainedmodel with human values via fine-tuning. This practice is considered safe, asno current method can recover the unsafe, pre-fine-tuning model weights. Inthis paper, we demonstrate that this assumption is often false. Concretely, wepresent Spectral DeTuning, a method that can recover the weights of thepre-fine-tuning model using a few low-rank (LoRA) fine-tuned models. Incontrast to previous attacks that attempt to recover pre-fine-tuningcapabilities, our method aims to recover the exact pre-fine-tuning weights. Ourapproach exploits this new vulnerability against large-scale models such as apersonalized Stable Diffusion and an aligned Mistral.</description><author>Eliahu Horwitz, Jonathan Kahana, Yedid Hoshen</author><pubDate>Thu, 15 Feb 2024 18:59:02 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.10208v1</guid></item><item><title>Rewards-in-Context: Multi-objective Alignment of Foundation Models with Dynamic Preference Adjustment</title><link>http://arxiv.org/abs/2402.10207v1</link><description>We consider the problem of multi-objective alignment of foundation modelswith human preferences, which is a critical step towards helpful and harmlessAI systems. However, it is generally costly and unstable to fine-tune largefoundation models using reinforcement learning (RL), and themulti-dimensionality, heterogeneity, and conflicting nature of humanpreferences further complicate the alignment process. In this paper, weintroduce Rewards-in-Context (RiC), which conditions the response of afoundation model on multiple rewards in its prompt context and appliessupervised fine-tuning for alignment. The salient features of RiC aresimplicity and adaptivity, as it only requires supervised fine-tuning of asingle foundation model and supports dynamic adjustment for user preferencesduring inference time. Inspired by the analytical solution of an abstractedconvex optimization problem, our dynamic inference-time adjustment methodapproaches the Pareto-optimal solution for multiple objectives. Empiricalevidence demonstrates the efficacy of our method in aligning both LargeLanguage Models (LLMs) and diffusion models to accommodate diverse rewards withonly around $10\%$ GPU hours compared with multi-objective RL baseline.</description><author>Rui Yang, Xiaoman Pan, Feng Luo, Shuang Qiu, Han Zhong, Dong Yu, Jianshu Chen</author><pubDate>Thu, 15 Feb 2024 18:58:31 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.10207v1</guid></item><item><title>Ising on the Graph: Task-specific Graph Subsampling via the Ising Model</title><link>http://arxiv.org/abs/2402.10206v1</link><description>Reducing a graph while preserving its overall structure is an importantproblem with many applications. Typically, the reduction approaches eitherremove edges (sparsification) or merge nodes (coarsening) in an unsupervisedway with no specific downstream task in mind. In this paper, we present anapproach for subsampling graph structures using an Ising model defined oneither the nodes or edges and learning the external magnetic field of the Isingmodel using a graph neural network. Our approach is task-specific as it canlearn how to reduce a graph for a specific downstream task in an end-to-endfashion. The utilized loss function of the task does not even have to bedifferentiable. We showcase the versatility of our approach on three distinctapplications: image segmentation, 3D shape sparsification, and sparseapproximate matrix inverse determination.</description><author>Maria Bånkestad, Jennifer Andersson, Sebastian Mair, Jens Sjölund</author><pubDate>Thu, 15 Feb 2024 18:58:18 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.10206v1</guid></item><item><title>Multi-Excitation Projective Simulation with a Many-Body Physics Inspired Inductive Bias</title><link>http://arxiv.org/abs/2402.10192v1</link><description>With the impressive progress of deep learning, applications relying onmachine learning are increasingly being integrated into daily life. However,most deep learning models have an opaque, oracle-like nature making itdifficult to interpret and understand their decisions. This problem led to thedevelopment of the field known as eXplainable Artificial Intelligence (XAI).One method in this field known as Projective Simulation (PS) models achain-of-thought as a random walk of a particle on a graph with vertices thathave concepts attached to them. While this description has various benefits,including the possibility of quantization, it cannot be naturally used to modelthoughts that combine several concepts simultaneously. To overcome thislimitation, we introduce Multi-Excitation Projective Simulation (mePS), ageneralization that considers a chain-of-thought to be a random walk of severalparticles on a hypergraph. A definition for a dynamic hypergraph is put forwardto describe the agent's training history along with applications to AI andhypergraph visualization. An inductive bias inspired by the remarkablysuccessful few-body interaction models used in quantum many-body physics isformalized for our classical mePS framework and employed to tackle theexponential complexity associated with naive implementations of hypergraphs. Weprove that our inductive bias reduces the complexity from exponential topolynomial, with the exponent representing the cutoff on how many particles caninteract. We numerically apply our method to two toy environments and a morecomplex scenario modelling the diagnosis of a broken computer. Theseenvironments demonstrate the resource savings provided by an appropriate choiceof inductive bias, as well as showcasing aspects of interpretability. A quantummodel for mePS is also briefly outlined and some future directions for it arediscussed.</description><author>Philip A. LeMaitre, Marius Krumm, Hans J. Briegel</author><pubDate>Thu, 15 Feb 2024 18:48:32 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.10192v1</guid></item><item><title>BASE TTS: Lessons from building a billion-parameter Text-to-Speech model on 100K hours of data</title><link>http://arxiv.org/abs/2402.08093v2</link><description>We introduce a text-to-speech (TTS) model called BASE TTS, which stands for$\textbf{B}$ig $\textbf{A}$daptive $\textbf{S}$treamable TTS with$\textbf{E}$mergent abilities. BASE TTS is the largest TTS model to-date,trained on 100K hours of public domain speech data, achieving a newstate-of-the-art in speech naturalness. It deploys a 1-billion-parameterautoregressive Transformer that converts raw texts into discrete codes("speechcodes") followed by a convolution-based decoder which converts thesespeechcodes into waveforms in an incremental, streamable manner. Further, ourspeechcodes are built using a novel speech tokenization technique that featuresspeaker ID disentanglement and compression with byte-pair encoding. Echoing thewidely-reported "emergent abilities" of large language models when trained onincreasing volume of data, we show that BASE TTS variants built with 10K+ hoursand 500M+ parameters begin to demonstrate natural prosody on textually complexsentences. We design and share a specialized dataset to measure these emergentabilities for text-to-speech. We showcase state-of-the-art naturalness of BASETTS by evaluating against baselines that include publicly available large-scaletext-to-speech systems: YourTTS, Bark and TortoiseTTS. Audio samples generatedby the model can be heard at https://amazon-ltts-paper.com/.</description><author>Mateusz Łajszczak, Guillermo Cámbara, Yang Li, Fatih Beyhan, Arent van Korlaar, Fan Yang, Arnaud Joly, Álvaro Martín-Cortinas, Ammar Abbas, Adam Michalski, Alexis Moinet, Sri Karlapati, Ewa Muszyńska, Haohan Guo, Bartosz Putrycz, Soledad López Gambino, Kayeon Yoo, Elena Sokolova, Thomas Drugman</author><pubDate>Thu, 15 Feb 2024 18:57:26 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.08093v2</guid></item><item><title>Radio-astronomical Image Reconstruction with Conditional Denoising Diffusion Model</title><link>http://arxiv.org/abs/2402.10204v1</link><description>Reconstructing sky models from dirty radio images for accurate sourcelocalization and flux estimation is crucial for studying galaxy evolution athigh redshift, especially in deep fields using instruments like the AtacamaLarge Millimetre Array (ALMA). With new projects like the Square KilometreArray (SKA), there's a growing need for better source extraction methods.Current techniques, such as CLEAN and PyBDSF, often fail to detect faintsources, highlighting the need for more accurate methods. This study proposesusing stochastic neural networks to rebuild sky models directly from dirtyimages. This method can pinpoint radio sources and measure their fluxes withrelated uncertainties, marking a potential improvement in radio sourcecharacterization. We tested this approach on 10164 images simulated with theCASA tool simalma, based on ALMA's Cycle 5.3 antenna setup. We appliedconditional Denoising Diffusion Probabilistic Models (DDPMs) for sky modelsreconstruction, then used Photutils to determine source coordinates and fluxes,assessing the model's performance across different water vapor levels. Ourmethod showed excellence in source localization, achieving more than 90%completeness at a signal-to-noise ratio (SNR) as low as 2. It also surpassedPyBDSF in flux estimation, accurately identifying fluxes for 96% of sources inthe test set, a significant improvement over CLEAN+ PyBDSF's 57%. ConditionalDDPMs is a powerful tool for image-to-image translation, yielding accurate androbust characterisation of radio sources, and outperforming existingmethodologies. While this study underscores its significant potential forapplications in radio astronomy, we also acknowledge certain limitations thataccompany its usage, suggesting directions for further refinement and research.</description><author>Mariia Drozdova, Vitaliy Kinakh, Omkar Bait, Olga Taran, Erica Lastufka, Miroslava Dessauges-Zavadsky, Taras Holotyak, Daniel Schaerer, Slava Voloshynovskiy</author><pubDate>Thu, 15 Feb 2024 18:57:24 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.10204v1</guid></item><item><title>Bridging Associative Memory and Probabilistic Modeling</title><link>http://arxiv.org/abs/2402.10202v1</link><description>Associative memory and probabilistic modeling are two fundamental topics inartificial intelligence. The first studies recurrent neural networks designedto denoise, complete and retrieve data, whereas the second studies learning andsampling from probability distributions. Based on the observation thatassociative memory's energy functions can be seen as probabilistic modeling'snegative log likelihoods, we build a bridge between the two that enables usefulflow of ideas in both directions. We showcase four examples: First, we proposenew energy-based models that flexibly adapt their energy functions to newin-context datasets, an approach we term \textit{in-context learning of energyfunctions}. Second, we propose two new associative memory models: one thatdynamically creates new memories as necessitated by the training data usingBayesian nonparametrics, and another that explicitly computes proportionalmemory assignments using the evidence lower bound. Third, using tools fromassociative memory, we analytically and numerically characterize the memorycapacity of Gaussian kernel density estimators, a widespread tool inprobababilistic modeling. Fourth, we study a widespread implementation choicein transformers -- normalization followed by self attention -- to show itperforms clustering on the hypersphere. Altogether, this work urges furtherexchange of useful ideas between these two continents of artificialintelligence.</description><author>Rylan Schaeffer, Nika Zahedi, Mikail Khona, Dhruv Pai, Sang Truong, Yilun Du, Mitchell Ostrow, Sarthak Chandra, Andres Carranza, Ila Rani Fiete, Andrey Gromov, Sanmi Koyejo</author><pubDate>Thu, 15 Feb 2024 18:56:46 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.10202v1</guid></item><item><title>Real-time Animation Generation and Control on Rigged Models via Large Language Models</title><link>http://arxiv.org/abs/2310.17838v2</link><description>We introduce a novel method for real-time animation control and generation onrigged models using natural language input. First, we embed a large languagemodel (LLM) in Unity to output structured texts that can be parsed into diverseand realistic animations. Second, we illustrate LLM's potential to enableflexible state transition between existing animations. We showcase therobustness of our approach through qualitative results on various rigged modelsand motions.</description><author>Han Huang, Fernanda De La Torre, Cathy Mengying Fang, Andrzej Banburski-Fahey, Judith Amores, Jaron Lanier</author><pubDate>Thu, 15 Feb 2024 18:56:41 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.17838v2</guid></item><item><title>Chain-of-Thought Reasoning Without Prompting</title><link>http://arxiv.org/abs/2402.10200v1</link><description>In enhancing the reasoning capabilities of large language models (LLMs),prior research primarily focuses on specific prompting techniques such asfew-shot or zero-shot chain-of-thought (CoT) prompting. These methods, whileeffective, often involve manually intensive prompt engineering. Our study takesa novel approach by asking: Can LLMs reason effectively without prompting? Ourfindings reveal that, intriguingly, CoT reasoning paths can be elicited frompre-trained LLMs by simply altering the \textit{decoding} process. Rather thanconventional greedy decoding, we investigate the top-$k$ alternative tokens,uncovering that CoT paths are frequently inherent in these sequences. Thisapproach not only bypasses the confounders of prompting but also allows us toassess the LLMs' \textit{intrinsic} reasoning abilities. Moreover, we observethat the presence of a CoT in the decoding path correlates with a higherconfidence in the model's decoded answer. This confidence metric effectivelydifferentiates between CoT and non-CoT paths. Extensive empirical studies onvarious reasoning benchmarks show that the proposed CoT-decoding substantiallyoutperforms the standard greedy decoding.</description><author>Xuezhi Wang, Denny Zhou</author><pubDate>Thu, 15 Feb 2024 18:55:41 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.10200v1</guid></item><item><title>Unlocking the Potential of Transformers in Time Series Forecasting with Sharpness-Aware Minimization and Channel-Wise Attention</title><link>http://arxiv.org/abs/2402.10198v1</link><description>Transformer-based architectures achieved breakthrough performance in naturallanguage processing and computer vision, yet they remain inferior to simplerlinear baselines in multivariate long-term forecasting. To better understandthis phenomenon, we start by studying a toy linear forecasting problem forwhich we show that transformers are incapable of converging to their truesolution despite their high expressive power. We further identify the attentionof transformers as being responsible for this low generalization capacity.Building upon this insight, we propose a shallow lightweight transformer modelthat successfully escapes bad local minima when optimized with sharpness-awareoptimization. We empirically demonstrate that this result extends to allcommonly used real-world multivariate time series datasets. In particular,SAMformer surpasses the current state-of-the-art model TSMixer by 14.33% onaverage, while having ~4 times fewer parameters. The code is available athttps://github.com/romilbert/samformer.</description><author>Romain Ilbert, Ambroise Odonnat, Vasilii Feofanov, Aladin Virmaux, Giuseppe Paolo, Themis Palpanas, Ievgen Redko</author><pubDate>Thu, 15 Feb 2024 18:55:05 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.10198v1</guid></item><item><title>When Less is More: On the Value of "Co-training" for Semi-Supervised Software Defect Predictors</title><link>http://arxiv.org/abs/2211.05920v2</link><description>Labeling a module defective or non-defective is an expensive task. Hence,there are often limits on how much-labeled data is available for training.Semi-supervised classifiers use far fewer labels for training models. However,there are numerous semi-supervised methods, including self-labeling,co-training, maximal-margin, and graph-based methods, to name a few. Only ahandful of these methods have been tested in SE for (e.g.) predicting defectsand even there, those methods have been tested on just a handful of projects. This paper applies a wide range of 55 semi-supervised learners to over 714projects. We find that semi-supervised "co-training methods" work significantlybetter than other approaches. Specifically, after labeling, just 2.5% of data, then make predictions that are competitive to those using 100%of the data. That said, co-training needs to be used cautiously since the specific choiceof co-training methods needs to be carefully selected based on a user'sspecific goals. Also, we warn that a commonly-used co-training method("multi-view"-- where different learners get different sets of columns) doesnot improve predictions (while adding too much to the run time costs 11 hoursvs. 1.8 hours). It is an open question, worthy of future work, to test if these reductionscan be seen in other areas of software analytics. To assist with exploringother areas, all the codes used are available athttps://github.com/ai-se/Semi-Supervised.</description><author>Suvodeep Majumder, Joymallya Chakraborty, Tim Menzies</author><pubDate>Thu, 15 Feb 2024 18:51:53 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2211.05920v2</guid></item><item><title>A Trembling House of Cards? Mapping Adversarial Attacks against Language Agents</title><link>http://arxiv.org/abs/2402.10196v1</link><description>Language agents powered by large language models (LLMs) have seen explodingdevelopment. Their capability of using language as a vehicle for thought andcommunication lends an incredible level of flexibility and versatility. Peoplehave quickly capitalized on this capability to connect LLMs to a wide range ofexternal components and environments: databases, tools, the Internet, roboticembodiment, etc. Many believe an unprecedentedly powerful automation technologyis emerging. However, new automation technologies come with new safety risks,especially for intricate systems like language agents. There is a surprisinglylarge gap between the speed and scale of their development and deployment andour understanding of their safety risks. Are we building a house of cards? Inthis position paper, we present the first systematic effort in mappingadversarial attacks against language agents. We first present a unifiedconceptual framework for agents with three major components: Perception, Brain,and Action. Under this framework, we present a comprehensive discussion andpropose 12 potential attack scenarios against different components of an agent,covering different attack strategies (e.g., input manipulation, adversarialdemonstrations, jailbreaking, backdoors). We also draw connections tosuccessful attack strategies previously applied to LLMs. We emphasize theurgency to gain a thorough understanding of language agent risks before theirwidespread deployment.</description><author>Lingbo Mo, Zeyi Liao, Boyuan Zheng, Yu Su, Chaowei Xiao, Huan Sun</author><pubDate>Thu, 15 Feb 2024 18:51:32 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.10196v1</guid></item><item><title>Inverse Feasibility in Over-the-Air Federated Learning</title><link>http://arxiv.org/abs/2211.14115v4</link><description>We introduce the concept of inverse feasibility for linear forward models asa tool to enhance OTA FL algorithms. Inverse feasibility is defined as an upperbound on the condition number of the forward operator as a function of itsparameters. We analyze an existing OTA FL model using this definition, identifyareas for improvement, and propose a new OTA FL model. Numerical experimentsillustrate the main implications of the theoretical results. The proposedframework, which is based on inverse problem theory, can potentially complementexisting notions of security and privacy by providing additional desirablecharacteristics to networks.</description><author>Tomasz Piotrowski, Rafail Ismayilov, Matthias Frey, Renato L. G. Cavalcante</author><pubDate>Thu, 15 Feb 2024 18:50:16 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2211.14115v4</guid></item><item><title>BitDelta: Your Fine-Tune May Only Be Worth One Bit</title><link>http://arxiv.org/abs/2402.10193v1</link><description>Large Language Models (LLMs) are typically trained in two phases:pre-training on large internet-scale datasets, and fine-tuning for downstreamtasks. Given the higher computational demand of pre-training, it's intuitive toassume that fine-tuning adds less new information to the model, and is thusmore compressible. We explore this assumption by decomposing the weights offine-tuned models into their pre-trained components and an additional delta. Weintroduce a simple method, BitDelta, which successfully quantizes this deltadown to 1 bit without compromising performance. This interesting finding notonly highlights the potential redundancy of information added duringfine-tuning, but also has significant implications for the multi-tenant servingand multi-tenant storage of fine-tuned models. By enabling the use of a singlehigh-precision base model accompanied by multiple 1-bit deltas, BitDeltadramatically reduces GPU memory requirements by more than 10x, which can alsobe translated to enhanced generation latency in multi-tenant settings. Wevalidate BitDelta through experiments across Llama-2 and Mistral modelfamilies, and on models up to 70B parameters, showcasing minimal performancedegradation over all tested settings.</description><author>James Liu, Guangxuan Xiao, Kai Li, Jason D. Lee, Song Han, Tri Dao, Tianle Cai</author><pubDate>Thu, 15 Feb 2024 18:50:06 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.10193v1</guid></item><item><title>FedAnchor: Enhancing Federated Semi-Supervised Learning with Label Contrastive Loss for Unlabeled Clients</title><link>http://arxiv.org/abs/2402.10191v1</link><description>Federated learning (FL) is a distributed learning paradigm that facilitatescollaborative training of a shared global model across devices while keepingdata localized. The deployment of FL in numerous real-world applications facesdelays, primarily due to the prevalent reliance on supervised tasks. Generatingdetailed labels at edge devices, if feasible, is demanding, given resourceconstraints and the imperative for continuous data updates. In addressing thesechallenges, solutions such as federated semi-supervised learning (FSSL), whichrelies on unlabeled clients' data and a limited amount of labeled data on theserver, become pivotal. In this paper, we propose FedAnchor, an innovative FSSLmethod that introduces a unique double-head structure, called anchor head,paired with the classification head trained exclusively on labeled anchor dataon the server. The anchor head is empowered with a newly designed labelcontrastive loss based on the cosine similarity metric. Our approach mitigatesthe confirmation bias and overfitting issues associated with pseudo-labelingtechniques based on high-confidence model prediction samples. Extensiveexperiments on CIFAR10/100 and SVHN datasets demonstrate that our methodoutperforms the state-of-the-art method by a significant margin in terms ofconvergence rate and model accuracy.</description><author>Xinchi Qiu, Yan Gao, Lorenzo Sani, Heng Pan, Wanru Zhao, Pedro P. B. Gusmao, Mina Alibeigi, Alex Iacob, Nicholas D. Lane</author><pubDate>Thu, 15 Feb 2024 18:48:21 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.10191v1</guid></item><item><title>Uncertainty Decomposition and Quantification for In-Context Learning of Large Language Models</title><link>http://arxiv.org/abs/2402.10189v1</link><description>In-context learning has emerged as a groundbreaking ability of Large LanguageModels (LLMs) and revolutionized various fields by providing a fewtask-relevant demonstrations in the prompt. However, trustworthy issues withLLM's response, such as hallucination, have also been actively discussed.Existing works have been devoted to quantifying the uncertainty in LLM'sresponse, but they often overlook the complex nature of LLMs and the uniquenessof in-context learning. In this work, we delve into the predictive uncertaintyof LLMs associated with in-context learning, highlighting that suchuncertainties may stem from both the provided demonstrations (aleatoricuncertainty) and ambiguities tied to the model's configurations (epistemicuncertainty). We propose a novel formulation and corresponding estimationmethod to quantify both types of uncertainties. The proposed method offers anunsupervised way to understand the prediction of in-context learning in aplug-and-play fashion. Extensive experiments are conducted to demonstrate theeffectiveness of the decomposition. The code and data are available at:\url{https://github.com/lingchen0331/UQ_ICL}.</description><author>Chen Ling, Xujiang Zhao, Wei Cheng, Yanchi Liu, Yiyou Sun, Xuchao Zhang, Mika Oishi, Takao Osaki, Katsushi Matsuda, Jie Ji, Guangji Bai, Liang Zhao, Haifeng Chen</author><pubDate>Thu, 15 Feb 2024 18:46:24 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.10189v1</guid></item><item><title>Self-consistent Validation for Machine Learning Electronic Structure</title><link>http://arxiv.org/abs/2402.10186v1</link><description>Machine learning has emerged as a significant approach to efficiently tackleelectronic structure problems. Despite its potential, there is less guaranteefor the model to generalize to unseen data that hinders its application inreal-world scenarios. To address this issue, a technique has been proposed toestimate the accuracy of the predictions. This method integrates machinelearning with self-consistent field methods to achieve both low validation costand interpret-ability. This, in turn, enables exploration of the model'sability with active learning and instills confidence in its integration intoreal-world studies.</description><author>Gengyuan Hu, Gengchen Wei, Zekun Lou, Philip H. S. Torr, Wanli Ouyang, Han-sen Zhong, Chen Lin</author><pubDate>Thu, 15 Feb 2024 18:41:35 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.10186v1</guid></item><item><title>Rethinking Information Structures in RLHF: Reward Generalization from a Graph Theory Perspective</title><link>http://arxiv.org/abs/2402.10184v1</link><description>There is a trilemma in reinforcement learning from human feedback (RLHF): theincompatibility between highly diverse contexts, low labeling cost, andreliable alignment performance. Here we aim to mitigate such incompatibilitythrough the design of dataset information structures during reward modeling.Specifically, we first reexamine the RLHF process and propose a theoreticalframework portraying it as an autoencoding process over text distributions. Ourframework formalizes the RLHF objective of ensuring distributional consistencybetween human preference and large language model (LLM) behavior. Building onthis framework, we then systematically investigate the performance impact ofinformation structure in the reward modeling stage of RLHF. To furtherunderstand reward generalization in the reward modeling stage, we introduce anew method based on random graph theory that models generalization in thesemantic space. A key insight of our analysis is the superiority of thetree-based information structure in reward modeling, compared to chain-basedbaselines adopted by conventional RLHF methods. We derive that under highlycomplex contexts with limited data, the tree-based reward model (RM) induces upto $\Theta(\log n/\log\log n)$ times less variance than chain-based RM where$n$ is the dataset size. To validate our theoretical contribution, wedemonstrate that on three different NLP tasks, the tree-based RM achieves 65%win rate on average against chain-based baselines. Looking forward, we hope ourframework can serve as a step towards understanding goal misgeneralization.</description><author>Tianyi Qiu, Fanzhi Zeng, Jiaming Ji, Dong Yan, Kaile Wang, Jiayi Zhou, Han Yang, Josef Dai, Xuehai Pan, Yaodong Yang</author><pubDate>Thu, 15 Feb 2024 18:39:24 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.10184v1</guid></item><item><title>Generalizing across Temporal Domains with Koopman Operators</title><link>http://arxiv.org/abs/2402.07834v2</link><description>In the field of domain generalization, the task of constructing a predictivemodel capable of generalizing to a target domain without access to target dataremains challenging. This problem becomes further complicated when consideringevolving dynamics between domains. While various approaches have been proposedto address this issue, a comprehensive understanding of the underlyinggeneralization theory is still lacking. In this study, we contribute noveltheoretic results that aligning conditional distribution leads to the reductionof generalization bounds. Our analysis serves as a key motivation for solvingthe Temporal Domain Generalization (TDG) problem through the application ofKoopman Neural Operators, resulting in Temporal Koopman Networks (TKNets). Byemploying Koopman Operators, we effectively address the time-evolvingdistributions encountered in TDG using the principles of Koopman theory, wheremeasurement functions are sought to establish linear transition relationsbetween evolving domains. Through empirical evaluations conducted on syntheticand real-world datasets, we validate the effectiveness of our proposedapproach.</description><author>Qiuhao Zeng, Wei Wang, Fan Zhou, Gezheng Xu, Ruizhi Pu, Changjian Shui, Christian Gagne, Shichun Yang, Boyu Wang, Charles X. Ling</author><pubDate>Thu, 15 Feb 2024 18:28:51 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.07834v2</guid></item><item><title>TDAG: A Multi-Agent Framework based on Dynamic Task Decomposition and Agent Generation</title><link>http://arxiv.org/abs/2402.10178v1</link><description>The emergence of Large Language Models (LLMs) like ChatGPT has inspired thedevelopment of LLM-based agents capable of addressing complex, real-worldtasks. However, these agents often struggle during task execution due tomethodological constraints, such as error propagation and limited adaptability.To address this issue, we propose a multi-agent framework based on dynamic TaskDecomposition and Agent Generation (TDAG). This framework dynamicallydecomposes complex tasks into smaller subtasks and assigns each to aspecifically generated subagent, thereby enhancing adaptability in diverse andunpredictable real-world tasks. Simultaneously, existing benchmarks often lackthe granularity needed to evaluate incremental progress in complex, multi-steptasks. In response, we introduce ItineraryBench in the context of travelplanning, featuring interconnected, progressively complex tasks with afine-grained evaluation system. ItineraryBench is designed to assess agents'abilities in memory, planning, and tool usage across tasks of varyingcomplexity. Our experimental results reveal that TDAG significantly outperformsestablished baselines, showcasing its superior adaptability and contextawareness in complex task scenarios.</description><author>Yaoxiang Wang, Zhiyong Wu, Junfeng Yao, Jinsong Su</author><pubDate>Thu, 15 Feb 2024 18:27:37 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.10178v1</guid></item><item><title>Large Scale Constrained Clustering With Reinforcement Learning</title><link>http://arxiv.org/abs/2402.10177v1</link><description>Given a network, allocating resources at clusters level, rather than at eachnode, enhances efficiency in resource allocation and usage. In this paper, westudy the problem of finding fully connected disjoint clusters to minimize theintra-cluster distances and maximize the number of nodes assigned to theclusters, while also ensuring that no two nodes within a cluster exceed athreshold distance. While the problem can easily be formulated using a binarylinear model, traditional combinatorial optimization solvers struggle whendealing with large-scale instances. We propose an approach to solve thisconstrained clustering problem via reinforcement learning. Our method involvestraining an agent to generate both feasible and (near) optimal solutions. Theagent learns problem-specific heuristics, tailored to the instances encounteredin this task. In the results section, we show that our algorithm finds nearoptimal solutions, even for large scale instances.</description><author>Benedikt Schesch, Marco Caserta</author><pubDate>Thu, 15 Feb 2024 18:27:18 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.10177v1</guid></item><item><title>OpenMathInstruct-1: A 1.8 Million Math Instruction Tuning Dataset</title><link>http://arxiv.org/abs/2402.10176v1</link><description>Recent work has shown the immense potential of synthetically generateddatasets for training large language models (LLMs), especially for acquiringtargeted skills. Current large-scale math instruction tuning datasets such asMetaMathQA (Yu et al., 2024) and MAmmoTH (Yue et al., 2024) are constructedusing outputs from closed-source LLMs with commercially restrictive licenses. Akey reason limiting the use of open-source LLMs in these data generationpipelines has been the wide gap between the mathematical skills of the bestclosed-source LLMs, such as GPT-4, and the best open-source LLMs. Building onthe recent progress in open-source LLMs, our proposed prompting novelty, andsome brute-force scaling, we construct OpenMathInstruct-1, a math instructiontuning dataset with 1.8M problem-solution pairs. The dataset is constructed bysynthesizing code-interpreter solutions for GSM8K and MATH, two popular mathreasoning benchmarks, using the recently released and permissively licensedMixtral model. Our best model, OpenMath-CodeLlama-70B, trained on a subset ofOpenMathInstruct-1, achieves a score of 84.6% on GSM8K and 50.7% on MATH, whichis competitive with the best gpt-distilled models. We release our code, models,and the OpenMathInstruct-1 dataset under a commercially permissive license.</description><author>Shubham Toshniwal, Ivan Moshkov, Sean Narenthiran, Daria Gitman, Fei Jia, Igor Gitman</author><pubDate>Thu, 15 Feb 2024 18:26:11 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.10176v1</guid></item><item><title>Towards better Human-Agent Alignment: Assessing Task Utility in LLM-Powered Applications</title><link>http://arxiv.org/abs/2402.09015v2</link><description>The rapid development in the field of Large Language Models (LLMs) has led toa surge in applications that facilitate collaboration among multiple agents toassist humans in their daily tasks. However, a significant gap remains inassessing whether LLM-powered applications genuinely enhance user experienceand task execution efficiency. This highlights the pressing need for methods toverify utility of LLM-powered applications, particularly by ensuring alignmentbetween the application's functionality and end-user needs. We introduceAgentEval provides an implementation for the math problems}, a novel frameworkdesigned to simplify the utility verification process by automaticallyproposing a set of criteria tailored to the unique purpose of any givenapplication. This allows for a comprehensive assessment, quantifying theutility of an application against the suggested criteria. We present acomprehensive analysis of the robustness of quantifier's work.</description><author>Negar Arabzadeh, Julia Kiseleva, Qingyun Wu, Chi Wang, Ahmed Awadallah, Victor Dibia, Adam Fourney, Charles Clarke</author><pubDate>Thu, 15 Feb 2024 18:24:03 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.09015v2</guid></item><item><title>Out-Of-Domain Unlabeled Data Improves Generalization</title><link>http://arxiv.org/abs/2310.00027v2</link><description>We propose a novel framework for incorporating unlabeled data intosemi-supervised classification problems, where scenarios involving theminimization of either i) adversarially robust or ii) non-robust loss functionshave been considered. Notably, we allow the unlabeled samples to deviateslightly (in total variation sense) from the in-domain distribution. The coreidea behind our framework is to combine Distributionally Robust Optimization(DRO) with self-supervised training. As a result, we also leverage efficientpolynomial-time algorithms for the training stage. From a theoreticalstandpoint, we apply our framework on the classification problem of a mixtureof two Gaussians in $\mathbb{R}^d$, where in addition to the $m$ independentand labeled samples from the true distribution, a set of $n$ (usually with$n\gg m$) out of domain and unlabeled samples are given as well. Using only thelabeled data, it is known that the generalization error can be bounded by$\propto\left(d/m\right)^{1/2}$. However, using our method on both isotropicand non-isotropic Gaussian mixture models, one can derive a new set ofanalytically explicit and non-asymptotic bounds which show substantialimprovement on the generalization error compared to ERM. Our results underscoretwo significant insights: 1) out-of-domain samples, even when unlabeled, can beharnessed to narrow the generalization gap, provided that the true datadistribution adheres to a form of the ``cluster assumption", and 2) thesemi-supervised learning paradigm can be regarded as a special case of ourframework when there are no distributional shifts. We validate our claimsthrough experiments conducted on a variety of synthetic and real-worlddatasets.</description><author>Amir Hossein Saberi, Amir Najafi, Alireza Heidari, Mohammad Hosein Movasaghinia, Abolfazl Motahari, Babak H. Khalaj</author><pubDate>Thu, 15 Feb 2024 18:23:41 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.00027v2</guid></item><item><title>A Technological Perspective on Misuse of Available AI</title><link>http://arxiv.org/abs/2403.15325v1</link><description>Potential malicious misuse of civilian artificial intelligence (AI) posesserious threats to security on a national and international level. Besidesdefining autonomous systems from a technological viewpoint and explaining howAI development is characterized, we show how already existing and openlyavailable AI technology could be misused. To underline this, we developed threeexemplary use cases of potentially misused AI that threaten political, digitaland physical security. The use cases can be built from existing AI technologiesand components from academia, the private sector and the developer-community.This shows how freely available AI can be combined into autonomous weaponsystems. Based on the use cases, we deduce points of control and furthermeasures to prevent the potential threat through misused AI. Further, wepromote the consideration of malicious misuse of civilian AI systems in thediscussion on autonomous weapon systems (AWS).</description><author>Lukas Pöhler, Valentin Schrader, Alexander Ladwein, Florian von Keller</author><pubDate>Fri, 22 Mar 2024 17:30:58 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.15325v1</guid></item><item><title>Unlocking Structure Measuring: Introducing PDD, an Automatic Metric for Positional Discourse Coherence</title><link>http://arxiv.org/abs/2402.10175v1</link><description>Recent large language models (LLMs) have shown remarkable performance inaligning generated text with user intentions across various tasks. When itcomes to long-form text generation, there has been a growing interest ingeneration from a discourse coherence perspective. However, existing lexical orsemantic metrics such as BLEU, ROUGE, BertScore cannot effectively capture thediscourse coherence. The development of discourse-specific automatic evaluationmethods for assessing the output of LLMs warrants greater focus andexploration. In this paper, we present a novel automatic metric designed toquantify the discourse divergence between two long-form articles. Extensiveexperiments on three datasets from representative domains demonstrate that ourmetric aligns more closely with human preferences and GPT-4 coherenceevaluation, outperforming existing evaluation methods.</description><author>Yinhong Liu, Yixuan Su, Ehsan Shareghi, Nigel Collier</author><pubDate>Thu, 15 Feb 2024 18:23:39 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.10175v1</guid></item><item><title>OptiMUS: Scalable Optimization Modeling with (MI)LP Solvers and Large Language Models</title><link>http://arxiv.org/abs/2402.10172v1</link><description>Optimization problems are pervasive in sectors from manufacturing anddistribution to healthcare. However, most such problems are still solvedheuristically by hand rather than optimally by state-of-the-art solvers becausethe expertise required to formulate and solve these problems limits thewidespread adoption of optimization tools and techniques. This paper introducesOptiMUS, a Large Language Model (LLM)-based agent designed to formulate andsolve (mixed integer) linear programming problems from their natural languagedescriptions. OptiMUS can develop mathematical models, write and debug solvercode, evaluate the generated solutions, and improve its model and code based onthese evaluations. OptiMUS utilizes a modular structure to process problems,allowing it to handle problems with long descriptions and complex data withoutlong prompts. Experiments demonstrate that OptiMUS outperforms existingstate-of-the-art methods on easy datasets by more than $20\%$ and on harddatasets (including a new dataset, NLP4LP, released with this paper thatfeatures long and complex problems) by more than $30\%$.</description><author>Ali AhmadiTeshnizi, Wenzhi Gao, Madeleine Udell</author><pubDate>Thu, 15 Feb 2024 18:19:18 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.10172v1</guid></item><item><title>Data Engineering for Scaling Language Models to 128K Context</title><link>http://arxiv.org/abs/2402.10171v1</link><description>We study the continual pretraining recipe for scaling language models'context lengths to 128K, with a focus on data engineering. We hypothesize thatlong context modeling, in particular \textit{the ability to utilize informationat arbitrary input locations}, is a capability that is mostly already acquiredthrough large-scale pretraining, and that this capability can be readilyextended to contexts substantially longer than seen during training~(e.g., 4Kto 128K) through lightweight continual pretraining on appropriate data mixture.We investigate the \textit{quantity} and \textit{quality} of the data forcontinual pretraining: (1) for quantity, we show that 500 million to 5 billiontokens are enough to enable the model to retrieve information anywhere withinthe 128K context; (2) for quality, our results equally emphasize \textit{domainbalance} and \textit{length upsampling}. Concretely, we find that naivelyupsampling longer data on certain domains like books, a common practice ofexisting work, gives suboptimal performance, and that a balanced domain mixtureis important. We demonstrate that continual pretraining of the full model on1B-5B tokens of such data is an effective and affordable strategy for scalingthe context length of language models to 128K. Our recipe outperforms strongopen-source long-context models and closes the gap to frontier models likeGPT-4 128K.</description><author>Yao Fu, Rameswar Panda, Xinyao Niu, Xiang Yue, Hannaneh Hajishirzi, Yoon Kim, Hao Peng</author><pubDate>Thu, 15 Feb 2024 18:19:16 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.10171v1</guid></item><item><title>Secure Vertical Federated Learning Under Unreliable Connectivity</title><link>http://arxiv.org/abs/2305.16794v2</link><description>Most work in privacy-preserving federated learning (FL) has focused onhorizontally partitioned datasets where clients hold the same features andtrain complete client-level models independently. However, individual datapoints are often scattered across different institutions, known as clients, invertical FL (VFL) settings. Addressing this category of FL necessitates theexchange of intermediate outputs and gradients among participants, resulting inpotential privacy leakage risks and slow convergence rates. Additionally, inmany real-world scenarios, VFL training also faces the acute issue of clientstragglers and drop-outs, a serious challenge that can significantly hinder thetraining process but has been largely overlooked in existing studies. In thiswork, we present vFedSec, a first dropout-tolerant VFL protocol, which cansupport the most generalized vertical framework. It achieves secure andefficient model training by using an innovative Secure Layer alongside anembedding-padding technique. We provide theoretical proof that our designattains enhanced security while maintaining training performance. Empiricalresults from extensive experiments also demonstrate vFedSec is robust to clientdropout and provides secure training with negligible computation andcommunication overhead. Compared to widely adopted homomorphic encryption (HE)methods, our approach achieves a remarkable &gt; 690x speedup and reducescommunication costs significantly by &gt; 9.6x.</description><author>Xinchi Qiu, Heng Pan, Wanru Zhao, Chenyang Ma, William F. Shen, Pedro P. B. Gusmao, Nicholas D. Lane</author><pubDate>Thu, 15 Feb 2024 18:16:43 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.16794v2</guid></item><item><title>Minimally Supervised Learning using Topological Projections in Self-Organizing Maps</title><link>http://arxiv.org/abs/2401.06923v2</link><description>Parameter prediction is essential for many applications, facilitatinginsightful interpretation and decision-making. However, in many real lifedomains, such as power systems, medicine, and engineering, it can be veryexpensive to acquire ground truth labels for certain datasets as they mayrequire extensive and expensive laboratory testing. In this work, we introducea semi-supervised learning approach based on topological projections inself-organizing maps (SOMs), which significantly reduces the required number oflabeled data points to perform parameter prediction, effectively exploitinginformation contained in large unlabeled datasets. Our proposed method firsttrains SOMs on unlabeled data and then a minimal number of available labeleddata points are assigned to key best matching units (BMU). The values estimatedfor newly-encountered data points are computed utilizing the average of the $n$closest labeled data points in the SOM's U-matrix in tandem with a topologicalshortest path distance calculation scheme. Our results indicate that theproposed minimally supervised model significantly outperforms traditionalregression techniques, including linear and polynomial regression, Gaussianprocess regression, K-nearest neighbors, as well as deep neural network modelsand related clustering schemes.</description><author>Zimeng Lyu, Alexander Ororbia, Rui Li, Travis Desell</author><pubDate>Thu, 15 Feb 2024 18:15:35 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.06923v2</guid></item><item><title>The Emergence of Reproducibility and Consistency in Diffusion Models</title><link>http://arxiv.org/abs/2310.05264v2</link><description>In this work, we investigate an intriguing and prevalent phenomenon ofdiffusion models which we term as "consistent model reproducibility": given thesame starting noise input and a deterministic sampler, different diffusionmodels often yield remarkably similar outputs. We confirm this phenomenonthrough comprehensive experiments, implying that different diffusion modelsconsistently reach the same data distribution and scoring function regardlessof diffusion model frameworks, model architectures, or training procedures.More strikingly, our further investigation implies that diffusion models arelearning distinct distributions affected by the training data size. This issupported by the fact that the model reproducibility manifests in two distincttraining regimes: (i) "memorization regime", where the diffusion model overfitsto the training data distribution, and (ii) "generalization regime", where themodel learns the underlying data distribution. Our study also finds that thisvaluable property generalizes to many variants of diffusion models, includingthose for conditional use, solving inverse problems, and model fine-tuning.Finally, our work raises numerous intriguing theoretical questions for futureinvestigation and highlights practical implications regarding trainingefficiency, model privacy, and the controlled generation of diffusion models.</description><author>Huijie Zhang, Jinfan Zhou, Yifu Lu, Minzhe Guo, Peng Wang, Liyue Shen, Qing Qu</author><pubDate>Thu, 15 Feb 2024 18:14:53 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.05264v2</guid></item><item><title>DeepSRGM -- Sequence Classification and Ranking in Indian Classical Music with Deep Learning</title><link>http://arxiv.org/abs/2402.10168v1</link><description>A vital aspect of Indian Classical Music (ICM) is Raga, which serves as amelodic framework for compositions and improvisations alike. Raga Recognitionis an important music information retrieval task in ICM as it can aid numerousdownstream applications ranging from music recommendations to organizing hugemusic collections. In this work, we propose a deep learning based approach toRaga recognition. Our approach employs efficient pre possessing and learnstemporal sequences in music data using Long Short Term Memory based RecurrentNeural Networks (LSTM-RNN). We train and test the network on smaller sequencessampled from the original audio while the final inference is performed on theaudio as a whole. Our method achieves an accuracy of 88.1% and 97 % duringinference on the Comp Music Carnatic dataset and its 10 Raga subsetrespectively making it the state-of-the-art for the Raga recognition task. Ourapproach also enables sequence ranking which aids us in retrieving melodicpatterns from a given music data base that are closely related to the presentedquery sequence.</description><author>Sathwik Tejaswi Madhusudhan, Girish Chowdhary</author><pubDate>Thu, 15 Feb 2024 18:11:02 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.10168v1</guid></item><item><title>Random features and polynomial rules</title><link>http://arxiv.org/abs/2402.10164v1</link><description>Random features models play a distinguished role in the theory of deeplearning, describing the behavior of neural networks close to theirinfinite-width limit. In this work, we present a thorough analysis of thegeneralization performance of random features models for generic supervisedlearning problems with Gaussian data. Our approach, built with tools from thestatistical mechanics of disordered systems, maps the random features model toan equivalent polynomial model, and allows us to plot average generalizationcurves as functions of the two main control parameters of the problem: thenumber of random features $N$ and the size $P$ of the training set, bothassumed to scale as powers in the input dimension $D$. Our results extend thecase of proportional scaling between $N$, $P$ and $D$. They are in accordancewith rigorous bounds known for certain particular learning tasks and are inquantitative agreement with numerical experiments performed over many order ofmagnitudes of $N$ and $P$. We find good agreement also far from the asymptoticlimits where $D\to \infty$ and at least one between $P/D^K$, $N/D^L$ remainsfinite.</description><author>Fabián Aguirre-López, Silvio Franz, Mauro Pastore</author><pubDate>Thu, 15 Feb 2024 18:09:41 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.10164v1</guid></item><item><title>Hidden Traveling Waves bind Working Memory Variables in Recurrent Neural Networks</title><link>http://arxiv.org/abs/2402.10163v1</link><description>Traveling waves are a fundamental phenomenon in the brain, playing a crucialrole in short-term information storage. In this study, we leverage the conceptof traveling wave dynamics within a neural lattice to formulate a theoreticalmodel of neural working memory, study its properties, and its real worldimplications in AI. The proposed model diverges from traditional approaches,which assume information storage in static, register-like locations updated byinterference. Instead, the model stores data as waves that is updated by thewave's boundary conditions. We rigorously examine the model's capabilities inrepresenting and learning state histories, which are vital for learninghistory-dependent dynamical systems. The findings reveal that the modelreliably stores external information and enhances the learning process byaddressing the diminishing gradient problem. To understand the model'sreal-world applicability, we explore two cases: linear boundary condition andnon-linear, self-attention-driven boundary condition. The experiments revealthat the linear scenario is effectively learned by Recurrent Neural Networks(RNNs) through backpropagation when modeling history-dependent dynamicalsystems. Conversely, the non-linear scenario parallels the autoregressive loopof an attention-only transformer. Collectively, our findings suggest thebroader relevance of traveling waves in AI and its potential in advancingneural network architectures.</description><author>Arjun Karuvally, Terrence J. Sejnowski, Hava T. Siegelmann</author><pubDate>Thu, 15 Feb 2024 18:08:58 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.10163v1</guid></item><item><title>Knowledge-Infused LLM-Powered Conversational Health Agent: A Case Study for Diabetes Patients</title><link>http://arxiv.org/abs/2402.10153v1</link><description>Effective diabetes management is crucial for maintaining health in diabeticpatients. Large Language Models (LLMs) have opened new avenues for diabetesmanagement, facilitating their efficacy. However, current LLM-based approachesare limited by their dependence on general sources and lack of integration withdomain-specific knowledge, leading to inaccurate responses. In this paper, wepropose a knowledge-infused LLM-powered conversational health agent (CHA) fordiabetic patients. We customize and leverage the open-source openCHA framework,enhancing our CHA with external knowledge and analytical capabilities. Thisintegration involves two key components: 1) incorporating the American DiabetesAssociation dietary guidelines and the Nutritionix information and 2) deployinganalytical tools that enable nutritional intake calculation and comparison withthe guidelines. We compare the proposed CHA with GPT4. Our evaluation includes100 diabetes-related questions on daily meal choices and assessing thepotential risks associated with the suggested diet. Our findings show that theproposed agent demonstrates superior performance in generating responses tomanage essential nutrients.</description><author>Mahyar Abbasian, Zhongqi Yang, Elahe Khatibi, Pengfei Zhang, Nitish Nagesh, Iman Azimi, Ramesh Jain, Amir M. Rahmani</author><pubDate>Thu, 15 Feb 2024 18:00:02 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.10153v1</guid></item><item><title>ScamSpot: Fighting Financial Fraud in Instagram Comments</title><link>http://arxiv.org/abs/2402.08869v1</link><description>The long-standing problem of spam and fraudulent messages in the commentsections of Instagram pages in the financial sector claims new victims everyday. Instagram's current spam filter proves inadequate, and existing researchapproaches are primarily confined to theoretical concepts. Practicalimplementations with evaluated results are missing. To solve this problem, wepropose ScamSpot, a comprehensive system that includes a browser extension, afine-tuned BERT model and a REST API. This approach ensures publicaccessibility of our results for Instagram users using the Chrome browser.Furthermore, we conduct a data annotation study, shedding light on the reasonsand causes of the problem and evaluate the system through user feedback andcomparison with existing models. ScamSpot is an open-source project and ispublicly available at https://scamspot.github.io/.</description><author>Stefan Erben, Andreas Waldis</author><pubDate>Wed, 14 Feb 2024 00:30:18 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.08869v1</guid></item><item><title>ControlLM: Crafting Diverse Personalities for Language Models</title><link>http://arxiv.org/abs/2402.10151v1</link><description>As language models continue to scale in size and capability, they display anarray of emerging behaviors, both beneficial and concerning. This heightens theneed to control model behaviors. We hope to be able to control the personalitytraits of language models at the inference-time so as to have various characterfeatures, on top of which the requirements of different types of tasks can bemet. Personality is a higher-level and more abstract behavioral representationfor language models. We introduce ControlLM, which leverages differentialactivation patterns, derived from contrasting behavioral prompts in the model'slatent space, to influence the model's personality traits at inference. Thisapproach allows for the precise, real-time adjustment of model behavior. First,we demonstrate ControlLM's capacity to elicit diverse persona behaviors withoutany training, while precision control allows personality traits to closelymatch average human values. Subsequently, we showcase improved reasoning andquestion answering through selective amplification of beneficial attributeslike conscientiousness and friendliness. We hope that this work will inspireresearch on controlling human-like behaviors of language models and provideinsights for future research. Our code is publicly available at:https://github.com/wengsyx/ControlLM.</description><author>Yixuan Weng, Shizhu He, Kang Liu, Shengping Liu, Jun Zhao</author><pubDate>Thu, 15 Feb 2024 17:58:29 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.10151v1</guid></item><item><title>$f$-MICL: Understanding and Generalizing InfoNCE-based Contrastive Learning</title><link>http://arxiv.org/abs/2402.10150v1</link><description>In self-supervised contrastive learning, a widely-adopted objective functionis InfoNCE, which uses the heuristic cosine similarity for the representationcomparison, and is closely related to maximizing the Kullback-Leibler(KL)-based mutual information. In this paper, we aim at answering twointriguing questions: (1) Can we go beyond the KL-based objective? (2) Besidesthe popular cosine similarity, can we design a better similarity function? Weprovide answers to both questions by generalizing the KL-based mutualinformation to the $f$-Mutual Information in Contrastive Learning ($f$-MICL)using the $f$-divergences. To answer the first question, we provide a widerange of $f$-MICL objectives which share the nice properties of InfoNCE (e.g.,alignment and uniformity), and meanwhile result in similar or even superiorperformance. For the second question, assuming that the joint featuredistribution is proportional to the Gaussian kernel, we derive an $f$-Gaussiansimilarity with better interpretability and empirical performance. Finally, weidentify close relationships between the $f$-MICL objective and several popularInfoNCE-based objectives. Using benchmark tasks from both vision and naturallanguage, we empirically evaluate $f$-MICL with different $f$-divergences onvarious architectures (SimCLR, MoCo, and MoCo v3) and datasets. We observe that$f$-MICL generally outperforms the benchmarks and the best-performing$f$-divergence is task and dataset dependent.</description><author>Yiwei Lu, Guojun Zhang, Sun Sun, Hongyu Guo, Yaoliang Yu</author><pubDate>Thu, 15 Feb 2024 17:57:54 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.10150v1</guid></item><item><title>How to Fix a Broken Confidence Estimator: Evaluating Post-hoc Methods for Selective Classification with Deep Neural Networks</title><link>http://arxiv.org/abs/2305.15508v3</link><description>This paper addresses the problem of selective classification for deep neuralnetworks, where a model is allowed to abstain from low-confidence predictionsto avoid potential errors. We focus on so-called post-hoc methods, whichreplace the confidence estimator of a given classifier without modifying orretraining it, thus being practically appealing. Considering neural networkswith softmax outputs, our goal is to identify the best confidence estimatorthat can be computed directly from the unnormalized logits. This problem ismotivated by the intriguing observation in recent work that many classifiersappear to have a "broken" confidence estimator, in the sense that theirselective classification performance is much worse than what could be expectedby their corresponding accuracies. We perform an extensive experimental studyof many existing and proposed confidence estimators applied to 84 pretrainedImageNet classifiers available from popular repositories. Our results show thata simple $p$-norm normalization of the logits, followed by taking the maximumlogit as the confidence estimator, can lead to considerable gains in selectiveclassification performance, completely fixing the pathological behaviorobserved in many classifiers. As a consequence, the selective classificationperformance of any classifier becomes almost entirely determined by itscorresponding accuracy. Moreover, these results are shown to be consistentunder distribution shift.</description><author>Luís Felipe P. Cattelan, Danilo Silva</author><pubDate>Thu, 15 Feb 2024 17:56:41 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.15508v3</guid></item><item><title>A chaotic maps-based privacy-preserving distributed deep learning for incomplete and Non-IID datasets</title><link>http://arxiv.org/abs/2402.10145v1</link><description>Federated Learning is a machine learning approach that enables the trainingof a deep learning model among several participants with sensitive data thatwish to share their own knowledge without compromising the privacy of theirdata. In this research, the authors employ a secured Federated Learning methodwith an additional layer of privacy and proposes a method for addressing thenon-IID challenge. Moreover, differential privacy is compared withchaotic-based encryption as layer of privacy. The experimental approachassesses the performance of the federated deep learning model with differentialprivacy using both IID and non-IID data. In each experiment, the FederatedLearning process improves the average performance metrics of the deep neuralnetwork, even in the case of non-IID data.</description><author>Irina Arévalo, Jose L. Salmeron</author><pubDate>Thu, 15 Feb 2024 17:49:50 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.10145v1</guid></item><item><title>Tracking Changing Probabilities via Dynamic Learners</title><link>http://arxiv.org/abs/2402.10142v1</link><description>Consider a predictor, a learner, whose input is a stream of discrete items.The predictor's task, at every time point, is probabilistic multiclassprediction, i.e., to predict which item may occur next by outputting zero ormore candidate items, each with a probability, after which the actual item isrevealed and the predictor learns from this observation. To outputprobabilities, the predictor keeps track of the proportions of the items it hasseen. The predictor has constant (limited) space and we seek efficientprediction and update techniques: The stream is unbounded, the set of items isunknown to the predictor and their totality can also grow unbounded. Moreover,there is non-stationarity: the underlying frequencies of items may change,substantially, from time to time. For instance, new items may start appearingand a few currently frequent items may cease to occur again. The predictor,being space-bounded, need only provide probabilities for those items with(currently) sufficiently high frequency, i.e., the salient items. This problemis motivated in the setting of prediction games, a self-supervised learningregime where concepts serve as both the predictors and the predictands, and theset of concepts grows over time, resulting in non-stationarities as newconcepts are generated and used. We develop moving average techniques designedto respond to such non-stationarities in a timely manner, and explore theirproperties. One is a simple technique based on queuing of count snapshots, andanother is a combination of queuing together with an extended version of sparseEMA. The latter combination supports predictand-specific dynamic learningrates. We find that this flexibility allows for a more accurate and timelyconvergence.</description><author>Omid Madani</author><pubDate>Thu, 15 Feb 2024 17:48:58 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.10142v1</guid></item><item><title>Better Fair than Sorry: Adversarial Missing Data Imputation for Fair GNNs</title><link>http://arxiv.org/abs/2311.01591v2</link><description>This paper addresses the problem of learning fair Graph Neural Networks(GNNs) under missing protected attributes. GNNs have achieved state-of-the-artresults in many relevant tasks where decisions might disproportionately impactspecific communities. However, existing work on fair GNNs assumes that eitherprotected attributes are fully-observed or that the missing data imputation isfair. In practice, biases in the imputation will be propagated to the modeloutcomes, leading them to overestimate the fairness of their predictions. Weaddress this challenge by proposing Better Fair than Sorry (BFtS), a fairmissing data imputation model for protected attributes used by fair GNNs. Thekey design principle behind BFtS is that imputations should approximate theworst-case scenario for the fair GNN -- i.e. when optimizing fairness is thehardest. We implement this idea using a 3-player adversarial scheme where twoadversaries collaborate against the fair GNN. Experiments using synthetic andreal datasets show that BFtS often achieves a better fairness $\times$ accuracytrade-off than existing alternatives.</description><author>Debolina Halder Lina, Arlei Silva</author><pubDate>Thu, 15 Feb 2024 17:48:33 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.01591v2</guid></item><item><title>Concentrated Differential Privacy for Bandits</title><link>http://arxiv.org/abs/2309.00557v2</link><description>Bandits serve as the theoretical foundation of sequential learning and analgorithmic foundation of modern recommender systems. However, recommendersystems often rely on user-sensitive data, making privacy a critical concern.This paper contributes to the understanding of Differential Privacy (DP) inbandits with a trusted centralised decision-maker, and especially theimplications of ensuring zero Concentrated Differential Privacy (zCDP). First,we formalise and compare different adaptations of DP to bandits, depending onthe considered input and the interaction protocol. Then, we propose threeprivate algorithms, namely AdaC-UCB, AdaC-GOPE and AdaC-OFUL, for three banditsettings, namely finite-armed bandits, linear bandits, and linear contextualbandits. The three algorithms share a generic algorithmic blueprint, i.e. theGaussian mechanism and adaptive episodes, to ensure a good privacy-utilitytrade-off. We analyse and upper bound the regret of these three algorithms. Ouranalysis shows that in all of these settings, the prices of imposing zCDP are(asymptotically) negligible in comparison with the regrets incurred obliviousto privacy. Next, we complement our regret upper bounds with the first minimaxlower bounds on the regret of bandits with zCDP. To prove the lower bounds, weelaborate a new proof technique based on couplings and optimal transport. Weconclude by experimentally validating our theoretical results for the threedifferent settings of bandits.</description><author>Achraf Azize, Debabrota Basu</author><pubDate>Thu, 15 Feb 2024 17:44:24 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2309.00557v2</guid></item><item><title>Learning Complex Teamwork Tasks Using a Given Sub-task Decomposition</title><link>http://arxiv.org/abs/2302.04944v2</link><description>Training a team to complete a complex task via multi-agent reinforcementlearning can be difficult due to challenges such as policy search in a largejoint policy space, and non-stationarity caused by mutually adapting agents. Tofacilitate efficient learning of complex multi-agent tasks, we propose anapproach which uses an expert-provided decomposition of a task into simplermulti-agent sub-tasks. In each sub-task, a subset of the entire team is trainedto acquire sub-task-specific policies. The sub-teams are then merged andtransferred to the target task, where their policies are collectivelyfine-tuned to solve the more complex target task. We show empirically that suchapproaches can greatly reduce the number of timesteps required to solve acomplex target task relative to training from-scratch. However, we alsoidentify and investigate two problems with naive implementations of approachesbased on sub-task decomposition, and propose a simple and scalable method toaddress these problems which augments existing actor-critic algorithms. Wedemonstrate the empirical benefits of our proposed method, enabling sub-taskdecomposition approaches to be deployed in diverse multi-agent tasks.</description><author>Elliot Fosong, Arrasy Rahman, Ignacio Carlucho, Stefano V. Albrecht</author><pubDate>Thu, 15 Feb 2024 17:43:25 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2302.04944v2</guid></item><item><title>Connectivity Oracles for Predictable Vertex Failures</title><link>http://arxiv.org/abs/2312.08489v2</link><description>The problem of designing connectivity oracles supporting vertex failures isone of the basic data structures problems for undirected graphs. It is alreadywell understood: previous works [Duan--Pettie STOC'10; Long--Saranurak FOCS'22]achieve query time linear in the number of failed vertices, and it isconditionally optimal as long as we require preprocessing time polynomial inthe size of the graph and update time polynomial in the number of failedvertices. We revisit this problem in the paradigm of algorithms with predictions: weask if the query time can be improved if the set of failed vertices can bepredicted beforehand up to a small number of errors. More specifically, wedesign a data structure that, given a graph $G=(V,E)$ and a set of verticespredicted to fail $\widehat{D} \subseteq V$ of size $d=|\widehat{D}|$,preprocesses it in time $\tilde{O}(d|E|)$ and then can receive an update givenas the symmetric difference between the predicted and the actual set of failedvertices $\widehat{D} \triangle D = (\widehat{D} \setminus D) \cup (D \setminus\widehat{D})$ of size $\eta = |\widehat{D} \triangle D|$, process it in time$\tilde{O}(\eta^4)$, and after that answer connectivity queries in $G \setminusD$ in time $O(\eta)$. Viewed from another perspective, our data structureprovides an improvement over the state of the art for the \emph{fully dynamicsubgraph connectivity problem} in the \emph{sensitivity setting}[Henzinger--Neumann ESA'16]. We argue that the preprocessing time and query time of our data structure areconditionally optimal under standard fine-grained complexity assumptions.</description><author>Bingbing Hu, Evangelos Kosinas, Adam Polak</author><pubDate>Thu, 15 Feb 2024 17:40:29 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.08489v2</guid></item><item><title>ODD: A Benchmark Dataset for the NLP-based Opioid Related Aberrant Behavior Detection</title><link>http://arxiv.org/abs/2307.02591v3</link><description>Opioid related aberrant behaviors (ORABs) present novel risk factors foropioid overdose. This paper introduces a novel biomedical natural languageprocessing benchmark dataset named ODD, for ORAB Detection Dataset. ODD is anexpert-annotated dataset designed to identify ORABs from patients' EHR notesand classify them into nine categories; 1) Confirmed Aberrant Behavior, 2)Suggested Aberrant Behavior, 3) Opioids, 4) Indication, 5) Diagnosed opioiddependency, 6) Benzodiazepines, 7) Medication Changes, 8) Central NervousSystem-related, and 9) Social Determinants of Health. We explored twostate-of-the-art natural language processing models (fine-tuning andprompt-tuning approaches) to identify ORAB. Experimental results show that theprompt-tuning models outperformed the fine-tuning models in most cateogoriesand the gains were especially higher among uncommon categories (SuggestedAberrant Behavior, Confirmed Aberrant Behaviors, Diagnosed Opioid Dependence,and Medication Change). Although the best model achieved the highest 88.17\% onmacro average area under precision recall curve, uncommon classes still have alarge room for performance improvement. ODD is publicly available.</description><author>Sunjae Kwon, Xun Wang, Weisong Liu, Emily Druhl, Minhee L. Sung, Joel I. Reisman, Wenjun Li, Robert D. Kerns, William Becker, Hong Yu</author><pubDate>Thu, 15 Feb 2024 17:40:03 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.02591v3</guid></item><item><title>TOAD: Task-Oriented Automatic Dialogs with Diverse Response Styles</title><link>http://arxiv.org/abs/2402.10137v2</link><description>In light of recent advances in large language models (LLMs), the expectationsfor the next generation of virtual assistants include enhanced naturalness andadaptability across diverse usage scenarios. However, the creation ofhigh-quality annotated data for Task-Oriented Dialog (TOD) is recognized to beslow and costly. To address these challenges, we introduce Task-OrientedAutomatic Dialogs (TOAD), a novel and scalable TOD dataset along with itsautomatic generation pipeline. The TOAD dataset simulates realistic app contextinteraction and provide a variety of system response style options. Two aspectsof system response styles are considered, verbosity level and users' expressionmirroring. We benchmark TOAD on two response generation tasks and the resultsshow that modelling more verbose or responses without user expression mirroringis more challenging.</description><author>Yinhong Liu, Yimai Fang, David Vandyke, Nigel Collier</author><pubDate>Fri, 16 Feb 2024 10:57:32 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.10137v2</guid></item><item><title>Benchmarking federated strategies in Peer-to-Peer Federated learning for biomedical data</title><link>http://arxiv.org/abs/2402.10135v1</link><description>The increasing requirements for data protection and privacy has attracted ahuge research interest on distributed artificial intelligence and specificallyon federated learning, an emerging machine learning approach that allows theconstruction of a model between several participants who hold their own privatedata. In the initial proposal of federated learning the architecture wascentralised and the aggregation was done with federated averaging, meaning thata central server will orchestrate the federation using the most straightforwardaveraging strategy. This research is focused on testing different federatedstrategies in a peer-to-peer environment. The authors propose variousaggregation strategies for federated learning, including weighted averagingaggregation, using different factors and strategies based on participantcontribution. The strategies are tested with varying data sizes to identify themost robust ones. This research tests the strategies with several biomedicaldatasets and the results of the experiments show that the accuracy-basedweighted average outperforms the classical federated averaging method.</description><author>Jose L. Salmeron, Irina Arévalo, Antonio Ruiz-Celma</author><pubDate>Thu, 15 Feb 2024 17:38:32 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.10135v1</guid></item><item><title>Revisiting LARS for Large Batch Training Generalization of Neural Networks</title><link>http://arxiv.org/abs/2309.14053v4</link><description>This paper explores Large Batch Training techniques using layer-wise adaptivescaling ratio (LARS) across diverse settings, uncovering insights. LARSalgorithms with warm-up tend to be trapped in sharp minimizers early on due toredundant ratio scaling. Additionally, a fixed steep decline in the latterphase restricts deep neural networks from effectively navigating early-phasesharp minimizers. Building on these findings, we propose Time Varying LARS(TVLARS), a novel algorithm that replaces warm-up with a configurablesigmoid-like function for robust training in the initial phase. TVLARS promotesgradient exploration early on, surpassing sharp optimizers and graduallytransitioning to LARS for robustness in later phases. Extensive experimentsdemonstrate that TVLARS consistently outperforms LARS and LAMB in most cases,with up to 2\% improvement in classification scenarios. Notably, in allself-supervised learning cases, TVLARS dominates LARS and LAMB with performanceimprovements of up to 10\%.</description><author>Khoi Do, Duong Nguyen, Hoa Nguyen, Long Tran-Thanh, Nguyen-Hoang Tran, Quoc-Viet Pham</author><pubDate>Thu, 15 Feb 2024 17:37:56 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2309.14053v4</guid></item><item><title>Zero-Shot Reasoning: Personalized Content Generation Without the Cold Start Problem</title><link>http://arxiv.org/abs/2402.10133v1</link><description>Procedural content generation uses algorithmic techniques to create largeamounts of new content for games at much lower production costs. In newerapproaches, procedural content generation utilizes machine learning. However,these methods usually require expensive collection of large amounts of data, aswell as the development and training of fairly complex learning models, whichcan be both extremely time-consuming and expensive. The core of our research isto explore whether we can lower the barrier to the use of personalizedprocedural content generation through a more practical and generalizableapproach with large language models. Matching game content with playerpreferences benefits both players, who enjoy the game more, and developers, whoincreasingly depend on players enjoying the game before being able to monetizeit. Therefore, this paper presents a novel approach to achievingpersonalization by using large language models to propose levels based on thegameplay data continuously collected from individual players. We compared thelevels generated using our approach with levels generated with more traditionalprocedural generation techniques. Our easily reproducible method has provenviable in a production setting and outperformed levels generated by traditionalmethods in the probability that a player will not quit the game mid-level.</description><author>Davor Hafnar, Jure Demšar</author><pubDate>Thu, 15 Feb 2024 17:37:25 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.10133v1</guid></item><item><title>Is Continual Learning Ready for Real-world Challenges?</title><link>http://arxiv.org/abs/2402.10130v1</link><description>Despite continual learning's long and well-established academic history, itsapplication in real-world scenarios remains rather limited. This paper contendsthat this gap is attributable to a misalignment between the actual challengesof continual learning and the evaluation protocols in use, rendering proposedsolutions ineffective for addressing the complexities of real-world setups. Wevalidate our hypothesis and assess progress to date, using a new 3D semanticsegmentation benchmark, OCL-3DSS. We investigate various continual learningschemes from the literature by utilizing more realistic protocols thatnecessitate online and continual learning for dynamic, real-world scenarios(eg., in robotics and 3D vision applications). The outcomes are sobering: allconsidered methods perform poorly, significantly deviating from the upper boundof joint offline training. This raises questions about the applicability ofexisting methods in realistic settings. Our paper aims to initiate a paradigmshift, advocating for the adoption of continual learning methods through newexperimental protocols that better emulate real-world conditions to facilitatebreakthroughs in the field.</description><author>Theodora Kontogianni, Yuanwen Yue, Siyu Tang, Konrad Schindler</author><pubDate>Thu, 15 Feb 2024 17:34:56 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.10130v1</guid></item><item><title>GES: Generalized Exponential Splatting for Efficient Radiance Field Rendering</title><link>http://arxiv.org/abs/2402.10128v1</link><description>Advancements in 3D Gaussian Splatting have significantly accelerated 3Dreconstruction and generation. However, it may require a large number ofGaussians, which creates a substantial memory footprint. This paper introducesGES (Generalized Exponential Splatting), a novel representation that employsGeneralized Exponential Function (GEF) to model 3D scenes, requiring far fewerparticles to represent a scene and thus significantly outperforming GaussianSplatting methods in efficiency with a plug-and-play replacement ability forGaussian-based utilities. GES is validated theoretically and empirically inboth principled 1D setup and realistic 3D scenes. It is shown to represent signals with sharp edges more accurately, which aretypically challenging for Gaussians due to their inherent low-passcharacteristics. Our empirical analysis demonstrates that GEF outperformsGaussians in fitting natural-occurring signals (e.g. squares, triangles, andparabolic signals), thereby reducing the need for extensive splittingoperations that increase the memory footprint of Gaussian Splatting. With theaid of a frequency-modulated loss, GES achieves competitive performance innovel-view synthesis benchmarks while requiring less than half the memorystorage of Gaussian Splatting and increasing the rendering speed by up to 39%.The code is available on the project website https://abdullahamdi.com/ges .</description><author>Abdullah Hamdi, Luke Melas-Kyriazi, Guocheng Qian, Jinjie Mai, Ruoshi Liu, Carl Vondrick, Bernard Ghanem, Andrea Vedaldi</author><pubDate>Thu, 15 Feb 2024 17:32:50 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.10128v1</guid></item><item><title>Any-Shift Prompting for Generalization over Distributions</title><link>http://arxiv.org/abs/2402.10099v1</link><description>Image-language models with prompt learning have shown remarkable advances innumerous downstream vision tasks. Nevertheless, conventional prompt learningmethods overfit their training distribution and lose the generalization abilityon test distributions. To improve generalization across various distributionshifts, we propose any-shift prompting: a general probabilistic inferenceframework that considers the relationship between training and testdistributions during prompt learning. We explicitly connect training and testdistributions in the latent space by constructing training and test prompts ina hierarchical architecture. Within this framework, the test prompt exploitsthe distribution relationships to guide the generalization of the CLIPimage-language model from training to any test distribution. To effectivelyencode the distribution information and their relationships, we furtherintroduce a transformer inference network with a pseudo-shift trainingmechanism. The network generates the tailored test prompt with both trainingand test information in a feedforward pass, avoiding extra training costs attest time. Extensive experiments on twenty-three datasets demonstrate theeffectiveness of any-shift prompting on the generalization over variousdistribution shifts.</description><author>Zehao Xiao, Jiayi Shen, Mohammad Mahdi Derakhshani, Shengcai Liao, Cees G. M. Snoek</author><pubDate>Thu, 15 Feb 2024 16:53:42 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.10099v1</guid></item><item><title>Explain Variance of Prediction in Variational Time Series Models for Clinical Deterioration Prediction</title><link>http://arxiv.org/abs/2402.06808v2</link><description>Missingness and measurement frequency are two sides of the same coin. Howfrequent should we measure clinical variables and conduct laboratory tests? Itdepends on many factors such as the stability of patient conditions, diagnosticprocess, treatment plan and measurement costs. The utility of measurementsvaries disease by disease, patient by patient. In this study we propose a novelview of clinical variable measurement frequency from a predictive modelingperspective, namely the measurements of clinical variables reduce uncertaintyin model predictions. To achieve this goal, we propose variance SHAP withvariational time series models, an application of Shapley AdditiveExpanation(SHAP) algorithm to attribute epistemic prediction uncertainty. Theprediction variance is estimated by sampling the conditional hidden space invariational models and can be approximated deterministically by delta's method.This approach works with variational time series models such as variationalrecurrent neural networks and variational transformers. Since SHAP values areadditive, the variance SHAP of binary data imputation masks can be directlyinterpreted as the contribution to prediction variance by measurements. Wetested our ideas on a public ICU dataset with deterioration prediction task andstudy the relation between variance SHAP and measurement time intervals.</description><author>Jiacheng Liu, Jaideep Srivastava</author><pubDate>Thu, 15 Feb 2024 17:32:38 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.06808v2</guid></item><item><title>Nonlinear spiked covariance matrices and signal propagation in deep neural networks</title><link>http://arxiv.org/abs/2402.10127v1</link><description>Many recent works have studied the eigenvalue spectrum of the ConjugateKernel (CK) defined by the nonlinear feature map of a feedforward neuralnetwork. However, existing results only establish weak convergence of theempirical eigenvalue distribution, and fall short of providing precisequantitative characterizations of the ''spike'' eigenvalues and eigenvectorsthat often capture the low-dimensional signal structure of the learningproblem. In this work, we characterize these signal eigenvalues andeigenvectors for a nonlinear version of the spiked covariance model, includingthe CK as a special case. Using this general result, we give a quantitativedescription of how spiked eigenstructure in the input data propagates throughthe hidden layers of a neural network with random weights. As a secondapplication, we study a simple regime of representation learning where theweight matrix develops a rank-one signal component over training andcharacterize the alignment of the target function with the spike eigenvector ofthe CK on test data.</description><author>Zhichao Wang, Denny Wu, Zhou Fan</author><pubDate>Thu, 15 Feb 2024 17:31:19 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.10127v1</guid></item><item><title>Policy Improvement using Language Feedback Models</title><link>http://arxiv.org/abs/2402.07876v2</link><description>We introduce Language Feedback Models (LFMs) that identify desirablebehaviour - actions that help achieve tasks specified in the instruction - forimitation learning in instruction following. To train LFMs, we obtain feedbackfrom Large Language Models (LLMs) on visual trajectories verbalized to languagedescriptions. First, by using LFMs to identify desirable behaviour to imitate,we improve in task-completion rate over strong behavioural cloning baselines onthree distinct language grounding environments (Touchdown, ScienceWorld, andALFWorld). Second, LFMs outperform using LLMs as experts to directly predictactions, when controlling for the number of LLM output tokens. Third, LFMsgeneralize to unseen environments, improving task-completion rate by 3.5-12.0%through one round of adaptation. Finally, LFM can be modified to providehuman-interpretable feedback without performance loss, allowing humanverification of desirable behaviour for imitation learning.</description><author>Victor Zhong, Dipendra Misra, Xingdi Yuan, Marc-Alexandre Côté</author><pubDate>Thu, 15 Feb 2024 17:20:22 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.07876v2</guid></item><item><title>Are self-explanations from Large Language Models faithful?</title><link>http://arxiv.org/abs/2401.07927v3</link><description>Instruction-tuned Large Language Models (LLMs) excel at many tasks and willeven explain their reasoning, so-called self-explanations. However, convincingand wrong self-explanations can lead to unsupported confidence in LLMs, thusincreasing risk. Therefore, it's important to measure if self-explanationstruly reflect the model's behavior. Such a measure is calledinterpretability-faithfulness and is challenging to perform since the groundtruth is inaccessible, and many LLMs only have an inference API. To addressthis, we propose employing self-consistency checks to measure faithfulness. Forexample, if an LLM says a set of words is important for making a prediction,then it should not be able to make its prediction without these words. Whileself-consistency checks are a common approach to faithfulness, they have notpreviously been successfully applied to LLM self-explanations forcounterfactual, importance measure, and redaction explanations. Our resultsdemonstrate that faithfulness is explanation, model, and task-dependent,showing self-explanations should not be trusted in general. For example, withsentiment classification, counterfactuals are more faithful for Llama2,importance measures for Mistral, and redaction for Falcon 40B.</description><author>Andreas Madsen, Sarath Chandar, Siva Reddy</author><pubDate>Thu, 15 Feb 2024 17:19:22 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.07927v3</guid></item><item><title>Reusing Softmax Hardware Unit for GELU Computation in Transformers</title><link>http://arxiv.org/abs/2402.10118v2</link><description>Transformers have improved drastically the performance of natural languageprocessing (NLP) and computer vision applications. The computation oftransformers involves matrix multiplications and non-linear activationfunctions such as softmax and GELU (Gaussion Error Linear Unit) that areaccelerated directly in hardware. Currently, function evaluation is doneseparately for each function and rarely allows for hardware reuse. To mitigatethis problem, in this work, we map the computation of GELU to a softmaxoperator. In this way, the efficient hardware units designed already forsoftmax can be reused for computing GELU as well. Computation of GELU can enjoythe inherent vectorized nature of softmax and produce in parallel multiple GELUoutcomes. Experimental results show that computing GELU via a pre-existing andincrementally modified softmax hardware unit (a) does not reduce the accuracyof representative NLP applications and (b) allows the reduction of the overallhardware area and power by 6.1% and 11.9%, respectively, on average.</description><author>Christodoulos Peltekis, Kosmas Alexandridis, Giorgos Dimitrakopoulos</author><pubDate>Fri, 16 Feb 2024 08:52:29 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.10118v2</guid></item><item><title>Quantized Embedding Vectors for Controllable Diffusion Language Models</title><link>http://arxiv.org/abs/2402.10107v1</link><description>Improving the controllability, portability, and inference speed of diffusionlanguage models (DLMs) is a key challenge in natural language generation. Whilerecent research has shown significant success in complex text generation withlanguage models, the memory and computational power are still very demandingand fall short of expectations, which naturally results in low portability andinstability for the models. To mitigate these issues, numerous well-establishedmethods were proposed for neural network quantization. To further enhance theirportability of independent deployment as well as improve their stabilityevaluated by language perplexity, we propose a novel approach called theQuantized Embedding Controllable Diffusion Language Model (QE-CDLM). QE-CDLMbuilds upon the recent successful controllable DLMs by remodeling thetask-specific embedding space via quantization. This leads to a gradient-basedcontroller for the generation tasks, and more stable intermediate latentvariables are obtained, which naturally brings in an accelerated convergence aswell as better controllability. Additionally, the adaption fine-tuning methodis employed to reduce tunable weights. Experimental results on five challengingfine-grained control tasks demonstrate that QE-CDLM compares favorably toexisting methods in terms of quality and feasibility, achieving betterperplexity and lightweight fine-tuning.</description><author>Cheng Kang, Xinye Chen, Yong Hu, Daniel Novak</author><pubDate>Thu, 15 Feb 2024 17:02:48 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.10107v1</guid></item><item><title>Generating Visual Stimuli from EEG Recordings using Transformer-encoder based EEG encoder and GAN</title><link>http://arxiv.org/abs/2402.10115v1</link><description>In this study, we tackle a modern research challenge within the field ofperceptual brain decoding, which revolves around synthesizing images from EEGsignals using an adversarial deep learning framework. The specific objective isto recreate images belonging to various object categories by leveraging EEGrecordings obtained while subjects view those images. To achieve this, weemploy a Transformer-encoder based EEG encoder to produce EEG encodings, whichserve as inputs to the generator component of the GAN network. Alongside theadversarial loss, we also incorporate perceptual loss to enhance the quality ofthe generated images.</description><author>Rahul Mishra, Arnav Bhavsar</author><pubDate>Thu, 15 Feb 2024 17:10:27 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.10115v1</guid></item><item><title>Selective Reflection-Tuning: Student-Selected Data Recycling for LLM Instruction-Tuning</title><link>http://arxiv.org/abs/2402.10110v1</link><description>Instruction tuning is critical to large language models (LLMs) for achievingbetter instruction following and task adaptation capabilities but its successheavily relies on the training data quality. Many recent methods focus onimproving the data quality but often overlook the compatibility of the datawith the student model being finetuned. This paper introduces SelectiveReflection-Tuning, a novel paradigm that synergizes a teacher LLM's reflectionand introspection for improving existing data quality with the data selectioncapability of the student LLM, to automatically refine existinginstruction-tuning data. This teacher-student collaboration produceshigh-quality and student-compatible instruction-response pairs, resulting insample-efficient instruction tuning and LLMs of superior performance. SelectiveReflection-Tuning is a data augmentation and synthesis that generally improvesLLM finetuning and self-improvement without collecting brand-new data. We applyour method to Alpaca and WizardLM data and achieve much stronger and top-tier7B and 13B LLMs. Our codes, models, and data will be released athttps://github.com/tianyi-lab/Reflection_Tuning.</description><author>Ming Li, Lichang Chen, Jiuhai Chen, Shwai He, Jiuxiang Gu, Tianyi Zhou</author><pubDate>Thu, 15 Feb 2024 17:06:21 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.10110v1</guid></item><item><title>Towards Reducing Diagnostic Errors with Interpretable Risk Prediction</title><link>http://arxiv.org/abs/2402.10109v1</link><description>Many diagnostic errors occur because clinicians cannot easily access relevantinformation in patient Electronic Health Records (EHRs). In this work wepropose a method to use LLMs to identify pieces of evidence in patient EHR datathat indicate increased or decreased risk of specific diagnoses; our ultimateaim is to increase access to evidence and reduce diagnostic errors. Inparticular, we propose a Neural Additive Model to make predictions backed byevidence with individualized risk estimates at time-points where clinicians arestill uncertain, aiming to specifically mitigate delays in diagnosis and errorsstemming from an incomplete differential. To train such a model, it isnecessary to infer temporally fine-grained retrospective labels of eventual"true" diagnoses. We do so with LLMs, to ensure that the input text is frombefore a confident diagnosis can be made. We use an LLM to retrieve an initialpool of evidence, but then refine this set of evidence according tocorrelations learned by the model. We conduct an in-depth evaluation of theusefulness of our approach by simulating how it might be used by a clinician todecide between a pre-defined list of differential diagnoses.</description><author>Denis Jered McInerney, William Dickinson, Lucy Flynn, Andrea Young, Geoffrey Young, Jan-Willem van de Meent, Byron C. Wallace</author><pubDate>Thu, 15 Feb 2024 17:05:48 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.10109v1</guid></item><item><title>Dual input stream transformer for vertical drift correction in eye-tracking reading data</title><link>http://arxiv.org/abs/2311.06095v2</link><description>We introduce a novel Dual Input Stream Transformer (DIST) for the challengingproblem of assigning fixation points from eye-tracking data collected duringpassage reading to the line of text that the reader was actually focused on.This post-processing step is crucial for analysis of the reading data due tothe presence of noise in the form of vertical drift. We evaluate DIST againsteleven classical approaches on a comprehensive suite of nine diverse datasets.We demonstrate that combining multiple instances of the DIST model in anensemble achieves high accuracy across all datasets. Further combining the DISTensemble with the best classical approach yields an average accuracy of 98.17%. Our approach presents a significant step towards addressing the bottleneckof manual line assignment in reading research. Through extensive analysis andablation studies, we identify key factors that contribute to DIST's success,including the incorporation of line overlap features and the use of a secondinput stream. Via rigorous evaluation, we demonstrate that DIST is robust tovarious experimental setups, making it a safe first choice for practitioners inthe field.</description><author>Thomas M. Mercier, Marcin Budka, Martin R. Vasilev, Julie A. Kirkby, Bernhard Angele, Timothy J. Slattery</author><pubDate>Thu, 15 Feb 2024 17:05:14 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.06095v2</guid></item><item><title>Fast and explainable clustering based on sorting</title><link>http://arxiv.org/abs/2202.01456v2</link><description>We introduce a fast and explainable clustering method called CLASSIX. Itconsists of two phases, namely a greedy aggregation phase of the sorted datainto groups of nearby data points, followed by the merging of groups intoclusters. The algorithm is controlled by two scalar parameters, namely adistance parameter for the aggregation and another parameter controlling theminimal cluster size. Extensive experiments are conducted to give acomprehensive evaluation of the clustering performance on synthetic andreal-world datasets, with various cluster shapes and low to high featuredimensionality. Our experiments demonstrate that CLASSIX competes withstate-of-the-art clustering algorithms. The algorithm has linear spacecomplexity and achieves near linear time complexity on a wide range ofproblems. Its inherent simplicity allows for the generation of intuitiveexplanations of the computed clusters.</description><author>Xinye Chen, Stefan Güttel</author><pubDate>Thu, 15 Feb 2024 17:02:58 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2202.01456v2</guid></item><item><title>Str2Str: A Score-based Framework for Zero-shot Protein Conformation Sampling</title><link>http://arxiv.org/abs/2306.03117v2</link><description>The dynamic nature of proteins is crucial for determining their biologicalfunctions and properties, for which Monte Carlo (MC) and molecular dynamics(MD) simulations stand as predominant tools to study such phenomena. Byutilizing empirically derived force fields, MC or MD simulations explore theconformational space through numerically evolving the system via Markov chainor Newtonian mechanics. However, the high-energy barrier of the force fieldscan hamper the exploration of both methods by the rare event, resulting ininadequately sampled ensemble without exhaustive running. Existinglearning-based approaches perform direct sampling yet heavily rely ontarget-specific simulation data for training, which suffers from high dataacquisition cost and poor generalizability. Inspired by simulated annealing, wepropose Str2Str, a novel structure-to-structure translation framework capableof zero-shot conformation sampling with roto-translation equivariant property.Our method leverages an amortized denoising score matching objective trained ongeneral crystal structures and has no reliance on simulation data during bothtraining and inference. Experimental results across several benchmarkingprotein systems demonstrate that Str2Str outperforms previous state-of-the-artgenerative structure prediction models and can be orders of magnitude fastercompared to long MD simulations. Our open-source implementation is available athttps://github.com/lujiarui/Str2Str</description><author>Jiarui Lu, Bozitao Zhong, Zuobai Zhang, Jian Tang</author><pubDate>Thu, 15 Feb 2024 16:59:42 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.03117v2</guid></item><item><title>GeoEval: Benchmark for Evaluating LLMs and Multi-Modal Models on Geometry Problem-Solving</title><link>http://arxiv.org/abs/2402.10104v1</link><description>Recent advancements in Large Language Models (LLMs) and Multi-Modal Models(MMs) have demonstrated their remarkable capabilities in problem-solving. Yet,their proficiency in tackling geometry math problems, which necessitates anintegrated understanding of both textual and visual information, has not beenthoroughly evaluated. To address this gap, we introduce the GeoEval benchmark,a comprehensive collection that includes a main subset of 2000 problems, a 750problem subset focusing on backward reasoning, an augmented subset of 2000problems, and a hard subset of 300 problems. This benchmark facilitates adeeper investigation into the performance of LLMs and MMs on solving geometrymath problems. Our evaluation of ten LLMs and MMs across these varied subsetsreveals that the WizardMath model excels, achieving a 55.67\% accuracy rate onthe main subset but only a 6.00\% accuracy on the challenging subset. Thishighlights the critical need for testing models against datasets on which theyhave not been pre-trained. Additionally, our findings indicate that GPT-seriesmodels perform more effectively on problems they have rephrased, suggesting apromising method for enhancing model capabilities.</description><author>Jiaxin Zhang, Zhongzhi Li, Mingliang Zhang, Fei Yin, Chenglin Liu, Yashar Moshfeghi</author><pubDate>Thu, 15 Feb 2024 16:59:41 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.10104v1</guid></item><item><title>FedMT: Federated Learning with Mixed-type Labels</title><link>http://arxiv.org/abs/2210.02042v4</link><description>In federated learning (FL), classifiers (e.g., deep networks) are trained ondatasets from multiple data centers without exchanging data across them, whichimproves the sample efficiency. However, the conventional FL setting assumesthe same labeling criterion in all data centers involved, thus limiting itspractical utility. This limitation becomes particularly notable in domains likedisease diagnosis, where different clinical centers may adhere to differentstandards, making traditional FL methods unsuitable. This paper addresses thisimportant yet under-explored setting of FL, namely FL with mixed-type labels,where the allowance of different labeling criteria introduces inter-centerlabel space differences. To address this challenge effectively and efficiently,we introduce a model-agnostic approach called FedMT, which estimates labelspace correspondences and projects classification scores to construct lossfunctions. The proposed FedMT is versatile and integrates seamlessly withvarious FL methods, such as FedAvg. Experimental results on benchmark andmedical datasets highlight the substantial improvement in classificationaccuracy achieved by FedMT in the presence of mixed-type labels.</description><author>Qiong Zhang, Jing Peng, Xin Zhang, Aline Talhouk, Gang Niu, Xiaoxiao Li</author><pubDate>Thu, 15 Feb 2024 16:58:34 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2210.02042v4</guid></item><item><title>Indiscriminate Data Poisoning Attacks on Neural Networks</title><link>http://arxiv.org/abs/2204.09092v2</link><description>Data poisoning attacks, in which a malicious adversary aims to influence amodel by injecting "poisoned" data into the training process, have attractedsignificant recent attention. In this work, we take a closer look at existingpoisoning attacks and connect them with old and new algorithms for solvingsequential Stackelberg games. By choosing an appropriate loss function for theattacker and optimizing with algorithms that exploit second-order information,we design poisoning attacks that are effective on neural networks. We presentefficient implementations that exploit modern auto-differentiation packages andallow simultaneous and coordinated generation of tens of thousands of poisonedpoints, in contrast to existing methods that generate poisoned points one byone. We further perform extensive experiments that empirically explore theeffect of data poisoning attacks on deep neural networks.</description><author>Yiwei Lu, Gautam Kamath, Yaoliang Yu</author><pubDate>Thu, 15 Feb 2024 16:57:43 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2204.09092v2</guid></item><item><title>A privacy-preserving, distributed and cooperative FCM-based learning approach for Cancer Research</title><link>http://arxiv.org/abs/2402.10102v1</link><description>Distributed Artificial Intelligence is attracting interest day by day. Inthis paper, the authors introduce an innovative methodology for distributedlearning of Particle Swarm Optimization-based Fuzzy Cognitive Maps in aprivacy-preserving way. The authors design a training scheme for collaborativeFCM learning that offers data privacy compliant with the current regulation.This method is applied to a cancer detection problem, proving that theperformance of the model is improved by the Federated Learning process, andobtaining similar results to the ones that can be found in the literature.</description><author>Jose L. Salmeron, Irina Arévalo</author><pubDate>Thu, 15 Feb 2024 16:56:25 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.10102v1</guid></item><item><title>Adaptive Federated Learning in Heterogeneous Wireless Networks with Independent Sampling</title><link>http://arxiv.org/abs/2402.10097v1</link><description>Federated Learning (FL) algorithms commonly sample a random subset of clientsto address the straggler issue and improve communication efficiency. Whilerecent works have proposed various client sampling methods, they havelimitations in joint system and data heterogeneity design, which may not alignwith practical heterogeneous wireless networks. In this work, we advocate a newindependent client sampling strategy to minimize the wall-clock training timeof FL, while considering data heterogeneity and system heterogeneity in bothcommunication and computation. We first derive a new convergence bound fornon-convex loss functions with independent client sampling and then propose anadaptive bandwidth allocation scheme. Furthermore, we propose an efficientindependent client sampling algorithm based on the upper bounds on theconvergence rounds and the expected per-round training time, to minimize thewall-clock time of FL, while considering both the data and systemheterogeneity. Experimental results under practical wireless network settingswith real-world prototype demonstrate that the proposed independent samplingscheme substantially outperforms the current best sampling schemes undervarious training models and datasets.</description><author>Jiaxiang Geng, Yanzhao Hou, Xiaofeng Tao, Juncheng Wang, Bing Luo</author><pubDate>Thu, 15 Feb 2024 16:51:38 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.10097v1</guid></item><item><title>Decision Theoretic Foundations for Experiments Evaluating Human Decisions</title><link>http://arxiv.org/abs/2401.15106v2</link><description>Decision-making with information displays is a key focus of research in areaslike explainable AI, human-AI teaming, and data visualization. However, whatconstitutes a decision problem, and what is required for an experiment to becapable of concluding that human decisions are flawed in some way, remain opento speculation. We present a widely applicable definition of a decision problemsynthesized from statistical decision theory and information economics. Weargue that to attribute loss in human performance to forms of bias, anexperiment must provide participants with the information that a rational agentwould need to identify the normative decision. We evaluate the extent to whichrecent evaluations of decision-making from the literature on AI-assisteddecisions achieve this criteria. We find that only 10 (26\%) of 39 studies thatclaim to identify biased behavior present participants with sufficientinformation to characterize their behavior as deviating from gooddecision-making in at least one treatment condition. We motivate the value ofstudying well-defined decision problems by describing a characterization ofperformance losses they allow us to conceive. In contrast, the ambiguities of apoorly communicated decision problem preclude normative interpretation. Weconclude with recommendations for practice.</description><author>Jessica Hullman, Alex Kale, Jason Hartline</author><pubDate>Thu, 15 Feb 2024 16:51:16 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.15106v2</guid></item><item><title>Classification Diffusion Models</title><link>http://arxiv.org/abs/2402.10095v1</link><description>A prominent family of methods for learning data distributions relies ondensity ratio estimation (DRE), where a model is trained to $\textit{classify}$between data samples and samples from some reference distribution. Thesetechniques are successful in simple low-dimensional settings but fail toachieve good results on complex high-dimensional data, like images. A differentfamily of methods for learning distributions is that of denoising diffusionmodels (DDMs), in which a model is trained to $\textit{denoise}$ data samples.These approaches achieve state-of-the-art results in image, video, and audiogeneration. In this work, we present $\textit{Classification Diffusion Models}$(CDMs), a generative technique that adopts the denoising-based formalism ofDDMs while making use of a classifier that predicts the amount of noise addedto a clean signal, similarly to DRE methods. Our approach is based on theobservation that an MSE-optimal denoiser for white Gaussian noise can beexpressed in terms of the gradient of a cross-entropy-optimal classifier forpredicting the noise level. As we illustrate, CDM achieves better denoisingresults compared to DDM, and leads to at least comparable FID in imagegeneration. CDM is also capable of highly efficient one-step exact likelihoodestimation, achieving state-of-the-art results among methods that use a singlestep. Code is available on the project's webpage inhttps://shaharYadin.github.io/CDM/ .</description><author>Shahar Yadin, Noam Elata, Tomer Michaeli</author><pubDate>Thu, 15 Feb 2024 16:49:42 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.10095v1</guid></item><item><title>Stabilized Neural Differential Equations for Learning Dynamics with Explicit Constraints</title><link>http://arxiv.org/abs/2306.09739v3</link><description>Many successful methods to learn dynamical systems from data have recentlybeen introduced. However, ensuring that the inferred dynamics preserve knownconstraints, such as conservation laws or restrictions on the allowed systemstates, remains challenging. We propose stabilized neural differentialequations (SNDEs), a method to enforce arbitrary manifold constraints forneural differential equations. Our approach is based on a stabilization termthat, when added to the original dynamics, renders the constraint manifoldprovably asymptotically stable. Due to its simplicity, our method is compatiblewith all common neural differential equation (NDE) models and broadlyapplicable. In extensive empirical evaluations, we demonstrate that SNDEsoutperform existing methods while broadening the types of constraints that canbe incorporated into NDE training.</description><author>Alistair White, Niki Kilbertus, Maximilian Gelbrecht, Niklas Boers</author><pubDate>Thu, 15 Feb 2024 16:47:31 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.09739v3</guid></item><item><title>MIM-Refiner: A Contrastive Learning Boost from Intermediate Pre-Trained Representations</title><link>http://arxiv.org/abs/2402.10093v1</link><description>We introduce MIM (Masked Image Modeling)-Refiner, a contrastive learningboost for pre-trained MIM models. The motivation behind MIM-Refiner is rootedin the insight that optimal representations within MIM models generally residein intermediate layers. Accordingly, MIM-Refiner leverages multiple contrastiveheads that are connected to diverse intermediate layers. In each head, amodified nearest neighbor objective helps to construct respective semanticclusters. The refinement process is short but effective. Within a few epochs, we refinethe features of MIM models from subpar to state-of-the-art, off-the-shelffeatures. Refining a ViT-H, pre-trained with data2vec 2.0 on ImageNet-1K,achieves new state-of-the-art results in linear probing (84.7%) and low-shotclassification among models that are pre-trained on ImageNet-1K. In ImageNet-1K1-shot classification, MIM-Refiner sets a new state-of-the-art of 64.2%,outperforming larger models that were trained on up to 2000x more data such asDINOv2-g, OpenCLIP-G and MAWS-6.5B. Project page:https://ml-jku.github.io/MIM-Refiner</description><author>Benedikt Alkin, Lukas Miklautz, Sepp Hochreiter, Johannes Brandstetter</author><pubDate>Thu, 15 Feb 2024 16:46:16 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.10093v1</guid></item><item><title>Fine-tuning Large Language Model (LLM) Artificial Intelligence Chatbots in Ophthalmology and LLM-based evaluation using GPT-4</title><link>http://arxiv.org/abs/2402.10083v1</link><description>Purpose: To assess the alignment of GPT-4-based evaluation to human clinicianexperts, for the evaluation of responses to ophthalmology-related patientqueries generated by fine-tuned LLM chatbots. Methods: 400 ophthalmologyquestions and paired answers were created by ophthalmologists to representcommonly asked patient questions, divided into fine-tuning (368; 92%), andtesting (40; 8%). We find-tuned 5 different LLMs, including LLAMA2-7b,LLAMA2-7b-Chat, LLAMA2-13b, and LLAMA2-13b-Chat. For the testing dataset,additional 8 glaucoma QnA pairs were included. 200 responses to the testingdataset were generated by 5 fine-tuned LLMs for evaluation. A customizedclinical evaluation rubric was used to guide GPT-4 evaluation, grounded onclinical accuracy, relevance, patient safety, and ease of understanding. GPT-4evaluation was then compared against ranking by 5 clinicians for clinicalalignment. Results: Among all fine-tuned LLMs, GPT-3.5 scored the highest(87.1%), followed by LLAMA2-13b (80.9%), LLAMA2-13b-chat (75.5%),LLAMA2-7b-Chat (70%) and LLAMA2-7b (68.8%) based on the GPT-4 evaluation. GPT-4evaluation demonstrated significant agreement with human clinician rankings,with Spearman and Kendall Tau correlation coefficients of 0.90 and 0.80respectively; while correlation based on Cohen Kappa was more modest at 0.50.Notably, qualitative analysis and the glaucoma sub-analysis revealed clinicalinaccuracies in the LLM-generated responses, which were appropriatelyidentified by the GPT-4 evaluation. Conclusion: The notable clinical alignmentof GPT-4 evaluation highlighted its potential to streamline the clinicalevaluation of LLM chatbot responses to healthcare-related queries. Bycomplementing the existing clinician-dependent manual grading, this efficientand automated evaluation could assist the validation of future developments inLLM applications for healthcare.</description><author>Ting Fang Tan, Kabilan Elangovan, Liyuan Jin, Yao Jie, Li Yong, Joshua Lim, Stanley Poh, Wei Yan Ng, Daniel Lim, Yuhe Ke, Nan Liu, Daniel Shu Wei Ting</author><pubDate>Thu, 15 Feb 2024 16:43:41 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.10083v1</guid></item><item><title>FedRDF: A Robust and Dynamic Aggregation Function against Poisoning Attacks in Federated Learning</title><link>http://arxiv.org/abs/2402.10082v1</link><description>Federated Learning (FL) represents a promising approach to typical privacyconcerns associated with centralized Machine Learning (ML) deployments. Despiteits well-known advantages, FL is vulnerable to security attacks such asByzantine behaviors and poisoning attacks, which can significantly degrademodel performance and hinder convergence. The effectiveness of existingapproaches to mitigate complex attacks, such as median, trimmed mean, or Krumaggregation functions, has been only partially demonstrated in the case ofspecific attacks. Our study introduces a novel robust aggregation mechanismutilizing the Fourier Transform (FT), which is able to effectively handlingsophisticated attacks without prior knowledge of the number of attackers.Employing this data technique, weights generated by FL clients are projectedinto the frequency domain to ascertain their density function, selecting theone exhibiting the highest frequency. Consequently, malicious clients' weightsare excluded. Our proposed approach was tested against various model poisoningattacks, demonstrating superior performance over state-of-the-art aggregationmethods.</description><author>Enrique Mármol Campos, Aurora González Vidal, José Luis Hernández Ramos, Antonio Skarmeta</author><pubDate>Thu, 15 Feb 2024 16:42:04 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.10082v1</guid></item><item><title>Identifiability of Direct Effects from Summary Causal Graphs</title><link>http://arxiv.org/abs/2306.16958v4</link><description>Dynamic structural causal models (SCMs) are a powerful framework forreasoning in dynamic systems about direct effects which measure how a change inone variable affects another variable while holding all other variablesconstant. The causal relations in a dynamic structural causal model can bequalitatively represented with an acyclic full-time causal graph. Assuminglinearity and no hidden confounding and given the full-time causal graph, thedirect causal effect is always identifiable. However, in many application sucha graph is not available for various reasons but nevertheless experts haveaccess to the summary causal graph of the full-time causal graph whichrepresents causal relations between time series while omitting temporalinformation and allowing cycles. This paper presents a complete identifiabilityresult which characterizes all cases for which the direct effect is graphicallyidentifiable from a summary causal graph and gives two sound finite adjustmentsets that can be used to estimate the direct effect whenever it isidentifiable.</description><author>Simon Ferreira, Charles K. Assaad</author><pubDate>Thu, 15 Feb 2024 16:42:00 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.16958v4</guid></item><item><title>Forecasting Response to Treatment with Global Deep Learning and Patient-Specific Pharmacokinetic Priors</title><link>http://arxiv.org/abs/2309.13135v6</link><description>Forecasting healthcare time series is crucial for early detection of adverseoutcomes and for patient monitoring. Forecasting, however, can be difficult inpractice due to noisy and intermittent data. The challenges are oftenexacerbated by change points induced via extrinsic factors, such as theadministration of medication. To address these challenges, we propose a novelhybrid global-local architecture and a pharmacokinetic encoder that informsdeep learning models of patient-specific treatment effects. We showcase theefficacy of our approach in achieving significant accuracy gains for a bloodglucose forecasting task using both realistically simulated and real-worlddata. Our global-local architecture improves over patient-specific models by9.2-14.6%. Additionally, our pharmacokinetic encoder improves over alternativeencoding techniques by 4.4% on simulated data and 2.1% on real-world data. Theproposed approach can have multiple beneficial applications in clinicalpractice, such as issuing early warnings about unexpected treatment responses,or helping to characterize patient-specific treatment effects in terms of drugabsorption and elimination characteristics.</description><author>Willa Potosnak, Cristian Challu, Kin G. Olivares, Artur Dubrawski</author><pubDate>Thu, 15 Feb 2024 16:41:09 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2309.13135v6</guid></item><item><title>InstructBooth: Instruction-following Personalized Text-to-Image Generation</title><link>http://arxiv.org/abs/2312.03011v2</link><description>Personalizing text-to-image models using a limited set of images for aspecific object has been explored in subject-specific image generation.However, existing methods often face challenges in aligning with text promptsdue to overfitting to the limited training images. In this work, we introduceInstructBooth, a novel method designed to enhance image-text alignment inpersonalized text-to-image models without sacrificing the personalizationability. Our approach first personalizes text-to-image models with a smallnumber of subject-specific images using a unique identifier. Afterpersonalization, we fine-tune personalized text-to-image models usingreinforcement learning to maximize a reward that quantifies image-textalignment. Additionally, we propose complementary techniques to increase thesynergy between these two processes. Our method demonstrates superiorimage-text alignment compared to existing baselines, while maintaining highpersonalization ability. In human evaluations, InstructBooth outperforms themwhen considering all comprehensive factors. Our project page is athttps://sites.google.com/view/instructbooth.</description><author>Daewon Chae, Nokyung Park, Jinkyu Kim, Kimin Lee</author><pubDate>Thu, 15 Feb 2024 16:38:46 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.03011v2</guid></item><item><title>QUICK: Quantization-aware Interleaving and Conflict-free Kernel for efficient LLM inference</title><link>http://arxiv.org/abs/2402.10076v1</link><description>We introduce QUICK, a group of novel optimized CUDA kernels for the efficientinference of quantized Large Language Models (LLMs). QUICK addresses the sharedmemory bank-conflict problem of state-of-the-art mixed precision matrixmultiplication kernels. Our method interleaves the quantized weight matrices ofLLMs offline to skip the shared memory write-back after the dequantization. Wedemonstrate up to 1.91x speedup over existing kernels of AutoAWQ on largerbatches and up to 1.94x throughput gain on representative LLM models on variousNVIDIA GPU devices.</description><author>Taesu Kim, Jongho Lee, Daehyun Ahn, Sarang Kim, Jiwoong Choi, Minkyu Kim, Hyungjun Kim</author><pubDate>Thu, 15 Feb 2024 16:38:41 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.10076v1</guid></item><item><title>On Designing Features for Condition Monitoring of Rotating Machines</title><link>http://arxiv.org/abs/2402.09957v1</link><description>Various methods for designing input features have been proposed for faultrecognition in rotating machines using one-dimensional raw sensor data. Theavailable methods are complex, rely on empirical approaches, and may differdepending on the condition monitoring data used. Therefore, this articleproposes a novel algorithm to design input features that unifies the featureextraction process for different time-series sensor data. This new insight fordesigning/extracting input features is obtained through the lens of histogramtheory. The proposed algorithm extracts discriminative input features, whichare suitable for a simple classifier to deep neural network-based classifiers.The designed input features are given as input to the classifier withend-to-end training in a single framework for machine conditions recognition.The proposed scheme has been validated through three real-time datasets: a)acoustic dataset, b) CWRU vibration dataset, and c) IMS vibration dataset. Thereal-time results and comparative study show the effectiveness of the proposedscheme for the prediction of the machine's health states.</description><author>Seetaram Maurya, Nishchal K. Verma</author><pubDate>Thu, 15 Feb 2024 14:08:08 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.09957v1</guid></item><item><title>GraphCBAL: Class-Balanced Active Learning for Graph Neural Networks via Reinforcement Learning</title><link>http://arxiv.org/abs/2402.10074v1</link><description>Graph neural networks (GNNs) have recently demonstrated significant success.Active learning for GNNs aims to query the valuable samples from the unlabeleddata for annotation to maximize the GNNs' performance at a low cost. However,most existing methods for reinforced active learning in GNNs may lead to ahighly imbalanced class distribution, especially in highly skewed classscenarios. This further adversely affects the classification performance. Totackle this issue, in this paper, we propose a novel reinforced class-balancedactive learning framework for GNNs, namely, GraphCBAL. It learns an optimalpolicy to acquire class-balanced and informative nodes for annotation,maximizing the performance of GNNs trained with selected labeled nodes.GraphCBAL designs class-balance-aware states, as well as a reward function thatachieves trade-off between model performance and class balance. We furtherupgrade GraphCBAL to GraphCBAL++ by introducing a punishment mechanism toobtain a more class-balanced labeled set. Extensive experiments on multipledatasets demonstrate the effectiveness of the proposed approaches, achievingsuperior performance over state-of-the-art baselines. In particular, ourmethods can strike the balance between classification results and classbalance.</description><author>Chengcheng Yu, Jiapeng Zhu, Xiang Li</author><pubDate>Thu, 15 Feb 2024 16:37:14 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.10074v1</guid></item><item><title>Both Matter: Enhancing the Emotional Intelligence of Large Language Models without Compromising the General Intelligence</title><link>http://arxiv.org/abs/2402.10073v1</link><description>Emotional Intelligence (EI), consisting of emotion perception, emotioncognition and emotion expression, plays the critical roles in improving userinteraction experience for the current large language model (LLM) basedconversational general AI assistants. Previous works mainly focus on raisingthe emotion perception ability of them via naive fine-tuning on EI-relatedclassification or regression tasks. However, this leads to the incompleteenhancement of EI and catastrophic forgetting of the general intelligence (GI).To this end, we first introduce \textsc{EiBench}, a large-scale collection ofEI-related tasks in the text-to-text formation with task instructions thatcovers all three aspects of EI, which lays a solid foundation for thecomprehensive EI enhancement of LLMs. Then a novel \underline{\textbf{Mo}}dular\underline{\textbf{E}}motional \underline{\textbf{I}}ntelligence enhancementmethod (\textbf{MoEI}), consisting of Modular Parameter Expansion andintra-inter modulation, is proposed to comprehensively enhance the EI of LLMswithout compromise their GI. Extensive experiments on two representativeLLM-based assistants, Flan-T5 and LLaMA-2-Chat, demonstrate the effectivenessof MoEI to improving EI while maintain GI.</description><author>Weixiang Zhao, Zhuojun Li, Shilong Wang, Yang Wang, Yulin Hu, Yanyan Zhao, Chen Wei, Bing Qin</author><pubDate>Thu, 15 Feb 2024 16:36:04 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.10073v1</guid></item><item><title>NYCTALE: Neuro-Evidence Transformer for Adaptive and Personalized Lung Nodule Invasiveness Prediction</title><link>http://arxiv.org/abs/2402.10066v1</link><description>Drawing inspiration from the primate brain's intriguing evidence accumulationprocess, and guided by models from cognitive psychology and neuroscience, thepaper introduces the NYCTALE framework, a neuro-inspired and evidenceaccumulation-based Transformer architecture. The proposed neuro-inspiredNYCTALE offers a novel pathway in the domain of Personalized Medicine (PM) forlung cancer diagnosis. In nature, Nyctales are small owls known for theirnocturnal behavior, hunting primarily during the darkness of night. The NYCTALEoperates in a similarly vigilant manner, i.e., processing data in anevidence-based fashion and making predictions dynamically/adaptively. Distinctfrom conventional Computed Tomography (CT)-based Deep Learning (DL) models, theNYCTALE performs predictions only when sufficient amount of evidence isaccumulated. In other words, instead of processing all or a pre-defined subsetof CT slices, for each person, slices are provided one at a time. The NYCTALEframework then computes an evidence vector associated with contribution of eachnew CT image. A decision is made once the total accumulated evidence surpassesa specific threshold. Preliminary experimental analyses conducted using achallenging in-house dataset comprising 114 subjects. The results arenoteworthy, suggesting that NYCTALE outperforms the benchmark accuracy evenwith approximately 60% less training data on this demanding and small dataset.</description><author>Sadaf Khademi, Anastasia Oikonomou, Konstantinos N. Plataniotis, Arash Mohammadi</author><pubDate>Thu, 15 Feb 2024 16:31:54 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.10066v1</guid></item><item><title>How Much Does Each Datapoint Leak Your Privacy? Quantifying the Per-datum Membership Leakage</title><link>http://arxiv.org/abs/2402.10065v1</link><description>We study the per-datum Membership Inference Attacks (MIAs), where an attackeraims to infer whether a fixed target datum has been included in the inputdataset of an algorithm and thus, violates privacy. First, we define themembership leakage of a datum as the advantage of the optimal adversarytargeting to identify it. Then, we quantify the per-datum membership leakagefor the empirical mean, and show that it depends on the Mahalanobis distancebetween the target datum and the data-generating distribution. We furtherassess the effect of two privacy defences, i.e. adding Gaussian noise andsub-sampling. We quantify exactly how both of them decrease the per-datummembership leakage. Our analysis builds on a novel proof technique thatcombines an Edgeworth expansion of the likelihood ratio test and aLindeberg-Feller central limit theorem. Our analysis connects the existinglikelihood ratio and scalar product attacks, and also justifies differentcanary selection strategies used in the privacy auditing literature. Finally,our experiments demonstrate the impacts of the leakage score, the sub-samplingratio and the noise scale on the per-datum membership leakage as indicated bythe theory.</description><author>Achraf Azize, Debabrota Basu</author><pubDate>Thu, 15 Feb 2024 16:30:55 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.10065v1</guid></item><item><title>Balancing the Causal Effects in Class-Incremental Learning</title><link>http://arxiv.org/abs/2402.10063v1</link><description>Class-Incremental Learning (CIL) is a practical and challenging problem forachieving general artificial intelligence. Recently, Pre-Trained Models (PTMs)have led to breakthroughs in both visual and natural language processing tasks.Despite recent studies showing PTMs' potential ability to learn sequentially, aplethora of work indicates the necessity of alleviating the catastrophicforgetting of PTMs. Through a pilot study and a causal analysis of CIL, wereveal that the crux lies in the imbalanced causal effects between new and olddata. Specifically, the new data encourage models to adapt to new classes whilehindering the adaptation of old classes. Similarly, the old data encouragesmodels to adapt to old classes while hindering the adaptation of new classes.In other words, the adaptation process between new and old classes conflictsfrom the causal perspective. To alleviate this problem, we propose Balancingthe Causal Effects (BaCE) in CIL. Concretely, BaCE proposes two objectives forbuilding causal paths from both new and old data to the prediction of new andclasses, respectively. In this way, the model is encouraged to adapt to allclasses with causal effects from both new and old data and thus alleviates thecausal imbalance problem. We conduct extensive experiments on continual imageclassification, continual text classification, and continual named entityrecognition. Empirical results show that BaCE outperforms a series of CILmethods on different tasks and settings.</description><author>Junhao Zheng, Ruiyan Wang, Chongzhi Zhang, Huawen Feng, Qianli Ma</author><pubDate>Thu, 15 Feb 2024 16:30:45 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.10063v1</guid></item><item><title>EcoVal: An Efficient Data Valuation Framework for Machine Learning</title><link>http://arxiv.org/abs/2402.09288v2</link><description>Quantifying the value of data within a machine learning workflow can play apivotal role in making more strategic decisions in machine learninginitiatives. The existing Shapley value based frameworks for data valuation inmachine learning are computationally expensive as they require considerableamount of repeated training of the model to obtain the Shapley value. In thispaper, we introduce an efficient data valuation framework EcoVal, to estimatethe value of data for machine learning models in a fast and practical manner.Instead of directly working with individual data sample, we determine the valueof a cluster of similar data points. This value is further propagated amongstall the member cluster points. We show that the overall data value can bedetermined by estimating the intrinsic and extrinsic value of each data. Thisis enabled by formulating the performance of a model as a \textit{productionfunction}, a concept which is popularly used to estimate the amount of outputbased on factors like labor and capital in a traditional free economic market.We provide a formal proof of our valuation technique and elucidate theprinciples and mechanisms that enable its accelerated performance. Wedemonstrate the real-world applicability of our method by showcasing itseffectiveness for both in-distribution and out-of-sample data. This workaddresses one of the core challenges of efficient data valuation at scale inmachine learning models.</description><author>Ayush K Tarun, Vikram S Chundawat, Murari Mandal, Hong Ming Tan, Bowei Chen, Mohan Kankanhalli</author><pubDate>Thu, 15 Feb 2024 16:30:12 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.09288v2</guid></item><item><title>X-maps: Direct Depth Lookup for Event-based Structured Light Systems</title><link>http://arxiv.org/abs/2402.10061v1</link><description>We present a new approach to direct depth estimation for Spatial AugmentedReality (SAR) applications using event cameras. These dynamic vision sensorsare a great fit to be paired with laser projectors for depth estimation in astructured light approach. Our key contributions involve a conversion of theprojector time map into a rectified X-map, capturing x-axis correspondences forincoming events and enabling direct disparity lookup without any additionalsearch. Compared to previous implementations, this significantly simplifiesdepth estimation, making it more efficient, while the accuracy is similar tothe time map-based process. Moreover, we compensate non-linear temporalbehavior of cheap laser projectors by a simple time map calibration, resultingin improved performance and increased depth estimation accuracy. Since depthestimation is executed by two lookups only, it can be executed almost instantly(less than 3 ms per frame with a Python implementation) for incoming events.This allows for real-time interactivity and responsiveness, which makes ourapproach especially suitable for SAR experiences where low latency, high framerates and direct feedback are crucial. We present valuable insights gained intodata transformed into X-maps and evaluate our depth from disparity estimationagainst the state of the art time map-based results. Additional results andcode are available on our project page: https://fraunhoferhhi.github.io/X-maps/</description><author>Wieland Morgenstern, Niklas Gard, Simon Baumann, Anna Hilsmann, Peter Eisert</author><pubDate>Thu, 15 Feb 2024 16:29:46 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.10061v1</guid></item><item><title>Empirical Comparison between Cross-Validation and Mutation-Validation in Model Selection</title><link>http://arxiv.org/abs/2311.14079v2</link><description>Mutation validation (MV) is a recently proposed approach for model selection,garnering significant interest due to its unique characteristics and potentialbenefits compared to the widely used cross-validation (CV) method. In thisstudy, we empirically compared MV and $k$-fold CV using benchmark andreal-world datasets. By employing Bayesian tests, we compared generalizationestimates yielding three posterior probabilities: practical equivalence, CVsuperiority, and MV superiority. We also evaluated the differences in thecapacity of the selected models and computational efficiency. We found thatboth MV and CV select models with practically equivalent generalizationperformance across various machine learning algorithms and the majority ofbenchmark datasets. MV exhibited advantages in terms of selecting simplermodels and lower computational costs. However, in some cases MV selected overlysimplistic models leading to underfitting and showed instability inhyperparameter selection. These limitations of MV became more evident in theevaluation of a real-world neuroscientific task of predicting sex at birthusing brain functional connectivity.</description><author>Jinyang Yu, Sami Hamdan, Leonard Sasse, Abigail Morrison, Kaustubh R. Patil</author><pubDate>Thu, 15 Feb 2024 16:28:57 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.14079v2</guid></item><item><title>Towards Safer Large Language Models through Machine Unlearning</title><link>http://arxiv.org/abs/2402.10058v1</link><description>The rapid advancement of Large Language Models (LLMs) has demonstrated theirvast potential across various domains, attributed to their extensivepretraining knowledge and exceptional generalizability. However, LLMs oftenencounter challenges in generating harmful content when faced with problematicprompts. To address this problem, existing work attempted to implement agradient ascent based approach to prevent LLMs from producing harmful output.While these methods can be effective, they frequently impact the model utilityin responding to normal prompts. To address this gap, we introduce SelectiveKnowledge negation Unlearning (SKU), a novel unlearning framework for LLMs,designed to eliminate harmful knowledge while preserving utility on normalprompts. Specifically, SKU is consisted of two stages: harmful knowledgeacquisition stage and knowledge negation stage. The first stage aims toidentify and acquire harmful knowledge within the model, whereas the second isdedicated to remove this knowledge. SKU selectively isolates and removesharmful knowledge in model parameters, ensuring the model's performance remainsrobust on normal prompts. Our experiments conducted across various LLMarchitectures demonstrate that SKU identifies a good balance point betweenremoving harmful information and preserving utility.</description><author>Zheyuan Liu, Guangyao Dou, Zhaoxuan Tan, Yijun Tian, Meng Jiang</author><pubDate>Thu, 15 Feb 2024 16:28:34 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.10058v1</guid></item><item><title>Robust semi-automatic vessel tracing in the human retinal image by an instance segmentation neural network</title><link>http://arxiv.org/abs/2402.10055v1</link><description>The morphology and hierarchy of the vascular systems are essential forperfusion in supporting metabolism. In human retina, one of the mostenergy-demanding organs, retinal circulation nourishes the entire inner retinaby an intricate vasculature emerging and remerging at the optic nerve head(ONH). Thus, tracing the vascular branching from ONH through the vascular treecan illustrate vascular hierarchy and allow detailed morphologicalquantification, and yet remains a challenging task. Here, we presented a novelapproach for a robust semi-automatic vessel tracing algorithm on human fundusimages by an instance segmentation neural network (InSegNN). Distinct fromsemantic segmentation, InSegNN separates and labels different vascular treesindividually and therefore enable tracing each tree throughout its branching.We have built-in three strategies to improve robustness and accuracy withtemporal learning, spatial multi-sampling, and dynamic probability map. Weachieved 83% specificity, and 50% improvement in Symmetric Best Dice (SBD)compared to literature, and outperformed baseline U-net. We have demonstratedtracing individual vessel trees from fundus images, and simultaneously retainthe vessel hierarchy information. InSegNN paves a way for any subsequentmorphological analysis of vascular morphology in relation to retinal diseases.</description><author>Siyi Chen, Amir H. Kashani, Ji Yi</author><pubDate>Thu, 15 Feb 2024 16:25:28 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.10055v1</guid></item><item><title>Unmemorization in Large Language Models via Self-Distillation and Deliberate Imagination</title><link>http://arxiv.org/abs/2402.10052v1</link><description>While displaying impressive generation capabilities across many tasks, LargeLanguage Models (LLMs) still struggle with crucial issues of privacy violationand unwanted exposure of sensitive data. This raises an essential question: howshould we prevent such undesired behavior of LLMs while maintaining theirstrong generation and natural language understanding (NLU) capabilities? Inthis work, we introduce a novel approach termed deliberate imagination in thecontext of LLM unlearning. Instead of trying to forget memorized data, weemploy a self-distillation framework, guiding LLMs to deliberately imaginealternative scenarios. As demonstrated in a wide range of experiments, theproposed method not only effectively unlearns targeted text but also preservesthe LLMs' capabilities in open-ended generation tasks as well as in NLU tasks.Our results demonstrate the usefulness of this approach across different modelsand sizes, and also with parameter-efficient fine-tuning, offering a novelpathway to addressing the challenges with private and sensitive data in LLMapplications.</description><author>Yijiang River Dong, Hongzhou Lin, Mikhail Belkin, Ramon Huerta, Ivan Vulić</author><pubDate>Thu, 15 Feb 2024 16:21:14 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.10052v1</guid></item><item><title>Protect Your Score: Contact Tracing With Differential Privacy Guarantees</title><link>http://arxiv.org/abs/2312.11581v2</link><description>The pandemic in 2020 and 2021 had enormous economic and societalconsequences, and studies show that contact tracing algorithms can be key inthe early containment of the virus. While large strides have been made towardsmore effective contact tracing algorithms, we argue that privacy concernscurrently hold deployment back. The essence of a contact tracing algorithmconstitutes the communication of a risk score. Yet, it is precisely thecommunication and release of this score to a user that an adversary canleverage to gauge the private health status of an individual. We pinpoint arealistic attack scenario and propose a contact tracing algorithm withdifferential privacy guarantees against this attack. The algorithm is tested onthe two most widely used agent-based COVID19 simulators and demonstratessuperior performance in a wide range of settings. Especially for realistic testscenarios and while releasing each risk score with epsilon=1 differentialprivacy, we achieve a two to ten-fold reduction in the infection rate of thevirus. To the best of our knowledge, this presents the first contact tracingalgorithm with differential privacy guarantees when revealing risk scores forCOVID19.</description><author>Rob Romijnders, Christos Louizos, Yuki M. Asano, Max Welling</author><pubDate>Thu, 15 Feb 2024 16:21:11 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.11581v2</guid></item><item><title>Moderating Model Marketplaces: Platform Governance Puzzles for AI Intermediaries</title><link>http://arxiv.org/abs/2311.12573v2</link><description>The AI development community is increasingly making use of hostingintermediaries such as Hugging Face provide easy access to user-uploaded modelsand training data. These model marketplaces lower technical deployment barriersfor hundreds of thousands of users, yet can be used in numerous potentiallyharmful and illegal ways. In this article, we explain ways in which AI systems,which can both `contain' content and be open-ended tools, present one of thetrickiest platform governance challenges seen to date. We provide case studiesof several incidents across three illustrative platforms -- Hugging Face,GitHub and Civitai -- to examine how model marketplaces moderate models.Building on this analysis, we outline important (and yet nevertheless limited)practices that industry has been developing to respond to moderation demands:licensing, access and use restrictions, automated content moderation, and openpolicy development. While the policy challenge at hand is a considerable one,we conclude with some ideas as to how platforms could better mobilize resourcesto act as a careful, fair, and proportionate regulatory access point.</description><author>Robert Gorwa, Michael Veale</author><pubDate>Thu, 15 Feb 2024 16:19:33 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.12573v2</guid></item><item><title>A Latent Space Correlation-Aware Autoencoder for Anomaly Detection in Skewed Data</title><link>http://arxiv.org/abs/2301.00462v3</link><description>Unsupervised learning-based anomaly detection in latent space has gainedimportance since discriminating anomalies from normal data becomes difficult inhigh-dimensional space. Both density estimation and distance-based methods todetect anomalies in latent space have been explored in the past. These methodsprove that retaining valuable properties of input data in latent space helps inthe better reconstruction of test data. Moreover, real-world sensor data isskewed and non-Gaussian in nature, making mean-based estimators unreliable forskewed data. Again, anomaly detection methods based on reconstruction errorrely on Euclidean distance, which does not consider useful correlationinformation in the feature space and also fails to accurately reconstruct thedata when it deviates from the training distribution. In this work, we addressthe limitations of reconstruction error-based autoencoders and propose akernelized autoencoder that leverages a robust form of Mahalanobis distance(MD) to measure latent dimension correlation to effectively detect both nearand far anomalies. This hybrid loss is aided by the principle of maximizing themutual information gain between the latent dimension and the high-dimensionalprior data space by maximizing the entropy of the latent space while preservinguseful correlation information of the original data in the low-dimensionallatent space. The multi-objective function has two goals -- it measurescorrelation information in the latent feature space in the form of robust MDdistance and simultaneously tries to preserve useful correlation informationfrom the original data space in the latent space by maximizing mutualinformation between the prior and latent space.</description><author>Padmaksha Roy</author><pubDate>Thu, 15 Feb 2024 16:18:32 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2301.00462v3</guid></item><item><title>DistriBlock: Identifying adversarial audio samples by leveraging characteristics of the output distribution</title><link>http://arxiv.org/abs/2305.17000v2</link><description>Adversarial attacks can mislead automatic speech recognition (ASR) systemsinto predicting an arbitrary target text, thus posing a clear security threat.To prevent such attacks, we propose DistriBlock, an efficient detectionstrategy applicable to any ASR system that predicts a probability distributionover output tokens in each time step. We measure a set of characteristics ofthis distribution: the median, maximum, and minimum over the outputprobabilities, the entropy of the distribution, as well as the Kullback-Leiblerand the Jensen-Shannon divergence with respect to the distributions of thesubsequent time step. Then, by leveraging the characteristics observed for bothbenign and adversarial data, we apply binary classifiers, including simplethreshold-based classification, ensembles of such classifiers, and neuralnetworks. Through extensive analysis across different state-of-the-art ASRsystems and language data sets, we demonstrate the supreme performance of thisapproach, with a mean area under the receiver operating characteristic fordistinguishing target adversarial examples against clean and noisy data of 99\%and 97\%, respectively. To assess the robustness of our method, we show thatadaptive adversarial examples that can circumvent DistriBlock are much noisier,which makes them easier to detect through filtering and creates another avenuefor preserving the system's robustness.</description><author>Matías P. Pizarro B., Dorothea Kolossa, Asja Fischer</author><pubDate>Thu, 15 Feb 2024 16:18:29 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.17000v2</guid></item><item><title>SwissNYF: Tool Grounded LLM Agents for Black Box Setting</title><link>http://arxiv.org/abs/2402.10051v1</link><description>While Large Language Models (LLMs) have demonstrated enhanced capabilities infunction-calling, these advancements primarily rely on accessing the functions'responses. This methodology is practical for simpler APIs but faces scalabilityissues with irreversible APIs that significantly impact the system, such as adatabase deletion API. Similarly, processes requiring extensive time for eachAPI call and those necessitating forward planning, like automated actionpipelines, present complex challenges. Furthermore, scenarios often arise wherea generalized approach is needed because algorithms lack direct access to thespecific implementations of these functions or secrets to use them. Traditionaltool planning methods are inadequate in these cases, compelling the need tooperate within black-box environments. Unlike their performance in toolmanipulation, LLMs excel in black-box tasks, such as program synthesis.Therefore, we harness the program synthesis capabilities of LLMs to strategizetool usage in black-box settings, ensuring solutions are verified prior toimplementation. We introduce TOPGUN, an ingeniously crafted approach leveragingprogram synthesis for black box tool planning. Accompanied by SwissNYF, acomprehensive suite that integrates black-box algorithms for planning andverification tasks, addressing the aforementioned challenges and enhancing theversatility and effectiveness of LLMs in complex API interactions. The publiccode for SwissNYF is available at https://github.com/iclr-dummy-user/SwissNYF.</description><author>Somnath Sendhil Kumar, Dhruv Jain, Eshaan Agarwal, Raunak Pandey</author><pubDate>Thu, 15 Feb 2024 16:15:38 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.10051v1</guid></item><item><title>SemRel2024: A Collection of Semantic Textual Relatedness Datasets for 14 Languages</title><link>http://arxiv.org/abs/2402.08638v3</link><description>Exploring and quantifying semantic relatedness is central to representinglanguage. It holds significant implications across various NLP tasks, includingoffering insights into the capabilities and performance of Large LanguageModels (LLMs). While earlier NLP research primarily focused on semanticsimilarity, often within the English language context, we instead investigatethe broader phenomenon of semantic relatedness. In this paper, we presentSemRel, a new semantic relatedness dataset collection annotated by nativespeakers across 14 languages:Afrikaans, Algerian Arabic, Amharic, English,Hausa, Hindi, Indonesian, Kinyarwanda, Marathi, Moroccan Arabic, ModernStandard Arabic, Punjabi, Spanish, and Telugu. These languages originate fromfive distinct language families and are predominantly spoken in Africa and Asia-- regions characterised by a relatively limited availability of NLP resources.Each instance in the SemRel datasets is a sentence pair associated with a scorethat represents the degree of semantic textual relatedness between the twosentences. The scores are obtained using a comparative annotation framework. Wedescribe the data collection and annotation processes, related challenges whenbuilding the datasets, and their impact and utility in NLP. We further reportexperiments for each language and across the different languages.</description><author>Nedjma Ousidhoum, Shamsuddeen Hassan Muhammad, Mohamed Abdalla, Idris Abdulmumin, Ibrahim Said Ahmad, Sanchit Ahuja, Alham Fikri Aji, Vladimir Araujo, Abinew Ali Ayele, Pavan Baswani, Meriem Beloucif, Chris Biemann, Sofia Bourhim, Christine De Kock, Genet Shanko Dekebo, Oumaima Hourrane, Gopichand Kanumolu, Lokesh Madasu, Samuel Rutunda, Manish Shrivastava, Thamar Solorio, Nirmal Surange, Hailegnaw Getaneh Tilaye, Krishnapriya Vishnubhotla, Genta Winata, Seid Muhie Yimam, Saif M. Mohammad</author><pubDate>Thu, 15 Feb 2024 16:15:01 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.08638v3</guid></item><item><title>Hierarchical State Space Models for Continuous Sequence-to-Sequence Modeling</title><link>http://arxiv.org/abs/2402.10211v1</link><description>Reasoning from sequences of raw sensory data is a ubiquitous problem acrossfields ranging from medical devices to robotics. These problems often involveusing long sequences of raw sensor data (e.g. magnetometers, piezoresistors) topredict sequences of desirable physical quantities (e.g. force, inertialmeasurements). While classical approaches are powerful for locally-linearprediction problems, they often fall short when using real-world sensors. Thesesensors are typically non-linear, are affected by extraneous variables (e.g.vibration), and exhibit data-dependent drift. For many problems, the predictiontask is exacerbated by small labeled datasets since obtaining ground-truthlabels requires expensive equipment. In this work, we present HierarchicalState-Space Models (HiSS), a conceptually simple, new technique for continuoussequential prediction. HiSS stacks structured state-space models on top of eachother to create a temporal hierarchy. Across six real-world sensor datasets,from tactile-based state prediction to accelerometer-based inertialmeasurement, HiSS outperforms state-of-the-art sequence models such as causalTransformers, LSTMs, S4, and Mamba by at least 23% on MSE. Our experimentsfurther indicate that HiSS demonstrates efficient scaling to smaller datasetsand is compatible with existing data-filtering techniques. Code, datasets andvideos can be found on https://hiss-csp.github.io.</description><author>Raunaq Bhirangi, Chenyu Wang, Venkatesh Pattabiraman, Carmel Majidi, Abhinav Gupta, Tess Hellebrekers, Lerrel Pinto</author><pubDate>Thu, 15 Feb 2024 18:59:43 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.10211v1</guid></item></channel></rss>