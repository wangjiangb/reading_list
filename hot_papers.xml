<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/"><channel><title>Arxivhot papers</title><link></link><description>Arxiv paper</description><language>en-US</language><lastBuildDate>Thu, 16 Jan 2025 01:00:04 GMT</lastBuildDate><generator>rfeed v1.0.0</generator><docs>https://github.com/svpino/rfeed/blob/master/README.md</docs><item><title>Towards Fair Class-wise Robustness: Class Optimal Distribution Adversarial Training</title><link>http://arxiv.org/abs/2501.04527v1</link><description>Adversarial training has proven to be a highly effective method for improvingthe robustness of deep neural networks against adversarial attacks.Nonetheless, it has been observed to exhibit a limitation in terms of robustfairness, characterized by a significant disparity in robustness acrossdifferent classes. Recent efforts to mitigate this problem have turned toclass-wise reweighted methods. However, these methods suffer from a lack ofrigorous theoretical analysis and are limited in their exploration of theweight space, as they mainly rely on existing heuristic algorithms or intuitionto compute weights. In addition, these methods fail to guarantee theconsistency of the optimization direction due to the decoupled optimization ofweights and the model parameters. They potentially lead to suboptimal weightassignments and consequently, a suboptimal model. To address these problems,this paper proposes a novel min-max training framework, Class OptimalDistribution Adversarial Training (CODAT), which employs distributionallyrobust optimization to fully explore the class-wise weight space, thus enablingthe identification of the optimal weight with theoretical guarantees.Furthermore, we derive a closed-form optimal solution to the internalmaximization and then get a deterministic equivalent objective function, whichprovides a theoretical basis for the joint optimization of weights and modelparameters. Meanwhile, we propose a fairness elasticity coefficient for theevaluation of the algorithm with regard to both robustness and robust fairness.Experimental results on various datasets show that the proposed method caneffectively improve the robust fairness of the model and outperform thestate-of-the-art approaches.</description><author>Hongxin Zhi, Hongtao Yu, Shaome Li, Xiuming Zhao, Yiteng Wu</author><pubDate>Wed, 08 Jan 2025 14:19:03 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.04527v1</guid></item><item><title>ReFocus: Visual Editing as a Chain of Thought for Structured Image Understanding</title><link>http://arxiv.org/abs/2501.05452v1</link><description>Structured image understanding, such as interpreting tables and charts,requires strategically refocusing across various structures and texts within animage, forming a reasoning sequence to arrive at the final answer. However,current multimodal large language models (LLMs) lack this multihop selectiveattention capability. In this work, we introduce ReFocus, a simple yeteffective framework that equips multimodal LLMs with the ability to generate"visual thoughts" by performing visual editing on the input image through code,shifting and refining their visual focuses. Specifically, ReFocus enablesmultimodal LLMs to generate Python codes to call tools and modify the inputimage, sequentially drawing boxes, highlighting sections, and masking outareas, thereby enhancing the visual reasoning process. We experiment upon awide range of structured image understanding tasks involving tables and charts.ReFocus largely improves performance on all tasks over GPT-4o without visualediting, yielding an average gain of 11.0% on table tasks and 6.8% on charttasks. We present an in-depth analysis of the effects of different visualedits, and reasons why ReFocus can improve the performance without introducingadditional information. Further, we collect a 14k training set using ReFocus,and prove that such visual chain-of-thought with intermediate informationoffers a better supervision than standard VQA data, reaching a 8.0% averagegain over the same model trained with QA pairs and 2.6% over CoT.</description><author>Xingyu Fu, Minqian Liu, Zhengyuan Yang, John Corring, Yijuan Lu, Jianwei Yang, Dan Roth, Dinei Florencio, Cha Zhang</author><pubDate>Thu, 09 Jan 2025 18:59:58 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.05452v1</guid></item><item><title>An Empirical Study of Autoregressive Pre-training from Videos</title><link>http://arxiv.org/abs/2501.05453v1</link><description>We empirically study autoregressive pre-training from videos. To perform ourstudy, we construct a series of autoregressive video models, called Toto. Wetreat videos as sequences of visual tokens and train transformer models toautoregressively predict future tokens. Our models are pre-trained on a diversedataset of videos and images comprising over 1 trillion visual tokens. Weexplore different architectural, training, and inference design choices. Weevaluate the learned visual representations on a range of downstream tasksincluding image recognition, video classification, object tracking, androbotics. Our results demonstrate that, despite minimal inductive biases,autoregressive pre-training leads to competitive performance across allbenchmarks. Finally, we find that scaling our video models results in similarscaling curves to those seen in language models, albeit with a different rate.More details at https://brjathu.github.io/toto/</description><author>Jathushan Rajasegaran, Ilija Radosavovic, Rahul Ravishankar, Yossi Gandelsman, Christoph Feichtenhofer, Jitendra Malik</author><pubDate>Thu, 09 Jan 2025 18:59:58 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.05453v1</guid></item><item><title>Decentralized Diffusion Models</title><link>http://arxiv.org/abs/2501.05450v1</link><description>Large-scale AI model training divides work across thousands of GPUs, thensynchronizes gradients across them at each step. This incurs a significantnetwork burden that only centralized, monolithic clusters can support, drivingup infrastructure costs and straining power systems. We propose DecentralizedDiffusion Models, a scalable framework for distributing diffusion modeltraining across independent clusters or datacenters by eliminating thedependence on a centralized, high-bandwidth networking fabric. Our methodtrains a set of expert diffusion models over partitions of the dataset, each infull isolation from one another. At inference time, the experts ensemblethrough a lightweight router. We show that the ensemble collectively optimizesthe same objective as a single model trained over the whole dataset. This meanswe can divide the training burden among a number of "compute islands," loweringinfrastructure costs and improving resilience to localized GPU failures.Decentralized diffusion models empower researchers to take advantage ofsmaller, more cost-effective and more readily available compute like on-demandGPU nodes rather than central integrated systems. We conduct extensiveexperiments on ImageNet and LAION Aesthetics, showing that decentralizeddiffusion models FLOP-for-FLOP outperform standard diffusion models. We finallyscale our approach to 24 billion parameters, demonstrating that high-qualitydiffusion models can now be trained with just eight individual GPU nodes inless than a week.</description><author>David McAllister, Matthew Tancik, Jiaming Song, Angjoo Kanazawa</author><pubDate>Thu, 09 Jan 2025 18:59:56 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.05450v1</guid></item><item><title>Explainable AI-Enhanced Deep Learning for Pumpkin Leaf Disease Detection: A Comparative Analysis of CNN Architectures</title><link>http://arxiv.org/abs/2501.05449v1</link><description>Pumpkin leaf diseases are significant threats to agricultural productivity,requiring a timely and precise diagnosis for effective management. Traditionalidentification methods are laborious and susceptible to human error,emphasizing the necessity for automated solutions. This study employs on the"Pumpkin Leaf Disease Dataset", that comprises of 2000 high-resolution imagesseparated into five categories. Downy mildew, powdery mildew, mosaic disease,bacterial leaf spot, and healthy leaves. The dataset was rigorously assembledfrom several agricultural fields to ensure a strong representation for modeltraining. We explored many proficient deep learning architectures, includingDenseNet201, DenseNet121, DenseNet169, Xception, ResNet50, ResNet101 andInceptionResNetV2, and observed that ResNet50 performed most effectively, withan accuracy of 90.5% and comparable precision, recall, and F1-Score. We usedExplainable AI (XAI) approaches like Grad-CAM, Grad-CAM++, Score-CAM, andLayer-CAM to provide meaningful representations of model decision-makingprocesses, which improved understanding and trust in automated diseasediagnostics. These findings demonstrate ResNet50's potential to revolutionizepumpkin leaf disease detection, allowing for earlier and more accuratetreatments.</description><author>Md. Arafat Alam Khandaker, Ziyan Shirin Raha, Shifat Islam, Tashreef Muhammad</author><pubDate>Thu, 09 Jan 2025 18:59:35 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.05449v1</guid></item><item><title>Relative Pose Estimation through Affine Corrections of Monocular Depth Priors</title><link>http://arxiv.org/abs/2501.05446v1</link><description>Monocular depth estimation (MDE) models have undergone significantadvancements over recent years. Many MDE models aim to predict affine-invariantrelative depth from monocular images, while recent developments in large-scaletraining and vision foundation models enable reasonable estimation of metric(absolute) depth. However, effectively leveraging these predictions forgeometric vision tasks, in particular relative pose estimation, remainsrelatively under explored. While depths provide rich constraints for cross-viewimage alignment, the intrinsic noise and ambiguity from the monocular depthpriors present practical challenges to improving upon classic keypoint-basedsolutions. In this paper, we develop three solvers for relative pose estimationthat explicitly account for independent affine (scale and shift) ambiguities,covering both calibrated and uncalibrated conditions. We further propose ahybrid estimation pipeline that combines our proposed solvers with classicpoint-based solvers and epipolar constraints. We find that the affinecorrection modeling is beneficial to not only the relative depth priors butalso, surprisingly, the ``metric" ones. Results across multiple datasetsdemonstrate large improvements of our approach over classic keypoint-basedbaselines and PnP-based solutions, under both calibrated and uncalibratedsetups. We also show that our method improves consistently with differentfeature matchers and MDE models, and can further benefit from very recentadvances on both modules. Code is available athttps://github.com/MarkYu98/madpose.</description><author>Yifan Yu, Shaohui Liu, Rémi Pautrat, Marc Pollefeys, Viktor Larsson</author><pubDate>Thu, 09 Jan 2025 18:58:30 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.05446v1</guid></item><item><title>Consistent Flow Distillation for Text-to-3D Generation</title><link>http://arxiv.org/abs/2501.05445v1</link><description>Score Distillation Sampling (SDS) has made significant strides in distillingimage-generative models for 3D generation. However, itsmaximum-likelihood-seeking behavior often leads to degraded visual quality anddiversity, limiting its effectiveness in 3D applications. In this work, wepropose Consistent Flow Distillation (CFD), which addresses these limitations.We begin by leveraging the gradient of the diffusion ODE or SDE samplingprocess to guide the 3D generation. From the gradient-based samplingperspective, we find that the consistency of 2D image flows across differentviewpoints is important for high-quality 3D generation. To achieve this, weintroduce multi-view consistent Gaussian noise on the 3D object, which can berendered from various viewpoints to compute the flow gradient. Our experimentsdemonstrate that CFD, through consistent flows, significantly outperformsprevious methods in text-to-3D generation.</description><author>Runjie Yan, Yinbo Chen, Xiaolong Wang</author><pubDate>Thu, 09 Jan 2025 18:56:05 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.05445v1</guid></item><item><title>Can MLLMs Reason in Multimodality? EMMA: An Enhanced MultiModal ReAsoning Benchmark</title><link>http://arxiv.org/abs/2501.05444v1</link><description>The ability to organically reason over and with both text and images is apillar of human intelligence, yet the ability of Multimodal Large LanguageModels (MLLMs) to perform such multimodal reasoning remains under-explored.Existing benchmarks often emphasize text-dominant reasoning or rely on shallowvisual cues, failing to adequately assess integrated visual and textualreasoning. We introduce EMMA (Enhanced MultiModal reAsoning), a benchmarktargeting organic multimodal reasoning across mathematics, physics, chemistry,and coding. EMMA tasks demand advanced cross-modal reasoning that cannot beaddressed by reasoning independently in each modality, offering an enhancedtest suite for MLLMs' reasoning capabilities. Our evaluation ofstate-of-the-art MLLMs on EMMA reveals significant limitations in handlingcomplex multimodal and multi-step reasoning tasks, even with advancedtechniques like Chain-of-Thought prompting and test-time compute scalingunderperforming. These findings underscore the need for improved multimodalarchitectures and training paradigms to close the gap between human and modelreasoning in multimodality.</description><author>Yunzhuo Hao, Jiawei Gu, Huichen Will Wang, Linjie Li, Zhengyuan Yang, Lijuan Wang, Yu Cheng</author><pubDate>Thu, 09 Jan 2025 18:55:52 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.05444v1</guid></item><item><title>A survey of textual cyber abuse detection using cutting-edge language models and large language models</title><link>http://arxiv.org/abs/2501.05443v1</link><description>The success of social media platforms has facilitated the emergence ofvarious forms of online abuse within digital communities. This abuse manifestsin multiple ways, including hate speech, cyberbullying, emotional abuse,grooming, and sexting. In this paper, we present a comprehensive analysis ofthe different forms of abuse prevalent in social media, with a particular focuson how emerging technologies, such as Language Models (LMs) and Large LanguageModels (LLMs), are reshaping both the detection and generation of abusivecontent within these networks. We delve into the mechanisms through whichsocial media abuse is perpetuated, exploring the psychological and socialimpact. Additionally, we examine the dual role of advanced languagemodels-highlighting their potential to enhance automated detection systems forabusive behavior while also acknowledging their capacity to generate harmfulcontent. This paper aims to contribute to the ongoing discourse on onlinesafety and ethics, offering insights into the evolving landscape of cyberabuseand the technological innovations that both mitigate and exacerbate it.</description><author>Jose A. Diaz-Garcia, Joao Paulo Carvalho</author><pubDate>Thu, 09 Jan 2025 18:55:50 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.05443v1</guid></item><item><title>Progressive Growing of Video Tokenizers for Highly Compressed Latent Spaces</title><link>http://arxiv.org/abs/2501.05442v1</link><description>Video tokenizers are essential for latent video diffusion models, convertingraw video data into spatiotemporally compressed latent spaces for efficienttraining. However, extending state-of-the-art video tokenizers to achieve atemporal compression ratio beyond 4x without increasing channel capacity posessignificant challenges. In this work, we propose an alternative approach toenhance temporal compression. We find that the reconstruction quality oftemporally subsampled videos from a low-compression encoder surpasses that ofhigh-compression encoders applied to original videos. This indicates thathigh-compression models can leverage representations from lower-compressionmodels. Building on this insight, we develop a bootstrappedhigh-temporal-compression model that progressively trains high-compressionblocks atop well-trained lower-compression models. Our method includes across-level feature-mixing module to retain information from the pretrainedlow-compression model and guide higher-compression blocks to capture theremaining details from the full video sequence. Evaluation of video benchmarksshows that our method significantly improves reconstruction quality whileincreasing temporal compression compared to direct extensions of existing videotokenizers. Furthermore, the resulting compact latent space effectively trainsa video diffusion model for high-quality video generation with a reduced tokenbudget.</description><author>Aniruddha Mahapatra, Long Mai, Yitian Zhang, David Bourgin, Feng Liu</author><pubDate>Thu, 09 Jan 2025 18:55:15 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.05442v1</guid></item><item><title>The GAN is dead; long live the GAN! A Modern GAN Baseline</title><link>http://arxiv.org/abs/2501.05441v1</link><description>There is a widely-spread claim that GANs are difficult to train, and GANarchitectures in the literature are littered with empirical tricks. We provideevidence against this claim and build a modern GAN baseline in a moreprincipled manner. First, we derive a well-behaved regularized relativistic GANloss that addresses issues of mode dropping and non-convergence that werepreviously tackled via a bag of ad-hoc tricks. We analyze our lossmathematically and prove that it admits local convergence guarantees, unlikemost existing relativistic losses. Second, our new loss allows us to discardall ad-hoc tricks and replace outdated backbones used in common GANs withmodern architectures. Using StyleGAN2 as an example, we present a roadmap ofsimplification and modernization that results in a new minimalist baseline --R3GAN. Despite being simple, our approach surpasses StyleGAN2 on FFHQ,ImageNet, CIFAR, and Stacked MNIST datasets, and compares favorably againststate-of-the-art GANs and diffusion models.</description><author>Yiwen Huang, Aaron Gokaslan, Volodymyr Kuleshov, James Tompkin</author><pubDate>Thu, 09 Jan 2025 18:53:06 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.05441v1</guid></item><item><title>From Simple to Complex Skills: The Case of In-Hand Object Reorientation</title><link>http://arxiv.org/abs/2501.05439v1</link><description>Learning policies in simulation and transferring them to the real world hasbecome a promising approach in dexterous manipulation. However, bridging thesim-to-real gap for each new task requires substantial human effort, such ascareful reward engineering, hyperparameter tuning, and system identification.In this work, we present a system that leverages low-level skills to addressthese challenges for more complex tasks. Specifically, we introduce ahierarchical policy for in-hand object reorientation based on previouslyacquired rotation skills. This hierarchical policy learns to select whichlow-level skill to execute based on feedback from both the environment and thelow-level skill policies themselves. Compared to learning from scratch, thehierarchical policy is more robust to out-of-distribution changes and transferseasily from simulation to real-world environments. Additionally, we propose ageneralizable object pose estimator that uses proprioceptive information,low-level skill predictions, and control errors as inputs to estimate theobject pose over time. We demonstrate that our system can reorient objects,including symmetrical and textureless ones, to a desired pose.</description><author>Haozhi Qi, Brent Yi, Mike Lambeta, Yi Ma, Roberto Calandra, Jitendra Malik</author><pubDate>Thu, 09 Jan 2025 18:49:39 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.05439v1</guid></item><item><title>$DPF^*$: improved Depth Potential Function for scale-invariant sulcal depth estimation</title><link>http://arxiv.org/abs/2501.05436v1</link><description>The shape of human brain is complex and highly variable, with interactionsbetween brain size, cortical folding, and age well-documented in theliterature. However, few studies have explored how global brain size influencesgeometric features of the cortical surface derived from anatomical MRI. In thiswork, we focus on sulcal depth, an imaging phenotype that has gainedsignificant attention in both basic research and clinical applications. We makekey contributions to the field by: 1) providing the first quantitative analysisof how brain size affects sulcal depth measurements; 2) introducing a novel,scale-invariant method for sulcal depth estimation based on an originalformalization of the problem; 3) presenting a validation framework and sharingour code and benchmark data with the community; and 4) demonstrating thebiological relevance of our new sulcal depth measure using a large sample of1,987 subjects spanning the developmental period from 26 weeks post-conceptionto adulthood.</description><author>Maxime Dieudonné, Guillaume Auzias, Julien Lefèvre</author><pubDate>Thu, 09 Jan 2025 18:48:55 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.05436v1</guid></item><item><title>Neuro-Symbolic AI in 2024: A Systematic Review</title><link>http://arxiv.org/abs/2501.05435v1</link><description>Background: The field of Artificial Intelligence has undergone cyclicalperiods of growth and decline, known as AI summers and winters. Currently, weare in the third AI summer, characterized by significant advancements andcommercialization, particularly in the integration of Symbolic AI andSub-Symbolic AI, leading to the emergence of Neuro-Symbolic AI. Methods: The review followed the PRISMA methodology, utilizing databases suchas IEEE Explore, Google Scholar, arXiv, ACM, and SpringerLink. The inclusioncriteria targeted peer-reviewed papers published between 2020 and 2024. Paperswere screened for relevance to Neuro-Symbolic AI, with further inclusion basedon the availability of associated codebases to ensure reproducibility. Results: From an initial pool of 1,428 papers, 167 met the inclusion criteriaand were analyzed in detail. The majority of research efforts are concentratedin the areas of learning and inference (63%), logic and reasoning (35%), andknowledge representation (44%). Explainability and trustworthiness are lessrepresented (28%), with Meta-Cognition being the least explored area (5%). Thereview identifies significant interdisciplinary opportunities, particularly inintegrating explainability and trustworthiness with other research areas. Conclusion: Neuro-Symbolic AI research has seen rapid growth since 2020, withconcentrated efforts in learning and inference. Significant gaps remain inexplainability, trustworthiness, and Meta-Cognition. Addressing these gapsthrough interdisciplinary research will be crucial for advancing the fieldtowards more intelligent, reliable, and context-aware AI systems.</description><author>Brandon C. Colelough, William Regli</author><pubDate>Thu, 09 Jan 2025 18:48:35 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.05435v1</guid></item><item><title>Gradient-based facial encoding for key generation to encrypt and decrypt multimedia data</title><link>http://arxiv.org/abs/2412.06927v2</link><description>Security systems relying on passwords are vulnerable to being forgotten,guessed, or breached. Likewise, biometric systems that operate independentlyare at risk of template spoofing and replay incidents. This paper introduces abiocryptosystem utilizing face recognition techniques to address these issues,allowing for the encryption and decryption of various file types through theAdvanced Encryption Standard (AES). The proposed system creates a distinct32-bit encryption key derived from facial features identified by Histogram ofOriented Gradients (HOG) and categorized using Support Vector Machines (SVM).HOG efficiently identifies edge-aligned facial features, even in dim lighting,ensuring that reliable biometric keys can be generated. This key is then usedwith AES to encrypt and decrypt a variety of data formats, such as text, audio,and video files. This encryption key, derived from an individual's distinctivefacial traits, is exceedingly challenging for adversaries to reproduce orguess. The security and performance of the system have been validated throughexperiments using several metrics, including correlation analysis, Shannonentropy, normalized Hamming distance, and the avalanche effect on 25 differentfile types. Potential uses for the proposed system include secure file sharing,online transactions, and data archiving, making it a strong and trustworthyapproach to safeguarding sensitive information by integrating the uniqueness offacial biometrics with the established security of AES encryption.</description><author>Ankit Kumar Patel, Dewanshi Paul, Sarthak Giri, Sneha Chaudhary, Bikalpa Gautam</author><pubDate>Thu, 09 Jan 2025 18:44:39 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.06927v2</guid></item><item><title>AgroGPT: Efficient Agricultural Vision-Language Model with Expert Tuning</title><link>http://arxiv.org/abs/2410.08405v2</link><description>Significant progress has been made in advancing large multimodalconversational models (LMMs), capitalizing on vast repositories of image-textdata available online. Despite this progress, these models often encountersubstantial domain gaps, hindering their ability to engage in complexconversations across new domains. Recent efforts have aimed to mitigate thisissue, albeit relying on domain-specific image-text data to curateinstruction-tuning data. However, many domains, such as agriculture, lack suchvision-language data. In this work, we propose an approach to constructinstruction-tuning data that harnesses vision-only data for the agriculturedomain. We utilize diverse agricultural datasets spanning multiple domains,curate class-specific information, and employ large language models (LLMs) toconstruct an expert-tuning set, resulting in a 70k expert-tuning dataset calledAgroInstruct. Subsequently, we expert-tuned and created AgroGPT, an efficientLMM that can hold complex agriculture-related conversations and provide usefulinsights. We also develop AgroEvals for evaluation and compare {AgroGPT's}performance with large open and closed-source models. {AgroGPT} excels atidentifying fine-grained agricultural concepts, can act as an agricultureexpert, and provides helpful information for multimodal agriculture questions.The code, datasets, and models are available athttps://github.com/awaisrauf/agroGPT.</description><author>Muhammad Awais, Ali Husain Salem Abdulla Alharthi, Amandeep Kumar, Hisham Cholakkal, Rao Muhammad Anwer</author><pubDate>Thu, 09 Jan 2025 18:43:18 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.08405v2</guid></item><item><title>Flatland Vision</title><link>http://arxiv.org/abs/2501.05429v1</link><description>When is it possible to project two sets of labeled points lying in a pair ofprojective planes to the same image on a projective line? We give a completeanswer to this question and describe the loci of the projection centers thatenable a common image. In particular, we find that there exists a solution tothis problem if and only if these two sets are themselves images of a commonpointset in projective space.</description><author>Sameer Agarwal, Erin Connelly, Annalisa Crannell, Timothy Duff, Rekha R. Thomas</author><pubDate>Thu, 09 Jan 2025 18:42:47 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.05429v1</guid></item><item><title>Zero-1-to-G: Taming Pretrained 2D Diffusion Model for Direct 3D Generation</title><link>http://arxiv.org/abs/2501.05427v1</link><description>Recent advances in 2D image generation have achieved remarkablequality,largely driven by the capacity of diffusion models and the availabilityof large-scale datasets. However, direct 3D generation is still constrained bythe scarcity and lower fidelity of 3D datasets. In this paper, we introduceZero-1-to-G, a novel approach that addresses this problem by enabling directsingle-view generation on Gaussian splats using pretrained 2D diffusion models.Our key insight is that Gaussian splats, a 3D representation, can be decomposedinto multi-view images encoding different attributes. This reframes thechallenging task of direct 3D generation within a 2D diffusion framework,allowing us to leverage the rich priors of pretrained 2D diffusion models. Toincorporate 3D awareness, we introduce cross-view and cross-attribute attentionlayers, which capture complex correlations and enforce 3D consistency acrossgenerated splats. This makes Zero-1-to-G the first direct image-to-3Dgenerative model to effectively utilize pretrained 2D diffusion priors,enabling efficient training and improved generalization to unseen objects.Extensive experiments on both synthetic and in-the-wild datasets demonstratesuperior performance in 3D object generation, offering a new approach tohigh-quality 3D generation.</description><author>Xuyi Meng, Chen Wang, Jiahui Lei, Kostas Daniilidis, Jiatao Gu, Lingjie Liu</author><pubDate>Thu, 09 Jan 2025 18:37:35 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.05427v1</guid></item><item><title>From Images to Insights: Transforming Brain Cancer Diagnosis with Explainable AI</title><link>http://arxiv.org/abs/2501.05426v1</link><description>Brain cancer represents a major challenge in medical diagnostics, requisiteprecise and timely detection for effective treatment. Diagnosis initiallyrelies on the proficiency of radiologists, which can cause difficulties andthreats when the expertise is sparse. Despite the use of imaging resources,brain cancer remains often difficult, time-consuming, and vulnerable tointraclass variability. This study conveys the Bangladesh Brain Cancer MRIDataset, containing 6,056 MRI images organized into three categories: BrainTumor, Brain Glioma, and Brain Menin. The dataset was collected from severalhospitals in Bangladesh, providing a diverse and realistic sample for research.We implemented advanced deep learning models, and DenseNet169 achievedexceptional results, with accuracy, precision, recall, and F1-Score allreaching 0.9983. In addition, Explainable AI (XAI) methods including GradCAM,GradCAM++, ScoreCAM, and LayerCAM were employed to provide visualrepresentations of the decision-making processes of the models. In the contextof brain cancer, these techniques highlight DenseNet169's potential to enhancediagnostic accuracy while simultaneously offering transparency, facilitatingearly diagnosis and better patient outcomes.</description><author>Md. Arafat Alam Khandaker, Ziyan Shirin Raha, Salehin Bin Iqbal, M. F. Mridha, Jungpil Shin</author><pubDate>Thu, 09 Jan 2025 18:35:43 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.05426v1</guid></item><item><title>Entangled Mean Estimation in High-Dimensions</title><link>http://arxiv.org/abs/2501.05425v1</link><description>We study the task of high-dimensional entangled mean estimation in thesubset-of-signals model. Specifically, given $N$ independent random points$x_1,\ldots,x_N$ in $\mathbb{R}^D$ and a parameter $\alpha \in (0, 1)$ suchthat each $x_i$ is drawn from a Gaussian with mean $\mu$ and unknowncovariance, and an unknown $\alpha$-fraction of the points haveidentity-bounded covariances, the goal is to estimate the common mean $\mu$.The one-dimensional version of this task has received significant attention intheoretical computer science and statistics over the past decades. Recent work[LY20; CV24] has given near-optimal upper and lower bounds for theone-dimensional setting. On the other hand, our understanding of even theinformation-theoretic aspects of the multivariate setting has remained limited. In this work, we design a computationally efficient algorithm achieving aninformation-theoretically near-optimal error. Specifically, we show that theoptimal error (up to polylogarithmic factors) is $f(\alpha,N) + \sqrt{D/(\alphaN)}$, where the term $f(\alpha,N)$ is the error of the one-dimensional problemand the second term is the sub-Gaussian error rate. Our algorithmic approachemploys an iterative refinement strategy, whereby we progressively learn moreaccurate approximations $\hat \mu$ to $\mu$. This is achieved via a novelrejection sampling procedure that removes points significantly deviating from$\hat \mu$, as an attempt to filter out unusually noisy samples. A complicationthat arises is that rejection sampling introduces bias in the distribution ofthe remaining points. To address this issue, we perform a careful analysis ofthe bias, develop an iterative dimension-reduction strategy, and employ a novelsubroutine inspired by list-decodable learning that leverages theone-dimensional result.</description><author>Ilias Diakonikolas, Daniel M. Kane, Sihan Liu, Thanasis Pittas</author><pubDate>Thu, 09 Jan 2025 18:31:35 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.05425v1</guid></item><item><title>Using LLMs to Infer Non-Binary COVID-19 Sentiments of Chinese Micro-bloggers</title><link>http://arxiv.org/abs/2501.05423v1</link><description>Studying public sentiment during crises is crucial for understanding howopinions and sentiments shift, resulting in polarized societies. We studyWeibo, the most popular microblogging site in China, using posts made duringthe outbreak of the COVID-19 crisis. The study period includes the pre-COVID-19stage, the outbreak stage, and the early stage of epidemic prevention. We useLlama 3 8B, a Large Language Model, to analyze users' sentiments on theplatform by classifying them into positive, negative, sarcastic, and neutralcategories. Analyzing sentiment shifts on Weibo provides insights into howsocial events and government actions influence public opinion. This studycontributes to understanding the dynamics of social sentiments during healthcrises, fulfilling a gap in sentiment analysis for Chinese platforms. Byexamining these dynamics, we aim to offer valuable perspectives on digitalcommunication's role in shaping society's responses during unprecedented globalchallenges.</description><author>Jerry Chongyi Hu, Mohammed Shahid Modi, Boleslaw K. Szymanski</author><pubDate>Thu, 09 Jan 2025 18:30:14 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.05423v1</guid></item><item><title>Uncertainty-aware Knowledge Tracing</title><link>http://arxiv.org/abs/2501.05415v1</link><description>Knowledge Tracing (KT) is crucial in education assessment, which focuses ondepicting students' learning states and assessing students' mastery ofsubjects. With the rise of modern online learning platforms, particularlymassive open online courses (MOOCs), an abundance of interaction data hasgreatly advanced the development of the KT technology. Previous researchcommonly adopts deterministic representation to capture students' knowledgestates, which neglects the uncertainty during student interactions and thusfails to model the true knowledge state in learning process. In light of this,we propose an Uncertainty-Aware Knowledge Tracing model (UKT) which employsstochastic distribution embeddings to represent the uncertainty in studentinteractions, with a Wasserstein self-attention mechanism designed to capturethe transition of state distribution in student learning behaviors.Additionally, we introduce the aleatory uncertainty-aware contrastive learningloss, which strengthens the model's robustness towards different types ofuncertainties. Extensive experiments on six real-world datasets demonstratethat UKT not only significantly surpasses existing deep learning-based modelsin KT prediction, but also shows unique advantages in handling the uncertaintyof student interactions.</description><author>Weihua Cheng, Hanwen Du, Chunxiao Li, Ersheng Ni, Liangdi Tan, Tianqi Xu, Yongxin Ni</author><pubDate>Thu, 09 Jan 2025 18:17:27 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.05415v1</guid></item><item><title>LongProc: Benchmarking Long-Context Language Models on Long Procedural Generation</title><link>http://arxiv.org/abs/2501.05414v1</link><description>Existing benchmarks for evaluating long-context language models (LCLMs)primarily focus on long-context recall, requiring models to produce shortresponses based on a few critical snippets while processing thousands ofirrelevant tokens. We introduce LongProc (Long Procedural Generation), a newbenchmark that requires both the integration of highly dispersed informationand long-form generation. LongProc consists of six diverse proceduralgeneration tasks, such as extracting structured information from HTML pagesinto a TSV format and executing complex search procedures to create travelplans. These tasks challenge LCLMs by testing their ability to follow detailedprocedural instructions, synthesize and reason over dispersed information, andgenerate structured, long-form outputs (up to 8K tokens). Furthermore, as thesetasks adhere to deterministic procedures and yield structured outputs, theyenable reliable rule-based evaluation. We evaluate 17 LCLMs on LongProc acrossthree difficulty levels, with maximum numbers of output tokens set at 500, 2K,and 8K. Notably, while all tested models claim a context window size above 32Ktokens, open-weight models typically falter on 2K-token tasks, andclosed-source models like GPT-4o show significant degradation on 8K-tokentasks. Further analysis reveals that LCLMs struggle to maintain long-rangecoherence in long-form generations. These findings highlight criticallimitations in current LCLMs and suggest substantial room for improvement. Dataand code available at: https://princeton-pli.github.io/LongProc</description><author>Xi Ye, Fangcong Yin, Yinghui He, Joie Zhang, Howard Yen, Tianyu Gao, Greg Durrett, Danqi Chen</author><pubDate>Thu, 09 Jan 2025 18:16:55 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.05414v1</guid></item><item><title>Conditional Deep Canonical Time Warping</title><link>http://arxiv.org/abs/2412.18234v2</link><description>Temporal alignment of sequences is a fundamental challenge in manyapplications, such as computer vision and bioinformatics, where local timeshifting needs to be accounted for. Misalignment can lead to poor modelgeneralization, especially in high-dimensional sequences. Existing methodsoften struggle with optimization when dealing with high-dimensional sparsedata, falling into poor alignments. Feature selection is frequently used toenhance model performance for sparse data. However, a fixed set of selectedfeatures would not generally work for dynamically changing sequences and wouldneed to be modified based on the state of the sequence. Therefore, modifyingthe selected feature based on contextual input would result in betteralignment. Our suggested method, Conditional Deep Canonical Temporal TimeWarping (CDCTW), is designed for temporal alignment in sparse temporal data toaddress these challenges. CDCTW enhances alignment accuracy for highdimensional time-dependent views be performing dynamic time warping on dataembedded in maximally correlated subspace which handles sparsity with novelfeature selection method. We validate the effectiveness of CDCTW throughextensive experiments on various datasets, demonstrating superior performanceover previous techniques.</description><author>Afek Steinberg, Ran Eisenberg, Ofir Lindenbaum</author><pubDate>Thu, 09 Jan 2025 18:16:38 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.18234v2</guid></item><item><title>Seeing Sound: Assembling Sounds from Visuals for Audio-to-Image Generation</title><link>http://arxiv.org/abs/2501.05413v1</link><description>Training audio-to-image generative models requires an abundance of diverseaudio-visual pairs that are semantically aligned. Such data is almost alwayscurated from in-the-wild videos, given the cross-modal semantic correspondencethat is inherent to them. In this work, we hypothesize that insisting on theabsolute need for ground truth audio-visual correspondence, is not onlyunnecessary, but also leads to severe restrictions in scale, quality, anddiversity of the data, ultimately impairing its use in the modern generativemodels. That is, we propose a scalable image sonification framework whereinstances from a variety of high-quality yet disjoint uni-modal origins can beartificially paired through a retrieval process that is empowered by reasoningcapabilities of modern vision-language models. To demonstrate the efficacy ofthis approach, we use our sonified images to train an audio-to-image generativemodel that performs competitively against state-of-the-art. Finally, through aseries of ablation studies, we exhibit several intriguing auditory capabilitieslike semantic mixing and interpolation, loudness calibration and acoustic spacemodeling through reverberation that our model has implicitly developed to guidethe image generation process.</description><author>Darius Petermann, Mahdi M. Kalayeh</author><pubDate>Thu, 09 Jan 2025 18:13:57 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.05413v1</guid></item><item><title>A Novel Pathology Foundation Model by Mayo Clinic, Charité, and Aignostics</title><link>http://arxiv.org/abs/2501.05409v1</link><description>Recent advances in digital pathology have demonstrated the effectiveness offoundation models across diverse applications. In this report, we present anovel vision foundation model based on the RudolfV approach. Our model wastrained on a dataset comprising 1.2 million histopathology whole slide images,collected from two medical institutions: Mayo Clinic and Charit\'e -Universt\"atsmedizin Berlin. Comprehensive evaluations show that our modelachieves state-of-the-art performance across twenty-one public benchmarkdatasets, even though it is neither the largest model by parameter count nor bytraining dataset size.</description><author>Maximilian Alber, Stephan Tietz, Jonas Dippel, Timo Milbich, Timothée Lesort, Panos Korfiatis, Moritz Krügener, Beatriz Perez Cancer, Neelay Shah, Alexander Möllers, Philipp Seegerer, Alexandra Carpen-Amarie, Kai Standvoss, Gabriel Dernbach, Edwin de Jong, Simon Schallenberg, Andreas Kunft, Helmut Hoffer von Ankershoffen, Gavin Schaeferle, Patrick Duffy, Matt Redlon, Philipp Jurmeister, David Horst, Lukas Ruff, Klaus-Robert Müller, Frederick Klauschen, Andrew Norgan</author><pubDate>Thu, 09 Jan 2025 18:06:45 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.05409v1</guid></item><item><title>TimeRL: Efficient Deep Reinforcement Learning with Polyhedral Dependence Graphs</title><link>http://arxiv.org/abs/2501.05408v1</link><description>Modern deep learning (DL) workloads increasingly use complex deepreinforcement learning (DRL) algorithms that generate training data within thelearning loop. This results in programs with several nested loops and dynamicdata dependencies between tensors. While DL systems with eager executionsupport such dynamism, they lack the optimizations and smart scheduling ofgraph-based execution. Graph-based execution, however, cannot express dynamictensor shapes, instead requiring the use of multiple static subgraphs. Eitherexecution model for DRL thus leads to redundant computation, reducedparallelism, and less efficient memory management. We describe TimeRL, a system for executing dynamic DRL programs that combinesthe dynamism of eager execution with the whole-program optimizations andscheduling of graph-based execution. TimeRL achieves this by introducing thedeclarative programming model of recurrent tensors, which allows users todefine dynamic dependencies as intuitive recurrence equations. TimeRLtranslates recurrent tensors into a polyhedral dependence graph (PDG) withdynamic dependencies as symbolic expressions. Through simple PDGtransformations, TimeRL applies whole-program optimizations, such as automaticvectorization, incrementalization, and operator fusion. The PDG also allows forthe computation of an efficient program-wide execution schedule, which decideson buffer deallocations, buffer donations, and GPU/CPU memory swapping. We showthat TimeRL executes current DRL algorithms up to 47$\times$ faster thanexisting DRL systems, while using 16$\times$ less GPU peak memory.</description><author>Pedro F. Silvestre, Peter Pietzuch</author><pubDate>Thu, 09 Jan 2025 18:05:33 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.05408v1</guid></item><item><title>On-line Policy Improvement using Monte-Carlo Search</title><link>http://arxiv.org/abs/2501.05407v1</link><description>We present a Monte-Carlo simulation algorithm for real-time policyimprovement of an adaptive controller. In the Monte-Carlo simulation, thelong-term expected reward of each possible action is statistically measured,using the initial policy to make decisions in each step of the simulation. Theaction maximizing the measured expected reward is then taken, resulting in animproved policy. Our algorithm is easily parallelizable and has beenimplemented on the IBM SP1 and SP2 parallel-RISC supercomputers. We have obtained promising initial results in applying this algorithm to thedomain of backgammon. Results are reported for a wide variety of initialpolicies, ranging from a random policy to TD-Gammon, an extremely strongmulti-layer neural network. In each case, the Monte-Carlo algorithm gives asubstantial reduction, by as much as a factor of 5 or more, in the error rateof the base players. The algorithm is also potentially useful in many otheradaptive control applications in which it is possible to simulate theenvironment.</description><author>Gerald Tesauro, Gregory R. Galperin</author><pubDate>Thu, 09 Jan 2025 18:05:05 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.05407v1</guid></item><item><title>Attention Mechanisms Don't Learn Additive Models: Rethinking Feature Importance for Transformers</title><link>http://arxiv.org/abs/2405.13536v2</link><description>We address the critical challenge of applying feature attribution methods tothe transformer architecture, which dominates current applications in naturallanguage processing and beyond. Traditional attribution methods to explainableAI (XAI) explicitly or implicitly rely on linear or additive surrogate modelsto quantify the impact of input features on a model's output. In this work, weformally prove an alarming incompatibility: transformers are structurallyincapable of representing linear or additive surrogate models used for featureattribution, undermining the grounding of these conventional explanationmethodologies. To address this discrepancy, we introduce the Softmax-LinkedAdditive Log Odds Model (SLALOM), a novel surrogate model specifically designedto align with the transformer framework. SLALOM demonstrates the capacity todeliver a range of insightful explanations with both synthetic and real-worlddatasets. We highlight SLALOM's unique efficiency-quality curve by showing thatSLALOM can produce explanations with substantially higher fidelity thancompeting surrogate models or provide explanations of comparable quality at afraction of their computational costs. We release code for SLALOM as anopen-source project online at https://github.com/tleemann/slalom_explanations.</description><author>Tobias Leemann, Alina Fastowski, Felix Pfeiffer, Gjergji Kasneci</author><pubDate>Thu, 09 Jan 2025 17:58:44 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.13536v2</guid></item><item><title>Snapshot: Towards Application-centered Models for Pedestrian Trajectory Prediction in Urban Traffic Environments</title><link>http://arxiv.org/abs/2409.01971v2</link><description>This paper explores pedestrian trajectory prediction in urban traffic whilefocusing on both model accuracy and real-world applicability. While promisingapproaches exist, they often revolve around pedestrian datasets excludingtraffic-related information, or resemble architectures that are either notreal-time capable or robust. To address these limitations, we first introduce adedicated benchmark based on Argoverse 2, specifically targeting pedestrians intraffic environments. Following this, we present Snapshot, a modular,feed-forward neural network that outperforms the current state of the art,reducing the Average Displacement Error (ADE) by 8.8% while utilizingsignificantly less information. Despite its agent-centric encoding scheme,Snapshot demonstrates scalability, real-time performance, and robustness tovarying motion histories. Moreover, by integrating Snapshot into a modularautonomous driving software stack, we showcase its real-world applicability.</description><author>Nico Uhlemann, Yipeng Zhou, Tobias Simeon Mohr, Markus Lienkamp</author><pubDate>Thu, 09 Jan 2025 17:57:53 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2409.01971v2</guid></item><item><title>Using Linearized Optimal Transport to Predict the Evolution of Stochastic Particle Systems</title><link>http://arxiv.org/abs/2408.01857v2</link><description>We develop an algorithm to approximate the time evolution of a probabilitydistribution without explicitly learning an operator that governs theevolution. A particular application of interest is discrete measures $\mu_t^N$that arise from systems of $N$ particles in $\mathbb R^d$. In many suchsituations, the individual particles move chaotically on short time scales,making it difficult to learn the dynamics of a governing operator, but the bulkdistribution $\mu_t^N$ approximates an absolutely continuous measure $\mu_t$that evolves ``smoothly.'' If $\mu_t$ is known on some time interval, thenlinearized optimal transport theory provides an Euler-like scheme forapproximating the evolution of $\mu_t$ using its ``tangent vector field''(represented as a time-dependent vector field on $\mathbb R^d$), which can becomputed as a limit of optimal transport maps. We propose an analog of thisEuler approximation to predict the evolution of the discrete measure $\mu_t^N$(without knowing $\mu_t$). To approximate the analogous tangent vector field,we use a finite difference over a time step that sits between two time scalesof the system -- long enough for a large-$N$ evolution ($\mu_t$) to emerge butshort enough to satisfactorily approximate the derivative object used in theEuler scheme. The emergence of the limiting behavior ensures the optimaltransport maps closely approximate the vector field describing the bulkdistribution's smooth evolution instead of the individual particles' morechaotic movements. We demonstrate the efficacy of our approach with twoillustrative examples, Gaussian diffusion and a cell chemotaxis model, and showthat our method succeeds in predicting the bulk behavior over relatively largesteps.</description><author>Nicholas Karris, Evangelos A. Nikitopoulos, Ioannis Kevrekidis, Seungjoon Lee, Alexander Cloninger</author><pubDate>Thu, 09 Jan 2025 17:54:15 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.01857v2</guid></item><item><title>BRATI: Bidirectional Recurrent Attention for Time-Series Imputation</title><link>http://arxiv.org/abs/2501.05401v1</link><description>Missing data in time-series analysis poses significant challenges, affectingthe reliability of downstream applications. Imputation, the process ofestimating missing values, has emerged as a key solution. This paper introducesBRATI, a novel deep-learning model designed to address multivariate time-seriesimputation by combining Bidirectional Recurrent Networks and Attentionmechanisms. BRATI processes temporal dependencies and feature correlationsacross long and short time horizons, utilizing two imputation blocks thatoperate in opposite temporal directions. Each block integrates recurrent layersand attention mechanisms to effectively resolve long-term dependencies. We evaluate BRATI on three real-world datasets under diverse missing-datascenarios: randomly missing values, fixed-length missing sequences, andvariable-length missing sequences. Our findings demonstrate that BRATIconsistently outperforms state-of-the-art models, delivering superior accuracyand robustness in imputing multivariate time-series data.</description><author>Armando Collado-Villaverde, Pablo Muñoz, Maria D. R-Moreno</author><pubDate>Thu, 09 Jan 2025 17:50:56 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.05401v1</guid></item><item><title>Performance of YOLOv7 in Kitchen Safety While Handling Knife</title><link>http://arxiv.org/abs/2501.05399v1</link><description>Safe knife practices in the kitchen significantly reduce the risk of cuts,injuries, and serious accidents during food preparation. Using YOLOv7, anadvanced object detection model, this study focuses on identifying safety risksduring knife handling, particularly improper finger placement and blade contactwith hand. The model's performance was evaluated using metrics such asprecision, recall, mAP50, and mAP50-95. The results demonstrate that YOLOv7achieved its best performance at epoch 31, with a mAP50-95 score of 0.7879,precision of 0.9063, and recall of 0.7503. These findings highlight YOLOv7'spotential to accurately detect knife-related hazards, promoting the developmentof improved kitchen safety.</description><author>Athulya Sundaresan Geetha</author><pubDate>Thu, 09 Jan 2025 17:47:57 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.05399v1</guid></item><item><title>Mechanistic understanding and validation of large AI models with SemanticLens</title><link>http://arxiv.org/abs/2501.05398v1</link><description>Unlike human-engineered systems such as aeroplanes, where each component'srole and dependencies are well understood, the inner workings of AI modelsremain largely opaque, hindering verifiability and undermining trust. Thispaper introduces SemanticLens, a universal explanation method for neuralnetworks that maps hidden knowledge encoded by components (e.g., individualneurons) into the semantically structured, multimodal space of a foundationmodel such as CLIP. In this space, unique operations become possible, including(i) textual search to identify neurons encoding specific concepts, (ii)systematic analysis and comparison of model representations, (iii) automatedlabelling of neurons and explanation of their functional roles, and (iv) auditsto validate decision-making against requirements. Fully scalable and operatingwithout human input, SemanticLens is shown to be effective for debugging andvalidation, summarizing model knowledge, aligning reasoning with expectations(e.g., adherence to the ABCDE-rule in melanoma classification), and detectingcomponents tied to spurious correlations and their associated training data. Byenabling component-level understanding and validation, the proposed approachhelps bridge the "trust gap" between AI models and traditional engineeredsystems. We provide code for SemanticLens onhttps://github.com/jim-berend/semanticlens and a demo onhttps://semanticlens.hhi-research-insights.eu.</description><author>Maximilian Dreyer, Jim Berend, Tobias Labarta, Johanna Vielhaben, Thomas Wiegand, Sebastian Lapuschkin, Wojciech Samek</author><pubDate>Thu, 09 Jan 2025 17:47:34 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.05398v1</guid></item><item><title>FairCode: Evaluating Social Bias of LLMs in Code Generation</title><link>http://arxiv.org/abs/2501.05396v1</link><description>Large language models (LLMs) have demonstrated significant capability in codegeneration, drawing increasing attention to the evaluation of the quality andsafety of their outputs. However, research on bias in code generation remainslimited. Existing studies typically assess bias by applying malicious promptsor reapply tasks and dataset for discriminative models. Given that LLMs areoften aligned with human values and that prior datasets are not fully optimizedfor code-related tasks, there is a pressing need for benchmarks specificallydesigned for evaluating code models. In this study, we introduce FairCode, anovel benchmark for evaluating bias in code generation. FairCode comprises twotasks: function implementation and test case generation, each evaluating socialbias through diverse scenarios. Additionally, we propose a new metric,FairScore, to assess model performance on this benchmark. We conductexperiments on widely used LLMs and provide a comprehensive analysis of theresults. The findings reveal that all tested LLMs exhibit bias. The code isavailable at https://github.com/YongkDu/FairCode.</description><author>Yongkang Du, Jen-tse Huang, Jieyu Zhao, Lu Lin</author><pubDate>Thu, 09 Jan 2025 17:42:23 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.05396v1</guid></item><item><title>The global consensus on the risk management of autonomous driving</title><link>http://arxiv.org/abs/2501.05391v1</link><description>Every maneuver of a vehicle redistributes risks between road users. Whilehuman drivers do this intuitively, autonomous vehicles allow and requiredeliberative algorithmic risk management. But how should traffic risks bedistributed among road users? In a global experimental study in eight countrieswith different cultural backgrounds and almost 11,000 participants, we comparedrisk distribution preferences. It turns out that risk preferences in roadtraffic are strikingly similar between the cultural zones. The vast majority ofparticipants in all countries deviates from a guiding principle of minimizingaccident probabilities in favor of weighing up the probability and severity ofaccidents. At the national level, the consideration of accident probability andseverity hardly differs between countries. The social dilemma of autonomousvehicles detected in deterministic crash scenarios disappears in riskassessments of everyday traffic situations in all countries. In no country docyclists receive a risk bonus that goes beyond their higher vulnerability. Insum, our results suggest that a global consensus on the risk ethics ofautonomous driving is easier to establish than on the ethics of crashing.</description><author>Sebastian Krügel, Matthias Uhl</author><pubDate>Thu, 09 Jan 2025 17:33:08 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.05391v1</guid></item><item><title>Tailored-LLaMA: Optimizing Few-Shot Learning in Pruned LLaMA Models with Task-Specific Prompts</title><link>http://arxiv.org/abs/2410.19185v2</link><description>Large language models demonstrate impressive proficiency in languageunderstanding and generation. Nonetheless, training these models from scratch,even the least complex billion-parameter variant demands significantcomputational resources rendering it economically impractical for manyorganizations. With large language models functioning as general-purpose tasksolvers, this paper investigates their task-specific fine-tuning. We employtask-specific datasets and prompts to fine-tune two pruned LLaMA models having5 billion and 4 billion parameters. This process utilizes the pre-trainedweights and focuses on a subset of weights using the LoRA method. One challengein fine-tuning the LLaMA model is crafting a precise prompt tailored to thespecific task. To address this, we propose a novel approach to fine-tune theLLaMA model under two primary constraints: task specificity and prompteffectiveness. Our approach, Tailored LLaMA initially employs structuralpruning to reduce the model sizes from 7B to 5B and 4B parameters.Subsequently, it applies a carefully designed prompt specific to the task andutilizes the LoRA method to accelerate the fine-tuning process. Moreover,fine-tuning a model pruned by 50\% for less than one hour restores the meanaccuracy of classification tasks to 95.68\% at a 20\% compression ratio and to86.54\% at a 50\% compression ratio through few-shot learning with 50 shots.Our validation of Tailored LLaMA on these two pruned variants demonstrates thateven when compressed to 50\%, the models maintain over 65\% of the baselinemodel accuracy in few-shot classification and generation tasks. These findingshighlight the efficacy of our tailored approach in maintaining high performancewith significantly reduced model sizes.</description><author>Danyal Aftab, Steven Davy</author><pubDate>Thu, 09 Jan 2025 17:29:40 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.19185v2</guid></item><item><title>Generalized Kernel Thinning</title><link>http://arxiv.org/abs/2110.01593v7</link><description>The kernel thinning (KT) algorithm of Dwivedi and Mackey (2021) compresses aprobability distribution more effectively than independent sampling bytargeting a reproducing kernel Hilbert space (RKHS) and leveraging a lesssmooth square-root kernel. Here we provide four improvements. First, we showthat KT applied directly to the target RKHS yields tighter, dimension-freeguarantees for any kernel, any distribution, and any fixed function in theRKHS. Second, we show that, for analytic kernels like Gaussian, inversemultiquadric, and sinc, target KT admits maximum mean discrepancy (MMD)guarantees comparable to or better than those of square-root KT without makingexplicit use of a square-root kernel. Third, we prove that KT with a fractionalpower kernel yields better-than-Monte-Carlo MMD guarantees for non-smoothkernels, like Laplace and Mat\'ern, that do not have square-roots. Fourth, weestablish that KT applied to a sum of the target and power kernels (a procedurewe call KT+) simultaneously inherits the improved MMD guarantees of power KTand the tighter individual function guarantees of target KT. In our experimentswith target KT and KT+, we witness significant improvements in integrationerror even in $100$ dimensions and when compressing challenging differentialequation posteriors.</description><author>Raaz Dwivedi, Lester Mackey</author><pubDate>Thu, 09 Jan 2025 17:28:02 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2110.01593v7</guid></item><item><title>Integrating Explainable AI for Effective Malware Detection in Encrypted Network Traffic</title><link>http://arxiv.org/abs/2501.05387v1</link><description>Encrypted network communication ensures confidentiality, integrity, andprivacy between endpoints. However, attackers are increasingly exploitingencryption to conceal malicious behavior. Detecting unknown encrypted malicioustraffic without decrypting the payloads remains a significant challenge. Inthis study, we investigate the integration of explainable artificialintelligence (XAI) techniques to detect malicious network traffic. We employensemble learning models to identify malicious activity using multi-viewfeatures extracted from various aspects of encrypted communication. Toeffectively represent malicious communication, we compiled a robust datasetwith 1,127 unique connections, more than any other available open-sourcedataset, and spanning 54 malware families. Our models were benchmarked againstthe CTU-13 dataset, achieving performance of over 99% accuracy, precision, andF1-score. Additionally, the eXtreme Gradient Boosting (XGB) model demonstrated99.32% accuracy, 99.53% precision, and 99.43% F1-score on our custom dataset.By leveraging Shapley Additive Explanations (SHAP), we identified that themaximum packet size, mean inter-arrival time of packets, and transport layersecurity version used are the most critical features for the global modelexplanation. Furthermore, key features were identified as important for localexplanations across both datasets for individual traffic samples. Theseinsights provide a deeper understanding of the model decision-making process,enhancing the transparency and reliability of detecting malicious encryptedtraffic.</description><author>Sileshi Nibret Zeleke, Amsalu Fentie Jember, Mario Bochicchio</author><pubDate>Thu, 09 Jan 2025 17:21:00 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.05387v1</guid></item><item><title>MemLLM: Finetuning LLMs to Use An Explicit Read-Write Memory</title><link>http://arxiv.org/abs/2404.11672v2</link><description>While current large language models (LLMs) perform well on manyknowledge-related tasks, they are limited by relying on their parameters as animplicit storage mechanism. As a result, they struggle with memorizing rareevents and with updating their memory as facts change over time. In addition,the uninterpretable nature of parametric memory makes it challenging to preventhallucination. Model editing and augmenting LLMs with parameters specializedfor memory are only partial solutions. In this paper, we introduce MemLLM, anovel method of enhancing LLMs by integrating a structured and explicitread-and-write memory module. MemLLM tackles the aforementioned challenges byenabling dynamic interaction with the memory and improving the LLM'scapabilities in using stored knowledge. Our experiments indicate that MemLLMenhances the LLM's performance and interpretability, in language modeling ingeneral and knowledge-intensive tasks in particular. We see MemLLM as animportant step towards making LLMs more grounded and factual through memoryaugmentation.</description><author>Ali Modarressi, Abdullatif Köksal, Ayyoob Imani, Mohsen Fayyaz, Hinrich Schütze</author><pubDate>Thu, 09 Jan 2025 17:18:12 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.11672v2</guid></item><item><title>Large Physics Models: Towards a collaborative approach with Large Language Models and Foundation Models</title><link>http://arxiv.org/abs/2501.05382v1</link><description>This paper explores ideas and provides a potential roadmap for thedevelopment and evaluation of physics-specific large-scale AI models, which wecall Large Physics Models (LPMs). These models, based on foundation models suchas Large Language Models (LLMs) - trained on broad data - are tailored toaddress the demands of physics research. LPMs can function independently or aspart of an integrated framework. This framework can incorporate specializedtools, including symbolic reasoning modules for mathematical manipulations,frameworks to analyse specific experimental and simulated data, and mechanismsfor synthesizing theories and scientific literature. We begin by examiningwhether the physics community should actively develop and refine dedicatedmodels, rather than relying solely on commercial LLMs. We then outline how LPMscan be realized through interdisciplinary collaboration among experts inphysics, computer science, and philosophy of science. To integrate these modelseffectively, we identify three key pillars: Development, Evaluation, andPhilosophical Reflection. Development focuses on constructing models capable ofprocessing physics texts, mathematical formulations, and diverse physical data.Evaluation assesses accuracy and reliability by testing and benchmarking.Finally, Philosophical Reflection encompasses the analysis of broaderimplications of LLMs in physics, including their potential to generate newscientific understanding and what novel collaboration dynamics might arise inresearch. Inspired by the organizational structure of experimentalcollaborations in particle physics, we propose a similarly interdisciplinaryand collaborative approach to building and refining Large Physics Models. Thisroadmap provides specific objectives, defines pathways to achieve them, andidentifies challenges that must be addressed to realise physics-specific largescale AI models.</description><author>Kristian G. Barman, Sascha Caron, Emily Sullivan, Henk W. de Regt, Roberto Ruiz de Austri, Mieke Boon, Michael Färber, Stefan Fröse, Faegheh Hasibi, Andreas Ipp, Rukshak Kapoor, Gregor Kasieczka, Daniel Kostić, Michael Krämer, Tobias Golling, Luis G. Lopez, Jesus Marco, Sydney Otten, Pawel Pawlowski, Pietro Vischia, Erik Weber, Christoph Weniger</author><pubDate>Thu, 09 Jan 2025 17:11:22 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.05382v1</guid></item><item><title>Arc2Avatar: Generating Expressive 3D Avatars from a Single Image via ID Guidance</title><link>http://arxiv.org/abs/2501.05379v1</link><description>Inspired by the effectiveness of 3D Gaussian Splatting (3DGS) inreconstructing detailed 3D scenes within multi-view setups and the emergence oflarge 2D human foundation models, we introduce Arc2Avatar, the first SDS-basedmethod utilizing a human face foundation model as guidance with just a singleimage as input. To achieve that, we extend such a model for diverse-view humanhead generation by fine-tuning on synthetic data and modifying itsconditioning. Our avatars maintain a dense correspondence with a human facemesh template, allowing blendshape-based expression generation. This isachieved through a modified 3DGS approach, connectivity regularizers, and astrategic initialization tailored for our task. Additionally, we propose anoptional efficient SDS-based correction step to refine the blendshapeexpressions, enhancing realism and diversity. Experiments demonstrate thatArc2Avatar achieves state-of-the-art realism and identity preservation,effectively addressing color issues by allowing the use of very low guidance,enabled by our strong identity prior and initialization strategy, withoutcompromising detail.</description><author>Dimitrios Gerogiannis, Foivos Paraperas Papantoniou, Rolandos Alexandros Potamias, Alexandros Lattas, Stefanos Zafeiriou</author><pubDate>Thu, 09 Jan 2025 17:04:33 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.05379v1</guid></item><item><title>A Portable Solution for Simultaneous Human Movement and Mobile EEG Acquisition: Readiness Potentials for Basketball Free-throw Shooting</title><link>http://arxiv.org/abs/2501.05378v1</link><description>Advances in wireless electroencephalography (EEG) technology promise torecord brain-electrical activity in everyday situations. To better understandthe relationship between brain activity and natural behavior, it is necessaryto monitor human movement patterns. Here, we present a pocketable setupconsisting of two smartphones to simultaneously capture human posture and EEGsignals. We asked 26 basketball players to shoot 120 free throws each. First,we investigated whether our setup allows us to capture the readiness potential(RP) that precedes voluntary actions. Second, we investigated whether the RPdiffers between successful and unsuccessful free-throw attempts. The resultsconfirmed the presence of the RP, but the amplitude of the RP was not relatedto shooting success. However, offline analysis of real-time human pose signalsderived from a smartphone camera revealed pose differences between successfuland unsuccessful shots for some individuals. We conclude that a highlyportable, low-cost and lightweight acquisition setup, consisting of twosmartphones and a head-mounted wireless EEG amplifier, is sufficient to monitorcomplex human movement patterns and associated brain dynamics outside thelaboratory.</description><author>Contreras-Altamirano, Melanie Klapprott, Nadine Jacobsen, Paul Maanen, Julius Welzel, Stefan Debener</author><pubDate>Thu, 09 Jan 2025 17:00:53 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.05378v1</guid></item><item><title>Accelerated Diffusion Models via Speculative Sampling</title><link>http://arxiv.org/abs/2501.05370v1</link><description>Speculative sampling is a popular technique for accelerating inference inLarge Language Models by generating candidate tokens using a fast draft modeland accepting or rejecting them based on the target model's distribution. Whilespeculative sampling was previously limited to discrete sequences, we extend itto diffusion models, which generate samples via continuous, vector-valuedMarkov chains. In this context, the target model is a high-quality butcomputationally expensive diffusion model. We propose various draftingstrategies, including a simple and effective approach that does not requiretraining a draft model and is applicable out of the box to any diffusion model.Our experiments demonstrate significant generation speedup on various diffusionmodels, halving the number of function evaluations, while generating exactsamples from the target model.</description><author>Valentin De Bortoli, Alexandre Galashov, Arthur Gretton, Arnaud Doucet</author><pubDate>Thu, 09 Jan 2025 16:50:16 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.05370v1</guid></item><item><title>Developing a Foundation of Vector Symbolic Architectures Using Category Theory</title><link>http://arxiv.org/abs/2501.05368v1</link><description>At the risk of overstating the case, connectionist approaches to machinelearning, i.e. neural networks, are enjoying a small vogue right now. However,these methods require large volumes of data and produce models that areuninterpretable to humans. An alternative framework that is compatible withneural networks and gradient-based learning, but explicitly modelscompositionality, is Vector Symbolic Architectures (VSAs). VSAs are a family ofalgebras on high-dimensional vector representations. They arose in cognitivescience from the need to unify neural processing and the kind of symbolicreasoning that humans perform. While machine learning methods have benefitedfrom category theoretical analyses, VSAs have not yet received similartreatment. In this paper, we present a first attempt at applying categorytheory to VSAs. Specifically, we conduct a brief literature surveydemonstrating the lacking intersection of these two topics, provide a list ofdesiderata for VSAs, and propose that VSAs may be understood as a (division)rig in a category enriched over a monoid in Met (the category of Lawvere metricspaces). This final contribution suggests that VSAs may be generalised beyondcurrent implementations. It is our hope that grounding VSAs in category theorywill lead to more rigorous connections with other research, both within andbeyond, learning and cognition.</description><author>Nolan P Shaw, P Michael Furlong, Britt Anderson, Jeff Orchard</author><pubDate>Thu, 09 Jan 2025 16:49:04 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.05368v1</guid></item><item><title>1-2-1: Renaissance of Single-Network Paradigm for Virtual Try-On</title><link>http://arxiv.org/abs/2501.05369v1</link><description>Virtual Try-On (VTON) has become a crucial tool in ecommerce, enabling therealistic simulation of garments on individuals while preserving their originalappearance and pose. Early VTON methods relied on single generative networks,but challenges remain in preserving fine-grained garment details due tolimitations in feature extraction and fusion. To address these issues, recentapproaches have adopted a dual-network paradigm, incorporating a complementary"ReferenceNet" to enhance garment feature extraction and fusion. Whileeffective, this dual-network approach introduces significant computationaloverhead, limiting its scalability for high-resolution and long-durationimage/video VTON applications. In this paper, we challenge the dual-networkparadigm by proposing a novel single-network VTON method that overcomes thelimitations of existing techniques. Our method, namely MNVTON, introduces aModality-specific Normalization strategy that separately processes text, imageand video inputs, enabling them to share the same attention layers in a VTONnetwork. Extensive experimental results demonstrate the effectiveness of ourapproach, showing that it consistently achieves higher-quality, more detailedresults for both image and video VTON tasks. Our results suggest that thesingle-network paradigm can rival the performance of dualnetwork approaches,offering a more efficient alternative for high-quality, scalable VTONapplications.</description><author>Shuliang Ning, Yipeng Qin, Xiaoguang Han</author><pubDate>Thu, 09 Jan 2025 16:49:04 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.05369v1</guid></item><item><title>Search-o1: Agentic Search-Enhanced Large Reasoning Models</title><link>http://arxiv.org/abs/2501.05366v1</link><description>Large reasoning models (LRMs) like OpenAI-o1 have demonstrated impressivelong stepwise reasoning capabilities through large-scale reinforcementlearning. However, their extended reasoning processes often suffer fromknowledge insufficiency, leading to frequent uncertainties and potentialerrors. To address this limitation, we introduce \textbf{Search-o1}, aframework that enhances LRMs with an agentic retrieval-augmented generation(RAG) mechanism and a Reason-in-Documents module for refining retrieveddocuments. Search-o1 integrates an agentic search workflow into the reasoningprocess, enabling dynamic retrieval of external knowledge when LRMs encounteruncertain knowledge points. Additionally, due to the verbose nature ofretrieved documents, we design a separate Reason-in-Documents module to deeplyanalyze the retrieved information before injecting it into the reasoning chain,minimizing noise and preserving coherent reasoning flow. Extensive experimentson complex reasoning tasks in science, mathematics, and coding, as well as sixopen-domain QA benchmarks, demonstrate the strong performance of Search-o1.This approach enhances the trustworthiness and applicability of LRMs in complexreasoning tasks, paving the way for more reliable and versatile intelligentsystems. The code is available at\url{https://github.com/sunnynexus/Search-o1}.</description><author>Xiaoxi Li, Guanting Dong, Jiajie Jin, Yuyao Zhang, Yujia Zhou, Yutao Zhu, Peitian Zhang, Zhicheng Dou</author><pubDate>Thu, 09 Jan 2025 16:48:17 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.05366v1</guid></item><item><title>Extracting Affect Aggregates from Longitudinal Social Media Data with Temporal Adapters for Large Language Models</title><link>http://arxiv.org/abs/2409.17990v2</link><description>This paper proposes temporally aligned Large Language Models (LLMs) as a toolfor longitudinal analysis of social media data. We fine-tune Temporal Adaptersfor Llama 3 8B on full timelines from a panel of British Twitter users, andextract longitudinal aggregates of emotions and attitudes with establishedquestionnaires. We focus our analysis on the beginning of the COVID-19 pandemicthat had a strong impact on public opinion and collective emotions. We validateour estimates against representative British survey data and find strongpositive, significant correlations for several collective emotions. Theobtained estimates are robust across multiple training seeds and promptformulations, and in line with collective emotions extracted using atraditional classification model trained on labeled data. We demonstrate theflexibility of our method on questions of public opinion for which nopre-trained classifier is available. Our work extends the analysis of affect inLLMs to a longitudinal setting through Temporal Adapters. It enables flexible,new approaches towards the longitudinal analysis of social media data.</description><author>Georg Ahnert, Max Pellert, David Garcia, Markus Strohmaier</author><pubDate>Thu, 09 Jan 2025 16:47:32 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2409.17990v2</guid></item><item><title>No-Regret Linear Bandits under Gap-Adjusted Misspecification</title><link>http://arxiv.org/abs/2501.05361v1</link><description>This work studies linear bandits under a new notion of gap-adjustedmisspecification and is an extension of Liu et al. (2023). When the underlyingreward function is not linear, existing linear bandits work usually relies on auniform misspecification parameter $\epsilon$ that measures the sup-norm errorof the best linear approximation. This results in an unavoidable linear regretwhenever $\epsilon &gt; 0$. We propose a more natural model of misspecificationwhich only requires the approximation error at each input $x$ to beproportional to the suboptimality gap at $x$. It captures the intuition that,for optimization problems, near-optimal regions should matter more and we cantolerate larger approximation errors in suboptimal regions. Quite surprisingly, we show that the classical LinUCB algorithm -- designedfor the realizable case -- is automatically robust against such$\rho$-gap-adjusted misspecification with parameter $\rho$ diminishing at$O(1/(d \sqrt{\log T}))$. It achieves a near-optimal $O(\sqrt{T})$ regret forproblems that the best-known regret is almost linear in time horizon $T$. Wefurther advance this frontier by presenting a novel phased elimination-basedalgorithm whose gap-adjusted misspecification parameter $\rho = O(1/\sqrt{d})$does not scale with $T$. This algorithm attains optimal $O(\sqrt{T})$ regretand is deployment-efficient, requiring only $\log T$ batches of exploration. Italso enjoys an adaptive $O(\log T)$ regret when a constant suboptimality gapexists. Technically, our proof relies on a novel self-bounding argument thatbounds the part of the regret due to misspecification by the regret itself, anda new inductive lemma that limits the misspecification error within thesuboptimality gap for all valid actions in each batch selected by G-optimaldesign.</description><author>Chong Liu, Dan Qiao, Ming Yin, Ilija Bogunovic, Yu-Xiang Wang</author><pubDate>Thu, 09 Jan 2025 16:44:53 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.05361v1</guid></item><item><title>CROPS: Model-Agnostic Training-Free Framework for Safe Image Synthesis with Latent Diffusion Models</title><link>http://arxiv.org/abs/2501.05359v1</link><description>With advances in diffusion models, image generation has shown significantperformance improvements. This raises concerns about the potential abuse ofimage generation, such as the creation of explicit or violent images, commonlyreferred to as Not Safe For Work (NSFW) content. To address this, the StableDiffusion model includes several safety checkers to censor initial text promptsand final output images generated from the model. However, recent research hasshown that these safety checkers have vulnerabilities against adversarialattacks, allowing them to generate NSFW images. In this paper, we find thatthese adversarial attacks are not robust to small changes in text prompts orinput latents. Based on this, we propose CROPS (Circular or RandOm Prompts forSafety), a model-agnostic framework that easily defends against adversarialattacks generating NSFW images without requiring additional training. Moreover,we develop an approach that utilizes one-step diffusion models for efficientNSFW detection (CROPS-1), further reducing computational resources. Wedemonstrate the superiority of our method in terms of performance andapplicability.</description><author>Junha Park, Ian Ryu, Jaehui Hwang, Hyungkeun Park, Jiyoon Kim, Jong-Seok Lee</author><pubDate>Thu, 09 Jan 2025 16:43:21 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.05359v1</guid></item><item><title>GPT4Scene: Understand 3D Scenes from Videos with Vision-Language Models</title><link>http://arxiv.org/abs/2501.01428v3</link><description>In recent years, 2D Vision-Language Models (VLMs) have made significantstrides in image-text understanding tasks. However, their performance in 3Dspatial comprehension, which is critical for embodied intelligence, remainslimited. Recent advances have leveraged 3D point clouds and multi-view imagesas inputs, yielding promising results. However, we propose exploring a purelyvision-based solution inspired by human perception, which merely relies onvisual cues for 3D spatial understanding. This paper empirically investigatesthe limitations of VLMs in 3D spatial knowledge, revealing that their primaryshortcoming lies in the lack of global-local correspondence between the sceneand individual frames. To address this, we introduce GPT4Scene, a novel visualprompting paradigm in VLM training and inference that helps build theglobal-local relationship, significantly improving the 3D spatial understandingof indoor scenes. Specifically, GPT4Scene constructs a 3D Bird's Eye View (BEV)image from the video and marks consistent object IDs across both frames and theBEV image. The model then inputs the concatenated BEV image and video frameswith markers. In zero-shot evaluations, GPT4Scene improves performance overclosed-source VLMs like GPT-4o. Additionally, we prepare a processed videodataset consisting of 165K text annotation to fine-tune open-source VLMs,achieving state-of-the-art performance on all 3D understanding tasks.Surprisingly, after training with the GPT4Scene paradigm, VLMs consistentlyimprove during inference, even without visual prompting and BEV image asexplicit correspondence. It demonstrates that the proposed paradigm helps VLMsdevelop an intrinsic ability to understand 3D scenes, which paves the way for anoninvasive approach to extending pre-trained VLMs for 3D scene understanding.</description><author>Zhangyang Qi, Zhixiong Zhang, Ye Fang, Jiaqi Wang, Hengshuang Zhao</author><pubDate>Thu, 09 Jan 2025 16:41:07 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.01428v3</guid></item><item><title>TradingAgents: Multi-Agents LLM Financial Trading Framework</title><link>http://arxiv.org/abs/2412.20138v2</link><description>Significant progress has been made in automated problem-solving usingsocieties of agents powered by large language models (LLMs). In finance,efforts have largely focused on single-agent systems handling specific tasks ormulti-agent frameworks independently gathering data. However, multi-agentsystems' potential to replicate real-world trading firms' collaborativedynamics remains underexplored. TradingAgents proposes a novel stock tradingframework inspired by trading firms, featuring LLM-powered agents inspecialized roles such as fundamental analysts, sentiment analysts, technicalanalysts, and traders with varied risk profiles. The framework includes Bulland Bear researcher agents assessing market conditions, a risk management teammonitoring exposure, and traders synthesizing insights from debates andhistorical data to make informed decisions. By simulating a dynamic,collaborative trading environment, this framework aims to improve tradingperformance. Detailed architecture and extensive experiments reveal itssuperiority over baseline models, with notable improvements in cumulativereturns, Sharpe ratio, and maximum drawdown, highlighting the potential ofmulti-agent LLM frameworks in financial trading. More details on TradingAgentsare available at https://TradingAgents-AI.github.io.</description><author>Yijia Xiao, Edward Sun, Di Luo, Wei Wang</author><pubDate>Thu, 09 Jan 2025 16:36:26 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.20138v2</guid></item><item><title>Unsupervised representation learning with Hebbian synaptic and structural plasticity in brain-like feedforward neural networks</title><link>http://arxiv.org/abs/2406.04733v2</link><description>Neural networks that can capture key principles underlying brain computationoffer exciting new opportunities for developing artificial intelligence andbrain-like computing algorithms. Such networks remain biologically plausiblewhile leveraging localized forms of synaptic learning rules and modular networkarchitecture found in the neocortex. Compared to backprop-driven deep learningapproches, they provide more suitable models for deployment of neuromorphichardware and have greater potential for scalability on large-scale computingclusters. The development of such brain-like neural networks depends on havinga learning procedure that can build effective internal representations fromdata. In this work, we introduce and evaluate a brain-like neural network modelcapable of unsupervised representation learning. It builds on the BayesianConfidence Propagation Neural Network (BCPNN), which has earlier beenimplemented as abstract as well as biophyscially detailed recurrent attractorneural networks explaining various cortical associative memory phenomena. Herewe developed a feedforward BCPNN model to perform representation learning byincorporating a range of brain-like attributes derived from neocorticalcircuits such as cortical columns, divisive normalization, Hebbian synapticplasticity, structural plasticity, sparse activity, and sparse patchyconnectivity. The model was tested on a diverse set of popular machine learningbenchmarks: grayscale images (MNIST, F-MNIST), RGB natural images (SVHN,CIFAR-10), QSAR (MUV, HIV), and malware detection (EMBER). The performance ofthe model when using a linear classifier to predict the class labels faredcompetitively with conventional multi-layer perceptrons and otherstate-of-the-art brain-like neural networks.</description><author>Naresh Ravichandran, Anders Lansner, Pawel Herman</author><pubDate>Thu, 09 Jan 2025 16:30:53 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.04733v2</guid></item><item><title>PFML: Self-Supervised Learning of Time-Series Data Without Representation Collapse</title><link>http://arxiv.org/abs/2411.10087v2</link><description>Self-supervised learning (SSL) is a data-driven learning approach thatutilizes the innate structure of the data to guide the learning process. Incontrast to supervised learning, which depends on external labels, SSL utilizesthe inherent characteristics of the data to produce its own supervisory signal.However, one frequent issue with SSL methods is representation collapse, wherethe model outputs a constant input-invariant feature representation. This issuehinders the potential application of SSL methods to new data modalities, astrying to avoid representation collapse wastes researchers' time and effort.This paper introduces a novel SSL algorithm for time-series data calledPrediction of Functionals from Masked Latents (PFML). Instead of predictingmasked input signals or their latent representations directly, PFML operates bypredicting statistical functionals of the input signal corresponding to maskedembeddings, given a sequence of unmasked embeddings. The algorithm is designedto avoid representation collapse, rendering it straightforwardly applicable todifferent time-series data domains, such as novel sensor modalities in clinicaldata. We demonstrate the effectiveness of PFML through complex, real-lifeclassification tasks across three different data modalities: infant posture andmovement classification from multi-sensor inertial measurement unit data,emotion recognition from speech data, and sleep stage classification from EEGdata. The results show that PFML is superior to a conceptually similar SSLmethod and a contrastive learning-based SSL method. Additionally, PFML is onpar with the current state-of-the-art SSL method, while also being conceptuallysimpler and without suffering from representation collapse.</description><author>Einari Vaaras, Manu Airaksinen, Okko Räsänen</author><pubDate>Thu, 09 Jan 2025 16:22:42 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2411.10087v2</guid></item><item><title>AccentBox: Towards High-Fidelity Zero-Shot Accent Generation</title><link>http://arxiv.org/abs/2409.09098v2</link><description>While recent Zero-Shot Text-to-Speech (ZS-TTS) models have achieved highnaturalness and speaker similarity, they fall short in accent fidelity andcontrol. To address this issue, we propose zero-shot accent generation thatunifies Foreign Accent Conversion (FAC), accented TTS, and ZS-TTS, with a noveltwo-stage pipeline. In the first stage, we achieve state-of-the-art (SOTA) onAccent Identification (AID) with 0.56 f1 score on unseen speakers. In thesecond stage, we condition a ZS-TTS system on the pretrained speaker-agnosticaccent embeddings extracted by the AID model. The proposed system achieveshigher accent fidelity on inherent/cross accent generation, and enables unseenaccent generation.</description><author>Jinzuomu Zhong, Korin Richmond, Zhiba Su, Siqi Sun</author><pubDate>Thu, 09 Jan 2025 16:20:05 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2409.09098v2</guid></item><item><title>JAQ: Joint Efficient Architecture Design and Low-Bit Quantization with Hardware-Software Co-Exploration</title><link>http://arxiv.org/abs/2501.05339v1</link><description>The co-design of neural network architectures, quantization precisions, andhardware accelerators offers a promising approach to achieving an optimalbalance between performance and efficiency, particularly for model deploymenton resource-constrained edge devices. In this work, we propose the JAQFramework, which jointly optimizes the three critical dimensions. However,effectively automating the design process across the vast search space of thosethree dimensions poses significant challenges, especially when pursuingextremely low-bit quantization. Specifical, the primary challenges include: (1)Memory overhead in software-side: Low-precision quantization-aware training canlead to significant memory usage due to storing large intermediate features andlatent weights for back-propagation, potentially causing memory exhaustion. (2)Search time-consuming in hardware-side: The discrete nature of hardwareparameters and the complex interplay between compiler optimizations andindividual operators make the accelerator search time-consuming. To addressthese issues, JAQ mitigates the memory overhead through a channel-wise sparsequantization (CSQ) scheme, selectively applying quantization to the mostsensitive components of the model during optimization. Additionally, JAQdesigns BatchTile, which employs a hardware generation network to encode allpossible tiling modes, thereby speeding up the search for the optimal compilermapping strategy. Extensive experiments demonstrate the effectiveness of JAQ,achieving approximately 7% higher Top-1 accuracy on ImageNet compared toprevious methods and reducing the hardware search time per iteration to 0.15seconds.</description><author>Mingzi Wang, Yuan Meng, Chen Tang, Weixiang Zhang, Yijian Qin, Yang Yao, Yingxin Li, Tongtong Feng, Xin Wang, Xun Guan, Zhi Wang, Wenwu Zhu</author><pubDate>Thu, 09 Jan 2025 16:10:06 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.05339v1</guid></item><item><title>Stream Aligner: Efficient Sentence-Level Alignment via Distribution Induction</title><link>http://arxiv.org/abs/2501.05336v1</link><description>The rapid advancement of large language models (LLMs) has led to significantimprovements in their capabilities, but also to increased concerns about theiralignment with human values and intentions. Current alignment strategies,including adaptive training and inference-time methods, have demonstratedpotential in this area. However, these approaches still struggle to balancedeployment complexity and capability across various tasks and difficulties. Inthis work, we introduce the Streaming Distribution Induce Aligner (StreamAligner), a novel alignment paradigm that combines efficiency with enhancedperformance in various tasks throughout the generation process. Stream Alignerachieves dynamic sentence-level correction by using a small model to learn thepreferences of the suffix sentence, iteratively correcting the suffix sentenceoutput by the upstream model, and then using the corrected sentence to replacethe suffix sentence in subsequent generations. Compared to Aligner, ourexperiments demonstrate that Stream Aligner reduces reliance on thecapabilities of additional models, enhances the reasoning abilities of LLMs,and decreases latency during user interaction. Specifically, Stream Aligner-2Bmodel has achieved an improvement of 76.1% in helpfulness, 36.0% inharmlessness on the tested Llama2-70B-chat model, and Stream Aligner-8B hasachieved an improvement of 3.5% on the math ability of the testedLlama3-70B-Instruct model.</description><author>Hantao Lou, Jiaming Ji, Kaile Wang, Yaodong Yang</author><pubDate>Thu, 09 Jan 2025 16:02:51 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.05336v1</guid></item><item><title>The Bakers and Millers Game with Restricted Locations</title><link>http://arxiv.org/abs/2501.05334v1</link><description>We study strategic location choice by customers and sellers, termed theBakers and Millers Game in the literature. In our generalized setting, eachmiller can freely choose any location for setting up a mill, while each bakeris restricted in the choice of location for setting up a bakery. For optimalbargaining power, a baker would like to select a location with many millers tobuy flour from and with little competition from other bakers. Likewise, amiller aims for a location with many bakers and few competing millers. Thus,both types of agents choose locations to optimize the ratio of agents ofopposite type divided by agents of the same type at their chosen location.Originally raised in the context of Fractional Hedonic Games, the Bakers andMillers Game has applications that range from commerce to product design. We study the impact of location restrictions on the properties of the game.While pure Nash equilibria trivially exist in the setting without locationrestrictions, we show via a sophisticated, efficient algorithm that even themore challenging restricted setting admits equilibria. Moreover, the computedequilibrium approximates the optimal social welfare by a factor of at most$2\left(\frac{e}{e-1}\right)$. Furthermore, we give tight bounds on the priceof anarchy/stability. On the conceptual side, the location choice feature adds a new layer to thestandard setting of Hedonic Games, in the sense that agents that select thesame location form a coalition. This allows to naturally restrict the possiblecoalitions that can be formed. With this, our model generalizes simplesymmetric Fractional Hedonic Games on complete bipartite valuation graphs andalso Hedonic Diversity Games with utilities single-peaked at 0. We believe thatthis generalization is also a very interesting direction for other types ofHedonic Games.</description><author>Simon Krogmann, Pascal Lenzner, Alexander Skopalik</author><pubDate>Thu, 09 Jan 2025 15:59:32 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.05334v1</guid></item><item><title>Stability and List-Replicability for Agnostic Learners</title><link>http://arxiv.org/abs/2501.05333v1</link><description>Two seminal papers--Alon, Livni, Malliaris, Moran (STOC 2019) and Bun, Livni,and Moran (FOCS 2020)--established the equivalence between online learnabilityand globally stable PAC learnability in binary classification. However, Chase,Chornomaz, Moran, and Yehudayoff (STOC 2024) recently showed that thisequivalence does not hold in the agnostic setting. Specifically, they provedthat in the agnostic setting, only finite hypothesis classes are globallystable learnable. Therefore, agnostic global stability is too restrictive tocapture interesting hypothesis classes. To address this limitation, Chase \emph{et al.} introduced two relaxations ofagnostic global stability. In this paper, we characterize the classes that arelearnable under their proposed relaxed conditions, resolving the two openproblems raised in their work. First, we prove that in the setting where the stability parameter can dependon the excess error (the gap between the learner's error and the bestachievable error by the hypothesis class), agnostic stability is fullycharacterized by the Littlestone dimension. Consequently, as in the realizablecase, this form of learnability is equivalent to online learnability. As part of the proof of this theorem, we strengthen the celebrated result ofBun et al. by showing that classes with infinite Littlestone dimension are notstably PAC learnable, even if we allow the stability parameter to depend on theexcess error. For the second relaxation proposed by Chase et al., we prove that only finitehypothesis classes are globally stable learnable even if we restrict theagnostic setting to distributions with small population loss.</description><author>Ari Blonda, Shan Gao, Hamed Hatami, Pooya Hatami</author><pubDate>Thu, 09 Jan 2025 15:59:15 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.05333v1</guid></item><item><title>AnCoGen: Analysis, Control and Generation of Speech with a Masked Autoencoder</title><link>http://arxiv.org/abs/2501.05332v1</link><description>This article introduces AnCoGen, a novel method that leverages a maskedautoencoder to unify the analysis, control, and generation of speech signalswithin a single model. AnCoGen can analyze speech by estimating key attributes,such as speaker identity, pitch, content, loudness, signal-to-noise ratio, andclarity index. In addition, it can generate speech from these attributes andallow precise control of the synthesized speech by modifying them. Extensiveexperiments demonstrated the effectiveness of AnCoGen across speechanalysis-resynthesis, pitch estimation, pitch modification, and speechenhancement.</description><author>Samir Sadok, Simon Leglaive, Laurent Girin, Gaël Richard, Xavier Alameda-Pineda</author><pubDate>Thu, 09 Jan 2025 15:58:37 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.05332v1</guid></item><item><title>Knowledge Transfer in Model-Based Reinforcement Learning Agents for Efficient Multi-Task Learning</title><link>http://arxiv.org/abs/2501.05329v1</link><description>We propose an efficient knowledge transfer approach for model-basedreinforcement learning, addressing the challenge of deploying large worldmodels in resource-constrained environments. Our method distills ahigh-capacity multi-task agent (317M parameters) into a compact 1M parametermodel, achieving state-of-the-art performance on the MT30 benchmark with anormalized score of 28.45, a substantial improvement over the original 1Mparameter model's score of 18.93. This demonstrates the ability of ourdistillation technique to consolidate complex multi-task knowledge effectively.Additionally, we apply FP16 post-training quantization, reducing the model sizeby 50% while maintaining performance. Our work bridges the gap between thepower of large models and practical deployment constraints, offering a scalablesolution for efficient and accessible multi-task reinforcement learning inrobotics and other resource-limited domains.</description><author>Dmytro Kuzmenko, Nadiya Shvai</author><pubDate>Thu, 09 Jan 2025 15:55:08 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.05329v1</guid></item><item><title>OpenOmni: Large Language Models Pivot Zero-shot Omnimodal Alignment across Language with Real-time Self-Aware Emotional Speech Synthesis</title><link>http://arxiv.org/abs/2501.04561v2</link><description>Recent advancements in omnimodal learning have been achieved in understandingand generation across images, text, and speech, though mainly withinproprietary models. Limited omnimodal datasets and the inherent challengesassociated with real-time emotional speech generation have hindered open-sourceprogress. To address these issues, we propose openomni, a two-stage trainingmethod combining omnimodal alignment and speech generation to develop astate-of-the-art omnimodal large language model. In the alignment phase, apre-trained speech model is further trained on text-image tasks to generalizefrom vision to speech in a (near) zero-shot manner, outperforming modelstrained on tri-modal datasets. In the speech generation phase, a lightweightdecoder facilitates real-time emotional speech through training on speech tasksand preference learning. Experiments demonstrate that openomni consistentlyimproves across omnimodal, vision-language, and speech-language evaluations,enabling natural, emotion-rich dialogues and real-time emotional speechgeneration.</description><author>Run Luo, Ting-En Lin, Haonan Zhang, Yuchuan Wu, Xiong Liu, Min Yang, Yongbin Li, Longze Chen, Jiaming Li, Lei Zhang, Yangyi Chen, Hamid Alinejad-Rokny, Fei Huang</author><pubDate>Thu, 09 Jan 2025 15:54:14 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.04561v2</guid></item><item><title>The explanation dialogues: an expert focus study to understand requirements towards explanations within the GDPR</title><link>http://arxiv.org/abs/2501.05325v1</link><description>Explainable AI (XAI) provides methods to understand non-interpretable machinelearning models. However, we have little knowledge about what legal expertsexpect from these explanations, including their legal compliance with, andvalue against European Union legislation. To close this gap, we present theExplanation Dialogues, an expert focus study to uncover the expectations,reasoning, and understanding of legal experts and practitioners towards XAI,with a specific focus on the European General Data Protection Regulation. Thestudy consists of an online questionnaire and follow-up interviews, and iscentered around a use-case in the credit domain. We extract both a set ofhierarchical and interconnected codes using grounded theory, and present thestandpoints of the participating experts towards XAI. We find that thepresented explanations are hard to understand and lack information, and discussissues that can arise from the different interests of the data controller andsubject. Finally, we present a set of recommendations for developers of XAImethods, and indications of legal areas of discussion. Among others,recommendations address the presentation, choice, and content of anexplanation, technical risks as well as the end-user, while we provide legalpointers to the contestability of explanations, transparency thresholds,intellectual property rights as well as the relationship between involvedparties.</description><author>Laura State, Alejandra Bringas Colmenarejo, Andrea Beretta, Salvatore Ruggieri, Franco Turini, Stephanie Law</author><pubDate>Thu, 09 Jan 2025 15:50:02 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.05325v1</guid></item><item><title>Distributed Learning and Inference Systems: A Networking Perspective</title><link>http://arxiv.org/abs/2501.05323v1</link><description>Machine learning models have achieved, and in some cases surpassed,human-level performance in various tasks, mainly through centralized trainingof static models and the use of large models stored in centralized clouds forinference. However, this centralized approach has several drawbacks, includingprivacy concerns, high storage demands, a single point of failure, andsignificant computing requirements. These challenges have driven interest indeveloping alternative decentralized and distributed methods for AI trainingand inference. Distribution introduces additional complexity, as it requiresmanaging multiple moving parts. To address these complexities and fill a gap inthe development of distributed AI systems, this work proposes a novelframework, Data and Dynamics-Aware Inference and Training Networks (DA-ITN).The different components of DA-ITN and their functions are explored, and theassociated challenges and research areas are highlighted.</description><author>Hesham G. Moussa, Arashmid Akhavain, S. Maryam Hosseini, Bill McCormick</author><pubDate>Thu, 09 Jan 2025 15:48:29 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.05323v1</guid></item><item><title>Robust Conformal Prediction Using Privileged Information</title><link>http://arxiv.org/abs/2406.05405v3</link><description>We develop a method to generate prediction sets with a guaranteed coveragerate that is robust to corruptions in the training data, such as missing ornoisy variables. Our approach builds on conformal prediction, a powerfulframework to construct prediction sets that are valid under the i.i.dassumption. Importantly, naively applying conformal prediction does not providereliable predictions in this setting, due to the distribution shift induced bythe corruptions. To account for the distribution shift, we assume access toprivileged information (PI). The PI is formulated as additional features thatexplain the distribution shift, however, they are only available duringtraining and absent at test time. We approach this problem by introducing anovel generalization of weighted conformal prediction and support our methodwith theoretical coverage guarantees. Empirical experiments on both real andsynthetic datasets indicate that our approach achieves a valid coverage rateand constructs more informative predictions compared to existing methods, whichare not supported by theoretical guarantees.</description><author>Shai Feldman, Yaniv Romano</author><pubDate>Thu, 09 Jan 2025 15:47:33 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.05405v3</guid></item><item><title>Voxel-Aggregated Feature Synthesis: Efficient Dense Mapping for Simulated 3D Reasoning</title><link>http://arxiv.org/abs/2411.10616v2</link><description>We address the issue of the exploding computational requirements of recentState-of-the-art (SOTA) open set multimodel 3D mapping (dense 3D mapping)algorithms and present Voxel-Aggregated Feature Synthesis (VAFS), a novelapproach to dense 3D mapping in simulation. Dense 3D mapping involvessegmenting and embedding sequential RGBD frames which are then fused into 3D.This leads to redundant computation as the differences between frames are smallbut all are individually segmented and embedded. This makes dense 3D mappingimpractical for research involving embodied agents in which the environment,and thus the mapping, must be modified with regularity. VAFS drasticallyreduces this computation by using the segmented point cloud computed by asimulator's physics engine and synthesizing views of each region. This reducesthe number of features to embed from the number of captured RGBD frames to thenumber of objects in the scene, effectively allowing a "ground truth" semanticmap to be computed an order of magnitude faster than traditional methods. Wetest the resulting representation by assessing the IoU scores of semanticqueries for different objects in the simulated scene, and find that VAFSexceeds the accuracy and speed of prior dense 3D mapping techniques.</description><author>Owen Burns, Rizwan Qureshi</author><pubDate>Thu, 09 Jan 2025 15:45:59 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2411.10616v2</guid></item><item><title>Less is More: The Influence of Pruning on the Explainability of CNNs</title><link>http://arxiv.org/abs/2302.08878v2</link><description>Modern, state-of-the-art Convolutional Neural Networks (CNNs) in computervision have millions of parameters. Thus, explaining the complex decisions ofsuch networks to humans is challenging. A technical approach to reduce CNNcomplexity is network pruning, where less important parameters are deleted. Thework presented in this paper investigates whether this technical complexityreduction also helps with perceived explainability. To do so, we conducted apre-study and two human-grounded experiments, assessing the effects ofdifferent pruning ratios on CNN explainability. Overall, we evaluated fourdifferent compression rates (i.e., CPR 2, 4, 8, and 32) with 37 500 tasks onMechanical Turk. Results indicate that lower compression rates have a positiveinfluence on explainability, while higher compression rates show negativeeffects. Furthermore, we were able to identify sweet spots that increase boththe perceived explainability and the model's performance.</description><author>David Weber, Florian Merkle, Pascal Schöttle, Stephan Schlögl</author><pubDate>Thu, 09 Jan 2025 15:35:59 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2302.08878v2</guid></item><item><title>Geometry Restoration and Dewarping of Camera-Captured Document Images</title><link>http://arxiv.org/abs/2501.03145v2</link><description>This research focuses on developing a method for restoring the topology ofdigital images of paper documents captured by a camera, using algorithms fordetection, segmentation, geometry restoration, and dewarping. Our methodologyemploys deep learning (DL) for document outline detection, followed by computervision (CV) to create a topological 2D grid using cubic polynomialinterpolation and correct nonlinear distortions by remapping the image. Usingclassical CV methods makes the document topology restoration process moreefficient and faster, as it requires significantly fewer computationalresources and memory. We developed a new pipeline for automatic documentdewarping and reconstruction, along with a framework and annotated dataset todemonstrate its efficiency. Our experiments confirm the promise of ourmethodology and its superiority over existing benchmarks (including mobile appsand popular DL solutions, such as RectiNet, DocGeoNet, and DocTr++) bothvisually and in terms of document readability via Optical Character Recognition(OCR) and geometry restoration metrics. This paves the way for creatinghigh-quality digital copies of paper documents and enhancing the efficiency ofOCR systems. Project page: https://github.com/HorizonParadox/DRCCBI</description><author>Valery Istomin, Oleg Pereziabov, Ilya Afanasyev</author><pubDate>Thu, 09 Jan 2025 15:31:29 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.03145v2</guid></item><item><title>Optimizing Distributed Deployment of Mixture-of-Experts Model Inference in Serverless Computing</title><link>http://arxiv.org/abs/2501.05313v1</link><description>With the advancement of serverless computing, running machine learning (ML)inference services over a serverless platform has been advocated, given itslabor-free scalability and cost effectiveness. Mixture-of-Experts (MoE) modelshave been a dominant type of model architectures to enable large modelsnowadays, with parallel expert networks. Serving large MoE models on serverlesscomputing is potentially beneficial, but has been underexplored due tosubstantial challenges in handling the skewed expert popularity andscatter-gather communication bottleneck in MoE model execution, forcost-efficient serverless MoE deployment and performance guarantee. We studyoptimized MoE model deployment and distributed inference serving on aserverless platform, that effectively predict expert selection, pipelinecommunication with model execution, and minimize the overall billed cost ofserving MoE models. Especially, we propose a Bayesian optimization frameworkwith multi-dimensional epsilon-greedy search to learn expert selections andoptimal MoE deployment achieving optimal billed cost, including: 1) a Bayesiandecision-making method for predicting expert popularity; 2) flexibly pipelinedscatter-gather communication; and 3) an optimal model deployment algorithm fordistributed MoE serving. Extensive experiments on AWS Lambda show that ourdesigns reduce the billed cost of all MoE layers by at least 75.67% compared toCPU clusters while maintaining satisfactory inference throughput. As comparedto LambdaML in serverless computing, our designs achieves 43.41% lower costwith a throughput decrease of at most 18.76%.</description><author>Mengfan Liu, Wei Wang, Chuan Wu</author><pubDate>Thu, 09 Jan 2025 15:29:33 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.05313v1</guid></item><item><title>Identity-Preserving Video Dubbing Using Motion Warping</title><link>http://arxiv.org/abs/2501.04586v2</link><description>Video dubbing aims to synthesize realistic, lip-synced videos from areference video and a driving audio signal. Although existing methods canaccurately generate mouth shapes driven by audio, they often fail to preserveidentity-specific features, largely because they do not effectively capture thenuanced interplay between audio cues and the visual attributes of referenceidentity . As a result, the generated outputs frequently lack fidelity inreproducing the unique textural and structural details of the referenceidentity. To address these limitations, we propose IPTalker, a novel and robustframework for video dubbing that achieves seamless alignment between drivingaudio and reference identity while ensuring both lip-sync accuracy andhigh-fidelity identity preservation. At the core of IPTalker is atransformer-based alignment mechanism designed to dynamically capture and modelthe correspondence between audio features and reference images, therebyenabling precise, identity-aware audio-visual integration. Building on thisalignment, a motion warping strategy further refines the results by spatiallydeforming reference images to match the target audio-driven configuration. Adedicated refinement process then mitigates occlusion artifacts and enhancesthe preservation of fine-grained textures, such as mouth details and skinfeatures. Extensive qualitative and quantitative evaluations demonstrate thatIPTalker consistently outperforms existing approaches in terms of realism, lipsynchronization, and identity retention, establishing a new state of the artfor high-quality, identity-consistent video dubbing.</description><author>Runzhen Liu, Qinjie Lin, Yunfei Liu, Lijian Lin, Ye Zhu, Yu Li, Chuhua Xian, Fa-Ting Hong</author><pubDate>Thu, 09 Jan 2025 15:27:58 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.04586v2</guid></item><item><title>Private Selection with Heterogeneous Sensitivities</title><link>http://arxiv.org/abs/2501.05309v1</link><description>Differentially private (DP) selection involves choosing a high-scoringcandidate from a finite candidate pool, where each score depends on a sensitivedataset. This problem arises naturally in a variety of contexts including modelselection, hypothesis testing, and within many DP algorithms. Classicalmethods, such as Report Noisy Max (RNM), assume all candidates' scores areequally sensitive to changes in a single individual's data, but this oftenisn't the case. To address this, algorithms like the Generalised ExponentialMechanism (GEM) leverage variability in candidate sensitivities. However, weobserve that while these algorithms can outperform RNM in some situations, theymay underperform in others - they can even perform worse than random selection.In this work, we explore how the distribution of scores and sensitivitiesimpacts DP selection mechanisms. In all settings we study, we find that thereexists a mechanism that utilises heterogeneity in the candidate sensitivitiesthat outperforms standard mechanisms like RNM. However, no single mechanismuniformly outperforms RNM. We propose using the correlation between the scoresand sensitivities as the basis for deciding which DP selection mechanism touse. Further, we design a slight variant of GEM, modified GEM that generallyperforms well whenever GEM performs poorly. Relying on the correlationheuristic we propose combined GEM, which adaptively chooses between GEM andmodified GEM and outperforms both in polarised settings.</description><author>Daniela Antonova, Allegra Laro, Audra McMillan, Lorenz Wolf</author><pubDate>Thu, 09 Jan 2025 15:25:07 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.05309v1</guid></item><item><title>Time Transfer: On Optimal Learning Rate and Batch Size In The Infinite Data Limit</title><link>http://arxiv.org/abs/2410.05838v2</link><description>One of the main challenges in optimal scaling of large language models (LLMs)is the prohibitive cost of hyperparameter tuning, particularly learning rate$\eta$ and batch size $B$. While techniques like $\mu$P (Yang et al., 2022)provide scaling rules for optimal $\eta$ transfer in the infinite model sizelimit, the optimal scaling behavior in the infinite data size limit remainsunknown. We fill in this gap by observing for the first time an intricatedependence of optimal $\eta$ scaling on the pretraining token budget $T$, $B$and its relation to the critical batch size $B_\mathrm{crit}$, which we measureto evolve as $B_\mathrm{crit} \propto T$. Furthermore, we show that the optimalbatch size is positively correlated with $B_\mathrm{crit}$: keeping it fixedbecomes suboptimal over time even if learning rate is scaled optimally.Surprisingly, our results demonstrate that the observed optimal $\eta$ and $B$dynamics are preserved with $\mu$P model scaling, challenging the conventionalview of $B_\mathrm{crit}$ dependence solely on loss value. Complementingoptimality, we examine the sensitivity of loss to changes in learning rate,where we find the sensitivity to decrease with increase of $T$ and to remainconstant with $\mu$P model scaling. We hope our results make the first steptowards a unified picture of the joint optimal data and model scaling.</description><author>Oleg Filatov, Jan Ebert, Jiangtao Wang, Stefan Kesselheim</author><pubDate>Thu, 09 Jan 2025 14:04:01 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.05838v2</guid></item><item><title>REFA: Reference Free Alignment for multi-preference optimization</title><link>http://arxiv.org/abs/2412.16378v2</link><description>We introduce REFA, a family of reference-free alignment methods that optimizeover multiple user preferences while enforcing fine-grained length control. Ourapproach integrates deviation-based weighting to emphasize high-qualityresponses more strongly, length normalization to prevent trivial short-responsesolutions, and an EOS-probability regularizer to mitigate dataset-inducedbrevity biases. Theoretically, we show that under the Uncertainty Reductionwith Sequence Length Assertion (URSLA), naive length normalization can stillincentivize length-based shortcuts. By contrast, REFA corrects these subtleincentives, guiding models toward genuinely more informative and higher-qualityoutputs. Empirically, REFA sets a new state-of-the-art among reference-freealignment methods, producing richer responses aligned more closely with humanpreferences. Compared to a base supervised fine-tuned (SFT) mistral-7b modelthat achieves 8.4% length-controlled win rate (LC-WR) and 6.2% win rate (WR),our best REFA configuration attains 21.62% LC-WR and 19.87% WR on theAlpacaEval v2 benchmark. This represents a substantial improvement over boththe strongest multi-preference baseline, InfoNCA (16.82% LC-WR, 10.44% WR), andthe strongest reference-free baseline, SimPO (20.01% LC-WR, 17.65% WR)</description><author>Taneesh Gupta, Rahul Madhavan, Xuchao Zhang, Chetan Bansal, Saravan Rajmohan</author><pubDate>Thu, 09 Jan 2025 15:20:31 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.16378v2</guid></item><item><title>AgentForge: A Flexible Low-Code Platform for Reinforcement Learning Agent Design</title><link>http://arxiv.org/abs/2410.19528v3</link><description>Developing a reinforcement learning (RL) agent often involves identifyingvalues for numerous parameters, covering the policy, reward function,environment, and agent-internal architecture. Since these parameters areinterrelated in complex ways, optimizing them is a black-box problem thatproves especially challenging for nonexperts. Although existingoptimization-as-a-service platforms (e.g., Vizier and Optuna) can handle suchproblems, they are impractical for RL systems, since the need for manual usermapping of each parameter to distinct components makes the effort cumbersome.It also requires understanding of the optimization process, limiting thesystems' application beyond the machine learning field and restricting accessin areas such as cognitive science, which models human decision-making. Totackle these challenges, the paper presents AgentForge, a flexible low-codeplatform to optimize any parameter set across an RL system. Available athttps://github.com/feferna/AgentForge, it allows an optimization problem to bedefined in a few lines of code and handed to any of the interfaced optimizers.With AgentForge, the user can optimize the parameters either individually orjointly. The paper presents an evaluation of its performance for a challengingvision-based RL problem.</description><author>Francisco Erivaldo Fernandes Junior, Antti Oulasvirta</author><pubDate>Thu, 09 Jan 2025 15:12:04 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.19528v3</guid></item><item><title>A Contrastive Symmetric Forward-Forward Algorithm (SFFA) for Continual Learning Tasks</title><link>http://arxiv.org/abs/2409.07387v2</link><description>The so-called Forward-Forward Algorithm (FFA) has recently gained momentum asan alternative to the conventional back-propagation algorithm for neuralnetwork learning, yielding competitive performance across various modelingtasks. By replacing the backward pass of gradient back-propagation with twocontrastive forward passes, the FFA avoids several shortcomings undergone byits predecessor (e.g., vanishing/exploding gradient) by enabling layer-wisetraining heuristics. In classification tasks, this contrastive method has beenproven to effectively create a latent sparse representation of the input data,ultimately favoring discriminability. However, FFA exhibits an inherentasymmetric gradient behavior due to an imbalanced loss function betweenpositive and negative data, adversely impacting on the model's generalizationcapabilities and leading to an accuracy degradation. To address this issue,this work proposes the Symmetric Forward-Forward Algorithm (SFFA), a novelmodification of the original FFA which partitions each layer into positive andnegative neurons. This allows the local fitness function to be defined as theratio between the activation of positive neurons and the overall layeractivity, resulting in a symmetric loss landscape during the training phase. Toevaluate the enhanced convergence of our method, we conduct several experimentsusing multiple image classification benchmarks, comparing the accuracy ofmodels trained with SFFA to those trained with its FFA counterpart. As abyproduct of this reformulation, we explore the advantages of using alayer-wise training algorithm for Continual Learning (CL) tasks. Thespecialization of neurons and the sparsity of their activations induced bylayer-wise training algorithms enable efficient CL strategies that incorporatenew knowledge (classes) into the neural network, while preventing catastrophicforgetting of previously...</description><author>Erik B. Terres-Escudero, Javier Del Ser, Pablo Garcia Bringas</author><pubDate>Thu, 09 Jan 2025 14:58:03 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2409.07387v2</guid></item><item><title>Cross-Attention Graph Neural Networks for Inferring Gene Regulatory Networks with Skewed Degree Distribution</title><link>http://arxiv.org/abs/2412.16220v3</link><description>Inferencing Gene Regulatory Networks (GRNs) from gene expression data is apivotal challenge in systems biology, and several innovative computationalmethods have been introduced. However, most of these studies have notconsidered the skewed degree distribution of genes. Specifically, some genesmay regulate multiple target genes while some genes may be regulated bymultiple regulator genes. Such a skewed degree distribution issue significantlycomplicates the application of directed graph embedding methods. To tackle thisissue, we propose the Cross-Attention Complex Dual Graph Embedding Model(XATGRN). Our XATGRN employs a cross-attention mechanism to effectively captureintricate gene interactions from gene expression profiles. Additionally, ituses a Dual Complex Graph Embedding approach to manage the skewed degreedistribution, thereby ensuring precise prediction of regulatory relationshipsand their directionality. Our model consistently outperforms existingstate-of-the-art methods across various datasets, underscoring its efficacy inelucidating complex gene regulatory mechanisms. Our codes used in this paperare publicly available at: https://github.com/kikixiong/XATGRN.</description><author>Jiaqi Xiong, Nan Yin, Shiyang Liang, Haoyang Li, Yingxu Wang, Duo Ai, Fang Pan, Jingjie Wang</author><pubDate>Thu, 09 Jan 2025 14:55:29 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.16220v3</guid></item><item><title>Drift2Matrix: Kernel-Induced Self Representation for Concept Drift Adaptation in Co-evolving Time Series</title><link>http://arxiv.org/abs/2501.01480v2</link><description>In the realm of time series analysis, tackling the phenomenon of conceptdrift poses a significant challenge. Concept drift -- characterized by theevolving statistical properties of time series data, affects the reliabilityand accuracy of conventional analysis models. This is particularly evident inco-evolving scenarios where interactions among variables are crucial. Thispaper presents Drift2Matrix, a novel framework that leverages kernel-inducedself-representation for adaptive responses to concept drift in time series.Drift2Matrix employs a kernel-based learning mechanism to generate arepresentation matrix, encapsulating the inherent dynamics of co-evolving timeseries. This matrix serves as a key tool for identification and adaptation toconcept drift by observing its temporal variations. Furthermore, Drift2Matrixeffectively identifies prevailing patterns and offers insights into emergingtrends through pattern evolution analysis. Our empirical evaluation ofDrift2Matrix across various datasets demonstrates its effectiveness in handlingthe complexities of concept drift. This approach introduces a novel perspectivein the theoretical domain of co-evolving time series analysis, enhancingadaptability and accuracy in the face of dynamic data environments.</description><author>Kunpeng Xu, Lifei Chen, Shengrui Wang</author><pubDate>Thu, 09 Jan 2025 14:52:13 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.01480v2</guid></item><item><title>Comparison Study: Glacier Calving Front Delineation in Synthetic Aperture Radar Images With Deep Learning</title><link>http://arxiv.org/abs/2501.05281v1</link><description>Calving front position variation of marine-terminating glaciers is anindicator of ice mass loss and a crucial parameter in numerical glacier models.Deep Learning (DL) systems can automatically extract this position fromSynthetic Aperture Radar (SAR) imagery, enabling continuous, weather- andillumination-independent, large-scale monitoring. This study presents the firstcomparison of DL systems on a common calving front benchmark dataset. Amulti-annotator study with ten annotators is performed to contrast thebest-performing DL system against human performance. The best DL model'soutputs deviate 221 m on average, while the average deviation of the humanannotators is 38 m. This significant difference shows that current DL systemsdo not yet match human performance and that further research is needed toenable fully automated monitoring of glacier calving fronts. The study ofVision Transformers, foundation models, and the inclusion and processingstrategy of more information are identified as avenues for future research.</description><author>Nora Gourmelon, Konrad Heidler, Erik Loebel, Daniel Cheng, Julian Klink, Anda Dong, Fei Wu, Noah Maul, Moritz Koch, Marcel Dreier, Dakota Pyles, Thorsten Seehaus, Matthias Braun, Andreas Maier, Vincent Christlein</author><pubDate>Thu, 09 Jan 2025 14:43:36 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.05281v1</guid></item><item><title>Learning convolution operators on compact Abelian groups</title><link>http://arxiv.org/abs/2501.05279v1</link><description>We consider the problem of learning convolution operators associated tocompact Abelian groups. We study a regularization-based approach and providecorresponding learning guarantees, discussing natural regularity condition onthe convolution kernel. More precisely, we assume the convolution kernel is afunction in a translation invariant Hilbert space and analyze a natural ridgeregression (RR) estimator. Building on existing results for RR, we characterizethe accuracy of the estimator in terms of finite sample bounds. Interestingly,regularity assumptions which are classical in the analysis of RR, have a noveland natural interpretation in terms of space/frequency localization.Theoretical results are illustrated by numerical simulations.</description><author>Emilia Magnani, Ernesto De Vito, Philipp Hennig, Lorenzo Rosasco</author><pubDate>Thu, 09 Jan 2025 14:43:08 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.05279v1</guid></item><item><title>Off-Policy Evaluation and Counterfactual Methods in Dynamic Auction Environments</title><link>http://arxiv.org/abs/2501.05278v1</link><description>Counterfactual estimators are critical for learning and refining policiesusing logged data, a process known as Off-Policy Evaluation (OPE). OPE allowsresearchers to assess new policies without costly experiments, speeding up theevaluation process. Online experimental methods, such as A/B tests, areeffective but often slow, thus delaying the policy selection and optimizationprocess. In this work, we explore the application of OPE methods in the context ofresource allocation in dynamic auction environments. Given the competitivenature of environments where rapid decision-making is crucial for gaining acompetitive edge, the ability to quickly and accurately assess algorithmicperformance is essential. By utilizing counterfactual estimators as apreliminary step before conducting A/B tests, we aim to streamline theevaluation process, reduce the time and resources required for experimentation,and enhance confidence in the chosen policies. Our investigation focuses on thefeasibility and effectiveness of using these estimators to predict the outcomesof potential resource allocation strategies, evaluate their performance, andfacilitate more informed decision-making in policy selection. Motivated by theoutcomes of our initial study, we envision an advanced analytics systemdesigned to seamlessly and dynamically assess new resource allocationstrategies and policies.</description><author>Ritam Guha, Nilavra Pathak</author><pubDate>Thu, 09 Jan 2025 14:39:40 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.05278v1</guid></item><item><title>Codebook LLMs: Evaluating LLMs as Measurement Tools for Political Science Concepts</title><link>http://arxiv.org/abs/2407.10747v2</link><description>Codebooks -- documents that operationalize concepts and outline annotationprocedures -- are used almost universally by social scientists when codingpolitical texts. To code these texts automatically, researchers are increasingturning to generative large language models (LLMs). However, there is limitedempirical evidence on whether "off-the-shelf" LLMs faithfully follow real-worldcodebook operationalizations and measure complex political constructs withsufficient accuracy. To address this, we gather and curate three real-worldpolitical science codebooks -- covering protest events, political violence andmanifestos -- along with their unstructured texts and human labels. We alsopropose a five-stage framework for codebook-LLM measurement: preparing acodebook for both humans and LLMs, testing LLMs' basic capabilities on acodebook, evaluating zero-shot measurement accuracy (i.e. off-the-shelfperformance), analyzing errors, and further (parameter-efficient) supervisedtraining of LLMs. We provide an empirical demonstration of this framework usingour three codebook datasets and several pretrained 7-12 billion open-weightLLMs. We find current open-weight LLMs have limitations in following codebookszero-shot, but that supervised instruction tuning can substantially improveperformance. Rather than suggesting the "best" LLM, our contribution lies inour codebook datasets, evaluation framework, and guidance for appliedresearchers who wish to implement their own codebook-LLM measurement projects.</description><author>Andrew Halterman, Katherine A. Keith</author><pubDate>Thu, 09 Jan 2025 14:35:36 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.10747v2</guid></item><item><title>Safeguarding System Prompts for LLMs</title><link>http://arxiv.org/abs/2412.13426v2</link><description>Large language models (LLMs) are increasingly utilized in applications wheresystem prompts, which guide model outputs, play a crucial role. These promptsoften contain business logic and sensitive information, making their protectionessential. However, adversarial and even regular user queries can exploit LLMvulnerabilities to expose these hidden prompts. To address this issue, wepropose PromptKeeper, a robust defense mechanism designed to safeguard systemprompts. PromptKeeper tackles two core challenges: reliably detecting promptleakage and mitigating side-channel vulnerabilities when leakage occurs. Byframing detection as a hypothesis-testing problem, PromptKeeper effectivelyidentifies both explicit and subtle leakage. Upon detection, it regeneratesresponses using a dummy prompt, ensuring that outputs remain indistinguishablefrom typical interactions when no leakage is present. PromptKeeper ensuresrobust protection against prompt extraction attacks via either adversarial orregular queries, while preserving conversational capability and runtimeefficiency during benign user interactions.</description><author>Zhifeng Jiang, Zhihua Jin, Guoliang He</author><pubDate>Thu, 09 Jan 2025 14:33:25 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.13426v2</guid></item><item><title>BTMTrack: Robust RGB-T Tracking via Dual-template Bridging and Temporal-Modal Candidate Elimination</title><link>http://arxiv.org/abs/2501.03616v2</link><description>RGB-T tracking leverages the complementary strengths of RGB and thermalinfrared (TIR) modalities to address challenging scenarios such as lowillumination and adverse weather. However, existing methods often fail toeffectively integrate temporal information and perform efficient cross-modalinteractions, which constrain their adaptability to dynamic targets. In thispaper, we propose BTMTrack, a novel framework for RGB-T tracking. The core ofour approach lies in the dual-template backbone network and the Temporal-ModalCandidate Elimination (TMCE) strategy. The dual-template backbone effectivelyintegrates temporal information, while the TMCE strategy focuses the model ontarget-relevant tokens by evaluating temporal and modal correlations, reducingcomputational overhead and avoiding irrelevant background noise. Building uponthis foundation, we propose the Temporal Dual Template Bridging (TDTB) module,which facilitates precise cross-modal fusion through dynamically filteredtokens. This approach further strengthens the interaction between templates andthe search region. Extensive experiments conducted on three benchmark datasetsdemonstrate the effectiveness of BTMTrack. Our method achieves state-of-the-artperformance, with a 72.3% precision rate on the LasHeR test set and competitiveresults on RGBT210 and RGBT234 datasets.</description><author>Zhongxuan Zhang, Bi Zeng, Xinyu Ni, Yimin Du</author><pubDate>Thu, 09 Jan 2025 14:33:09 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.03616v2</guid></item><item><title>Solving the Catastrophic Forgetting Problem in Generalized Category Discovery</title><link>http://arxiv.org/abs/2501.05272v1</link><description>Generalized Category Discovery (GCD) aims to identify a mix of known andnovel categories within unlabeled data sets, providing a more realistic settingfor image recognition. Essentially, GCD needs to remember existing patternsthoroughly to recognize novel categories. Recent state-of-the-art method SimGCDtransfers the knowledge from known-class data to the learning of novel classesthrough debiased learning. However, some patterns are catastrophically forgotduring adaptation and thus lead to poor performance in novel categoriesclassification. To address this issue, we propose a novel learning approach,LegoGCD, which is seamlessly integrated into previous methods to enhance thediscrimination of novel classes while maintaining performance on previouslyencountered known classes. Specifically, we design two types of techniquestermed as Local Entropy Regularization (LER) and Dual-views Kullback Leiblerdivergence constraint (DKL). The LER optimizes the distribution of potentialknown class samples in unlabeled data, thus ensuring the preservation ofknowledge related to known categories while learning novel classes. Meanwhile,DKL introduces Kullback Leibler divergence to encourage the model to produce asimilar prediction distribution of two view samples from the same image. Inthis way, it successfully avoids mismatched prediction and generates morereliable potential known class samples simultaneously. Extensive experimentsvalidate that the proposed LegoGCD effectively addresses the known categoryforgetting issue across all datasets, eg, delivering a 7.74% and 2.51% accuracyboost on known and novel classes in CUB, respectively. Our code is availableat: https://github.com/Cliffia123/LegoGCD.</description><author>Xinzi Cao, Xiawu Zheng, Guanhong Wang, Weijiang Yu, Yunhang Shen, Ke Li, Yutong Lu, Yonghong Tian</author><pubDate>Thu, 09 Jan 2025 14:31:54 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.05272v1</guid></item><item><title>Regret Analysis: a control perspective</title><link>http://arxiv.org/abs/2501.04572v2</link><description>Online learning and model reference adaptive control have many interestingintersections. One area where they differ however is in how the algorithms areanalyzed and what objective or metric is used to discriminate "good" algorithmsfrom "bad" algorithms. In adaptive control there are usually two objectives: 1)prove that all time varying parameters/states of the system are bounded, and 2)that the instantaneous error between the adaptively controlled system and areference system converges to zero over time (or at least a compact set). Foronline learning the performance of algorithms is often characterized by theregret the algorithm incurs. Regret is defined as the cumulative loss (cost)over time from the online algorithm minus the cumulative loss (cost) of thesingle optimal fixed parameter choice in hindsight. Another significantdifference between the two areas of research is with regard to the assumptionsmade in order to obtain said results. Adaptive control makes assumptions aboutthe input-output properties of the control problem and derives solutions for afixed error model or optimization task. In the online learning literatureresults are derived for classes of loss functions (i.e. convex) while a prioriassuming that all time varying parameters are bounded, which for manyoptimization tasks is not unrealistic, but is a non starter in controlapplications. In this work we discuss these differences in detail through theregret based analysis of gradient descent for convex functions and the controlbased analysis of a streaming regression problem. We close with a discussionabout the newly defined paradigm of online adaptive control and ask thefollowing question "Are regret optimal control strategies deployable?"</description><author>Travis E. Gibson, Sawal Acharya</author><pubDate>Thu, 09 Jan 2025 14:30:41 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.04572v2</guid></item><item><title>CellViT++: Energy-Efficient and Adaptive Cell Segmentation and Classification Using Foundation Models</title><link>http://arxiv.org/abs/2501.05269v1</link><description>Digital Pathology is a cornerstone in the diagnosis and treatment ofdiseases. A key task in this field is the identification and segmentation ofcells in hematoxylin and eosin-stained images. Existing methods for cellsegmentation often require extensive annotated datasets for training and arelimited to a predefined cell classification scheme. To overcome theselimitations, we propose $\text{CellViT}^{{\scriptscriptstyle ++}}$, a frameworkfor generalized cell segmentation in digital pathology.$\text{CellViT}^{{\scriptscriptstyle ++}}$ utilizes Vision Transformers withfoundation models as encoders to compute deep cell features and segmentationmasks simultaneously. To adapt to unseen cell types, we rely on acomputationally efficient approach. It requires minimal data for training andleads to a drastically reduced carbon footprint. We demonstrate excellentperformance on seven different datasets, covering a broad spectrum of celltypes, organs, and clinical settings. The framework achieves remarkablezero-shot segmentation and data-efficient cell-type classification.Furthermore, we show that $\text{CellViT}^{{\scriptscriptstyle ++}}$ canleverage immunofluorescence stainings to generate training datasets without theneed for pathologist annotations. The automated dataset generation approachsurpasses the performance of networks trained on manually labeled data,demonstrating its effectiveness in creating high-quality training datasetswithout expert annotations. To advance digital pathology,$\text{CellViT}^{{\scriptscriptstyle ++}}$ is available as an open-sourceframework featuring a user-friendly, web-based interface for visualization andannotation. The code is available underhttps://github.com/TIO-IKIM/CellViT-plus-plus.</description><author>Fabian Hörst, Moritz Rempe, Helmut Becker, Lukas Heine, Julius Keyl, Jens Kleesiek</author><pubDate>Thu, 09 Jan 2025 14:26:50 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.05269v1</guid></item><item><title>Patch-GAN Transfer Learning with Reconstructive Models for Cloud Removal</title><link>http://arxiv.org/abs/2501.05265v1</link><description>Cloud removal plays a crucial role in enhancing remote sensing imageanalysis, yet accurately reconstructing cloud-obscured regions remains asignificant challenge. Recent advancements in generative models have made thegeneration of realistic images increasingly accessible, offering newopportunities for this task. Given the conceptual alignment between imagegeneration and cloud removal tasks, generative models present a promisingapproach for addressing cloud removal in remote sensing. In this work, wepropose a deep transfer learning approach built on a generative adversarialnetwork (GAN) framework to explore the potential of the novel maskedautoencoder (MAE) image reconstruction model in cloud removal. Due to thecomplexity of remote sensing imagery, we further propose using a patch-wisediscriminator to determine whether each patch of the image is real or not. Theproposed reconstructive transfer learning approach demonstrates significantimprovements in cloud removal performance compared to other GAN-based methods.Additionally, whilst direct comparisons with some of the state-of-the-art cloudremoval techniques are limited due to unclear details regarding theirtrain/test data splits, the proposed model achieves competitive results basedon available benchmarks.</description><author>Wanli Ma, Oktay Karakus, Paul L. Rosin</author><pubDate>Thu, 09 Jan 2025 14:19:46 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.05265v1</guid></item><item><title>On the role of Artificial Intelligence methods in modern force-controlled manufacturing robotic tasks</title><link>http://arxiv.org/abs/2409.16828v3</link><description>This position paper explores the integration of Artificial Intelligence (AI)into force-controlled robotic tasks within the scope of advanced manufacturing,a cornerstone of Industry 4.0. AI's role in enhancing robotic manipulators -key drivers in the Fourth Industrial Revolution - is rapidly leading tosignificant innovations in smart manufacturing. The objective of this articleis to frame these innovations in practical force-controlled applications - e.g.deburring, polishing, and assembly tasks like peg-in-hole (PiH) - highlightingtheir necessity for maintaining high-quality production standards. By reportingon recent AI-based methodologies, this article contrasts them and identifiescurrent challenges to be addressed in future research. The analysis concludeswith a perspective on future research directions, emphasizing the need forcommon performance metrics to validate AI techniques, integration of variousenhancements for performance optimization, and the importance of validatingthem in relevant scenarios. These future directions aim to provide consistencywith already adopted approaches, so as to be compatible with manufacturingstandards, increasing the relevance of AI-driven methods in both academic andindustrial contexts.</description><author>Vincenzo Petrone, Enrico Ferrentino, Pasquale Chiacchio</author><pubDate>Thu, 09 Jan 2025 14:10:38 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2409.16828v3</guid></item><item><title>Towards Balanced Continual Multi-Modal Learning in Human Pose Estimation</title><link>http://arxiv.org/abs/2501.05264v1</link><description>3D human pose estimation (3D HPE) has emerged as a prominent research topic,particularly in the realm of RGB-based methods. However, RGB images aresusceptible to limitations such as sensitivity to lighting conditions andpotential user discomfort. Consequently, multi-modal sensing, which leveragesnon-intrusive sensors, is gaining increasing attention. Nevertheless,multi-modal 3D HPE still faces challenges, including modality imbalance and theimperative for continual learning. In this work, we introduce a novel balancedcontinual multi-modal learning method for 3D HPE, which harnesses the power ofRGB, LiDAR, mmWave, and WiFi. Specifically, we propose a Shapley value-basedcontribution algorithm to quantify the contribution of each modality andidentify modality imbalance. To address this imbalance, we employ a re-learningstrategy. Furthermore, recognizing that raw data is prone to noisecontamination, we develop a novel denoising continual learning approach. Thisapproach incorporates a noise identification and separation module to mitigatethe adverse effects of noise and collaborates with the balanced learningstrategy to enhance optimization. Additionally, an adaptive EWC mechanism isemployed to alleviate catastrophic forgetting. We conduct extensive experimentson the widely-adopted multi-modal dataset, MM-Fi, which demonstrate thesuperiority of our approach in boosting 3D pose estimation and mitigatingcatastrophic forgetting in complex scenarios. We will release our codes.</description><author>Jiaxuan Peng, Mengshi Qi, Dong Zhao, Huadong Ma</author><pubDate>Thu, 09 Jan 2025 14:19:33 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.05264v1</guid></item><item><title>Enhancing Plagiarism Detection in Marathi with a Weighted Ensemble of TF-IDF and BERT Embeddings for Low-Resource Language Processing</title><link>http://arxiv.org/abs/2501.05260v1</link><description>Plagiarism involves using another person's work or concepts without properattribution, presenting them as original creations. With the growing amount ofdata communicated in regional languages such as Marathi -- one of India'sregional languages -- it is crucial to design robust plagiarism detectionsystems tailored for low-resource languages. Language models like BidirectionalEncoder Representations from Transformers (BERT) have demonstrated exceptionalcapability in text representation and feature extraction, making them essentialtools for semantic analysis and plagiarism detection. However, the applicationof BERT for low-resource languages remains under-explored, particularly in thecontext of plagiarism detection. This paper presents a method to enhance theaccuracy of plagiarism detection for Marathi texts using BERT sentenceembeddings in conjunction with Term Frequency-Inverse Document Frequency(TF-IDF) feature representation. This approach effectively capturesstatistical, semantic, and syntactic aspects of text features through aweighted voting ensemble of machine learning models.</description><author>Atharva Mutsaddi, Aditya Choudhary</author><pubDate>Thu, 09 Jan 2025 14:14:18 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.05260v1</guid></item><item><title>Automating the Detection of Code Vulnerabilities by Analyzing GitHub Issues</title><link>http://arxiv.org/abs/2501.05258v1</link><description>In today's digital landscape, the importance of timely and accuratevulnerability detection has significantly increased. This paper presents anovel approach that leverages transformer-based models and machine learningtechniques to automate the identification of software vulnerabilities byanalyzing GitHub issues. We introduce a new dataset specifically designed forclassifying GitHub issues relevant to vulnerability detection. We then examinevarious classification techniques to determine their effectiveness. The resultsdemonstrate the potential of this approach for real-world application in earlyvulnerability detection, which could substantially reduce the window ofexploitation for software vulnerabilities. This research makes a keycontribution to the field by providing a scalable and computationally efficientframework for automated detection, enabling the prevention of compromisedsoftware usage before official notifications. This work has the potential toenhance the security of open-source software ecosystems.</description><author>Daniele Cipollone, Changjie Wang, Mariano Scazzariello, Simone Ferlin, Maliheh Izadi, Dejan Kostic, Marco Chiesa</author><pubDate>Thu, 09 Jan 2025 14:13:39 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.05258v1</guid></item><item><title>CallNavi: A Study and Challenge on Function Calling Routing and Invocation in Large Language Models</title><link>http://arxiv.org/abs/2501.05255v1</link><description>Interacting with a software system via a chatbot can be challenging,especially when the chatbot needs to generate API calls, in the right order andwith the right parameters, to communicate with the system. API calling inchatbot systems poses significant challenges, particularly in complex,multi-step tasks requiring accurate API selection and execution. We contributeto this domain in three ways: first, by introducing a novel dataset designed toassess models on API function selection, parameter generation, and nested APIcalls; second, by benchmarking state-of-the-art language models across varyinglevels of complexity to evaluate their performance in API function generationand parameter accuracy; and third, by proposing an enhanced API routing methodthat combines general-purpose large language models for API selection withfine-tuned models for parameter generation and some prompt engineeringapproach. These approaches lead to substantial improvements in handling complexAPI tasks, offering practical advancements for real-world API-driven chatbotsystems.</description><author>Yewei Song, Cedric Lothritz, Xunzhu Tang, Saad Ezzini, Jacques Klein, Tegawendé F. Bissyandé, Andrey Boytsov, Ulrick Ble, Anne Goujon</author><pubDate>Thu, 09 Jan 2025 14:12:43 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.05255v1</guid></item><item><title>Evaluation of uncertainty estimations for Gaussian process regression based machine learning interatomic potentials</title><link>http://arxiv.org/abs/2410.20398v2</link><description>Uncertainty estimations for machine learning interatomic potentials (MLIPs)are crucial for quantifying model error and identifying informative trainingsamples in active learning strategies. In this study, we evaluate uncertaintyestimations of Gaussian process regression (GPR)-based MLIPs, including thepredictive GPR standard deviation and ensemble-based uncertainties. We do thisin terms of calibration and in terms of impact on model performance in anactive learning scheme. We consider GPR models with Coulomb and Smooth Overlapof Atomic Positions (SOAP) representations as inputs to predict potentialenergy surfaces and excitation energies of molecules. Regarding calibration, wefind that ensemble-based uncertainty estimations show already poor globalcalibration (e.g., averaged over the whole test set). In contrast, the GPRstandard deviation shows good global calibration, but when grouping predictionsby their uncertainty, we observe a systematical bias for predictions with highuncertainty. Although an increasing uncertainty correlates with an increasingbias, the bias is not captured quantitatively by the uncertainty. Therefore,the GPR standard deviation can be useful to identify predictions with a highbias and error but, without further knowledge, should not be interpreted as aquantitative measure for a potential error range. Selecting the samples withthe highest GPR standard deviation from a fixed configuration space leads to amodel that overemphasizes the borders of the configuration space represented inthe fixed dataset. This may result in worse performance in more densely sampledareas but better generalization for extrapolation tasks.</description><author>Matthias Holzenkamp, Dongyu Lyu, Ulrich Kleinekathöfer, Peter Zaspel</author><pubDate>Thu, 09 Jan 2025 14:11:34 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.20398v2</guid></item><item><title>From Scientific Texts to Verifiable Code: Automating the Process with Transformers</title><link>http://arxiv.org/abs/2501.05252v1</link><description>Despite the vast body of research literature proposing algorithms with formalguarantees, the amount of verifiable code in today's systems remains minimal.This discrepancy stems from the inherent difficulty of verifying code,particularly due to the time-consuming nature and strict formalism of proofdetails that formal verification tools require. However, the emergence oftransformers in Large Language Models presents a promising solution to thischallenge. In this position paper, we believe that transformers have thepotential to read research papers that propose algorithms with formal proofsand translate these proofs into verifiable code. We leverage transformers tofirst build a formal structure of the proof using the original text from thepaper, and then to handle the tedious, low-level aspects of proofs that areoften omitted by humans. We argue that this approach can significantly reducethe barrier to formal verification. The above idea of reading papers to writeverifiable code opens new avenues for automating the verification of complexsystems, enabling a future where formally verified algorithms from academicresearch can more seamlessly transition into real-world software systems,thereby improving code reliability and security.</description><author>Changjie Wang, Mariano Scazzariello, Marco Chiesa</author><pubDate>Thu, 09 Jan 2025 14:03:35 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.05252v1</guid></item><item><title>RAG-WM: An Efficient Black-Box Watermarking Approach for Retrieval-Augmented Generation of Large Language Models</title><link>http://arxiv.org/abs/2501.05249v1</link><description>In recent years, tremendous success has been witnessed in Retrieval-AugmentedGeneration (RAG), widely used to enhance Large Language Models (LLMs) indomain-specific, knowledge-intensive, and privacy-sensitive tasks. However,attackers may steal those valuable RAGs and deploy or commercialize them,making it essential to detect Intellectual Property (IP) infringement. Mostexisting ownership protection solutions, such as watermarks, are designed forrelational databases and texts. They cannot be directly applied to RAGs becauserelational database watermarks require white-box access to detect IPinfringement, which is unrealistic for the knowledge base in RAGs. Meanwhile,post-processing by the adversary's deployed LLMs typically destructs textwatermark information. To address those problems, we propose a novel black-box"knowledge watermark" approach, named RAG-WM, to detect IP infringement ofRAGs. RAG-WM uses a multi-LLM interaction framework, comprising a WatermarkGenerator, Shadow LLM &amp; RAG, and Watermark Discriminator, to create watermarktexts based on watermark entity-relationship tuples and inject them into thetarget RAG. We evaluate RAG-WM across three domain-specific and twoprivacy-sensitive tasks on four benchmark LLMs. Experimental results show thatRAG-WM effectively detects the stolen RAGs in various deployed LLMs.Furthermore, RAG-WM is robust against paraphrasing, unrelated content removal,knowledge insertion, and knowledge expansion attacks. Lastly, RAG-WM can alsoevade watermark detection approaches, highlighting its promising application indetecting IP infringement of RAG systems.</description><author>Peizhuo Lv, Mengjie Sun, Hao Wang, Xiaofeng Wang, Shengzhi Zhang, Yuxuan Chen, Kai Chen, Limin Sun</author><pubDate>Thu, 09 Jan 2025 14:01:15 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.05249v1</guid></item><item><title>Deriving Coding-Specific Sub-Models from LLMs using Resource-Efficient Pruning</title><link>http://arxiv.org/abs/2501.05248v1</link><description>Large Language Models (LLMs) have demonstrated their exceptional performancein various complex code generation tasks. However, their broader adoption islimited by significant computational demands and high resource requirements,particularly memory and processing power. To mitigate such requirements, modelpruning techniques are used to create more compact models with significantlyfewer parameters. However, current approaches do not focus on the efficientextraction of programming-language-specific sub-models. In this work, weexplore the idea of efficiently deriving coding-specific sub-models throughunstructured pruning (i.e., Wanda). We investigate the impact of differentdomain-specific calibration datasets on pruning outcomes across three distinctdomains and extend our analysis to extracting four language-specificsub-models: Python, Java, C++, and JavaScript. We are the first to efficientlyextract programming-language-specific sub-models using appropriate calibrationdatasets while maintaining acceptable accuracy w.r.t. full models. We are alsothe first to provide analytical evidence that domain-specific tasks activatedistinct regions within LLMs, supporting the creation of specialized sub-modelsthrough unstructured pruning. We believe that this work has significantpotential to enhance LLM accessibility for coding by reducing computationalrequirements to enable local execution on consumer-grade hardware, andsupporting faster inference times critical for real-time development feedback.</description><author>Laura Puccioni, Alireza Farshin, Mariano Scazzariello, Changjie Wang, Marco Chiesa, Dejan Kostic</author><pubDate>Thu, 09 Jan 2025 14:00:01 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.05248v1</guid></item><item><title>Visual Semantic Navigation with Real Robots</title><link>http://arxiv.org/abs/2311.16623v2</link><description>Visual Semantic Navigation (VSN) is the ability of a robot to learn visualsemantic information for navigating in unseen environments. These VSN modelsare typically tested in those virtual environments where they are trained,mainly using reinforcement learning based approaches. Therefore, we do not yethave an in-depth analysis of how these models would behave in the real world.In this work, we propose a new solution to integrate VSN models into realrobots, so that we have true embodied agents. We also release a novel ROS-basedframework for VSN, ROS4VSN, so that any VSN-model can be easily deployed in anyROS-compatible robot and tested in a real setting. Our experiments with twodifferent robots, where we have embedded two state-of-the-art VSN agents,confirm that there is a noticeable performance difference of these VSNsolutions when tested in real-world and simulation environments. We hope thatthis research will endeavor to provide a foundation for addressing thisconsequential issue, with the ultimate aim of advancing the performance andefficiency of embodied agents within authentic real-world scenarios. Code toreproduce all our experiments can be found athttps://github.com/gramuah/ros4vsn.</description><author>Carlos Gutiérrez-Álvarez, Pablo Ríos-Navarro, Rafael Flor-Rodríguez, Francisco Javier Acevedo-Rodríguez, Roberto J. López-Sastre</author><pubDate>Thu, 09 Jan 2025 13:59:21 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.16623v2</guid></item><item><title>Online Prompt and Solver Selection for Program Synthesis</title><link>http://arxiv.org/abs/2501.05247v1</link><description>Large Language Models (LLMs) demonstrate impressive capabilities in thedomain of program synthesis. This level of performance is not, however,universal across all tasks, all LLMs and all prompting styles. There are manyareas where one LLM dominates, one prompting style dominates, or where callinga symbolic solver is a better choice than an LLM. A key challenge for the userthen, is to identify not only when an LLM is the right choice of solver, andthe appropriate LLM to call for a given synthesis task, but also the right wayto call it. A non-expert user who makes the wrong choice, incurs a cost both interms of results (number of tasks solved, and the time it takes to solve them)and financial cost, if using a closed-source language model via a commercialAPI. We frame this choice as an online learning problem. We use a multi-armedbandit algorithm to select which symbolic solver, or LLM and prompt combinationto deploy in order to maximize a given reward function (which may prioritizesolving time, number of synthesis tasks solved, or financial cost of solving).We implement an instance of this approach, called CYANEA, and evaluate it onsynthesis queries from the literature in ranking function synthesis, from thesyntax-guided synthesis competition, and fresh, unseen queries generated fromSMT problems. CYANEA solves 37.2\% more queries than the best single solver andachieves results within 4\% of the virtual best solver.</description><author>Yixuan Li, Lewis Frampton, Federico Mora, Elizabeth Polgreen</author><pubDate>Thu, 09 Jan 2025 13:57:09 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.05247v1</guid></item><item><title>Multi-class Decoding of Attended Speaker Direction Using Electroencephalogram and Audio Spatial Spectrum</title><link>http://arxiv.org/abs/2411.06928v2</link><description>Decoding the directional focus of an attended speaker from listeners'electroencephalogram (EEG) signals is essential for developing brain-computerinterfaces to improve the quality of life for individuals with hearingimpairment. Previous works have concentrated on binary directional focusdecoding, i.e., determining whether the attended speaker is on the left orright side of the listener. However, a more precise decoding of the exactdirection of the attended speaker is necessary for effective speech processing.Additionally, audio spatial information has not been effectively leveraged,resulting in suboptimal decoding results. In this paper, it is found that onthe recently presented dataset with 14-class directional focus, models relyingexclusively on EEG inputs exhibit significantly lower accuracy when decodingthe directional focus in both leave-one-subject-out and leave-one-trial-outscenarios. By integrating audio spatial spectra with EEG features, the decodingaccuracy can be effectively improved. The CNN, LSM-CNN, and Deformer models areemployed to decode the directional focus from listeners' EEG signals and audiospatial spectra. The proposed Sp-EEG-Deformer model achieves notable 14-classdecoding accuracies of 55.35% and 57.19% in leave-one-subject-out andleave-one-trial-out scenarios with a decision window of 1 second, respectively.Experiment results indicate increased decoding accuracy as the number ofalternative directions reduces. These findings suggest the efficacy of ourproposed dual modal directional focus decoding strategy.</description><author>Yuanming Zhang, Jing Lu, Fei Chen, Haoliang Du, Xia Gao, Zhibin Lin</author><pubDate>Thu, 09 Jan 2025 13:56:49 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2411.06928v2</guid></item><item><title>Towards a Problem-Oriented Domain Adaptation Framework for Machine Learning</title><link>http://arxiv.org/abs/2501.04528v1</link><description>Domain adaptation is a sub-field of machine learning that involvestransferring knowledge from a source domain to perform the same task in thetarget domain. It is a typical challenge in machine learning that arises, e.g.,when data is obtained from various sources or when using a data basis thatchanges over time. Recent advances in the field offer promising methods, but itis still challenging for researchers and practitioners to determine if domainadaptation is suitable for a given problem -- and, subsequently, to select theappropriate approach. This article employs design science research to develop aproblem-oriented framework for domain adaptation, which is matured in threeevaluation episodes. We describe a framework that distinguishes between fivedomain adaptation scenarios, provides recommendations for addressing eachscenario, and offers guidelines for determining if a problem falls into one ofthese scenarios. During the multiple evaluation episodes, the framework istested on artificial and real-world datasets and an experimental studyinvolving 100 participants. The evaluation demonstrates that the framework hasthe explanatory power to capture any domain adaptation problem effectively. Insummary, we provide clear guidance for researchers and practitioners who wantto employ domain adaptation but lack in-depth knowledge of the possibilities.</description><author>Philipp Spitzer, Dominik Martin, Laurin Eichberger, Niklas Kühl</author><pubDate>Wed, 08 Jan 2025 14:19:54 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.04528v1</guid></item></channel></rss>