<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/"><channel><title>Arxivaction recognition</title><link></link><description>Arxiv paper</description><language>en-US</language><lastBuildDate>Sun, 18 Feb 2024 18:05:34 GMT</lastBuildDate><generator>rfeed v1.0.0</generator><docs>https://github.com/svpino/rfeed/blob/master/README.md</docs><item><title>TikTokActions: A TikTok-Derived Video Dataset for Human Action Recognition</title><link>http://arxiv.org/abs/2402.08875v1</link><description>The increasing variety and quantity of tagged multimedia content on platformssuch as TikTok provides an opportunity to advance computer vision modeling. Wehave curated a distinctive dataset of 283,582 unique video clips categorizedunder 386 hashtags relating to modern human actions. We release this dataset asa valuable resource for building domain-specific foundation models for humanmovement modeling tasks such as action recognition. To validate this dataset,which we name TikTokActions, we perform two sets of experiments. First, wepretrain the state-of-the-art VideoMAEv2 with a ViT-base backbone onTikTokActions subset, and then fine-tune and evaluate on popular datasets suchas UCF101 and the HMDB51. We find that the performance of the model pre-trainedusing our Tik-Tok dataset is comparable to models trained on larger actionrecognition datasets (95.3% on UCF101 and 53.24% on HMDB51). Furthermore, ourinvestigation into the relationship between pre-training dataset size andfine-tuning performance reveals that beyond a certain threshold, theincremental benefit of larger training sets diminishes. This work introduces auseful TikTok video dataset that is available for public use and providesinsights into the marginal benefit of increasing pre-training dataset sizes forvideo-based foundation models.</description><author>Yang Qian, Yinan Sun, Ali Kargarandehkordi, Onur Cezmi Mutlu, Saimourya Surabhi, Pingyi Chen, Zain Jabbar, Dennis Paul Wall, Peter Washington</author><pubDate>Wed, 14 Feb 2024 00:41:10 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.08875v1</guid></item></channel></rss>